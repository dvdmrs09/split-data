{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an instruction that evaluates to the absolute value of top of the stack.", "response": "def _abs16(ins):\n    ''' Absolute value of top of the stack (16 bits in HL)\n    '''\n    output = _16bit_oper(ins.quad[2])\n    output.append('call __ABS16')\n    output.append('push hl')\n    REQUIRES.add('abs16.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _shru16(ins):\n    ''' Logical right shift 16bit unsigned integer.\n    The result is pushed onto the stack.\n\n    Optimizations:\n      * If 2nd op is 0 then\n        do nothing\n\n      * If 2nd op is 1\n        Shift Right Arithmetic\n    '''\n    op1, op2 = tuple(ins.quad[2:])\n    if is_int(op2):\n        op = int16(op2)\n        if op == 0:\n            return []\n\n        output = _16bit_oper(op1)\n        if op == 1:\n            output.append('srl h')\n            output.append('rr l')\n            output.append('push hl')\n            return output\n\n        output.append('ld b, %i' % op)\n    else:\n        output = _8bit_oper(op2)\n        output.append('ld b, a')\n        output.extend(_16bit_oper(op1))\n\n    label = tmp_label()\n    output.append('%s:' % label)\n    output.append('srl h')\n    output.append('rr l')\n    output.append('djnz %s' % label)\n    output.append('push hl')\n    return output", "response": "Logical right shift 16bit unsigned integer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a txt file and returns the content as a unicode string.", "response": "def read_txt_file(fname):\n    \"\"\"Reads a txt file, regardless of its encoding\n    \"\"\"\n    encodings = ['utf-8-sig', 'cp1252']\n    with open(fname, 'rb') as f:\n        content = bytes(f.read())\n\n    for i in encodings:\n        try:\n            result = content.decode(i)\n            if six.PY2:\n                result = result.encode('utf-8')\n            return result\n        except UnicodeDecodeError:\n            pass\n\n    global_.FILENAME = fname\n    errmsg.syntax_error(1, 'Invalid file encoding. Use one of: %s' % ', '.join(encodings))\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_file(fname, mode='rb', encoding='utf-8'):\n    if six.PY2 or 't' not in mode:\n        kwargs = {}\n    else:\n        kwargs = {'encoding': encoding}\n\n    return open(fname, mode, **kwargs)", "response": "A wrapper for open that supports both Python 2 and Python 3."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_int(str_num):\n    str_num = (str_num or \"\").strip().upper()\n    if not str_num:\n        return None\n\n    base = 10\n    if str_num.startswith('0X'):\n        base = 16\n        str_num = str_num[2:]\n    if str_num.endswith('H'):\n        base = 16\n        str_num = str_num[:-1]\n    if str_num.startswith('$'):\n        base = 16\n        str_num = str_num[1:]\n\n    try:\n        return int(str_num, base)\n    except ValueError:\n        return None", "response": "Given an integer number return its value or None if it could not be parsed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef out(self, l):\n        if not isinstance(l, list):\n            l = [l]\n\n        self.output.extend([int(i) & 0xFF for i in l])", "response": "Adds a list of bytes to the output string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef standard_block(self, _bytes):\n        self.out(self.BLOCK_STANDARD)  # Standard block ID\n        self.out(self.LH(1000))  # 1000 ms standard pause\n        self.out(self.LH(len(_bytes) + 1))  # + 1 for CHECKSUM byte\n\n        checksum = 0\n        for i in _bytes:\n            checksum ^= (int(i) & 0xFF)\n            self.out(i)\n\n        self.out(checksum)", "response": "Adds a standard block of bytes to the internal buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the TZX file to fname", "response": "def dump(self, fname):\n        \"\"\" Saves TZX file to fname\n        \"\"\"\n        with open(fname, 'wb') as f:\n            f.write(self.output)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving a generic standard header for the current object.", "response": "def save_header(self, _type, title, length, param1, param2):\n        \"\"\" Saves a generic standard header:\n                type:   00 -- Program\n                        01 -- Number Array\n                        02 -- Char Array\n                        03 -- Code\n\n                title:  Name title.\n                        Will be truncated to 10 chars and padded\n                        with spaces if necessary.\n\n                length: Data length (in bytes) of the next block.\n\n                param1: For CODE -> Start address.\n                        For PROGRAM -> Autostart line (>=32768 for no autostart)\n                        For DATA (02 & 03) high byte of param1 have the variable name.\n\n                param2: For CODE -> 32768\n                        For PROGRAM -> Start of the Variable area relative to program Start (Length of basic in bytes)\n                        For DATA (02 & 03) NOT USED\n\n        Info taken from: http://www.worldofspectrum.org/faq/reference/48kreference.htm#TapeDataStructure\n        \"\"\"\n        title = (title + 10 * ' ')[:10]  # Padd it with spaces\n        title_bytes = [ord(i) for i in title]  # Convert it to bytes\n\n        _bytes = [self.BLOCK_TYPE_HEADER, _type] + title_bytes + self.LH(length) + self.LH(param1) + self.LH(param2)\n        self.standard_block(_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef standard_bytes_header(self, title, addr, length):\n        self.save_header(self.HEADER_TYPE_CODE, title, length, param1=addr, param2=32768)", "response": "Generates a standard header block of CODE type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef standard_program_header(self, title, length, line=32768):\n        self.save_header(self.HEADER_TYPE_BASIC, title, length, param1=line, param2=length)", "response": "Generates a standard header block of PROGRAM type\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the given bytes as code.", "response": "def save_code(self, title, addr, _bytes):\n        \"\"\" Saves the given bytes as code. If bytes are strings,\n        its chars will be converted to bytes\n        \"\"\"\n        self.standard_bytes_header(title, addr, len(_bytes))\n        _bytes = [self.BLOCK_TYPE_DATA] + [(int(x) & 0xFF) for x in _bytes]  # & 0xFF truncates to bytes\n        self.standard_block(_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_program(self, title, bytes, line=32768):\n        self.standard_program_header(title, len(bytes), line)\n        bytes = [self.BLOCK_TYPE_DATA] + [(int(x) & 0xFF) for x in bytes]  # & 0xFF truncates to bytes\n        self.standard_block(bytes)", "response": "Saves the given bytes as a BASIC program."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a node for a string slice.", "response": "def make_node(cls, lineno, s, lower, upper):\n        \"\"\" Creates a node for a string slice. S is the string expression Tree.\n        Lower and upper are the bounds, if lower & upper are constants, and\n        s is also constant, then a string constant is returned.\n\n        If lower > upper, an empty string is returned.\n        \"\"\"\n        if lower is None or upper is None or s is None:\n            return None\n\n        if not check_type(lineno, Type.string, s):\n            return None\n\n        lo = up = None\n        base = NUMBER(api.config.OPTIONS.string_base.value, lineno=lineno)\n        lower = TYPECAST.make_node(gl.SYMBOL_TABLE.basic_types[gl.STR_INDEX_TYPE],\n                                   BINARY.make_node('MINUS', lower, base, lineno=lineno,\n                                                    func=lambda x, y: x - y), lineno)\n        upper = TYPECAST.make_node(gl.SYMBOL_TABLE.basic_types[gl.STR_INDEX_TYPE],\n                                   BINARY.make_node('MINUS', upper, base, lineno=lineno,\n                                                    func=lambda x, y: x - y), lineno)\n\n        if lower is None or upper is None:\n            return None\n\n        if is_number(lower):\n            lo = lower.value\n            if lo < gl.MIN_STRSLICE_IDX:\n                lower.value = lo = gl.MIN_STRSLICE_IDX\n\n        if is_number(upper):\n            up = upper.value\n            if up > gl.MAX_STRSLICE_IDX:\n                upper.value = up = gl.MAX_STRSLICE_IDX\n\n        if is_number(lower, upper):\n            if lo > up:\n                return STRING('', lineno)\n\n            if s.token == 'STRING':  # A constant string? Recalculate it now\n                up += 1\n                st = s.value.ljust(up)  # Procrustean filled (right)\n                return STRING(st[lo:up], lineno)\n\n            # a$(0 TO INF.) = a$\n            if lo == gl.MIN_STRSLICE_IDX and up == gl.MAX_STRSLICE_IDX:\n                return s\n\n        return cls(s, lower, upper, lineno)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the instruction sequence for converting from the given type to byte.", "response": "def to_byte(stype):\n    \"\"\" Returns the instruction sequence for converting from\n    the given type to byte.\n    \"\"\"\n    output = []\n\n    if stype in ('i8', 'u8'):\n        return []\n\n    if is_int_type(stype):\n        output.append('ld a, l')\n    elif stype == 'f16':\n        output.append('ld a, e')\n    elif stype == 'f':  # Converts C ED LH to byte\n        output.append('call __FTOU32REG')\n        output.append('ld a, l')\n        REQUIRES.add('ftou32reg.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_word(stype):\n    output = []  # List of instructions\n\n    if stype == 'u8':  # Byte to word\n        output.append('ld l, a')\n        output.append('ld h, 0')\n\n    elif stype == 'i8':  # Signed byte to word\n        output.append('ld l, a')\n        output.append('add a, a')\n        output.append('sbc a, a')\n        output.append('ld h, a')\n\n    elif stype == 'f16':  # Must MOVE HL into DE\n        output.append('ex de, hl')\n\n    elif stype == 'f':\n        output.append('call __FTOU32REG')\n        REQUIRES.add('ftou32reg.asm')\n\n    return output", "response": "Returns the instruction sequence for converting the given type stored in DE HL to word ( unsigned ) HL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_fixed(stype):\n    output = []  # List of instructions\n\n    if is_int_type(stype):\n        output = to_word(stype)\n        output.append('ex de, hl')\n        output.append('ld hl, 0')  # 'Truncate' the fixed point\n    elif stype == 'f':\n        output.append('call __FTOF16REG')\n        REQUIRES.add('ftof16reg.asm')\n\n    return output", "response": "Returns the instruction sequence for converting the given\n    type stored in DE HL to fixed DE HL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the instruction sequence for converting the given type stored in DE HL to fixed DE HL.", "response": "def to_float(stype):\n    \"\"\" Returns the instruction sequence for converting the given\n    type stored in DE,HL to fixed DE,HL.\n    \"\"\"\n    output = []  # List of instructions\n\n    if stype == 'f':\n        return []  # Nothing to do\n\n    if stype == 'f16':\n        output.append('call __F16TOFREG')\n        REQUIRES.add('f16tofreg.asm')\n        return output\n\n    # If we reach this point, it's an integer type\n    if stype == 'u8':\n        output.append('call __U8TOFREG')\n    elif stype == 'i8':\n        output.append('call __I8TOFREG')\n    else:\n        output = to_long(stype)\n        if stype in ('i16', 'i32'):\n            output.append('call __I32TOFREG')\n        else:\n            output.append('call __U32TOFREG')\n\n    REQUIRES.add('u32tofreg.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noutputting the ending sequence", "response": "def _end(ins):\n    \"\"\" Outputs the ending sequence\n    \"\"\"\n    global FLAG_end_emitted\n    output = _16bit_oper(ins.quad[1])\n    output.append('ld b, h')\n    output.append('ld c, l')\n\n    if FLAG_end_emitted:\n        return output + ['jp %s' % END_LABEL]\n\n    FLAG_end_emitted = True\n\n    output.append('%s:' % END_LABEL)\n    if OPTIONS.headerless.value:\n        return output + ['ret']\n\n    output.append('di')\n    output.append('ld hl, (%s)' % CALL_BACK)\n    output.append('ld sp, hl')\n    output.append('exx')\n    output.append('pop hl')\n    output.append('exx')\n    output.append('pop iy')\n    output.append('pop ix')\n    output.append('ei')\n    output.append('ret')\n    output.append('%s:' % CALL_BACK)\n    output.append('DEFW 0')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _data(ins):\n    output = []\n    t = ins.quad[1]\n    q = eval(ins.quad[2])\n\n    if t in ('i8', 'u8'):\n        size = 'B'\n    elif t in ('i16', 'u16'):\n        size = 'W'\n    elif t in ('i32', 'u32'):\n        size = 'W'\n        z = list()\n        for expr in ins.quad[2]:\n            z.extend(['(%s) & 0xFFFF' % expr, '(%s) >> 16' % expr])\n        q = z\n    elif t == 'str':\n        size = \"B\"\n        q = ['\"%s\"' % x.replace('\"', '\"\"') for x in q]\n    elif t == 'f':\n        dat_ = [api.fp.immediate_float(float(x)) for x in q]\n        for x in dat_:\n            output.extend(['DEFB %s' % x[0], 'DEFW %s, %s' % (x[1], x[2])])\n        return output\n    else:\n        raise InvalidIC(ins.quad, 'Unimplemented data size %s for %s' % (t, q))\n\n    for x in q:\n        output.append('DEF%s %s' % (size, x))\n\n    return output", "response": "Defines a data item for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _var(ins):\n    output = []\n    output.append('%s:' % ins.quad[1])\n    output.append('DEFB %s' % ((int(ins.quad[2]) - 1) * '00, ' + '00'))\n\n    return output", "response": "Defines a memory variable.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndefine a memory space with a default CONSTANT expression", "response": "def _varx(ins):\n    \"\"\" Defines a memory space with a default CONSTANT expression\n    1st parameter is the var name\n    2nd parameter is the type-size (u8 or i8 for byte, u16 or i16 for word, etc)\n    3rd parameter is the list of expressions. All of them will be converted to the\n        type required.\n    \"\"\"\n    output = []\n    output.append('%s:' % ins.quad[1])\n    q = eval(ins.quad[3])\n\n    if ins.quad[2] in ('i8', 'u8'):\n        size = 'B'\n    elif ins.quad[2] in ('i16', 'u16'):\n        size = 'W'\n    elif ins.quad[2] in ('i32', 'u32'):\n        size = 'W'\n        z = list()\n        for expr in q:\n            z.extend(['(%s) & 0xFFFF' % expr, '(%s) >> 16' % expr])\n        q = z\n    else:\n        raise InvalidIC(ins.quad, 'Unimplemented vard size: %s' % ins.quad[2])\n\n    for x in q:\n        output.append('DEF%s %s' % (size, x))\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _vard(ins):\n    output = []\n    output.append('%s:' % ins.quad[1])\n\n    q = eval(ins.quad[2])\n\n    for x in q:\n        if x[0] == '#':  # literal?\n            size_t = 'W' if x[1] == '#' else 'B'\n            output.append('DEF{0} {1}'.format(size_t, x.lstrip('#')))\n            continue\n\n        # must be an hex number\n        x = x.upper()\n        assert RE_HEXA.match(x), 'expected an hex number, got \"%s\"' % x\n        size_t = 'B' if len(x) <= 2 else 'W'\n        if x[0] > '9':  # Not a number?\n            x = '0' + x\n        output.append('DEF{0} {1}h'.format(size_t, x))\n\n    return output", "response": "Defines a memory space with a default set of bytes or words in hexadecimal."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _lvarx(ins):\n    output = []\n\n    l = eval(ins.quad[3])  # List of bytes to push\n    label = tmp_label()\n    offset = int(ins.quad[1])\n    tmp = list(ins.quad)\n    tmp[1] = label\n    ins.quad = tmp\n    AT_END.extend(_varx(ins))\n\n    output.append('push ix')\n    output.append('pop hl')\n    output.append('ld bc, %i' % -offset)\n    output.append('add hl, bc')\n    output.append('ex de, hl')\n    output.append('ld hl, %s' % label)\n    output.append('ld bc, %i' % (len(l) * YY_TYPES[ins.quad[2]]))\n    output.append('ldir')\n\n    return output", "response": "Defines a local variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefine a local variable. 1st param is offset of the local variable. 2nd param is a list of bytes in hexadecimal.", "response": "def _lvard(ins):\n    \"\"\" Defines a local variable. 1st param is offset of the local variable.\n    2nd param is a list of bytes in hexadecimal.\n    \"\"\"\n    output = []\n\n    l = eval(ins.quad[2])  # List of bytes to push\n    label = tmp_label()\n    offset = int(ins.quad[1])\n    tmp = list(ins.quad)\n    tmp[1] = label\n    ins.quad = tmp\n    AT_END.extend(_vard(ins))\n\n    output.append('push ix')\n    output.append('pop hl')\n    output.append('ld bc, %i' % -offset)\n    output.append('add hl, bc')\n    output.append('ex de, hl')\n    output.append('ld hl, %s' % label)\n    output.append('ld bc, %i' % len(l))\n    output.append('ldir')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate OUT to asm.", "response": "def _out(ins):\n    \"\"\" Translates OUT to asm.\n    \"\"\"\n    output = _8bit_oper(ins.quad[2])\n    output.extend(_16bit_oper(ins.quad[1]))\n    output.append('ld b, h')\n    output.append('ld c, l')\n    output.append('out (c), a')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntranslates IN to asm.", "response": "def _in(ins):\n    \"\"\" Translates IN to asm.\n    \"\"\"\n    output = _16bit_oper(ins.quad[1])\n    output.append('ld b, h')\n    output.append('ld c, l')\n    output.append('in a, (c)')\n    output.append('push af')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a 32 bit value from a memory address.", "response": "def _load32(ins):\n    \"\"\" Load a 32 bit value from a memory address\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    \"\"\"\n    output = _32bit_oper(ins.quad[2])\n    output.append('push de')\n    output.append('push hl')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a 32 bit fixed point value from a memory address.", "response": "def _loadf16(ins):\n    \"\"\" Load a 32 bit (16.16) fixed point value from a memory address\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    \"\"\"\n    output = _f16_oper(ins.quad[2])\n    output.append('push de')\n    output.append('push hl')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a floating point value from a memory address.", "response": "def _loadf(ins):\n    \"\"\" Loads a floating point value from a memory address.\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    \"\"\"\n    output = _float_oper(ins.quad[2])\n    output.extend(_fpush())\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _loadstr(ins):\n    temporal, output = _str_oper(ins.quad[2], no_exaf=True)\n\n    if not temporal:\n        output.append('call __LOADSTR')\n        REQUIRES.add('loadstr.asm')\n\n    output.append('push hl')\n    return output", "response": "Loads a string value from a memory address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _store8(ins):\n    output = _8bit_oper(ins.quad[2])\n\n    op = ins.quad[1]\n\n    indirect = op[0] == '*'\n    if indirect:\n        op = op[1:]\n\n    immediate = op[0] == '#'\n    if immediate:\n        op = op[1:]\n\n    if is_int(op) or op[0] == '_':\n        if is_int(op):\n            op = str(int(op) & 0xFFFF)\n\n        if immediate:\n            if indirect:\n                output.append('ld (%s), a' % op)\n            else:  # ???\n                output.append('ld (%s), a' % op)\n        elif indirect:\n            output.append('ld hl, (%s)' % op)\n            output.append('ld (hl), a')\n        else:\n            output.append('ld (%s), a' % op)\n    else:\n        if immediate:\n            if indirect:  # A label not starting with _\n                output.append('ld hl, (%s)' % op)\n                output.append('ld (hl), a')\n            else:\n                output.append('ld (%s), a' % op)\n            return output\n        else:\n            output.append('pop hl')\n\n        if indirect:\n            output.append('ld e, (hl)')\n            output.append('inc hl')\n            output.append('ld d, (hl)')\n            output.append('ld (de), a')\n        else:\n            output.append('ld (hl), a')\n\n    return output", "response": "Stores 2nd operand content into address of 1st operand."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstores 2nd operand content into address of 1st operand.", "response": "def _store16(ins):\n    \"\"\" Stores 2nd operand content into address of 1st operand.\n    store16 a, x =>  *(&a) = x\n    Use '*' for indirect store on 1st operand.\n    \"\"\"\n    output = []\n    output = _16bit_oper(ins.quad[2])\n\n    try:\n        value = ins.quad[1]\n        indirect = False\n        if value[0] == '*':\n            indirect = True\n            value = value[1:]\n\n        value = int(value) & 0xFFFF\n        if indirect:\n            output.append('ex de, hl')\n            output.append('ld hl, (%s)' % str(value))\n            output.append('ld (hl), e')\n            output.append('inc hl')\n            output.append('ld (hl), d')\n        else:\n            output.append('ld (%s), hl' % str(value))\n    except ValueError:\n        if value[0] == '_':\n            if indirect:\n                output.append('ex de, hl')\n                output.append('ld hl, (%s)' % str(value))\n                output.append('ld (hl), e')\n                output.append('inc hl')\n                output.append('ld (hl), d')\n            else:\n                output.append('ld (%s), hl' % str(value))\n        elif value[0] == '#':\n            value = value[1:]\n            if indirect:\n                output.append('ex de, hl')\n                output.append('ld hl, (%s)' % str(value))\n                output.append('ld (hl), e')\n                output.append('inc hl')\n                output.append('ld (hl), d')\n            else:\n                output.append('ld (%s), hl' % str(value))\n        else:\n            output.append('ex de, hl')\n            if indirect:\n                output.append('pop hl')\n                output.append('ld a, (hl)')\n                output.append('inc hl')\n                output.append('ld h, (hl)')\n                output.append('ld l, a')\n            else:\n                output.append('pop hl')\n\n            output.append('ld (hl), e')\n            output.append('inc hl')\n            output.append('ld (hl), d')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstoring 2nd operand content into address of 1st operand.", "response": "def _store32(ins):\n    \"\"\" Stores 2nd operand content into address of 1st operand.\n    store16 a, x =>  *(&a) = x\n    \"\"\"\n    op = ins.quad[1]\n\n    indirect = op[0] == '*'\n    if indirect:\n        op = op[1:]\n\n    immediate = op[0] == '#'  # Might make no sense here?\n    if immediate:\n        op = op[1:]\n\n    if is_int(op) or op[0] == '_' or immediate:\n        output = _32bit_oper(ins.quad[2], preserveHL=indirect)\n\n        if is_int(op):\n            op = str(int(op) & 0xFFFF)\n\n        if indirect:\n            output.append('ld hl, (%s)' % op)\n            output.append('call __STORE32')\n            REQUIRES.add('store32.asm')\n\n            return output\n\n        output.append('ld (%s), hl' % op)\n        output.append('ld (%s + 2), de' % op)\n\n        return output\n\n    output = _32bit_oper(ins.quad[2], preserveHL=True)\n    output.append('pop hl')\n\n    if indirect:\n        output.append('call __ISTORE32')\n        REQUIRES.add('store32.asm')\n\n        return output\n\n    output.append('call __STORE32')\n    REQUIRES.add('store32.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstoring 2\u00ba operand content into address of 1st operand.", "response": "def _storef16(ins):\n    \"\"\" Stores 2\u00ba operand content into address of 1st operand.\n    store16 a, x =>  *(&a) = x\n    \"\"\"\n    value = ins.quad[2]\n    if is_float(value):\n        val = float(ins.quad[2])  # Immediate?\n        (de, hl) = f16(val)\n        q = list(ins.quad)\n        q[2] = (de << 16) | hl\n        ins.quad = tuple(q)\n\n    return _store32(ins)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstore a floating point value into a memory address.", "response": "def _storef(ins):\n    \"\"\" Stores a floating point value into a memory address.\n    \"\"\"\n    output = _float_oper(ins.quad[2])\n\n    op = ins.quad[1]\n\n    indirect = op[0] == '*'\n    if indirect:\n        op = op[1:]\n\n    immediate = op[0] == '#'  # Might make no sense here?\n    if immediate:\n        op = op[1:]\n\n    if is_int(op) or op[0] == '_':\n        if is_int(op):\n            op = str(int(op) & 0xFFFF)\n\n        if indirect:\n            output.append('ld hl, (%s)' % op)\n        else:\n            output.append('ld hl, %s' % op)\n    else:\n        output.append('pop hl')\n        if indirect:\n            output.append('call __ISTOREF')\n            REQUIRES.add('storef.asm')\n\n            return output\n\n    output.append('call __STOREF')\n    REQUIRES.add('storef.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _storestr(ins):\n    op1 = ins.quad[1]\n    indirect = op1[0] == '*'\n    if indirect:\n        op1 = op1[1:]\n\n    immediate = op1[0] == '#'\n    if immediate and not indirect:\n        raise InvalidIC('storestr does not allow immediate destination', ins.quad)\n\n    if not indirect:\n        op1 = '#' + op1\n\n    tmp1, tmp2, output = _str_oper(op1, ins.quad[2], no_exaf=True)\n\n    if not tmp2:\n        output.append('call __STORE_STR')\n        REQUIRES.add('storestr.asm')\n    else:\n        output.append('call __STORE_STR2')\n        REQUIRES.add('storestr2.asm')\n\n    return output", "response": "Stores a string value into a memory address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts data from typeA to typeB.", "response": "def _cast(ins):\n    \"\"\" Convert data from typeA to typeB (only numeric data types)\n    \"\"\"\n    # Signed and unsigned types are the same in the Z80\n    tA = ins.quad[2]  # From TypeA\n    tB = ins.quad[3]  # To TypeB\n\n    YY_TYPES[tA]  # Type sizes\n    xsB = sB = YY_TYPES[tB]  # Type sizes\n\n    output = []\n    if tA in ('u8', 'i8'):\n        output.extend(_8bit_oper(ins.quad[4]))\n    elif tA in ('u16', 'i16'):\n        output.extend(_16bit_oper(ins.quad[4]))\n    elif tA in ('u32', 'i32'):\n        output.extend(_32bit_oper(ins.quad[4]))\n    elif tA == 'f16':\n        output.extend(_f16_oper(ins.quad[4]))\n    elif tA == 'f':\n        output.extend(_float_oper(ins.quad[4]))\n    else:\n        raise errors.GenericError(\n            'Internal error: invalid typecast from %s to %s' % (tA, tB))\n\n    if tB in ('u8', 'i8'):  # It was a byte\n        output.extend(to_byte(tA))\n    elif tB in ('u16', 'i16'):\n        output.extend(to_word(tA))\n    elif tB in ('u32', 'i32'):\n        output.extend(to_long(tA))\n    elif tB == 'f16':\n        output.extend(to_fixed(tA))\n    elif tB == 'f':\n        output.extend(to_float(tA))\n\n    xsB += sB % 2  # make it even (round up)\n\n    if xsB > 4:\n        output.extend(_fpush())\n    else:\n        if xsB > 2:\n            output.append('push de')  # Fixed or 32 bit Integer\n\n        if sB > 1:\n            output.append('push hl')  # 16 bit Integer\n        else:\n            output.append('push af')  # 8 bit Integer\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\njumps if the top of the stack is 0 to arg ( 1 )", "response": "def _jzerof(ins):\n    \"\"\" Jumps if top of the stack (40bit, float) is 0 to arg(1)\n    \"\"\"\n    value = ins.quad[1]\n    if is_float(value):\n        if float(value) == 0:\n            return ['jp %s' % str(ins.quad[2])]  # Always true\n        else:\n            return []\n\n    output = _float_oper(value)\n    output.append('ld a, c')\n    output.append('or l')\n    output.append('or h')\n    output.append('or e')\n    output.append('or d')\n    output.append('jp z, %s' % str(ins.quad[2]))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _jzerostr(ins):\n    output = []\n    disposable = False  # True if string must be freed from memory\n\n    if ins.quad[1][0] == '_':  # Variable?\n        output.append('ld hl, (%s)' % ins.quad[1][0])\n    else:\n        output.append('pop hl')\n        output.append('push hl')  # Saves it for later\n        disposable = True\n\n    output.append('call __STRLEN')\n\n    if disposable:\n        output.append('ex (sp), hl')\n        output.append('call __MEM_FREE')\n        output.append('pop hl')\n        REQUIRES.add('alloc.asm')\n\n    output.append('ld a, h')\n    output.append('or l')\n    output.append('jp z, %s' % str(ins.quad[2]))\n    REQUIRES.add('strlen.asm')\n    return output", "response": "Jumps if the top of the stack contains a NULL pointer\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\njumping if top of the stack is not 0 to arg ( 1 )", "response": "def _jnzero16(ins):\n    \"\"\" Jumps if top of the stack (16bit) is != 0 to arg(1)\n    \"\"\"\n    value = ins.quad[1]\n    if is_int(value):\n        if int(value) != 0:\n            return ['jp %s' % str(ins.quad[2])]  # Always true\n        else:\n            return []\n\n    output = _16bit_oper(value)\n    output.append('ld a, h')\n    output.append('or l')\n    output.append('jp nz, %s' % str(ins.quad[2]))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\njumps if top of the stack is!0 to arg ( 1 )", "response": "def _jnzero32(ins):\n    \"\"\" Jumps if top of the stack (32bit) is !=0 to arg(1)\n    \"\"\"\n    value = ins.quad[1]\n    if is_int(value):\n        if int(value) != 0:\n            return ['jp %s' % str(ins.quad[2])]  # Always true\n        else:\n            return []\n\n    output = _32bit_oper(value)\n    output.append('ld a, h')\n    output.append('or l')\n    output.append('or e')\n    output.append('or d')\n    output.append('jp nz, %s' % str(ins.quad[2]))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\njumping if top of the stack is!0 to arg ( 1 )", "response": "def _jnzerof16(ins):\n    \"\"\" Jumps if top of the stack (32bit) is !=0 to arg(1)\n    Fixed Point (16.16 bit) values.\n    \"\"\"\n    value = ins.quad[1]\n    if is_float(value):\n        if float(value) != 0:\n            return ['jp %s' % str(ins.quad[2])]  # Always true\n        else:\n            return []\n\n    output = _f16_oper(value)\n    output.append('ld a, h')\n    output.append('or l')\n    output.append('or e')\n    output.append('or d')\n    output.append('jp nz, %s' % str(ins.quad[2]))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _jgezerou8(ins):\n    output = []\n    value = ins.quad[1]\n    if not is_int(value):\n        output = _8bit_oper(value)\n\n    output.append('jp %s' % str(ins.quad[2]))\n    return output", "response": "Jumps if top of the stack is > = 0 to arg ( 1 ) Always TRUE for unsigned\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _jgezeroi8(ins):\n    value = ins.quad[1]\n    if is_int(value):\n        if int(value) >= 0:\n            return ['jp %s' % str(ins.quad[2])]  # Always true\n        else:\n            return []\n\n    output = _8bit_oper(value)\n    output.append('add a, a')  # Puts sign into carry\n    output.append('jp nc, %s' % str(ins.quad[2]))\n    return output", "response": "Jumps if top of the stack is >= 0 to arg1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\njump if top of the stack is > = 0 to arg ( 1 ) Always TRUE for unsigned", "response": "def _jgezerou16(ins):\n    \"\"\" Jumps if top of the stack (16bit) is >= 0 to arg(1)\n        Always TRUE for unsigned\n    \"\"\"\n    output = []\n    value = ins.quad[1]\n    if not is_int(value):\n        output = _16bit_oper(value)\n\n    output.append('jp %s' % str(ins.quad[2]))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _jgezerou32(ins):\n    output = []\n    value = ins.quad[1]\n    if not is_int(value):\n        output = _32bit_oper(value)\n\n    output.append('jp %s' % str(ins.quad[2]))\n    return output", "response": "Jumps if top of the stack is >= 0 to arg ( 1 ) Always TRUE for unsigned\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns from a procedure or function an 8bits value", "response": "def _ret8(ins):\n    \"\"\" Returns from a procedure / function an 8bits value\n    \"\"\"\n    output = _8bit_oper(ins.quad[1])\n    output.append('#pragma opt require a')\n    output.append('jp %s' % str(ins.quad[2]))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns from a procedure or function a 16bits value", "response": "def _ret16(ins):\n    \"\"\" Returns from a procedure / function a 16bits value\n    \"\"\"\n    output = _16bit_oper(ins.quad[1])\n    output.append('#pragma opt require hl')\n    output.append('jp %s' % str(ins.quad[2]))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ret32(ins):\n    output = _32bit_oper(ins.quad[1])\n    output.append('#pragma opt require hl,de')\n    output.append('jp %s' % str(ins.quad[2]))\n    return output", "response": "Returns from a procedure or function a 32bits value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn from a procedure a function a Fixed Point ( 32bits ) value", "response": "def _retf16(ins):\n    \"\"\" Returns from a procedure / function a Fixed Point (32bits) value\n    \"\"\"\n    output = _f16_oper(ins.quad[1])\n    output.append('#pragma opt require hl,de')\n    output.append('jp %s' % str(ins.quad[2]))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _retf(ins):\n    output = _float_oper(ins.quad[1])\n    output.append('#pragma opt require a,bc,de')\n    output.append('jp %s' % str(ins.quad[2]))\n    return output", "response": "Returns from a procedure a Floating Point ( 40bits ) value\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn from a procedure or function a string pointer ( 16bits ) value", "response": "def _retstr(ins):\n    \"\"\" Returns from a procedure / function a string pointer (16bits) value\n    \"\"\"\n    tmp, output = _str_oper(ins.quad[1], no_exaf=True)\n\n    if not tmp:\n        output.append('call __LOADSTR')\n        REQUIRES.add('loadstr.asm')\n\n    output.append('#pragma opt require hl')\n    output.append('jp %s' % str(ins.quad[2]))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call(ins):\n    output = []\n    output.append('call %s' % str(ins.quad[1]))\n\n    try:\n        val = int(ins.quad[2])\n        if val == 1:\n            output.append('push af')  # Byte\n        else:\n            if val > 4:\n                output.extend(_fpush())\n            else:\n                if val > 2:\n                    output.append('push de')\n                if val > 1:\n                    output.append('push hl')\n\n    except ValueError:\n        pass\n\n    return output", "response": "Returns a list of the return values of a function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _leave(ins):\n    global FLAG_use_function_exit\n\n    output = []\n\n    if ins.quad[1] == '__fastcall__':\n        output.append('ret')\n        return output\n\n    nbytes = int(ins.quad[1])  # Number of bytes to pop (params size)\n\n    if nbytes == 0:\n        output.append('ld sp, ix')\n        output.append('pop ix')\n        output.append('ret')\n\n        return output\n\n    if nbytes == 1:\n        output.append('ld sp, ix')\n        output.append('pop ix')\n        output.append('inc sp')  # \"Pops\" 1 byte\n        output.append('ret')\n\n        return output\n\n    if nbytes <= 11:  # Number of bytes it worth the hassle to \"pop\" off the stack\n        output.append('ld sp, ix')\n        output.append('pop ix')\n        output.append('exx')\n        output.append('pop hl')\n        for i in range((nbytes >> 1) - 1):\n            output.append('pop bc')  # Removes (n * 2  - 2) bytes form the stack\n\n        if nbytes & 1:  # Odd?\n            output.append('inc sp')  # \"Pops\" 1 byte (This should never happens, since params are always even-sized)\n\n        output.append('ex (sp), hl')  # Place back return address\n        output.append('exx')\n        output.append('ret')\n\n        return output\n\n    if not FLAG_use_function_exit:\n        FLAG_use_function_exit = True  # Use standard exit\n        output.append('exx')\n        output.append('ld hl, %i' % nbytes)\n        output.append('__EXIT_FUNCTION:')\n        output.append('ld sp, ix')\n        output.append('pop ix')\n        output.append('pop de')\n        output.append('add hl, sp')\n        output.append('ld sp, hl')\n        output.append('push de')\n        output.append('exx')\n        output.append('ret')\n    else:\n        output.append('exx')\n        output.append('ld hl, %i' % nbytes)\n        output.append('jp __EXIT_FUNCTION')\n\n    return output", "response": "Return from a function popping N bytes from the stack and leaving the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenters a function sequence for doing a function.", "response": "def _enter(ins):\n    \"\"\" Enter function sequence for doing a function start\n        ins.quad[1] contains size (in bytes) of local variables\n        Use '__fastcall__' as 1st parameter to prepare a fastcall\n        function (no local variables).\n    \"\"\"\n    output = []\n\n    if ins.quad[1] == '__fastcall__':\n        return output\n\n    output.append('push ix')\n    output.append('ld ix, 0')\n    output.append('add ix, sp')\n\n    size_bytes = int(ins.quad[1])\n\n    if size_bytes != 0:\n        if size_bytes < 7:\n            output.append('ld hl, 0')\n            output.extend(['push hl'] * (size_bytes >> 1))\n\n            if size_bytes % 2:  # odd?\n                output.append('push hl')\n                output.append('inc sp')\n        else:\n            output.append('ld hl, -%i' % size_bytes)  # \"Pushes nn bytes\"\n            output.append('add hl, sp')\n            output.append('ld sp, hl')\n            output.append('ld (hl), 0')\n            output.append('ld bc, %i' % (size_bytes - 1))\n            output.append('ld d, h')\n            output.append('ld e, l')\n            output.append('inc de')\n            output.append('ldir')  # Clear with ZEROs\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npush a 32bit param into the stack", "response": "def _param32(ins):\n    \"\"\" Pushes 32bit param into the stack\n    \"\"\"\n    output = _32bit_oper(ins.quad[1])\n    output.append('push de')\n    output.append('push hl')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npush 32bit fixed point param into the stack", "response": "def _paramf16(ins):\n    \"\"\" Pushes 32bit fixed point param into the stack\n    \"\"\"\n    output = _f16_oper(ins.quad[1])\n    output.append('push de')\n    output.append('push hl')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npushing 40bit float param into the stack", "response": "def _paramf(ins):\n    \"\"\" Pushes 40bit (float) param into the stack\n    \"\"\"\n    output = _float_oper(ins.quad[1])\n    output.extend(_fpush())\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying a block of memory from param 2 addrto param 1 addr.", "response": "def _memcopy(ins):\n    \"\"\" Copies a block of memory from param 2 addr\n    to param 1 addr.\n    \"\"\"\n    output = _16bit_oper(ins.quad[3])\n    output.append('ld b, h')\n    output.append('ld c, l')\n    output.extend(_16bit_oper(ins.quad[1], ins.quad[2], reversed=True))\n    output.append('ldir')  # ***\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convertToBool():\n    if not OPTIONS.strictBool.value:\n        return []\n\n    REQUIRES.add('strictbool.asm')\n\n    result = []\n    result.append('pop af')\n    result.append('call __NORMALIZE_BOOLEAN')\n    result.append('push af')\n\n    return result", "response": "Convert a byte value to boolean"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef emit_end(MEMORY=None):\n    output = []\n    output.extend(AT_END)\n\n    if REQUIRES.intersection(MEMINITS) or '__MEM_INIT' in INITS:\n        output.append(OPTIONS.heap_start_label.value + ':')\n        output.append('; Defines DATA END\\n' + 'ZXBASIC_USER_DATA_END EQU ZXBASIC_MEM_HEAP + ZXBASIC_HEAP_SIZE')\n    else:\n        output.append('; Defines DATA END --> HEAP size is 0\\n' + 'ZXBASIC_USER_DATA_END EQU ZXBASIC_MEM_HEAP')\n\n    output.append('; Defines USER DATA Length in bytes\\n' +\n                  'ZXBASIC_USER_DATA_LEN EQU ZXBASIC_USER_DATA_END - ZXBASIC_USER_DATA')\n\n    if OPTIONS.autorun.value:\n        output.append('END %s' % START_LABEL)\n    else:\n        output.append('END')\n\n    return output", "response": "This function is used to emit the end of the current memory area."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbegin converting each quad instruction to asm by iterating over the \"mem\" array, and called its associated function. Each function returns an array of ASM instructions which will be appended to the 'output' array", "response": "def emit(mem):\n    \"\"\" Begin converting each quad instruction to asm\n    by iterating over the \"mem\" array, and called its\n    associated function. Each function returns an array of\n    ASM instructions which will be appended to the\n    'output' array\n    \"\"\"\n\n    def output_join(output, new_chunk):\n        \"\"\" Extends output instruction list\n        performing a little peep-hole optimization\n        \"\"\"\n        changed = True and OPTIONS.optimization.value > 0  # Only enter here if -O0 was not set\n\n        while changed and new_chunk:\n            if output:\n                a1 = output[-1]  # Last output instruction\n                i1 = inst(a1)\n                o1 = oper(a1)\n            else:\n                a1 = i1 = o1 = None\n\n            if len(output) > 1:\n                a0 = output[-2]\n                i0 = inst(a0)\n                o0 = oper(a0)\n            else:\n                a0 = i0 = o0 = None\n\n            a2 = new_chunk[0]  # Fist new output instruction\n            i2 = inst(a2)\n            o2 = oper(a2)\n\n            if OPT00 and i2[-1] == ':':\n                # Ok, a2 is a label\n                # check if the above starts with jr / jp\n                if i1 in ('jp', 'jr') and o1[0] == i2[:-1]:\n                    # Ok remove the above instruction\n                    output.pop()\n                    changed = True\n                    continue\n\n            if OPT01 and i1 == 'push' and i2 == 'pop' and o1[0] == o2[0]:\n                # Ok, we have a push/pop sequence which refers to\n                # the same register pairs\n                # Ok, remove these instructions (both)\n                output.pop()\n                new_chunk = new_chunk[1:]\n                changed = True\n                continue\n\n            if (\n                OPT03 and\n                (i1 == 'sbc' and\n                 o1[0] == o1[1] == 'a' and\n                 i2 == 'or' and\n                 o2[0] == 'a' and\n                 len(new_chunk) > 1)\n            ):\n                a3 = new_chunk[1]\n                i3 = inst(a3)\n                o3 = oper(a3)\n                c = condition(a3)\n                if i3 in ('jp', 'jr') and c in ('z', 'nz'):\n                    c = 'nc' if c == 'z' else 'c'\n                    changed = True\n                    output.pop()\n                    new_chunk.pop(0)\n                    new_chunk[0] = '%s %s, %s' % (i3, c, o3[0])\n                    continue\n\n            if OPT04 and i1 == 'push' and i2 == 'pop':\n                if 'af' in (o1[0], o2[0]):\n                    output.pop()\n                    new_chunk[0] = 'ld %s, %s' % (o2[0][0], o1[0][0])\n                    changed = True\n                    continue\n\n                if o1[0] in ('hl', 'de') and o2[0] in ('hl', 'de'):\n                    # push hl; push de; pop hl; pop de || push de; push hl; pop de; pop hl => ex de, hl\n                    if len(new_chunk) > 1 and len(output) > 1 and oper(new_chunk[1])[0] == o1[0] and \\\n                            o2[0] == oper(output[-2])[0] and \\\n                            inst(output[-2]) == 'push' and inst(new_chunk[1]) == 'pop':\n                        output.pop()\n                        new_chunk.pop(0)\n                        new_chunk.pop(0)\n                        output[-1] = 'ex de, hl'\n                        changed = True\n                        continue\n\n                    # push hl; pop de || push de ; pop hl\n                    if len(new_chunk) > 1 and inst(new_chunk[1]) in ('pop', 'ld') and oper(new_chunk[1])[0] == o1[0]:\n                        output.pop()\n                        new_chunk[0] = 'ex de, hl'\n                        changed = True\n                        continue\n\n                if o1[0] not in ('ix', 'iy') and o2[0] not in ('ix', 'iy'):\n                    # Change push XX, pop YY sequence with ld Yh, Xl; ld Yl, Xl\n                    output.pop()\n                    new_chunk = ['ld %s, %s' % (o2[0][0], o1[0][0])] + new_chunk\n                    new_chunk[1] = 'ld %s, %s' % (o2[0][1], o1[0][1])\n                    changed = True\n                    continue\n\n            # ex af, af'; ex af, af' => <nothing>\n            # ex de, hl ; ex de, hl  => <nothing>\n            if OPT16 and i1 == i2 == 'ex' and o1 == o2:\n                output.pop()\n                new_chunk.pop(0)\n                changed = True\n                continue\n\n            # Tries to optimize:\n            # jp <condition>, LABEL\n            # jp OTHER\n            # LABEL:\n            # into\n            # JP !<condition>, OTHER\n            # LABEL:\n            if OPT17 and len(output) > 1:\n                if i0 == i1 == 'jp' \\\n                        and i2[-1] == ':' \\\n                        and condition(a0) in {'c', 'nc', 'z', 'nz'} \\\n                        and condition(a1) is None \\\n                        and a2[:-1] in o0:\n                    output.pop()\n                    output.pop()\n                    new_chunk = ['jp %s, %s' % ({'c': 'nc',\n                                                 'z': 'nz',\n                                                 'nc': 'c',\n                                                 'nz': 'z'}[condition(a0)], o1[0])] + new_chunk\n                    changed = True\n                    continue\n\n            # Tries to optimize a == b for U/Integers\n            # call __EQ16\n            # or a\n            # jp nz, ...\n            # into:\n            # or a\n            # sbc hl, de\n            # jp z, ...\n            if OPT18 and i1 == 'call' and o1[0] == '__EQ16' \\\n                    and i2 in {'or', 'and'} and o2[0] == 'a' \\\n                    and len(new_chunk) > 1:\n                a3 = new_chunk[1]\n                i3 = inst(a3)\n                c3 = condition(a3)\n                if i3 == 'jp' and c3 in {'z', 'nz'}:\n                    cond = 'z' if c3 == 'nz' else 'nz'\n                    new_chunk[1] = 'jp %s, %s' % (cond, oper(a3)[0])\n                    output.pop()\n                    new_chunk.insert(1, 'sbc hl, de')\n                    changed = True\n                    continue\n\n            # Tries to optimize a == b for U/Bytes\n            # sub N\n            # sub 1\n            # jp nc, __LABEL\n            # into:\n            # sub N\n            # or a\n            # jp nz, __LABEL\n            if OPT19 and i1 == 'sub' and '1' in o1 and i2 == 'jp' and len(output) > 1:\n                c2 = condition(new_chunk[0])\n                if c2 in {'c', 'nc'}:\n                    cond = 'z' if c2 == 'c' else 'nz'\n                    new_chunk[0] = 'jp %s, %s' % (cond, o2[0])\n                    if i0 in ('sub', 'dec'):\n                        output.pop()\n                    else:\n                        output[-1] = 'or a'\n                    changed = True\n                    continue\n\n            # Removes useless or a from sequence:\n            # sub X\n            # or a\n            # jp z/nz ...\n            if OPT21 and i1 == 'sub' and i2 in {'or', 'and'} and o2[0] == 'a':\n                new_chunk.pop(0)\n                changed = True\n                continue\n\n            # Converts:\n            # ld a, (ix +/- n)\n            # ld r, a\n            # pop af\n            # Into:\n            # pop af\n            # ld r, (ix +/- n)\n            if OPT22 and len(output) > 1 and i1 == 'ld' and o1[0] in 'bcdehl' and o1[1] == 'a' and \\\n                    (i2, o2) == ('pop', ['af', 'sp']):\n                if (i0, o0[:1]) == ('ld', ['a']) and RE_IX_IDX.match(o0[1]):\n                    output.pop()  # Removes ld r, a\n                    output.pop()  # Removes ld a, (ix + n)\n                    new_chunk.insert(1, 'ld %s, %s' % (o1[0], o0[1]))  # Inserts 'ld r, (ix + n)' after 'pop af'\n                    changed = True\n                    continue\n\n            # Converts:\n            # ld hl, (NN) | ld hl, NN | pop hl\n            # ld b, h\n            # ld c, l\n            # in a, (c)\n            # Into:\n            # ld bc, (NN) | ld bc, NN | pop bc\n            # in a, (c)\n            if OPT23 and len(new_chunk) > 3 and inst(new_chunk[3]) == 'in':\n                ia = inst(new_chunk[1])\n                oa = oper(new_chunk[1])\n                ib = inst(new_chunk[2])\n                ob = oper(new_chunk[2])\n                if (ia, oa[0], oa[1], ib, ob[0], ob[1]) == ('ld', 'b', 'h', 'ld', 'c', 'l'):\n                    ii = inst(new_chunk[0])\n                    oi = oper(new_chunk[0])\n                    if ii in ('pop', 'ld') and oi[0] == 'hl':\n                        new_chunk[0] = ii + ' ' + 'bc' + (', %s' % oi[1] if ii == 'ld' else '')\n                        new_chunk.pop(1)\n                        new_chunk.pop(1)\n                        changed = True\n                        continue\n\n            # Converts:\n            # ld hl, (NN) | ld hl, NN | pop hl\n            # ld b, h\n            # ld c, l\n            # out (c), a\n            # Into:\n            # ld bc, (NN) | ld bc, NN | pop bc\n            # out (c), a\n            if OPT23 and len(new_chunk) > 3 and inst(new_chunk[-1]) == 'out':\n                ia = inst(new_chunk[-3])\n                oa = oper(new_chunk[-3])\n                ib = inst(new_chunk[-2])\n                ob = oper(new_chunk[-2])\n                if (ia, oa[0], oa[1], ib, ob[0], ob[1]) == ('ld', 'b', 'h', 'ld', 'c', 'l'):\n                    ii = inst(new_chunk[-4])\n                    oi = oper(new_chunk[-4])\n                    if ii in ('pop', 'ld') and oi[0] == 'hl':\n                        new_chunk[-4] = ii + ' ' + 'bc' + (', %s' % oi[1] if ii == 'ld' else '')\n                        new_chunk.pop(-2)\n                        new_chunk.pop(-2)\n                        changed = True\n                        continue\n\n            # Converts:\n            # or X | and X\n            # or a | and a\n            # Into:\n            # or X | and X\n            if OPT24 and i1 in ('and', 'or') and new_chunk[0] in ('or a', 'and a'):\n                new_chunk.pop(0)\n                changed = True\n                continue\n\n            # Converts:\n            # ld h, X  (X != A)\n            # ld a, Y\n            # or/and/cp/add/sub h\n            # Into:\n            # ld a, Y\n            # or/and/cp X\n            if OPT25 and \\\n                    (i1 in ('cp', 'or', 'and') and o1[0] == 'h' or\n                     i1 in ('sub', 'add', 'sbc', 'adc') and o1[1] == 'h') \\\n                    and i0 == 'ld' and o0[0] == 'a' and len(output) > 2:\n                ii = inst(output[-3])\n                oo = oper(output[-3])\n                if i1 in ('add', 'adc', 'sbc'):\n                    i1 = i1 + ' a,'\n                if ii == 'ld' and oo[0] == 'h' and oo[1] != 'a':\n                    output[-1] = '{0} {1}'.format(i1, oo[1])\n                    output.pop(-3)\n                    changed = True\n                    continue\n\n            # Converts:\n            # ld a, (nn) | ld a, (ix+N)\n            # inc/dec a\n            # ld (nn), a | ld (ix+N), a\n            # Into:\n            # ld hl, _n    | <removed>\n            # inc/dec (hl) | inc/dec (ix+N)\n            if OPT26 and i1 in ('inc', 'dec') and o1[0] == 'a' and i0 == i2 == 'ld' and \\\n                    (o0[0], o0[1]) == (o2[1], o2[0]) and o0[1][0] == '(':\n                new_chunk.pop(0)\n                if RE_IX_IDX.match(o0[1]):\n                    output[-1] = '{0} {1}'.format(i1, o0[1])\n                    output.pop(-2)\n                else:\n                    output[-1] = '{0} (hl)'.format(i1)\n                    output[-2] = 'ld hl, {0}'.format(o0[1][1:-1])\n                changed = True\n                continue\n\n            # Converts:\n            # ld X, Y\n            # ld Y, X\n            # Into:\n            # ld X, Y\n            if OPT02 and i1 == i2 == 'ld' and o1[0] == o2[1] and o2[0] == o1[1]:\n                # This and previous instruction are LD X, Y\n                # Ok, previous instruction is LD A, B and current is LD B, A. Remove this one.\n                new_chunk = new_chunk[1:]\n                changed = True\n                continue\n\n            # Converts:\n            # ld h, X\n            # or/and h\n            # Into:\n            # or/and X\n            if OPT27 and i1 == 'ld' and o1[0] == 'h' and i2 in ('and', 'or') and o2[0] == 'h':\n                output.pop()\n                new_chunk[0] = '{0} {1}'.format(i2, o1[1])\n                changed = True\n                continue\n\n            # Converts\n            # ld a, r|(ix+/-N)|(hl)\n            # ld h, a\n            # ld a, XXX | pop af\n            # Into:\n            # ld h, r|(ix+/-N)|(hl)\n            # ld a, XXX | pop af\n            if OPT28 and i1 == i0 == 'ld' and o0[0] == 'a' and \\\n                    (o0[1] in ('a', 'b', 'c', 'd', 'e', 'h', 'l', '(hl)') or RE_IX_IDX.match(o0[1])) and \\\n                    (o1[0], o1[1]) == ('h', 'a') and new_chunk and (new_chunk[0] == 'pop af' or\n                                                                    i2 == 'ld' and o2[0] == 'a'):\n\n                output.pop()\n                output[-1] = 'ld h, {0}'.format(o0[1])\n                changed = True\n                continue\n\n            # Converts:\n            # cp 0\n            # Into:\n            # or a\n            if OPT29 and i1 == 'cp' and o1[0] == '0':\n                output[-1] = 'or a'\n                changed = True\n                continue\n\n            # Converts:\n            # or/and X\n            # jp c/nc XXX\n            # Into:\n            # <nothing>/jp XXX\n            if OPT30 and i1 in ('and', 'or') and i2 == 'jp':\n                c = condition(new_chunk[0])\n                if c in ('c', 'nc'):\n                    output.pop()\n                    if c == 'nc':\n                        new_chunk[0] = 'jp {0}'.format(o2[0])\n                    else:\n                        new_chunk.pop(0)\n                    changed = True\n                    continue\n\n            # Converts\n            # jp XXX\n            # <any inst>\n            # Into:\n            # jp XXX\n            if OPT31 and i1 == 'jp' and not condition(output[-1]) and i2 is not None and \\\n                    i2[-1] != ':' and new_chunk[0] not in ASMS:\n                new_chunk.pop(0)\n                changed = True\n                continue\n\n            # Converts:\n            # call __LOADSTR\n            # ld a, 1\n            # call __PRINSTR\n            # Into:\n            # xor a\n            # call __PRINTSTR\n            if OPT32 and i0 == 'call' and o0[0] == '__LOADSTR' and i1 == 'ld' and tuple(o1) == ('a', '1') and \\\n                    i2 == 'call' and o2[0] == '__PRINTSTR':\n                output.pop(-2)\n                output[-1] = 'xor a'\n                changed = True\n                continue\n\n            changed, new_chunk = optiblock(new_chunk)\n\n        output.extend(new_chunk)\n\n    output = []\n    for i in mem:\n        output_join(output, QUADS[i.quad[0]][1](i))\n        if RE_BOOL.match(i.quad[0]):  # If it is a boolean operation convert it to 0/1 if the STRICT_BOOL flag is True\n            output_join(output, convertToBool())\n\n    changed = OPTIONS.optimization.value > 1\n    while changed:\n        to_remove = []\n\n        for i, ins in enumerate(output):\n            ins = ins[:-1]\n            if ins not in TMP_LABELS:\n                continue\n\n            for j, ins2 in enumerate(output):\n                if j == i:\n                    continue\n                if ins in oper(ins2):\n                    break\n            else:\n                to_remove.append(i)\n\n        changed = len(to_remove) > 0\n        to_remove.reverse()\n        for i in to_remove:\n            output.pop(i)\n\n        tmp = output\n        output = []\n        for i in tmp:\n            output_join(output, [i])\n\n    for i in sorted(REQUIRES):\n        output.append('#include once <%s>' % i)\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef t_defexpr_CONTINUE(self, t):\n        r'[\\\\_]\\r?\\n'\n        t.lexer.lineno += 1\n        t.value = t.value[1:]\n        return t", "response": "r \\ _ \\ r?\\n"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef t_prepro_ID(self, t):\n        r'[_a-zA-Z][_a-zA-Z0-9]*'  # preprocessor directives\n        t.type = reserved_directives.get(t.value.lower(), 'ID')\n        states_ = {\n            'DEFINE': 'define',\n            'PRAGMA': 'pragma',\n            'IF': 'if',\n            'ERROR': 'msg',\n            'WARNING': 'msg'\n        }\n\n        if t.type in states_:\n            t.lexer.begin(states_[t.type])\n        elif t.type == 'ID' and self.expectingDirective:\n            self.error(\"invalid directive #%s\" % t.value)\n\n        self.expectingDirective = False\n        return t", "response": "Look for reserved ID directives and parse them as ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef t_INITIAL_asm_sharp(self, t):\n        r'[ \\t]*\\#'  # Only matches if at beginning of line and \"#\"\n        if self.find_column(t) == 1:\n            t.lexer.push_state('prepro')  # Start preprocessor\n            self.expectingDirective = True", "response": "Tokenize the initial asm."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef put_current_line(self, prefix='', suffix=''):\n        return '%s#line %i \"%s\"%s' % (prefix, self.lex.lineno, self.filestack[-1][0], suffix)", "response": "Returns line and file for include sequences."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform and end of include.", "response": "def include_end(self):\n        \"\"\" Performs and end of include.\n        \"\"\"\n        self.lex = self.filestack[-1][2]\n        self.input_data = self.filestack[-1][3]\n        self.filestack.pop()\n\n        if not self.filestack:  # End of input?\n            return\n\n        self.filestack[-1][1] += 1  # Increment line counter of previous file\n\n        result = lex.LexToken()\n        result.value = self.put_current_line(suffix='\\n')\n        result.type = '_ENDFILE_'\n        result.lineno = self.lex.lineno\n        result.lexpos = self.lex.lexpos\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefining input string removing current lexer.", "response": "def input(self, str, filename=''):\n        \"\"\" Defines input string, removing current lexer.\n        \"\"\"\n        self.filestack.append([filename, 1, self.lex, self.input_data])\n\n        self.input_data = str\n        self.lex = lex.lex(object=self)\n        self.lex.input(self.input_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a token from the current input.", "response": "def token(self):\n        \"\"\" Returns a token from the current input. If tok is None\n        from the current input, it means we are at end of current input\n        (e.g. at end of include file). If so, closes the current input\n        and discards it; then pops the previous input and lexer from\n        the input stack, and gets another token.\n\n        If new token is again None, repeat the process described above\n        until the token is either not None, or self.lex is None, wich\n        means we must effectively return None, because parsing has\n        ended.\n        \"\"\"\n        tok = None\n        if self.next_token is not None:\n            tok = lex.LexToken()\n            tok.value = ''\n            tok.lineno = self.lex.lineno\n            tok.lexpos = self.lex.lexpos\n            tok.type = self.next_token\n            self.next_token = None\n\n        while self.lex is not None and tok is None:\n            tok = self.lex.token()\n            if tok is not None:\n                break\n\n            tok = self.include_end()\n\n        return tok"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the column in the input file that contains the given token.", "response": "def find_column(self, token):\n        \"\"\" Compute column:\n                - token is a token instance\n        \"\"\"\n        i = token.lexpos\n        while i > 0:\n            if self.input_data[i - 1] == '\\n':\n                break\n            i -= 1\n\n        column = token.lexpos - i + 1\n        return column"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts duration pitch to a pair of unsigned 16 bit integers and to be loaded in DE HL following the ROM listing.", "response": "def getDEHL(duration, pitch):\n    \"\"\"Converts duration,pitch to a pair of unsigned 16 bit integers,\n    to be loaded in DE,HL, following the ROM listing.\n    Returns a t-uple with the DE, HL values.\n    \"\"\"\n    intPitch = int(pitch)\n    fractPitch = pitch - intPitch  # Gets fractional part\n    tmp = 1 + 0.0577622606 * fractPitch\n    if not -60 <= intPitch <= 127:\n        raise BeepError('Pitch out of range: must be between [-60, 127]')\n\n    if duration < 0 or duration > 10:\n        raise BeepError('Invalid duration: must be between [0, 10]')\n\n    A = intPitch + 60\n    B = -5 + int(A / 12)  # -5 <= B <= 10\n    A %= 0xC  # Semitones above C\n\n    frec = TABLE[A]\n    tmp2 = tmp * frec\n    f = tmp2 * 2.0 ** B\n\n    DE = int(0.5 + f * duration - 1)\n    HL = int(0.5 + 437500.0 / f - 30.125)\n    return DE, HL"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_node(cls, *args):\n        new_args = []\n\n        args = [x for x in args if not is_null(x)]\n        for x in args:\n            assert isinstance(x, Symbol)\n            if x.token == 'BLOCK':\n                new_args.extend(SymbolBLOCK.make_node(*x.children).children)\n            else:\n                new_args.append(x)\n\n        result = SymbolBLOCK(*new_args)\n        return result", "response": "Creates a chain of code blocks."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef t_MACROS(t):\n    r'__[a-zA-Z]+__'\n\n    if t.value in macros:\n        t.type = t.value\n        return t\n\n    syntax_error(t.lexer.lineno, \"unknown macro '%s'\" % t.value)", "response": "r A macro can only be used in the tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_string_NGRAPH(t):\n    r\"\\\\[ '.:][ '.:]\"\n    global __STRING\n\n    P = {' ': 0, \"'\": 2, '.': 8, ':': 10}\n    N = {' ': 0, \"'\": 1, '.': 4, ':': 5}\n\n    __STRING += chr(128 + P[t.value[1]] + N[t.value[2]])", "response": "r A string with NGram"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_asm(t):\n    r'\\b[aA][sS][mM]\\b'\n\n    global ASM, ASMLINENO, IN_STATE\n    t.lexer.begin('asm')\n\n    ASM = ''\n    ASMLINENO = t.lexer.lineno\n    IN_STATE = True", "response": "r \\ b [ aA][sS][mM]\\b"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef t_ID(t):\n    r'[a-zA-Z][a-zA-Z0-9]*[$%]?'\n    t.type = reserved.get(t.value.lower(), 'ID')\n    callables = {\n        api.constants.CLASS.array: 'ARRAY_ID',\n    }\n\n    if t.type != 'ID':\n        t.value = t.type\n    else:\n        entry = api.global_.SYMBOL_TABLE.get_entry(t.value) if api.global_.SYMBOL_TABLE is not None else None\n        if entry:\n            t.type = callables.get(entry.class_, t.type)\n\n    if t.type == 'BIN':\n        t.lexer.begin('bin')\n        return None\n\n    return t", "response": "t_ID is a token that is used to identify the type of the object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef t_bin_ZERO(t):\n    r'[^01]'\n    t.lexer.begin('INITIAL')\n    t.type = 'NUMBER'\n    t.value = 0\n    t.lexer.lexpos -= 1\n    return t", "response": "r A binary number."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the column of the next non - blank line in the token instance.", "response": "def find_column(token):\n    \"\"\" Compute column:\n            input is the input text string\n            token is a token instance\n    \"\"\"\n    i = token.lexpos\n    input = token.lexer.lexdata\n\n    while i > 0:\n        if input[i - 1] == '\\n':\n            break\n        i -= 1\n\n    column = token.lexpos - i + 1\n\n    return column"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns whether the token is a label.", "response": "def is_label(token):\n    \"\"\" Return whether the token is a label (an integer number or id\n    at the beginning of a line.\n\n    To do so, we compute find_column() and moves back to the beginning\n    of the line if previous chars are spaces or tabs. If column 0 is\n    reached, it's a label.\n    \"\"\"\n    if not LABELS_ALLOWED:\n        return False\n\n    c = i = token.lexpos\n    input = token.lexer.lexdata\n    c -= 1\n    while c > 0 and input[c] in (' ', '\\t'):\n        c -= 1\n\n    while i > 0:\n        if input[i] == '\\n':\n            break\n        i -= 1\n\n    column = c - i\n\n    if column == 0:\n        column += 1\n\n    return column == 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_val(other):\n    assert isinstance(other, (numbers.Number, SymbolNUMBER, SymbolCONST))\n    if isinstance(other, SymbolNUMBER):\n        return other.value\n\n    if isinstance(other, SymbolCONST):\n        return other.expr.value\n\n    return other", "response": "Given a Number a Numeric Constant or a python number return its value\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping a table on screen for debugging purposes", "response": "def __dumptable(self, table):\n        \"\"\" Dumps table on screen\n        for debugging purposes\n        \"\"\"\n        for x in table.table.keys():\n            sys.stdout.write(\"{0}\\t<--- {1} {2}\".format(x, table[x], type(table[x])))\n            if isinstance(table[x], ID):\n                sys.stdout(\" {0}\".format(table[x].value)),\n            sys.stdout.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvisits the Return node.", "response": "def visit_RETURN(self, node):\n        \"\"\" Visits only children[1], since children[0] points to\n        the current function being returned from (if any), and\n        might cause infinite recursion.\n        \"\"\"\n        if len(node.children) == 2:\n            node.children[1] = (yield ToVisit(node.children[1]))\n        yield node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef count(self):\n        return functools.reduce(lambda x, y: x * y, (x.count for x in self.bounds))", "response": "Count the number of cells in the array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the size of the array cell + indexes", "response": "def memsize(self):\n        \"\"\" Total array cell + indexes size\n        \"\"\"\n        return self.size + 1 + TYPE.size(gl.BOUND_TYPE) * len(self.bounds)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a node containing the type cast of the given one.", "response": "def make_node(cls, new_type, node, lineno):\n        \"\"\" Creates a node containing the type cast of\n        the given one. If new_type == node.type, then\n        nothing is done, and the same node is\n        returned.\n\n        Returns None on failure (and calls syntax_error)\n        \"\"\"\n        assert isinstance(new_type, SymbolTYPE)\n\n        # None (null) means the given AST node is empty (usually an error)\n        if node is None:\n            return None  # Do nothing. Return None\n\n        assert isinstance(node, Symbol), '<%s> is not a Symbol' % node\n        # The source and dest types are the same\n        if new_type == node.type_:\n            return node  # Do nothing. Return as is\n\n        STRTYPE = TYPE.string\n        # Typecasting, at the moment, only for number\n        if node.type_ == STRTYPE:\n            syntax_error(lineno, 'Cannot convert string to a value. '\n                                 'Use VAL() function')\n            return None\n\n        # Converting from string to number is done by STR\n        if new_type == STRTYPE:\n            syntax_error(lineno, 'Cannot convert value to string. '\n                                 'Use STR() function')\n            return None\n\n        # If the given operand is a constant, perform a static typecast\n        if is_CONST(node):\n            node.expr = cls(new_type, node.expr, lineno)\n            return node\n\n        if not is_number(node) and not is_const(node):\n            return cls(new_type, node, lineno)\n\n        # It's a number. So let's convert it directly\n        if is_const(node):\n            node = SymbolNUMBER(node.value, node.lineno, node.type_)\n\n        if new_type.is_basic and not TYPE.is_integral(new_type):  # not an integer\n            node.value = float(node.value)\n        else:  # It's an integer\n            new_val = (int(node.value) & ((1 << (8 * new_type.size)) - 1))  # Mask it\n\n            if node.value >= 0 and node.value != new_val:\n                errmsg.warning_conversion_lose_digits(node.lineno)\n                node.value = new_val\n            elif node.value < 0 and (1 << (new_type.size * 8)) + \\\n                    node.value != new_val:  # Test for positive to negative coercion\n                errmsg.warning_conversion_lose_digits(node.lineno)\n                node.value = new_val - (1 << (new_type.size * 8))\n\n        node.type_ = new_type\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnormalizes a namespace to be a single dot - separated list of dots.", "response": "def normalize_namespace(namespace):\n    \"\"\" Given a namespace (e.g. '.' or 'mynamespace'),\n    returns it in normalized form. That is:\n        - always prefixed with a dot\n        - no trailing dots\n        - any double dots are converted to single dot (..my..namespace => .my.namespace)\n        - one or more dots (e.g. '.', '..', '...') are converted to '.' (Global namespace)\n    \"\"\"\n    namespace = (DOT + DOT.join(RE_DOTS.split(namespace))).rstrip(DOT) + DOT\n    return namespace"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_program(p):\n    if p[1] is not None:\n        [MEMORY.add_instruction(x) for x in p[1] if isinstance(x, Asm)]", "response": "Program is a list of Asm objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprograming line is a list of instruction objects", "response": "def p_program_line(p):\n    \"\"\" program : program line\n    \"\"\"\n    if p[2] is not None:\n        [MEMORY.add_instruction(x) for x in p[2] if isinstance(x, Asm)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_def_label(p):\n    p[0] = None\n    __DEBUG__(\"Declaring '%s%s' in %i\" % (NAMESPACE, p[1], p.lineno(1)))\n    MEMORY.declare_label(p[1], p.lineno(1), p[3])", "response": "A label declaration is a special case."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlines - label asms NEWLINE", "response": "def p_line_label_asm(p):\n    \"\"\" line : LABEL asms NEWLINE\n    \"\"\"\n    p[0] = p[2]\n    __DEBUG__(\"Declaring '%s%s' (value %04Xh) in %i\" % (NAMESPACE, p[1], MEMORY.org, p.lineno(1)))\n    MEMORY.declare_label(p[1], p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_asm_ld8(p):\n    if p[2] in ('H', 'L') and p[4] in ('IXH', 'IXL', 'IYH', 'IYL'):\n        p[0] = None\n        error(p.lineno(0), \"Unexpected token '%s'\" % p[4])\n    else:\n        p[0] = Asm(p.lineno(1), 'LD %s,%s' % (p[2], p[4]))", "response": "Parse an ASM L8 sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_LOCAL(p):\n    p[0] = None\n    for label, line in p[2]:\n        __DEBUG__(\"Setting label '%s' as local at line %i\" % (label, line))\n\n        MEMORY.set_label(label, line, local=True)", "response": "A macro that sets the first element of the tree to be local."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_DEFS(p):  # Define bytes\n    if len(p[2]) > 2:\n        error(p.lineno(1), \"too many arguments for DEFS\")\n\n    if len(p[2]) < 2:\n        num = Expr.makenode(Container(0, p.lineno(1)))  # Defaults to 0\n        p[2] = p[2] + (num,)\n\n    p[0] = Asm(p.lineno(1), 'DEFS', p[2])", "response": "asm : DEFS number_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_namespace(p):\n    global NAMESPACE\n\n    NAMESPACE = normalize_namespace(p[2])\n    __DEBUG__('Setting namespace to ' + (NAMESPACE.rstrip(DOT) or DOT), level=1)", "response": "Set the NAMESPACE property of the asm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_incbin(p):\n    try:\n        fname = zxbpp.search_filename(p[2], p.lineno(2), local_first=True)\n        if not fname:\n            p[0] = None\n            return\n        with api.utils.open_file(fname, 'rb') as f:\n            filecontent = f.read()\n    except IOError:\n        error(p.lineno(2), \"cannot read file '%s'\" % p[2])\n        p[0] = None\n        return\n\n    p[0] = Asm(p.lineno(1), 'DEFB', filecontent)", "response": "A function to parse INCBIN STRINGs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_JP_hl(p):\n    s = 'JP '\n    if p[2] == '(HL)':\n        s += p[2]\n    else:\n        s += '(%s)' % p[3]\n\n    p[0] = Asm(p.lineno(1), s)", "response": "Asm parser for JP hl."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_BIT(p):\n    bit = p[2].eval()\n    if bit < 0 or bit > 7:\n        error(p.lineno(3), 'Invalid bit position %i. Must be in [0..7]' % bit)\n        p[0] = None\n        return\n\n    p[0] = Asm(p.lineno(3), '%s %i,%s' % (p[1], bit, p[4]))", "response": "asm : bitop expr COMMA A\n            | bitop pexpr COMMA A\n            | bitop expr COMMA reg8\n            | bitop pexpr COMMA reg8\n            | bitop expr COMMA reg8_hl\n            | bitop pexpr COMMA reg8_hl"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_jrjp(p):\n    if p[1] in ('JR', 'DJNZ'):\n        op = 'N'\n        p[2] = Expr.makenode(Container('-', p.lineno(1)), p[2], Expr.makenode(Container(MEMORY.org + 2, p.lineno(1))))\n    else:\n        op = 'NN'\n\n    p[0] = Asm(p.lineno(1), p[1] + ' ' + op, p[2])", "response": "A macro - line parser for the next statement in the JVM."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_im(p):\n    val = p[2].eval()\n    if val not in (0, 1, 2):\n        error(p.lineno(1), 'Invalid IM number %i' % val)\n        p[0] = None\n        return\n\n    p[0] = Asm(p.lineno(1), 'IM %i' % val)", "response": "A function to parse the IM expression."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing expr DIV expr", "response": "def p_expr_div_expr(p):\n    \"\"\" expr : expr BAND expr\n             | expr BOR expr\n             | expr BXOR expr\n             | expr PLUS expr\n             | expr MINUS expr\n             | expr MUL expr\n             | expr DIV expr\n             | expr MOD expr\n             | expr POW expr\n             | expr LSHIFT expr\n             | expr RSHIFT expr\n             | pexpr BAND expr\n             | pexpr BOR expr\n             | pexpr BXOR expr\n             | pexpr PLUS expr\n             | pexpr MINUS expr\n             | pexpr MUL expr\n             | pexpr DIV expr\n             | pexpr MOD expr\n             | pexpr POW expr\n             | pexpr LSHIFT expr\n             | pexpr RSHIFT expr\n             | expr BAND pexpr\n             | expr BOR pexpr\n             | expr BXOR pexpr\n             | expr PLUS pexpr\n             | expr MINUS pexpr\n             | expr MUL pexpr\n             | expr DIV pexpr\n             | expr MOD pexpr\n             | expr POW pexpr\n             | expr LSHIFT pexpr\n             | expr RSHIFT pexpr\n             | pexpr BAND pexpr\n             | pexpr BOR pexpr\n             | pexpr BXOR pexpr\n             | pexpr PLUS pexpr\n             | pexpr MINUS pexpr\n             | pexpr MUL pexpr\n             | pexpr DIV pexpr\n             | pexpr MOD pexpr\n             | pexpr POW pexpr\n             | pexpr LSHIFT pexpr\n             | pexpr RSHIFT pexpr\n    \"\"\"\n    p[0] = Expr.makenode(Container(p[2], p.lineno(2)), p[1], p[3])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_expr_label(p):\n    p[0] = Expr.makenode(Container(MEMORY.get_label(p[1], p.lineno(1)), p.lineno(1)))", "response": "P expr_label - > expr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_preprocessor_line_line_file(p):\n    p.lexer.lineno = int(p[2]) + p.lexer.lineno - p.lineno(3) - 1\n    gl.FILENAME = p[3]", "response": "preproc_line : _LINE INTEGER STRING"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nassembles input string and leave the result in the", "response": "def assemble(input_):\n    \"\"\" Assembles input string, and leave the result in the\n    MEMORY global object\n    \"\"\"\n    global MEMORY\n\n    if MEMORY is None:\n        MEMORY = Memory()\n\n    parser.parse(input_, lexer=LEXER, debug=OPTIONS.Debug.value > 2)\n    if len(MEMORY.scopes):\n        error(MEMORY.scopes[-1], 'Missing ENDP to close this scope')\n\n    return gl.has_errors"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_binary(outputfname, format_, progname='', binary_files=None, headless_binary_files=None):\n    global AUTORUN_ADDR\n\n    org, binary = MEMORY.dump()\n    if gl.has_errors:\n        return\n\n    if binary_files is None:\n        binary_files = []\n\n    if headless_binary_files is None:\n        headless_binary_files = []\n\n    bin_blocks = []\n    for fname in binary_files:\n        with api.utils.open_file(fname) as f:\n            bin_blocks.append((os.path.basename(fname), f.read()))\n\n    headless_bin_blocks = []\n    for fname in headless_binary_files:\n        with api.utils.open_file(fname) as f:\n            headless_bin_blocks.append(f.read())\n\n    if AUTORUN_ADDR is None:\n        AUTORUN_ADDR = org\n\n    if not progname:\n        progname = os.path.basename(outputfname)[:10]\n\n    if OPTIONS.use_loader.value:\n        import basic  # Minimalist basic tokenizer\n\n        program = basic.Basic()\n        if org > 16383:  # Only for zx48k: CLEAR if below 16383\n            program.add_line([['CLEAR', org - 1]])\n        program.add_line([['LOAD', '\"\"', program.token('CODE')]])\n\n        if OPTIONS.autorun.value:\n            program.add_line([['RANDOMIZE', program.token('USR'), AUTORUN_ADDR]])\n        else:\n            program.add_line([['REM'], ['RANDOMIZE', program.token('USR'), AUTORUN_ADDR]])\n\n    if format_ in ('tap', 'tzx'):\n        t = {'tap': outfmt.TAP, 'tzx': outfmt.TZX}[format_]()\n\n        if OPTIONS.use_loader.value:\n            t.save_program('loader', program.bytes, line=1)  # Put line 0 to protect against MERGE\n\n        t.save_code(progname, org, binary)\n        for name, block in bin_blocks:\n            t.save_code(name, 0, block)\n        for block in headless_bin_blocks:\n            t.standard_block(block)\n\n        t.dump(outputfname)\n\n    else:\n        with open(outputfname, 'wb') as f:\n            f.write(bytearray(binary))", "response": "Generates the memory binary file for the given format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the bytes representation of the current asm.", "response": "def bytes(self):\n        \"\"\" Returns opcodes\n        \"\"\"\n        if self.asm not in ('DEFB', 'DEFS', 'DEFW'):\n            if self.pending:\n                tmp = self.arg  # Saves current arg temporarily\n                self.arg = tuple([0] * self.arg_num)\n                result = super(Asm, self).bytes()\n                self.arg = tmp  # And recovers it\n\n                return result\n\n            return super(Asm, self).bytes()\n\n        if self.asm == 'DEFB':\n            if self.pending:\n                return tuple([0] * self.arg_num)\n\n            return tuple([x & 0xFF for x in self.argval()])\n\n        if self.asm == 'DEFS':\n            if self.pending:\n                N = self.arg[0]\n                if isinstance(N, Expr):\n                    N = N.eval()\n                return tuple([0] * N)  # ??\n\n            args = self.argval()\n            num = args[1] & 0xFF\n            return tuple([num] * args[0])\n\n        if self.pending:  # DEFW\n            return tuple([0] * 2 * self.arg_num)\n\n        result = ()\n        for i in self.argval():\n            x = i & 0xFFFF\n            result += (x & 0xFF, x >> 8)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef argval(self):\n        if gl.has_errors:\n            return [None]\n\n        if self.asm in ('DEFB', 'DEFS', 'DEFW'):\n            return tuple([x.eval() if isinstance(x, Expr) else x for x in self.arg])\n\n        self.arg = tuple([x if not isinstance(x, Expr) else x.eval() for x in self.arg])\n        if gl.has_errors:\n            return [None]\n\n        if self.asm.split(' ')[0] in ('JR', 'DJNZ'):  # A relative jump?\n            if self.arg[0] < -128 or self.arg[0] > 127:\n                error(self.lineno, 'Relative jump out of range')\n                return [None]\n\n        return super(Asm, self).argval()", "response": "Solve args values or raise errors if not defined yet"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef try_eval(self):\n        item = self.symbol.item\n\n        if isinstance(item, int):\n            return item\n\n        if isinstance(item, Label):\n            if item.defined:\n                if isinstance(item.value, Expr):\n                    return item.value.try_eval()\n                else:\n                    return item.value\n            else:\n                if Expr.ignore:\n                    return None\n\n                # Try to resolve into the global namespace\n                error(self.symbol.lineno, \"Undefined label '%s'\" % item.name)\n                return None\n\n        try:\n            if isinstance(item, tuple):\n                return tuple([x.try_eval() for x in item])\n\n            if isinstance(item, list):\n                return [x.try_eval() for x in item]\n\n            if item == '-' and len(self.children) == 1:\n                return -self.left.try_eval()\n\n            try:\n                return self.funct[item](self.left.try_eval(), self.right.try_eval())\n            except ZeroDivisionError:\n                error(self.symbol.lineno, 'Division by 0')\n            except KeyError:\n                pass\n\n        except TypeError:\n            pass\n\n        return None", "response": "Recursively evaluates the node. Returns None if it is still unresolved."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefine a label value. It can be anything. Even an AST", "response": "def define(self, value, lineno, namespace=None):\n        \"\"\" Defines label value. It can be anything. Even an AST\n        \"\"\"\n        if self.defined:\n            error(lineno, \"label '%s' already defined at line %i\" % (self.name, self.lineno))\n\n        self.value = value\n        self.lineno = lineno\n        self.namespace = NAMESPACE if namespace is None else namespace"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve(self, lineno):\n        if not self.defined:\n            error(lineno, \"Undeclared label '%s'\" % self.name)\n\n        if isinstance(self.value, Expr):\n            return self.value.eval()\n\n        return self.value", "response": "Resolves the label value. Exits with error if value is not defined."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enter_proc(self, lineno):\n        self.local_labels.append({})  # Add a new context\n        self.scopes.append(lineno)\n        __DEBUG__('Entering scope level %i at line %i' % (len(self.scopes), lineno))", "response": "Adds a new context\n        to the list of scope level names and adds a new context\n        to the list of scope level names and the current line number."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_org(self, value, lineno):\n        if value < 0 or value > MAX_MEM:\n            error(lineno, \"Memory ORG out of range [0 .. 65535]. Current value: %i\" % value)\n\n        self.index = self.ORG = value", "response": "Sets a new ORG value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves a name and a namespace returns the name as namespace +. + name.", "response": "def id_name(label, namespace=None):\n        \"\"\" Given a name and a namespace, resolves\n        returns the name as namespace + '.' + name. If namespace\n        is none, the current NAMESPACE is used\n        \"\"\"\n        if not label.startswith(DOT):\n            if namespace is None:\n                namespace = NAMESPACE\n            ex_label = namespace + label  # The mangled namespace.labelname label\n        else:\n            if namespace is None:\n                namespace = GLOBAL_NAMESPACE  # Global namespace\n            ex_label = label\n\n        return ex_label, namespace"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __set_byte(self, byte, lineno):\n        if byte < 0 or byte > 255:\n            error(lineno, 'Invalid byte value %i' % byte)\n\n        self.memory_bytes[self.org] = byte\n        self.index += 1", "response": "Sets a byte at the current location and increments org in one."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexits current procedure. Local labels are transferred to global scope unless they have been marked as local ones. Raises an error if no current local context (stack underflow)", "response": "def exit_proc(self, lineno):\n        \"\"\" Exits current procedure. Local labels are transferred to global\n        scope unless they have been marked as local ones.\n\n        Raises an error if no current local context (stack underflow)\n        \"\"\"\n        __DEBUG__('Exiting current scope from lineno %i' % lineno)\n\n        if len(self.local_labels) <= 1:\n            error(lineno, 'ENDP in global scope (with no PROC)')\n            return\n\n        for label in self.local_labels[-1].values():\n            if label.local:\n                if not label.defined:\n                    error(lineno, \"Undefined LOCAL label '%s'\" % label.name)\n                    return\n                continue\n\n            name = label.name\n            _lineno = label.lineno\n            value = label.value\n\n            if name not in self.global_labels.keys():\n                self.global_labels[name] = label\n            else:\n                self.global_labels[name].define(value, _lineno)\n\n        self.local_labels.pop()  # Removes current context\n        self.scopes.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_instruction(self, instr):\n        if gl.has_errors:\n            return\n\n        __DEBUG__('%04Xh [%04Xh] ASM: %s' % (self.org, self.org - self.ORG, instr.asm))\n        self.set_memory_slot()\n        self.orgs[self.org] += (instr,)\n\n        for byte in instr.bytes():\n            self.__set_byte(byte, instr.lineno)", "response": "This method adds an instruction to the current ASM memory slot and adds the opcode to the memory bytes at the current memory position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a tuple containing code ORG and a list of OUTPUT ArcGIS memory regions.", "response": "def dump(self):\n        \"\"\" Returns a tuple containing code ORG, and a list of OUTPUT\n        \"\"\"\n        org = min(self.memory_bytes.keys())  # Org is the lowest one\n        OUTPUT = []\n        align = []\n\n        for i in range(org, max(self.memory_bytes.keys()) + 1):\n            if gl.has_errors:\n                return org, OUTPUT\n\n            try:\n                try:\n                    a = [x for x in self.orgs[i] if isinstance(x, Asm)]  # search for asm instructions\n\n                    if not a:\n                        align.append(0)  # Fill with ZEROes not used memory regions\n                        continue\n\n                    OUTPUT += align\n                    align = []\n                    a = a[0]\n                    if a.pending:\n                        a.arg = a.argval()\n                        a.pending = False\n                        tmp = a.bytes()\n\n                        for r in range(len(tmp)):\n                            self.memory_bytes[i + r] = tmp[r]\n                except KeyError:\n                    pass\n\n                OUTPUT.append(self.memory_bytes[i])\n\n            except KeyError:\n                OUTPUT.append(0)  # Fill with ZEROes not used memory regions\n\n        return org, OUTPUT"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef declare_label(self, label, lineno, value=None, local=False, namespace=None):\n        ex_label, namespace = Memory.id_name(label, namespace)\n\n        is_address = value is None\n        if value is None:\n            value = self.org\n\n        if ex_label in self.local_labels[-1].keys():\n            self.local_labels[-1][ex_label].define(value, lineno)\n            self.local_labels[-1][ex_label].is_address = is_address\n        else:\n            self.local_labels[-1][ex_label] = Label(ex_label, lineno, value, local, namespace, is_address)\n\n        self.set_memory_slot()\n\n        return self.local_labels[-1][ex_label]", "response": "Sets a label with the given value or with the current address. Returns the label object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_label(self, label, lineno):\n        global NAMESPACE\n\n        ex_label, namespace = Memory.id_name(label)\n\n        for i in range(len(self.local_labels) - 1, -1, -1):  # Downstep\n            result = self.local_labels[i].get(ex_label, None)\n            if result is not None:\n                return result\n\n        result = Label(ex_label, lineno, namespace=namespace)\n        self.local_labels[-1][ex_label] = result  # HINT: no namespace\n\n        return result", "response": "Returns a label in the current context or in the global one."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a label lineno and local flag in the current scope .", "response": "def set_label(self, label, lineno, local=False):\n        \"\"\" Sets a label, lineno and local flag in the current scope\n        (even if it exist in previous scopes). If the label exist in\n        the current scope, changes it flags.\n\n        The resulting label is returned.\n        \"\"\"\n        ex_label, namespace = Memory.id_name(label)\n\n        if ex_label in self.local_labels[-1].keys():\n            result = self.local_labels[-1][ex_label]\n            result.lineno = lineno\n        else:\n            result = self.local_labels[-1][ex_label] = Label(ex_label, lineno, namespace=NAMESPACE)\n\n        if result.local == local:\n            warning(lineno, \"label '%s' already declared as LOCAL\" % label)\n\n        result.local = local\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef memory_map(self):\n        return '\\n'.join(sorted(\"%04X: %s\" % (x.value, x.name) for x in self.global_labels.values() if x.is_address))", "response": "Returns a string containing a memory map containing a memory map containing a hex address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _aload8(ins):\n    ''' Loads an 8 bit value from a memory address\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    '''\n    output = _addr(ins.quad[2])\n    output.append('ld a, (hl)')\n    output.append('push af')\n\n    return output", "response": "Load an 8 bit value from a memory address\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a 16 bit value from a memory address", "response": "def _aload16(ins):\n    ''' Loads a 16 bit value from a memory address\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    '''\n    output = _addr(ins.quad[2])\n\n    output.append('ld e, (hl)')\n    output.append('inc hl')\n    output.append('ld d, (hl)')\n    output.append('ex de, hl')\n    output.append('push hl')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a 32 bit value from a memory address.", "response": "def _aload32(ins):\n    ''' Load a 32 bit value from a memory address\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    '''\n    output = _addr(ins.quad[2])\n\n    output.append('call __ILOAD32')\n    output.append('push de')\n    output.append('push hl')\n\n    REQUIRES.add('iload32.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a floating point value from a memory address.", "response": "def _aloadf(ins):\n    ''' Loads a floating point value from a memory address.\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    '''\n    output = _addr(ins.quad[2])\n    output.append('call __LOADF')\n    output.extend(_fpush())\n\n    REQUIRES.add('iloadf.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a string value from a memory address.", "response": "def _aloadstr(ins):\n    ''' Loads a string value from a memory address.\n    '''\n    output = _addr(ins.quad[2])\n\n    output.append('call __ILOADSTR')\n    output.append('push hl')\n    REQUIRES.add('loadstr.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstores 2\u00ba operand content into address of 1st operand.", "response": "def _astore8(ins):\n    ''' Stores 2\u00ba operand content into address of 1st operand.\n    1st operand is an array element. Dimensions are pushed into the\n    stack.\n    Use '*' for indirect store on 1st operand (A pointer to an array)\n    '''\n    output = _addr(ins.quad[1])\n    op = ins.quad[2]\n\n    indirect = op[0] == '*'\n    if indirect:\n        op = op[1:]\n\n    immediate = op[0] == '#'\n    if immediate:\n        op = op[1:]\n\n    if is_int(op):\n        if indirect:\n            if immediate:\n                op = str(int(op) & 0xFFFF)  # Truncate to 16bit pointer\n                output.append('ld a, (%s)' % op)\n            else:\n                output.append('ld de, (%s)' % op)\n                output.append('ld a, (de)')\n        else:\n            op = str(int(op) & 0xFF)  # Truncate to byte\n            output.append('ld (hl), %s' % op)\n            return output\n\n    elif op[0] == '_':\n        if indirect:\n            if immediate:\n                output.append('ld a, (%s)' % op)  # Redundant: *#_id == _id\n            else:\n                output.append('ld de, (%s)' % op)  # *_id\n                output.append('ld a, (de)')\n        else:\n            if immediate:\n                output.append('ld a, %s' % op)  # #_id\n            else:\n                output.append('ld a, (%s)' % op)  # _id\n    else:\n        output.append('pop af')  # tn\n\n    output.append('ld (hl), a')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _astore16(ins):\n    ''' Stores 2\u00ba operand content into address of 1st operand.\n    store16 a, x =>  *(&a) = x\n    Use '*' for indirect store on 1st operand.\n    '''\n    output = _addr(ins.quad[1])\n    op = ins.quad[2]\n\n    indirect = op[0] == '*'\n    if indirect:\n        op = op[1:]\n\n    immediate = op[0] == '#'\n    if immediate:\n        op = op[1:]\n\n    if is_int(op):\n        op = str(int(op) & 0xFFFF)  # Truncate to 16bit pointer\n\n        if indirect:\n            if immediate:\n                output.append('ld de, (%s)' % op)\n            else:\n                output.append('ld de, (%s)' % op)\n                output.append('call __LOAD_DE_DE')\n                REQUIRES.add('lddede.asm')\n        else:\n            H = int(op) >> 8\n            L = int(op) & 0xFF\n            output.append('ld (hl), %i' % L)\n            output.append('inc hl')\n            output.append('ld (hl), %i' % H)\n            return output\n\n    elif op[0] == '_':\n        if indirect:\n            if immediate:\n                output.append('ld de, (%s)' % op)  # redundant: *#_id == _id\n            else:\n                output.append('ld de, (%s)' % op)  # *_id\n                output.append('call __LOAD_DE_DE')\n                REQUIRES.add('lddede.asm')\n        else:\n            if immediate:\n                output.append('ld de, %s' % op)\n            else:\n                output.append('ld de, (%s)' % op)\n    else:\n        output.append('pop de')\n\n    output.append('ld (hl), e')\n    output.append('inc hl')\n    output.append('ld (hl), d')\n\n    return output", "response": "Stores 2\u00ba operand content into address of 1st operand."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstore 2\u00ba operand content into address of 1st operand.", "response": "def _astore32(ins):\n    ''' Stores 2\u00ba operand content into address of 1st operand.\n    store16 a, x =>  *(&a) = x\n    '''\n    output = _addr(ins.quad[1])\n\n    value = ins.quad[2]\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    try:\n        value = int(ins.quad[2]) & 0xFFFFFFFF  # Immediate?\n        if indirect:\n            output.append('push hl')\n            output.append('ld hl, %i' % (value & 0xFFFF))\n            output.append('call __ILOAD32')\n            output.append('ld b, h')\n            output.append('ld c, l')  # BC = Lower 16 bits\n            output.append('pop hl')\n            REQUIRES.add('iload32.asm')\n        else:\n            output.append('ld de, %i' % (value >> 16))\n            output.append('ld bc, %i' % (value & 0xFFFF))\n    except ValueError:\n        output.append('pop bc')\n        output.append('pop de')\n\n    output.append('call __STORE32')\n    REQUIRES.add('store32.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _astoref16(ins):\n    ''' Stores 2\u00ba operand content into address of 1st operand.\n    storef16 a, x =>  *(&a) = x\n    '''\n    output = _addr(ins.quad[1])\n\n    value = ins.quad[2]\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    if indirect:\n        output.append('push hl')\n        output.extend(_f16_oper(ins.quad[2], useBC=True))\n        output.append('pop hl')\n        REQUIRES.add('iload32.asm')\n    else:\n        output.extend(_f16_oper(ins.quad[2], useBC=True))\n\n    output.append('call __STORE32')\n    REQUIRES.add('store32.asm')\n\n    return output", "response": "Stores 2\u00ba operand content into address of 1st operand."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _astoref(ins):\n    ''' Stores a floating point value into a memory address.\n    '''\n    output = _addr(ins.quad[1])\n\n    value = ins.quad[2]\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    if indirect:\n        output.append('push hl')\n        output.extend(_float_oper(ins.quad[2]))\n        output.append('pop hl')\n    else:\n        output.extend(_float_oper(ins.quad[2]))\n\n    output.append('call __STOREF')\n    REQUIRES.add('storef.asm')\n\n    return output", "response": "Stores a floating point value into a memory address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _astorestr(ins):\n    ''' Stores a string value into a memory address.\n    It copies content of 2nd operand (string), into 1st, reallocating\n    dynamic memory for the 1st str. These instruction DOES ALLOW\n    immediate strings for the 2nd parameter, starting with '#'.\n    '''\n    output = _addr(ins.quad[1])\n    op = ins.quad[2]\n\n    indirect = op[0] == '*'\n    if indirect:\n        op = op[1:]\n\n    immediate = op[0] == '#'\n    if immediate:\n        op = op[1:]\n\n    temporal = op[0] != '$'\n    if not temporal:\n        op = op[1:]\n\n    if is_int(op):\n        op = str(int(op) & 0xFFFF)\n        if indirect:\n            if immediate:  # *#<addr> = ld hl, (number)\n                output.append('ld de, (%s)' % op)\n            else:\n                output.append('ld de, (%s)' % op)\n                output.append('call __LOAD_DE_DE')\n                REQUIRES.add('lddede.asm')\n        else:\n            # Integer does not make sense here (unless it's a ptr)\n            raise InvalidICError(str(ins))\n\n            output.append('ld de, (%s)' % op)\n    elif op[0] == '_':  # an identifier\n        temporal = False  # Global var is not a temporary string\n\n        if indirect:\n            if immediate:  # *#_id = _id\n                output.append('ld de, (%s)' % op)\n            else:  # *_id\n                output.append('ld de, (%s)' % op)\n                output.append('call __LOAD_DE_DE')\n                REQUIRES.add('lddede.asm')\n        else:\n            if immediate:\n                output.append('ld de, %s' % op)\n            else:\n                output.append('ld de, (%s)' % op)\n    else:  # tn\n        output.append('pop de')\n\n        if indirect:\n            output.append('call __LOAD_DE_DE')\n            REQUIRES.add('lddede.asm')\n\n    if not temporal:\n        output.append('call __STORE_STR')\n        REQUIRES.add('storestr.asm')\n    else:  # A value already on dynamic memory\n        output.append('call __STORE_STR2')\n        REQUIRES.add('storestr2.asm')\n\n    return output", "response": "Stores a string value into a memory address."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a pop sequence for 32 bit operands.", "response": "def _32bit_oper(op1, op2=None, reversed=False, preserveHL=False):\n    \"\"\" Returns pop sequence for 32 bits operands\n    1st operand in HLDE, 2nd operand remains in the stack\n\n    Now it does support operands inversion calling __SWAP32.\n\n    However, if 1st operand is integer (immediate) or indirect, the stack\n    will be rearranged, so it contains a 32 bit pushed parameter value for the\n    subroutine to be called.\n\n    If preserveHL is True, then BC will be used instead of HL for lower part\n    for the 1st operand.\n    \"\"\"\n    output = []\n\n    if op1 is not None:\n        op1 = str(op1)\n\n    if op2 is not None:\n        op2 = str(op2)\n\n    op = op2 if op2 is not None else op1\n\n    int1 = False  # whether op1 (2nd operand) is integer\n\n    indirect = (op[0] == '*')\n    if indirect:\n        op = op[1:]\n\n    immediate = (op[0] == '#')\n    if immediate:\n        op = op[1:]\n\n    hl = 'hl' if not preserveHL and not indirect else 'bc'\n\n    if is_int(op):\n        int1 = True\n        op = int(op)\n\n        if indirect:\n            if immediate:\n                output.append('ld hl, %i' % op)\n            else:\n                output.append('ld hl, (%i)' % op)\n\n            output.append('call __ILOAD32')\n            REQUIRES.add('iload32.asm')\n\n            if preserveHL:\n                output.append('ld b, h')\n                output.append('ld c, l')\n        else:\n            DE, HL = int32(op)\n            output.append('ld de, %i' % DE)\n            output.append('ld %s, %i' % (hl, HL))\n    else:\n        if op[0] == '_':\n            if immediate:\n                output.append('ld %s, %s' % (hl, op))\n            else:\n                output.append('ld %s, (%s)' % (hl, op))\n        else:\n            if immediate:\n                output.append('ld %s, (%s) & 0xFFFF' % (hl, op))\n            else:\n                output.append('pop %s' % hl)\n\n        if indirect:\n            output.append('call __ILOAD32')\n            REQUIRES.add('iload32.asm')\n\n            if preserveHL:\n                output.append('ld b, h')\n                output.append('ld c, l')\n        else:\n            if op[0] == '_':\n                output.append('ld de, (%s + 2)' % op)\n            else:\n                if immediate:\n                    output.append('ld de, (%s) >> 16' % op)\n                else:\n                    output.append('pop de')\n\n    if op2 is not None:\n        op = op1\n\n        indirect = (op[0] == '*')\n        if indirect:\n            op = op[1:]\n\n        immediate = (op[0] == '#')\n        if immediate:\n            op = op[1:]\n\n        if is_int(op):\n            op = int(op)\n\n            if indirect:\n                output.append('exx')\n                if immediate:\n                    output.append('ld hl, %i' % (op & 0xFFFF))\n                else:\n                    output.append('ld hl, (%i)' % (op & 0xFFFF))\n\n                output.append('call __ILOAD32')\n                output.append('push de')\n                output.append('push hl')\n                output.append('exx')\n                REQUIRES.add('iload32.asm')\n            else:\n                DE, HL = int32(op)\n                output.append('ld bc, %i' % DE)\n                output.append('push bc')\n                output.append('ld bc, %i' % HL)\n                output.append('push bc')\n        else:\n            if indirect:\n                output.append('exx')  # uses alternate set to put it on the stack\n                if op[0] == '_':\n                    if immediate:\n                        output.append('ld hl, %s' % op)\n                    else:\n                        output.append('ld hl, (%s)' % op)\n                else:\n                    output.append('pop hl')  # Pointers are only 16 bits ***\n\n                output.append('call __ILOAD32')\n                output.append('push de')\n                output.append('push hl')\n                output.append('exx')\n                REQUIRES.add('iload32.asm')\n            elif immediate:\n                output.append('ld bc, (%s) >> 16' % op)\n                output.append('push bc')\n                output.append('ld bc, (%s) & 0xFFFF' % op)\n                output.append('push bc')\n            elif op[0] == '_':  # an address\n                if int1 or op1[0] == '_':  # If previous op was integer, we can use hl in advance\n                    tmp = output\n                    output = []\n                    output.append('ld hl, (%s + 2)' % op)\n                    output.append('push hl')\n                    output.append('ld hl, (%s)' % op)\n                    output.append('push hl')\n                    output.extend(tmp)\n                else:\n                    output.append('ld bc, (%s + 2)' % op)\n                    output.append('push bc')\n                    output.append('ld bc, (%s)' % op)\n                    output.append('push bc')\n            else:\n                pass  # 2nd operand remains in the stack\n\n    if op2 is not None and reversed:\n        output.append('call __SWAP32')\n        REQUIRES.add('swap32.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a 32 - bit integer to the stack and returns the result.", "response": "def _add32(ins):\n    \"\"\" Pops last 2 bytes from the stack and adds them.\n    Then push the result onto the stack.\n\n    Optimizations:\n      * If any of the operands is ZERO,\n        then do NOTHING: A + 0 = 0 + A = A\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n\n    if _int_ops(op1, op2) is not None:\n        o1, o2 = _int_ops(op1, op2)\n\n        if int(o2) == 0:  # A + 0 = 0 + A = A => Do Nothing\n            output = _32bit_oper(o1)\n            output.append('push de')\n            output.append('push hl')\n            return output\n\n    if op1[0] == '_' and op2[0] != '_':\n        op1, op2 = op2, op1  # swap them\n\n    if op2[0] == '_':\n        output = _32bit_oper(op1)\n        output.append('ld bc, (%s)' % op2)\n        output.append('add hl, bc')\n        output.append('ex de, hl')\n        output.append('ld bc, (%s + 2)' % op2)\n        output.append('adc hl, bc')\n        output.append('push hl')\n        output.append('push de')\n        return output\n\n    output = _32bit_oper(op1, op2)\n    output.append('pop bc')\n    output.append('add hl, bc')\n    output.append('ex de, hl')\n    output.append('pop bc')\n    output.append('adc hl, bc')\n    output.append('push hl')  # High and low parts are reversed\n    output.append('push de')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _sub32(ins):\n    op1, op2 = tuple(ins.quad[2:])\n\n    if is_int(op2):\n        if int(op2) == 0:  # A - 0 = A => Do Nothing\n            output = _32bit_oper(op1)\n            output.append('push de')\n            output.append('push hl')\n            return output\n\n    rev = op1[0] != 't' and not is_int(op1) and op2[0] == 't'\n\n    output = _32bit_oper(op1, op2, rev)\n    output.append('call __SUB32')\n    output.append('push de')\n    output.append('push hl')\n    REQUIRES.add('sub32.asm')\n    return output", "response": "Sub32 implementation of the 32 - bit sub - function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmultiplying two last 32bit values on top of the stack and returns the value on top of the stack and .", "response": "def _mul32(ins):\n    \"\"\" Multiplies two last 32bit values on top of the stack and\n    and returns the value on top of the stack\n\n    Optimizations done:\n\n        * If any operand is 1, do nothing\n        * If any operand is 0, push 0\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n    if _int_ops(op1, op2):\n        op1, op2 = _int_ops(op1, op2)\n        output = _32bit_oper(op1)\n\n        if op2 == 1:\n            output.append('push de')\n            output.append('push hl')\n            return output  # A * 1 = Nothing\n\n        if op2 == 0:\n            output.append('ld hl, 0')\n            output.append('push hl')\n            output.append('push hl')\n            return output\n\n    output = _32bit_oper(op1, op2)\n    output.append('call __MUL32')  # Inmmediate\n    output.append('push de')\n    output.append('push hl')\n    REQUIRES.add('mul32.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompare top 2 operands and returns a 32 bit unsigned version of the top 2 operands.", "response": "def _ltu32(ins):\n    \"\"\" Compares & pops top 2 operands out of the stack, and checks\n        if the 1st operand < 2nd operand (top of the stack).\n        Pushes 0 if False, 1 if True.\n\n        32 bit unsigned version\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n    rev = op1[0] != 't' and not is_int(op1) and op2[0] == 't'\n    output = _32bit_oper(op1, op2, rev)\n    output.append('call __SUB32')\n    output.append('sbc a, a')\n    output.append('push af')\n    REQUIRES.add('sub32.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompare top 2 operands and returns a 32 bit unsigned version of the tree.", "response": "def _gtu32(ins):\n    \"\"\" Compares & pops top 2 operands out of the stack, and checks\n        if the 1st operand > 2nd operand (top of the stack).\n        Pushes 0 if False, 1 if True.\n\n        32 bit unsigned version\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n    rev = op1[0] != 't' and not is_int(op1) and op2[0] == 't'\n    output = _32bit_oper(op1, op2, rev)\n    output.append('pop bc')\n    output.append('or a')\n    output.append('sbc hl, bc')\n    output.append('ex de, hl')\n    output.append('pop de')\n    output.append('sbc hl, de')\n    output.append('sbc a, a')\n    output.append('push af')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare top 2 operands and returns a 32 bit un - signed version of the stack.", "response": "def _eq32(ins):\n    \"\"\" Compares & pops top 2 operands out of the stack, and checks\n        if the 1st operand == 2nd operand (top of the stack).\n        Pushes 0 if False, 1 if True.\n\n        32 bit un/signed version\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n    output = _32bit_oper(op1, op2)\n    output.append('call __EQ32')\n    output.append('push af')\n    REQUIRES.add('eq32.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _and32(ins):\n    op1, op2 = tuple(ins.quad[2:])\n\n    if _int_ops(op1, op2):\n        op1, op2 = _int_ops(op1, op2)\n\n        if op2 == 0:  # X and False = False\n            if str(op1)[0] == 't':  # a temporary term (stack)\n                output = _32bit_oper(op1)  # Remove op1 from the stack\n            else:\n                output = []\n            output.append('xor a')\n            output.append('push af')\n            return output\n\n            # For X and TRUE = X we do nothing as we have to convert it to boolean\n            # which is a rather expensive instruction\n\n    output = _32bit_oper(op1, op2)\n    output.append('call __AND32')\n    output.append('push af')\n    REQUIRES.add('and32.asm')\n    return output", "response": "Compares and pops top 2 operands out of the stack and checks\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _not32(ins):\n    output = _32bit_oper(ins.quad[2])\n    output.append('call __NOT32')\n    output.append('push af')\n    REQUIRES.add('not32.asm')\n    return output", "response": "Negates top ( Logical NOT ) of the stack"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _bnot32(ins):\n    output = _32bit_oper(ins.quad[2])\n    output.append('call __BNOT32')\n    output.append('push de')\n    output.append('push hl')\n    REQUIRES.add('bnot32.asm')\n    return output", "response": "Negates top ( 32 bits in DEHL and push hl"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnegate top of the stack.", "response": "def _neg32(ins):\n    \"\"\" Negates top of the stack (32 bits in DEHL)\n    \"\"\"\n    output = _32bit_oper(ins.quad[2])\n    output.append('call __NEG32')\n    output.append('push de')\n    output.append('push hl')\n    REQUIRES.add('neg32.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _abs32(ins):\n    output = _32bit_oper(ins.quad[2])\n    output.append('call __ABS32')\n    output.append('push de')\n    output.append('push hl')\n    REQUIRES.add('abs32.asm')\n    return output", "response": "Returns the absolute value of top of the stack."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _shl32(ins):\n    op1, op2 = tuple(ins.quad[2:])\n\n    if is_int(op2):\n        output = _32bit_oper(op1)\n\n        if int(op2) == 0:\n            output.append('push de')\n            output.append('push hl')\n            return output\n\n        if int(op2) > 1:\n            label = tmp_label()\n            output.append('ld b, %s' % op2)\n            output.append('%s:' % label)\n            output.append('call __SHL32')\n            output.append('djnz %s' % label)\n        else:\n            output.append('call __SHL32')\n\n        output.append('push de')\n        output.append('push hl')\n        REQUIRES.add('shl32.asm')\n        return output\n\n    output = _8bit_oper(op2)\n    output.append('ld b, a')\n    output.extend(_32bit_oper(op1))\n    label = tmp_label()\n    output.append('%s:' % label)\n    output.append('call __SHL32')\n    output.append('djnz %s' % label)\n    output.append('push de')\n    output.append('push hl')\n    REQUIRES.add('shl32.asm')\n    return output", "response": "Logical Left shift 32bit unsigned integers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _float_oper(op1, op2=None):\n    ''' Returns pop sequence for floating point operands\n    1st operand in A DE BC, 2nd operand remains in the stack\n\n    Unlike 8bit and 16bit version, this does not supports\n    operands inversion. Since many of the instructions are implemented\n    as functions, they must support this.\n\n    However, if 1st operand is a number (immediate) or indirect, the stack\n    will be rearranged, so it contains a 48 bit pushed parameter value for the\n    subroutine to be called.\n    '''\n    output = []\n    op = op2 if op2 is not None else op1\n\n    indirect = (op[0] == '*')\n    if indirect:\n        op = op[1:]\n\n    if is_float(op):\n        op = float(op)\n\n        if indirect:\n            op = int(op) & 0xFFFF\n            output.append('ld hl, (%i)' % op)\n            output.append('call __ILOADF')\n            REQUIRES.add('iloadf.asm')\n        else:\n            A, DE, BC = _float(op)\n            output.append('ld a, %s' % A)\n            output.append('ld de, %s' % DE)\n            output.append('ld bc, %s' % BC)\n    else:\n        if indirect:\n            if op[0] == '_':\n                output.append('ld hl, (%s)' % op)\n            else:\n                output.append('pop hl')\n\n            output.append('call __ILOADF')\n            REQUIRES.add('iloadf.asm')\n        else:\n            if op[0] == '_':\n                output.append('ld a, (%s)' % op)\n                output.append('ld de, (%s + 1)' % op)\n                output.append('ld bc, (%s + 3)' % op)\n            else:\n                output.extend(_fpop())\n\n    if op2 is not None:\n        op = op1\n        if is_float(op):  # An float must be in the stack. Let's pushit\n            A, DE, BC = _float(op)\n            output.append('ld hl, %s' % BC)\n            output.append('push hl')\n            output.append('ld hl, %s' % DE)\n            output.append('push hl')\n            output.append('ld h, %s' % A)\n            output.append('push hl')\n        elif op[0] == '*':  # Indirect\n            op = op[1:]\n            output.append('exx')  # uses alternate set to put it on the stack\n            output.append(\"ex af, af'\")\n            if is_int(op):  # noqa TODO: it will fail\n                op = int(op)\n                output.append('ld hl, %i' % op)\n            elif op[0] == '_':\n                output.append('ld hl, (%s)' % op)\n            else:\n                output.append('pop hl')\n\n            output.append('call __ILOADF')\n            output.extend(_fpush())\n            output.append(\"ex af, af'\")\n            output.append('exx')\n            REQUIRES.add('iloadf.asm')\n        elif op[0] == '_':\n            if is_float(op2):\n                tmp = output\n                output = []\n                output.append('ld hl, %s + 4' % op)\n                '''\n                output.append('ld hl, (%s + 3)' % op)\n                output.append('push hl')\n                output.append('ld hl, (%s + 1)' % op)\n                output.append('push hl')\n                output.append('ld a, (%s)' % op)\n                output.append('push af')\n                '''\n                output.append('call __FP_PUSH_REV')\n                output.extend(tmp)\n                REQUIRES.add('pushf.asm')\n            else:\n                '''\n                output.append('ld hl, (%s + 3)' % op)\n                output.append('push hl')\n                output.append('ld hl, (%s + 1)' % op)\n                output.append('push hl')\n                output.append('ld hl, (%s - 1)' % op)\n                output.append('push hl')\n                '''\n                output.append('ld hl, %s + 4' % op)\n                output.append('call __FP_PUSH_REV')\n                REQUIRES.add('pushf.asm')\n        else:\n            pass  # Else do nothing, and leave the op onto the stack\n\n    return output", "response": "Returns pop sequence for floating point operands in A DE BC 2nd operand remains in the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds 2 float values. The result is pushed onto the stack.", "response": "def _addf(ins):\n    ''' Adds 2 float values. The result is pushed onto the stack.\n    '''\n    op1, op2 = tuple(ins.quad[2:])\n\n    if _f_ops(op1, op2) is not None:\n        opa, opb = _f_ops(op1, op2)\n        if opb == 0:  # A + 0 => A\n            output = _float_oper(opa)\n            output.extend(_fpush())\n            return output\n\n    output = _float_oper(op1, op2)\n    output.append('call __ADDF')\n    output.extend(_fpush())\n    REQUIRES.add('addf.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _divf(ins):\n    ''' Divides 2 float values. The result is pushed onto the stack.\n    '''\n    op1, op2 = tuple(ins.quad[2:])\n\n    if is_float(op2) and float(op2) == 1:  # Nothing to do. A / 1 = A\n        output = _float_oper(op1)\n        output.extend(_fpush())\n        return output\n\n    output = _float_oper(op1, op2)\n    output.append('call __DIVF')\n    output.extend(_fpush())\n    REQUIRES.add('divf.asm')\n    return output", "response": "Divides 2 float values. The result is pushed onto the stack."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _modf(ins):\n    ''' Reminder of div. 2 float values. The result is pushed onto the stack.\n    '''\n    op1, op2 = tuple(ins.quad[2:])\n    output = _float_oper(op1, op2)\n    output.append('call __MODF')\n    output.extend(_fpush())\n    REQUIRES.add('modf.asm')\n    return output", "response": "Reminder of div. 2 float values. The result is pushed onto the stack."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ltf(ins):\n    ''' Compares & pops top 2 operands out of the stack, and checks\n        if the 1st operand < 2nd operand (top of the stack).\n        Pushes 0 if False, 1 if True.\n\n        Floating Point version\n    '''\n    op1, op2 = tuple(ins.quad[2:])\n    output = _float_oper(op1, op2)\n    output.append('call __LTF')\n    output.append('push af')\n    REQUIRES.add('ltf.asm')\n    return output", "response": "Compares top 2 operands out of the stack and checks\n        if the 1st operand < 2nd operand."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnegate top of the stack ( 48 bits )", "response": "def _notf(ins):\n    ''' Negates top of the stack (48 bits)\n    '''\n    output = _float_oper(ins.quad[2])\n    output.append('call __NOTF')\n    output.append('push af')\n    REQUIRES.add('notf.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange sign of top of the stack ( 48 bits )", "response": "def _negf(ins):\n    ''' Changes sign of top of the stack (48 bits)\n    '''\n    output = _float_oper(ins.quad[2])\n    output.append('call __NEGF')\n    output.extend(_fpush())\n    REQUIRES.add('negf.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the absolute value of the top of the stack.", "response": "def _absf(ins):\n    ''' Absolute value of top of the stack (48 bits)\n    '''\n    output = _float_oper(ins.quad[2])\n    output.append('res 7, e')  # Just resets the sign bit!\n    output.extend(_fpush())\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_uniques(l):\n    result = []\n\n    for i in l:\n        if i not in result:\n            result.append(i)\n\n    return result", "response": "Returns a list with no repeated elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef t_CHAR(self, t):\n        r\"'.'\"  # A single char\n\n        t.value = ord(t.value[1])\n        t.type = 'INTEGER'\n        return t", "response": "r \"'.. \"' r'."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef t_BIN(self, t):\n        r'(%[01]+)|([01]+[bB])'  # A Binary integer\n        # Note 00B is a 0 binary, but\n        # 00Bh is a 12 in hex. So this pattern must come\n        # after HEXA\n\n        if t.value[0] == '%':\n            t.value = t.value[1:]  # Remove initial %\n        else:\n            t.value = t.value[:-1]  # Remove last 'b'\n\n        t.value = int(t.value, 2)  # Convert to decimal\n        t.type = 'INTEGER'\n        return t", "response": "A Binary integer t"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses preprocessor ID directives.", "response": "def t_preproc_ID(self, t):\n        r'[_a-zA-Z][_a-zA-Z0-9]*'  # preprocessor directives\n        t.type = preprocessor.get(t.value.lower(), 'ID')\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_INITIAL_SHARP(self, t):\n        r'\\#'\n\n        if self.find_column(t) == 1:\n            t.lexer.begin('preproc')\n        else:\n            self.t_INITIAL_preproc_error(t)", "response": "r \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S + \\ S +"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefining input string removing current lexer.", "response": "def input(self, str):\n        \"\"\" Defines input string, removing current lexer.\n        \"\"\"\n        self.input_data = str\n        self.lex = lex.lex(object=self)\n        self.lex.input(self.input_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef typecast(self, type_):\n        self.value = SymbolTYPECAST.make_node(type_, self.value, self.lineno)\n        return self.value is not None", "response": "Test typecast to the argument expression."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _paddr(offset):\n    ''' Generic array address parameter loading.\n    Emmits output code for setting IX at the right location.\n    bytes = Number of bytes to load:\n        1 => 8 bit value\n        2 => 16 bit value / string\n        4 => 32 bit value / f16 value\n        5 => 40 bit value\n    '''\n    output = []\n\n    indirect = offset[0] == '*'\n    if indirect:\n        offset = offset[1:]\n\n    I = int(offset)\n    if I >= 0:\n        I += 4  # Return Address + \"push IX\"\n\n    output.append('push ix')\n    output.append('pop hl')\n    output.append('ld de, %i' % I)\n    output.append('add hl, de')\n\n    if indirect:\n        output.append('ld c, (hl)')\n        output.append('inc hl')\n        output.append('ld h, (hl)')\n        output.append('ld l, c')\n\n    output.append('call __ARRAY')\n    REQUIRES.add('array.asm')\n    return output", "response": "Generic array address parameter loading."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload an 8 bit value from a memory address.", "response": "def _paload8(ins):\n    ''' Loads an 8 bit value from a memory address\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    '''\n    output = _paddr(ins.quad[2])\n    output.append('ld a, (hl)')\n    output.append('push af')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _paload16(ins):\n    ''' Loads a 16 bit value from a memory address\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    '''\n    output = _paddr(ins.quad[2])\n\n    output.append('ld e, (hl)')\n    output.append('inc hl')\n    output.append('ld d, (hl)')\n    output.append('ex de, hl')\n    output.append('push hl')\n\n    return output", "response": "Load a 16 bit value from a memory address\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _paload32(ins):\n    ''' Load a 32 bit value from a memory address\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    '''\n    output = _paddr(ins.quad[2])\n\n    output.append('call __ILOAD32')\n    output.append('push de')\n    output.append('push hl')\n\n    REQUIRES.add('iload32.asm')\n\n    return output", "response": "Load a 32 bit value from a memory address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _paloadf(ins):\n    ''' Loads a floating point value from a memory address.\n    If 2nd arg. start with '*', it is always treated as\n    an indirect value.\n    '''\n    output = _paddr(ins.quad[2])\n    output.append('call __ILOADF')\n    output.extend(_fpush())\n\n    REQUIRES.add('iloadf.asm')\n\n    return output", "response": "Load a floating point value from a memory address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a string value from a memory address.", "response": "def _paloadstr(ins):\n    ''' Loads a string value from a memory address.\n    '''\n    output = _paddr(ins.quad[2])\n\n    output.append('call __ILOADSTR')\n    output.append('push hl')\n    REQUIRES.add('loadstr.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pastore8(ins):\n    ''' Stores 2\u00ba operand content into address of 1st operand.\n    1st operand is an array element. Dimensions are pushed into the\n    stack.\n    Use '*' for indirect store on 1st operand (A pointer to an array)\n    '''\n    output = _paddr(ins.quad[1])\n\n    value = ins.quad[2]\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    try:\n        value = int(ins.quad[2]) & 0xFFFF\n        if indirect:\n            output.append('ld a, (%i)' % value)\n            output.append('ld (hl), a')\n        else:\n            value &= 0xFF\n            output.append('ld (hl), %i' % value)\n    except ValueError:\n        output.append('pop af')\n        output.append('ld (hl), a')\n\n    return output", "response": "Stores 2\u00ba operand content into address of 1st operand."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstore 2\u00ba operand content into address of 1st operand.", "response": "def _pastore16(ins):\n    ''' Stores 2\u00ba operand content into address of 1st operand.\n    store16 a, x =>  *(&a) = x\n    Use '*' for indirect store on 1st operand.\n    '''\n    output = _paddr(ins.quad[1])\n\n    value = ins.quad[2]\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    try:\n        value = int(ins.quad[2]) & 0xFFFF\n        output.append('ld de, %i' % value)\n        if indirect:\n            output.append('call __LOAD_DE_DE')\n            REQUIRES.add('lddede.asm')\n\n    except ValueError:\n        output.append('pop de')\n\n    output.append('ld (hl), e')\n    output.append('inc hl')\n    output.append('ld (hl), d')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pastore32(ins):\n    ''' Stores 2\u00ba operand content into address of 1st operand.\n    store16 a, x =>  *(&a) = x\n    '''\n    output = _paddr(ins.quad[1])\n\n    value = ins.quad[2]\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    try:\n        value = int(ins.quad[2]) & 0xFFFFFFFF  # Immediate?\n        if indirect:\n            output.append('push hl')\n            output.append('ld hl, %i' % (value & 0xFFFF))\n            output.append('call __ILOAD32')\n            output.append('ld b, h')\n            output.append('ld c, l')  # BC = Lower 16 bits\n            output.append('pop hl')\n            REQUIRES.add('iload32.asm')\n        else:\n            output.append('ld de, %i' % (value >> 16))\n            output.append('ld bc, %i' % (value & 0xFFFF))\n    except ValueError:\n        output.append('pop bc')\n        output.append('pop de')\n\n    output.append('call __STORE32')\n    REQUIRES.add('store32.asm')\n\n    return output", "response": "Stores 2\u00ba operand content into address of 1st operand."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstore 2\u00ba operand content into address of 1st operand.", "response": "def _pastoref16(ins):\n    ''' Stores 2\u00ba operand content into address of 1st operand.\n    storef16 a, x =>  *(&a) = x\n    '''\n    output = _paddr(ins.quad[1])\n\n    value = ins.quad[2]\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    try:\n        if indirect:\n            value = int(ins.quad[2])\n            output.append('push hl')\n            output.append('ld hl, %i' % (value & 0xFFFF))\n            output.append('call __ILOAD32')\n            output.append('ld b, h')\n            output.append('ld c, l')  # BC = Lower 16 bits\n            output.append('pop hl')\n            REQUIRES.add('iload32.asm')\n        else:\n            de, hl = f16(value)\n            output.append('ld de, %i' % de)\n            output.append('ld bc, %i' % hl)\n    except ValueError:\n        output.append('pop bc')\n        output.append('pop de')\n\n    output.append('call __STORE32')\n    REQUIRES.add('store32.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pastoref(ins):\n    ''' Stores a floating point value into a memory address.\n    '''\n    output = _paddr(ins.quad[1])\n\n    value = ins.quad[2]\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    try:\n        if indirect:\n            value = int(value) & 0xFFFF  # Inmediate?\n            output.append('push hl')\n            output.append('ld hl, %i' % value)\n            output.append('call __ILOADF')\n            output.append('ld a, c')\n            output.append('ld b, h')\n            output.append('ld c, l')  # BC = Lower 16 bits, A = Exp\n            output.append('pop hl')     # Recovers pointer\n            REQUIRES.add('iloadf.asm')\n        else:\n            value = float(value)  # Inmediate?\n            C, DE, HL = fp.immediate_float(value)  # noqa TODO: it will fail\n            output.append('ld a, %s' % C)\n            output.append('ld de, %s' % DE)\n            output.append('ld bc, %s' % HL)\n    except ValueError:\n        output.append('pop bc')\n        output.append('pop de')\n        output.append('ex (sp), hl')  # Preserve HL for STOREF\n        output.append('ld a, l')\n        output.append('pop hl')\n\n    output.append('call __STOREF')\n    REQUIRES.add('storef.asm')\n\n    return output", "response": "Stores a floating point value into a memory address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstoring a string value into a memory address.", "response": "def _pastorestr(ins):\n    ''' Stores a string value into a memory address.\n    It copies content of 2nd operand (string), into 1st, reallocating\n    dynamic memory for the 1st str. These instruction DOES ALLOW\n    inmediate strings for the 2nd parameter, starting with '#'.\n    '''\n    output = _paddr(ins.quad[1])\n    temporal = False\n    value = ins.quad[2]\n\n    indirect = value[0] == '*'\n    if indirect:\n        value = value[1:]\n\n    immediate = value[0]\n    if immediate:\n        value = value[1:]\n\n    if value[0] == '_':\n        if indirect:\n            if immediate:\n                output.append('ld de, (%s)' % value)\n            else:\n                output.append('ld de, (%s)' % value)\n                output.append('call __LOAD_DE_DE')\n                REQUIRES.add('lddede.asm')\n        else:\n            if immediate:\n                output.append('ld de, %s' % value)\n            else:\n                output.append('ld de, (%s)' % value)\n    else:\n        output.append('pop de')\n        temporal = True\n\n        if indirect:\n            output.append('call __LOAD_DE_DE')\n            REQUIRES.add('lddede.asm')\n\n    if not temporal:\n        output.append('call __STORE_STR')\n        REQUIRES.add('storestr.asm')\n    else:  # A value already on dynamic memory\n        output.append('call __STORE_STR2')\n        REQUIRES.add('storestr2.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an integer to a little - endian t - tuple of bytes.", "response": "def num2bytes(x, bytes):\n    \"\"\" Returns x converted to a little-endian t-uple of bytes.\n    E.g. num2bytes(255, 4) = (255, 0, 0, 0)\n    \"\"\"\n    if not isinstance(x, int):  # If it is another \"thing\", just return ZEROs\n        return tuple([0] * bytes)\n\n    x = x & ((2 << (bytes * 8)) - 1)  # mask the initial value\n    result = ()\n\n    for i in range(bytes):\n        result += (x & 0xFF,)\n        x >>= 8\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef argval(self):\n        if self.arg is None or any(x is None for x in self.arg):\n            return None\n\n        for x in self.arg:\n            if not isinstance(x, int):\n                raise InvalidArgError(self.arg)\n\n        return self.arg", "response": "Returns the value of the arg."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bytes(self):\n        result = []\n        op = self.opcode.split(' ')\n        argi = 0\n\n        while op:\n            q = op.pop(0)\n\n            if q == 'XX':\n                for k in range(self.argbytes[argi] - 1):\n                    op.pop(0)\n\n                result.extend(num2bytes(self.argval()[argi], self.argbytes[argi]))\n                argi += 1\n            else:\n                result.append(int(q, 16))  # Add opcode\n\n        if len(result) != self.size:\n            raise InternalMismatchSizeError(len(result), self)\n\n        return result", "response": "Returns a t - tuple with instruction bytes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwarning for implicit type x for id_.", "response": "def warning_implicit_type(lineno, id_, type_=None):\n    \"\"\" Warning: Using default implicit type 'x'\n    \"\"\"\n    if OPTIONS.strict.value:\n        syntax_error_undeclared_type(lineno, id_)\n        return\n\n    if type_ is None:\n        type_ = global_.DEFAULT_TYPE\n\n    warning(lineno, \"Using default implicit type '%s' for '%s'\" % (type_, id_))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn operands of an ASM instruction.", "response": "def oper(inst):\n    \"\"\" Returns operands of an ASM instruction.\n    Even \"indirect\" operands, like SP if RET or CALL is used.\n    \"\"\"\n    i = inst.strip(' \\t\\n').split(' ')\n    I = i[0].lower()  # Instruction\n    i = ''.join(i[1:])\n\n    op = i.split(',')\n    if I in {'call', 'jp', 'jr'} and len(op) > 1:\n        op = op[1:] + ['f']\n\n    elif I == 'djnz':\n        op.append('b')\n\n    elif I in {'push', 'pop', 'call'}:\n        op.append('sp')  # Sp is also affected by push, pop and call\n\n    elif I in {'or', 'and', 'xor', 'neg', 'cpl', 'rrca', 'rlca'}:\n        op.append('a')\n\n    elif I in {'rra', 'rla'}:\n        op.extend(['a', 'f'])\n\n    elif I in ('rr', 'rl'):\n        op.append('f')\n\n    elif I in {'adc', 'sbc'}:\n        if len(op) == 1:\n            op = ['a', 'f'] + op\n\n    elif I in {'add', 'sub'}:\n        if len(op) == 1:\n            op = ['a'] + op\n\n    elif I in {'ldd', 'ldi', 'lddr', 'ldir'}:\n        op = ['hl', 'de', 'bc']\n\n    elif I in {'cpd', 'cpi', 'cpdr', 'cpir'}:\n        op = ['a', 'hl', 'bc']\n\n    elif I == 'exx':\n        op = ['*', 'bc', 'de', 'hl', 'b', 'c', 'd', 'e', 'h', 'l']\n\n    elif I in {'ret', 'reti', 'retn'}:\n        op += ['sp']\n\n    elif I == 'out':\n        if len(op) and RE_OUTC.match(op[0]):\n            op[0] = 'c'\n        else:\n            op.pop(0)\n\n    elif I == 'in':\n        if len(op) > 1 and RE_OUTC.match(op[1]):\n            op[1] = 'c'\n        else:\n            op.pop(1)\n\n    for i in range(len(op)):\n        tmp = RE_INDIR16.match(op[i])\n        if tmp is not None:\n            op[i] = '(' + op[i].strip()[1:-1].strip().lower() + ')'  # '  (  dE )  ' => '(de)'\n\n    return op"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef condition(i):\n    I = inst(i)\n\n    if I not in {'call', 'jp', 'jr', 'ret'}:\n        return None  # This instruction always execute\n\n    if I == 'ret':\n        i = [x.lower() for x in i.split(' ') if x != '']\n        return i[1] if len(i) > 1 else None\n\n    i = [x.strip() for x in i.split(',')]\n    i = [x.lower() for x in i[0].split(' ') if x != '']\n    if len(i) > 1 and i[1] in {'c', 'nc', 'z', 'nz', 'po', 'pe', 'p', 'm'}:\n        return i[1]\n\n    return None", "response": "Returns the flag this instruction uses\n    or None. E. g. c z p m is not - zero etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef single_registers(op):\n    result = set()\n    if isinstance(op, str):\n        op = [op]\n\n    for x in op:\n        if is_8bit_register(x):\n            result = result.union([x])\n        elif x == 'sp':\n            result.add(x)\n        elif x == 'af':\n            result = result.union(['a', 'f'])\n        elif x == \"af'\":\n            result = result.union([\"a'\", \"f'\"])\n        elif is_16bit_register(x):  # Must be a 16bit reg or we have an internal error!\n            result = result.union([LO16(x), HI16(x)])\n\n    return list(result)", "response": "Given a list of single registers returns a list of single registers."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the list of 8 - bit registers that can be used by an asm instruction to return a result.", "response": "def result(i):\n    \"\"\" Returns which 8-bit registers are used by an asm\n    instruction to return a result.\n    \"\"\"\n    ins = inst(i)\n    op = oper(i)\n\n    if ins in ('or', 'and') and op == ['a']:\n        return ['f']\n\n    if ins in {'xor', 'or', 'and', 'neg', 'cpl', 'daa', 'rld', 'rrd', 'rra', 'rla', 'rrca', 'rlca'}:\n        return ['a', 'f']\n\n    if ins in {'bit', 'cp', 'scf', 'ccf'}:\n        return ['f']\n\n    if ins in {'sub', 'add', 'sbc', 'adc'}:\n        if len(op) == 1:\n            return ['a', 'f']\n        else:\n            return single_registers(op[0]) + ['f']\n\n    if ins == 'djnz':\n        return ['b', 'f']\n\n    if ins in {'ldir', 'ldi', 'lddr', 'ldd'}:\n        return ['f', 'b', 'c', 'd', 'e', 'h', 'l']\n\n    if ins in {'cpi', 'cpir', 'cpd', 'cpdr'}:\n        return ['f', 'b', 'c', 'h', 'l']\n\n    if ins in ('pop', 'ld'):\n        return single_registers(op[0])\n\n    if ins in {'inc', 'dec', 'sbc', 'rr', 'rl', 'rrc', 'rlc'}:\n        return ['f'] + single_registers(op[0])\n\n    if ins in ('set', 'res'):\n        return single_registers(op[1])\n\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef block_partition(block, i):\n    i += 1\n    new_block = BasicBlock(block.asm[i:])\n    block.mem = block.mem[:i]\n    block.asm = block.asm[:i]\n    block.update_labels()\n    new_block.update_labels()\n\n    new_block.goes_to = block.goes_to\n    block.goes_to = IdentitySet()\n\n    new_block.label_goes = block.label_goes\n    block.label_goes = []\n\n    new_block.next = new_block.original_next = block.original_next\n    new_block.prev = block\n    new_block.add_comes_from(block)\n\n    if new_block.next is not None:\n        new_block.next.prev = new_block\n        new_block.next.add_comes_from(new_block)\n        new_block.next.delete_from(block)\n\n    block.next = block.original_next = new_block\n    block.update_next_block()\n    block.add_goes_to(new_block)\n\n    return block, new_block", "response": "Partition a basic block into two blocks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef partition_block(block):\n    result = [block]\n\n    if not block.is_partitionable:\n        return result\n\n    EDP = END_PROGRAM_LABEL + ':'\n\n    for i in range(len(block) - 1):\n        if i and block.asm[i] == EDP:  # END_PROGRAM label always starts a basic block\n            block, new_block = block_partition(block, i - 1)\n            LABELS[END_PROGRAM_LABEL].basic_block = new_block\n            result.extend(partition_block(new_block))\n            return result\n\n        if block.mem[i].is_ender:\n            block, new_block = block_partition(block, i)\n            result.extend(partition_block(new_block))\n            op = block.mem[i].opers\n\n            for l in op:\n                if l in LABELS.keys():\n                    JUMP_LABELS.add(l)\n                    block.label_goes += [l]\n            return result\n\n        if block.asm[i] in arch.zx48k.backend.ASMS:\n            if i > 0:\n                block, new_block = block_partition(block, i - 1)\n                result.extend(partition_block(new_block))\n                return result\n\n            block, new_block = block_partition(block, i)\n            result.extend(partition_block(new_block))\n            return result\n\n    for label in JUMP_LABELS:\n        must_partition = False\n        if LABELS[label].basic_block is block:\n            for i in range(len(block)):\n                cell = block.mem[i]\n                if cell.inst == label:\n                    break\n\n                if cell.is_label:\n                    continue\n\n                if cell.is_ender:\n                    continue\n\n                must_partition = True\n\n            if must_partition:\n                block, new_block = block_partition(block, i - 1)\n                LABELS[label].basic_block = new_block\n                result.extend(partition_block(new_block))\n                return result\n\n    return result", "response": "Partition a block into a list of blocks with the same block."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all the labels in the global label table.", "response": "def get_labels(MEMORY, basic_block):\n    \"\"\" Traverses memory, to annotate all the labels in the global\n    LABELS table\n    \"\"\"\n    for cell in MEMORY:\n        if cell.is_label:\n            label = cell.inst\n            LABELS[label] = LabelInfo(label, cell.addr, basic_block)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the global memory array with the given one", "response": "def initialize_memory(basic_block):\n    \"\"\" Initializes global memory array with the given one\n    \"\"\"\n    global MEMORY\n\n    MEMORY = basic_block.mem\n    get_labels(MEMORY, basic_block)\n    basic_block.mem = MEMORY"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclean up initial memory.", "response": "def cleanupmem(initial_memory):\n    \"\"\" Cleans up initial memory. Each label must be\n    ALONE. Each instruction must have an space, etc...\n    \"\"\"\n    i = 0\n    while i < len(initial_memory):\n        tmp = initial_memory[i]\n        match = RE_LABEL.match(tmp)\n        if not match:\n            i += 1\n            continue\n\n        if tmp.rstrip() == match.group():\n            i += 1\n            continue\n\n        initial_memory[i] = tmp[match.end():]\n        initial_memory.insert(i, match.group())\n        i += 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cleanup_local_labels(block):\n    global PROC_COUNTER\n\n    stack = [[]]\n    hashes = [{}]\n    stackprc = [PROC_COUNTER]\n    used = [{}]  # List of hashes of unresolved labels per scope\n\n    MEMORY = block.mem\n\n    for cell in MEMORY:\n        if cell.inst.upper() == 'PROC':\n            stack += [[]]\n            hashes += [{}]\n            stackprc += [PROC_COUNTER]\n            used += [{}]\n            PROC_COUNTER += 1\n            continue\n\n        if cell.inst.upper() == 'ENDP':\n            if len(stack) > 1:  # There might be unbalanced stack due to syntax errors\n                for label in used[-1].keys():\n                    if label in stack[-1]:\n                        newlabel = hashes[-1][label]\n                        for cell in used[-1][label]:\n                            cell.replace_label(label, newlabel)\n\n                stack.pop()\n                hashes.pop()\n                stackprc.pop()\n                used.pop()\n            continue\n\n        tmp = cell.asm.strip()\n        if tmp.upper()[:5] == 'LOCAL':\n            tmp = tmp[5:].split(',')\n            for lbl in tmp:\n                lbl = lbl.strip()\n                if lbl in stack[-1]:\n                    continue\n                stack[-1] += [lbl]\n                hashes[-1][lbl] = 'PROC%i.' % stackprc[-1] + lbl\n                if used[-1].get(lbl, None) is None:\n                    used[-1][lbl] = []\n\n            cell.asm = ';' + cell.asm  # Remove it\n            continue\n\n        if cell.is_label:\n            label = cell.inst\n            for i in range(len(stack) - 1, -1, -1):\n                if label in stack[i]:\n                    label = hashes[i][label]\n                    cell.asm = label + ':'\n                    break\n            continue\n\n        for label in cell.used_labels:\n            labelUsed = False\n            for i in range(len(stack) - 1, -1, -1):\n                if label in stack[i]:\n                    newlabel = hashes[i][label]\n                    cell.replace_label(label, newlabel)\n                    labelUsed = True\n                    break\n\n            if not labelUsed:\n                if used[-1].get(label, None) is None:\n                    used[-1][label] = []\n\n                used[-1][label] += [cell]\n\n    for i in range(len(MEMORY) - 1, -1, -1):\n        if MEMORY[i].asm[0] == ';':\n            MEMORY.pop(i)\n\n    block.mem = MEMORY\n    block.asm = [x.asm for x in MEMORY if len(x.asm.strip())]", "response": "Removes any local labels from the block and returns a unique version of the block."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef optimize(initial_memory):\n    global BLOCKS\n    global PROC_COUNTER\n\n    LABELS.clear()\n    JUMP_LABELS.clear()\n    del MEMORY[:]\n    PROC_COUNTER = 0\n\n    cleanupmem(initial_memory)\n    if OPTIONS.optimization.value <= 2:\n        return '\\n'.join(x for x in initial_memory if not RE_PRAGMA.match(x))\n\n    optimize_init()\n    bb = BasicBlock(initial_memory)\n    cleanup_local_labels(bb)\n    initialize_memory(bb)\n\n    BLOCKS = basic_blocks = get_basic_blocks(bb)  # 1st partition the Basic Blocks\n\n    for x in basic_blocks:\n        x.clean_up_comes_from()\n        x.clean_up_goes_to()\n\n    for x in basic_blocks:\n        x.update_goes_and_comes()\n\n    LABELS['*START*'].basic_block.add_goes_to(basic_blocks[0])\n    LABELS['*START*'].basic_block.next = basic_blocks[0]\n\n    basic_blocks[0].prev = LABELS['*START*'].basic_block\n    LABELS[END_PROGRAM_LABEL].basic_block.add_goes_to(LABELS['*__END_PROGRAM*'].basic_block)\n\n    for x in basic_blocks:\n        x.optimize()\n\n    for x in basic_blocks:\n        if x.comes_from == [] and len([y for y in JUMP_LABELS if x is LABELS[y].basic_block]):\n            x.ignored = True\n\n    return '\\n'.join([y for y in flatten_list([x.asm for x in basic_blocks if not x.ignored])\n                      if not RE_PRAGMA.match(y)])", "response": "This will remove useless instructions from the memory and return a string of the resulting basic blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresets the flags to an unknown state", "response": "def reset_flags(self):\n        \"\"\" Resets flags to an \"unknown state\"\n        \"\"\"\n        self.C = None\n        self.Z = None\n        self.P = None\n        self.S = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, r):\n        if r is None:\n            return None\n\n        if r.lower() == '(sp)' and self.stack:\n            return self.stack[-1]\n\n        if r[:1] == '(':\n            return self.mem[r[1:-1]]\n\n        r = r.lower()\n        if is_number(r):\n            return str(valnum(r))\n\n        if not is_register(r):\n            return None\n\n        return self.regs[r]", "response": "Returns the precomputed value of the given expression\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nliking get but returns the <int > value.", "response": "def getv(self, r):\n        \"\"\" Like the above, but returns the <int> value.\n        \"\"\"\n        v = self.get(r)\n        if not is_unknown(v):\n            try:\n                v = int(v)\n            except ValueError:\n                v = None\n        else:\n            v = None\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef eq(self, r1, r2):\n        if not is_register(r1) or not is_register(r2):\n            return False\n\n        if self.regs[r1] is None or self.regs[r2] is None:  # HINT: This's been never USED??\n            return False\n\n        return self.regs[r1] == self.regs[r2]", "response": "True if values of r1 and r2 registers are equal"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inc(self, r):\n        self.set_flag(None)\n\n        if not is_register(r):\n            if r[0] == '(':  # a memory position, basically: inc(hl)\n                r_ = r[1:-1].strip()\n                v_ = self.getv(self.mem.get(r_, None))\n                if v_ is not None:\n                    v_ = (v_ + 1) & 0xFF\n                    self.mem[r_] = str(v_)\n                    self.Z = int(v_ == 0)  # HINT: This might be improved\n                else:\n                    self.mem[r_] = new_tmp_val()\n            return\n\n        if self.getv(r) is not None:\n            self.set(r, self.getv(r) + 1)\n        else:\n            self.set(r, None)", "response": "Does inc on the register and precomputes flags\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndoing a ROTATION to the RIGHT |>>", "response": "def rrc(self, r):\n        \"\"\" Does a ROTATION to the RIGHT |>>\n        \"\"\"\n        if not is_number(self.regs[r]):\n            self.set(r, None)\n            self.set_flag(None)\n            return\n\n        v_ = self.getv(self.regs[r]) & 0xFF\n        self.regs[r] = str((v_ >> 1) | ((v_ & 1) << 7))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rr(self, r):\n        if self.C is None or not is_number(self.regs[r]):\n            self.set(r, None)\n            self.set_flag(None)\n            return\n\n        self.rrc(r)\n        tmp = self.C\n        v_ = self.getv(self.regs[r])\n        self.C = v_ >> 7\n        self.regs[r] = str((v_ & 0x7F) | (tmp << 7))", "response": "Like the above bus uses carry\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndoing a ROTATION to the LEFT <<|", "response": "def rlc(self, r):\n        \"\"\" Does a ROTATION to the LEFT <<|\n        \"\"\"\n        if not is_number(self.regs[r]):\n            self.set(r, None)\n            self.set_flag(None)\n            return\n\n        v_ = self.getv(self.regs[r]) & 0xFF\n        self.set(r, ((v_ << 1) & 0xFF) | (v_ >> 7))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nliking the above bus uses carry", "response": "def rl(self, r):\n        \"\"\" Like the above, bus uses carry\n        \"\"\"\n        if self.C is None or not is_number(self.regs[r]):\n            self.set(r, None)\n            self.set_flag(None)\n            return\n\n        self.rlc(r)\n        tmp = self.C\n        v_ = self.getv(self.regs[r])\n        self.C = v_ & 1\n        self.regs[r] = str((v_ & 0xFE) | tmp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrue if value of r is val.", "response": "def _is(self, r, val):\n        \"\"\" True if value of r is val.\n        \"\"\"\n        if not is_register(r) or val is None:\n            return False\n\n        r = r.lower()\n        if is_register(val):\n            return self.eq(r, val)\n\n        if is_number(val):\n            val = str(valnum(val))\n        else:\n            val = str(val)\n\n        if val[0] == '(':\n            val = self.mem[val[1:-1]]\n\n        return self.regs[r] == val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the registers values with the given instruction.", "response": "def op(self, i, o):\n        \"\"\" Tries to update the registers values with the given\n        instruction.\n        \"\"\"\n        for ii in range(len(o)):\n            if is_register(o[ii]):\n                o[ii] = o[ii].lower()\n\n        if i == 'ld':\n            self.set(o[0], o[1])\n            return\n\n        if i == 'push':\n            if valnum(self.regs['sp']):\n                self.set('sp', (self.getv(self.regs['sp']) - 2) % 0xFFFF)\n            else:\n                self.set('sp', None)\n            self.stack.append(self.regs[o[0]])\n            return\n\n        if i == 'pop':\n            self.set(o[0], self.stack and self.stack.pop() or None)\n            if valnum(self.regs['sp']):\n                self.set('sp', (self.getv(self.regs['sp']) + 2) % 0xFFFF)\n            else:\n                self.set('sp', None)\n            return\n\n        if i == 'inc':\n            self.inc(o[0])\n            return\n\n        if i == 'dec':\n            self.dec(o[0])\n            return\n\n        if i == 'rra':\n            self.rr('a')\n            return\n        if i == 'rla':\n            self.rl('a')\n            return\n        if i == 'rlca':\n            self.rlc('a')\n            return\n        if i == 'rrca':\n            self.rrc('a')\n            return\n        if i == 'rr':\n            self.rr(o[0])\n            return\n        if i == 'rl':\n            self.rl(o[0])\n            return\n\n        if i == 'exx':\n            tmp = self.regs['bc']\n            self.set('bc', \"bc'\")\n            self.set(\"bc'\", tmp)\n            tmp = self.regs['de']\n            self.set('de', \"de'\")\n            self.set(\"de'\", tmp)\n            tmp = self.regs['hl']\n            self.set('hl', \"hl'\")\n            self.set(\"hl'\", tmp)\n            return\n\n        if i == 'ex':\n            tmp = self.get(o[1])\n            self.set(o[1], o[0])\n            self.set(o[0], tmp)\n            return\n\n        if i == 'xor':\n            self.C = 0\n\n            if o[0] == 'a':\n                self.set('a', 0)\n                self.Z = 1\n                return\n\n            if self.getv('a') is None or self.getv(o[0]) is None:\n                self.Z = None\n                self.set('a', None)\n                return\n\n            self.set('a', self.getv('a') ^ self.getv(o[0]))\n            self.Z = int(self.get('a') == 0)\n            return\n\n        if i in ('or', 'and'):\n            self.C = 0\n\n            if self.getv('a') is None or self.getv(o[0]) is None:\n                self.Z = None\n                self.set('a', None)\n                return\n\n            if i == 'or':\n                self.set('a', self.getv('a') | self.getv(o[0]))\n            else:\n                self.set('a', self.getv('a') & self.getv(o[0]))\n\n            self.Z = int(self.get('a') == 0)\n            return\n\n        if i in ('adc', 'sbc'):\n            if len(o) == 1:\n                o = ['a', o[0]]\n\n            if self.C is None:\n                self.set(o[0], 'None')\n                self.Z = None\n                self.set(o[0], None)\n                return\n\n            if i == 'sbc' and o[0] == o[1]:\n                self.Z = int(not self.C)\n                self.set(o[0], -self.C)\n                return\n\n            if self.getv(o[0]) is None or self.getv(o[1]) is None:\n                self.set_flag(None)\n                self.set(o[0], None)\n                return\n\n            if i == 'adc':\n                val = self.getv(o[0]) + self.getv(o[1]) + self.C\n                if is_8bit_register(o[0]):\n                    self.C = int(val > 0xFF)\n                else:\n                    self.C = int(val > 0xFFFF)\n                self.set(o[0], val)\n                return\n\n            val = self.getv(o[0]) - self.getv(o[1]) - self.C\n            self.C = int(val < 0)\n            self.Z = int(val == 0)\n            self.set(o[0], val)\n            return\n\n        if i in ('add', 'sub'):\n            if len(o) == 1:\n                o = ['a', o[0]]\n\n            if i == 'sub' and o[0] == o[1]:\n                self.Z = 1\n                self.C = 0\n                self.set(o[0], 0)\n                return\n\n            if not is_number(self.get(o[0])) or not is_number(self.get(o[1])) is None:\n                self.set_flag(None)\n                self.set(o[0], None)\n                return\n\n            if i == 'add':\n                val = self.getv(o[0]) + self.getv(o[1])\n                if is_8bit_register(o[0]):\n                    self.C = int(val > 0xFF)\n                    val &= 0xFF\n                    self.Z = int(val == 0)\n                    self.S = val >> 7\n                else:\n                    self.C = int(val > 0xFFFF)\n                    val &= 0xFFFF\n\n                self.set(o[0], val)\n                return\n\n            val = self.getv(o[0]) - self.getv(o[1])\n            if is_8bit_register(o[0]):\n                self.C = int(val < 0)\n                val &= 0xFF\n                self.Z = int(val == 0)\n                self.S = val >> 7\n            else:\n                self.C = int(val < 0)\n                val &= 0xFFFF\n\n            self.set(o[0], val)\n            return\n\n        if i == 'neg':\n            if self.getv('a') is None:\n                self.set_flag(None)\n                return\n\n            val = -self.getv('a')\n            self.set('a', val)\n            self.Z = int(not val)\n            val &= 0xFF\n            self.S = val >> 7\n            return\n\n        if i == 'scf':\n            self.C = 1\n            return\n\n        if i == 'ccf':\n            if self.C is not None:\n                self.C = int(not self.C)\n            return\n\n        if i == 'cpl':\n            if self.getv('a') is None:\n                return\n\n            self.set('a', 0xFF ^ self.getv('a'))\n            return\n\n        # Unknown. Resets ALL\n        self.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef opers(self):\n        i = [x for x in self.asm.strip(' \\t\\n').split(' ') if x != '']\n\n        if len(i) == 1:\n            return []\n\n        i = ''.join(i[1:]).split(',')\n        if self.condition_flag is not None:\n            i = i[1:]\n        else:\n            i = i[0:]\n\n        op = [x.lower() if is_register(x) else x for x in i]\n        return op", "response": "Returns a list of operators this mnemonic uses\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef destroys(self):\n\n        if self.asm in arch.zx48k.backend.ASMS:\n            return ALL_REGS\n\n        res = set([])\n        i = self.inst\n        o = self.opers\n\n        if i in {'push', 'ret', 'call', 'rst', 'reti', 'retn'}:\n            return ['sp']\n\n        if i == 'pop':\n            res.update('sp', single_registers(o[:1]))\n        elif i in {'ldi', 'ldir', 'ldd', 'lddr'}:\n            res.update('a', 'b', 'c', 'd', 'e', 'f')\n        elif i in {'otir', 'otdr', 'oti', 'otd', 'inir', 'indr', 'ini', 'ind'}:\n            res.update('h', 'l', 'b')\n        elif i in {'cpir', 'cpi', 'cpdr', 'cpd'}:\n            res.update('h', 'l', 'b', 'c', 'f')\n        elif i in ('ld', 'in'):\n            res.update(single_registers(o[:1]))\n        elif i in ('inc', 'dec'):\n            res.update('f', single_registers(o[:1]))\n        elif i == 'exx':\n            res.update('b', 'c', 'd', 'e', 'h', 'l')\n        elif i == 'ex':\n            res.update(single_registers(o[0]))\n            res.update(single_registers(o[1]))\n        elif i in {'ccf', 'scf', 'bit', 'cp'}:\n            res.add('f')\n        elif i in {'or', 'and', 'xor', 'add', 'adc', 'sub', 'sbc'}:\n            if len(o) > 1:\n                res.update(single_registers(o[0]))\n            else:\n                res.add('a')\n            res.add('f')\n        elif i in {'neg', 'cpl', 'daa', 'rra', 'rla', 'rrca', 'rlca', 'rrd', 'rld'}:\n            res.update('a', 'f')\n        elif i == 'djnz':\n            res.update('b', 'f')\n        elif i in {'rr', 'rl', 'rrc', 'rlc', 'srl', 'sra', 'sll', 'sla'}:\n            res.update(single_registers(o[0]))\n            res.add('f')\n        elif i in ('set', 'res'):\n            res.update(single_registers(o[1]))\n\n        return list(res)", "response": "Returns a list of all the destroys for the current entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the set of registers operands etc. required by an instruction.", "response": "def requires(self):\n        \"\"\" Returns the registers, operands, etc. required by an instruction.\n        \"\"\"\n        if self.asm in arch.zx48k.backend.ASMS:\n            return ALL_REGS\n\n        if self.inst == '#pragma':\n            tmp = self.__instr.split(' ')[1:]\n            if tmp[0] != 'opt':\n                return\n            if tmp[1] == 'require':\n                return set(flatten_list([single_registers(x.strip(', \\t\\r')) for x in tmp[2:]]))\n\n            return set([])\n\n        result = set([])\n        i = self.inst\n        o = [x.lower() for x in self.opers]\n\n        if i in ['ret', 'pop', 'push']:\n            result.add('sp')\n\n        if self.condition_flag is not None or i in ['sbc', 'adc']:\n            result.add('f')\n\n        for O in o:\n            if '(hl)' in O:\n                result.add('h')\n                result.add('l')\n\n            if '(de)' in O:\n                result.add('d')\n                result.add('e')\n\n            if '(bc)' in O:\n                result.add('b')\n                result.add('c')\n\n            if '(sp)' in O:\n                result.add('sp')\n\n            if '(ix' in O:\n                result.add('ixh')\n                result.add('ixl')\n\n            if '(iy' in O:\n                result.add('iyh')\n                result.add('iyl')\n\n        if i in ['ccf']:\n            result.add('f')\n\n        elif i in {'rra', 'rla', 'rrca', 'rlca'}:\n            result.add('a')\n            result.add('f')\n\n        elif i in ['xor', 'cp']:\n            # XOR A, and CP A don't need the a register\n            if o[0] != 'a':\n                result.add('a')\n\n                if o[0][0] != '(' and not is_number(o[0]):\n                    result = result.union(single_registers(o))\n\n        elif i in ['or', 'and']:\n            # AND A, and OR A do need the a register\n            result.add('a')\n\n            if o[0][0] != '(' and not is_number(o[0]):\n                result = result.union(single_registers(o))\n\n        elif i in {'adc', 'sbc', 'add', 'sub'}:\n            if len(o) == 1:\n                if i not in ('sub', 'sbc') or o[0] != 'a':\n                    # sbc a and sub a dont' need the a register\n                    result.add('a')\n\n                if o[0][0] != '(' and not is_number(o[0]):\n                    result = result.union(single_registers(o))\n            else:\n                if o[0] != o[1] or i in ('add', 'adc'):\n                    # sub HL, HL or sub X, X don't need the X register(s)\n                    result = result.union(single_registers(o))\n\n            if i in ['adc', 'sbc']:\n                result.add('f')\n\n        elif i in {'daa', 'rld', 'rrd', 'neg', 'cpl'}:\n            result.add('a')\n\n        elif i in {'rl', 'rr', 'rlc', 'rrc'}:\n            result = result.union(single_registers(o) + ['f'])\n\n        elif i in {'sla', 'sll', 'sra', 'srl', 'inc', 'dec'}:\n            result = result.union(single_registers(o))\n\n        elif i == 'djnz':\n            result.add('b')\n\n        elif i in {'ldir', 'lddr', 'ldi', 'ldd'}:\n            result = result.union(['b', 'c', 'd', 'e', 'h', 'l'])\n\n        elif i in {'cpi', 'cpd', 'cpir', 'cpdr'}:\n            result = result.union(['a', 'b', 'c', 'h', 'l'])\n\n        elif i == 'ld' and not is_number(o[1]):\n            result = result.union(single_registers(o[1]))\n\n        elif i == 'ex':\n            if o[0] == 'de':\n                result = result.union(['d', 'e', 'h', 'l'])\n            elif o[1] == '(sp)':\n                result = result.union(['h', 'l'])  # sp already included\n            else:\n                result = result.union(['a', 'f', \"a'\", \"f'\"])\n\n        elif i == 'exx':\n            result = result.union(['b', 'c', 'd', 'e', 'h', 'l'])\n\n        elif i == 'push':\n            result = result.union(single_registers(o))\n\n        elif i in {'bit', 'set', 'res'}:\n            result = result.union(single_registers(o[1]))\n\n        elif i == 'out':\n            result.add(o[1])\n            if o[0] == '(c)':\n                result.add('c')\n\n        elif i == 'in':\n            if o[1] == '(c)':\n                result.add('c')\n\n        elif i == 'im':\n            result.add('i')\n\n        result = list(result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning if this instruction affects any of the registers in reglist.", "response": "def affects(self, reglist):\n        \"\"\" Returns if this instruction affects any of the registers\n        in reglist.\n        \"\"\"\n        if isinstance(reglist, str):\n            reglist = [reglist]\n\n        reglist = single_registers(reglist)\n\n        return len([x for x in self.destroys if x in reglist]) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn if this instruction needs any of the registers in reglist.", "response": "def needs(self, reglist):\n        \"\"\" Returns if this instruction need any of the registers\n        in reglist.\n        \"\"\"\n        if isinstance(reglist, str):\n            reglist = [reglist]\n\n        reglist = single_registers(reglist)\n\n        return len([x for x in self.requires if x in reglist]) > 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of required labels for this instruction", "response": "def used_labels(self):\n        \"\"\" Returns a list of required labels for this instruction\n        \"\"\"\n        result = []\n\n        tmp = self.asm.strip(' \\n\\r\\t')\n        if not len(tmp) or tmp[0] in ('#', ';'):\n            return result\n\n        try:\n            tmpLexer = asmlex.lex.lex(object=asmlex.Lexer(), lextab='zxbasmlextab')\n            tmpLexer.input(tmp)\n\n            while True:\n                token = tmpLexer.token()\n                if not token:\n                    break\n\n                if token.type == 'ID':\n                    result += [token.value]\n        except:\n            pass\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_label(self, oldLabel, newLabel):\n        if oldLabel == newLabel:\n            return\n\n        tmp = re.compile(r'\\b' + oldLabel + r'\\b')\n        last = 0\n        l = len(newLabel)\n        while True:\n            match = tmp.search(self.asm[last:])\n            if not match:\n                break\n\n            txt = self.asm\n            self.asm = txt[:last + match.start()] + newLabel + txt[last + match.end():]\n            last += match.start() + l", "response": "Replaces old label with a new one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_partitionable(self):\n        if len(self.mem) < 2:\n            return False  # An atomic block\n\n        if any(x.is_ender or x.asm in arch.zx48k.backend.ASMS for x in self.mem):\n            return True\n\n        for label in JUMP_LABELS:\n            if LABELS[label].basic_block == self and (not self.mem[0].is_label or self.mem[0].inst != label):\n                return True\n\n        return False", "response": "Returns if this block can be partitioned in 2 or more blocks."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the basic_block from the list for the entry in the entry list.", "response": "def delete_from(self, basic_block):\n        \"\"\" Removes the basic_block ptr from the list for \"comes_from\"\n        if it exists. It also sets self.prev to None if it is basic_block.\n        \"\"\"\n        if basic_block is None:\n            return\n\n        if self.lock:\n            return\n\n        self.lock = True\n\n        if self.prev is basic_block:\n            if self.prev.next is self:\n                self.prev.next = None\n            self.prev = None\n\n        for i in range(len(self.comes_from)):\n            if self.comes_from[i] is basic_block:\n                self.comes_from.pop(i)\n                break\n\n        self.lock = False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the basic_block to the comes_from list.", "response": "def add_comes_from(self, basic_block):\n        \"\"\" This simulates a set. Adds the basic_block to the comes_from\n        list if not done already.\n        \"\"\"\n        if basic_block is None:\n            return\n\n        if self.lock:\n            return\n\n        # Return if already added\n        if basic_block in self.comes_from:\n            return\n\n        self.lock = True\n        self.comes_from.add(basic_block)\n        basic_block.add_goes_to(self)\n        self.lock = False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the next basic block and the next sets.", "response": "def update_next_block(self):\n        \"\"\" If the last instruction of this block is a JP, JR or RET (with no\n        conditions) then the next and goes_to sets just contains a\n        single block\n        \"\"\"\n        last = self.mem[-1]\n        if last.inst not in ('ret', 'jp', 'jr') or last.condition_flag is not None:\n            return\n\n        if last.inst == 'ret':\n            if self.next is not None:\n                self.next.delete_from(self)\n                self.delete_goes(self.next)\n            return\n\n        if last.opers[0] not in LABELS.keys():\n            __DEBUG__(\"INFO: %s is not defined. No optimization is done.\" % last.opers[0], 2)\n            LABELS[last.opers[0]] = LabelInfo(last.opers[0], 0, DummyBasicBlock(ALL_REGS, ALL_REGS))\n\n        n_block = LABELS[last.opers[0]].basic_block\n        if self.next is n_block:\n            return\n\n        if self.next.prev == self:\n            # The next basic block is not this one since it ends with a jump\n            self.next.delete_from(self)\n            self.delete_goes(self.next)\n\n        self.next = n_block\n        self.next.add_comes_from(self)\n        self.add_goes_to(self.next)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the goes_to and comes_from sets of the receivers.", "response": "def update_goes_and_comes(self):\n        \"\"\" Once the block is a Basic one, check the last instruction and updates\n        goes_to and comes_from set of the receivers.\n        Note: jp, jr and ret are already done in update_next_block()\n        \"\"\"\n        # Remove any block from the comes_from and goes_to list except the PREVIOUS and NEXT\n        if not len(self):\n            return\n\n        if self.mem[-1].inst == 'ret':\n            return  # subroutine returns are updated from CALLer blocks\n\n        self.update_used_by_list()\n\n        if not self.mem[-1].is_ender:\n            return\n\n        last = self.mem[-1]\n        inst = last.inst\n        oper = last.opers\n        cond = last.condition_flag\n\n        if oper and oper[0] not in LABELS.keys():\n            __DEBUG__(\"INFO: %s is not defined. No optimization is done.\" % oper[0], 1)\n            LABELS[oper[0]] = LabelInfo(oper[0], 0, DummyBasicBlock(ALL_REGS, ALL_REGS))\n\n        if inst == 'djnz' or inst in ('jp', 'jr') and cond is not None:\n            if oper[0] in LABELS.keys():\n                self.add_goes_to(LABELS[oper[0]].basic_block)\n\n        elif inst in ('jp', 'jr') and cond is None:\n            if oper[0] in LABELS.keys():\n                self.delete_goes(self.next)\n                self.next = LABELS[oper[0]].basic_block\n                self.add_goes_to(self.next)\n\n        elif inst == 'call':\n            LABELS[oper[0]].basic_block.add_comes_from(self)\n            stack = [LABELS[oper[0]].basic_block]\n            bbset = IdentitySet()\n\n            while stack:\n                bb = stack.pop(0)\n\n                while bb is not None:\n                    if bb in bbset:\n                        break\n\n                    bbset.add(bb)\n                    if len(bb):\n                        bb1 = bb[-1]\n                        if bb1.inst == 'ret':\n                            bb.add_goes_to(self.next)\n                            if bb1.condition_flag is None:  # 'ret'\n                                break\n\n                        if bb1.inst in ('jp', 'jr') and bb1.condition_flag is not None:  # jp/jr nc/nz/.. LABEL\n                            if bb1.opers[0] in LABELS:  # some labels does not exist (e.g. immediate numeric addresses)\n                                stack += [LABELS[bb1.opers[0]].basic_block]\n\n                    bb = bb.next  # next contiguous block\n\n            if cond is None:\n                self.calls.add(LABELS[oper[0]].basic_block)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck whether any of the given regs are required from the given point to the end or not.", "response": "def is_used(self, regs, i, top=None):\n        \"\"\" Checks whether any of the given regs are required from the given point\n        to the end or not.\n        \"\"\"\n        if i < 0:\n            i = 0\n\n        if self.lock:\n            return True\n\n        regs = list(regs)  # make a copy\n        if top is None:\n            top = len(self)\n        else:\n            top -= 1\n\n        for ii in range(i, top):\n            for r in self.mem[ii].requires:\n                if r in regs:\n                    return True\n\n            for r in self.mem[ii].destroys:\n                if r in regs:\n                    regs.remove(r)\n\n            if not regs:\n                return False\n\n        self.lock = True\n        result = self.goes_requires(regs)\n        self.lock = False\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a list of registers returns a list of them that are safe to write from the given index until the given end_.", "response": "def safe_to_write(self, regs, i=0, end_=0):\n        \"\"\" Given a list of registers (8 or 16 bits) returns a list of them\n        that are safe to modify from the given index until the position given\n        which, if omitted, defaults to the end of the block.\n        :param regs: register or iterable of registers (8 or 16 bit one)\n        :param i: initial position of the block to examine\n        :param end_: final position to examine\n        :returns: registers safe to write\n        \"\"\"\n        if is_register(regs):\n            regs = set(single_registers(regs))\n        else:\n            regs = set(single_registers(x) for x in regs)\n        return not regs.intersection(self.requires(i, end_))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of registers and variables that this block requires. By default checks from the beginning.", "response": "def requires(self, i=0, end_=None):\n        \"\"\" Returns a list of registers and variables this block requires.\n        By default checks from the beginning (i = 0).\n        :param i: initial position of the block to examine\n        :param end_: final position to examine\n        :returns: registers safe to write\n        \"\"\"\n        if i < 0:\n            i = 0\n        end_ = len(self) if end_ is None or end_ > len(self) else end_\n        regs = {'a', 'b', 'c', 'd', 'e', 'f', 'h', 'l', 'i', 'ixh', 'ixl', 'iyh', 'iyl', 'sp'}\n        result = []\n\n        for ii in range(i, end_):\n            for r in self.mem[ii].requires:\n                r = r.lower()\n                if r in regs:\n                    result.append(r)\n                    regs.remove(r)\n\n            for r in self.mem[ii].destroys:\n                r = r.lower()\n                if r in regs:\n                    regs.remove(r)\n\n            if not regs:\n                break\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef destroys(self, i=0):\n        regs = {'a', 'b', 'c', 'd', 'e', 'f', 'h', 'l', 'i', 'ixh', 'ixl', 'iyh', 'iyl', 'sp'}\n        top = len(self)\n        result = []\n\n        for ii in range(i, top):\n            for r in self.mem[ii].destroys:\n                if r in regs:\n                    result.append(r)\n                    regs.remove(r)\n\n            if not regs:\n                break\n\n        return result", "response": "Returns a list of registers this block destroys by default checks from the beginning."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef swap(self, a, b):\n        self.mem[a], self.mem[b] = self.mem[b], self.mem[a]\n        self.asm[a], self.asm[b] = self.asm[b], self.asm[a]", "response": "Swaps the memory positions a and b."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef goes_requires(self, regs):\n        if len(self) and self.mem[-1].inst == 'call' and self.mem[-1].condition_flag is None:\n            for block in self.calls:\n                if block.is_used(regs, 0):\n                    return True\n\n                d = block.destroys()\n                if not len([x for x in regs if x not in d]):\n                    return False  # If all registers are destroyed then they're not used\n\n        for block in self.goes_to:\n            if block.is_used(regs, 0):\n                return True\n\n        return False", "response": "Returns True if any of the goes_to blocks requires any of the given registers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_label_idx(self, label):\n        for i in range(len(self)):\n            if self.mem[i].is_label and self.mem[i].inst == label:\n                return i\n\n        return None", "response": "Returns the index of a label. Returns None if the label is not found."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_first_non_label_instruction(self):\n        for i in range(len(self)):\n            if not self.mem[i].is_label:\n                return self.mem[i]\n\n        return None", "response": "Returns the first non - label instruction in the block."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to detect peep - hole patterns in this basic block and remove them.", "response": "def optimize(self):\n        \"\"\" Tries to detect peep-hole patterns in this basic block\n        and remove them.\n        \"\"\"\n        changed = OPTIONS.optimization.value > 2  # only with -O3 will enter here\n\n        while changed:\n            changed = False\n            regs = Registers()\n\n            if len(self) and self[-1].inst in ('jp', 'jr') and \\\n                    self.original_next is LABELS[self[-1].opers[0]].basic_block:\n                # { jp Label ; Label: ; ... } => { Label: ; ... }\n                LABELS[self[-1].opers[0]].used_by.remove(self)\n                self.pop(len(self) - 1)\n                changed = True\n                continue\n\n            for i in range(len(self)):\n                try:\n                    if self.mem[i].is_label:\n                        # ignore labels\n                        continue\n                except IndexError:\n                    print(i)\n                    print('\\n'.join(str(x) for x in self.mem))\n                    raise\n\n                i1 = self.mem[i].inst\n                o1 = self.mem[i].opers\n\n                if i > 0:\n                    i0 = self.mem[i - 1].inst\n                    o0 = self.mem[i - 1].opers\n                else:\n                    i0 = o0 = None\n\n                if i < len(self) - 1:\n                    i2 = self.mem[i + 1].inst\n                    o2 = self.mem[i + 1].opers\n                else:\n                    i2 = o2 = None\n\n                if i < len(self) - 2:\n                    i3 = self.mem[i + 2].inst\n                    o3 = self.mem[i + 2].opers\n                else:\n                    i3 = o3 = None\n\n                if i1 == 'ld':\n                    if OPT00 and o1[0] == o1[1]:\n                        # { LD X, X } => {}\n                        self.pop(i)\n                        changed = True\n                        break\n\n                    if OPT01 and o0 == 'ld' and o0[0] == o1[1] and o1[0] == o0[1]:\n                        # { LD A, X; LD X, A} => {LD A, X}\n                        self.pop(i)\n                        changed = True\n                        break\n\n                    if OPT02 and i0 == i1 == 'ld' and o0[1] == o1[1] and \\\n                            is_register(o0[0]) and is_register(o1[0]) and not is_16bit_idx_register(o1[0]):\n                        if is_8bit_register(o1[0]):\n                            if not is_8bit_register(o1[1]):\n                                # { LD r1, N; LD r2, N} => {LD r1, N; LD r2, r1}\n                                changed = True\n                                self[i] = 'ld %s, %s' % (o1[0], o0[0])\n                                break\n                        else:\n                            changed = True\n                            # {LD r1, NN; LD r2, NN} => { LD r1, NN; LD r2H, r1H; LD r2L, r1L}\n                            self[i] = 'ld %s, %s' % (HI16(o1[0]), HI16(o0[0]))\n                            self.insert(i + 1, 'ld %s, %s' % (LO16(o1[0]), LO16(o0[0])))\n                            break\n\n                    if OPT03 and is_register(o1[0]) and o1[0] != 'sp' and \\\n                            not self.is_used(single_registers(o1[0]), i + 1):\n                        # LD X, nnn ; X not used later => Remove instruction\n                        tmp = str(self.asm)\n                        self.pop(i)\n                        changed = True\n                        __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                        break\n\n                    if OPT04 and o1 == ['h', 'a'] and i2 == 'ld' and o2[0] == 'a' \\\n                            and i3 == 'sub' and o3[0] == 'h' and not self.is_used('h', i + 3):\n                        if is_number(o2[1]):\n                            self[i] = 'neg'\n                            self[i + 1] = 'add a, %s' % o2[1]\n                            self[i + 2] = 'ccf'\n                            changed = True\n                            break\n\n                    if OPT05 and regs._is(o1[0], o1[1]):  # and regs.get(o1[0])[0:3] != '(ix':\n                        tmp = str(self.asm)\n                        self.pop(i)\n                        changed = True\n                        __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                        break\n\n                    if OPT06 and o1[0] in ('hl', 'de') and \\\n                            i2 == 'ex' and o2[0] == 'de' and o2[1] == 'hl' and \\\n                            not self.is_used(single_registers(o1[0]), i + 2):\n                        # { LD HL, XX ; EX DE, HL; POP HL } ::= { LD DE, XX ; POP HL }\n                        reg = 'de' if o1[0] == 'hl' else 'hl'\n                        self.pop(i + 1)\n                        self[i] = 'ld %s, %s' % (reg, o1[1])\n                        changed = True\n                        break\n\n                    if OPT07 and i0 == 'ld' and i2 == 'ld' and o2[1] == 'hl' and not self.is_used(['h', 'l'], i + 2) \\\n                            and (o0[0] == 'h' and o0[1] == 'b' and o1[0] == 'l' and o1[1] == 'c' or\n                                 o0[0] == 'l' and o0[1] == 'c' and o1[0] == 'h' and o1[1] == 'b' or\n                                 o0[0] == 'h' and o0[1] == 'd' and o1[0] == 'l' and o1[1] == 'e' or\n                                 o0[0] == 'l' and o0[1] == 'e' and o1[0] == 'h' and o1[1] == 'd'):\n                        # { LD h, rH ; LD l, rl ; LD (XX), HL } ::= { LD (XX), R }\n                        tmp = str(self.asm)\n                        r2 = 'de' if o0[1] in ('d', 'e') else 'bc'\n                        self[i + 1] = 'ld %s, %s' % (o2[0], r2)\n                        self.pop(i)\n                        self.pop(i - 1)\n                        changed = True\n                        __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                        break\n\n                    if OPT08 and i1 == i2 == 'ld' and i > 0 and \\\n                            (o1[1] == 'h' and o1[0] == 'b' and o2[1] == 'l' and o2[0] == 'c' or\n                             o1[1] == 'l' and o1[0] == 'c' and o2[1] == 'h' and o2[0] == 'b' or\n                             o1[1] == 'h' and o1[0] == 'd' and o2[1] == 'l' and o2[0] == 'e' or\n                             o1[1] == 'l' and o1[0] == 'e' and o2[1] == 'h' and o2[\n                             0] == 'd') and \\\n                            regs.get('hl') is not None and not self.is_used(['h', 'l'], i + 2) and \\\n                            not self[i - 1].needs(['h', 'l']) and not self[i - 1].affects(['h', 'l']):\n                        # { LD HL, XXX ; <inst> ; LD rH, H; LD rL, L } ::= { LD HL, XXX ; LD rH, H; LD rL, L; <inst> }\n                        changed = True\n                        tmp = str(self.asm)\n                        self.swap(i - 1, i + 1)\n                        __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                        break\n\n                    if OPT09 and i > 0 and i0 == i1 == i2 == 'ld' and \\\n                            o0[0] == 'hl' and \\\n                            (o1[1] == 'h' and o1[0] == 'b' and o2[1] == 'l' and o2[0] == 'c' or\n                             o1[1] == 'l' and o1[0] == 'c' and o2[1] == 'h' and o2[0] == 'b' or\n                             o1[1] == 'h' and o1[0] == 'd' and o2[1] == 'l' and o2[0] == 'e' or\n                             o1[1] == 'l' and o1[0] == 'e' and o2[1] == 'h' and o2[0] == 'd') and \\\n                            not self.is_used(['h', 'l'], i + 2):\n                        # { LD HL, XXX ;  LD rH, H; LD rL, L } ::= { LD rr, XXX }\n                        changed = True\n                        r1 = 'de' if o1[0] in ('d', 'e') else 'bc'\n                        tmp = str(self.asm)\n                        self[i - 1] = 'ld %s, %s' % (r1, o0[1])\n                        self.pop(i + 1)\n                        self.pop(i)\n                        __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                        break\n\n                if OPT10 and i1 in ('inc', 'dec') and o1[0] == 'a':\n                    if i2 == i0 == 'ld' and o2[0] == o0[1] and 'a' == o0[0] == o2[1] and o0[1][0] == '(':\n                        if not RE_INDIR.match(o2[0]):\n                            if not self.is_used(['a', 'h', 'l'], i + 2):\n                                # { LD A, (X); [ DEC A | INC A ]; LD (X), A} ::= {LD HL, X; [ DEC (HL) | INC (HL) ]}\n                                tmp = str(self.asm)\n                                self.pop(i + 1)\n                                self[i - 1] = 'ld hl, %s' % (o0[1][1:-1])\n                                self[i] = '%s (hl)' % i1\n                                changed = True\n                                __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                                break\n                        else:\n                            if not self.is_used(['a'], i + 2):\n                                # { LD A, (IX + n); [ DEC A | INC A ]; LD (X), A} ::=\n                                # { [ DEC (IX + n) | INC (IX + n) ] }\n                                tmp = str(self.asm)\n                                self.pop(i + 1)\n                                self.pop(i)\n                                self[i - 1] = '%s %s' % (i1, o0[1])\n                                changed = True\n                                __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                                break\n\n                if OPT11 and i0 == 'push' and i3 == 'pop' and o0[0] != o3[0] \\\n                        and o0[0] in ('hl', 'de') and o3[0] in ('hl', 'de') \\\n                        and i1 == i2 == 'ld' and (\n                        o1[0] == HI16(o0[0]) and o2[0] == LO16(o0[0]) and o1[1] == HI16(o3[0]) and\n                        o2[1] == LO16(o3[0]) or\n                        o2[0] == HI16(o0[0]) and o1[0] == LO16(o0[0]) and o2[1] == HI16(\n                        o3[0]) and o1[1] == LO16(o3[0])):\n                    # { PUSH HL; LD H, D; LD L, E; POP HL } ::= {EX DE, HL}\n                    self.pop(i + 2)\n                    self.pop(i + 1)\n                    self.pop(i)\n                    self[i - 1] = 'ex de, hl'\n                    changed = True\n                    break\n\n                if i0 == 'push' and i1 == 'pop':\n                    if OPT12 and o0[0] == o1[0]:\n                        # { PUSH X ; POP X } ::= { }\n                        self.pop(i)\n                        self.pop(i - 1)\n                        changed = True\n                        break\n\n                    if OPT13 and o0[0] in ('de', 'hl') and o1[0] in ('de', 'hl') and not self.is_used(\n                            single_registers(o0[0]), i + 1):\n                        # { PUSH DE ; POP HL } ::= { EX DE, HL }\n                        self.pop(i)\n                        self[i - 1] = 'ex de, hl'\n                        changed = True\n                        break\n\n                    if OPT14 and 'af' in (o0[0], o1[0]):\n                        # { push Xx ; pop af } => { ld a, X }\n                        if not self.is_used(o1[0][1], i + 1):\n                            self[i - 1] = 'ld %s, %s' % (HI16(o1[0]), HI16(o0[0]))\n                            self.pop(i)\n                            changed = True\n                            break\n                    elif OPT15 and not is_16bit_idx_register(o0[0]) and not is_16bit_idx_register(\n                            o1[0]) and 'af' not in (o0[0], o1[0]):\n                        # { push Xx ; pop Yy } => { ld Y, X ; ld y, x }\n                        self[i - 1] = 'ld %s, %s' % (HI16(o1[0]), HI16(o0[0]))\n                        self[i] = 'ld %s, %s' % (LO16(o1[0]), LO16(o0[0]))\n                        changed = True\n                        break\n\n                if OPT16 and i > 0 and not self.mem[i - 1].is_label and i1 == 'pop' and \\\n                        (not self.mem[i - 1].affects([o1[0], 'sp']) or\n                         self.safe_to_write(o1[0], i + 1)) and \\\n                        not self.mem[i - 1].needs([o1[0], 'sp']):\n                    # { <inst>;  POP X } => { POP X; <inst> } ; if inst does not uses X\n                    tmp = str(self.asm)\n                    self.swap(i - 1, i)\n                    changed = True\n                    __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                    break\n\n                if OPT17 and i1 == 'xor' and o1[0] == 'a' and regs._is('a', 0) and regs.Z and not regs.C:\n                    tmp = str(self.asm)\n                    self.pop(i)\n                    __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                    changed = True\n                    break\n\n                if OPT18 and i3 is not None and \\\n                        (i0 == i1 == 'ld' and i2 == i3 == 'push') and \\\n                        (o0[0] == o3[0] == 'de' and o1[0] == o2[0] == 'bc'):  # and \\\n                    if not self.is_used(['h', 'l', 'd', 'e', 'b', 'c'], i + 3):\n                        # { LD DE, (X2) ; LD BC, (X1); PUSH DE; PUSH BC } ::=\n                        # { LD HL, (X2); PUSH HL; LD HL, (X1); PUSH HL }\n                        self[i - 1] = 'ld hl, %s' % o1[1]\n                        self[i] = 'push hl'\n                        self[i + 1] = 'ld hl, %s' % o0[1]\n                        self[i + 2] = 'push hl'\n                        changed = True\n                        break\n\n                if i1 in ('jp', 'jr', 'call') and o1[0] in JUMP_LABELS:\n                    c = self.mem[i].condition_flag\n                    if OPT19 and c is not None:\n                        if c == 'c' and regs.C == 1 or \\\n                                c == 'z' and regs.Z == 1 or \\\n                                c == 'nc' and regs.C == 0 or \\\n                                c == 'nz' and regs.Z == 0:\n                            # If the condition is always satisfied, replace with a simple jump / call\n                            changed = True\n                            tmp = str(self.asm)\n                            self[i] = '%s %s' % (i1, o1[0])\n                            self.update_goes_and_comes()\n                            __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                            break\n\n                    ii = LABELS[o1[0]].basic_block.get_first_non_label_instruction()\n                    ii1 = None if ii is None else ii.inst\n                    cc = None if ii is None else ii.condition_flag\n                    # Are we calling / jumping into another jump?\n                    if OPT20 and ii1 in ('jp', 'jr') and (\n                            cc is None or\n                            cc == c or\n                            cc == 'c' and regs.C == 1 or\n                            cc == 'z' and regs.Z == 1 or\n                            cc == 'nc' and regs.C == 0 or\n                            cc == 'nz' and regs.Z == 0):\n                        if c is None:\n                            c = ''\n                        else:\n                            c = c + ', '\n\n                        changed = True\n                        tmp = str(self.asm)\n                        LABELS[o1[0]].used_by.remove(self)  # This block no longer uses this label\n                        self[i] = '%s %s%s' % (i1, c, ii.opers[0])\n                        self.update_goes_and_comes()\n                        __DEBUG__('Changed %s ==> %s' % (tmp, self.asm), 2)\n                        break\n\n                if OPT22 and i0 == 'sbc' and o0[0] == o0[1] == 'a' and \\\n                        i1 == 'or' and o1[0] == 'a' and \\\n                        i2 == 'jp' and \\\n                        self[i + 1].condition_flag is not None and \\\n                        not self.is_used(['a'], i + 2):\n                    c = self.mem[i + 1].condition_flag\n                    if c in ('z', 'nz'):\n                        c = 'c' if c == 'nz' else 'nc'\n                        changed = True\n                        self[i + 1] = 'jp %s, %s' % (c, o2[0])\n                        self.pop(i)\n                        self.pop(i - 1)\n                        break\n\n                if OPT23 and i0 == 'ld' and is_16bit_register(o0[0]) and o0[1][0] == '(' and \\\n                        i1 == 'ld' and o1[0] == 'a' and o1[1] == LO16(o0[0]) and not self.is_used(\n                        single_registers(o0[0]), i + 1):\n                    # { LD HL, (X) ; LD A, L } ::=  { LD A, (X) }\n                    self.pop(i)\n                    self[i - 1] = 'ld a, %s' % o0[1]\n                    changed = True\n                    break\n\n                if OPT24 and i1 == i2 == 'ccf':  # { ccf ; ccf }\u00a0::= {\u00a0}\n                    self.pop(i)\n                    self.pop(i)\n                    changed = True\n                    break\n\n                if OPT25 and i1 == 'ld' and is_register(o1[0]) and o1[0] != 'sp':\n                    is8 = is_8bit_register(o1[0])\n                    ss = [x for x, y in regs.regs.items() if x != o1[0] and y is not None and y == regs.get(o1[1]) and\n                          not is_8bit_register(o1[1])]\n                    for r_ in ss:\n                        if is8 != is_8bit_register(r_):\n                            continue\n                        changed = True\n                        if is8:   # ld A, n; ld B, n => ld A, n; ld B, A\n                            self[i] = 'ld %s, %s' % (o1[0], r_)\n                        else:    # ld HL, n; ld DE, n => ld HL, n; ld d, h; ld e, l\n                            # 16 bit register\n                            self[i] = 'ld %s, %s' % (HI16(o1[0]), HI16(r_))\n                            self.insert(i + 1, 'ld %s, %s' % (LO16(o1[0]), LO16(r_)))\n                        break\n\n                    if changed:\n                        break\n\n                if OPT26 and i1 == i2 == 'ld' and (o1[0], o1[1], o2[0], o2[1]) == ('d', 'h', 'e', 'l') and \\\n                        not self.is_used(['h', 'l'], i + 2):\n                    self[i] = 'ex de, hl'\n                    self.pop(i + 1)\n                    changed = True\n                    break\n\n                if OPT27 and i1 in ('cp', 'or', 'and', 'add', 'adc', 'sub', 'sbc') and o1[-1] != 'a' and \\\n                        not self.is_used(o1[-1], i + 1) and i0 == 'ld' and o0[0] == o1[-1] and \\\n                        (o0[1] == '(hl)' or RE_IXIND.match(o0[1])):\n                    template = '{0} %s{1}' % ('a, ' if i1 in ('add', 'adc', 'sbc') else '')\n                    self[i] = template.format(i1, o0[1])\n                    self.pop(i - 1)\n                    changed = True\n                    break\n\n                regs.op(i1, o1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string representation of the operands in the tree.", "response": "def _str_oper(op1, op2=None, reversed=False, no_exaf=False):\n    ''' Returns pop sequence for 16 bits operands\n    1st operand in HL, 2nd operand in DE\n\n    You can swap operators extraction order\n    by setting reversed to True.\n\n    If no_exaf = True => No bits flags in A' will be used.\n                        This saves two bytes.\n    '''\n    output = []\n\n    if op2 is not None and reversed:\n        op1, op2 = op2, op1\n\n    tmp2 = False\n    if op2 is not None:\n        val = op2\n        if val[0] == '*':\n            indirect = True\n            val = val[1:]\n        else:\n            indirect = False\n\n        if val[0] == '_':  # Direct\n            output.append('ld de, (%s)' % val)\n        elif val[0] == '#':  # Direct\n            output.append('ld de, %s' % val[1:])\n        elif val[0] == '$':  # Direct in the stack\n            output.append('pop de')\n        else:\n            output.append('pop de')\n            tmp2 = True\n\n        if indirect:\n            output.append('call __LOAD_DE_DE')\n            REQUIRES.add('lddede.asm')  # TODO: This is never used??\n\n    if reversed:\n        tmp = output\n        output = []\n\n    val = op1\n    tmp1 = False\n    if val[0] == '*':\n        indirect = True\n        val = val[1:]\n    else:\n        indirect = False\n\n    if val[0] == '_':  # Direct\n        output.append('ld hl, (%s)' % val)\n    elif val[0] == '#':  # Inmmediate\n        output.append('ld hl, %s' % val[1:])\n    elif val[0] == '$':  # Direct in the stack\n        output.append('pop hl')\n    else:\n        output.append('pop hl')\n        tmp1 = True\n\n    if indirect:\n        output.append('ld hl, %s' % val[1:])\n        output.append('ld c, (hl)')\n        output.append('inc hl')\n        output.append('ld h, (hl)')\n        output.append('ld l, c')\n\n    if reversed:\n        output.extend(tmp)\n\n    if not no_exaf:\n        if tmp1 and tmp2:\n            output.append('ld a, 3')  # Marks both strings to be freed\n        elif tmp1:\n            output.append('ld a, 1')  # Marks str1 to be freed\n        elif tmp2:\n            output.append('ld a, 2')  # Marks str2 to be freed\n        else:\n            output.append('xor a')  # Marks no string to be freed\n\n    if op2 is not None:\n        return (tmp1, tmp2, output)\n\n    return (tmp1, output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noutputs a FREEMEM sequence for 1 or 2 ops", "response": "def _free_sequence(tmp1, tmp2=False):\n    ''' Outputs a FREEMEM sequence for 1 or 2 ops\n    '''\n    if not tmp1 and not tmp2:\n        return []\n\n    output = []\n    if tmp1 and tmp2:\n        output.append('pop de')\n        output.append('ex (sp), hl')\n        output.append('push de')\n        output.append('call __MEM_FREE')\n        output.append('pop hl')\n        output.append('call __MEM_FREE')\n    else:\n        output.append('ex (sp), hl')\n        output.append('call __MEM_FREE')\n\n    output.append('pop hl')\n    REQUIRES.add('alloc.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomparing & pops top 2 strings out of the stack.", "response": "def _nestr(ins):\n    ''' Compares & pops top 2 strings out of the stack.\n    Temporal values are freed from memory. (a$ != b$)\n    '''\n    (tmp1, tmp2, output) = _str_oper(ins.quad[2], ins.quad[3])\n    output.append('call __STRNE')\n    output.append('push af')\n    REQUIRES.add('string.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_node(cls, lineno, fname, func=None, type_=None, *operands):\n        if func is not None and len(operands) == 1:  # Try constant-folding\n            if is_number(operands[0]) or is_string(operands[0]):  # e.g. ABS(-5)\n                return SymbolNUMBER(func(operands[0].value), type_=type_, lineno=lineno)\n\n        return cls(lineno, fname, type_, *operands)", "response": "Creates a node for a unary operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _8bit_oper(op1, op2=None, reversed_=False):\n    output = []\n\n    if op2 is not None and reversed_:\n        tmp = op1\n        op1 = op2\n        op2 = tmp\n\n    op = op1\n    indirect = (op[0] == '*')\n    if indirect:\n        op = op[1:]\n\n    immediate = (op[0] == '#')\n    if immediate:\n        op = op[1:]\n\n    if is_int(op):\n        op = int(op)\n\n        if indirect:\n            output.append('ld a, (%i)' % op)\n        else:\n            if op == 0:\n                output.append('xor a')\n            else:\n                output.append('ld a, %i' % int8(op))\n    else:\n        if immediate:\n            if indirect:\n                output.append('ld a, (%s)' % op)\n            else:\n                output.append('ld a, %s' % op)\n        elif op[0] == '_':\n            if indirect:\n                idx = 'bc' if reversed_ else 'hl'\n                output.append('ld %s, (%s)' % (idx, op))  # can't use HL\n                output.append('ld a, (%s)' % idx)\n            else:\n                output.append('ld a, (%s)' % op)\n        else:\n            if immediate:\n                output.append('ld a, %s' % op)\n            elif indirect:\n                idx = 'bc' if reversed_ else 'hl'\n                output.append('pop %s' % idx)\n                output.append('ld a, (%s)' % idx)\n            else:\n                output.append('pop af')\n\n    if op2 is None:\n        return output\n\n    if not reversed_:\n        tmp = output\n        output = []\n\n    op = op2\n    indirect = (op[0] == '*')\n    if indirect:\n        op = op[1:]\n\n    immediate = (op[0] == '#')\n    if immediate:\n        op = op[1:]\n\n    if is_int(op):\n        op = int(op)\n\n        if indirect:\n            output.append('ld hl, (%i - 1)' % op)\n        else:\n            output.append('ld h, %i' % int8(op))\n    else:\n        if immediate:\n            if indirect:\n                output.append('ld hl, %s' % op)\n                output.append('ld h, (hl)')\n            else:\n                output.append('ld h, %s' % op)\n        elif op[0] == '_':\n            if indirect:\n                output.append('ld hl, (%s)' % op)\n                output.append('ld h, (hl)' % op)\n            else:\n                output.append('ld hl, (%s - 1)' % op)\n        else:\n            output.append('pop hl')\n\n        if indirect:\n            output.append('ld h, (hl)')\n\n    if not reversed_:\n        output.extend(tmp)\n\n    return output", "response": "Returns a pop sequence for 8 bits operands op1 and op2."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding an 8 - bit integer to the stack and returns the result.", "response": "def _add8(ins):\n    \"\"\" Pops last 2 bytes from the stack and adds them.\n    Then push the result onto the stack.\n\n    Optimizations:\n      * If any of the operands is ZERO,\n        then do NOTHING: A + 0 = 0 + A = A\n\n      * If any of the operands is 1, then\n        INC is used\n\n      * If any of the operands is -1 (255), then\n        DEC is used\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n    if _int_ops(op1, op2) is not None:\n        op1, op2 = _int_ops(op1, op2)\n\n        output = _8bit_oper(op1)\n        if op2 == 0:  # Nothing to add: A + 0 = A\n            output.append('push af')\n            return output\n\n        op2 = int8(op2)\n\n        if op2 == 1:  # Adding 1 is just an inc\n            output.append('inc a')\n            output.append('push af')\n            return output\n\n        if op2 == 0xFF:  # Adding 255 is just a dec\n            output.append('dec a')\n            output.append('push af')\n            return output\n\n        output.append('add a, %i' % int8(op2))\n        output.append('push af')\n        return output\n\n    if op2[0] == '_':  # stack optimization\n        op1, op2 = op2, op1\n\n    output = _8bit_oper(op1, op2)\n    output.append('add a, h')\n    output.append('push af')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsubs function for internal use only.", "response": "def _sub8(ins):\n    \"\"\" Pops last 2 bytes from the stack and subtract them.\n    Then push the result onto the stack. Top-1 of the stack is\n    subtracted Top\n    _sub8 t1, a, b === t1 <-- a - b\n\n    Optimizations:\n      * If 2nd op is ZERO,\n        then do NOTHING: A - 0 = A\n\n      * If 1st operand is 0, then\n        just do a NEG\n\n      * If any of the operands is 1, then\n        DEC is used\n\n      * If any of the operands is -1 (255), then\n        INC is used\n    \"\"\"\n\n    op1, op2 = tuple(ins.quad[2:])\n    if is_int(op2):  # 2nd operand\n        op2 = int8(op2)\n        output = _8bit_oper(op1)\n\n        if op2 == 0:\n            output.append('push af')\n            return output  # A - 0 = A\n\n        op2 = int8(op2)\n\n        if op2 == 1:  # A - 1 == DEC A\n            output.append('dec a')\n            output.append('push af')\n            return output\n\n        if op2 == 0xFF:  # A - (-1) == INC A\n            output.append('inc a')\n            output.append('push af')\n            return output\n\n        output.append('sub %i' % op2)\n        output.append('push af')\n        return output\n\n    if is_int(op1):  # 1st operand is numeric?\n        if int8(op1) == 0:  # 0 - A = -A ==> NEG A\n            output = _8bit_oper(op2)\n            output.append('neg')\n            output.append('push af')\n            return output\n\n    # At this point, even if 1st operand is numeric, proceed\n    # normally\n\n    if op2[0] == '_':  # Optimization when 2nd operand is an id\n        rev = True\n        op1, op2 = op2, op1\n    else:\n        rev = False\n\n    output = _8bit_oper(op1, op2, rev)\n    output.append('sub h')\n    output.append('push af')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _mul8(ins):\n\n    op1, op2 = tuple(ins.quad[2:])\n    if _int_ops(op1, op2) is not None:\n        op1, op2 = _int_ops(op1, op2)\n\n        output = _8bit_oper(op1)\n        if op2 == 1:  # A * 1 = 1 * A = A\n            output.append('push af')\n            return output\n\n        if op2 == 0:\n            output.append('xor a')\n            output.append('push af')\n            return output\n\n        if op2 == 2:  # A * 2 == A SLA 1\n            output.append('add a, a')\n            output.append('push af')\n            return output\n\n        if op2 == 4:  # A * 4 == A SLA 2\n            output.append('add a, a')\n            output.append('add a, a')\n            output.append('push af')\n            return output\n\n        output.append('ld h, %i' % int8(op2))\n    else:\n        if op2[0] == '_':  # stack optimization\n            op1, op2 = op2, op1\n\n        output = _8bit_oper(op1, op2)\n\n    output.append('call __MUL8_FAST')  # Inmmediate\n    output.append('push af')\n    REQUIRES.add('mul8.asm')\n    return output", "response": "Multiplies 2 las values from the stack."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _divu8(ins):\n    op1, op2 = tuple(ins.quad[2:])\n    if is_int(op2):\n        op2 = int8(op2)\n\n        output = _8bit_oper(op1)\n        if op2 == 1:\n            output.append('push af')\n            return output\n\n        if op2 == 2:\n            output.append('srl a')\n            output.append('push af')\n            return output\n\n        output.append('ld h, %i' % int8(op2))\n    else:\n        if op2[0] == '_':  # Optimization when 2nd operand is an id\n            if is_int(op1) and int(op1) == 0:\n                output = list()  # Optimization: Discard previous op if not from the stack\n                output.append('xor a')\n                output.append('push af')\n                return output\n\n            rev = True\n            op1, op2 = op2, op1\n        else:\n            rev = False\n\n        output = _8bit_oper(op1, op2, rev)\n\n    output.append('call __DIVU8_FAST')\n    output.append('push af')\n    REQUIRES.add('div8.asm')\n    return output", "response": "Divides 2 8bit unsigned integers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ltu8(ins):\n    output = _8bit_oper(ins.quad[2], ins.quad[3])\n    output.append('cp h')\n    output.append('sbc a, a')\n    output.append('push af')\n\n    return output", "response": "Compares top 2 operands and pushes them out of the stack and checks\n        if the 1st operand < 2nd operand."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompare top 2 operands out of the stack and checks if the 1st operand < 2nd operand. Returns a list of 8 bit signed version of the tree.", "response": "def _lti8(ins):\n    \"\"\" Compares & pops top 2 operands out of the stack, and checks\n        if the 1st operand < 2nd operand (top of the stack).\n        Pushes 0 if False, 1 if True.\n\n        8 bit signed version\n    \"\"\"\n    output = []\n    output.extend(_8bit_oper(ins.quad[2], ins.quad[3]))\n    output.append('call __LTI8')\n    output.append('push af')\n    REQUIRES.add('lti8.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _gtu8(ins):\n    output = _8bit_oper(ins.quad[2], ins.quad[3], reversed_=True)\n    output.append('cp h')\n    output.append('sbc a, a')\n    output.append('push af')\n\n    return output", "response": "Compares top 2 operands and pushes them out of the stack and checks\n        if the 1st operand > 2nd operand."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare top 2 operands out of the stack and checks if they are equal.", "response": "def _eq8(ins):\n    \"\"\" Compares & pops top 2 operands out of the stack, and checks\n        if the 1st operand == 2nd operand (top of the stack).\n        Pushes 0 if False, 1 if True.\n\n        8 bit un/signed version\n    \"\"\"\n    if is_int(ins.quad[3]):\n        output = _8bit_oper(ins.quad[2])\n        n = int8(ins.quad[3])\n        if n:\n            if n == 1:\n                output.append('dec a')\n            else:\n                output.append('sub %i' % n)\n    else:\n        output = _8bit_oper(ins.quad[2], ins.quad[3])\n        output.append('sub h')\n\n    output.append('sub 1')  # Sets Carry only if 0\n    output.append('sbc a, a')\n    output.append('push af')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _leu8(ins):\n    output = _8bit_oper(ins.quad[2], ins.quad[3], reversed_=True)\n    output.append('sub h')  # Carry if H > A\n    output.append('ccf')  # Negates => Carry if H <= A\n    output.append('sbc a, a')\n    output.append('push af')\n\n    return output", "response": "Compares top 2 operands and pops top 3 operands out of the stack and checks\n        if the 1st operand < 2nd operand."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _lei8(ins):\n    output = _8bit_oper(ins.quad[2], ins.quad[3])\n    output.append('call __LEI8')\n    output.append('push af')\n    REQUIRES.add('lei8.asm')\n\n    return output", "response": "Compares top 2 operands and pushes them out of the stack and checks\n        if the 1st operand < 2nd operand. Returns the new stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _gei8(ins):\n    output = _8bit_oper(ins.quad[2], ins.quad[3], reversed_=True)\n    output.append('call __LEI8')\n    output.append('push af')\n    REQUIRES.add('lei8.asm')\n\n    return output", "response": "Compares top 2 operands and pushes them out of the stack and checks\n        if the 1st operand > 2nd operand."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _and8(ins):\n    op1, op2 = tuple(ins.quad[2:])\n    if _int_ops(op1, op2) is not None:\n        op1, op2 = _int_ops(op1, op2)\n\n        output = _8bit_oper(op1)  # Pops the stack (if applicable)\n        if op2 != 0:  # X and True = X\n            output.append('push af')\n            return output\n\n        # False and X = False\n        output.append('xor a')\n        output.append('push af')\n        return output\n\n    output = _8bit_oper(op1, op2)\n    # output.append('call __AND8')\n    lbl = tmp_label()\n    output.append('or a')\n    output.append('jr z, %s' % lbl)\n    output.append('ld a, h')\n    output.append('%s:' % lbl)\n    output.append('push af')\n    # REQUIRES.add('and8.asm')\n\n    return output", "response": "Internal function to produce an AND instruction."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npop top 2 operands out of the stack and pushes the result.", "response": "def _band8(ins):\n    \"\"\" Pops top 2 operands out of the stack, and does\n        1st AND (bitwise) 2nd operand (top of the stack),\n        pushes the result.\n\n        8 bit un/signed version\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n    if _int_ops(op1, op2) is not None:\n        op1, op2 = _int_ops(op1, op2)\n\n        output = _8bit_oper(op1)\n        if op2 == 0xFF:  # X & 0xFF = X\n            output.append('push af')\n            return output\n\n        if op2 == 0:  # X and 0 = 0\n            output.append('xor a')\n            output.append('push af')\n            return output\n\n        op1, op2 = tuple(ins.quad[2:])\n\n    output = _8bit_oper(op1, op2)\n    output.append('and h')\n    output.append('push af')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npops top 2 operands out of the stack, and checks if 1st operand XOR (logical) 2nd operand (top of the stack), pushes 0 if False, 1 if True. 8 bit un/signed version", "response": "def _xor8(ins):\n    \"\"\" Pops top 2 operands out of the stack, and checks\n        if 1st operand XOR (logical) 2nd operand (top of the stack),\n        pushes 0 if False, 1 if True.\n\n        8 bit un/signed version\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n    if _int_ops(op1, op2) is not None:\n        op1, op2 = _int_ops(op1, op2)\n\n        output = _8bit_oper(op1)  # True or X = not X\n        if op2 == 0:  # False xor X = X\n            output.append('push af')\n            return output\n\n        output.append('sub 1')\n        output.append('sbc a, a')\n        output.append('push af')\n        return output\n\n    output = _8bit_oper(op1, op2)\n    output.append('call __XOR8')\n    output.append('push af')\n    REQUIRES.add('xor8.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _not8(ins):\n    output = _8bit_oper(ins.quad[2])\n    output.append('sub 1')  # Gives carry only if A = 0\n    output.append('sbc a, a')  # Gives FF only if Carry else 0\n    output.append('push af')\n\n    return output", "response": "Negates top of the stack"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnegates (BITWISE NOT) top of the stack (8 bits in AF)", "response": "def _bnot8(ins):\n    \"\"\" Negates (BITWISE NOT) top of the stack (8 bits in AF)\n    \"\"\"\n    output = _8bit_oper(ins.quad[2])\n    output.append('cpl')  # Gives carry only if A = 0\n    output.append('push af')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnegate top of the stack.", "response": "def _neg8(ins):\n    \"\"\" Negates top of the stack (8 bits in AF)\n    \"\"\"\n    output = _8bit_oper(ins.quad[2])\n    output.append('neg')\n    output.append('push af')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _abs8(ins):\n    output = _8bit_oper(ins.quad[2])\n    output.append('call __ABS8')\n    output.append('push af')\n    REQUIRES.add('abs8.asm')\n    return output", "response": "Returns the absolute value of top of the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshifts 8bit unsigned integer to the right.", "response": "def _shru8(ins):\n    \"\"\" Shift 8bit unsigned integer to the right. The result is pushed onto the stack.\n\n    Optimizations:\n      * If 1nd or 2nd op is 0 then\n        do nothing\n\n      * If 2nd op is < 4 then\n        unroll loop\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n\n    if is_int(op2):\n        op2 = int8(op2)\n\n        output = _8bit_oper(op1)\n        if op2 == 0:\n            output.append('push af')\n            return output\n\n        if op2 < 4:\n            output.extend(['srl a'] * op2)\n            output.append('push af')\n            return output\n\n        label = tmp_label()\n        output.append('ld b, %i' % int8(op2))\n        output.append('%s:' % label)\n        output.append('srl a')\n        output.append('djnz %s' % label)\n        output.append('push af')\n        return output\n\n    if is_int(op1) and int(op1) == 0:\n        output = _8bit_oper(op2)\n        output.append('xor a')\n        output.append('push af')\n        return output\n\n    output = _8bit_oper(op1, op2, True)\n    label = tmp_label()\n    label2 = tmp_label()\n    output.append('or a')\n    output.append('ld b, a')\n    output.append('ld a, h')\n    output.append('jr z, %s' % label2)\n    output.append('%s:' % label)\n    output.append('srl a')\n    output.append('djnz %s' % label)\n    output.append('%s:' % label2)\n    output.append('push af')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrue if this macro is defined in the given symbol", "response": "def is_defined(self, symbolTable=None):\n        \"\"\" True if this macro has been defined\n        \"\"\"\n        if symbolTable is None:\n            symbolTable = self.table\n\n        return symbolTable.defined(self.id_)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an array BOUND LIST. node. children are appended to the node.", "response": "def make_node(cls, node, *args):\n        ''' Creates an array BOUND LIST.\n        '''\n        if node is None:\n            return cls.make_node(SymbolBOUNDLIST(), *args)\n\n        if node.token != 'BOUNDLIST':\n            return cls.make_node(None, node, *args)\n\n        for arg in args:\n            if arg is None:\n                continue\n            node.appendChild(arg)\n\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes the parser state", "response": "def init():\n    \"\"\" Initializes parser state\n    \"\"\"\n    global LABELS\n    global LET_ASSIGNMENT\n    global PRINT_IS_USED\n    global SYMBOL_TABLE\n\n    global ast\n    global data_ast\n    global optemps\n    global OPTIONS\n    global last_brk_linenum\n\n    LABELS = {}\n    LET_ASSIGNMENT = False\n    PRINT_IS_USED = False\n    last_brk_linenum = 0\n\n    ast = None\n    data_ast = None  # Global Variables AST\n    optemps = OpcodesTemps()\n\n    gl.INITS.clear()\n    del gl.FUNCTION_CALLS[:]\n    del gl.FUNCTION_LEVEL[:]\n    del gl.FUNCTIONS[:]\n    SYMBOL_TABLE = gl.SYMBOL_TABLE = api.symboltable.SymbolTable()\n    OPTIONS = api.config.OPTIONS\n\n    # DATAs info\n    gl.DATA_LABELS.clear()\n    gl.DATA_IS_USED = False\n    del gl.DATAS[:]\n    gl.DATA_PTR_CURRENT = api.utils.current_data_label()\n    gl.DATA_FUNCTIONS = []\n    gl.error_msg_cache.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_number(value, lineno, type_=None):\n    return symbols.NUMBER(value, type_=type_, lineno=lineno)", "response": "Creates a number node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_typecast(type_, node, lineno):\n    assert isinstance(type_, symbols.TYPE)\n    return symbols.TYPECAST.make_node(type_, node, lineno)", "response": "Wrapper for a Typecast node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_binary(lineno, operator, left, right, func=None, type_=None):\n    return symbols.BINARY.make_node(operator, left, right, lineno, func, type_)", "response": "Wrapper for creating a Binary node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_unary(lineno, operator, operand, func=None, type_=None):\n    return symbols.UNARY.make_node(lineno, operator, operand, func, type_)", "response": "Wrapper for making a Unary node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_builtin(lineno, fname, operands, func=None, type_=None):\n    if operands is None:\n        operands = []\n    assert isinstance(operands, Symbol) or isinstance(operands, tuple) or isinstance(operands, list)\n    # TODO: In the future, builtin functions will be implemented in an external library, like POINT or ATTR\n    __DEBUG__('Creating BUILTIN \"{}\"'.format(fname), 1)\n    if not isinstance(operands, collections.Iterable):\n        operands = [operands]\n    return symbols.BUILTIN.make_node(lineno, fname, func, type_, *operands)", "response": "Wrapper for creating a Builtin function node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping for creating a String Slice node", "response": "def make_strslice(lineno, s, lower, upper):\n    \"\"\" Wrapper: returns String Slice node\n    \"\"\"\n    return symbols.STRSLICE.make_node(lineno, s, lower, upper)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_sentence(sentence, *args, **kwargs):\n    return symbols.SENTENCE(*([sentence] + list(args)), **kwargs)", "response": "Wrapper for creating a Sentence node"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_argument(expr, lineno, byref=None):\n    if expr is None:\n        return  # There were a syntax / semantic error\n\n    if byref is None:\n        byref = OPTIONS.byref.value\n    return symbols.ARGUMENT(expr, lineno=lineno, byref=byref)", "response": "Wrapper for creating an ARGUMENT node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_array_access(id_, lineno, arglist):\n    return symbols.ARRAYACCESS.make_node(id_, arglist, lineno)", "response": "Creates an array access node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_call(id_, lineno, args):\n    assert isinstance(args, symbols.ARGLIST)\n\n    entry = SYMBOL_TABLE.access_call(id_, lineno)\n    if entry is None:\n        return None\n\n    if entry.class_ is CLASS.unknown and entry.type_ == TYPE.string and len(args) == 1 and is_numeric(args[0]):\n        entry.class_ = CLASS.var  # A scalar variable. e.g a$(expr)\n\n    if entry.class_ == CLASS.array:  # An already declared array\n        arr = symbols.ARRAYLOAD.make_node(id_, args, lineno)\n        if arr is None:\n            return None\n\n        if arr.offset is not None:\n            offset = make_typecast(TYPE.uinteger,\n                                   make_number(arr.offset, lineno=lineno),\n                                   lineno)\n            arr.appendChild(offset)\n        return arr\n\n    if entry.class_ == CLASS.var:  # An already declared/used string var\n        if len(args) > 1:\n            api.errmsg.syntax_error_not_array_nor_func(lineno, id_)\n            return None\n\n        entry = SYMBOL_TABLE.access_var(id_, lineno)\n        if entry is None:\n            return None\n\n        if len(args) == 1:\n            return symbols.STRSLICE.make_node(lineno, entry, args[0].value, args[0].value)\n\n        entry.accessed = True\n        return entry\n\n    return make_func_call(id_, lineno, args)", "response": "This function will return an AST node for a function call or array access."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_type(typename, lineno, implicit=False):\n    assert isinstance(typename, str)\n    if not SYMBOL_TABLE.check_is_declared(typename, lineno, 'type'):\n        return None\n\n    type_ = symbols.TYPEREF(SYMBOL_TABLE.get_entry(typename), lineno, implicit)\n    return type_", "response": "Converts a typename identifier to a type usage symbol"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_bound(lower, upper, lineno):\n    return symbols.BOUND.make_node(lower, upper, lineno)", "response": "Wrapper for creating an array bound node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_label(id_, lineno):\n    entry = SYMBOL_TABLE.declare_label(id_, lineno)\n    if entry:\n        gl.DATA_LABELS[id_] = gl.DATA_PTR_CURRENT  # This label points to the current DATA block index\n    return entry", "response": "Creates a label entry. Returns None on error."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_break(lineno, p):\n    global last_brk_linenum\n\n    if not OPTIONS.enableBreak.value or lineno == last_brk_linenum or is_null(p):\n        return None\n\n    last_brk_linenum = lineno\n    return make_sentence('CHKBREAK', make_number(lineno, lineno, TYPE.uinteger))", "response": "Make a BREAK instruction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprogram that starts the program.", "response": "def p_start(p):\n    \"\"\" start : program\n    \"\"\"\n    global ast, data_ast\n\n    user_data = make_label('.ZXBASIC_USER_DATA', 0)\n    make_label('.ZXBASIC_USER_DATA_LEN', 0)\n\n    if PRINT_IS_USED:\n        zxbpp.ID_TABLE.define('___PRINT_IS_USED___', 1)\n        # zxbasmpp.ID_TABLE.define('___PRINT_IS_USED___', 1)\n\n    if zxblex.IN_STATE:\n        p.type = 'NEWLINE'\n        p_error(p)\n        sys.exit(1)\n\n    ast = p[0] = p[1]\n    __end = make_sentence('END', make_number(0, lineno=p.lexer.lineno))\n\n    if not is_null(ast):\n        ast.appendChild(__end)\n    else:\n        ast = __end\n\n    SYMBOL_TABLE.check_labels()\n    SYMBOL_TABLE.check_classes()\n\n    if gl.has_errors:\n        return\n\n    __DEBUG__('Checking pending labels', 1)\n    if not api.check.check_pending_labels(ast):\n        return\n\n    __DEBUG__('Checking pending calls', 1)\n    if not api.check.check_pending_calls():\n        return\n\n    data_ast = make_sentence('BLOCK', user_data)\n\n    # Appends variable declarations at the end.\n    for var in SYMBOL_TABLE.vars_:\n        data_ast.appendChild(make_var_declaration(var))\n\n    # Appends arrays declarations at the end.\n    for var in SYMBOL_TABLE.arrays:\n        data_ast.appendChild(make_array_declaration(var))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprogram : program program_line", "response": "def p_program(p):\n    \"\"\" program : program program_line\n    \"\"\"\n    p[0] = make_block(p[1], p[2], make_break(p.lineno(2), p[2]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_program_line_label(p):\n    lbl = make_label(p[1], p.lineno(1))\n    p[0] = make_block(lbl, p[2]) if len(p) == 3 else lbl", "response": "Label line with block if it is not already in the program line."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_var_decl(p):\n    for vardata in p[2]:\n        SYMBOL_TABLE.declare_variable(vardata[0], vardata[1], p[3])\n\n    p[0] = None", "response": "declare variable in sequence"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_bound(p):\n    p[0] = make_bound(make_number(OPTIONS.array_base.value,\n                                  lineno=p.lineno(1)), p[1], p.lexer.lineno)", "response": "parse an array element bound"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_const_vector_elem_list(p):\n    if p[1] is None:\n        return\n\n    if not is_static(p[1]):\n        if isinstance(p[1], symbols.UNARY):\n            tmp = make_constexpr(p.lineno(1), p[1])\n        else:\n            api.errmsg.syntax_error_not_constant(p.lexer.lineno)\n            p[0] = None\n            return\n    else:\n        tmp = p[1]\n\n    p[0] = [tmp]", "response": "p = parser. parse_const_vector_elem_list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_const_vector_elem_list_list(p):\n    if p[1] is None or p[3] is None:\n        return\n\n    if not is_static(p[3]):\n        if isinstance(p[3], symbols.UNARY):\n            tmp = make_constexpr(p.lineno(2), p[3])\n        else:\n            api.errmsg.syntax_error_not_constant(p.lineno(2))\n            p[0] = None\n            return\n    else:\n        tmp = p[3]\n\n    if p[1] is not None:\n        p[1].append(tmp)\n    p[0] = p[1]", "response": "parse a const vector elem list list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_const_vector_vector_list(p):\n    if len(p[3]) != len(p[1][0]):\n        syntax_error(p.lineno(2), 'All rows must have the same number of elements')\n        p[0] = None\n        return\n\n    p[0] = p[1] + [p[3]]", "response": "A function to parse a const_vector_list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_statement_border(p):\n    p[0] = make_sentence('BORDER',\n                         make_typecast(TYPE.ubyte, p[2], p.lineno(1)))", "response": "statement : BORDER expr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_statement_plot(p):\n    p[0] = make_sentence('PLOT',\n                         make_typecast(TYPE.ubyte, p[2], p.lineno(3)),\n                         make_typecast(TYPE.ubyte, p[4], p.lineno(3)))", "response": "statement : PLOT expr COMMA expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_statement_plot_attr(p):\n    p[0] = make_sentence('PLOT',\n                         make_typecast(TYPE.ubyte, p[3], p.lineno(4)),\n                         make_typecast(TYPE.ubyte, p[5], p.lineno(4)), p[2])", "response": "statement : PLOT attr_list expr COMMA expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_statement_draw(p):\n    p[0] = make_sentence('DRAW',\n                         make_typecast(TYPE.integer, p[2], p.lineno(3)),\n                         make_typecast(TYPE.integer, p[4], p.lineno(3)))", "response": "statement : DRAW expr COMMA expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_statement_draw_attr(p):\n    p[0] = make_sentence('DRAW',\n                         make_typecast(TYPE.integer, p[3], p.lineno(4)),\n                         make_typecast(TYPE.integer, p[5], p.lineno(4)), p[2])", "response": "Statement draw attr list expr COMMA expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_statement_circle(p):\n    p[0] = make_sentence('CIRCLE',\n                         make_typecast(TYPE.byte_, p[2], p.lineno(3)),\n                         make_typecast(TYPE.byte_, p[4], p.lineno(5)),\n                         make_typecast(TYPE.byte_, p[6], p.lineno(5)))", "response": "statement : CIRCLE expr COMMA expr COMMA expr"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_statement_beep(p):\n    p[0] = make_sentence('BEEP', make_typecast(TYPE.float_, p[2], p.lineno(1)),\n                         make_typecast(TYPE.float_, p[4], p.lineno(3)))", "response": "statement : BEEP expr COMMA expr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing an assignment statement.", "response": "def p_assignment(p):\n    \"\"\" statement : lexpr expr\n    \"\"\"\n    global LET_ASSIGNMENT\n\n    LET_ASSIGNMENT = False  # Mark we're no longer using LET\n    p[0] = None\n    q = p[1:]\n    i = 1\n\n    if q[1] is None:\n        return\n\n    if isinstance(q[1], symbols.VAR) and q[1].class_ == CLASS.unknown:\n        q[1] = SYMBOL_TABLE.access_var(q[1].name, p.lineno(i))\n\n    q1class_ = q[1].class_ if isinstance(q[1], symbols.VAR) else CLASS.unknown\n    variable = SYMBOL_TABLE.access_id(q[0], p.lineno(i), default_type=q[1].type_, default_class=q1class_)\n    if variable is None:\n        return  # HINT: This only happens if variable was not declared with DIM and --strict flag is in use\n\n    if variable.class_ == CLASS.unknown:  # The variable is implicit\n        variable.class_ = CLASS.var\n\n    if variable.class_ not in (CLASS.var, CLASS.array):\n        api.errmsg.syntax_error_cannot_assing_not_a_var(p.lineno(i), variable.name)\n        return\n\n    if variable.class_ == CLASS.var and q1class_ == CLASS.array:\n        syntax_error(p.lineno(i), 'Cannot assign an array to an scalar variable')\n        return\n\n    if variable.class_ == CLASS.array:\n        if q1class_ != variable.class_:\n            syntax_error(p.lineno(i), 'Cannot assign an scalar to an array variable')\n            return\n\n        if q[1].type_ != variable.type_:\n            syntax_error(p.lineno(i), 'Arrays must have the same element type')\n            return\n\n        if variable.memsize != q[1].memsize:\n            syntax_error(p.lineno(i), \"Arrays '%s' and '%s' must have the same size\" %\n                         (variable.name, q[1].name))\n            return\n\n        if variable.count != q[1].count:\n            warning(p.lineno(i), \"Arrays '%s' and '%s' don't have the same number of dimensions\" %\n                    (variable.name, q[1].name))\n        else:\n            for b1, b2 in zip(variable.bounds, q[1].bounds):\n                if b1.count != b2.count:\n                    warning(p.lineno(i), \"Arrays '%s' and '%s' don't have the same dimensions\" %\n                            (variable.name, q[1].name))\n                    break\n        # Array copy\n        p[0] = make_sentence('ARRAYCOPY', variable, q[1])\n        return\n\n    expr = make_typecast(variable.type_, q[1], p.lineno(i))\n    p[0] = make_sentence('LET', variable, expr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_lexpr(p):\n    global LET_ASSIGNMENT\n\n    LET_ASSIGNMENT = True  # Mark we're about to start a LET sentence\n\n    if p[1] == 'LET':\n        p[0] = p[2]\n        i = 2\n    else:\n        p[0] = p[1]\n        i = 1\n\n    SYMBOL_TABLE.access_id(p[i], p.lineno(i))", "response": "lexpr : ID EQ\n              | LET ID EQ\n              | ARRAY_ID EQ\n              | LET ARRAY_ID EQ"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_arr_assignment(p):\n    i = 2 if p[1].upper() == 'LET' else 1\n    id_ = p[i]\n    arg_list = p[i + 1]\n    expr = p[i + 3]\n\n    p[0] = None\n    if arg_list is None or expr is None:\n        return  # There were errors\n\n    entry = SYMBOL_TABLE.access_call(id_, p.lineno(i))\n    if entry is None:\n        return\n\n    if entry.type_ == TYPE.string:\n        variable = gl.SYMBOL_TABLE.access_array(id_, p.lineno(i))\n        if len(variable.bounds) + 1 == len(arg_list):\n            ss = arg_list.children.pop().value\n            p[0] = make_array_substr_assign(p.lineno(i), id_, arg_list, (ss, ss), expr)\n            return\n\n    arr = make_array_access(id_, p.lineno(i), arg_list)\n    if arr is None:\n        return\n\n    expr = make_typecast(arr.type_, expr, p.lineno(i))\n    if entry is None:\n        return\n\n    p[0] = make_sentence('LETARRAY', arr, expr)", "response": "A statement for assignment of ARRAY_ID arg_list EQ expr\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_substr_assignment_no_let(p):\n    # This can be only a substr assignment like a$(i + 3) = \".\", since arrays\n    # have ARRAY_ID already\n    entry = SYMBOL_TABLE.access_call(p[1], p.lineno(1))\n    if entry is None:\n        return\n\n    if entry.class_ == CLASS.unknown:\n        entry.class_ = CLASS.var\n\n    if p[6].type_ != TYPE.string:\n        api.errmsg.syntax_error_expected_string(p.lineno(5), p[6].type_)\n\n    lineno = p.lineno(2)\n    base = make_number(OPTIONS.string_base.value, lineno, _TYPE(gl.STR_INDEX_TYPE))\n    substr = make_typecast(_TYPE(gl.STR_INDEX_TYPE), p[3], lineno)\n    p[0] = make_sentence('LETSUBSTR', entry,\n                         make_binary(lineno, 'MINUS', substr, base, func=lambda x, y: x - y),\n                         make_binary(lineno, 'MINUS', substr, base, func=lambda x, y: x - y),\n                         p[6])", "response": "A substr assignment statement."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_substr_assignment(p):\n    if p[3] is None or p[5] is None:\n        return  # There were errors\n\n    p[0] = None\n    entry = SYMBOL_TABLE.access_call(p[2], p.lineno(2))\n    if entry is None:\n        return\n\n    if entry.class_ == CLASS.unknown:\n        entry.class_ = CLASS.var\n\n    assert entry.class_ == CLASS.var and entry.type_ == TYPE.string\n\n    if p[5].type_ != TYPE.string:\n        api.errmsg.syntax_error_expected_string(p.lineno(4), p[5].type_)\n\n    if len(p[3]) > 1:\n        syntax_error(p.lineno(2), \"Accessing string with too many indexes. Expected only one.\")\n        return\n\n    if len(p[3]) == 1:\n        substr = (\n            make_typecast(_TYPE(gl.STR_INDEX_TYPE), p[3][0].value, p.lineno(2)),\n            make_typecast(_TYPE(gl.STR_INDEX_TYPE), p[3][0].value, p.lineno(2)))\n    else:\n        substr = (make_typecast(_TYPE(gl.STR_INDEX_TYPE),\n                                make_number(gl.MIN_STRSLICE_IDX,\n                                            lineno=p.lineno(2)),\n                                p.lineno(2)),\n                  make_typecast(_TYPE(gl.STR_INDEX_TYPE),\n                                make_number(gl.MAX_STRSLICE_IDX,\n                                            lineno=p.lineno(2)),\n                                p.lineno(2)))\n\n    lineno = p.lineno(2)\n    base = make_number(OPTIONS.string_base.value, lineno, _TYPE(gl.STR_INDEX_TYPE))\n    p[0] = make_sentence('LETSUBSTR', entry,\n                         make_binary(lineno, 'MINUS', substr[0], base, func=lambda x, y: x - y),\n                         make_binary(lineno, 'MINUS', substr[1], base, func=lambda x, y: x - y),\n                         p[5])", "response": "Statement for substr assignment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_str_assign(p):\n    if p[1].upper() != 'LET':\n        q = p[1]\n        r = p[4]\n        s = p[2]\n        lineno = p.lineno(3)\n    else:\n        q = p[2]\n        r = p[5]\n        s = p[3]\n        lineno = p.lineno(4)\n\n    if q is None or s is None:\n        p[0] = None\n        return\n\n    if r.type_ != TYPE.string:\n        api.errmsg.syntax_error_expected_string(lineno, r.type_)\n\n    entry = SYMBOL_TABLE.access_var(q, lineno, default_type=TYPE.string)\n    if entry is None:\n        p[0] = None\n        return\n\n    p[0] = make_sentence('LETSUBSTR', entry, s[0], s[1], r)", "response": "A string assignment statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_if_sentence(p):\n    cond_ = p[1]\n    if len(p) == 6:\n        lbl = make_label(p[3], p.lineno(3))\n        stat_ = make_block(lbl, p[4])\n        endif_ = p[5]\n    elif len(p) == 5:\n        stat_ = p[3]\n        endif_ = p[4]\n    else:\n        stat_ = make_nop()\n        endif_ = p[3]\n\n    p[0] = make_sentence('IF', cond_, make_block(stat_, endif_), lineno=p.lineno(2))", "response": "P an if statement."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses single - line IF statements.", "response": "def p_single_line_if(p):\n    \"\"\" if_inline : if_then_part statements %prec ID\n                  | if_then_part co_statements_co %prec NEWLINE\n                  | if_then_part statements_co %prec NEWLINE\n                  | if_then_part co_statements %prec ID\n    \"\"\"\n    cond_ = p[1]\n    stat_ = p[2]\n    p[0] = make_sentence('IF', cond_, stat_, lineno=p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the else - if - part of a statement.", "response": "def p_elseif_part(p):\n    \"\"\" elseif_expr : ELSEIF expr then\n                    | LABEL ELSEIF expr then\n    \"\"\"\n    if p[1] == 'ELSEIF':\n        label_ = make_nop()  # No label\n        cond_ = p[2]\n    else:\n        label_ = make_label(p[1], p.lineno(1))\n        cond_ = p[3]\n\n    p[0] = label_, cond_"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_elseif_list(p):\n    label_, cond_ = p[1]\n    then_ = p[2]\n    else_ = p[3]\n\n    if isinstance(else_, list):  # it's an else part\n        else_ = make_block(*else_)\n    else:\n        then_ = make_block(then_, else_)\n        else_ = None\n\n    p[0] = make_block(label_, make_sentence('IF', cond_, then_, else_, lineno=p.lineno(1)))", "response": "P 3. 1. 3. elseiflist"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_elseif_elseiflist(p):\n    label_, cond_ = p[1]\n    then_ = p[2]\n    else_ = p[3]\n    p[0] = make_block(label_, make_sentence('IF', cond_, then_, else_, lineno=p.lineno(1)))", "response": "P 3. 1. 6. If list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_else_part_endif(p):\n    if p[2] == '\\n':\n        if len(p) == 4:\n            p[0] = [make_nop(), p[3]]\n        elif len(p) == 6:\n            p[0] = [make_label(p[3], p.lineno(3)), p[4], p[5]]\n        else:\n            p[0] = [p[3], p[4]]\n    else:\n        p[0] = [p[2], p[3]]", "response": "P [ 1 ] else_part_inline"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_else_part_label(p):\n    lbl = make_label(p[1], p.lineno(1))\n    p[0] = [make_block(lbl, p[3]), p[4]]", "response": "Label the else part of a block."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_if_then_part(p):\n    if is_number(p[2]):\n        api.errmsg.warning_condition_is_always(p.lineno(1), bool(p[2].value))\n\n    p[0] = p[2]", "response": "If expr then part"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_next1(p):\n    if p[1] == 'NEXT':\n        p1 = make_nop()\n        p3 = p[2]\n    else:\n        p1 = make_label(p[1], p.lineno(1))\n        p3 = p[3]\n\n    if p3 != gl.LOOPS[-1][1]:\n        api.errmsg.syntax_error_wrong_for_var(p.lineno(2), gl.LOOPS[-1][1], p3)\n        p[0] = make_nop()\n        return\n\n    p[0] = p1", "response": "A function to be used in the loop loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles FOR start and FOR statements.", "response": "def p_for_sentence_start(p):\n    \"\"\" for_start : FOR ID EQ expr TO expr step\n    \"\"\"\n    gl.LOOPS.append(('FOR', p[2]))\n    p[0] = None\n\n    if p[4] is None or p[6] is None or p[7] is None:\n        return\n\n    if is_number(p[4], p[6], p[7]):\n        if p[4].value != p[6].value and p[7].value == 0:\n            warning(p.lineno(5), 'STEP value is 0 and FOR might loop forever')\n\n        if p[4].value > p[6].value and p[7].value > 0:\n            warning(p.lineno(5), 'FOR start value is greater than end. This FOR loop is useless')\n\n        if p[4].value < p[6].value and p[7].value < 0:\n            warning(p.lineno(2), 'FOR start value is lower than end. This FOR loop is useless')\n\n    id_type = common_type(common_type(p[4], p[6]), p[7])\n    variable = SYMBOL_TABLE.access_var(p[2], p.lineno(2), default_type=id_type)\n    if variable is None:\n        return\n\n    variable.accessed = True\n    expr1 = make_typecast(variable.type_, p[4], p.lineno(3))\n    expr2 = make_typecast(variable.type_, p[6], p.lineno(5))\n    expr3 = make_typecast(variable.type_, p[7], p.lexer.lineno)\n\n    p[0] = make_sentence('FOR', variable, expr1, expr2, expr3)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_error_raise(p):\n    q = make_number(1, lineno=p.lineno(2))\n    r = make_binary(p.lineno(1), 'MINUS',\n                    make_typecast(TYPE.ubyte, p[2], p.lineno(1)), q,\n                    lambda x, y: x - y)\n    p[0] = make_sentence('ERROR', r)", "response": "A statement that can be used to raise an error."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_stop_raise(p):\n    q = make_number(9, lineno=p.lineno(1)) if len(p) == 2 else p[2]\n    z = make_number(1, lineno=p.lineno(1))\n    r = make_binary(p.lineno(1), 'MINUS',\n                    make_typecast(TYPE.ubyte, q, p.lineno(1)), z,\n                    lambda x, y: x - y)\n    p[0] = make_sentence('STOP', r)", "response": "A stop raise statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_do_loop(p):\n    if len(p) == 4:\n        q = make_block(p[2], p[3])\n    else:\n        q = p[2]\n\n    if p[1] == 'DO':\n        gl.LOOPS.append(('DO',))\n\n    if q is None:\n        warning(p.lineno(1), 'Infinite empty loop')\n\n    # An infinite loop and no warnings\n    p[0] = make_sentence('DO_LOOP', q)\n    gl.LOOPS.pop()", "response": "A do loop statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_read(p):\n    gl.DATA_IS_USED = True\n    reads = []\n\n    if p[2] is None:\n        return\n\n    for arg in p[2]:\n        entry = arg.value\n        if entry is None:\n            p[0] = None\n            return\n\n        if isinstance(entry, symbols.VARARRAY):\n            api.errmsg.syntax_error(p.lineno(1), \"Cannot read '%s'. It's an array\" % entry.name)\n            p[0] = None\n            return\n\n        if isinstance(entry, symbols.VAR):\n            if entry.class_ != CLASS.var:\n                api.errmsg.syntax_error_cannot_assing_not_a_var(p.lineno(2), entry.name)\n                p[0] = None\n                return\n\n            entry.accessed = True\n            if entry.type_ == TYPE.auto:\n                entry.type_ = _TYPE(gl.DEFAULT_TYPE)\n                api.errmsg.warning_implicit_type(p.lineno(2), p[2], entry.type_)\n\n            reads.append(make_sentence('READ', entry))\n            continue\n\n        if isinstance(entry, symbols.ARRAYLOAD):\n            reads.append(make_sentence('READ', symbols.ARRAYACCESS(entry.entry, entry.args, entry.lineno)))\n            continue\n\n        api.errmsg.syntax_error(p.lineno(1), \"Syntax error. Can only read a variable or an array element\")\n        p[0] = None\n        return\n\n    p[0] = make_block(*reads)", "response": "parse a READ statement"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_do_loop_while(p):\n    if len(p) == 6:\n        q = make_block(p[2], p[3])\n        r = p[5]\n    else:\n        q = p[2]\n        r = p[4]\n\n    if p[1] == 'DO':\n        gl.LOOPS.append(('DO',))\n\n    p[0] = make_sentence('DO_WHILE', r, q)\n    gl.LOOPS.pop()\n\n    if is_number(r):\n        api.errmsg.warning_condition_is_always(p.lineno(3), bool(r.value))\n    if q is None:\n        api.errmsg.warning_empty_loop(p.lineno(3))", "response": "parse a DO loop while statement"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_do_while_loop(p):\n    r = p[1]\n    q = p[2]\n    if q == 'LOOP':\n        q = None\n\n    p[0] = make_sentence('WHILE_DO', r, q)\n    gl.LOOPS.pop()\n\n    if is_number(r):\n        api.errmsg.warning_condition_is_always(p.lineno(2), bool(r.value))", "response": "Process a while loop statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_while_sentence(p):\n    gl.LOOPS.pop()\n    q = make_block(p[2], p[3])\n\n    if is_number(p[1]) and p[1].value:\n        if q is None:\n            warning(p[1].lineno, \"Condition is always true and leads to an infinite loop.\")\n        else:\n            warning(p[1].lineno, \"Condition is always true and might lead to an infinite loop.\")\n\n    p[0] = make_sentence('WHILE', p[1], q)", "response": "Process a WHILE statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_exit(p):\n    q = p[2]\n    p[0] = make_sentence('EXIT_%s' % q)\n\n    for i in gl.LOOPS:\n        if q == i[0]:\n            return\n\n    syntax_error(p.lineno(1), 'Syntax Error: EXIT %s out of loop' % q)", "response": "EXIT WHILE DOCOME WHILE DOCOME FOR FOREXIT"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse an ATTR_LIST statement.", "response": "def p_attr(p):\n    \"\"\" attr : OVER expr\n             | INVERSE expr\n             | INK expr\n             | PAPER expr\n             | BRIGHT expr\n             | FLASH expr\n    \"\"\"\n    # ATTR_LIST are used by drawing commands: PLOT, DRAW, CIRCLE\n    # BOLD and ITALIC are ignored by them, so we put them out of the\n    # attr definition so something like DRAW BOLD 1; .... will raise\n    # a syntax error\n    p[0] = make_sentence(p[1] + '_TMP',\n                         make_typecast(TYPE.ubyte, p[2], p.lineno(1)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_print_list(p):\n    p[0] = p[1]\n    p[0].eol = (p[3] is not None)\n\n    if p[3] is not None:\n        p[0].appendChild(p[3])", "response": "print_list is a list of lists of lists of dicts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_print_list_comma(p):\n    p[0] = p[1]\n    p[0].eol = (p[3] is not None)\n    p[0].appendChild(make_sentence('PRINT_COMMA'))\n\n    if p[3] is not None:\n        p[0].appendChild(p[3])", "response": "A function to parse the print_list_comma."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_on_goto(p):\n    expr = make_typecast(TYPE.ubyte, p[2], p.lineno(1))\n    p[0] = make_sentence('ON_' + p[3], expr, *p[4])", "response": "statement : ON expr goto label_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a RETURN statement.", "response": "def p_return(p):\n    \"\"\" statement : RETURN\n    \"\"\"\n    if not FUNCTION_LEVEL:  # At less one level, otherwise, this return is from a GOSUB\n        p[0] = make_sentence('RETURN')\n        return\n\n    if FUNCTION_LEVEL[-1].kind != KIND.sub:\n        syntax_error(p.lineno(1), 'Syntax Error: Functions must RETURN a value, or use EXIT FUNCTION instead.')\n        p[0] = None\n        return\n\n    p[0] = make_sentence('RETURN', FUNCTION_LEVEL[-1])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_return_expr(p):\n    if not FUNCTION_LEVEL:  # At less one level\n        syntax_error(p.lineno(1), 'Syntax Error: Returning value out of FUNCTION')\n        p[0] = None\n        return\n\n    if FUNCTION_LEVEL[-1].kind is None:  # This function was not correctly declared.\n        p[0] = None\n        return\n\n    if FUNCTION_LEVEL[-1].kind != KIND.function:\n        syntax_error(p.lineno(1), 'Syntax Error: SUBs cannot return a value')\n        p[0] = None\n        return\n\n    if is_numeric(p[2]) and FUNCTION_LEVEL[-1].type_ == TYPE.string:\n        syntax_error(p.lineno(2), 'Type Error: Function must return a string, not a numeric value')\n        p[0] = None\n        return\n\n    if not is_numeric(p[2]) and FUNCTION_LEVEL[-1].type_ != TYPE.string:\n        syntax_error(p.lineno(2), 'Type Error: Function must return a numeric value, not a string')\n        p[0] = None\n        return\n\n    p[0] = make_sentence('RETURN', FUNCTION_LEVEL[-1],\n                         make_typecast(FUNCTION_LEVEL[-1].type_, p[2],\n                                       p.lineno(1)))", "response": "Parse a RETURN statement."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_poke2(p):\n    i = 2 if isinstance(p[2], Symbol) or p[2] is None else 3\n    if p[i + 1] is None or p[i + 3] is None:\n        p[0] = None\n        return\n    p[0] = make_sentence('POKE',\n                         make_typecast(TYPE.uinteger, p[i + 1], p.lineno(i + 2)),\n                         make_typecast(p[i], p[i + 3], p.lineno(i + 3))\n                         )", "response": "statement : POKE numbertype expr COMMA expr\n                   | POKE LP numbertype expr COMMA expr RP"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a simple instruction.", "response": "def p_simple_instruction(p):\n    \"\"\" statement : ITALIC expr\n                   | BOLD expr\n                   | INK expr\n                   | PAPER expr\n                   | BRIGHT expr\n                   | FLASH expr\n                   | OVER expr\n                   | INVERSE expr\n    \"\"\"\n    p[0] = make_sentence(p[1], make_typecast(TYPE.ubyte, p[2], p.lineno(1)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing load code statement", "response": "def p_load_code(p):\n    \"\"\" statement : load_or_verify expr ID\n                  | load_or_verify expr CODE\n                  | load_or_verify expr CODE expr\n                  | load_or_verify expr CODE expr COMMA expr\n    \"\"\"\n    if p[2].type_ != TYPE.string:\n        api.errmsg.syntax_error_expected_string(p.lineno(3), p[2].type_)\n\n    if len(p) == 4:\n        if p[3].upper() not in ('SCREEN', 'SCREEN$', 'CODE'):\n            syntax_error(p.lineno(3), 'Unexpected \"%s\" ID. Expected \"SCREEN$\" instead' % p[3])\n            return None\n        else:\n            if p[3].upper() == 'CODE':  # LOAD \"...\" CODE\n                start = make_number(0, lineno=p.lineno(3))\n                length = make_number(0, lineno=p.lineno(3))\n            else:  # SCREEN$\n                start = make_number(16384, lineno=p.lineno(3))\n                length = make_number(6912, lineno=p.lineno(3))\n    else:\n        start = make_typecast(TYPE.uinteger, p[4], p.lineno(3))\n\n        if len(p) == 5:\n            length = make_number(0, lineno=p.lineno(3))\n        else:\n            length = make_typecast(TYPE.uinteger, p[6], p.lineno(5))\n\n    p[0] = make_sentence(p[1], p[2], start, length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_expr_div_expr(p):\n    p[0] = make_binary(p.lineno(2), 'DIV', p[1], p[3], lambda x, y: x / y)", "response": "expr : expr DIV expr"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_expr_mod_expr(p):\n    p[0] = make_binary(p.lineno(2), 'MOD', p[1], p[3], lambda x, y: x % y)", "response": "expr : expr MOD expr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expr_pow_expr(p):\n    p[0] = make_binary(p.lineno(2), 'POW',\n                       make_typecast(TYPE.float_, p[1], p.lineno(2)),\n                       make_typecast(TYPE.float_, p[3], p.lexer.lineno),\n                       lambda x, y: x ** y)", "response": "expr = expr POW expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_expr_shl_expr(p):\n    if p[1] is None or p[3] is None:\n        p[0] = None\n        return\n\n    if p[1].type_ in (TYPE.float_, TYPE.fixed):\n        p[1] = make_typecast(TYPE.ulong, p[1], p.lineno(2))\n\n    p[0] = make_binary(p.lineno(2), 'SHL', p[1],\n                       make_typecast(TYPE.ubyte, p[3], p.lineno(2)),\n                       lambda x, y: x << y)", "response": "P expr SHL expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_expr_LT_expr(p):\n    p[0] = make_binary(p.lineno(2), 'LT', p[1], p[3], lambda x, y: x < y)", "response": "expr : expr LT expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_expr_GT_expr(p):\n    p[0] = make_binary(p.lineno(2), 'GT', p[1], p[3], lambda x, y: x > y)", "response": "expr : expr GT expr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_expr_GE_expr(p):\n    p[0] = make_binary(p.lineno(2), 'GE', p[1], p[3], lambda x, y: x >= y)", "response": "expr : expr GE expr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_expr_NE_expr(p):\n    p[0] = make_binary(p.lineno(2), 'NE', p[1], p[3], lambda x, y: x != y)", "response": "expr : expr NE expr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expr_OR_expr(p):\n    p[0] = make_binary(p.lineno(2), 'OR', p[1], p[3], lambda x, y: x or y)", "response": "expr : expr OR expr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_expr_BOR_expr(p):\n    p[0] = make_binary(p.lineno(2), 'BOR', p[1], p[3], lambda x, y: x | y)", "response": "expr : expr BOR expr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_expr_XOR_expr(p):\n    p[0] = make_binary(p.lineno(2), 'XOR', p[1], p[3], lambda x, y: (x and not y) or (not x and y))", "response": "expr : expr XOR expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_expr_AND_expr(p):\n    p[0] = make_binary(p.lineno(2), 'AND', p[1], p[3], lambda x, y: x and y)", "response": "expr : expr AND expr"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_expr_BAND_expr(p):\n    p[0] = make_binary(p.lineno(2), 'BAND', p[1], p[3], lambda x, y: x & y)", "response": "expr : expr BAND expr"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_expr_PI(p):\n    p[0] = make_number(PI, lineno=p.lineno(1), type_=TYPE.float_)", "response": "A function to generate the PI expression."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expr_id_substr(p):\n    entry = SYMBOL_TABLE.access_var(p[1], p.lineno(1), default_type=TYPE.string)\n    p[0] = None\n    if entry is None:\n        return\n\n    entry.accessed = True\n    p[0] = make_strslice(p.lineno(1), entry, p[2][0], p[2][1])", "response": "string : ID substr"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstring : LP expr RP substr", "response": "def p_string_expr_lp(p):\n    \"\"\" string : LP expr RP substr\n    \"\"\"\n    if p[2].type_ != TYPE.string:\n        syntax_error(p.lexer.lineno,\n                     \"Expected a string type expression. \"\n                     \"Got %s type instead\" % TYPE.to_string(p[2].type_))\n        p[0] = None\n    else:\n        p[0] = make_strslice(p.lexer.lineno, p[2], p[4][0], p[4][1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_subind_str(p):\n    p[0] = (make_typecast(TYPE.uinteger, p[2], p.lineno(1)),\n            make_typecast(TYPE.uinteger, p[4], p.lineno(3)))", "response": "substr : LP expr TO expr RP"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_subind_TO(p):\n    p[0] = (make_typecast(TYPE.uinteger,\n                          make_number(0, lineno=p.lineno(2)),\n                          p.lineno(1)),\n            make_typecast(TYPE.uinteger,\n                          make_number(gl.MAX_STRSLICE_IDX, lineno=p.lineno(3)),\n                          p.lineno(2)))", "response": "Subind to LP TO RP"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_addr_of_id(p):\n    entry = SYMBOL_TABLE.access_id(p[2], p.lineno(2))\n    if entry is None:\n        p[0] = None\n        return\n\n    entry.accessed = True\n    result = make_unary(p.lineno(1), 'ADDRESS', entry, type_=_TYPE(gl.PTR_TYPE))\n\n    if is_dynamic(entry):\n        p[0] = result\n    else:\n        p[0] = make_constexpr(p.lineno(1), result)", "response": "bexpr : ADDRESSOF ID\n             | ADDRESSOF ARRAY_ID\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the ID call expression.", "response": "def p_idcall_expr(p):\n    \"\"\" func_call : ID arg_list %prec UMINUS\n    \"\"\"  # This can be a function call or a string index\n    p[0] = make_call(p[1], p.lineno(1), p[2])\n    if p[0] is None:\n        return\n\n    if p[0].token in ('STRSLICE', 'VAR', 'STRING'):\n        entry = SYMBOL_TABLE.access_call(p[1], p.lineno(1))\n        entry.accessed = True\n        return\n\n    # TODO: Check that arrays really needs kind=function to be set\n    # Both array accesses and functions are tagged as functions\n    # functions also has the class_ attribute set to 'function'\n    p[0].entry.set_kind(KIND.function, p.lineno(1))\n    p[0].entry.accessed = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_let_arr_substr(p):\n    i = 2 if p[1].upper() == 'LET' else 1\n\n    id_ = p[i]\n    arg_list = p[i + 1]\n    substr = p[i + 2]\n    expr_ = p[i + 4]\n    p[0] = make_array_substr_assign(p.lineno(i), id_, arg_list, substr, expr_)", "response": "P_let_arr_substr is a helper function for inserting a substr statement in a LET ARRAY_ID arg_list substr EQ expr\n                  | ARRAY_ID substr EQ expr\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_let_arr_substr_in_args4(p):\n    i = 2 if p[1].upper() == 'LET' else 1\n\n    id_ = p[i]\n    arg_list = p[i + 2]\n    substr = (arg_list.children.pop().value, p[i + 4])\n    expr_ = p[i + 7]\n    p[0] = make_array_substr_assign(p.lineno(i), id_, arg_list, substr, expr_)", "response": "A let arr substr in args 4."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_addr_of_array_element(p):\n    p[0] = None\n\n    if p[3] is None:\n        return\n\n    result = make_array_access(p[2], p.lineno(2), p[3])\n    if result is None:\n        return\n\n    result.entry.accessed = True\n    p[0] = make_unary(p.lineno(1), 'ADDRESS', result, type_=_TYPE(gl.PTR_TYPE))", "response": "A function to create an array access."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_bexpr_func(p):\n    args = make_arg_list(make_argument(p[2], p.lineno(2)))\n    p[0] = make_call(p[1], p.lineno(1), args)\n    if p[0] is None:\n        return\n\n    if p[0].token in ('STRSLICE', 'VAR', 'STRING'):\n        entry = SYMBOL_TABLE.access_call(p[1], p.lineno(1))\n        entry.accessed = True\n        return\n\n    # TODO: Check that arrays really needs kind=function to be set\n    # Both array accesses and functions are tagged as functions\n    # functions also has the class_ attribute set to 'function'\n    p[0].entry.set_kind(KIND.function, p.lineno(1))\n    p[0].entry.accessed = True", "response": "A function is a function call."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_funcdecl(p):\n    if p[1] is None:\n        p[0] = None\n        return\n\n    p[0] = p[1]\n    p[0].local_symbol_table = SYMBOL_TABLE.table[SYMBOL_TABLE.current_scope]\n    p[0].locals_size = SYMBOL_TABLE.leave_scope()\n    FUNCTION_LEVEL.pop()\n    p[0].entry.body = p[2]\n\n    entry = p[0].entry\n    entry.forwarded = False", "response": "function_declaration : function_header function_body"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_funcdeclforward(p):\n    if p[2] is None:\n        if FUNCTION_LEVEL:\n            FUNCTION_LEVEL.pop()\n        return\n\n    if p[2].entry.forwarded:\n        syntax_error(p.lineno(1), \"duplicated declaration for function '%s'\" % p[2].name)\n\n    p[2].entry.forwarded = True\n    SYMBOL_TABLE.leave_scope()\n    FUNCTION_LEVEL.pop()", "response": "function declaration is forward"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_param_definition(p):\n    p[0] = p[1]\n    if p[0] is not None:\n        p[0].byref = OPTIONS.byref.value", "response": "param_definition is a param_definition object that is passed to the API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_function_body(p):\n    if not FUNCTION_LEVEL:\n        syntax_error(p.lineno(3), \"Unexpected token 'END %s'. No Function or Sub has been defined.\" % p[2])\n        p[0] = None\n        return\n\n    a = FUNCTION_LEVEL[-1].kind\n    if a not in (KIND.sub, KIND.function):  # This function/sub was not correctly declared, so exit now\n        p[0] = None\n        return\n\n    i = 2 if p[1] == 'END' else 3\n    b = p[i].lower()\n\n    if a != b:\n        syntax_error(p.lineno(i), \"Unexpected token 'END %s'. Should be 'END %s'\" % (b.upper(), a.upper()))\n        p[0] = None\n    else:\n        p[0] = None if p[1] == 'END' else p[1]", "response": "Parse the function body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expr_usr(p):\n    if p[2].type_ == TYPE.string:\n        p[0] = make_builtin(p.lineno(1), 'USR_STR', p[2], type_=TYPE.uinteger)\n    else:\n        p[0] = make_builtin(p.lineno(1), 'USR',\n                            make_typecast(TYPE.uinteger, p[2], p.lineno(1)),\n                            type_=TYPE.uinteger)", "response": "bexpr : USR bexpr %prec UMINUS"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_expr_peek(p):\n    p[0] = make_builtin(p.lineno(1), 'PEEK',\n                        make_typecast(TYPE.uinteger, p[2], p.lineno(1)),\n                        type_=TYPE.ubyte)", "response": "bexpr : PEEK bexpr %prec UMINUS"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_expr_lbound(p):\n    entry = SYMBOL_TABLE.access_array(p[3], p.lineno(3))\n    if entry is None:\n        p[0] = None\n        return\n\n    entry.accessed = True\n\n    if p[1] == 'LBOUND':\n        p[0] = make_number(entry.bounds[OPTIONS.array_base.value].lower,\n                           p.lineno(3), TYPE.uinteger)\n    else:\n        p[0] = make_number(entry.bounds[OPTIONS.array_base.value].upper,\n                           p.lineno(3), TYPE.uinteger)", "response": "A function to handle LBOUND and UBOUND expressions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_expr_lbound_expr(p):\n    entry = SYMBOL_TABLE.access_array(p[3], p.lineno(3))\n    if entry is None:\n        p[0] = None\n        return\n\n    entry.accessed = True\n    num = make_typecast(TYPE.uinteger, p[5], p.lineno(6))\n\n    if is_number(num):\n        if num.value == 0:  # 0 => Number of dims\n            p[0] = make_number(len(entry.bounds), p.lineno(3), TYPE.uinteger)\n            return\n\n        val = num.value - 1\n        if val < 0 or val >= len(entry.bounds):\n            syntax_error(p.lineno(6), \"Dimension out of range\")\n            p[0] = None\n            return\n\n        if p[1] == 'LBOUND':\n            p[0] = make_number(entry.bounds[val].lower, p.lineno(3), TYPE.uinteger)\n        else:\n            p[0] = make_number(entry.bounds[val].upper, p.lineno(3), TYPE.uinteger)\n        return\n\n    if p[1] == 'LBOUND':\n        entry.lbound_used = True\n    else:\n        entry.ubound_used = True\n\n    p[0] = make_builtin(p.lineno(1), p[1], [entry, num], type_=TYPE.uinteger)", "response": "p = parse_expr_lbound_expr ( p )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_len(p):\n    arg = p[2]\n    if arg is None:\n        p[0] = None\n    elif isinstance(arg, symbols.VAR) and arg.class_ == CLASS.array:\n        p[0] = make_number(len(arg.bounds), lineno=p.lineno(1))  # Do constant folding\n    elif arg.type_ != TYPE.string:\n        api.errmsg.syntax_error_expected_string(p.lineno(1), TYPE.to_string(arg.type_))\n        p[0] = None\n    elif is_string(arg):  # Constant string?\n        p[0] = make_number(len(arg.value), lineno=p.lineno(1))  # Do constant folding\n    else:\n        p[0] = make_builtin(p.lineno(1), 'LEN', arg, type_=TYPE.uinteger)", "response": "Parse the LEN expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_str(p):\n    if is_number(p[2]):  # A constant is converted to string directly\n        p[0] = symbols.STRING(str(p[2].value), p.lineno(1))\n    else:\n        p[0] = make_builtin(p.lineno(1), 'STR',\n                            make_typecast(TYPE.float_, p[2], p.lineno(1)),\n                            type_=TYPE.string)", "response": "%prec UMINUS\n    string expr %prec UMINUS\n    string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_chr_one(p):\n    arg_list = make_arg_list(make_argument(p[2], p.lineno(1)))\n    arg_list[0].value = make_typecast(TYPE.ubyte, arg_list[0].value, p.lineno(1))\n    p[0] = make_builtin(p.lineno(1), 'CHR', arg_list, type_=TYPE.string)", "response": "\\ x1b [ 1mNAME \\ x1b [ 0m chr - 1 - > CHR"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstrings : CHR arg_list", "response": "def p_chr(p):\n    \"\"\" string : CHR arg_list\n    \"\"\"\n    if len(p[2]) < 1:\n        syntax_error(p.lineno(1), \"CHR$ function need at less 1 parameter\")\n        p[0] = None\n        return\n\n    for i in range(len(p[2])):  # Convert every argument to 8bit unsigned\n        p[2][i].value = make_typecast(TYPE.ubyte, p[2][i].value, p.lineno(1))\n\n    p[0] = make_builtin(p.lineno(1), 'CHR', p[2], type_=TYPE.string)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_code(p):\n\n    def asc(x):\n        if len(x):\n            return ord(x[0])\n\n        return 0\n\n    if p[2] is None:\n        p[0] = None\n        return\n\n    if p[2].type_ != TYPE.string:\n        api.errmsg.syntax_error_expected_string(p.lineno(1), TYPE.to_string(p[2].type_))\n        p[0] = None\n    else:\n        p[0] = make_builtin(p.lineno(1), 'CODE', p[2], lambda x: asc(x), type_=TYPE.ubyte)", "response": "Code parser for internal use."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_node(lower, upper, lineno):\n        if not is_static(lower, upper):\n            syntax_error(lineno, 'Array bounds must be constants')\n            return None\n\n        if isinstance(lower, SymbolVAR):\n            lower = lower.value\n        if isinstance(upper, SymbolVAR):\n            upper = upper.value\n\n        lower.value = int(lower.value)\n        upper.value = int(upper.value)\n\n        if lower.value < 0:\n            syntax_error(lineno, 'Array bounds must be greater than 0')\n            return None\n\n        if lower.value > upper.value:\n            syntax_error(lineno, 'Lower array bound must be less or equal to upper one')\n            return None\n\n        return SymbolBOUND(lower.value, upper.value)", "response": "Creates a node that is a range of the array."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a number for a BASIC program. That is the number of the BASIC log file.", "response": "def number(self, number):\n        \"\"\" Returns a floating point (or integer) number for a BASIC\n        program. That is: It's ASCII representation followed by 5 bytes\n        in floating point or integer format (if number in (-65535 + 65535)\n        \"\"\"\n        s = [ord(x) for x in str(number)] + [14]  # Bytes of string representation in bytes\n\n        if number == int(number) and abs(number) < 65536:  # integer form?\n            sign = 0xFF if number < 0 else 0\n            b = [0, sign] + self.numberLH(number) + [0]\n        else:  # Float form\n            (C, ED, LH) = fp.immediate_float(number)\n            C = C[:2]  # Remove 'h'\n            ED = ED[:4]  # Remove 'h'\n            LH = LH[:4]  # Remove 'h'\n\n            b = [int(C, 16)]  # Convert to BASE 10\n            b += [int(ED[:2], 16), int(ED[2:], 16)]\n            b += [int(LH[:2], 16), int(LH[2:], 16)]\n\n        return s + b"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a given string into a list of BASIC commands and the remaining strings.", "response": "def parse_sentence(self, string):\n        \"\"\" Parses the given sentence. BASIC commands must be\n        types UPPERCASE and as SEEN in ZX BASIC. e.g. GO SUB for gosub, etc...\n        \"\"\"\n\n        result = []\n\n        def shift(string_):\n            \"\"\" Returns first word of a string, and remaining\n            \"\"\"\n            string_ = string_.strip()  # Remove spaces and tabs\n\n            if not string_:  # Avoid empty strings\n                return '', ''\n\n            i = string_.find(' ')\n            if i == -1:\n                command_ = string_\n                string_ = ''\n            else:\n                command_ = string_[:i]\n                string_ = string_[i:]\n\n            return command_, string_\n\n        command, string = shift(string)\n        while command != '':\n            result += self.token(command)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the bytes of a sentence.", "response": "def sentence_bytes(self, sentence):\n        \"\"\" Return bytes of a sentence.\n        This is a very simple parser. Sentence is a list of strings and numbers.\n        1st element of sentence MUST match a token.\n        \"\"\"\n        result = [TOKENS[sentence[0]]]\n\n        for i in sentence[1:]:  # Remaining bytes\n            if isinstance(i, str):\n                result.extend(self.literal(i))\n            elif isinstance(i, float) or isinstance(i, int):  # A number?\n                result.extend(self.number(i))\n            else:\n                result.extend(i)  # Must be another thing\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the bytes for a basic line.", "response": "def line(self, sentences, line_number=None):\n        \"\"\" Return the bytes for a basic line.\n        If no line number is given, current one + 10 will be used\n        Sentences if a list of sentences\n        \"\"\"\n        if line_number is None:\n            line_number = self.current_line + 10\n        self.current_line = line_number\n\n        sep = []\n        result = []\n        for sentence in sentences:\n            result.extend(sep)\n            result.extend(self.sentence_bytes(sentence))\n            sep = [ord(':')]\n\n        result.extend([ENTER])\n        result = self.line_number(line_number) + self.numberLH(len(result)) + result\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a line to the output.", "response": "def add_line(self, sentences, line_number=None):\n        \"\"\" Add current line to the output.\n        See self.line() for more info\n        \"\"\"\n        self.bytes += self.line(sentences, line_number)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the offset in bytes of the base memory of the current object.", "response": "def offset(self):\n        \"\"\" If this is a constant access (e.g. A(1))\n        return the offset in bytes from the beginning of the\n        variable in memory.\n\n        Otherwise, if it's not constant (e.g. A(i))\n        returns None\n        \"\"\"\n        offset = 0\n        # Now we must typecast each argument to a u16 (POINTER) type\n        # i is the dimension ith index, b is the bound\n        for i, b in zip(self.arglist, self.entry.bounds):\n            tmp = i.children[0]\n            if is_number(tmp) or is_const(tmp):\n                if offset is not None:\n                    offset = offset * b.count + tmp.value\n            else:\n                offset = None\n                break\n\n        if offset is not None:\n            offset = TYPE.size(gl.SIZE_TYPE) + TYPE.size(gl.BOUND_TYPE) * len(self.arglist) + offset * self.type_.size\n\n        return offset"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an array access. A node.", "response": "def make_node(cls, id_, arglist, lineno):\n        \"\"\" Creates an array access. A(x1, x2, ..., xn)\n        \"\"\"\n        assert isinstance(arglist, SymbolARGLIST)\n        variable = gl.SYMBOL_TABLE.access_array(id_, lineno)\n        if variable is None:\n            return None\n\n        if len(variable.bounds) != len(arglist):\n            syntax_error(lineno, \"Array '%s' has %i dimensions, not %i\" %\n                         (variable.name, len(variable.bounds), len(arglist)))\n            return None\n\n        # Checks for array subscript range if the subscript is constant\n        # e.g. A(1) is a constant subscript access\n        for i, b in zip(arglist, variable.bounds):\n            btype = gl.SYMBOL_TABLE.basic_types[gl.BOUND_TYPE]\n            lower_bound = NUMBER(b.lower, type_=btype, lineno=lineno)\n            i.value = BINARY.make_node('MINUS',\n                                       TYPECAST.make_node(btype, i.value, lineno),\n                                       lower_bound, lineno, func=lambda x, y: x - y,\n                                       type_=btype)\n            if is_number(i.value) or is_const(i.value):\n                val = i.value.value\n                if val < 0 or val > b.count:\n                    warning(lineno, \"Array '%s' subscript out of range\" % id_)\n\n        # Returns the variable entry and the node\n        return cls(variable, arglist, lineno)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef t_INITIAL_COMMENT(self, t):\n        r';'\n        t.lexer.push_state('asmcomment')\n        t.type = 'TOKEN'\n        t.value = ';'\n        return t", "response": "r This is the initial comment token."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlook for preprocessor ID directives and set the type to ID", "response": "def t_prepro_ID(self, t):\n        r'[_a-zA-Z][_a-zA-Z0-9]*'  # preprocessor directives\n        t.type = reserved_directives.get(t.value.lower(), 'ID')\n        if t.type == 'DEFINE':\n            t.lexer.begin('define')\n        elif t.type == 'PRAGMA':\n            t.lexer.begin('pragma')\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef put_current_line(self, prefix=''):\n        return '%s#line %i \"%s\"\\n' % (prefix, self.lex.lineno, os.path.basename(self.filestack[-1][0]))", "response": "Returns line and file for include sequences."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nincluding a file into the internal state.", "response": "def include(self, filename):\n        \"\"\" Changes FILENAME and line count\n        \"\"\"\n        if filename != STDIN and filename in [x[0] for x in self.filestack]:  # Already included?\n            self.warning(' Recursive inclusion')\n\n        self.filestack.append([filename, 1, self.lex, self.input_data])\n        self.lex = lex.lex(object=self)\n        result = self.put_current_line()  # First #line start with \\n (EOL)\n\n        try:\n            if filename == STDIN:\n                self.input_data = sys.stdin.read()\n            else:\n                self.input_data = api.utils.read_txt_file(filename)\n\n            if len(self.input_data) and self.input_data[-1] != EOL:\n                self.input_data += EOL\n        except IOError:\n            self.input_data = EOL\n\n        self.lex.input(self.input_data)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_alias(self, entry):\n        assert isinstance(entry, SymbolVAR)\n        self.aliased_by.append(entry)", "response": "Adds an alias to the current list aliased_by"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_alias(self, entry):\n        entry.add_alias(self)\n        self.alias = entry\n        self.scope = entry.scope  # Local aliases can be \"global\" (static)\n        self.byref = entry.byref\n        self.offset = entry.offset\n        self.addr = entry.addr", "response": "Make this variable an alias of another one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a var_instance to a label one", "response": "def to_label(var_instance):\n        \"\"\" Converts a var_instance to a label one\n        \"\"\"\n        # This can be done 'cause LABEL is just a dummy descent of VAR\n        assert isinstance(var_instance, SymbolVAR)\n        from symbols import LABEL\n        var_instance.__class__ = LABEL\n        var_instance.class_ = CLASS.label\n        var_instance._scope_owner = []\n        return var_instance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a var_instance to a function one", "response": "def to_function(var_instance, lineno=None):\n        \"\"\" Converts a var_instance to a function one\n        \"\"\"\n        assert isinstance(var_instance, SymbolVAR)\n        from symbols import FUNCTION\n        var_instance.__class__ = FUNCTION\n        var_instance.class_ = CLASS.function\n        var_instance.reset(lineno=lineno)\n        return var_instance"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_vararray(var_instance, bounds):\n        assert isinstance(var_instance, SymbolVAR)\n        from symbols import BOUNDLIST\n        from symbols import VARARRAY\n        assert isinstance(bounds, BOUNDLIST)\n        var_instance.__class__ = VARARRAY\n        var_instance.class_ = CLASS.array\n        var_instance.bounds = bounds\n        return var_instance", "response": "Converts a var_instance to a var array one\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _paddr(ins):\n    output = []\n\n    oper = ins.quad[1]\n    indirect = (oper[0] == '*')\n    if indirect:\n        oper = oper[1:]\n\n    I = int(oper)\n    if I >= 0:\n        I += 4  # Return Address + \"push IX\"\n\n    output.append('push ix')\n    output.append('pop hl')\n    output.append('ld de, %i' % I)\n    output.append('add hl, de')\n\n    if indirect:\n        output.append('ld e, (hl)')\n        output.append('inc hl')\n        output.append('ld h, (hl)')\n        output.append('ld l, e')\n\n    output.append('push hl')\n    return output", "response": "Returns code sequence which points to\n    local variable or parameter HL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _pload(offset, size):\n    output = []\n\n    indirect = offset[0] == '*'\n    if indirect:\n        offset = offset[1:]\n\n    I = int(offset)\n    if I >= 0:  # If it is a parameter, round up to even bytes\n        I += 4 + (size % 2 if not indirect else 0)  # Return Address + \"push IX\"\n\n    ix_changed = (indirect or size < 5) and (abs(I) + size) > 127  # Offset > 127 bytes. Need to change IX\n    if ix_changed:  # more than 1 byte\n        output.append('push ix')\n        output.append('ld de, %i' % I)\n        output.append('add ix, de')\n        I = 0\n    elif size == 5:  # For floating point numbers we always use DE as IX offset\n        output.append('push ix')\n        output.append('pop hl')\n        output.append('ld de, %i' % I)\n        output.append('add hl, de')\n        I = 0\n\n    if indirect:\n        output.append('ld h, (ix%+i)' % (I + 1))\n        output.append('ld l, (ix%+i)' % I)\n\n        if size == 1:\n            output.append('ld a, (hl)')\n        elif size == 2:\n            output.append('ld c, (hl)')\n            output.append('inc hl')\n            output.append('ld h, (hl)')\n            output.append('ld l, c')\n        elif size == 4:\n            output.append('call __ILOAD32')\n            REQUIRES.add('iload32.asm')\n        else:  # Floating point\n            output.append('call __ILOADF')\n            REQUIRES.add('iloadf.asm')\n    else:\n        if size == 1:\n            output.append('ld a, (ix%+i)' % I)\n        else:\n            if size <= 4:  # 16/32bit integer, low part\n                output.append('ld l, (ix%+i)' % I)\n                output.append('ld h, (ix%+i)' % (I + 1))\n\n                if size > 2:  # 32 bit integer, high part\n                    output.append('ld e, (ix%+i)' % (I + 2))\n                    output.append('ld d, (ix%+i)' % (I + 3))\n\n            else:  # Floating point\n                output.append('call __PLOADF')\n                REQUIRES.add('ploadf.asm')\n\n    if ix_changed:\n        output.append('pop ix')\n\n    return output", "response": "Generic parameter loading.\n    Emmits output code for setting IX at the right location.\n    size = Number of bytes to load:\n        1 => 8 bit value\n        2 => 16 bit value / string\n        4 => 32 bit value / f16 value\n        5 => 40 bit value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pload32(ins):\n    output = _pload(ins.quad[2], 4)\n    output.append('push de')\n    output.append('push hl')\n    return output", "response": "Loads from stack pointer X 2nd parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ploadf(ins):\n    output = _pload(ins.quad[2], 5)\n    output.extend(_fpush())\n    return output", "response": "Loads from stack pointer SP + X 2nd parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ploadstr(ins):\n    output = _pload(ins.quad[2], 2)\n    if ins.quad[1][0] != '$':\n        output.append('call __LOADSTR')\n        REQUIRES.add('loadstr.asm')\n\n    output.append('push hl')\n    return output", "response": "Loads from stack pointer X 2nd parameter X being\n    X 2nd operand X being\n    X 2nd parameter X being\n    X 2nd operand X 2nd operand X"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading from stack pointer SP + X 2nd parameter.", "response": "def _fploadstr(ins):\n    \"\"\" Loads from stack pointer (SP) + X, being\n    X 2st parameter.\n\n    1st operand must be a SIGNED integer.\n    Unlike ploadstr, this version does not push the result\n    back into the stack.\n    \"\"\"\n    output = _pload(ins.quad[2], 2)\n    if ins.quad[1][0] != '$':\n        output.append('call __LOADSTR')\n        REQUIRES.add('loadstr.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstore 2nd parameter at stack pointer X 1st parameter.", "response": "def _pstore8(ins):\n    \"\"\" Stores 2nd parameter at stack pointer (SP) + X, being\n    X 1st parameter.\n\n    1st operand must be a SIGNED integer.\n    \"\"\"\n    value = ins.quad[2]\n    offset = ins.quad[1]\n    indirect = offset[0] == '*'\n    size = 0\n    if indirect:\n        offset = offset[1:]\n        size = 1\n\n    I = int(offset)\n    if I >= 0:\n        I += 4  # Return Address + \"push IX\"\n        if not indirect:\n            I += 1  # F flag ignored\n\n    if is_int(value):\n        output = []\n    else:\n        output = _8bit_oper(value)\n\n    ix_changed = not (-128 + size <= I <= 127 - size)  # Offset > 127 bytes. Need to change IX\n    if ix_changed:  # more than 1 byte\n        output.append('push ix')\n        output.append('pop hl')\n        output.append('ld de, %i' % I)\n        output.append('add hl, de')\n\n    if indirect:\n        if ix_changed:\n            output.append('ld c, (hl)')\n            output.append('inc hl')\n            output.append('ld h, (hl)')\n            output.append('ld l, c')\n        else:\n            output.append('ld h, (ix%+i)' % (I + 1))\n            output.append('ld l, (ix%+i)' % I)\n\n        if is_int(value):\n            output.append('ld (hl), %i' % int8(value))\n        else:\n            output.append('ld (hl), a')\n\n        return output\n\n    # direct store\n    if ix_changed:\n        if is_int(value):\n            output.append('ld (hl), %i' % int8(value))\n        else:\n            output.append('ld (hl), a')\n\n        return output\n\n    if is_int(value):\n        output.append('ld (ix%+i), %i' % (I, int8(value)))\n    else:\n        output.append('ld (ix%+i), a' % I)\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pstore16(ins):\n    value = ins.quad[2]\n    offset = ins.quad[1]\n    indirect = offset[0] == '*'\n    size = 1\n    if indirect:\n        offset = offset[1:]\n\n    I = int(offset)\n    if I >= 0:\n        I += 4  # Return Address + \"push IX\"\n\n    if is_int(value):\n        output = []\n    else:\n        output = _16bit_oper(value)\n\n    ix_changed = not (-128 + size <= I <= 127 - size)  # Offset > 127 bytes. Need to change IX\n\n    if indirect:\n        if is_int(value):\n            output.append('ld hl, %i' % int16(value))\n\n        output.append('ld bc, %i' % I)\n        output.append('call __PISTORE16')\n        REQUIRES.add('istore16.asm')\n        return output\n\n    # direct store\n    if ix_changed:  # more than 1 byte\n        if not is_int(value):\n            output.append('ex de, hl')\n\n        output.append('push ix')\n        output.append('pop hl')\n        output.append('ld bc, %i' % I)\n        output.append('add hl, bc')\n\n        if is_int(value):\n            v = int16(value)\n            output.append('ld (hl), %i' % (v & 0xFF))\n            output.append('inc hl')\n            output.append('ld (hl), %i' % (v >> 8))\n            return output\n        else:\n            output.append('ld (hl), e')\n            output.append('inc hl')\n            output.append('ld (hl), d')\n            return output\n\n    if is_int(value):\n        v = int16(value)\n        output.append('ld (ix%+i), %i' % (I, v & 0xFF))\n        output.append('ld (ix%+i), %i' % (I + 1, v >> 8))\n    else:\n        output.append('ld (ix%+i), l' % I)\n        output.append('ld (ix%+i), h' % (I + 1))\n\n    return output", "response": "Stores 2nd parameter at stack pointer X 1st parameter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstore 2nd parameter at stack pointer X 1st parameter being X 1st operand must be a SIGNED integer. Returns Address + push IX", "response": "def _pstore32(ins):\n    \"\"\" Stores 2nd parameter at stack pointer (SP) + X, being\n    X 1st parameter.\n\n    1st operand must be a SIGNED integer.\n    \"\"\"\n    value = ins.quad[2]\n    offset = ins.quad[1]\n    indirect = offset[0] == '*'\n    if indirect:\n        offset = offset[1:]\n\n    I = int(offset)\n    if I >= 0:\n        I += 4  # Return Address + \"push IX\"\n\n    output = _32bit_oper(value)\n\n    if indirect:\n        output.append('ld bc, %i' % I)\n        output.append('call __PISTORE32')\n        REQUIRES.add('pistore32.asm')\n        return output\n\n    # direct store\n    output.append('ld bc, %i' % I)\n    output.append('call __PSTORE32')\n    REQUIRES.add('pstore32.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstoring 2nd parameter at stack pointer X 1st parameter being X 1st operand must be a SIGNED integer.", "response": "def _pstoref16(ins):\n    \"\"\" Stores 2nd parameter at stack pointer (SP) + X, being\n    X 1st parameter.\n\n    1st operand must be a SIGNED integer.\n    \"\"\"\n    value = ins.quad[2]\n    offset = ins.quad[1]\n    indirect = offset[0] == '*'\n    if indirect:\n        offset = offset[1:]\n\n    I = int(offset)\n    if I >= 0:\n        I += 4  # Return Address + \"push IX\"\n\n    output = _f16_oper(value)\n\n    if indirect:\n        output.append('ld bc, %i' % I)\n        output.append('call __PISTORE32')\n        REQUIRES.add('pistore32.asm')\n        return output\n\n    # direct store\n    output.append('ld bc, %i' % I)\n    output.append('call __PSTORE32')\n    REQUIRES.add('pstore32.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pstoref(ins):\n    value = ins.quad[2]\n    offset = ins.quad[1]\n    indirect = offset[0] == '*'\n    if indirect:\n        offset = offset[1:]\n\n    I = int(offset)\n    if I >= 0:\n        I += 4  # Return Address + \"push IX\"\n\n    output = _float_oper(value)\n\n    if indirect:\n        output.append('ld hl, %i' % I)\n        output.append('call __PISTOREF')\n        REQUIRES.add('storef.asm')\n        return output\n\n    # direct store\n    output.append('ld hl, %i' % I)\n    output.append('call __PSTOREF')\n    REQUIRES.add('pstoref.asm')\n\n    return output", "response": "Stores 2nd parameter at stack pointer X 1st parameter being\n    X 1st operand must be a SIGNED integer."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of strings representing the store string.", "response": "def _pstorestr(ins):\n    \"\"\" Stores 2nd parameter at stack pointer (SP) + X, being\n    X 1st parameter.\n\n    1st operand must be a SIGNED integer.\n\n    Note: This procedure proceeds as _pstore16, since STRINGS are 16bit pointers.\n    \"\"\"\n    output = []\n    temporal = False\n\n    # 2nd operand first, because must go into the stack\n    value = ins.quad[2]\n\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    if value[0] == '_':\n        output.append('ld de, (%s)' % value)\n\n        if indirect:\n            output.append('call __LOAD_DE_DE')\n            REQUIRES.add('lddede.asm')\n\n    elif value[0] == '#':\n        output.append('ld de, %s' % value[1:])\n    else:\n        output.append('pop de')\n        temporal = value[0] != '$'\n        if indirect:\n            output.append('call __LOAD_DE_DE')\n            REQUIRES.add('lddede.asm')\n\n    # Now 1st operand\n    value = ins.quad[1]\n    if value[0] == '*':\n        value = value[1:]\n        indirect = True\n    else:\n        indirect = False\n\n    I = int(value)\n    if I >= 0:\n        I += 4  # Return Address + \"push IX\"\n\n    output.append('ld bc, %i' % I)\n\n    if not temporal:\n        if indirect:\n            output.append('call __PISTORE_STR')\n            REQUIRES.add('storestr.asm')\n        else:\n            output.append('call __PSTORE_STR')\n            REQUIRES.add('pstorestr.asm')\n    else:\n        if indirect:\n            output.append('call __PISTORE_STR2')\n            REQUIRES.add('storestr2.asm')\n        else:\n            output.append('call __PSTORE_STR2')\n            REQUIRES.add('pstorestr2.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a node for a unary operation.", "response": "def make_node(cls, lineno, operator, operand, func=None, type_=None):\n        \"\"\" Creates a node for a unary operation. E.g. -x or LEN(a$)\n\n        Parameters:\n            -func: lambda function used on constant folding when possible\n            -type_: the resulting type (by default, the same as the argument).\n                For example, for LEN (str$), result type is 'u16'\n                and arg type is 'string'\n        \"\"\"\n        assert type_ is None or isinstance(type_, SymbolTYPE)\n\n        if func is not None:  # Try constant-folding\n            if is_number(operand):  # e.g. ABS(-5)\n                return SymbolNUMBER(func(operand.value), lineno=lineno)\n            elif is_string(operand):  # e.g. LEN(\"a\")\n                return SymbolSTRING(func(operand.text), lineno=lineno)\n\n        if type_ is None:\n            type_ = operand.type_\n\n        if operator == 'MINUS':\n            if not type_.is_signed:\n                type_ = type_.to_signed()\n                operand = SymbolTYPECAST.make_node(type_, operand, lineno)\n        elif operator == 'NOT':\n            type_ = TYPE.ubyte\n\n        return cls(operator, operand, lineno, type_)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_signed(cls, type_):\n        if type_ in cls.unsigned:\n            return {TYPE.ubyte: TYPE.byte_,\n                    TYPE.uinteger: TYPE.integer,\n                    TYPE.ulong: TYPE.long_}[type_]\n        if type_ in cls.decimals or type_ in cls.signed:\n            return type_\n        return cls.unknown", "response": "Return signed type or equivalent\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_type(cls, typename):\n        NAME_TYPES = {cls.TYPE_NAMES[x]: x for x in cls.TYPE_NAMES}\n        return NAME_TYPES.get(typename, None)", "response": "Converts a type ID to name. On error returns None. On error returns None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a floating point operand converted to 32 bits unsigned int.", "response": "def f16(op):\n    \"\"\" Returns a floating point operand converted to 32 bits unsigned int.\n    Negative numbers are returned in 2 complement.\n\n    The result is returned in a tuple (DE, HL) => High16 (Int part), Low16 (Decimal part)\n    \"\"\"\n    op = float(op)\n\n    negative = op < 0\n    if negative:\n        op = -op\n\n    DE = int(op)\n    HL = int((op - DE) * 2**16) & 0xFFFF\n    DE &= 0xFFFF\n\n    if negative:  # Do C2\n        DE ^= 0xFFFF\n        HL ^= 0xFFFF\n\n        DEHL = ((DE << 16) | HL) + 1\n        HL = DEHL & 0xFFFF\n        DE = (DEHL >> 16) & 0xFFFF\n\n    return (DE, HL)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a pop sequence for 32 bits operands inversion calling __SWAP32.", "response": "def _f16_oper(op1, op2=None, useBC=False, reversed=False):\n    \"\"\" Returns pop sequence for 32 bits operands\n    1st operand in HLDE, 2nd operand remains in the stack\n\n    Now it does support operands inversion calling __SWAP32.\n\n    However, if 1st operand is integer (immediate) or indirect, the stack\n    will be rearranged, so it contains a 32 bit pushed parameter value for the\n    subroutine to be called.\n\n    If preserveHL is True, then BC will be used instead of HL for lower part\n    for the 1st operand.\n    \"\"\"\n    output = []\n\n    if op1 is not None:\n        op1 = str(op1)\n\n    if op2 is not None:\n        op2 = str(op2)\n\n    op = op2 if op2 is not None else op1\n\n    float1 = False  # whether op1 (2nd operand) is float\n\n    indirect = (op[0] == '*')\n    if indirect:\n        op = op[1:]\n\n    immediate = (op[0] == '#')\n    if immediate:\n        op = op[1:]\n\n    hl = 'hl' if not useBC and not indirect else 'bc'\n\n    if is_float(op):\n        float1 = True\n        op = float(op)\n\n        if indirect:\n            op = int(op) & 0xFFFF\n            if immediate:\n                output.append('ld hl, %i' % op)\n            else:\n                output.append('ld hl, (%i)' % op)\n\n            output.append('call __ILOAD32')\n            REQUIRES.add('iload32.asm')\n\n            if preserveHL:  # noqa TODO: it will fail\n                output.append('ld b, h')\n                output.append('ld c, l')\n        else:\n            DE, HL = f16(op)\n            output.append('ld de, %i' % DE)\n            output.append('ld %s, %i' % (hl, HL))\n    else:\n        if op[0] == '_':\n            if immediate:\n                output.append('ld %s, %s' % (hl, op))\n            else:\n                output.append('ld %s, (%s)' % (hl, op))\n        else:\n            output.append('pop %s' % hl)\n\n        if indirect:\n            output.append('call __ILOAD32')\n            REQUIRES.add('iload32.asm')\n\n            if preserveHL:  # noqa TODO: it will fail\n                output.append('ld b, h')\n                output.append('ld c, l')\n        else:\n            if op[0] == '_':\n                output.append('ld de, (%s + 2)' % op)\n            else:\n                output.append('pop de')\n\n    if op2 is not None:\n        op = op1\n\n        indirect = (op[0] == '*')\n        if indirect:\n            op = op[1:]\n\n        immediate = (op[0] == '#')\n        if immediate:\n            op = op[1:]\n\n        if is_float(op):\n            op = float(op)\n\n            if indirect:\n                op = int(op)\n                output.append('exx')\n                if immediate:\n                    output.append('ld hl, %i' % (op & 0xFFFF))\n                else:\n                    output.append('ld hl, (%i)' % (op & 0xFFFF))\n\n                output.append('call __ILOAD32')\n                output.append('push de')\n                output.append('push hl')\n                output.append('exx')\n                REQUIRES.add('iload32.asm')\n            else:\n                DE, HL = f16(op)\n                output.append('ld bc, %i' % DE)\n                output.append('push bc')\n                output.append('ld bc, %i' % HL)\n                output.append('push bc')\n        else:\n            if indirect:\n                output.append('exx')  # uses alternate set to put it on the stack\n                if op[0] == '_':\n                    if immediate:\n                        output.append('ld hl, %s' % op)\n                    else:\n                        output.append('ld hl, (%s)' % op)\n                else:\n                    output.append('pop hl')  # Pointers are only 16 bits ***\n\n                output.append('call __ILOAD32')\n                output.append('push de')\n                output.append('push hl')\n                output.append('exx')\n                REQUIRES.add('iload32.asm')\n            elif op[0] == '_':  # an address\n                if float1 or op1[0] == '_':  # If previous op was constant, we can use hl in advance\n                    tmp = output\n                    output = []\n                    output.append('ld hl, (%s + 2)' % op)\n                    output.append('push hl')\n                    output.append('ld hl, (%s)' % op)\n                    output.append('push hl')\n                    output.extend(tmp)\n                else:\n                    output.append('ld bc, (%s + 2)' % op)\n                    output.append('push bc')\n                    output.append('ld bc, (%s)' % op)\n                    output.append('push bc')\n            else:\n                pass  # 2nd operand remains in the stack\n\n    if op2 is not None and reversed:\n        output.append('call __SWAP32')\n        REQUIRES.add('swap32.asm')\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _f16_to_32bit(ins):\n    ins.quad = [x for x in ins.quad]\n    for i in range(2, len(ins.quad)):\n        if is_float(ins.quad[i]):\n            de, hl = f16(ins.quad[i])\n            ins.quad[i] = str((de << 16) | hl)\n\n    ins.quad = tuple(ins.quad)\n    return ins", "response": "Convert a 16 bit float to 32bit integer representation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _mulf16(ins):\n    op1, op2 = tuple(ins.quad[2:])\n\n    if _f_ops(op1, op2) is not None:\n        op1, op2 = _f_ops(op1, op2)\n\n        if op2 == 1:  # A * 1 => A\n            output = _f16_oper(op1)\n            output.append('push de')\n            output.append('push hl')\n            return output\n\n        if op2 == -1:\n            return _neg32(ins)\n\n        output = _f16_oper(op1)\n        if op2 == 0:\n            output.append('ld hl, 0')\n            output.append('ld e, h')\n            output.append('ld d, l')\n            output.append('push de')\n            output.append('push hl')\n            return output\n\n    output = _f16_oper(op1, str(op2))\n    output.append('call __MULF16')\n    output.append('push de')\n    output.append('push hl')\n    REQUIRES.add('mulf16.asm')\n    return output", "response": "Multiplies 2 32bit fixed point numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndivides 2 32bit fixed point numbers.", "response": "def _divf16(ins):\n    \"\"\" Divides 2 32bit (16.16) fixed point numbers. The result is pushed onto the stack.\n\n        Optimizations:\n\n         * If 2nd operand is 1, do nothing\n         * If 2nd operand is -1, do NEG32\n    \"\"\"\n    op1, op2 = tuple(ins.quad[2:])\n\n    if is_float(op2):\n        if float(op2) == 1:\n            output = _f16_oper(op1)\n            output.append('push de')\n            output.append('push hl')\n            return output\n\n        if float(op2) == -1:\n            return _negf(ins)\n\n    rev = not is_float(op1) and op1[0] != 't' and op2[0] == 't'\n\n    output = _f16_oper(op1, op2, reversed=rev)\n    output.append('call __DIVF16')\n    output.append('push de')\n    output.append('push hl')\n    REQUIRES.add('divf16.asm')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nraising an exception raised when an invalid number of params in the given quad code has been emmitted.", "response": "def throw_invalid_quad_params(quad, QUADS, nparams):\n    \"\"\" Exception raised when an invalid number of params in the\n        quad code has been emmitted.\n    \"\"\"\n    raise InvalidICError(str(quad),\n                         \"Invalid quad code params for '%s' (expected %i, but got %i)\" %\n                         (quad, QUADS[quad][0], nparams)\n                         )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a floating point number as EXP + 128 Mantissa AttributeNames", "response": "def fp(x):\n    \"\"\" Returns a floating point number as EXP+128, Mantissa\n    \"\"\"\n\n    def bin32(f):\n        \"\"\" Returns ASCII representation for a 32 bit integer value\n        \"\"\"\n        result = ''\n        a = int(f) & 0xFFFFFFFF  # ensures int 32\n\n        for i in range(32):\n            result = str(a % 2) + result\n            a = a >> 1\n\n        return result\n\n    def bindec32(f):\n        \"\"\" Returns binary representation of a mantissa x (x is float)\n        \"\"\"\n        result = '0'\n        a = f\n\n        if f >= 1:\n            result = bin32(f)\n\n        result += '.'\n        c = int(a)\n\n        for i in range(32):\n            a -= c\n            a *= 2\n            c = int(a)\n            result += str(c)\n\n        return result\n\n    e = 0  # exponent\n    s = 1 if x < 0 else 0  # sign\n    m = abs(x)  # mantissa\n\n    while m >= 1:\n        m /= 2.0\n        e += 1\n\n    while 0 < m < 0.5:\n        m *= 2.0\n        e -= 1\n\n    M = bindec32(m)[3:]\n    M = str(s) + M\n    E = bin32(e + 128)[-8:] if x != 0 else bin32(0)[-8:]\n\n    return M, E"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn C DE HL as values for loading and immediate floating point.", "response": "def immediate_float(x):\n    \"\"\" Returns C DE HL as values for loading\n    and immediate floating point.\n    \"\"\"\n    def bin2hex(y):\n        return \"%02X\" % int(y, 2)\n\n    M, E = fp(x)\n\n    C = '0' + bin2hex(E) + 'h'\n    ED = '0' + bin2hex(M[8:16]) + bin2hex(M[:8]) + 'h'\n    LH = '0' + bin2hex(M[24:]) + bin2hex(M[16:24]) + 'h'\n\n    return C, ED, LH"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates in order calling the function with the current node.", "response": "def inorder(self, funct, stopOn=None):\n        \"\"\" Iterates in order, calling the function with the current node.\n        If stopOn is set to True or False, it will stop on true or false.\n        \"\"\"\n        if stopOn is None:\n            for i in self.children:\n                i.inorder(funct)\n        else:\n            for i in self.children:\n                if i.inorder(funct) == stopOn:\n                    return stopOn\n\n        return funct(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef preorder(self, funct, stopOn=None):\n        if funct(self.symbol) == stopOn and stopOn is not None:\n            return stopOn\n\n        if stopOn is None:\n            for i in self.children:\n                i.preorder(funct)\n        else:\n            for i in self.children:\n                if i.preorder(funct) == stopOn:\n                    return stopOn", "response": "Iterates in preorder calling the function with the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates in postorder calling the function with the current node.", "response": "def postorder(self, funct, stopOn=None):\n        \"\"\" Iterates in postorder, calling the function with the current node.\n        If stopOn is set to True or False, it will stop on true or false.\n        \"\"\"\n        if stopOn is None:\n            for i in range(len(self.children) - 1, -1, -1):\n                self.children[i].postorder(funct)\n        else:\n            for i in range(len(self.children) - 1, -1, -1):\n                if self.children[i].postorder(funct) == stopOn:\n                    return stopOn\n        return funct(self.symbol)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstore the symbol in an AST instance and left and right to the given ones", "response": "def makenode(clss, symbol, *nexts):\n        \"\"\" Stores the symbol in an AST instance,\n        and left and right to the given ones\n        \"\"\"\n        result = clss(symbol)\n        for i in nexts:\n            if i is None:\n                continue\n            if not isinstance(i, clss):\n                raise NotAnAstError(i)\n            result.appendChild(i)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_include_path():\n    f1 = os.path.basename(sys.argv[0]).lower()  # script filename\n    f2 = os.path.basename(sys.executable).lower()  # Executable filename\n\n    # If executable filename and script name are the same, we are\n    if f1 == f2 or f2 == f1 + '.exe':  # under a \"compiled\" python binary\n        result = os.path.dirname(os.path.realpath(sys.executable))\n    else:\n        result = os.path.dirname(os.path.realpath(__file__))\n\n    return result", "response": "Default include path using a tricky sys\n    calls."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches a filename into the list of include paths.", "response": "def search_filename(fname, lineno, local_first):\n    \"\"\" Search a filename into the list of the include path.\n    If local_first is true, it will try first in the current directory of\n    the file being analyzed.\n    \"\"\"\n    fname = api.utils.sanitize_filename(fname)\n    i_path = [CURRENT_DIR] + INCLUDEPATH if local_first else list(INCLUDEPATH)\n    i_path.extend(OPTIONS.include_path.value.split(':') if OPTIONS.include_path.value else [])\n    if os.path.isabs(fname):\n        if os.path.isfile(fname):\n            return fname\n    else:\n        for dir_ in i_path:\n            path = api.utils.sanitize_filename(os.path.join(dir_, fname))\n            if os.path.exists(path):\n                return path\n\n    error(lineno, \"file '%s' not found\" % fname)\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef include_file(filename, lineno, local_first):\n    global CURRENT_DIR\n    filename = search_filename(filename, lineno, local_first)\n    if filename not in INCLUDED.keys():\n        INCLUDED[filename] = []\n\n    if len(CURRENT_FILE) > 0:  # Added from which file, line\n        INCLUDED[filename].append((CURRENT_FILE[-1], lineno))\n\n    CURRENT_FILE.append(filename)\n    CURRENT_DIR = os.path.dirname(filename)\n    return LEXER.include(filename)", "response": "A function that performs a file inclusion in the preprocessor."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef include_once(filename, lineno, local_first):\n    filename = search_filename(filename, lineno, local_first)\n    if filename not in INCLUDED.keys():  # If not already included\n        return include_file(filename, lineno, local_first)  # include it and return\n\n    # Now checks if the file has been included more than once\n    if len(INCLUDED[filename]) > 1:\n        warning(lineno, \"file '%s' already included more than once, in file \"\n                        \"'%s' at line %i\" %\n                (filename, INCLUDED[filename][0][0], INCLUDED[filename][0][1]))\n\n    # Empty file (already included)\n    LEXER.next_token = '_ENDFILE_'\n    return ''", "response": "A function that will include a file at a specific line."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprograms : defs NEWLINE", "response": "def p_program_tokenstring(p):\n    \"\"\" program : defs NEWLINE\n    \"\"\"\n    try:\n        tmp = [str(x()) if isinstance(x, MacroCall) else x for x in p[1]]\n    except PreprocError as v:\n        error(v.lineno, v.message)\n\n    tmp.append(p[2])\n    p[0] = tmp"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninclude : INCLUDE STRING", "response": "def p_include(p):\n    \"\"\" include : INCLUDE STRING\n    \"\"\"\n    if ENABLED:\n        p[0] = include_file(p[2], p.lineno(2), local_first=True)\n    else:\n        p[0] = []\n        p.lexer.next_token = '_ENDFILE_'"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nincludes : INCLUDE FILENAME", "response": "def p_include_fname(p):\n    \"\"\" include : INCLUDE FILENAME\n    \"\"\"\n    if ENABLED:\n        p[0] = include_file(p[2], p.lineno(2), local_first=False)\n    else:\n        p[0] = []\n        p.lexer.next_token = '_ENDFILE_'"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninclude once is a no - op.", "response": "def p_include_once(p):\n    \"\"\" include_once : INCLUDE ONCE STRING\n    \"\"\"\n    if ENABLED:\n        p[0] = include_once(p[3], p.lineno(3), local_first=True)\n    else:\n        p[0] = []\n\n    if not p[0]:\n        p.lexer.next_token = '_ENDFILE_'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefining : DEFINE ID params defs", "response": "def p_define(p):\n    \"\"\" define : DEFINE ID params defs\n    \"\"\"\n    if ENABLED:\n        if p[4]:\n            if SPACES.match(p[4][0]):\n                p[4][0] = p[4][0][1:]\n            else:\n                warning(p.lineno(1), \"missing whitespace after the macro name\")\n\n        ID_TABLE.define(p[2], args=p[3], value=p[4], lineno=p.lineno(2),\n                        fname=CURRENT_FILE[-1])\n    p[0] = []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_define_params_empty(p):\n    # Defines the 'epsilon' parameter\n    p[0] = [ID('', value='', args=None, lineno=p.lineno(1),\n               fname=CURRENT_FILE[-1])]", "response": "Define the empty parameter list in the parameter list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_paramlist_single(p):\n    p[0] = [ID(p[1], value='', args=None, lineno=p.lineno(1),\n               fname=CURRENT_FILE[-1])]", "response": "paramlist is a list of ID tuples where the first element is the parameter name and the second is the value of the parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_ifdef(p):\n    global ENABLED\n\n    if ENABLED:\n        p[0] = [p[2]] + p[3]\n        p[0] += ['#line %i \"%s\"' % (p.lineno(4) + 1, CURRENT_FILE[-1])]\n    else:\n        p[0] = ['#line %i \"%s\"' % (p.lineno(4) + 1, CURRENT_FILE[-1])]\n\n    ENABLED = IFDEFS[-1][0]\n    IFDEFS.pop()", "response": "P - IF - DEFINE statement"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_ifdef_else(p):\n    global ENABLED\n\n    p[0] = p[1] + p[2]\n    p[0] += ['#line %i \"%s\"' % (p.lineno(3) + 1, CURRENT_FILE[-1])]\n    ENABLED = IFDEFS[-1][0]\n    IFDEFS.pop()", "response": "P 3. 4. 3. ifdef else"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_if_header(p):\n    global ENABLED\n\n    IFDEFS.append((ENABLED, p.lineno(2)))\n    ENABLED = ID_TABLE.defined(p[2])", "response": "Set ENABLED to True if the first line of the if header is defined."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset ENABLED to True if the IFN header is not defined.", "response": "def p_ifn_header(p):\n    \"\"\" if_header : IFNDEF ID\n    \"\"\"\n    global ENABLED\n\n    IFDEFS.append((ENABLED, p.lineno(2)))\n    ENABLED = not ID_TABLE.defined(p[2])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_exprge(p):\n    a = int(p[1]) if p[1].isdigit() else 0\n    b = int(p[3]) if p[3].isdigit() else 0\n\n    p[0] = '1' if a >= b else '0'", "response": "expr : expr GE expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter_(input_, filename='<internal>', state='INITIAL'):\n    global CURRENT_DIR\n\n    prev_dir = CURRENT_DIR\n    CURRENT_FILE.append(filename)\n    CURRENT_DIR = os.path.dirname(CURRENT_FILE[-1])\n    LEXER.input(input_, filename)\n    LEXER.lex.begin(state)\n    parser.parse(lexer=LEXER, debug=OPTIONS.Debug.value > 2)\n    CURRENT_FILE.pop()\n    CURRENT_DIR = prev_dir", "response": "Filter the input string thought the preprocessor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef del_data(name=None):\n    if name is None:\n        tplot_names = list(data_quants.keys())\n        for i in tplot_names:\n            del data_quants[i]\n        return\n    \n    if not isinstance(name, list):\n        name = [name]\n    \n    entries = []  \n    ###    \n    for i in name:\n        if ('?' in i) or ('*' in i):\n            for j in data_quants.keys():\n                var_verif = fnmatch.fnmatch(data_quants[j].name, i)\n                if var_verif == 1:\n                    entries.append(data_quants[j].name)\n                else:\n                    continue\n            for key in entries:\n                if key in data_quants:\n                    del data_quants[key]       \n    ###            \n        elif i not in data_quants.keys():\n            print(str(i) + \" is currently not in pytplot.\")\n            return\n        \n        else:\n            temp_data_quants = data_quants[i]\n            str_name = temp_data_quants.name\n            \n            del data_quants[str_name]\n        \n    return", "response": "This function deletes all tplot variables that are already stored in memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef xlim(min, max):\n    if not isinstance(min, (int, float, complex)):\n        min = tplot_utilities.str_to_int(min)\n    if not isinstance(max, (int, float, complex)):\n        max = tplot_utilities.str_to_int(max)\n    if 'x_range' in tplot_opt_glob:\n        lim_info['xlast'] = tplot_opt_glob['x_range']\n    else:\n        lim_info['xfull'] = Range1d(min, max)\n        lim_info['xlast'] = Range1d(min, max)\n    tplot_opt_glob['x_range'] = [min, max]\n    return", "response": "This function will set the x axis range for all time series plots"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ylim(name, min, max):\n    if name not in data_quants.keys():\n        print(\"That name is currently not in pytplot.\")\n        return\n    \n    temp_data_quant = data_quants[name]\n    temp_data_quant.yaxis_opt['y_range'] = [min, max]\n    \n    return", "response": "This function will set the y axis limits for a specific tplot variable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef store_data(name, data=None, delete=False, newname=None):\n    \n    \"\"\"\n    This function creates a \"Tplot Variable\" based on the inputs, and\n    stores this data in memory.  Tplot Variables store all of the information\n    needed to generate a plot.  \n    \n    Parameters:\n        name : str \n            Name of the tplot variable that will be created\n        data : dict\n            A python dictionary object.  \n            \n            'x' should be a 1-dimensional array that represents the data's x axis.  Typically this data is time,\n            represented in seconds since epoch (January 1st 1970)\n            \n            'y' should be the data values. This can be 2 dimensions if multiple lines or a spectrogram are desired.\n            \n            'v' is optional, and is only used for spectrogram plots.  This will be a list of bins to be used.  If this\n            is provided, then 'y' should have dimensions of x by z.\n            \n            'x' and 'y' can be any data format that can be read in by the pandas module.  Python lists, numpy arrays,\n            or any pandas data type will all work.\n        delete : bool, optional\n            Deletes the tplot variable matching the \"name\" parameter\n        newname: str\n            Renames TVar to new name\n        \n    .. note::\n        If you want to combine multiple tplot variables into one, simply supply the list of tplot variables to the\n        \"data\" parameter.  This will cause the data to overlay when plotted.\n        \n    Returns:\n        None\n        \n    Examples:\n        >>> # Store a single line\n        >>> import pytplot\n        >>> x_data = [1,2,3,4,5]\n        >>> y_data = [1,2,3,4,5]\n        >>> pytplot.store_data(\"Variable1\", data={'x':x_data, 'y':y_data})\n    \n        >>> # Store a two lines\n        >>> x_data = [1,2,3,4,5]\n        >>> y_data = [[1,5],[2,4],[3,3],[4,2],[5,1]]\n        >>> pytplot.store_data(\"Variable2\", data={'x':x_data, 'y':y_data})\n        \n        >>> # Store a spectrogram\n        >>> x_data = [1,2,3]\n        >>> y_data = [ [1,2,3] , [4,5,6], [7,8,9] ]\n        >>> v_data = [1,2,3]\n        >>> pytplot.store_data(\"Variable3\", data={'x':x_data, 'y':y_data, 'v':v_data})\n        \n        >>> # Combine two different line plots\n        >>> pytplot.store_data(\"Variable1and2\", data=['Variable1', 'Variable2'])\n        \n        >>> #Rename TVar\n        >>> pytplot.store_data('a', data={'x':[0,4,8,12,16], 'y':[1,2,3,4,5]})\n        >>> pytplot.store_data('a',newname='f')\n\n    \"\"\"\n    \n    global tplot_num\n    create_time = datetime.datetime.now()\n    \n    if delete is True:\n        del_data(name)\n        return\n\n    if data is None and newname is None:\n        print('Please provide data.')\n        return\n    \n    if newname is not None:\n        pytplot.tplot_rename(name, newname)\n        return\n    \n    if isinstance(data, list):\n        base_data = get_base_tplot_vars(data)\n        # Use first tplot var as the time range\n        trange = [np.nanmin(data_quants[base_data[0]].data.index), \n                  np.nanmax(data_quants[base_data[0]].data.index)]\n        df = base_data\n        spec_bins = None\n    else:\n        df = format_ydata(data['y'])            \n        times = data['x']\n\n        # If given a list of datetime objects, convert times to seconds since epoch.\n        if any(isinstance(t, datetime.datetime) for t in times):\n            for tt, time in enumerate(times):\n                times[tt] = (time-datetime.datetime(1970, 1, 1, tzinfo=datetime.timezone.utc)).total_seconds()\n        # If given a list of datetime string, convert times to seconds since epoch\n        elif any(isinstance(t, str) for t in times):\n            for tt, time in enumerate(times):\n                times[tt] = pytplot.tplot_utilities.str_to_int(time)\n\n        if len(times) != len(df.index):\n            print(\"The lengths of x and y do not match!\")\n            return\n        elif isinstance(times, pd.Series):\n            df = df.set_index(data['x'])\n        else:\n            df['Index'] = times\n            df = df.set_index('Index', drop=True)\n\n        trange = [np.nanmin(times), np.nanmax(times)]\n        \n        if 'v' in data or 'v2' in data:\n            # Generally the data is 1D, but occasionally\n            # the bins will vary in time.\n            if 'v' in data:\n                spec_bins = data['v']\n            else:\n                spec_bins = data['v2']\n            \n            if type(spec_bins) is not pd.DataFrame:\n                spec_bins = pd.DataFrame(spec_bins)\n                if len(spec_bins.columns) != 1:\n                    if len(spec_bins) == len(df.index):\n                        spec_bins = spec_bins.set_index(df.index)  \n                    else:\n                        print(\"Length of v and x do not match.  Cannot create tplot variable.\")\n                        return \n                else:\n                    spec_bins = spec_bins.transpose()         \n        else:\n            spec_bins = None\n        \n    xaxis_opt = dict(axis_label='Time')\n    yaxis_opt = dict(axis_label=name) if (spec_bins is None) else dict(axis_label='')\n    zaxis_opt = dict(axis_label='') if (spec_bins is None) else dict(axis_label=name)\n    line_opt = {}\n    dtype = ''\n    time_bar = []\n    # Dictionary to keep track of extra details needed for plotting\n    #     that aren't actual attributes in Bokeh\n    extras = dict(panel_size=1)\n    links = {}\n    temp = TVar(name, tplot_num, df, spec_bins, xaxis_opt, yaxis_opt, zaxis_opt, line_opt,\n                trange, dtype, create_time, time_bar, extras, links)\n    \n    data_quants[name] = temp\n    data_quants[name].yaxis_opt['y_range'] = get_y_range(df, spec_bins)\n    \n    return", "response": "This function creates a Tplot Variable based on the inputs and stores the data in memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_data(name):\n    \n    global data_quants\n    if name not in data_quants.keys():\n        print(\"That name is currently not in pytplot\")\n        return\n    \n    temp_data_quant = data_quants[name]\n    data_val = temp_data_quant.data.values\n    time_val = temp_data_quant.data.index\n    \n    return(time_val, data_val)", "response": "This function extracts the data from the Tplot Variables stored in memory. This function extracts the data from the Tplot Variables stored in memory. This function returns the time and data values of the variable whose name is name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a set of drawing specs for this item.", "response": "def generateDrawSpecs(self, p):\n        \"\"\"\n        Calls tickValues() and tickStrings() to determine where and how ticks should\n        be drawn, then generates from this a set of drawing commands to be\n        interpreted by drawPicture().\n        \"\"\"\n        profiler = debug.Profiler()\n\n        # bounds = self.boundingRect()\n        bounds = self.mapRectFromParent(self.geometry())\n\n        linkedView = self.linkedView()\n        if linkedView is None or self.grid is False:\n            tickBounds = bounds\n        else:\n            tickBounds = linkedView.mapRectToItem(self, linkedView.boundingRect())\n\n        if self.orientation == 'left':\n            span = (bounds.topRight(), bounds.bottomRight())\n            tickStart = tickBounds.right()\n            tickStop = bounds.right()\n            tickDir = -1\n            axis = 0\n        elif self.orientation == 'right':\n            span = (bounds.topLeft(), bounds.bottomLeft())\n            tickStart = tickBounds.left()\n            tickStop = bounds.left()\n            tickDir = 1\n            axis = 0\n        elif self.orientation == 'top':\n            span = (bounds.bottomLeft(), bounds.bottomRight())\n            tickStart = tickBounds.bottom()\n            tickStop = bounds.bottom()\n            tickDir = -1\n            axis = 1\n        elif self.orientation == 'bottom':\n            span = (bounds.topLeft(), bounds.topRight())\n            tickStart = tickBounds.top()\n            tickStop = bounds.top()\n            tickDir = 1\n            axis = 1\n        # print tickStart, tickStop, span\n\n        ## determine size of this item in pixels\n        points = list(map(self.mapToDevice, span))\n        if None in points:\n            return\n        lengthInPixels = Point(points[1] - points[0]).length()\n        if lengthInPixels == 0:\n            return\n\n        # Determine major / minor / subminor axis ticks\n        if self._tickLevels is None:\n            tickLevels = self.tickValues(self.range[0], self.range[1], lengthInPixels)\n            tickStrings = None\n        else:\n            ## parse self.tickLevels into the formats returned by tickLevels() and tickStrings()\n            tickLevels = []\n            tickStrings = []\n            for level in self._tickLevels:\n                values = []\n                strings = []\n                tickLevels.append((None, values))\n                tickStrings.append(strings)\n                for val, strn in level:\n                    values.append(val)\n                    strings.append(strn)\n\n        ## determine mapping between tick values and local coordinates\n        dif = self.range[1] - self.range[0]\n        if dif == 0:\n            xScale = 1\n            offset = 0\n        else:\n            if axis == 0:\n                xScale = -bounds.height() / dif\n                offset = self.range[0] * xScale - bounds.height()\n            else:\n                xScale = bounds.width() / dif\n                offset = self.range[0] * xScale\n\n        xRange = [x * xScale - offset for x in self.range]\n        xMin = min(xRange)\n        xMax = max(xRange)\n\n        profiler('init')\n\n        tickPositions = []  # remembers positions of previously drawn ticks\n\n        ## compute coordinates to draw ticks\n        ## draw three different intervals, long ticks first\n        tickSpecs = []\n        for i in range(len(tickLevels)):\n            tickPositions.append([])\n            ticks = tickLevels[i][1]\n\n            ## length of tick\n            tickLength = self.style['tickLength'] / ((i * 0.5) + 1.0)\n\n            lineAlpha = 255 / (i + 1)\n            if self.grid is not False:\n                lineAlpha *= self.grid / 255. * np.clip((0.05 * lengthInPixels / (len(ticks) + 1)), 0., 1.)\n\n            for v in ticks:\n                ## determine actual position to draw this tick\n                x = (v * xScale) - offset\n                if x < xMin or x > xMax:  ## last check to make sure no out-of-bounds ticks are drawn\n                    tickPositions[i].append(None)\n                    continue\n                tickPositions[i].append(x)\n\n                p1 = [x, x]\n                p2 = [x, x]\n                p1[axis] = tickStart\n                p2[axis] = tickStop\n                if self.grid is False:\n                    p2[axis] += tickLength * tickDir\n                tickPen = self.pen()\n                color = tickPen.color()\n                color.setAlpha(lineAlpha)\n                tickPen.setColor(color)\n                tickSpecs.append((tickPen, Point(p1), Point(p2)))\n        profiler('compute ticks')\n\n        if self.style['stopAxisAtTick'][0] is True:\n            stop = max(span[0].y(), min(map(min, tickPositions)))\n            if axis == 0:\n                span[0].setY(stop)\n            else:\n                span[0].setX(stop)\n        if self.style['stopAxisAtTick'][1] is True:\n            stop = min(span[1].y(), max(map(max, tickPositions)))\n            if axis == 0:\n                span[1].setY(stop)\n            else:\n                span[1].setX(stop)\n        axisSpec = (self.pen(), span[0], span[1])\n\n        textOffset = self.style['tickTextOffset'][axis]  ## spacing between axis and text\n        # if self.style['autoExpandTextSpace'] is True:\n        # textWidth = self.textWidth\n        # textHeight = self.textHeight\n        # else:\n        # textWidth = self.style['tickTextWidth'] ## space allocated for horizontal text\n        # textHeight = self.style['tickTextHeight'] ## space allocated for horizontal text\n\n        textSize2 = 0\n        textRects = []\n        textSpecs = []  ## list of draw\n\n        # If values are hidden, return early\n        if not self.style['showValues']:\n            return (axisSpec, tickSpecs, textSpecs)\n\n        for i in range(min(len(tickLevels), self.style['maxTextLevel'] + 1)):\n            ## Get the list of strings to display for this level\n            if tickStrings is None:\n                spacing, values = tickLevels[i]\n                strings = self.tickStrings(values, self.autoSIPrefixScale * self.scale, spacing)\n            else:\n                strings = tickStrings[i]\n\n            if len(strings) == 0:\n                continue\n\n            ## ignore strings belonging to ticks that were previously ignored\n            for j in range(len(strings)):\n                if tickPositions[i][j] is None:\n                    strings[j] = None\n\n            ## Measure density of text; decide whether to draw this level\n            rects = []\n            for s in strings:\n                if s is None:\n                    rects.append(None)\n                else:\n                    br = p.boundingRect(QtCore.QRectF(0, 0, 100, 100), QtCore.Qt.AlignCenter, asUnicode(s))\n                    ## boundingRect is usually just a bit too large\n                    ## (but this probably depends on per-font metrics?)\n                    br.setHeight(br.height() * 1.4)\n\n                    rects.append(br)\n                    textRects.append(rects[-1])\n\n            if len(textRects) > 0:\n                ## measure all text, make sure there's enough room\n                if axis == 0:\n                    textSize = np.sum([r.height() for r in textRects])\n                    textSize2 = np.max([r.width() for r in textRects])\n                else:\n                    textSize = np.sum([r.width() for r in textRects])\n                    textSize2 = np.max([r.height() for r in textRects])\n            else:\n                textSize = 0\n                textSize2 = 0\n\n            if i > 0:  ## always draw top level\n                ## If the strings are too crowded, stop drawing text now.\n                ## We use three different crowding limits based on the number\n                ## of texts drawn so far.\n                textFillRatio = float(textSize) / lengthInPixels\n                finished = False\n                for nTexts, limit in self.style['textFillLimits']:\n                    if len(textSpecs) >= nTexts and textFillRatio >= limit:\n                        finished = True\n                        break\n                if finished:\n                    break\n\n            # spacing, values = tickLevels[best]\n            # strings = self.tickStrings(values, self.scale, spacing)\n            # Determine exactly where tick text should be drawn\n            for j in range(len(strings)):\n                vstr = strings[j]\n                if vstr is None:  ## this tick was ignored because it is out of bounds\n                    continue\n                vstr = asUnicode(vstr)\n                x = tickPositions[i][j]\n                # textRect = p.boundingRect(QtCore.QRectF(0, 0, 100, 100), QtCore.Qt.AlignCenter, vstr)\n                textRect = rects[j]\n                height = textRect.height()\n                width = textRect.width()\n                # self.textHeight = height\n                offset = max(0, self.style['tickLength']) + textOffset\n                if self.orientation == 'left':\n                    textFlags = QtCore.Qt.TextDontClip | QtCore.Qt.AlignRight | QtCore.Qt.AlignVCenter\n                    rect = QtCore.QRectF(tickStop - offset - width, x - (height / 2), width, height)\n                elif self.orientation == 'right':\n                    textFlags = QtCore.Qt.TextDontClip | QtCore.Qt.AlignLeft | QtCore.Qt.AlignVCenter\n                    rect = QtCore.QRectF(tickStop + offset, x - (height / 2), width, height)\n                elif self.orientation == 'top':\n                    textFlags = QtCore.Qt.TextDontClip | QtCore.Qt.AlignCenter | QtCore.Qt.AlignBottom\n                    rect = QtCore.QRectF(x - width / 2., tickStop - offset - height, width, height)\n                elif self.orientation == 'bottom':\n                    textFlags = QtCore.Qt.TextDontClip | QtCore.Qt.AlignCenter | QtCore.Qt.AlignTop\n                    rect = QtCore.QRectF(x - width / 2., tickStop + offset, width, height)\n\n                # p.setPen(self.pen())\n                # p.drawText(rect, textFlags, vstr)\n                textSpecs.append((rect, textFlags, vstr))\n        profiler('compute text')\n\n        ## update max text size if needed.\n        self._updateMaxTextSize(textSize2)\n\n        return (axisSpec, tickSpecs, textSpecs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef static2dplot(var, time):\n\n    # Grab names of data loaded in as tplot variables.\n    names = list(pytplot.data_quants.keys())\n    # Get data we'll actually work with here.\n    valid_variables = tplot_utilities.get_data(names)\n\n    # Don't plot anything unless we have spectrograms with which to work.\n    if valid_variables:\n        # Get z label\n        labels = tplot_utilities.get_labels_axis_types(names)\n\n        # Put together data in easy-to-access format for plots.\n        data = {}\n        for name in valid_variables:\n            bins = tplot_utilities.get_bins(name)\n            time_values, z_values = tplot_utilities.get_z_t_values(name)\n            data[name] = [bins, z_values, time_values]\n\n        # Set up the 2D static plot\n        pytplot.static_window = pg.GraphicsWindow()\n        pytplot.static_window.resize(1000, 600)\n        pytplot.static_window.setWindowTitle('Static Window')\n        plot = pytplot.static_window.addPlot(title='2D Static Plot', row=0, col=0)\n        # Make it so that whenever this first starts up, you just have an empty plot\n        plot_data = plot.plot([], [])\n\n        if var in valid_variables:\n            # Get min/max values of data's time range (in both datetime and seconds since epoch)\n            t_min = np.nanmin(time_values)\n            t_min_str = tplot_utilities.int_to_str(np.nanmin(time_values))\n            t_min_conv_back = tplot_utilities.str_to_int(t_min_str)\n            t_max = np.nanmax(time_values)\n            t_max_str = tplot_utilities.int_to_str(np.nanmax(time_values))\n            t_max_conv_back = tplot_utilities.str_to_int(t_max_str)\n            # Convert user input to seconds since epoch\n            user_time = tplot_utilities.str_to_int(time)\n\n            # Covering situation where user entered a time not in the dataset!\n            # As long as they used a time in the dataset, this will not trigger.\n            if user_time not in range(t_min_conv_back, t_max_conv_back+1):\n                while True:\n                    try:\n                        user_time = tplot_utilities.str_to_int(input(\n                            'Chosen time not in range of data [{} to {}]. Input new time (%Y-%m-%d %H:%M:%S). '.format(\n                                t_min_str, t_max_str)))\n                    except:\n                        continue\n                    else:\n                        if user_time not in range(int(t_min), int(t_max)):\n                            continue\n                        else:\n                            break\n\n            # Get time closest to the user's time choice\n            time_array = np.array(data[var][2])\n            array = np.asarray(time_array)\n            idx = (np.abs(array - user_time)).argmin()\n            # If user indicated they wanted the interactive plot's axes to be logged, log 'em.\n            # But first make sure that values in x and y are loggable!\n            x_axis = False\n            y_axis = False\n            # Checking x axis\n            if np.nanmin(data[name][0][:]) < 0:\n                print('Negative data is incompatible with log plotting.')\n            elif np.nanmin(data[name][0][:]) >= 0 and labels[name][2] == 'log':\n                x_axis = True\n            # Checking y axis\n            if np.nanmin(list(data[name][1][idx])) < 0:\n                print('Negative data is incompatible with log plotting')\n            elif np.nanmin(list(data[name][1][idx])) >= 0 and labels[name][3] == 'log':\n                y_axis = True\n\n            # Set plot labels\n            plot.setLabel('bottom', '{}'.format(labels[name][0]))\n            plot.setLabel('left', '{}'.format(labels[name][1]))\n            plot.setLogMode(x=x_axis, y=y_axis)\n            # Update x and y range if user modified it\n            tplot_utilities.set_x_range(name, x_axis, plot)\n            tplot_utilities.set_y_range(name, y_axis, plot)\n            # Plot data based on time we're hovering over\n            plot_data.setData(data[name][0][:], list(data[name][1][idx]))", "response": "This function will plot the static option of the current page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the spec_bins are ascending or descending.", "response": "def _check_spec_bins_ordering(self):\n        \"\"\"\n        This is a private function of the TVar object, this is run during\n        object creation to check if spec_bins are ascending or descending\n        \"\"\"\n        if self.spec_bins is None:\n            return\n        if len(self.spec_bins) == len(self.data.index):\n            self.spec_bins_time_varying = True\n            break_top_loop = False\n            for index, row in self.spec_bins.iterrows():\n                if row.isnull().values.all():\n                    continue\n                else:\n                    for i in row.index:\n                        if np.isfinite(row[i]) and np.isfinite(row[i + 1]):\n                            ascending = row[i] < row[i + 1]\n                            break_top_loop = True\n                            break\n                        else:\n                            continue\n                    if break_top_loop:\n                        break\n        else:\n            ascending = self.spec_bins[0].iloc[0] < self.spec_bins[1].iloc[0]\n        return ascending"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interactiveplot(t_average=None):\n\n    # Grab names of data loaded in as tplot variables.\n    names = list(pytplot.data_quants.keys())\n    # Get data we'll actually work with here.\n    valid_variables = tplot_utilities.get_data(names)\n\n    # Don't plot anything unless we have spectrograms with which to work.\n    if valid_variables:\n        # Get z label\n        labels = tplot_utilities.get_labels_axis_types(names)\n\n        # Put together data in easy-to-access format for plots.\n        data = {}\n        for name in valid_variables:\n            bins = tplot_utilities.get_bins(name)\n            time_values, z_values = tplot_utilities.get_z_t_values(name)\n            data[name] = [bins, z_values, time_values]\n\n        # Set up the 2D interactive plot\n        pytplot.interactive_window = pg.GraphicsWindow()\n        pytplot.interactive_window.resize(1000, 600)\n        pytplot.interactive_window.setWindowTitle('Interactive Window')\n        plot = pytplot.interactive_window.addPlot(title='2D Interactive Plot', row=0, col=0)\n        # Make it so that whenever this first starts up, you just have an empty plot\n        plot_data = plot.plot([], [])\n\n        # The following update function is passed to change_hover_time in the HoverTime class\n        # defined in __init__.py. For reference, \"t\" essentially originates inside of\n        # TVarFigure(1D/Spec/Alt/Map), inside the _mousemoved function. It calls\n        # \"self._mouseMovedFunction(int(mousePoint.x()))\" and that is called every time the mouse is\n        # moved by Qt. Therefore, it gives the location of the mouse on the x axis. In tplot,\n        # mouse_moved_event is set to pytplot.hover_time.change_hover_time, so the mouseMovedFunction\n        # is pytplot.hover_time.change_hover_time. Thus, whenever change_hover_time is called, it\n        # calls every other function that is registered. Since the below function update() is\n        # registered as a listener, it'll update whenever hover_time is updated.\n        # to the HoverTime class with \"t\" as the input.\n\n        # TL;DR, t comes from getting the mouse location in pyqtgraph every time the mouse is moved\n        # and the below function will update the plot's position as the mouse is moved.\n        def update(t, name):\n            if name in valid_variables:\n                # Get the time closest to the x position the mouse is over.\n                time_array = np.array(data[name][2])\n                array = np.asarray(time_array)\n                idx = (np.abs(array - t)).argmin()\n\n                # If user indicated they wanted the interactive plot's axes to be logged, log 'em.\n                # But first make sure that values in x and y are loggable!\n                x_axis = False\n                y_axis = False\n                # Checking x axis\n                if np.nanmin(data[name][0][:]) < 0:\n                    print('Negative data is incompatible with log plotting.')\n                elif np.nanmin(data[name][0][:]) >= 0 and labels[name][2] == 'log':\n                    x_axis = True\n                # Checking y axis\n                if np.nanmin(list(data[name][1][idx])) < 0:\n                    print('Negative data is incompatible with log plotting')\n                elif np.nanmin(list(data[name][1][idx])) >= 0 and labels[name][3] == 'log':\n                    y_axis = True\n\n                # Set plot labels\n                plot.setLabel('bottom', '{}'.format(labels[name][0]))\n                plot.setLabel('left', '{}'.format(labels[name][1]))\n                plot.setLogMode(x=x_axis, y=y_axis)\n                # Update x and y range if user modified it\n                tplot_utilities.set_x_range(name, x_axis, plot)\n                tplot_utilities.set_y_range(name, y_axis, plot)\n\n                if 't_average' in pytplot.data_quants[name].extras:\n                    # If the user indicated that they wanted to average the interactive plot's y values based on a\n                    # certain time range around the cursor location, we then want to get average of values around\n                    # the cursor location.\n                    t_min = data[name][2][0]\n                    t_max = data[name][2][-1]\n\n                    delta = pytplot.data_quants[name].extras['t_average']/int(2)\n\n                    left_bound = data[name][2][idx] - delta\n                    right_bound = data[name][2][idx] + delta\n\n                    if (left_bound - t_min >= 0) and (t_max - right_bound >= 0):\n                        # Find index of left and right bounds, no fancy foot work necessary.\n                        idx_left = (np.abs(array - left_bound)).argmin()\n                        idx_right = (np.abs(array - right_bound)).argmin()\n                    elif left_bound - t_min < 0:\n                        # Find the number of seconds difference between the cursor's\n                        # left bound and the minimum time in the dataset, add that\n                        # difference to the right bound time (since you want to push the bound\n                        # forward in time, and set the left bound's index to be 0.\n                        idx_left = 0\n                        diff = right_bound + (t_min - left_bound)\n                        idx_right = (np.abs(array - diff)).argmin()\n                    elif t_max - right_bound < 0:\n                        # Find the number of seconds difference between the cursor's\n                        # right bound and the maximum time in the dataset, subtract that\n                        # difference from the left bound time (since you want to push the bound\n                        # back in time), and set the right bound's index to be -1.\n                        idx_right = -1\n                        diff = left_bound - (right_bound - t_max)\n                        idx_left = (np.abs(array - diff)).argmin()\n                    elif (left_bound - t_min < 0) and (t_max - right_bound < 0):\n                        # The user is asking to average the entire time frame of the dataset...\n                        # dunno why they want that, but if they do, use the time-averaged static plot,\n                        # not this.\n                        print(\n                            'This plot isn\\'t appropriate for what you want, use the time-averaged static plot.')\n\n                    # Average values based on the calculated right and left bounds' indices.\n                    time_diff = abs(idx_right - idx_left)\n                    # Make sure to account for edge problem\n                    if idx_right != -1:\n                        y_values_slice = data[name][1][idx_left:idx_right + 1]\n                    else:\n                        y_values_slice = data[name][1][idx_left:]\n                    y_values_avgd = np.sum(y_values_slice, axis=0)/np.float(time_diff)\n\n                    # Update x and y range if user modified it\n                    tplot_utilities.set_x_range(name, x_axis, plot)\n                    tplot_utilities.set_y_range(name, y_axis, plot)\n\n                    try:\n                        # Plot data based on time we're hovering over\n                        plot_data.setData(data[name][0][:], y_values_avgd)\n                    except ZeroDivisionError:\n                        pass\n                else:\n                    # Update x and y range if user modified it\n                    tplot_utilities.set_x_range(name, x_axis, plot)\n                    tplot_utilities.set_y_range(name, y_axis, plot)\n                    # If the user just wants a plain jane interactive plot...\n                    # Plot data based on time we're hovering over'\n                    try:\n                        plot_data.setData(data[name][0][:], list(data[name][1][idx]))\n                    except ZeroDivisionError:\n                        pass\n\n            else:\n                # Cover the situation where you hover over a non-spectrogram plot.\n                plot.setLogMode(False, False)\n                plot.setLabel('bottom', '')\n                plot.setLabel('left', '')\n                plot_data.setData([], [])\n\n        # Make the above function called whenever hover_time is updated.\n        pytplot.hover_time.register_listener(update)", "response": "Create an interactive plot of the current tplot variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_timespan(name):\n    \n    if name not in data_quants.keys():\n        print(\"That name is currently not in pytplot\") \n        return\n    print(\"Start Time: \" + tplot_utilities.int_to_str(data_quants[name].trange[0]))\n    print(\"End Time:   \" + tplot_utilities.int_to_str(data_quants[name].trange[1]))\n    \n    return(data_quants[name].trange[0], data_quants[name].trange[1])", "response": "This function extracts the time span from the Tplot Variables stored in memory. This function returns the time span of the variable that is currently in memory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef timebar(t, varname = None, databar = False, delete = False, color = 'black', thick = 1, dash = False):    \n    \n    # make sure t entered is a list\n    if not isinstance(t, list):\n        t = [t]\n    \n    #if entries in list not numerical, run str_to_int\n    if not isinstance(t[0], (int, float, complex)):\n        t1 = []\n        for time in t:\n            t1.append(tplot_utilities.str_to_int(time))\n        t = t1\n        \n    dim = 'height'\n    if databar is True:\n        dim = 'width'\n    \n    dash_pattern = 'solid'\n    if dash is True:\n        dash_pattern = 'dashed'\n        \n            \n    if delete is True:\n        tplot_utilities.timebar_delete(t, varname, dim)\n        return\n    \n    #if no varname specified, add timebars to every plot\n    if varname is None:\n        num_bars = len(t)\n        for i in range(num_bars):\n            tbar = {}\n            tbar['location'] = t[i]\n            tbar['dimension'] = dim\n            tbar['line_color'] = pytplot.tplot_utilities.rgb_color(color)\n\n            tbar['line_width'] = thick\n            tbar['line_dash'] = dash_pattern\n            for name in data_quants:\n                temp_data_quants = data_quants[name]\n                temp_data_quants.time_bar.append(tbar)\n    #if varname specified\n    else:\n        if not isinstance(varname, list):\n            varname = [varname]\n        for j in varname:\n            if j not in data_quants.keys():\n                print(str(j) + \"is currently not in pytplot\")\n            else:\n                num_bars = len(t)\n                for i in range(num_bars):\n                    tbar = {}\n                    tbar['location'] = t[i]\n                    tbar['dimension'] = dim\n                    tbar['line_color'] = pytplot.tplot_utilities.rgb_color(color)\n                    tbar['line_width'] = thick\n                    tbar['line_dash'] = dash_pattern\n                    temp_data_quants = data_quants[j]\n                    temp_data_quants.time_bar.append(tbar)\n    return", "response": "This function will add a vertical bar to all time series plots."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef options(name, option, value):\n\n    if not isinstance(name, list):\n        name = [name]\n    \n    option = option.lower()\n    \n    for i in name:\n        if i not in data_quants.keys():\n            print(str(i) + \" is currently not in pytplot.\")\n            return\n    \n        if option == 'color':\n            if isinstance(value, list):\n                data_quants[i].extras['line_color'] = value\n            else:\n                data_quants[i].extras['line_color'] = [value]\n        \n        if option == 'link':\n            if isinstance(value, list):\n                data_quants[i].link_to_tvar(value[0], value[1])\n                \n        if option == 'colormap':\n            if isinstance(value, list):\n                data_quants[i].extras['colormap'] = value\n            else:\n                data_quants[i].extras['colormap'] = [value]\n        \n        if option == 'spec':\n            _reset_plots(i)\n            data_quants[i].extras['spec'] = value\n        \n        if option == 'alt':\n            _reset_plots(i)\n            data_quants[i].extras['alt'] = value\n    \n        if option == 'map':\n            _reset_plots(i)\n            data_quants[i].extras['map'] = value\n\n        if option == 'legend_names':\n            data_quants[i].yaxis_opt['legend_names'] = value\n\n        if option == 'xlog_interactive':\n            if value:\n                data_quants[i].interactive_xaxis_opt['xi_axis_type'] = 'log'\n            else:\n                data_quants[i].interactive_xaxis_opt['xi_axis_type'] = 'linear'\n\n        if option == 'ylog':\n            negflag = _ylog_check(data_quants, value, i)\n            if negflag == 0:\n                data_quants[i].yaxis_opt['y_axis_type'] = 'log'\n            else:\n                data_quants[i].yaxis_opt['y_axis_type'] = 'linear'\n\n        if option == 'ylog_interactive':\n            if value:\n                data_quants[i].interactive_yaxis_opt['yi_axis_type'] = 'log'\n            else:\n                data_quants[i].interactive_xaxis_opt['xi_axis_type'] = 'linear'\n\n        if option == 'zlog':\n            negflag = _zlog_check(data_quants, value, i)\n            if negflag == 0:\n                data_quants[i].zaxis_opt['z_axis_type'] = 'log'\n            else:\n                data_quants[i].zaxis_opt['z_axis_type'] = 'linear'\n        \n        if option == 'nodata':\n            data_quants[i].line_opt['visible'] = value\n        \n        if option == 'line_style':\n            to_be = []\n            if value == 0 or value == 'solid_line':\n                to_be = []\n            elif value == 1 or value == 'dot':\n                to_be = [2, 4]\n            elif value == 2 or value == 'dash':\n                to_be = [6]\n            elif value == 3 or value == 'dash_dot':\n                to_be = [6, 4, 2, 4]\n            elif value == 4 or value == 'dash_dot_dot_dot':\n                to_be = [6, 4, 2, 4, 2, 4, 2, 4]\n            elif value == 5 or value == 'long_dash':\n                to_be = [10]\n                \n            data_quants[i].line_opt['line_dash'] = to_be\n            \n            if(value == 6 or value == 'none'):\n                data_quants[i].line_opt['visible'] = False\n\n        if option == 'char_size':\n            data_quants[i].extras['char_size'] = value\n                \n        if option == 'name':\n            data_quants[i].line_opt['name'] = value\n        \n        if option == \"panel_size\":\n            if value > 1 or value <= 0:\n                print(\"Invalid value. Should be (0, 1]\")\n                return\n            data_quants[i].extras['panel_size'] = value\n        \n        if option == 'basemap':\n            data_quants[i].extras['basemap'] = value\n        \n        if option == 'alpha':\n            if value > 1 or value < 0:\n                print(\"Invalid value. Should be [0, 1]\")\n                return\n            data_quants[i].extras['alpha'] = value\n            \n        if option == 'thick':\n            data_quants[i].line_opt['line_width'] = value\n        \n        if option == ('yrange' or 'y_range'):\n            data_quants[i].yaxis_opt['y_range'] = [value[0], value[1]]\n            \n        if option == ('zrange' or 'z_range'):\n            data_quants[i].zaxis_opt['z_range'] = [value[0], value[1]]\n\n        if option == 'xrange_interactive':\n            data_quants[i].interactive_xaxis_opt['xi_range'] = [value[0], value[1]]\n\n        if option == 'yrange_interactive':\n            data_quants[i].interactive_yaxis_opt['yi_range'] = [value[0], value[1]]\n            \n        if option == 'xtitle':\n            data_quants[i].xaxis_opt['axis_label'] = value\n        \n        if option == 'ytitle':\n            data_quants[i].yaxis_opt['axis_label'] = value\n        \n        if option == 'ztitle':\n            data_quants[i].zaxis_opt['axis_label'] = value\n        \n        if option == 'plotter':\n            _reset_plots(i)\n            data_quants[i].extras['plotter'] = value\n\n        if option == 'crosshair_x':\n            data_quants[i].xaxis_opt['crosshair'] = value\n\n        if option == 'crosshair_y':\n            data_quants[i].yaxis_opt['crosshair'] = value\n\n        if option == 'crosshair_z':\n            data_quants[i].zaxis_opt['crosshair'] = value\n\n        if option == 'static':\n            data_quants[i].extras['static'] = value\n\n        if option == 'static_tavg':\n            data_quants[i].extras['static_tavg'] = [value[0], value[1]]\n\n        if option == 't_average':\n            data_quants[i].extras['t_average'] = value\n    return", "response": "This function allows the user to set a large variety of options for individual plots."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tplot_restore(filename):\n    \n    #Error check\n    if not (os.path.isfile(filename)):\n        print(\"Not a valid file name\")\n        return\n    \n    #Check if the restored file was an IDL file\n    \n    if filename.endswith('.tplot'):\n        temp_tplot = readsav(filename)\n        for i in range(len(temp_tplot['dq'])):\n            data_name = temp_tplot['dq'][i][0].decode(\"utf-8\")\n            temp_x_data = temp_tplot['dq'][i][1][0][0]\n            #Pandas reads in data the other way I guess\n            if len(temp_tplot['dq'][i][1][0][2].shape) == 2:\n                temp_y_data = np.transpose(temp_tplot['dq'][i][1][0][2])\n            else:\n                temp_y_data = temp_tplot['dq'][i][1][0][2]\n            \n            \n            #If there are more than 4 fields, that means it is a spectrogram \n            if len(temp_tplot['dq'][i][1][0]) > 4:\n                temp_v_data = temp_tplot['dq'][i][1][0][4]\n                \n                #Change from little endian to big endian, since pandas apparently hates little endian\n                #We might want to move this into the store_data procedure eventually\n                if (temp_x_data.dtype.byteorder == '>'):\n                    temp_x_data = temp_x_data.byteswap().newbyteorder()\n                if (temp_y_data.dtype.byteorder == '>'):\n                    temp_y_data = temp_y_data.byteswap().newbyteorder()\n                if (temp_v_data.dtype.byteorder == '>'):\n                    temp_v_data = temp_v_data.byteswap().newbyteorder()\n                \n                store_data(data_name, data={'x':temp_x_data, 'y':temp_y_data, 'v':temp_v_data})\n            else:\n                #Change from little endian to big endian, since pandas apparently hates little endian\n                #We might want to move this into the store_data procedure eventually\n                if (temp_x_data.dtype.byteorder == '>'):\n                    temp_x_data = temp_x_data.byteswap().newbyteorder()\n                if (temp_y_data.dtype.byteorder == '>'):\n                    temp_y_data = temp_y_data.byteswap().newbyteorder()\n                store_data(data_name, data={'x':temp_x_data, 'y':temp_y_data})\n            \n            if temp_tplot['dq'][i][3].dtype.names is not None:\n                for option_name in temp_tplot['dq'][i][3].dtype.names:\n                    options(data_name, option_name, temp_tplot['dq'][i][3][option_name][0])\n            \n            data_quants[data_name].trange =  temp_tplot['dq'][i][4].tolist()\n            data_quants[data_name].dtype =  temp_tplot['dq'][i][5]\n            data_quants[data_name].create_time =  temp_tplot['dq'][i][6]\n        \n            for option_name in temp_tplot['tv'][0][0].dtype.names:\n                if option_name == 'TRANGE':\n                    tplot_options('x_range', temp_tplot['tv'][0][0][option_name][0])\n                if option_name == 'WSIZE':\n                    tplot_options('wsize', temp_tplot['tv'][0][0][option_name][0])\n                if option_name == 'VAR_LABEL':\n                    tplot_options('var_label', temp_tplot['tv'][0][0][option_name][0])\n            if 'P' in temp_tplot['tv'][0][1].tolist():\n                for option_name in temp_tplot['tv'][0][1]['P'][0].dtype.names:\n                    if option_name == 'TITLE':\n                        tplot_options('title', temp_tplot['tv'][0][1]['P'][0][option_name][0])\n                \n        #temp_tplot['tv'][0][1] is all of the \"settings\" variables\n            #temp_tplot['tv'][0][1]['D'][0] is \"device\" options\n            #temp_tplot['tv'][0][1]['P'][0] is \"plot\" options\n            #temp_tplot['tv'][0][1]['X'][0] is x axis options\n            #temp_tplot['tv'][0][1]['Y'][0] is y axis options\n        ####################################################################\n    else:\n        temp = pickle.load(open(filename,\"rb\"))\n        num_data_quants = temp[0]\n        for i in range(0, num_data_quants):\n            data_quants[temp[i+1].name] = temp[i+1]\n        tplot_opt_glob = temp[num_data_quants+1]\n    \n    return", "response": "This function will restore the data contained in the IDL file and return the IDL file that was saved with the tplot_save command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tplot(name,\n          var_label=None,\n          auto_color=True,\n          interactive=False,\n          combine_axes=True,\n          nb=False,\n          save_file=None,\n          gui=False,\n          qt=False,\n          bokeh=False,\n          save_png=None,\n          display=True,\n          testing=False):\n    \"\"\"\n    This is the function used to display the tplot variables stored in memory.\n    The default output is to show the plots stacked on top of one another inside a GUI window.\n    The GUI window has the option to export the plots in either PNG or HTML formats.\n\n    .. note::\n        This plotting routine uses the python Bokeh library, which creates plots using HTML and Javascript.\n        Bokeh is technically still in beta, so future patches to Bokeh may require updates to this function.\n\n    Parameters:\n        name : str / list\n            List of tplot variables that will be plotted\n        var_label : str, optional\n            The name of the tplot variable you would like as\n            a second x axis.\n        auto_color : bool, optional\n            Automatically color the plot lines.\n        interactive : bool, optional\n            If True, a secondary interactive plot will be generated next to spectrogram plots.\n            Mousing over the spectrogram will display a slice of data from that time on the\n            interactive chart.\n        combine_axes : bool, optional\n            If True, the axes are combined so that they all display the same x range.  This also enables\n            scrolling/zooming/panning on one plot to affect all of the other plots simultaneously.\n        nb : bool, optional\n            If True, the plot will be displayed inside of a current Jupyter notebook session.\n        save_file : str, optional\n            A full file name and path.\n            If this option is set, the plot will be automatically saved to the file name provided in an HTML format.\n            The plots can then be opened and viewed on any browser without any requirements.\n        bokeh : bool, optional\n            If True, plots data using bokeh\n            Else (bokeh=False or omitted), plots data using PyQtGraph\n        gui : bool, optional\n            If True, then this function will output the 2 HTML components of the generated plots as string variables.\n            This is useful if you are embedded the plots in your own GUI.  For more information, see\n            http://bokeh.pydata.org/en/latest/docs/user_guide/embed.html\n        qt : bool, optional\n            If True, then this function will display the plot inside of the Qt window.  From this window, you\n            can choose to export the plots as either an HTML file, or as a PNG.\n        save_png : str, optional\n            A full file name and path.\n            If this option is set, the plot will be automatically saved to the file name provided in a PNG format.\n        display: bool, optional\n            If True, then this function will display the plotted tplot variables. Necessary to make this optional\n            so we can avoid it in a headless server environment.\n        testing: bool, optional\n            If True, doesn't run the '(hasattr(sys, 'ps1'))' line that makes plots interactive - i.e., avoiding issues\n\n    Returns:\n        None\n\n    Examples:\n        >>> #Plot a single line in bokeh\n        >>> import pytplot\n        >>> x_data = [2,3,4,5,6]\n        >>> y_data = [1,2,3,4,5]\n        >>> pytplot.store_data(\"Variable1\", data={'x':x_data, 'y':y_data})\n        >>> pytplot.tplot(\"Variable1\",bokeh=True)\n\n        >>> #Display two plots\n        >>> x_data = [1,2,3,4,5]\n        >>> y_data = [[1,5],[2,4],[3,3],[4,2],[5,1]]\n        >>> pytplot.store_data(\"Variable2\", data={'x':x_data, 'y':y_data})\n        >>> pytplot.tplot([\"Variable1\", \"Variable2\"])\n\n        >>> #Display 2 plots, using Variable1 as another x axis\n        >>> x_data = [1,2,3]\n        >>> y_data = [ [1,2,3] , [4,5,6], [7,8,9] ]\n        >>> v_data = [1,2,3]\n        >>> pytplot.store_data(\"Variable3\", data={'x':x_data, 'y':y_data, 'v':v_data})\n        >>> pytplot.options(\"Variable3\", 'spec', 1)\n        >>> pytplot.tplot([\"Variable2\", \"Variable3\"], var_label='Variable1')\n\n        >>> #Plot all 3 tplot variables, sending the output to an HTML file\n        >>> pytplot.tplot([\"Variable1\", \"Variable2\", \"Variable3\"], save_file='C:/temp/pytplot_example.html')\n\n        >>> #Plot all 3 tplot variables, sending the HTML output to a pair of strings\n        >>> div, component = pytplot.tplot([\"Variable1\", \"Variable2\", \"Variable3\"], gui=True)\n    \"\"\"\n\n    if not pytplot.using_graphics and save_file is None:\n        print(\"Qt was not successfully imported.  Specify save_file to save the file as a .html file.\")\n        return\n    # Check a bunch of things\n    if not isinstance(name, list):\n        name = [name]\n        num_plots = 1\n    else:\n        num_plots = len(name)\n\n    for i in range(num_plots):\n        if isinstance(name[i], int):\n            name[i] = list(pytplot.data_quants.keys())[name[i]]\n        if name[i] not in pytplot.data_quants.keys():\n            print(str(i) + \" is currently not in pytplot\")\n            return\n\n    if isinstance(var_label, int):\n        var_label = list(pytplot.data_quants.keys())[var_label]\n\n    if bokeh:\n        layout = HTMLPlotter.generate_stack(name, var_label=var_label, auto_color=auto_color, combine_axes=combine_axes,\n                                            interactive=interactive)\n        # Output types\n        if gui:\n            script, div = components(layout)\n            return script, div\n        elif nb:\n            output_notebook()\n            show(layout)\n            return\n        elif save_file is not None:\n            output_file(save_file, mode='inline')\n            save(layout)\n            return\n        elif qt:\n            available_qt_window = tplot_utilities.get_available_qt_window()\n            dir_path = tempfile.gettempdir()  # send to user's temp directory\n            output_file(os.path.join(dir_path, \"temp.html\"), mode='inline')\n            save(layout)\n            new_layout = WebView()\n            available_qt_window.resize(pytplot.tplot_opt_glob['window_size'][0] + 100,\n                                       pytplot.tplot_opt_glob['window_size'][1] + 100)\n            new_layout.resize(pytplot.tplot_opt_glob['window_size'][0], pytplot.tplot_opt_glob['window_size'][1])\n            dir_path = tempfile.gettempdir()  # send to user's temp directory\n            new_layout.setUrl(QtCore.QUrl.fromLocalFile(os.path.join(dir_path, \"temp.html\")))\n            available_qt_window.newlayout(new_layout)\n            available_qt_window.show()\n            available_qt_window.activateWindow()\n            if testing:\n                return\n            if not (hasattr(sys, 'ps1')) or not hasattr(QtCore, 'PYQT_VERSION'):\n                QtGui.QApplication.instance().exec_()\n            return\n        else:\n            dir_path = tempfile.gettempdir()  # send to user's temp directory\n            output_file(os.path.join(dir_path, \"temp.html\"), mode='inline')\n            show(layout)\n            return\n    else:\n        if save_png is not None:\n            layout = QtPlotter.generate_stack(name, var_label=var_label, combine_axes=combine_axes,\n                                              mouse_moved_event=pytplot.hover_time.change_hover_time)\n            layout.resize(pytplot.tplot_opt_glob['window_size'][0], pytplot.tplot_opt_glob['window_size'][1])\n            for i, item in enumerate(layout.items()):\n                if type(item) == pg.graphicsItems.GraphicsLayout.GraphicsLayout:\n                    layout.items()[i].resize(pytplot.tplot_opt_glob['window_size'][0],\n                                             pytplot.tplot_opt_glob['window_size'][1])\n            exporter = PyTPlot_Exporter.PytplotExporter(layout)\n            exporter.parameters()['width'] = pytplot.tplot_opt_glob['window_size'][0]\n            exporter.parameters()['height'] = pytplot.tplot_opt_glob['window_size'][1]\n            exporter.export(save_png)\n\n        if display:\n            # Set up all things needed for when a user asks to save plot from window\n            layout_orig = QtPlotter.generate_stack(name, var_label=var_label, combine_axes=combine_axes,\n                                                   mouse_moved_event=pytplot.hover_time.change_hover_time)\n            layout_orig.resize(pytplot.tplot_opt_glob['window_size'][0], pytplot.tplot_opt_glob['window_size'][1])\n            for i, item in enumerate(layout_orig.items()):\n                if type(item) == pg.graphicsItems.GraphicsLayout.GraphicsLayout:\n                    layout_orig.items()[i].resize(pytplot.tplot_opt_glob['window_size'][0],\n                                                  pytplot.tplot_opt_glob['window_size'][1])\n            exporter = QtPlotter.PytplotExporter(layout_orig)\n\n            # Set up displayed plot window and grab plots to plot on it\n            available_qt_window = tplot_utilities.get_available_qt_window()\n            layout = QtPlotter.generate_stack(name, var_label=var_label, combine_axes=combine_axes,\n                                              mouse_moved_event=pytplot.hover_time.change_hover_time)\n\n            available_qt_window.newlayout(layout)\n            available_qt_window.resize(pytplot.tplot_opt_glob['window_size'][0],\n                                       pytplot.tplot_opt_glob['window_size'][1])\n\n            # Implement button that lets you save the PNG\n            available_qt_window.init_savepng(exporter)\n\n            # Show the plot window and plot\n            available_qt_window.show()\n            available_qt_window.activateWindow()\n\n            if interactive:\n                # Call 2D interactive window; This will only plot something when spectrograms are involved.\n                interactiveplot.interactiveplot()\n\n            static_list = [i for i in name if 'static' in pytplot.data_quants[i].extras]\n            for tplot_var in static_list:\n                # Call 2D static window; This will only plot something when spectrograms are involved.\n                staticplot.static2dplot(tplot_var, pytplot.data_quants[tplot_var].extras['static'])\n\n            static_tavg_list = [i for i in name if 'static_tavg' in pytplot.data_quants[i].extras]\n            for tplot_var in static_tavg_list:\n                # Call 2D static window for time-averaged values; This will only plot something when spectrograms\n                # are involved\n                staticplot_tavg.static2dplot_timeaveraged(\n                    tplot_var, pytplot.data_quants[tplot_var].extras['static_tavg'])\n\n            # (hasattr(sys, 'ps1')) checks to see if we're in ipython\n            # plots the plots!\n            if testing:\n                return\n            if not (hasattr(sys, 'ps1')) or not hasattr(QtCore, 'PYQT_VERSION'):\n                QtGui.QApplication.instance().exec_()\n\n        return", "response": "This function displays the tplot variables stored in memory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef static2dplot_timeaveraged(var, time):\n\n    # Grab names of data loaded in as tplot variables.\n    names = list(pytplot.data_quants.keys())\n    # Get data we'll actually work with here.\n    valid_variables = tplot_utilities.get_data(names)\n\n    # Don't plot anything unless we have spectrograms with which to work.\n    if valid_variables:\n        # Get z label\n        labels = tplot_utilities.get_labels_axis_types(names)\n\n        # Put together data in easy-to-access format for plots.\n        data = {}\n        for name in valid_variables:\n            bins = tplot_utilities.get_bins(name)\n            time_values, z_values = tplot_utilities.get_z_t_values(name)\n            data[name] = [bins, z_values, time_values]\n\n        # Set up the 2D static plot\n        pytplot.static_tavg_window = pg.GraphicsWindow()\n        pytplot.static_tavg_window.resize(1000, 600)\n        pytplot.static_tavg_window.setWindowTitle('Time-Averaged Values Static Window')\n        plot = pytplot.static_tavg_window.addPlot(title='2D Static Plot for Time-Averaged Values', row=0, col=0)\n        # Make it so that whenever this first starts up, you just have an empty plot\n        plot_data = plot.plot([], [])\n\n        if var in valid_variables:\n            # Get min/max values of data's time range (in both datetime and seconds since epoch)\n            t_min = np.nanmin(time_values)\n            t_min_str = tplot_utilities.int_to_str(np.nanmin(time_values))\n            t_min_conv_back = tplot_utilities.str_to_int(t_min_str)\n            t_max = np.nanmax(time_values)\n            t_max_str = tplot_utilities.int_to_str(np.nanmax(time_values))\n            t_max_conv_back = tplot_utilities.str_to_int(t_max_str)\n            # Convert user input to seconds since epoch\n            user_time = [tplot_utilities.str_to_int(i) for i in time]\n\n            # Covering situation where user entered a time not in the dataset!\n            # As long as they used a time in the dataset, this will not trigger.\n            for t, datetime in enumerate(user_time):\n                if datetime not in range(t_min_conv_back, t_max_conv_back+1):\n                    while True:\n                        try:\n                            if t == 0:\n                                time_bound = 'left bound'\n                            else:\n                                time_bound = 'right bound'\n                            user_time[t] = tplot_utilities.str_to_int(input(\n                                'Chosen {} time [{}] not in range of data [{} to {}]. Input new time (%Y-%m-%d %H:%M:%S).'.format(\n                                    time_bound, tplot_utilities.int_to_str(datetime), t_min_str, t_max_str)))\n                        except ValueError:\n                            continue\n                        else:\n                            if user_time[t] not in range(int(t_min), int(t_max)):\n                                continue\n                            else:\n                                break\n\n            # Get index of the time closest to the user's time choice\n            time_array = np.array(data[var][2])\n            array = np.asarray(time_array)\n            idx = [(np.abs(array - i)).argmin() for i in user_time]\n\n            # Average values based on the chosen time range's indices\n            time_diff = abs(idx[0]-idx[1])\n            # Make sure to account for edge problem\n            if idx[1] != -1:\n                y_values_slice = data[name][1][idx[0]:idx[1]+1]\n            else:\n                y_values_slice = data[name][1][idx[0]:]\n            y_values_avgd = np.nansum(y_values_slice, axis=0)/np.float(time_diff)\n\n            # If user indicated they wanted the interactive plot's axes to be logged, log 'em.\n            # But first make sure that values in x and y are loggable!\n            x_axis = False\n            y_axis = False\n            # Checking x axis\n            if np.nanmin(data[name][0][:]) < 0:\n                print('Negative data is incompatible with log plotting.')\n            elif np.nanmin(data[name][0][:]) >= 0 and labels[name][2] == 'log':\n                x_axis = True\n            # Checking y axis\n            if np.nanmin(list(data[name][1][idx[0]])) < 0 or np.nanmin(list(data[name][1][idx[1]])) < 0:\n                print('Negative data is incompatible with log plotting')\n            elif np.nanmin(list(data[name][1][idx[0]])) >= 0 and np.nanmin(list(data[name][1][idx[1]])) >= 0 and \\\n                    labels[name][3] == 'log':\n                y_axis = True\n\n            # Set plot labels\n            plot.setLabel('bottom', '{}'.format(labels[name][0]))\n            plot.setLabel('left', '{}'.format(labels[name][1]))\n            plot.setLogMode(x=x_axis, y=y_axis)\n            # Update x and y range if user modified it\n            tplot_utilities.set_x_range(name, x_axis, plot)\n            tplot_utilities.set_y_range(name, y_axis, plot)\n            # Plot data based on time we're hovering over\n            plot_data.setData(data[var][0][:], y_values_avgd)", "response": "This function will plot the static 2D static plot for the specified variable and time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef timestamp(val):  \n    \n    \n    \n    if val is 'on':\n        todaystring = datetime.datetime.now().strftime('%Y-%m-%d %H%M%S')\n        extra_layouts['time_stamp'] = todaystring\n    else:\n        if 'time_stamp' in extra_layouts:\n            del extra_layouts['time_stamp']\n    \n    return", "response": "This function will turn on a time stamp that shows up at the bottom of every generated plot."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef paint(self, p, *args):\n        '''\n        I have no idea why, but we need to generate the picture after painting otherwise \n        it draws incorrectly.  \n        '''\n        if self.picturenotgened:\n            self.generatePicture(self.getBoundingParents()[0].rect())\n            self.picturenotgened = False\n        pg.ImageItem.paint(self, p, *args)\n        self.generatePicture(self.getBoundingParents()[0].rect())", "response": "This method is called by the PGImageItem class when painting. It generates the picture if needed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the image of the item.", "response": "def setImage(self, image=None, autoLevels=None, **kargs):\n        \"\"\"\n        Same this as ImageItem.setImage, but we don't update the drawing\n        \"\"\"\n        \n        profile = debug.Profiler()\n\n        gotNewData = False\n        if image is None:\n            if self.image is None:\n                return\n        else:\n            gotNewData = True\n            shapeChanged = (self.image is None or image.shape != self.image.shape)\n            image = image.view(np.ndarray)\n            if self.image is None or image.dtype != self.image.dtype:\n                self._effectiveLut = None\n            self.image = image\n            if self.image.shape[0] > 2**15-1 or self.image.shape[1] > 2**15-1:\n                if 'autoDownsample' not in kargs:\n                    kargs['autoDownsample'] = True\n            if shapeChanged:\n                self.prepareGeometryChange()\n                self.informViewBoundsChanged()\n\n        profile()\n\n        if autoLevels is None:\n            if 'levels' in kargs:\n                autoLevels = False\n            else:\n                autoLevels = True\n        if autoLevels:\n            img = self.image\n            while img.size > 2**16:\n                img = img[::2, ::2]\n            mn, mx = img.min(), img.max()\n            if mn == mx:\n                mn = 0\n                mx = 255\n            kargs['levels'] = [mn,mx]\n\n        profile()\n\n        self.setOpts(update=False, **kargs)\n\n        profile()\n\n        self.qimage = None\n        self.update()\n\n        profile()\n\n        if gotNewData:\n            self.sigImageChanged.emit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getPaintItems(self, root=None):\n        if root is None:\n            root = self.item\n        preItems = []\n        postItems = []\n        if isinstance(root, QtGui.QGraphicsScene):\n            childs = [i for i in root.items() if i.parentItem() is None]\n            rootItem = []\n        else:\n            # CHANGE: For GraphicsLayouts, there is no function for childItems(), so I just\n            # replaced it with .items()\n            try:\n                childs = root.childItems()\n            except:\n                childs = root.items()\n            rootItem = [root]\n        childs.sort(key=lambda a: a.zValue())\n        while len(childs) > 0:\n            ch = childs.pop(0)\n            tree = self.getPaintItems(ch)\n\n            if int(ch.flags() & ch.ItemStacksBehindParent) > 0 or (\n                    ch.zValue() < 0 and int(ch.flags() & ch.ItemNegativeZStacksBehindParent) > 0):\n                preItems.extend(tree)\n            else:\n                postItems.extend(tree)\n        return preItems + rootItem + postItems", "response": "Return a list of all items that should be painted in the correct order."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns normalization on a network.", "response": "def run_norm(net, df=None, norm_type='zscore', axis='row', keep_orig=False):\n  '''\n  A dataframe (more accurately a dictionary of dataframes, e.g. mat,\n  mat_up...) can be passed to run_norm and a normalization will be run (\n  e.g. zscore) on either the rows or columns\n  '''\n\n  # df here is actually a dictionary of several dataframes, 'mat', 'mat_orig',\n  # etc\n  if df is None:\n    df = net.dat_to_df()\n\n  if norm_type == 'zscore':\n    df = zscore_df(df, axis, keep_orig)\n\n  if norm_type == 'qn':\n    df = qn_df(df, axis, keep_orig)\n\n  net.df_to_dat(df)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef qn_df(df, axis='row', keep_orig=False):\n  '''\n  do quantile normalization of a dataframe dictionary, does not write to net\n  '''\n  df_qn = {}\n\n  for mat_type in df:\n    inst_df = df[mat_type]\n\n    # using transpose to do row qn\n    if axis == 'row':\n      inst_df = inst_df.transpose()\n\n    missing_values = inst_df.isnull().values.any()\n\n    # make mask of missing values\n    if missing_values:\n\n      # get nan mask\n      missing_mask = pd.isnull(inst_df)\n\n      # tmp fill in na with zero, will not affect qn\n      inst_df = inst_df.fillna(value=0)\n\n    # calc common distribution\n    common_dist = calc_common_dist(inst_df)\n\n    # swap in common distribution\n    inst_df = swap_in_common_dist(inst_df, common_dist)\n\n    # swap back in missing values\n    if missing_values:\n      inst_df = inst_df.mask(missing_mask, other=np.nan)\n\n    # using transpose to do row qn\n    if axis == 'row':\n      inst_df = inst_df.transpose()\n\n    df_qn[mat_type] = inst_df\n\n  return df_qn", "response": "do quantile normalization of a dataframe dictionary does not write to net\n "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_common_dist(df):\n  '''\n  calculate a common distribution (for col qn only) that will be used to qn\n  '''\n\n  # axis is col\n  tmp_arr = np.array([])\n\n  col_names = df.columns.tolist()\n\n  for inst_col in col_names:\n\n    # sort column\n    tmp_vect = df[inst_col].sort_values(ascending=False).values\n\n    # stacking rows vertically (will transpose)\n    if tmp_arr.shape[0] == 0:\n      tmp_arr = tmp_vect\n    else:\n      tmp_arr = np.vstack((tmp_arr, tmp_vect))\n\n  tmp_arr = tmp_arr.transpose()\n\n  common_dist = tmp_arr.mean(axis=1)\n\n  return common_dist", "response": "calculate a common distribution for col qn only"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zscore_df(df, axis='row', keep_orig=False):\n  '''\n  take the zscore of a dataframe dictionary, does not write to net (self)\n  '''\n  df_z = {}\n\n  for mat_type in df:\n    if keep_orig and mat_type == 'mat':\n      mat_orig = deepcopy(df[mat_type])\n\n    inst_df = df[mat_type]\n\n    if axis == 'row':\n      inst_df = inst_df.transpose()\n\n    df_z[mat_type] = (inst_df - inst_df.mean())/inst_df.std()\n\n    if axis == 'row':\n      df_z[mat_type] = df_z[mat_type].transpose()\n\n  if keep_orig:\n    df_z['mat_orig'] = mat_orig\n\n  return df_z", "response": "take the zscore of a dataframe dictionary does not write to net"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate pvalue of category closeness \u2192 calculate pvalue of category closeness \u2192 calculate pvalue of category closeness \u2192 calculate pvalue of category closeness \u2192 calculate pvalue of category closeness \u2192 calculate pvalue of category closeness \u2192 calculate pvalue of category closeness \u2192 calculate pvalue of category closeness", "response": "def main(net):\n  '''\n  calculate pvalue of category closeness\n  '''\n  # calculate the distance between the data points within the same category and\n  # compare to null distribution\n  for inst_rc in ['row', 'col']:\n\n    inst_nodes = deepcopy(net.dat['nodes'][inst_rc])\n\n    inst_index = deepcopy(net.dat['node_info'][inst_rc]['clust'])\n\n    # reorder based on clustered order\n    inst_nodes = [ inst_nodes[i] for i in inst_index]\n\n    # make distance matrix dataframe\n    dm = dist_matrix_lattice(inst_nodes)\n\n    node_infos = list(net.dat['node_info'][inst_rc].keys())\n\n    all_cats = []\n    for inst_info in node_infos:\n      if 'dict_cat_' in inst_info:\n        all_cats.append(inst_info)\n\n    for cat_dict in all_cats:\n\n      tmp_dict = net.dat['node_info'][inst_rc][cat_dict]\n\n      pval_name = cat_dict.replace('dict_','pval_')\n      net.dat['node_info'][inst_rc][pval_name] = {}\n\n      for cat_name in tmp_dict:\n\n        subset = tmp_dict[cat_name]\n\n        inst_median = calc_median_dist_subset(dm, subset)\n\n        hist = calc_hist_distances(dm, subset, inst_nodes)\n\n        pval = 0\n\n        for i in range(len(hist['prob'])):\n          if i == 0:\n            pval = hist['prob'][i]\n          if i >= 1:\n            if inst_median >= hist['bins'][i]:\n              pval = pval + hist['prob'][i]\n\n        net.dat['node_info'][inst_rc][pval_name][cat_name] = pval"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef df_to_dat(net, df, define_cat_colors=False):\n  '''\n  This is always run when data is loaded.\n  '''\n  from . import categories\n\n  # check if df has unique values\n  df['mat'] = make_unique_labels.main(net, df['mat'])\n\n  net.dat['mat'] = df['mat'].values\n  net.dat['nodes']['row'] = df['mat'].index.tolist()\n  net.dat['nodes']['col'] = df['mat'].columns.tolist()\n\n  for inst_rc in ['row', 'col']:\n\n    if type(net.dat['nodes'][inst_rc][0]) is tuple:\n      # get the number of categories from the length of the tuple\n      # subtract 1 because the name is the first element of the tuple\n      num_cat = len(net.dat['nodes'][inst_rc][0]) - 1\n\n      net.dat['node_info'][inst_rc]['full_names'] = net.dat['nodes']\\\n          [inst_rc]\n\n      for inst_rcat in range(num_cat):\n        net.dat['node_info'][inst_rc]['cat-' + str(inst_rcat)] = \\\n          [i[inst_rcat + 1] for i in net.dat['nodes'][inst_rc]]\n\n      net.dat['nodes'][inst_rc] = [i[0] for i in net.dat['nodes'][inst_rc]]\n\n  if 'mat_up' in df:\n    net.dat['mat_up'] = df['mat_up'].values\n    net.dat['mat_dn'] = df['mat_dn'].values\n\n  if 'mat_orig' in df:\n    net.dat['mat_orig'] = df['mat_orig'].values\n\n  categories.dict_cat(net, define_cat_colors=define_cat_colors)", "response": "This function takes a DataFrame and converts it to a dictionary of data structures."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert list to numpy array", "response": "def mat_to_numpy_arr(self):\n  ''' convert list to numpy array - numpy arrays can not be saved as json '''\n  import numpy as np\n  self.dat['mat'] = np.asarray(self.dat['mat'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclustering net. dat and make visualization json and net. viz.", "response": "def cluster_row_and_col(net, dist_type='cosine', linkage_type='average',\n                        dendro=True, run_clustering=True, run_rank=True,\n                        ignore_cat=False, calc_cat_pval=False, links=False):\n  ''' cluster net.dat and make visualization json, net.viz.\n  optionally leave out dendrogram colorbar groups with dendro argument '''\n\n  import scipy\n  from copy import deepcopy\n  from scipy.spatial.distance import pdist\n  from . import categories, make_viz, cat_pval\n\n  dm = {}\n  for inst_rc in ['row', 'col']:\n\n    tmp_mat = deepcopy(net.dat['mat'])\n    dm[inst_rc] = calc_distance_matrix(tmp_mat, inst_rc, dist_type)\n\n    # save directly to dat structure\n    node_info = net.dat['node_info'][inst_rc]\n\n    node_info['ini'] = list(range( len(net.dat['nodes'][inst_rc]), -1, -1))\n\n    # cluster\n    if run_clustering is True:\n      node_info['clust'], node_info['group'] = \\\n          clust_and_group(net, dm[inst_rc], linkage_type=linkage_type)\n    else:\n      dendro = False\n      node_info['clust'] = node_info['ini']\n\n    # sorting\n    if run_rank is True:\n      node_info['rank'] = sort_rank_nodes(net, inst_rc, 'sum')\n      node_info['rankvar'] = sort_rank_nodes(net, inst_rc, 'var')\n    else:\n      node_info['rank'] = node_info['ini']\n      node_info['rankvar'] = node_info['ini']\n\n    ##################################\n    if ignore_cat is False:\n      categories.calc_cat_clust_order(net, inst_rc)\n\n  if calc_cat_pval is True:\n    cat_pval.main(net)\n\n  # make the visualization json\n  make_viz.viz_json(net, dendro, links)\n\n  return dm"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding out how many row and col categories are available \u00b0C", "response": "def check_categories(lines):\n  '''\n  find out how many row and col categories are available\n  '''\n  # count the number of row categories\n  rcat_line = lines[0].split('\\t')\n\n  # calc the number of row names and categories\n  num_rc = 0\n  found_end = False\n\n  # skip first tab\n  for inst_string in rcat_line[1:]:\n    if inst_string == '':\n      if found_end is False:\n        num_rc = num_rc + 1\n    else:\n      found_end = True\n\n  max_rcat = 15\n  if max_rcat > len(lines):\n    max_rcat = len(lines) - 1\n\n  num_cc = 0\n  for i in range(max_rcat):\n    ccat_line = lines[i + 1].split('\\t')\n\n    # make sure that line has length greater than one to prevent false cats from\n    # trailing new lines at end of matrix\n    if ccat_line[0] == '' and len(ccat_line) > 1:\n      num_cc = num_cc + 1\n\n  num_labels = {}\n  num_labels['row'] = num_rc + 1\n  num_labels['col'] = num_cc + 1\n\n  return num_labels"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_cat(net, define_cat_colors=False):\n  '''\n  make a dictionary of node-category associations\n  '''\n\n  # print('---------------------------------')\n  # print('---- dict_cat: before setting cat colors')\n  # print('---------------------------------\\n')\n  # print(define_cat_colors)\n  # print(net.viz['cat_colors'])\n\n  net.persistent_cat = True\n\n  for inst_rc in ['row', 'col']:\n    inst_keys = list(net.dat['node_info'][inst_rc].keys())\n    all_cats = [x for x in inst_keys if 'cat-' in x]\n\n    for inst_name_cat in all_cats:\n\n      dict_cat = {}\n      tmp_cats = net.dat['node_info'][inst_rc][inst_name_cat]\n      tmp_nodes = net.dat['nodes'][inst_rc]\n\n      for i in range(len(tmp_cats)):\n        inst_cat = tmp_cats[i]\n        inst_node = tmp_nodes[i]\n\n        if inst_cat not in dict_cat:\n          dict_cat[inst_cat] = []\n\n        dict_cat[inst_cat].append(inst_node)\n\n      tmp_name = 'dict_' + inst_name_cat.replace('-', '_')\n      net.dat['node_info'][inst_rc][tmp_name] = dict_cat\n\n  # merge with old cat_colors by default\n  cat_colors = net.viz['cat_colors']\n\n  if define_cat_colors == True:\n    cat_number = 0\n\n    for inst_rc in ['row', 'col']:\n\n      inst_keys = list(net.dat['node_info'][inst_rc].keys())\n      all_cats = [x for x in inst_keys if 'cat-' in x]\n\n      for cat_index in all_cats:\n\n        if cat_index not in cat_colors[inst_rc]:\n          cat_colors[inst_rc][cat_index] = {}\n\n        cat_names = sorted(list(set(net.dat['node_info'][inst_rc][cat_index])))\n\n        # loop through each category name and assign a color\n        for tmp_name in cat_names:\n\n          # using the same rules as the front-end to define cat_colors\n          inst_color = get_cat_color(cat_number + cat_names.index(tmp_name))\n\n          check_name = tmp_name\n\n          # check if category is string type and non-numeric\n          try:\n            float(check_name)\n            is_string_cat = False\n          except:\n            is_string_cat = True\n\n          if is_string_cat == True:\n            # check for default non-color\n            if ': ' in check_name:\n              check_name = check_name.split(': ')[1]\n\n            # if check_name == 'False' or check_name == 'false':\n            if 'False' in check_name or 'false' in check_name:\n              inst_color = '#eee'\n\n            if 'Not ' in check_name:\n              inst_color = '#eee'\n\n          # print('cat_colors')\n          # print('----------')\n          # print(cat_colors[inst_rc][cat_index])\n\n          # do not overwrite old colors\n          if tmp_name not in cat_colors[inst_rc][cat_index] and is_string_cat:\n\n            cat_colors[inst_rc][cat_index][tmp_name] = inst_color\n            # print('overwrite: ' + tmp_name + ' -> ' + str(inst_color))\n\n          cat_number = cat_number + 1\n\n    net.viz['cat_colors'] = cat_colors", "response": "make a dictionary of node - category associations\n \u00b0C"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the clustering ordering of the cluster categories in the given node info.", "response": "def calc_cat_clust_order(net, inst_rc):\n  '''\n  cluster category subset of data\n  '''\n  from .__init__ import Network\n  from copy import deepcopy\n  from . import calc_clust, run_filter\n\n  inst_keys = list(net.dat['node_info'][inst_rc].keys())\n  all_cats = [x for x in inst_keys if 'cat-' in x]\n\n  if len(all_cats) > 0:\n\n    for inst_name_cat in all_cats:\n\n      tmp_name = 'dict_' + inst_name_cat.replace('-', '_')\n      dict_cat = net.dat['node_info'][inst_rc][tmp_name]\n\n      unordered_cats = dict_cat.keys()\n\n      ordered_cats = order_categories(unordered_cats)\n\n      # this is the ordering of the columns based on their category, not\n      # including their clustering ordering within category\n      all_cat_orders = []\n      tmp_names_list = []\n      for inst_cat in ordered_cats:\n\n        inst_nodes = dict_cat[inst_cat]\n\n        tmp_names_list.extend(inst_nodes)\n\n      #   cat_net = deepcopy(Network())\n\n      #   cat_net.dat['mat'] = deepcopy(net.dat['mat'])\n      #   cat_net.dat['nodes'] = deepcopy(net.dat['nodes'])\n\n      #   cat_df = cat_net.dat_to_df()\n\n      #   sub_df = {}\n      #   if inst_rc == 'col':\n      #     sub_df['mat'] = cat_df['mat'][inst_nodes]\n      #   elif inst_rc == 'row':\n      #     # need to transpose df\n      #     cat_df['mat'] = cat_df['mat'].transpose()\n      #     sub_df['mat'] = cat_df['mat'][inst_nodes]\n      #     sub_df['mat'] = sub_df['mat'].transpose()\n\n      #   # filter matrix before clustering\n      #   ###################################\n      #   threshold = 0.0001\n      #   sub_df = run_filter.df_filter_row_sum(sub_df, threshold)\n      #   sub_df = run_filter.df_filter_col_sum(sub_df, threshold)\n\n      #   # load back to dat\n      #   cat_net.df_to_dat(sub_df)\n\n      #   cat_mat_shape = cat_net.dat['mat'].shape\n\n      #   print('***************')\n      #   try:\n      #     if cat_mat_shape[0]>1 and cat_mat_shape[1] > 1 and all_are_numbers == False:\n\n      #       calc_clust.cluster_row_and_col(cat_net, 'cos')\n      #       inst_cat_order = cat_net.dat['node_info'][inst_rc]['clust']\n      #     else:\n      #       inst_cat_order = list(range(len(cat_net.dat['nodes'][inst_rc])))\n\n      #   except:\n      #     inst_cat_order = list(range(len(cat_net.dat['nodes'][inst_rc])))\n\n\n      #   prev_order_len = len(all_cat_orders)\n\n      #   # add prev order length to the current order number\n      #   inst_cat_order = [i + prev_order_len for i in inst_cat_order]\n      #   all_cat_orders.extend(inst_cat_order)\n\n      # # generate ordered list of row/col names, which will be used to\n      # # assign the order to specific nodes\n      # names_clust_list = [x for (y, x) in sorted(zip(all_cat_orders,\n      #                     tmp_names_list))]\n\n      names_clust_list = tmp_names_list\n\n      # calc category-cluster order\n      final_order = []\n\n      for i in range(len(net.dat['nodes'][inst_rc])):\n\n        inst_node_name = net.dat['nodes'][inst_rc][i]\n        inst_node_num = names_clust_list.index(inst_node_name)\n\n        final_order.append(inst_node_num)\n\n      inst_index_cat = inst_name_cat.replace('-', '_') + '_index'\n\n      net.dat['node_info'][inst_rc][inst_index_cat] = final_order"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef order_categories(unordered_cats):\n  '''\n  If categories are strings, then simple ordering is fine.\n  If categories are values then I'll need to order based on their values.\n  The final ordering is given as the original categories (including titles) in a\n  ordered list.\n  '''\n\n  no_titles = remove_titles(unordered_cats)\n\n  all_are_numbers = check_all_numbers(no_titles)\n\n  if all_are_numbers:\n    ordered_cats = order_cats_based_on_values(unordered_cats, no_titles)\n  else:\n    ordered_cats = sorted(unordered_cats)\n\n  return ordered_cats", "response": "Order the categories in a\n."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads file as a string.", "response": "def load_file_as_string(self, file_string, filename=''):\n    '''\n    Load file as a string.\n    '''\n    load_data.load_file_as_string(self, file_string, filename=filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading Clustergrammer s dat format saved as JSON.", "response": "def load_data_file_to_net(self, filename):\n    '''\n    Load Clustergrammer's dat format (saved as JSON).\n    '''\n    inst_dat = self.load_json_to_dict(filename)\n    load_data.load_data_to_net(self, inst_dat)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads Pandas DataFrame. Load Pandas DataFrame.", "response": "def load_df(self, df):\n    '''\n    Load Pandas DataFrame.\n    '''\n    # self.__init__()\n    self.reset()\n\n    df_dict = {}\n    df_dict['mat'] = deepcopy(df)\n    # always define category colors if applicable when loading a df\n    data_formats.df_to_dat(self, df_dict, define_cat_colors=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload Pandas DataFrame into a dat file.", "response": "def df_to_dat(self, df, define_cat_colors=False):\n    '''\n    Load Pandas DataFrame (will be deprecated).\n    '''\n    data_formats.df_to_dat(self, df, define_cat_colors)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef widget(self, which_viz='viz'):\n    '''\n    Generate a widget visualization using the widget. The export_viz_to_widget\n    method passes the visualization JSON to the instantiated widget, which is\n    returned and visualized on the front-end.\n    '''\n    if hasattr(self, 'widget_class') == True:\n\n      # run clustering if necessary\n      if len(self.viz['row_nodes']) == 0:\n        self.cluster()\n\n      self.widget_instance = self.widget_class(network = self.export_viz_to_widget(which_viz))\n\n      return self.widget_instance\n    else:\n      print('Can not make widget because Network has no attribute widget_class')\n      print('Please instantiate Network with clustergrammer_widget using: Network(clustergrammer_widget)')", "response": "Generate a widget visualization using the widget class"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef widget_df(self):\n    '''\n    Export a DataFrame from the front-end visualization. For instance, a user\n    can filter to show only a single cluster using the dendrogram and then\n    get a dataframe of this cluster using the widget_df method.\n    '''\n\n    if hasattr(self, 'widget_instance') == True:\n\n      if self.widget_instance.mat_string != '':\n\n        tmp_net = deepcopy(Network())\n\n        df_string = self.widget_instance.mat_string\n\n        tmp_net.load_file_as_string(df_string)\n\n        df = tmp_net.export_df()\n\n        return df\n\n      else:\n        return self.export_df()\n\n    else:\n      if hasattr(self, 'widget_class') == True:\n        print('Please make the widget before exporting the widget DataFrame.')\n        print('Do this using the widget method: net.widget()')\n\n      else:\n        print('Can not make widget because Network has no attribute widget_class')\n        print('Please instantiate Network with clustergrammer_widget using: Network(clustergrammer_widget)')", "response": "Export a DataFrame from the front - end visualization."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_json_to_file(self, net_type, filename, indent='no-indent'):\n    '''\n    Save dat or viz as a JSON to file.\n    '''\n    export_data.write_json_to_file(self, net_type, filename, indent)", "response": "Save dat or viz as a JSON to file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters a network based on the sum across rows or columns.", "response": "def filter_sum(self, inst_rc, threshold, take_abs=True):\n    '''\n    Filter a network's rows or columns based on the sum across rows or columns.\n    '''\n    inst_df = self.dat_to_df()\n    if inst_rc == 'row':\n      inst_df = run_filter.df_filter_row_sum(inst_df, threshold, take_abs)\n    elif inst_rc == 'col':\n      inst_df = run_filter.df_filter_col_sum(inst_df, threshold, take_abs)\n    self.df_to_dat(inst_df)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters the matrix rows or columns based on sum / variance and only keep the top N.", "response": "def filter_N_top(self, inst_rc, N_top, rank_type='sum'):\n    '''\n    Filter the matrix rows or columns based on sum/variance, and only keep the top\n    N.\n    '''\n    inst_df = self.dat_to_df()\n\n    inst_df = run_filter.filter_N_top(inst_rc, inst_df, N_top, rank_type)\n\n    self.df_to_dat(inst_df)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_threshold(self, inst_rc, threshold, num_occur=1):\n    '''\n    Filter the matrix rows or columns based on num_occur values being above a\n    threshold (in absolute value).\n    '''\n    inst_df = self.dat_to_df()\n\n    inst_df = run_filter.filter_threshold(inst_df, inst_rc, threshold,\n      num_occur)\n\n    self.df_to_dat(inst_df)", "response": "Filter the matrix rows or columns based on num_occur values being above threshold."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiltering the matrix based on their category.", "response": "def filter_cat(self, axis, cat_index, cat_name):\n    '''\n    Filter the matrix based on their category. cat_index is the index of the category, the first category has index=1.\n    '''\n    run_filter.filter_cat(self, axis, cat_index, cat_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clip(self, lower=None, upper=None):\n    '''\n    Trim values at input thresholds using pandas function\n    '''\n    df = self.export_df()\n    df = df.clip(lower=lower, upper=upper)\n    self.load_df(df)", "response": "Trim values at input thresholds using pandas function\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes the matrix rows or columns using Z - score or Quantile Normalization.", "response": "def normalize(self, df=None, norm_type='zscore', axis='row', keep_orig=False):\n    '''\n    Normalize the matrix rows or columns using Z-score (zscore) or Quantile Normalization (qn). Users can optionally pass in a DataFrame to be normalized (and this will be incorporated into the Network object).\n    '''\n    normalize_fun.run_norm(self, df, norm_type, axis, keep_orig)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef random_sample(self, num_samples, df=None, replace=False, weights=None, random_state=100, axis='row'):\n    '''\n    Return random sample of matrix.\n    '''\n\n    if df is None:\n      df = self.dat_to_df()\n\n    if axis == 'row':\n      axis = 0\n    if axis == 'col':\n      axis = 1\n\n    df = self.export_df()\n    df = df.sample(n=num_samples, replace=replace, weights=weights, random_state=random_state,  axis=axis)\n\n    self.load_df(df)", "response": "Return random samples from the matrix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd categories to rows or columns of the specified axis.", "response": "def add_cats(self, axis, cat_data):\n    '''\n    Add categories to rows or columns using cat_data array of objects. Each object in cat_data is a dictionary with one key (category title) and value (rows/column names) that have this category. Categories will be added onto the existing categories and will be added in the order of the objects in the array.\n\n    Example ``cat_data``::\n\n\n        [\n          {\n            \"title\": \"First Category\",\n            \"cats\": {\n              \"true\": [\n                \"ROS1\",\n                \"AAK1\"\n              ]\n            }\n          },\n          {\n            \"title\": \"Second Category\",\n            \"cats\": {\n              \"something\": [\n                \"PDK4\"\n              ]\n            }\n          }\n        ]\n\n\n    '''\n    for inst_data in cat_data:\n      categories.add_cats(self, axis, inst_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enrichrgram(self, lib, axis='row'):\n    '''\n    Add Enrichr gene enrichment results to your visualization (where your rows\n    are genes). Run enrichrgram before clustering to incldue enrichment results\n    as row categories. Enrichrgram can also be run on the front-end using the\n    Enrichr logo at the top left.\n\n    Set lib to the Enrichr library that you want to use for enrichment analysis.\n    Libraries included:\n\n      * ChEA_2016\n      * KEA_2015\n      * ENCODE_TF_ChIP-seq_2015\n      * ENCODE_Histone_Modifications_2015\n      * Disease_Perturbations_from_GEO_up\n      * Disease_Perturbations_from_GEO_down\n      * GO_Molecular_Function_2015\n      * GO_Biological_Process_2015\n      * GO_Cellular_Component_2015\n      * Reactome_2016\n      * KEGG_2016\n      * MGI_Mammalian_Phenotype_Level_4\n      * LINCS_L1000_Chem_Pert_up\n      * LINCS_L1000_Chem_Pert_down\n\n    '''\n\n    df = self.export_df()\n    df, bar_info = enr_fun.add_enrichr_cats(df, axis, lib)\n    self.load_df(df)\n\n    self.dat['enrichrgram_lib'] = lib\n    self.dat['row_cat_bars'] = bar_info", "response": "Add enrichrgram results to the visualization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading gene expression data from 10x in sparse matrix format and returns a Pandas dataframe containing the gene name and unique id.", "response": "def load_gene_exp_to_df(inst_path):\n    '''\n    Loads gene expression data from 10x in sparse matrix format and returns a\n    Pandas dataframe\n    '''\n\n    import pandas as pd\n    from scipy import io\n    from scipy import sparse\n    from ast import literal_eval as make_tuple\n\n    # matrix\n    Matrix = io.mmread( inst_path + 'matrix.mtx')\n    mat = Matrix.todense()\n\n    # genes\n    filename = inst_path + 'genes.tsv'\n    f = open(filename, 'r')\n    lines = f.readlines()\n    f.close()\n\n    # # add unique id to all genes\n    # genes = []\n    # unique_id = 0\n    # for inst_line in lines:\n    #     inst_line = inst_line.strip().split()\n\n    #     if len(inst_line) > 1:\n    #       inst_gene = inst_line[1]\n    #     else:\n    #       inst_gene = inst_line[0]\n\n    #     genes.append(inst_gene + '_' + str(unique_id))\n    #     unique_id = unique_id + 1\n\n    # add unique id only to duplicate genes\n    ini_genes = []\n    for inst_line in lines:\n        inst_line = inst_line.strip().split()\n        if len(inst_line) > 1:\n          inst_gene = inst_line[1]\n        else:\n          inst_gene = inst_line[0]\n        ini_genes.append(inst_gene)\n\n    gene_name_count = pd.Series(ini_genes).value_counts()\n    duplicate_genes = gene_name_count[gene_name_count > 1].index.tolist()\n\n    dup_index = {}\n    genes = []\n    for inst_row in ini_genes:\n\n      # add index to non-unique genes\n      if inst_row in duplicate_genes:\n\n        # calc_non-unque index\n        if inst_row not in dup_index:\n          dup_index[inst_row] = 1\n        else:\n          dup_index[inst_row] = dup_index[inst_row] + 1\n\n        new_row = inst_row + '_' + str(dup_index[inst_row])\n\n      else:\n        new_row = inst_row\n\n      genes.append(new_row)\n\n    # barcodes\n    filename = inst_path + 'barcodes.tsv'\n    f = open(filename, 'r')\n    lines = f.readlines()\n    f.close()\n\n    cell_barcodes = []\n    for inst_bc in lines:\n        inst_bc = inst_bc.strip().split('\\t')\n\n        # remove dash from barcodes if necessary\n        if '-' in inst_bc[0]:\n          inst_bc[0] = inst_bc[0].split('-')[0]\n\n        cell_barcodes.append(inst_bc[0])\n\n    # parse tuples if necessary\n    try:\n        cell_barcodes = [make_tuple(x) for x in cell_barcodes]\n    except:\n        pass\n\n    try:\n        genes = [make_tuple(x) for x in genes]\n    except:\n        pass\n\n    # make dataframe\n    df = pd.DataFrame(mat, index=genes, columns=cell_barcodes)\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the similarity of samples from the same and different categories.", "response": "def sim_same_and_diff_category_samples(self, df, cat_index=1, dist_type='cosine',\n                                         equal_var=False, plot_roc=True,\n                                         precalc_dist=False, calc_roc=True):\n      '''\n      Calculate the similarity of samples from the same and different categories. The\n      cat_index gives the index of the category, where 1 in the first category\n      '''\n\n      cols = df.columns.tolist()\n\n      if type(precalc_dist) == bool:\n          # compute distnace between rows (transpose to get cols as rows)\n          dist_arr = 1 - pdist(df.transpose(), metric=dist_type)\n      else:\n          dist_arr = precalc_dist\n\n      # generate sample names with categories\n      sample_combos = list(combinations(range(df.shape[1]),2))\n\n      sample_names = [str(ind) + '_same' if cols[x[0]][cat_index] == cols[x[1]][cat_index] else str(ind) + '_different' for ind, x in enumerate(sample_combos)]\n\n      ser_dist = pd.Series(data=dist_arr, index=sample_names)\n\n      # find same-cat sample comparisons\n      same_cat = [x for x in sample_names if x.split('_')[1] == 'same']\n\n      # find diff-cat sample comparisons\n      diff_cat = [x for x in sample_names if x.split('_')[1] == 'different']\n\n      # make series of same and diff category sample comparisons\n      ser_same = ser_dist[same_cat]\n      ser_same.name = 'Same Category'\n      ser_diff = ser_dist[diff_cat]\n      ser_diff.name = 'Different Category'\n\n      sim_dict = {}\n      roc_data = {}\n      sim_data = {}\n\n      sim_dict['same'] = ser_same\n      sim_dict['diff'] = ser_diff\n\n      pval_dict = {}\n      ttest_stat, pval_dict['ttest'] = ttest_ind(ser_diff, ser_same, equal_var=equal_var)\n\n      ttest_stat, pval_dict['mannwhitney'] = mannwhitneyu(ser_diff, ser_same)\n\n      if calc_roc:\n          # calc AUC\n          true_index = list(np.ones(sim_dict['same'].shape[0]))\n          false_index = list(np.zeros(sim_dict['diff'].shape[0]))\n          y_true = true_index + false_index\n\n          true_val = list(sim_dict['same'].get_values())\n          false_val = list(sim_dict['diff'].get_values())\n          y_score = true_val + false_val\n\n          fpr, tpr, thresholds = roc_curve(y_true, y_score)\n\n          inst_auc = auc(fpr, tpr)\n\n          if plot_roc:\n              plt.figure()\n              plt.plot(fpr, tpr)\n              plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n              plt.figure(figsize=(10,10))\n\n              print('AUC', inst_auc)\n\n          roc_data['true'] = y_true\n          roc_data['score'] = y_score\n          roc_data['fpr'] = fpr\n          roc_data['tpr'] = tpr\n          roc_data['thresholds'] = thresholds\n          roc_data['auc'] = inst_auc\n\n      sim_data['sim_dict'] = sim_dict\n      sim_data['pval_dict'] = pval_dict\n      sim_data['roc_data'] = roc_data\n\n      return sim_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_signatures(self, df_ini, category_level, pval_cutoff=0.05,\n                          num_top_dims=False, verbose=True, equal_var=False):\n\n      ''' Generate signatures for column categories '''\n\n      df_t = df_ini.transpose()\n\n      # remove columns with constant values\n      df_t = df_t.loc[:, (df_t != df_t.iloc[0]).any()]\n\n      df = self.row_tuple_to_multiindex(df_t)\n\n      cell_types = sorted(list(set(df.index.get_level_values(category_level).tolist())))\n\n      keep_genes = []\n      keep_genes_dict = {}\n      gene_pval_dict = {}\n      all_fold_info = {}\n\n      for inst_ct in cell_types:\n\n          inst_ct_mat = df.xs(key=inst_ct, level=category_level)\n          inst_other_mat = df.drop(inst_ct, level=category_level)\n\n          # save mean values and fold change\n          fold_info = {}\n          fold_info['cluster_mean'] = inst_ct_mat.mean()\n          fold_info['other_mean'] = inst_other_mat.mean()\n          fold_info['log2_fold'] = fold_info['cluster_mean']/fold_info['other_mean']\n          fold_info['log2_fold'] = fold_info['log2_fold'].apply(np.log2)\n          all_fold_info[inst_ct] = fold_info\n\n          inst_stats, inst_pvals = ttest_ind(inst_ct_mat, inst_other_mat, axis=0, equal_var=equal_var)\n\n          ser_pval = pd.Series(data=inst_pvals, index=df.columns.tolist()).sort_values()\n\n          if num_top_dims == False:\n              ser_pval_keep = ser_pval[ser_pval < pval_cutoff]\n          else:\n              ser_pval_keep = ser_pval[:num_top_dims]\n\n          gene_pval_dict[inst_ct] = ser_pval_keep\n\n          inst_keep = ser_pval_keep.index.tolist()\n          keep_genes.extend(inst_keep)\n          keep_genes_dict[inst_ct] = inst_keep\n\n      keep_genes = sorted(list(set(keep_genes)))\n\n      df_gbm = df.groupby(level=category_level).mean().transpose()\n      cols = df_gbm.columns.tolist()\n      new_cols = []\n      for inst_col in cols:\n          new_col = (inst_col, category_level + ': ' + inst_col)\n          new_cols.append(new_col)\n      df_gbm.columns = new_cols\n\n      df_sig = df_gbm.ix[keep_genes]\n\n      if len(keep_genes) == 0 and verbose:\n          print('found no informative dimensions')\n\n      df_gene_pval = pd.concat(gene_pval_dict, axis=1, sort=False)\n\n      return df_sig, keep_genes_dict, df_gene_pval, all_fold_info", "response": "Generate signatures for column categories."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef predict_cats_from_sigs(self, df_data_ini, df_sig_ini, dist_type='cosine', predict_level='Predict Category',\n                             truth_level=1, unknown_thresh=-1):\n      ''' Predict category using signature '''\n\n      keep_rows = df_sig_ini.index.tolist()\n      data_rows = df_data_ini.index.tolist()\n\n      common_rows = list(set(data_rows).intersection(keep_rows))\n\n      df_data = deepcopy(df_data_ini.ix[common_rows])\n      df_sig = deepcopy(df_sig_ini.ix[common_rows])\n\n      # calculate sim_mat of df_data and df_sig\n      cell_types = df_sig.columns.tolist()\n      barcodes = df_data.columns.tolist()\n      sim_mat = 1 - pairwise_distances(df_sig.transpose(), df_data.transpose(), metric=dist_type)\n      df_sim = pd.DataFrame(data=sim_mat, index=cell_types, columns=barcodes).transpose()\n\n      # get the top column value (most similar signature)\n      df_sim_top = df_sim.idxmax(axis=1)\n\n      # get the maximum similarity of a cell to a cell type definition\n      max_sim = df_sim.max(axis=1)\n\n      unknown_cells = max_sim[max_sim < unknown_thresh].index.tolist()\n\n      # assign unknown cells (need category of same name)\n      df_sim_top[unknown_cells] = 'Unknown'\n\n      # add predicted category name to top list\n      top_list = df_sim_top.get_values()\n      top_list = [ predict_level + ': ' + x[0] if type(x) is tuple else predict_level + ': ' + x  for x in top_list]\n\n      # add cell type category to input data\n      df_cat = deepcopy(df_data)\n      cols = df_cat.columns.tolist()\n      new_cols = []\n\n      # check whether the columns have the true category available\n      has_truth = False\n      if type(cols[0]) is tuple:\n          has_truth = True\n\n      if has_truth:\n          new_cols = [tuple(list(a) + [b]) for a,b in zip(cols, top_list)]\n      else:\n          new_cols = [tuple([a] + [b]) for a,b in zip(cols, top_list)]\n\n      # transfer new categories\n      df_cat.columns = new_cols\n\n      # keep track of true and predicted labels\n      y_info = {}\n      y_info['true'] = []\n      y_info['pred'] = []\n\n      if has_truth:\n          y_info['true'] = [x[truth_level].split(': ')[1] for x in cols]\n          y_info['pred'] = [x.split(': ')[1] for x in top_list]\n\n      return df_cat, df_sim.transpose(), y_info", "response": "Predict a category using a signature."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef confusion_matrix_and_correct_series(self, y_info):\n      ''' Generate confusion matrix from y_info '''\n\n\n      a = deepcopy(y_info['true'])\n      true_count = dict((i, a.count(i)) for i in set(a))\n\n      a = deepcopy(y_info['pred'])\n      pred_count = dict((i, a.count(i)) for i in set(a))\n\n      sorted_cats = sorted(list(set(y_info['true'] + y_info['pred'])))\n      conf_mat = confusion_matrix(y_info['true'], y_info['pred'], sorted_cats)\n      df_conf = pd.DataFrame(conf_mat, index=sorted_cats, columns=sorted_cats)\n\n      total_correct = np.trace(df_conf)\n      total_pred = df_conf.sum().sum()\n      fraction_correct = total_correct/float(total_pred)\n\n      # calculate ser_correct\n      correct_list = []\n      cat_counts = df_conf.sum(axis=1)\n      all_cols = df_conf.columns.tolist()\n      for inst_cat in all_cols:\n          inst_correct = df_conf[inst_cat].loc[inst_cat] / cat_counts[inst_cat]\n          correct_list.append(inst_correct)\n\n      ser_correct = pd.Series(data=correct_list, index=all_cols)\n\n      populations = {}\n      populations['true'] = true_count\n      populations['pred'] = pred_count\n\n      return df_conf, populations, ser_correct, fraction_correct", "response": "Generate a confusion matrix from y_info and correct the series."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload data into nodes and mat convert mat to numpy array", "response": "def load_data_to_net(net, inst_net):\n  ''' load data into nodes and mat, also convert mat to numpy array'''\n  net.dat['nodes'] = inst_net['nodes']\n  net.dat['mat'] = inst_net['mat']\n  data_formats.mat_to_numpy_arr(net)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export_net_json(net, net_type, indent='no-indent'):\n  ''' export json string of dat '''\n  import json\n  from copy import deepcopy\n\n  if net_type == 'dat':\n    exp_dict = deepcopy(net.dat)\n\n    if type(exp_dict['mat']) is not list:\n      exp_dict['mat'] = exp_dict['mat'].tolist()\n      if 'mat_orig' in exp_dict:\n        exp_dict['mat_orig'] = exp_dict['mat_orig'].tolist()\n\n  elif net_type == 'viz':\n    exp_dict = net.viz\n\n  elif net_type == 'sim_row':\n    exp_dict = net.sim['row']\n\n  elif net_type == 'sim_col':\n    exp_dict = net.sim['col']\n\n  # make json\n  if indent == 'indent':\n    exp_json = json.dumps(exp_dict, indent=2)\n  else:\n    exp_json = json.dumps(exp_dict)\n\n  return exp_json", "response": "export json string of dat"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_matrix_to_tsv(net, filename=None, df=None):\n  '''\n  This will export the matrix in net.dat or a dataframe (optional df in\n  arguments) as a tsv file. Row/column categories will be saved as tuples in\n  tsv, which can be read back into the network object.\n  '''\n  import pandas as pd\n\n  if df is None:\n    df = net.dat_to_df()\n\n  return df['mat'].to_csv(filename, sep='\\t')", "response": "This will write the matrix in net. dat or a dataframe to a tsv file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(net, df=None):\n  '''\n  Run in load_data module (which runs when file is loaded or dataframe is loaded),\n  check for duplicate row/col names, and add index to names if necesary\n  '''\n  if df is None:\n    df = net.export_df()\n\n  # rows\n  #############\n  rows = df.index.tolist()\n  if type(rows[0]) is str:\n\n    if len(rows) != len(list(set(rows))):\n      new_rows = add_index_list(rows)\n      df.index = new_rows\n\n  elif type(rows[0]) is tuple:\n\n    row_names = []\n    for inst_row in rows:\n      row_names.append(inst_row[0])\n\n    if len(row_names) != len(list(set(row_names))):\n      row_names = add_index_list(row_names)\n\n      # add back to tuple\n      new_rows = []\n      for inst_index in range(len(rows)):\n        inst_row = rows[inst_index]\n        new_row = list(inst_row)\n        new_row[0] = row_names[inst_index]\n        new_row = tuple(new_row)\n        new_rows.append(new_row)\n\n      df.index = new_rows\n\n  # cols\n  #############\n  cols = df.columns.tolist()\n  if type(cols[0]) is str:\n\n    # list column names\n    if len(cols) != len(list(set(cols))):\n      new_cols = add_index_list(cols)\n      df.columns = new_cols\n\n  elif type(cols[0]) is tuple:\n\n    col_names = []\n    for inst_col in cols:\n      col_names.append(inst_col[0])\n\n    if len(col_names) != len(list(set(col_names))):\n      col_names = add_index_list(col_names)\n\n      # add back to tuple\n      new_cols = []\n      for inst_index in range(len(cols)):\n        inst_col = cols[inst_index]\n        new_col = list(inst_col)\n        new_col[0] = col_names[inst_index]\n        new_col = tuple(new_col)\n        new_cols.append(new_col)\n\n      df.columns = new_cols\n\n  # return dataframe with unique names\n  return df", "response": "Main function for the necesary\n module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef viz_json(net, dendro=True, links=False):\n  ''' make the dictionary for the clustergram.js visualization '''\n  from . import calc_clust\n  import numpy as np\n\n  all_dist = calc_clust.group_cutoffs()\n\n  for inst_rc in net.dat['nodes']:\n\n    inst_keys = net.dat['node_info'][inst_rc]\n    all_cats = [x for x in inst_keys if 'cat-' in x]\n\n    for i in range(len(net.dat['nodes'][inst_rc])):\n      inst_dict = {}\n      inst_dict['name'] = net.dat['nodes'][inst_rc][i]\n      inst_dict['ini'] = net.dat['node_info'][inst_rc]['ini'][i]\n      inst_dict['clust'] = net.dat['node_info'][inst_rc]['clust'].index(i)\n      inst_dict['rank'] = net.dat['node_info'][inst_rc]['rank'][i]\n\n      if 'rankvar' in inst_keys:\n        inst_dict['rankvar'] = net.dat['node_info'][inst_rc]['rankvar'][i]\n\n      # fix for similarity matrix\n      if len(all_cats) > 0:\n\n        for inst_name_cat in all_cats:\n\n          actual_cat_name = net.dat['node_info'][inst_rc][inst_name_cat][i]\n          inst_dict[inst_name_cat] = actual_cat_name\n\n          check_pval = 'pval_'+inst_name_cat.replace('-','_')\n\n          if check_pval in net.dat['node_info'][inst_rc]:\n            tmp_pval_name = inst_name_cat.replace('-','_') + '_pval'\n            inst_dict[tmp_pval_name] = net.dat['node_info'][inst_rc][check_pval][actual_cat_name]\n\n          tmp_index_name = inst_name_cat.replace('-', '_') + '_index'\n\n          inst_dict[tmp_index_name] = net.dat['node_info'][inst_rc] \\\n              [tmp_index_name][i]\n\n\n      if len(net.dat['node_info'][inst_rc]['value']) > 0:\n        inst_dict['value'] = net.dat['node_info'][inst_rc]['value'][i]\n\n      if len(net.dat['node_info'][inst_rc]['info']) > 0:\n        inst_dict['info'] = net.dat['node_info'][inst_rc]['info'][i]\n\n      if dendro is True:\n        inst_dict['group'] = []\n        for tmp_dist in all_dist:\n          tmp_dist = str(tmp_dist).replace('.', '')\n          tmp_append = float(\n              net.dat['node_info'][inst_rc]['group'][tmp_dist][i])\n          inst_dict['group'].append(tmp_append)\n\n      net.viz[inst_rc + '_nodes'].append(inst_dict)\n\n  mat_types = ['mat', 'mat_orig', 'mat_info', 'mat_hl', 'mat_up', 'mat_dn']\n\n  # save data as links or mat\n  ###########################\n  if links is True:\n    for i in range(len(net.dat['nodes']['row'])):\n      for j in range(len(net.dat['nodes']['col'])):\n\n        inst_dict = {}\n        inst_dict['source'] = i\n        inst_dict['target'] = j\n        inst_dict['value'] = float(net.dat['mat'][i, j])\n\n        if 'mat_up' in net.dat:\n          inst_dict['value_up'] = net.dat['mat_up'][i, j]\n          inst_dict['value_dn'] = net.dat['mat_dn'][i, j]\n\n        if 'mat_orig' in net.dat:\n          inst_dict['value_orig'] = net.dat['mat_orig'][i, j]\n\n          if np.isnan(inst_dict['value_orig']):\n            inst_dict['value_orig'] = 'NaN'\n\n\n        if 'mat_info' in net.dat:\n          inst_dict['info'] = net.dat['mat_info'][str((i, j))]\n\n        if 'mat_hl' in net.dat:\n          inst_dict['highlight'] = net.dat['mat_hl'][i, j]\n\n        net.viz['links'].append(inst_dict)\n\n  else:\n    for inst_mat in mat_types:\n      if inst_mat in net.dat:\n        net.viz[inst_mat] = net.dat[inst_mat].tolist()", "response": "make the dictionary for the clustergram. js visualization"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_npm(path=None, build_dir=None, source_dir=None, build_cmd='build', force=False, npm=None):\n\n    class NPM(BaseCommand):\n        description = 'install package.json dependencies using npm'\n\n        def run(self):\n            if skip_npm:\n                log.info('Skipping npm-installation')\n                return\n            node_package = path or HERE\n            node_modules = pjoin(node_package, 'node_modules')\n            is_yarn = os.path.exists(pjoin(node_package, 'yarn.lock'))\n\n            npm_cmd = npm\n\n            if npm is None:\n                if is_yarn:\n                    npm_cmd = ['yarn']\n                else:\n                    npm_cmd = ['npm']\n\n            if not which(npm_cmd[0]):\n                log.error(\"`{0}` unavailable.  If you're running this command \"\n                          \"using sudo, make sure `{0}` is availble to sudo\"\n                          .format(npm_cmd[0]))\n                return\n\n            if force or is_stale(node_modules, pjoin(node_package, 'package.json')):\n                log.info('Installing build dependencies with npm.  This may '\n                         'take a while...')\n                run(npm_cmd + ['install'], cwd=node_package)\n            if build_dir and source_dir and not force:\n                should_build = is_stale(build_dir, source_dir)\n            else:\n                should_build = True\n            if should_build:\n                run(npm_cmd + ['run', build_cmd], cwd=node_package)\n\n    return NPM", "response": "Returns a Command that can be used to install npm dependencies."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\njoins paths for glob processing", "response": "def _glob_pjoin(*parts):\n    \"\"\"Join paths for glob processing\"\"\"\n    if parts[0] in ('.', ''):\n        parts = parts[1:]\n    return pjoin(*parts).replace(os.sep, '/')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_data_files(data_specs, existing, top=HERE):\n    # Extract the existing data files into a staging object.\n    file_data = defaultdict(list)\n    for (path, files) in existing or []:\n        file_data[path] = files\n\n    # Extract the files and assign them to the proper data\n    # files path.\n    for (path, dname, pattern) in data_specs or []:\n        if os.path.isabs(dname):\n            dname = os.path.relpath(dname, top)\n        dname = dname.replace(os.sep, '/')\n        offset = 0 if dname in ('.', '') else len(dname) + 1\n        files = _get_files(_glob_pjoin(dname, pattern), top=top)\n        for fname in files:\n            # Normalize the path.\n            root = os.path.dirname(fname)\n            full_path = _glob_pjoin(path, root[offset:])\n            print(dname, root, full_path, offset)\n            if full_path.endswith('/'):\n                full_path = full_path[:-1]\n            file_data[full_path].append(fname)\n\n    # Construct the data files spec.\n    data_files = []\n    for (path, files) in file_data.items():\n        data_files.append((path, files))\n    return data_files", "response": "Expand data file specs into valid data files metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpand file patterns to a list of paths.", "response": "def _get_files(file_patterns, top=HERE):\n    \"\"\"Expand file patterns to a list of paths.\n\n    Parameters\n    -----------\n    file_patterns: list or str\n        A list of glob patterns for the data file locations.\n        The globs can be recursive if they include a `**`.\n        They should be relative paths from the top directory or\n        absolute paths.\n    top: str\n        the directory to consider for data files\n\n    Note:\n    Files in `node_modules` are ignored.\n    \"\"\"\n    if not isinstance(file_patterns, (list, tuple)):\n        file_patterns = [file_patterns]\n\n    for i, p in enumerate(file_patterns):\n        if os.path.isabs(p):\n            file_patterns[i] = os.path.relpath(p, top)\n\n    matchers = [_compile_pattern(p) for p in file_patterns]\n\n    files = set()\n\n    for root, dirnames, filenames in os.walk(top):\n        # Don't recurse into node_modules\n        if 'node_modules' in dirnames:\n            dirnames.remove('node_modules')\n        for m in matchers:\n            for filename in filenames:\n                fn = os.path.relpath(_glob_pjoin(root, filename), top)\n                fn = fn.replace(os.sep, '/')\n                if m(fn):\n                    files.add(fn.replace(os.sep, '/'))\n\n    return list(files)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpand file patterns to a list of package_data paths.", "response": "def _get_package_data(root, file_patterns=None):\n    \"\"\"Expand file patterns to a list of `package_data` paths.\n\n    Parameters\n    -----------\n    root: str\n        The relative path to the package root from `HERE`.\n    file_patterns: list or str, optional\n        A list of glob patterns for the data file locations.\n        The globs can be recursive if they include a `**`.\n        They should be relative paths from the root or\n        absolute paths.  If not given, all files will be used.\n\n    Note:\n    Files in `node_modules` are ignored.\n    \"\"\"\n    if file_patterns is None:\n        file_patterns = ['*']\n    return _get_files(file_patterns, _glob_pjoin(HERE, root))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef df_filter_row_sum(df, threshold, take_abs=True):\n  ''' filter rows in matrix at some threshold\n  and remove columns that have a sum below this threshold '''\n\n  from copy import deepcopy\n  from .__init__ import Network\n  net = Network()\n\n  if take_abs is True:\n    df_copy = deepcopy(df['mat'].abs())\n  else:\n    df_copy = deepcopy(df['mat'])\n\n  ini_rows = df_copy.index.values.tolist()\n  df_copy = df_copy.transpose()\n  tmp_sum = df_copy.sum(axis=0)\n  tmp_sum = tmp_sum.abs()\n  tmp_sum.sort_values(inplace=True, ascending=False)\n\n  tmp_sum = tmp_sum[tmp_sum > threshold]\n  keep_rows = sorted(tmp_sum.index.values.tolist())\n\n  if len(keep_rows) < len(ini_rows):\n    df['mat'] = grab_df_subset(df['mat'], keep_rows=keep_rows)\n\n    if 'mat_up' in df:\n      df['mat_up'] = grab_df_subset(df['mat_up'], keep_rows=keep_rows)\n      df['mat_dn'] = grab_df_subset(df['mat_dn'], keep_rows=keep_rows)\n\n    if 'mat_orig' in df:\n      df['mat_orig'] = grab_df_subset(df['mat_orig'], keep_rows=keep_rows)\n\n  return df", "response": "filter rows in matrix at some threshold\n  and remove columns that have a sum below this threshold"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiltering columns in matrix at some threshold and remove rows that have all zero values", "response": "def df_filter_col_sum(df, threshold, take_abs=True):\n  ''' filter columns in matrix at some threshold\n  and remove rows that have all zero values '''\n\n  from copy import deepcopy\n  from .__init__ import Network\n  net = Network()\n\n  if take_abs is True:\n    df_copy = deepcopy(df['mat'].abs())\n  else:\n    df_copy = deepcopy(df['mat'])\n\n  df_copy = df_copy.transpose()\n  df_copy = df_copy[df_copy.sum(axis=1) > threshold]\n  df_copy = df_copy.transpose()\n  df_copy = df_copy[df_copy.sum(axis=1) > 0]\n\n  if take_abs is True:\n    inst_rows = df_copy.index.tolist()\n    inst_cols = df_copy.columns.tolist()\n    df['mat'] = grab_df_subset(df['mat'], inst_rows, inst_cols)\n\n    if 'mat_up' in df:\n      df['mat_up'] = grab_df_subset(df['mat_up'], inst_rows, inst_cols)\n      df['mat_dn'] = grab_df_subset(df['mat_dn'], inst_rows, inst_cols)\n\n    if 'mat_orig' in df:\n      df['mat_orig'] = grab_df_subset(df['mat_orig'], inst_rows, inst_cols)\n\n  else:\n    df['mat'] = df_copy\n\n  return df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_threshold(df, inst_rc, threshold, num_occur=1):\n  '''\n  Filter a network's rows or cols based on num_occur values being above a\n  threshold (in absolute_value)\n  '''\n  from copy import deepcopy\n\n  inst_df = deepcopy(df['mat'])\n\n  if inst_rc == 'col':\n    inst_df = inst_df.transpose()\n\n  inst_df = inst_df.abs()\n\n  ini_rows = inst_df.index.values.tolist()\n\n  inst_df[inst_df < threshold] = 0\n  inst_df[inst_df >= threshold] = 1\n\n  tmp_sum = inst_df.sum(axis=1)\n\n  tmp_sum = tmp_sum[tmp_sum >= num_occur]\n\n  keep_names = tmp_sum.index.values.tolist()\n\n  if inst_rc == 'row':\n    if len(keep_names) < len(ini_rows):\n      df['mat'] = grab_df_subset(df['mat'], keep_rows=keep_names)\n\n      if 'mat_up' in df:\n        df['mat_up'] = grab_df_subset(df['mat_up'], keep_rows=keep_names)\n        df['mat_dn'] = grab_df_subset(df['mat_dn'], keep_rows=keep_names)\n\n      if 'mat_orig' in df:\n        df['mat_orig'] = grab_df_subset(df['mat_orig'], keep_rows=keep_names)\n\n  elif inst_rc == 'col':\n    inst_df = inst_df.transpose()\n\n    inst_rows = inst_df.index.values.tolist()\n    inst_cols = keep_names\n\n    df['mat'] = grab_df_subset(df['mat'], inst_rows, inst_cols)\n\n    if 'mat_up' in df:\n      df['mat_up'] = grab_df_subset(df['mat_up'], inst_rows, inst_cols)\n      df['mat_dn'] = grab_df_subset(df['mat_dn'], inst_rows, inst_cols)\n\n    if 'mat_orig' in df:\n      df['mat_orig'] = grab_df_subset(df['mat_orig'], inst_rows, inst_cols)\n\n  return df", "response": "Filter a network based on num_occur values being above threshold"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_clust(net, dist_type='cosine', run_clustering=True, dendro=True,\n                          requested_views=['pct_row_sum', 'N_row_sum'],\n                          linkage_type='average', sim_mat=False, filter_sim=0.1,\n                          calc_cat_pval=False, sim_mat_views=['N_row_sum'],\n                          run_enrichr=None, enrichrgram=None):\n  '''\n  This will calculate multiple views of a clustergram by filtering the\n  data and clustering after each filtering. This filtering will keep the top\n  N rows based on some quantity (sum, num-non-zero, etc).\n  '''\n  from copy import deepcopy\n  import scipy\n  from . import calc_clust, run_filter, make_views, make_sim_mat, cat_pval\n  from . import enrichr_functions as enr_fun\n\n  df = net.dat_to_df()\n\n  threshold = 0.0001\n  df = run_filter.df_filter_row_sum(df, threshold)\n  df = run_filter.df_filter_col_sum(df, threshold)\n\n  # default setting\n  define_cat_colors = False\n\n  if run_enrichr is not None:\n    df = enr_fun.add_enrichr_cats(df, 'row', run_enrichr)\n\n    define_cat_colors = True\n\n  # calculate initial view with no row filtering\n  net.df_to_dat(df, define_cat_colors=True)\n\n\n  inst_dm = calc_clust.cluster_row_and_col(net, dist_type=dist_type,\n                                linkage_type=linkage_type,\n                                run_clustering=run_clustering,\n                                dendro=dendro, ignore_cat=False,\n                                calc_cat_pval=calc_cat_pval)\n\n  all_views = []\n  send_df = deepcopy(df)\n\n  if 'N_row_sum' in requested_views:\n    all_views = make_views.N_rows(net, send_df, all_views,\n                                  dist_type=dist_type, rank_type='sum')\n\n  if 'N_row_var' in requested_views:\n    all_views = make_views.N_rows(net, send_df, all_views,\n                                  dist_type=dist_type, rank_type='var')\n\n  if 'pct_row_sum' in requested_views:\n    all_views = make_views.pct_rows(net, send_df, all_views,\n                                    dist_type=dist_type, rank_type='sum')\n\n  if 'pct_row_var' in requested_views:\n    all_views = make_views.pct_rows(net, send_df, all_views,\n                                    dist_type=dist_type, rank_type='var')\n\n  which_sim = []\n\n  if sim_mat == True:\n    which_sim = ['row', 'col']\n  elif sim_mat == 'row':\n    which_sim = ['row']\n  elif sim_mat == 'col':\n    which_sim = ['col']\n\n  if sim_mat is not False:\n    sim_net = make_sim_mat.main(net, inst_dm, which_sim, filter_sim, sim_mat_views)\n\n    net.sim = {}\n\n    for inst_rc in which_sim:\n      net.sim[inst_rc] = sim_net[inst_rc].viz\n\n      if inst_rc == 'row':\n        other_rc = 'col'\n      elif inst_rc == 'col':\n        other_rc = 'row'\n\n      # keep track of cat_colors\n      net.sim[inst_rc]['cat_colors'][inst_rc] = net.viz['cat_colors'][inst_rc]\n      net.sim[inst_rc]['cat_colors'][other_rc] = net.viz['cat_colors'][inst_rc]\n\n  else:\n    net.sim = {}\n\n  net.viz['views'] = all_views\n\n  if enrichrgram != None:\n    # toggle enrichrgram functionality from back-end\n    net.viz['enrichrgram'] = enrichrgram\n\n  if 'enrichrgram_lib' in net.dat:\n    net.viz['enrichrgram'] = True\n    net.viz['enrichrgram_lib'] = net.dat['enrichrgram_lib']\n\n  if 'row_cat_bars' in net.dat:\n    net.viz['row_cat_bars'] = net.dat['row_cat_bars']", "response": "This function calculates multiple views of a clustergram from a network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef infer_flags(bytecode, is_async=False):\n    flags = CompilerFlags(0)\n    if not isinstance(bytecode, (_bytecode.Bytecode,\n                                 _bytecode.ConcreteBytecode,\n                                 _bytecode.ControlFlowGraph)):\n        msg = ('Expected a Bytecode, ConcreteBytecode or ControlFlowGraph '\n               'instance not %s')\n        raise ValueError(msg % bytecode)\n\n    instructions = (bytecode.get_instructions()\n                    if isinstance(bytecode, _bytecode.ControlFlowGraph) else\n                    bytecode)\n    instr_names = {i.name for i in instructions\n                   if not isinstance(i, (_bytecode.SetLineno,\n                                         _bytecode.Label))}\n\n    if not (instr_names & {'STORE_NAME', 'LOAD_NAME', 'DELETE_NAME'}):\n        flags |= CompilerFlags.OPTIMIZED\n\n    flags |= bytecode.flags & (CompilerFlags.NEWLOCALS |\n                               CompilerFlags.VARARGS |\n                               CompilerFlags.VARKEYWORDS |\n                               CompilerFlags.NESTED)\n\n    if instr_names & {'YIELD_VALUE', 'YIELD_FROM'}:\n        if not is_async and not bytecode.flags & CompilerFlags.ASYNC_GENERATOR:\n            flags |= CompilerFlags.GENERATOR\n        else:\n            flags |= CompilerFlags.ASYNC_GENERATOR\n\n    if not (instr_names & {'LOAD_CLOSURE', 'LOAD_DEREF', 'STORE_DEREF',\n                           'DELETE_DEREF', 'LOAD_CLASSDEREF'}):\n        flags |= CompilerFlags.NOFREE\n\n    if (not (bytecode.flags & CompilerFlags.ITERABLE_COROUTINE or\n             flags & CompilerFlags.ASYNC_GENERATOR) and\n            (instr_names & {'GET_AWAITABLE', 'GET_AITER', 'GET_ANEXT',\n                            'BEFORE_ASYNC_WITH', 'SETUP_ASYNC_WITH'} or\n             bytecode.flags & CompilerFlags.COROUTINE)):\n        flags |= CompilerFlags.COROUTINE\n\n    flags |= bytecode.flags & CompilerFlags.ITERABLE_COROUTINE\n\n    flags |= bytecode.flags & CompilerFlags.FUTURE_GENERATOR_STOP\n\n    if ([bool(flags & getattr(CompilerFlags, k))\n         for k in ('COROUTINE', 'ITERABLE_COROUTINE', 'GENERATOR',\n                   'ASYNC_GENERATOR')].count(True) > 1):\n        raise ValueError(\"Code should not have more than one of the \"\n                         \"following flag set : generator, coroutine, \"\n                         \"iterable coroutine and async generator, got:\"\n                         \"%s\" % flags)\n\n    return flags", "response": "Infer the proper flags for a given bytecode."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmodify the instruction in - place.", "response": "def set(self, name, arg=UNSET):\n        \"\"\"Modify the instruction in-place.\n\n        Replace name and arg attributes. Don't modify lineno.\n        \"\"\"\n        self._set(name, arg, self._lineno)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup(tf, order=None):\n    global _tf_version_string, _tf_version\n    _tf_version_string = tf.__version__\n    _tf_version = _parse_tf_version(_tf_version_string)\n\n    if order is not None:\n        optimize(order)", "response": "Sets up global variables to adapt to peculiarities of\n    different tensorflow versions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef optimize(order):\n    if not isinstance(order, (list, tuple)):\n        order = [order]\n\n    for op in Operation.__subclasses__():\n        for impl in order:\n            if impl in op.impls:\n                op.use_impl(impl)\n                break", "response": "Optimize the order of the available resource types."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_tensor(td_tensor, indent=\"|   \", max_depth=-1, depth=0):\n    offset = depth * indent\n    line = \"td tensor: %s\" % td_tensor.name\n    if td_tensor.value is not None:\n        line += \" (%s)\" % (\",\".join(str(i) for i in td_tensor.value.shape),)\n\n    print(offset + line)\n\n    if td_tensor.op and (max_depth < 0 or max_depth > depth):\n        print_op(td_tensor.op, indent=indent, max_depth=max_depth, depth=depth+1)", "response": "Prints a tensor to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_op(td_op, indent=\"|   \", max_depth=-1, depth=0):\n    offset = depth * indent\n    line = \"td op: %s (%s)\" % (td_op.name, \",\".join(td_op.types))\n\n    print(offset + line)\n\n    if max_depth < 0 or max_depth > depth:\n        for td_tensor in td_op.inputs:\n            print_tensor(td_tensor, indent=indent, max_depth=max_depth, depth=depth+1)", "response": "Prints a single Operation object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_tf_tensor(tf_tensor, indent=\"|   \", max_depth=-1, depth=0):\n    offset = depth * indent\n    shape = tuple(int(i) for i in tf_tensor.get_shape())\n    line = \"tf tensor: %s (%s)\" % (tf_tensor.name, \",\".join(str(i) for i in shape))\n\n    print(offset + line)\n\n    if tf_tensor.op and (max_depth < 0 or max_depth > depth):\n        print_tf_op(tf_tensor.op, indent=indent, max_depth=max_depth, depth=depth+1)", "response": "Prints a tensor to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a tensorflow operation to stdout.", "response": "def print_tf_op(tf_op, indent=\"|   \", max_depth=-1, depth=0):\n    \"\"\" print_tf_op(tf_tensor, indent=\"    \", max_depth=-1)\n    Prints the dependency graph of a tensorflow operation *tf_op*, where each new level is indented\n    by *indent*. When *max_depth* is positive, the graph is truncated at that depth, where each\n    tensor and each op count as a level.\n    \"\"\"\n    offset = depth * indent\n    line = \"tf op: %s (%s)\" % (tf_op.name, tf_op.type)\n\n    print(offset + line)\n\n    if max_depth < 0 or max_depth > depth:\n        for tf_tensor in tf_op.inputs:\n            print_tf_tensor(tf_tensor, indent=indent, max_depth=max_depth, depth=depth+1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef LinSpace(start, stop, num):\n    return np.linspace(start, stop, num=num, dtype=np.float32),", "response": "Linspace implementation of the LinearSpace operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Range(start, limit, delta):\n    return np.arange(start, limit, delta, dtype=np.int32),", "response": "Returns an array of the specified range."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RandomUniformInt(shape, minval, maxval, seed):\n    if seed:\n        np.random.seed(seed)\n    return np.random.randint(minval, maxval, size=shape),", "response": "Random uniform int op."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nranks of the array.", "response": "def Rank(a):\n    \"\"\"\n    Rank op.\n    \"\"\"\n    return np.array([len(a.shape)], dtype=np.int32),"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsqueezes op. i. e. removes singular axes.", "response": "def Squeeze(a, squeeze_dims):\n    \"\"\"\n    Squeeze op, i.e. removes singular axes.\n    \"\"\"\n    if not squeeze_dims:\n        squeeze_dims = list(range(len(a.shape)))\n    slices = [(0 if (dim == 1 and i in squeeze_dims) else slice(None)) \\\n              for i, dim in enumerate(a.shape)]\n    return np.copy(a)[slices],"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ExpandDims(a, dim):\n    shape = list(a.shape)\n    if dim >= 0:\n        shape.insert(dim, 1)\n    else:\n        shape.insert(len(shape) + dim + 1, 1)\n    return np.copy(a).reshape(*shape),", "response": "Expand dim op, i.e. add singular axis at dim."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nslicing a array by given indices.", "response": "def Slice(a, begin, size):\n    \"\"\"\n    Slicing op.\n    \"\"\"\n    return np.copy(a)[[slice(*tpl) for tpl in zip(begin, begin+size)]],"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsplit op with n splits.", "response": "def Split(axis, a, n):\n    \"\"\"\n    Split op with n splits.\n    \"\"\"\n    return tuple(np.split(np.copy(a), n, axis=axis))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef SplitV(a, splits, axis):\n    return tuple(np.split(np.copy(a), np.cumsum(splits), axis=axis))", "response": "Split op with multiple split sizes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbatch diag op that returns only the diagonal elements.", "response": "def MatrixDiagPart(a):\n    \"\"\"\n    Batched diag op that returns only the diagonal elements.\n    \"\"\"\n    r = np.zeros(a.shape[:-2] + (min(a.shape[-2:]),))\n    for coord in np.ndindex(a.shape[:-2]):\n        pos = coord + (Ellipsis,)\n        r[pos] = np.diagonal(a[pos])\n    return r,"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselfing Adjoint Eigen decomp op.", "response": "def SelfAdjointEig(a):\n    \"\"\"\n    Eigen decomp op.\n    \"\"\"\n    shape = list(a.shape)\n    shape[-2] += 1\n    return np.append(*np.linalg.eig(a)).reshape(*shape),"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Svd(a, uv, full):\n    u, s, v = np.linalg.svd(a, full_matrices=full, compute_uv=uv)\n    return s, u, v", "response": "Single value decomp op."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute prod along specified axis.", "response": "def Prod(a, axis, keep_dims):\n    \"\"\"\n    Prod reduction op.\n    \"\"\"\n    return np.prod(a, axis=axis if not isinstance(axis, np.ndarray) else tuple(axis),\n                   keepdims=keep_dims),"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef SparseSegmentSqrtN(a, idxs, ids):\n    func = lambda _idxs: np.divide(reduce(np.add, a[idxs][_idxs]), np.math.sqrt(len(_idxs)))\n    return seg_map(func, a, ids),", "response": "Sparse segmented sum / sqrt N"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AvgPool3D(a, k, strides, padding):\n    patches = _pool_patches(a, k, strides, padding.decode(\"ascii\"))\n    return np.average(patches, axis=tuple(range(-len(k), 0))),", "response": "Average 3D pooling op."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, *names, **kwargs):\n        tensors = tuple(self._get(name, **kwargs) for name in names)\n        return tensors[0] if len(names) == 1 else tensors", "response": "Get a set of tensors given by names using a deep lookup within the current model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a new root tensor for a given key.", "response": "def add(self, tensor, tf_sess=None, key=None, **kwargs):\n        \"\"\"\n        Adds a new root *tensor* for a *key* which, if *None*, defaults to a consecutive number.\n        When *tensor* is not an instance of :py:class:`Tensor` but an instance of\n        ``tensorflow.Tensor``, it is converted first. In that case, *tf_sess* should be a valid\n        tensorflow session and *kwargs* are forwarded to the :py:class:`Tensor` constructor.\n        \"\"\"\n        if not isinstance(tensor, Tensor):\n            tensor = Tensor(tensor, tf_sess, **kwargs)\n\n        if key is None:\n            if len(self.roots) == 0:\n                key = 0\n            else:\n                key = max(self.roots.keys()) + 1\n\n        self.roots[key] = tensor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(self, path):\n        path = os.path.expandvars(os.path.expanduser(path))\n        with open(path, \"rb\") as f:\n            roots = pickle.load(f)\n\n        for key, tensor in roots.items():\n            self.add(tensor, key=key)", "response": "Loads all tensors from a file defined by path and adds them to the set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, path):\n        path = os.path.expandvars(os.path.expanduser(path))\n        with open(path, \"wb\") as f:\n            pickle.dump(self.roots, f)", "response": "Saves all the tensors of the root set to a file defined by path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, *names, **kwargs):\n        # create empty tensor ensembles with our method\n        tensor_ensembles = [TensorEnsemble([], self.method) for name in names]\n\n        # loop over models, collect and add tensors\n        for model in self.models:\n            tensors = model.get(*names, **kwargs)\n            if not isinstance(tensors, tuple):\n                tensors = (tensors,)\n            for i, t in enumerate(tensors if isinstance(tensors, tuple) else (tensors,)):\n                tensor_ensembles[i].tensors.append(t)\n\n        return tensor_ensembles[0] if len(names) == 1 else tuple(tensor_ensembles)", "response": "Get one or more tensor ensembles given by names using a deep\n        lookup within all read models."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self, paths):\n        for path in paths:\n            self.models.append(Model(path))", "response": "Loads models from a list of paths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate all contained tensors using a feed_dict and returns the ensemble value.", "response": "def eval(self, feed_dict=None):\n        \"\"\"\n        Evaluates all contained tensors using a *feed_dict* and returns the ensemble value. The keys\n        of *feed_dict* must be tensor ensembles. Its values can be batches, i.e., numpy arrays, or\n        lists or tuples of batches. In the latter case, these lists or tuples must have the same\n        length as the list of stored tensors as they will be mapped.\n        \"\"\"\n        # first, check that the length of all feed_dict keys match our own length\n        for tensor_ensemble in feed_dict:\n            if len(tensor_ensemble.tensors) != len(self.tensors):\n                raise EnsembleMismatchException(\"incompatible lengths of tensors: %d, %d\" \\\n                                                % (len(self.tensors), len(tensor_ensemble.tensors)))\n\n        # create a joined uuid\n        _uuid = uuid4()\n\n        # prepare feed_dicts\n        feed_dicts = [{} for _ in range(len(self.tensors))]\n        for tensor_ensemble, value in feed_dict.items():\n            for i, tensor in enumerate(tensor_ensemble.tensors):\n                if tensor is not None:\n                    feed_dicts[i][tensor] = value[i] if isinstance(value, (list, tuple)) else value\n\n        # eval all tensors\n        values = [t.eval(feed_dict=d, _uuid=_uuid) for t, d in zip(self.tensors, feed_dicts)]\n\n        # return the computed ensemble value\n        return self.func(values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pressed_keys(self):\n        # make a list of all the keys that are detected\n        pressed = []\n\n        # set all pins pins to be inputs w/pullups\n        for pin in self.row_pins+self.col_pins:\n            pin.direction = Direction.INPUT\n            pin.pull = Pull.UP\n\n        for row in range(len(self.row_pins)):\n            # set one row low at a time\n            self.row_pins[row].direction = Direction.OUTPUT\n            self.row_pins[row].value = False\n            # check the column pins, which ones are pulled down\n            for col in range(len(self.col_pins)):\n                if not self.col_pins[col].value:\n                    pressed.append(self.keys[row][col])\n            # reset the pin to be an input\n            self.row_pins[row].direction = Direction.INPUT\n            self.row_pins[row].pull = Pull.UP\n        return pressed", "response": "An array containing all the keys that are pressed from the initalized\n            list - of - lists passed in during creation"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_stdev(self, asset_type):\n        load_times = []\n        # Handle edge cases like TTFB\n        if asset_type == 'ttfb':\n            for page in self.pages:\n                if page.time_to_first_byte is not None:\n                    load_times.append(page.time_to_first_byte)\n        elif asset_type not in self.asset_types and asset_type != 'page':\n            raise ValueError('asset_type must be one of:\\nttfb\\n{0}'.format(\n                    '\\n'.join(self.asset_types)))\n        else:\n            load_times = self.get_load_times(asset_type)\n\n        if not load_times or not sum(load_times):\n            return 0\n        return round(stdev(load_times),\n                     self.decimal_precision)", "response": "Calculates the standard deviation for a set of asset types."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of all the pages of all the parser objects.", "response": "def pages(self):\n        \"\"\"\n        The aggregate pages of all the parser objects.\n        \"\"\"\n        pages = []\n        for har_dict in self.har_data:\n            har_parser = HarParser(har_data=har_dict)\n            if self.page_id:\n                for page in har_parser.pages:\n                    if page.page_id == self.page_id:\n                        pages.append(page)\n            else:\n                pages = pages + har_parser.pages\n        return pages"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef time_to_first_byte(self):\n        ttfb = []\n        for page in self.pages:\n            if page.time_to_first_byte is not None:\n                ttfb.append(page.time_to_first_byte)\n        return round(mean(ttfb), self.decimal_precision)", "response": "Returns the aggregate time to first byte for all pages."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the average load time for all runs.", "response": "def page_load_time(self):\n        \"\"\"\n        The average total load time for all runs (not weighted).\n        \"\"\"\n        load_times = self.get_load_times('page')\n        return round(mean(load_times), self.decimal_precision)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn aggregate javascript load time.", "response": "def js_load_time(self):\n        \"\"\"\n        Returns aggregate javascript load time.\n        \"\"\"\n        load_times = self.get_load_times('js')\n        return round(mean(load_times), self.decimal_precision)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn aggregate css load time for all pages.", "response": "def css_load_time(self):\n        \"\"\"\n        Returns aggregate css load time for all pages.\n        \"\"\"\n        load_times = self.get_load_times('css')\n        return round(mean(load_times), self.decimal_precision)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef image_load_time(self):\n        load_times = self.get_load_times('image')\n        return round(mean(load_times), self.decimal_precision)", "response": "Returns aggregate image load time for all pages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef html_load_time(self):\n        load_times = self.get_load_times('html')\n        return round(mean(load_times), self.decimal_precision)", "response": "Returns aggregate html load time for all pages."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef audio_load_time(self):\n        load_times = self.get_load_times('audio')\n        return round(mean(load_times), self.decimal_precision)", "response": "Returns aggregate audio load time for all pages."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef video_load_time(self):\n        load_times = self.get_load_times('video')\n        return round(mean(load_times), self.decimal_precision)", "response": "Returns aggregate video load time for all pages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction to match headers.", "response": "def match_headers(self, entry, header_type, header, value, regex=True):\n        \"\"\"\n        Function to match headers.\n\n        Since the output of headers might use different case, like:\n\n            'content-type' vs 'Content-Type'\n\n        This function is case-insensitive\n\n        :param entry: entry object\n        :param header_type: ``str`` of header type. Valid values:\n\n            * 'request'\n            * 'response'\n\n        :param header: ``str`` of the header to search for\n        :param value: ``str`` of value to search for\n        :param regex: ``bool`` indicating whether to use regex or exact match\n\n        :returns: a ``bool`` indicating whether a match was found\n        \"\"\"\n        if header_type not in entry:\n            raise ValueError('Invalid header_type, should be either:\\n\\n'\n                             '* \\'request\\'\\n*\\'response\\'')\n\n        # TODO - headers are empty in some HAR data.... need fallbacks here\n        for h in entry[header_type]['headers']:\n            if h['name'].lower() == header.lower() and h['value'] is not None:\n                if regex and re.search(value, h['value'], flags=re.IGNORECASE):\n                    return True\n                elif value == h['value']:\n                    return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the content type of a request matches the mimeType metadata.", "response": "def match_content_type(entry, content_type, regex=True):\n        \"\"\"\n        Matches the content type of a request using the mimeType metadata.\n\n        :param entry: ``dict`` of a single entry from a HarPage\n        :param content_type: ``str`` of regex to use for finding content type\n        :param regex: ``bool`` indicating whether to use regex or exact match.\n        \"\"\"\n        mimeType = entry['response']['content']['mimeType']\n\n        if regex and re.search(content_type, mimeType, flags=re.IGNORECASE):\n            return True\n\n        elif content_type == mimeType:\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the entry with the given request type matches the given request_type.", "response": "def match_request_type(self, entry, request_type, regex=True):\n        \"\"\"\n        Helper function that returns entries with a request type\n        matching the given `request_type` argument.\n\n        :param entry: entry object to analyze\n        :param request_type: ``str`` of request type to match\n        :param regex: ``bool`` indicating whether to use a regex or string match\n        \"\"\"\n        if regex:\n            return re.search(request_type, entry['request']['method'],\n                             flags=re.IGNORECASE) is not None\n        else:\n            return entry['request']['method'] == request_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a dictionary of the asset timeline for the requested assets.", "response": "def create_asset_timeline(self, asset_list):\n        \"\"\"\n        Returns a ``dict`` of the timeline for the requested assets. The key is\n        a datetime object (down to the millisecond) of ANY time where at least\n        one of the requested assets was loaded. The value is a ``list`` of ALL\n        assets that were loading at that time.\n\n        :param asset_list: ``list`` of the assets to create a timeline for.\n        \"\"\"\n        results = dict()\n        for asset in asset_list:\n            time_key = dateutil.parser.parse(asset['startedDateTime'])\n            load_time = int(asset['time'])\n            # Add the start time and asset to the results dict\n            if time_key in results:\n                results[time_key].append(asset)\n            else:\n                results[time_key] = [asset]\n            # For each millisecond the asset was loading, insert the asset\n            # into the appropriate key of the results dict. Starting the range()\n            # index at 1 because we already inserted the first millisecond.\n            for _ in range(1, load_time):\n                time_key = time_key + datetime.timedelta(milliseconds=1)\n                if time_key in results:\n                    results[time_key].append(asset)\n                else:\n                    results[time_key] = [asset]\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pages(self):\n        # Start with a page object for unknown entries if the HAR data has\n        # any entries with no page ID\n        pages = []\n        if any('pageref' not in entry for entry in self.har_data['entries']):\n            pages.append(HarPage('unknown', har_parser=self))\n        for har_page in self.har_data['pages']:\n            page = HarPage(har_page['id'], har_parser=self)\n            pages.append(page)\n\n        return pages", "response": "This is a list of HarPage objects each of which represents a page\n        from the HAR file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_entries(self, request_type=None, content_type=None,\n                       status_code=None, http_version=None, regex=True):\n        \"\"\"\n        Returns a ``list`` of entry objects based on the filter criteria.\n\n        :param request_type: ``str`` of request type (i.e. - GET or POST)\n        :param content_type: ``str`` of regex to use for finding content type\n        :param status_code: ``int`` of the desired status code\n        :param http_version: ``str`` of HTTP version of request\n        :param regex: ``bool`` indicating whether to use regex or exact match.\n        \"\"\"\n        results = []\n\n        for entry in self.entries:\n            \"\"\"\n            So yea... this is a bit ugly. We are looking for:\n\n                * The request type using self._match_request_type()\n                * The content type using self._match_headers()\n                * The HTTP response status code using self._match_status_code()\n                * The HTTP version using self._match_headers()\n\n            Oh lords of python.... please forgive my soul\n            \"\"\"\n            valid_entry = True\n            p = self.parser\n            if request_type is not None and not p.match_request_type(\n                    entry, request_type, regex=regex):\n                valid_entry = False\n            if content_type is not None:\n                if not self.parser.match_content_type(entry, content_type,\n                                                      regex=regex):\n                    valid_entry = False\n            if status_code is not None and not p.match_status_code(\n                    entry, status_code, regex=regex):\n                valid_entry = False\n            if http_version is not None and not p.match_http_version(\n                    entry, http_version, regex=regex):\n                valid_entry = False\n\n            if valid_entry:\n                results.append(entry)\n\n        return results", "response": "Returns a list of entries based on the filter criteria."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the total size of a collection of entries.", "response": "def get_total_size(self, entries):\n        \"\"\"\n        Returns the total size of a collection of entries.\n\n        :param entries: ``list`` of entries to calculate the total size of.\n        \"\"\"\n        size = 0\n        for entry in entries:\n            if entry['response']['bodySize'] > 0:\n                size += entry['response']['bodySize']\n        return size"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_total_size_trans(self, entries):\n        size = 0\n        for entry in entries:\n            if entry['response']['_transferSize'] > 0:\n                size += entry['response']['_transferSize']\n        return size", "response": "Returns the total size of a collection of entries - transferred."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef time_to_first_byte(self):\n        # The unknown page is just a placeholder for entries with no page ID.\n        # As such, it would not have a TTFB\n        if self.page_id == 'unknown':\n            return None\n        ttfb = 0\n        for entry in self.entries:\n            if entry['response']['status'] == 200:\n                for k, v in iteritems(entry['timings']):\n                    if k != 'receive':\n                        if v > 0:\n                            ttfb += v\n                break\n            else:\n                ttfb += entry['time']\n\n        return ttfb", "response": "Return the time to first byte of the page request in ms."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef group_by(self, *fields):\n        fields = self._expand_group_by_fields(self.model, fields)\n        return self._clone(klass=GroupByQuerySet, setup=True, _fields=fields)", "response": "Returns a new queryset with the specified fields grouped by the current queryset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the cached data built from instance raw _values as a dictionary.", "response": "def _data(self):\n        \"\"\"\n        Cached data built from instance raw _values as a dictionary.\n        \"\"\"\n        d = {}\n\n        # Iterate all keys and values\n        for k, v in self._row_values.items():\n            # Split related model fields\n            attrs = k.rsplit('__', 1)\n\n            # Set value depending case\n            if len(attrs) == 2:\n                # Related model field, store nested\n                fk, fn = attrs\n                if fk not in d:\n                    d[fk] = {}\n                d[fk][fn] = v\n\n            else:\n                # Own model field, store directly\n                d[k] = v\n\n        # Return (+cache) data\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npopulating instance with given.", "response": "def _set_values(self):\n        \"\"\"\n        Populate instance with given.\n        \"\"\"\n        # Iterate all keys and values in data\n        for k, v in self._data.items():\n            # If it's a dict, process it (it's probably instance data)\n            if isinstance(v, dict):\n                try:\n                    # Get related model from field (follow path)\n                    rel_model = self._model\n                    for attr in k.split('__'):\n                        rel_model = getattr(rel_model, attr).field.related_model\n\n                except AttributeError:\n                    # Not a model, maybe it is a dict field (?)\n                    pass\n\n                else:\n                    # Model, first shorten field name\n                    k = k.replace('__', '_')\n\n                    # Now init instance if required (not if we got ID None)\n                    if 'id' in v and v['id'] is None:\n                        # This means we grouped by ID, if it's none then FK is None\n                        v = None\n\n                    else:\n                        # Either we have ID or we didn't group by ID, use instance\n                        v = rel_model(**v)\n\n            # Set value\n            setattr(self, k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef group_by(self, *fields):\n        fields = self._expand_group_by_fields(self.model, fields)\n        clone = self._values(*fields)\n        clone._iterable_class = GroupByIterable\n        return clone", "response": "Returns a new queryset with the given fields grouped by the current queryset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexpanding FK fields into all related object s fields to avoid future lookups.", "response": "def _expand_group_by_fields(cls, model, fields):\n        \"\"\"\n        Expand FK fields into all related object's fields to avoid future\n        lookups.\n\n        :param fields: fields to \"group by\"\n        :return: expanded fields\n        \"\"\"\n        # Containers for resulting fields and related model fields\n        res = []\n        related = {}\n\n        # Add own fields and populate related fields\n        for field_name in fields:\n            if '__' in field_name:\n                # Related model field: append to related model's fields\n                fk_field_name, related_field = field_name.split('__', 1)\n                if fk_field_name not in related:\n                    related[fk_field_name] = [related_field]\n                else:\n                    related[fk_field_name].append(related_field)\n\n            else:\n                # Simple field, get the field instance\n                model_field = model._meta.get_field(field_name)\n\n                if isinstance(model_field, (ForeignKey, ManyToManyField)):\n                    # It's a related field, get model\n                    related_model = model_field.related_model\n\n                    # Append all its fields with the correct prefix\n                    res.extend('{}__{}'.format(field_name, f.column)\n                               for f in related_model._meta.fields)\n\n                else:\n                    # It's a common field, just append it\n                    res.append(field_name)\n\n        # Resolve all related fields\n        for fk_field_name, field_names in related.items():\n            # Get field\n            fk = model._meta.get_field(fk_field_name)\n\n            # Get all fields for that related model\n            related_fields = cls._expand_group_by_fields(fk.related_model,\n                                                         field_names)\n\n            # Append them with the correct prefix\n            res.extend('{}__{}'.format(fk_field_name, f) for f in related_fields)\n\n        # Return all fields\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, addr, data):\n        '''Write to dummy memory\n\n        Parameters\n        ----------\n        addr : int\n            The register address.\n        data : list, tuple\n            Data (byte array) to be written.\n\n        Returns\n        -------\n        nothing\n        '''\n        logger.debug(\n            \"Dummy SiTransferLayer.write addr: %s data: %s\" % (hex(addr), data))\n        for curr_addr, d in enumerate(data, start=addr):\n            self.mem[curr_addr] = array.array('B', [d])[0]", "response": "Write to dummy memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the data from memory.", "response": "def read(self, addr, size):\n        '''\n        Parameters\n        ----------\n        addr : int\n            The register address.\n        size : int\n            Length of data to be read (number of bytes).\n\n        Returns\n        -------\n        array : array\n            Data (byte array) read from memory. Returns 0 for each byte if it hasn't been written to.\n        '''\n        logger.debug(\"Dummy SiTransferLayer.read addr: %s size: %s\" % (hex(addr), size))\n        return array.array('B', [self.mem[curr_addr] if curr_addr in self.mem else 0 for curr_addr in range(addr, addr + size)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a value to a memory address and offset.", "response": "def set_value(self, value, addr, size, offset, **kwargs):\r\n        '''Writing a value of any arbitrary size (max. unsigned int 64) and offset to a register\r\n\r\n        Parameters\r\n        ----------\r\n        value : int, str\r\n            The register value (int, long, bit string) to be written.\r\n        addr : int\r\n            The register address.\r\n        size : int\r\n            Bit size/length of the value to be written to the register.\r\n        offset : int\r\n            Offset of the value to be written to the register (in number of bits).\r\n\r\n        Returns\r\n        -------\r\n        nothing\r\n        '''\r\n        div_offset, mod_offset = divmod(offset, 8)\r\n        div_size, mod_size = divmod(size + mod_offset, 8)\r\n        if mod_size:\r\n            div_size += 1\r\n        if mod_offset == 0 and mod_size == 0:\r\n            reg = BitLogic.from_value(0, size=div_size * 8)\r\n        else:\r\n            ret = self._intf.read(self._base_addr + addr + div_offset, size=div_size)\r\n            reg = BitLogic()\r\n            reg.frombytes(tobytes(ret))\r\n        reg[size + mod_offset - 1:mod_offset] = value\r\n        self._intf.write(self._base_addr + addr + div_offset, data=array.array('B', reg.tobytes()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a value from a register of any arbitrary size and offset from a register.", "response": "def get_value(self, addr, size, offset, **kwargs):\r\n        '''Reading a value of any arbitrary size (max. unsigned int 64) and offset from a register\r\n\r\n        Parameters\r\n        ----------\r\n        addr : int\r\n            The register address.\r\n        size : int\r\n            Bit size/length of the value.\r\n        offset : int\r\n            Offset of the value to be written to the register (in number of bits).\r\n\r\n        Returns\r\n        -------\r\n        reg : int\r\n            Register value.\r\n        '''\r\n        div_offset, mod_offset = divmod(offset, 8)\r\n        div_size, mod_size = divmod(size + mod_offset, 8)\r\n        if mod_size:\r\n            div_size += 1\r\n        ret = self._intf.read(self._base_addr + addr + div_offset, size=div_size)\r\n        reg = BitLogic()\r\n        reg.frombytes(tobytes(ret))\r\n        return reg[size + mod_offset - 1:mod_offset].tovalue()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_bytes(self, data, addr, **kwargs):\r\n        '''Writing bytes of any arbitrary size\r\n\r\n        Parameters\r\n        ----------\r\n        data : iterable\r\n            The data (byte array) to be written.\r\n        addr : int\r\n            The register address.\r\n\r\n        Returns\r\n        -------\r\n        nothing\r\n        '''\r\n        self._intf.write(self._conf['base_addr'] + addr, data)", "response": "Writes bytes of any arbitrary size to the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_bytes(self, addr, size, **kwargs):\r\n        '''Reading bytes of any arbitrary size\r\n\r\n        Parameters\r\n        ----------.\r\n        addr : int\r\n            The register address.\r\n        size : int\r\n            Byte length of the value.\r\n\r\n        Returns\r\n        -------\r\n        data : iterable\r\n            Byte array.\r\n        '''\r\n        return self._intf.read(self._conf['base_addr'] + addr, size)", "response": "Reads bytes of any arbitrary size from the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the current entry to the file", "response": "def write(self, size=None):\n        \"\"\"\n        to call start() automatically, set yaml file as follows:\n        registers:\n          - name        : CCPD_PCB\n            type        : StdRegister\n            hw_driver   : CCPD_PCB_SPI\n            size        : 32\n            auto_start  : True  <------ add this\n            fields: ......\n        \"\"\"\n        if size is None:\n            self._drv.set_data(self.tobytes())\n        else:\n            self._drv.set_data(self.tobytes()[:size])\n\n        if \"auto_start\" in self._conf:\n            if self._conf[\"auto_start\"]:\n                self._drv.start()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_value(cls, value, size=None, fmt='Q', **kwargs):\n        '''\n        Factory method\n\n        For format characters see: https://docs.python.org/2/library/struct.html\n        '''\n        bl = cls(**kwargs)  # size is 0 by default\n        bl.fromvalue(value=value, size=size, fmt=fmt)\n        return bl", "response": "Factory method\n        Factory method\n       FromValue"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromvalue(self, value, size=None, fmt='Q'):\n        '''\n        Append from a int/long number.\n        '''\n        if size and value.bit_length() > size:\n            raise TypeError('Value is too big for given size')\n        self.frombytes(struct.pack(fmt, value))\n        if size:\n            if not isinstance(size, integer_types) or not size > 0:\n                raise TypeError('Size must be greater than zero')\n            if size > self.length():\n                bitarray.extend(self, (size - self.length()) * [0])\n            else:\n                bitarray.__delitem__(self, slice(size, self.length()))", "response": "Append from a int or long number."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts bitstring to a int or long number.", "response": "def tovalue(self, fmt='Q'):\n        '''\n        Convert bitstring to a int/long number.\n        '''\n        format_size = struct.calcsize(fmt)\n        if self.length() > format_size * 8:\n            raise TypeError('Cannot convert to number')\n        ba = self.copy()\n        ba.extend((format_size * 8 - self.length()) * [0])\n        return struct.unpack_from(fmt, ba.tobytes())[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _swap_slice_indices(self, slc, make_slice=False):\n        '''Swap slice indices\n\n        Change slice indices from Verilog slicing (e.g. IEEE 1800-2012) to Python slicing.\n        '''\n        try:\n            start = slc.start\n            stop = slc.stop\n            slc_step = slc.step\n        except AttributeError:\n            if make_slice:\n                if slc < 0:\n                    slc += self.length()\n                return slice(slc, slc + 1)\n            else:\n                return slc\n        else:\n            if not start and start != 0:\n                slc_stop = self.length()\n            elif start < 0:\n                slc_stop = self.length() + start + 1\n            else:\n                slc_stop = start + 1\n            if not stop and stop != 0:\n                slc_start = 0\n            elif stop < 0:\n                slc_start = self.length() + stop\n            else:\n                slc_start = stop\n            return slice(slc_start, slc_stop, slc_step)", "response": "Swap slice indices from Verilog slicing ( e. g. IEEE 1800 -2012 to Python slicing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run_seq(self, size):\n        \n        # Write the sequence to the sequence generator (hw driver)\n        self['SEQ'].write(size) #write pattern to memory\n        \n        self['SEQ'].set_size(size)  # set size\n        self['SEQ'].set_repeat(1) # set repeat\n        for _ in range(1):\n            self['SEQ'].start() # start\n            \n            while not self['SEQ'].get_done():\n                #time.sleep(0.1)\n                print(\"Wait for done...\")", "response": "Runs the sequence generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclears all the stuff that are not set.", "response": "def _clear_strobes(self):\n        \"\"\"\n        Resets the \"enable\" and \"load\" output streams to all 0.\n\n        \"\"\"\n        #reset some stuff\n        self['SEQ']['GLOBAL_SHIFT_EN'].setall(False)\n        self['SEQ']['GLOBAL_CTR_LD'].setall(False)\n        self['SEQ']['GLOBAL_DAC_LD'].setall(False)\n        self['SEQ']['PIXEL_SHIFT_EN'].setall(False)\n        self['SEQ']['INJECTION'].setall(False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset data for outgoing stream", "response": "def set_data(self, data, addr=0):\n        '''\n        Sets data for outgoing stream\n        '''\n        if self._mem_bytes < len(data):\n            raise ValueError('Size of data (%d bytes) is too big for memory (%d bytes)' % (len(data), self._mem_bytes))\n        self._intf.write(self._conf['base_addr'] + self._spi_mem_offset + addr, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_data(self, size=None, addr=None):\n        '''\n        Gets data for incoming stream\n        '''\n        # readback memory offset\n        if addr is None:\n            addr = self._mem_bytes\n\n        if size and self._mem_bytes < size:\n            raise ValueError('Size is too big')\n\n        if size is None:\n            return self._intf.read(self._conf['base_addr'] + self._spi_mem_offset + addr, self._mem_bytes)\n        else:\n            return self._intf.read(self._conf['base_addr'] + self._spi_mem_offset + addr, size)", "response": "Gets data for incoming stream\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes serial device. Parameters of serial.Serial: http://pyserial.sourceforge.net/pyserial_api.html Plus termination string parameter eol", "response": "def init(self):\n        '''\n        Initialize serial device.\n        Parameters of serial.Serial: http://pyserial.sourceforge.net/pyserial_api.html\n        Plus termination string parameter eol\n        '''\n        super(Serial, self).init()\n        self.read_termination = self._init.get('read_termination', None)\n        self.write_termination = self._init.get('write_termination', self.read_termination)\n        try:\n            self.read_termination = bytes(self.read_termination, 'utf-8')\n            self.write_termination = bytes(self.write_termination, 'utf-8')\n        except TypeError as e:\n            logger.debug(e)\n        self.timeout = self._init.get('timeout', None)  # timeout of 0 returns immediately\n\n        self._port = serial.Serial(**{key: value for key, value in self._init.items() if key not in (\"read_termination\", \"write_termination\")})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_eeprom_calibration(self):  # use default values for temperature, EEPROM values are usually not calibrated and random\n        '''Reading EEPROM calibration for sources and regulators\n        '''\n        header = self.get_format()\n        if header == self.HEADER_GPAC:\n            data = self._read_eeprom(self.CAL_DATA_ADDR, size=calcsize(self.CAL_DATA_GPAC_FORMAT))\n            for idx, channel in enumerate(self._ch_cal.iterkeys()):\n                ch_data = data[idx * calcsize(self.CAL_DATA_CH_GPAC_FORMAT):(idx + 1) * calcsize(self.CAL_DATA_CH_GPAC_FORMAT)]\n                values = unpack_from(self.CAL_DATA_CH_GPAC_FORMAT, ch_data)\n                self._ch_cal[channel]['name'] = \"\".join([c for c in values[0] if (c in string.printable)])  # values[0].strip()\n                self._ch_cal[channel]['default'] = values[1]\n                self._ch_cal[channel]['min'] = values[2]\n                self._ch_cal[channel]['max'] = values[3]\n                self._ch_cal[channel]['ADCI']['gain'] = -values[4]  # fix gain sign\n                self._ch_cal[channel]['ADCI']['offset'] = values[5]\n                self._ch_cal[channel]['ADCV']['gain'] = values[6]\n                self._ch_cal[channel]['ADCV']['offset'] = values[7]\n                self._ch_cal[channel]['DAC']['gain'] = values[8]\n                self._ch_cal[channel]['DAC']['offset'] = values[9]\n                self._ch_cal[channel]['limit'] = values[10]\n        else:\n            raise ValueError('EEPROM data format not supported (header: %s)' % header)", "response": "Reads the EEPROM calibration for sources and regulators."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the voltage from the ADC.", "response": "def get_voltage(self, channel, unit='V'):\n        '''Reading voltage\n        '''\n        adc_ch = self._ch_map[channel]['ADCV']['adc_ch']\n        address = self._ch_map[channel]['ADCV']['address']\n        raw = self._get_adc_value(address=address)[adc_ch]\n\n        dac_offset = self._ch_cal[channel]['ADCV']['offset']\n        dac_gain = self._ch_cal[channel]['ADCV']['gain']\n\n        voltage = ((raw - dac_offset) / dac_gain)\n\n        if unit == 'raw':\n            return raw\n        elif unit == 'V':\n            return voltage / 1000\n        elif unit == 'mV':\n            return voltage\n        else:\n            raise TypeError(\"Invalid unit type.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads current from the ADC.", "response": "def get_current(self, channel, unit='A'):\n        '''Reading current\n        '''\n        values = self._get_adc_value(address=self._ch_map[channel]['ADCI']['address'])\n        raw = values[self._ch_map[channel]['ADCI']['adc_ch']]\n        dac_offset = self._ch_cal[channel]['ADCI']['offset']\n        dac_gain = self._ch_cal[channel]['ADCI']['gain']\n\n        if 'PWR' in channel:\n            current = ((raw - dac_offset) / dac_gain)\n\n            if unit == 'raw':\n                return raw\n            elif unit == 'A':\n                return current / 1000\n            elif unit == 'mA':\n                return current\n            elif unit == 'uA':\n                return current * 1000\n            else:\n                raise TypeError(\"Invalid unit type.\")\n        else:\n            voltage = values[self._ch_map[channel]['ADCV']['adc_ch']]\n            current = (((raw - voltage) - dac_offset) / dac_gain)\n\n            if unit == 'raw':\n                return raw\n            elif unit == 'A':\n                return current / 1000000\n            elif unit == 'mA':\n                return current / 1000\n            elif unit == 'uA':\n                return current\n            else:\n                raise TypeError(\"Invalid unit type.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable or disable output of power channel.", "response": "def set_enable(self, channel, value):\n        '''Enable/Disable output of power channel\n        '''\n        try:\n            bit = self._ch_map[channel]['GPIOEN']['bit']\n        except KeyError:\n            raise ValueError('set_enable() not supported for channel %s' % channel)\n        self._set_power_gpio_value(bit=bit, value=value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the channel is over current.", "response": "def get_over_current(self, channel):\n        '''Reading over current status of power channel\n        '''\n        try:\n            bit = self._ch_map[channel]['GPIOOC']['bit']\n        except KeyError:\n            raise ValueError('get_over_current() not supported for channel %s' % channel)\n        return not self._get_power_gpio_value(bit)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the current limit for the specified channel.", "response": "def set_current_limit(self, channel, value, unit='A'):\n        '''Setting current limit\n\n        Note: same limit for all channels.\n        '''\n        # TODO: add units / calibration\n        if unit == 'raw':\n            value = value\n        elif unit == 'A':\n            value = int(value * 1000 * self.CURRENT_LIMIT_GAIN)\n        elif unit == 'mA':\n            value = int(value * self.CURRENT_LIMIT_GAIN)\n        elif unit == 'uA':\n            value = int(value / 1000 * self.CURRENT_LIMIT_GAIN)\n        else:\n            raise TypeError(\"Invalid unit type.\")\n\n        I2cAnalogChannel._set_dac_value(self, address=self.CURRENT_LIMIT_DAC_SLAVE_ADD, dac_ch=self.CURRENT_LIMIT_DAC_CH, value=value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the current of current source to the given value.", "response": "def set_current(self, channel, value, unit='A'):\n        '''Setting current of current source\n        '''\n        dac_offset = self._ch_cal[channel]['DAC']['offset']\n        dac_gain = self._ch_cal[channel]['DAC']['gain']\n        if unit == 'raw':\n            value = value\n        elif unit == 'A':\n            value = int((-value * 1000000 - dac_offset) / dac_gain)  # fix sign of output\n        elif unit == 'mA':\n            value = int((-value * 1000 - dac_offset) / dac_gain)  # fix sign of output\n        elif unit == 'uA':\n            value = int((-value - dac_offset) / dac_gain)  # fix sign of output\n        else:\n            raise TypeError(\"Invalid unit type.\")\n\n        self._set_dac_value(channel=channel, value=value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _calculateParameters(self, fout):\n        q_d_f = 0\n\n        '''\n        fout = fref * (p_total / q_total) * (1 / div)\n\n        p_total = 2 * ((p_counter + 4) + p_0)     [16..1023]\n        q_total = q_counter + 2                   [2..129]\n        div = [2,(3),4..127]\n\n        constraints:\n\n        f_ref * p_total / q_total = [100..400] MHz\n        f_ref / q_total > 0.25 MHz\n        '''\n        for self.q_counter in range(128):\n            self.q_total = self.q_counter + 2\n            if (self.fref / self.q_total) < 0.25:  # PLL constraint\n                break\n            for self.div in range(2, 128):\n                q_d_f = self.q_total * self.div * fout\n                if isinstance(q_d_f, six.integer_types) and q_d_f > (15 * self.fref):  # = f0 * p\n                    if int(q_d_f) % int(self.fref) == 0:  # p, q, and d found\n                        self.p_total = q_d_f / self.fref\n                        while self.p_total <= 16:  # counter constraint\n                            self.p_total = self.p_total * 2\n                            self.div = self.div * 2\n                            if self.div > 127:\n                                break\n                            if self.p_total > 1023:\n                                break\n                        if ((self.fref * self.p_total / self.q_total) < 100 or (self.fref * self.p_total / self.q_total) > 400):  # PLL constraint\n                            break\n                        if int(self.p_total) % 2 == 0:\n                            self.p_0 = 0\n                        else:\n                            self.p_0 = 1\n                        self.p_counter = ((int(self.p_total) - self.p_0) / 2) - 4  # set p counter value\n\n                        if self.div == 2:\n                            self.clk1SRC = 0x02\n                            self.div1N = 4\n                        else:\n                            if self.div == 3:\n                                self.clk1SRC = 0x03\n                                self.div1N = 6\n                            else:\n                                self.clk1SRC = 0x01\n                                self.div1N = self.div\n\n                        if self.p_total <= 44:\n                            self.chg_pump = 0\n                        else:\n                            if self.p_total <= 479:\n                                self.chg_pump = 1\n                            else:\n                                if self.p_total <= 639:\n                                    self.chg_pump = 2\n                                else:\n                                    if self.p_total <= 799:\n                                        self.chg_pump = 3\n                                    else:\n                                        if self.p_total <= 1023:\n                                            self.chg_pump = 4\n                        ftest = self.fref * self.p_total / self.q_total * 1 / self.div\n                        fvco = self.fref * self.p_total / self.q_total\n                        logger.info('PLL frequency set to ' + str(ftest) + ' MHz' + ' (VCO @ ' + str(fvco) + ' MHz)')\n                        return True\n        logger.error('MIO_PLL: Could not find PLL parameters')\n        return False", "response": "This method calculates the parameters of the base class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the device. Parameters of visa.ResourceManager().open_resource()", "response": "def init(self):\n        '''\n        Initialize the device.\n        Parameters of visa.ResourceManager().open_resource()\n        '''\n        super(Visa, self).init()\n        backend = self._init.get('backend', '')  # Empty string means std. backend (NI VISA)\n        rm = visa.ResourceManager(backend)\n        try:\n            logger.info('BASIL VISA TL with %s backend found the following devices: %s', backend, \", \".join(rm.list_resources()))\n        except NotImplementedError:  # some backends do not always implement the list_resources function\n            logger.info('BASIL VISA TL with %s backend', backend)\n        self._resource = rm.open_resource(**{key: value for key, value in self._init.items() if key not in (\"backend\",)})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread data in BRAM. returns numpy array.", "response": "def get_data(self):\n        ''' Reading data in BRAM.\n\n        Returns\n        -------\n        array : numpy.ndarray\n            Array of unsigned integers (32 bit).\n        '''\n        fifo_int_size_1 = self.FIFO_INT_SIZE\n        fifo_int_size_2 = self.FIFO_INT_SIZE\n        if fifo_int_size_1 > fifo_int_size_2:\n            fifo_int_size = fifo_int_size_2  # use smaller chunk\n            logger.warning(\"Reading wrong FIFO size. Expected: %d <= %d\" % (fifo_int_size_1, fifo_int_size_2))\n        else:\n            fifo_int_size = fifo_int_size_1  # use smaller chunk\n        return np.frombuffer(self._intf.read(self._conf['base_data_addr'], size=4 * fifo_int_size), dtype=np.dtype('<u4'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_external(self, address):\n        self.bus.RD_B <= 1\n        self.bus.ADD <= self._x\n        self.bus.BUS_DATA <= self._high_impedence\n        for _ in range(5):\n            yield RisingEdge(self.clock)\n\n        yield RisingEdge(self.clock)\n        self.bus.ADD <= address + 0x4000\n\n        yield RisingEdge(self.clock)\n        self.bus.RD_B <= 0\n        yield RisingEdge(self.clock)\n        self.bus.RD_B <= 0\n        yield ReadOnly()\n        result = self.bus.BUS_DATA.value.integer\n        yield RisingEdge(self.clock)\n        self.bus.RD_B <= 1\n\n        yield RisingEdge(self.clock)\n        self.bus.RD_B <= 1\n        self.bus.ADD <= self._x\n\n        yield RisingEdge(self.clock)\n\n        for _ in range(5):\n            yield RisingEdge(self.clock)\n\n        raise ReturnValue(result)", "response": "A testbench interface that reads an external bus address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_external(self, address, value):\n        self.bus.WR_B <= 1\n        self.bus.ADD <= self._x\n\n        for _ in range(5):\n            yield RisingEdge(self.clock)\n\n        yield RisingEdge(self.clock)\n        self.bus.ADD <= address + 0x4000\n        self.bus.BUS_DATA <= int(value)\n        yield Timer(1)  # This is hack for iverilog\n        self.bus.ADD <= address + 0x4000\n        self.bus.BUS_DATA <= int(value)\n        yield RisingEdge(self.clock)\n        self.bus.WR_B <= 0\n        yield Timer(1)  # This is hack for iverilog\n        self.bus.BUS_DATA <= int(value)\n        self.bus.WR_B <= 0\n        yield RisingEdge(self.clock)\n        self.bus.WR_B <= 0\n        yield Timer(1)  # This is hack for iverilog\n        self.bus.BUS_DATA <= int(value)\n        self.bus.WR_B <= 0\n        yield RisingEdge(self.clock)\n        self.bus.WR_B <= 1\n        self.bus.BUS_DATA <= self._high_impedence\n        yield Timer(1)  # This is hack for iverilog\n        self.bus.WR_B <= 1\n        self.bus.BUS_DATA <= self._high_impedence\n        yield RisingEdge(self.clock)\n        self.bus.WR_B <= 1\n        self.bus.ADD <= self._x\n\n        for _ in range(5):\n            yield RisingEdge(self.clock)", "response": "Write external data to the bus."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_eeprom(self, address, size):\n        '''Read EEPROM\n        '''\n        self._intf.write(self._base_addr + self.CAL_EEPROM_ADD, array('B', pack('>H', address & 0x3FFF)))  # 14-bit address, 16384 bytes\n\n        n_pages, n_bytes = divmod(size, self.CAL_EEPROM_PAGE_SIZE)\n        data = array('B')\n        for _ in range(n_pages):\n            data.extend(self._intf.read(self._base_addr + self.CAL_EEPROM_ADD | 1, size=self.CAL_EEPROM_PAGE_SIZE))\n\n        if n_bytes > 0:\n            data.extend(self._intf.read(self._base_addr + self.CAL_EEPROM_ADD | 1, size=n_bytes))\n\n        return data", "response": "Read the EEPROM at the specified address and size."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_default(self, channels=None):\n        '''Setting default voltage\n        '''\n        if not channels:\n            channels = self._ch_cal.keys()\n        for channel in channels:\n            self.set_voltage(channel, self._ch_cal[channel]['default'], unit='V')", "response": "Sets default voltage for all the specified channels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_voltage(self, channel, unit='V'):\n        '''Reading voltage\n        '''\n        kwargs = self._ch_map[channel]['ADCV']\n        voltage_raw = self._get_adc_value(**kwargs)\n\n        voltage = (voltage_raw - self._ch_cal[channel]['ADCV']['offset']) / self._ch_cal[channel]['ADCV']['gain']\n\n        if unit == 'raw':\n            return voltage_raw\n        elif unit == 'V':\n            return voltage\n        elif unit == 'mV':\n            return voltage * 1000\n        else:\n            raise TypeError(\"Invalid unit type.\")", "response": "Reads voltage from the ADC and returns it in the specified unit."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_current(self, channel, unit='A'):\n        '''Reading current\n        '''\n        kwargs = self._ch_map[channel]['ADCI']\n        current_raw = self._get_adc_value(**kwargs)\n        voltage = self.get_voltage(channel)\n\n        current_raw_iq = current_raw - (self._ch_cal[channel]['ADCI']['iq_offset'] + self._ch_cal[channel]['ADCI']['iq_gain'] * voltage)  # quiescent current (IQ) compensation\n        current = (current_raw_iq - self._ch_cal[channel]['ADCI']['offset']) / self._ch_cal[channel]['ADCI']['gain']\n\n        if unit == 'raw':\n            return current_raw\n        elif unit == 'raw_iq':\n            return current_raw_iq\n        elif unit == 'A':\n            return current\n        elif unit == 'mA':\n            return current * 1000\n        elif unit == 'uA':\n            return current * 1000000\n        else:\n            raise TypeError(\"Invalid unit type.\")", "response": "Reads current from the ADC and returns it in the specified unit"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the EEPROM calibration for power regulators and temperature.", "response": "def read_eeprom_calibration(self, temperature=False):  # use default values for temperature, EEPROM values are usually not calibrated and random\n        '''Reading EEPROM calibration for power regulators and temperature\n        '''\n        header = self.get_format()\n        if header == self.HEADER_V1:\n            data = self._read_eeprom(self.CAL_DATA_ADDR, size=calcsize(self.CAL_DATA_V1_FORMAT))\n            for idx, channel in enumerate(self._ch_cal.iterkeys()):\n                ch_data = data[idx * calcsize(self.CAL_DATA_CH_V1_FORMAT):(idx + 1) * calcsize(self.CAL_DATA_CH_V1_FORMAT)]\n                values = unpack_from(self.CAL_DATA_CH_V1_FORMAT, ch_data)\n                self._ch_cal[channel]['name'] = \"\".join([c for c in values[0] if (c in string.printable)])  # values[0].strip()\n                self._ch_cal[channel]['default'] = values[1]\n                self._ch_cal[channel]['ADCI']['gain'] = values[2]\n                self._ch_cal[channel]['ADCI']['offset'] = values[3]\n                self._ch_cal[channel]['ADCI']['iq_gain'] = values[4]\n                self._ch_cal[channel]['ADCI']['iq_offset'] = values[5]\n                self._ch_cal[channel]['ADCV']['gain'] = values[6]\n                self._ch_cal[channel]['ADCV']['offset'] = values[7]\n                self._ch_cal[channel]['DACV']['gain'] = values[8]\n                self._ch_cal[channel]['DACV']['offset'] = values[9]\n            const_data = data[-calcsize(self.CAL_DATA_CONST_V1_FORMAT):]\n            values = unpack_from(self.CAL_DATA_CONST_V1_FORMAT, const_data)\n            if temperature:\n                for channel in self._ch_cal.keys():\n                    self._ch_cal[channel]['VNTC']['B_NTC'] = values[0]\n                    self._ch_cal[channel]['VNTC']['R1'] = values[1]\n                    self._ch_cal[channel]['VNTC']['R2'] = values[2]\n                    self._ch_cal[channel]['VNTC']['R4'] = values[3]\n                    self._ch_cal[channel]['VNTC']['R_NTC_25'] = values[4]\n                    self._ch_cal[channel]['VNTC']['VREF'] = values[5]\n        else:\n            raise ValueError('EEPROM data format not supported (header: %s)' % header)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_temperature(self, channel, sensor='VNTC'):\n        '''Reading temperature\n        '''\n#         NTC type SEMITEC 103KT1608 http://www.semitec.co.jp/english/products/pdf/KT_Thermistor.pdf\n#\n#         R_NTC = R_25 * exp(B_NTC * (1/T - 1/T_25))\n#\n#         R_NTC       measured NTC resistance\n#         R_NTC_25    resistance @ 25C\n#         B_NTC       temperature coefficient\n#         Temperature current temperature (Kelvin)\n#         T_25        298,15 K (25C)\n#\n#         B_NTC       NTC 'b' coefficient, NTC Semitec 103KT1608-1P\n#         R_NTC_25    NTC 25C resistance, NTC Semitec 103KT1608-1P\n#         R1          resistor value for NTC voltage divider\n#         R2          value of R2 in the reference voltage divider\n#         R4          value of R4 in the reference voltage divider\n#         VREF        supply voltage of the resistor bridge\n#\n\n        kwargs = self._ch_map[channel][sensor]\n        temp_raw = self._get_adc_value(**kwargs)\n\n        v_adc = ((temp_raw - self._ch_cal.items()[0][1]['ADCV']['offset']) / self._ch_cal.items()[0][1]['ADCV']['gain'])  # voltage, VDDA1\n        k = self._ch_cal[channel][sensor]['R4'] / (self._ch_cal[channel][sensor]['R2'] + self._ch_cal[channel][sensor]['R4'])  # reference voltage divider\n        r_ntc = self._ch_cal[channel][sensor]['R1'] * (k - v_adc / self._ch_cal[channel][sensor]['VREF']) / (1 - k + v_adc / self._ch_cal[channel][sensor]['VREF'])  # NTC resistance\n\n        return (self._ch_cal[channel][sensor]['B_NTC'] / (log(r_ntc) - log(self._ch_cal[channel][sensor]['R_NTC_25']) + self._ch_cal[channel][sensor]['B_NTC'] / self.T_KELVIN_25)) - self.T_KELVIN_0", "response": "Reading temperature in the specified sensor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfiltering and convert any given data array of any dtype.", "response": "def convert_data_array(arr, filter_func=None, converter_func=None):\r\n    '''Filter and convert any given data array of any dtype.\r\n\r\n    Parameters\r\n    ----------\r\n    arr : numpy.array\r\n        Data array of any dtype.\r\n    filter_func : function\r\n        Function that takes array and returns true or false for each item in array.\r\n    converter_func : function\r\n        Function that takes array and returns an array or tuple of arrays.\r\n\r\n    Returns\r\n    -------\r\n    array of specified dimension (converter_func) and content (filter_func)\r\n    '''\r\n#     if filter_func != None:\r\n#         if not hasattr(filter_func, '__call__'):\r\n#             raise ValueError('Filter is not callable')\r\n    if filter_func:\r\n        array = arr[filter_func(arr)]  # Indexing with Boolean Arrays\r\n#     if converter_func != None:\r\n#         if not hasattr(converter_func, '__call__'):\r\n#             raise ValueError('Converter is not callable')\r\n    if converter_func:\r\n        arr = converter_func(arr)\r\n    return array"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef logical_and(f1, f2):  # function factory\r\n    '''Logical and from functions.\r\n\r\n    Parameters\r\n    ----------\r\n    f1, f2 : function\r\n        Function that takes array and returns true or false for each item in array.\r\n\r\n    Returns\r\n    -------\r\n    Function\r\n\r\n    Examples\r\n    --------\r\n    filter_func=logical_and(is_data_record, is_data_from_channel(4))  # new filter function\r\n    filter_func(array) # array that has Data Records from channel 4\r\n    '''\r\n    def f_and(arr):\r\n        return np.logical_and(f1(arr), f2(arr))\r\n    f_and.__name__ = f1.__name__ + \"_and_\" + f2.__name__\r\n    return f_and", "response": "Logical and from functions.\r\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef logical_or(f1, f2):  # function factory\r\n    '''Logical or from functions.\r\n\r\n    Parameters\r\n    ----------\r\n    f1, f2 : function\r\n        Function that takes array and returns true or false for each item in array.\r\n\r\n    Returns\r\n    -------\r\n    Function\r\n    '''\r\n    def f_or(arr):\r\n        return np.logical_or(f1(arr), f2(arr))\r\n    f_or.__name__ = f1.__name__ + \"_or_\" + f2.__name__\r\n    return f_or", "response": "Returns a function that returns true or false for each item in array f1 and f2."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef logical_not(f):  # function factory\r\n    '''Logical not from functions.\r\n\r\n    Parameters\r\n    ----------\r\n    f1, f2 : function\r\n        Function that takes array and returns true or false for each item in array.\r\n\r\n    Returns\r\n    -------\r\n    Function\r\n    '''\r\n    def f_not(arr):\r\n        return np.logical_not(f(arr))\r\n    f_not.__name__ = \"not_\" + f.__name__\r\n    return f_not", "response": "Returns a function that returns true or false for each item in array f"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef arr_select(value):  # function factory\r\n    '''Selecting array elements by bitwise and comparison to a given value.\r\n\r\n    Parameters:\r\n    value : int\r\n        Value to which array elements are compared to.\r\n\r\n    Returns:\r\n    array : np.array\r\n    '''\r\n    def f_eq(arr):\r\n        return np.equal(np.bitwise_and(arr, value), value)\r\n    f_eq.__name__ = \"arr_bitwise_and_\" + str(value)  # or use inspect module: inspect.stack()[0][3]\r\n    return f_eq", "response": "Returns a function that returns True if the array elements are equal to a given value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef arr_astype(arr_type):  # function factory\r\n    '''Change dtype of array.\r\n\r\n    Parameters:\r\n    arr_type : str, np.dtype\r\n        Character codes (e.g. 'b', '>H'), type strings (e.g. 'i4', 'f8'), Python types (e.g. float, int) and numpy dtypes (e.g. np.uint32) are allowed.\r\n\r\n    Returns:\r\n    array : np.array\r\n    '''\r\n    def f_astype(arr):\r\n        return arr.astype(arr_type)\r\n    f_astype.__name__ = \"arr_astype_\" + str(arr_type)  # or use inspect module: inspect.stack()[0][3]\r\n    return f_astype", "response": "Returns a function that can be used to change dtype of array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send(self, obj):\n        assert isinstance(obj, ProtocolBase)\n        string = pickle.dumps(obj)\n        length = len(string)\n        self.sock.sendall(struct.pack(\"<I\", length) + string)", "response": "Send a string to the socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recv(self, blocking=True):\n        length = struct.unpack(\"<I\", self.sock.recv(4))[0]\n        return self._get_next_obj(length)", "response": "Receive the next object from the socket"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to read a new object from the socket.", "response": "def try_recv(self):\n        \"\"\"Return None immediately if nothing is waiting\"\"\"\n        try:\n            lenstr = self.sock.recv(4, socket.MSG_DONTWAIT)\n        except socket.error:\n            return None\n        if len(lenstr) < 4:\n            raise EOFError(\"Socket closed\")\n        length = struct.unpack(\"<I\", lenstr)[0]\n        return self._get_next_obj(length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_next_obj(self, length):\n        data = b''\n        while len(data) < length:\n            data += self.sock.recv(length - len(data))\n\n        return pickle.loads(data)", "response": "Get the next object from the socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_modules(self, type_name):\n        '''Getting modules by type name.\n\n        Parameters\n        ----------\n        type_name : string\n            Type name of the modules to be returned.\n\n        Returns\n        -------\n        List of modules of given type name else empty list.\n        '''\n        modules = []\n        for module in self:\n            if module.__class__.__name__ == type_name:\n                modules.append(module)\n        return modules", "response": "Gets the modules of a given type name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread response to command and convert it to 16 - bit integer.", "response": "def ask(self, command):\n        '''Read response to command and convert it to 16-bit integer.\n        Returns : list of values\n        '''\n        self.write(command)\n        time.sleep(0.1)\n        return self.read()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_enable(self, on, channel=1):\n        if isinstance(channel, str):\n            cmd = \"OPALL %d\" % int(on)\n        elif isinstance(channel, int):\n            cmd = \"OP%d %d\" % (channel, int(on))\n        self.write(cmd)", "response": "Enable or disable the active class for this class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_current(self, channel):\n        ret = self.ask(\"I%dO?\" % channel)\n        if ret[-1] != \"A\":\n            print(\"ttiQl355tp.get_current() format error\", ret)\n            return None\n        return float(ret[:-1])", "response": "get current time from the ttable"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_voltage(self, channel):\n        ret = self.ask(\"V%dO?\" % channel)\n        if ret[-1] != \"V\":\n            print(\"ttiQl355tp.get_voltage() format error\", ret)\n            return None\n        return float(ret[:-1])", "response": "get the voltage of a single channel"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_set_voltage(self, channel):\n        ret = self.ask(\"V%d?\" % channel)\n        if ret[:3] != \"V%d \" % channel:\n            print(\"ttiQl355tp.get_voltage() format error\", ret)\n            return None\n        return float(ret[3:])", "response": "get set voltage from ttiQl355tp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_current_limit(self, channel):\n        ret = self.ask(\"I%d?\" % channel)\n        if ret[:3] != \"I%d \" % channel:\n            print(\"ttiQl355tp.get_current_limit() format error\", ret)\n            return None\n        return float(ret[3:])", "response": "get current limit of the current system"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_voltage(self, value, channel=1):\n        cmd = \"V%d %f\" % (channel, value)\n        self.write(cmd)", "response": "set voltage of the current channel"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchannel 1=OP1, 2=OP2, AUX is not supported", "response": "def set_current_limit(self, value, channel=1):\n        \"\"\" channel: 1=OP1, 2=OP2, AUX is not supported\"\"\"\n        cmd = \"I%d %f\" % (channel, value)\n        self.write(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait until the device is ready.", "response": "def wait_for_ready(self, timeout=None, times=None, delay=None, delay_between=None, abort=None):\n        '''Determine the ready state of the device and wait until device is ready.\n\n        Parameters\n        ----------\n        timeout : int, float\n            The maximum amount of time to wait in seconds. Reaching the timeout will raise a RuntimeError.\n        times : int\n            Maximum number of times reading the ready state.\n        delay : int, float\n            The number of seconds to sleep before checks. Defaults to 0.\n        delay_between : int, float\n            The number of seconds to sleep between each check. Defaults to 0.\n        abort : Threading.Event\n            Breaking the loop from other threads.\n\n        Returns\n        -------\n        True if state is ready, else False.\n        '''\n        if delay:\n            try:\n                sleep(delay)\n            except IOError:  # negative values\n                pass\n        if timeout is not None:\n            if timeout < 0:\n                raise ValueError(\"timeout is smaller than 0\")\n            else:\n                stop = time() + timeout\n        times_checked = 0\n        while not self.is_ready:\n            now = time()\n            times_checked += 1\n            if abort and abort.is_set():\n                False\n            if timeout is not None and stop <= now:\n                raise RuntimeError('Time out while waiting for ready in %s, module %s' % (self.name, self.__class__.__module__))\n            if times and times > times_checked:\n                False\n            if delay_between:\n                try:\n                    sleep(delay_between)\n                except IOError:  # negative values\n                    pass\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_dac_value(self, channel, value):\n        '''Write DAC\n        '''\n        self._intf.write(self._base_addr + self.MAX_5380_ADD, array('B', pack('B', value)))", "response": "Write the value to the DAC."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_dac_value(self, channel, value):\n        '''Write DAC\n        '''\n        # DAC value cannot be -128\n        if value == -128:\n            value = -127\n        if value < 0:\n            sign = 1\n        else:\n            sign = 0\n        value = (sign << 7) | (0x7F & abs(value))\n        self._intf.write(self._base_addr + self.DS_4424_ADD, array('B', pack('BB', channel, value)))", "response": "Write the value to the specified channel of the DAC."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_eeprom_calibration(self, temperature=False):  # use default values for temperature, EEPROM values are usually not calibrated and random\n        '''Reading EEPROM calibration for power regulators and temperature\n        '''\n        header = self.get_format()\n        if header == self.HEADER_V2:\n            data = self._read_eeprom(self.CAL_DATA_ADDR, size=calcsize(self.CAL_DATA_V2_FORMAT))\n            for idx, channel in enumerate(self._ch_cal.iterkeys()):\n                ch_data = data[idx * calcsize(self.CAL_DATA_CH_V2_FORMAT):(idx + 1) * calcsize(self.CAL_DATA_CH_V2_FORMAT)]\n                values = unpack_from(self.CAL_DATA_CH_V2_FORMAT, ch_data)\n                self._ch_cal[channel]['name'] = \"\".join([c for c in values[0] if (c in string.printable)])  # values[0].strip()\n                self._ch_cal[channel]['default'] = values[1]\n                self._ch_cal[channel]['ADCI']['gain'] = values[2]\n                self._ch_cal[channel]['ADCI']['offset'] = values[3]\n                self._ch_cal[channel]['ADCI']['iq_gain'] = values[4]\n                self._ch_cal[channel]['ADCI']['iq_offset'] = values[5]\n                self._ch_cal[channel]['ADCV']['gain'] = values[6]\n                self._ch_cal[channel]['ADCV']['offset'] = values[7]\n                self._ch_cal[channel]['DACV']['gain'] = values[8]\n                self._ch_cal[channel]['DACV']['offset'] = values[9]\n                if temperature:\n                    self._ch_cal[channel]['NTC']['B_NTC'] = values[10]\n                    self._ch_cal[channel]['NTC']['R1'] = values[11]\n                    self._ch_cal[channel]['NTC']['R2'] = values[12]\n                    self._ch_cal[channel]['NTC']['R4'] = values[13]\n                    self._ch_cal[channel]['NTC']['R_NTC_25'] = values[14]\n                    self._ch_cal[channel]['NTC']['VREF'] = values[15]\n        else:\n            raise ValueError('EEPROM data format not supported (header: %s)' % header)", "response": "Reads the EEPROM calibration for power regulators and temperature."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_current_limit(self, channel, value, unit='A'):\n        '''Setting current limit\n\n        Note: same limit for all channels.\n        '''\n        dac_offset = self._ch_cal[channel]['DACI']['offset']\n        dac_gain = self._ch_cal[channel]['DACI']['gain']\n\n        if unit == 'raw':\n            value = value\n        elif unit == 'A':\n            value = int((value - dac_offset) / dac_gain)\n        elif unit == 'mA':\n            value = int((value / 1000 - dac_offset) / dac_gain)\n        else:\n            raise TypeError(\"Invalid unit type.\")\n\n        DacMax5380._set_dac_value(self, channel, value)", "response": "Set current limit for all channels."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_position(self, x, y, speed=None):\n        ''' Move chuck to absolute position in um'''\n        if speed:\n            self._intf.write('MoveChuckSubsite %1.1f %1.1f R Y %d' % (x, y, speed))\n        else:\n            self._intf.write('MoveChuckSubsite %1.1f %1.1f R Y' % (x, y))", "response": "Move chuck to absolute position in um"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_position(self, dx, dy, speed=None):\n        ''' Move chuck relative to actual position in um'''\n        if speed:\n            self._intf.write('MoveChuckPosition %1.1f %1.1f R Y %d' % (dx, dy, speed))\n        else:\n            self._intf.write('MoveChuckPosition %1.1f %1.1f R Y' % (dx, dy))", "response": "Move chuck relative to actual position in um"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the current read chuck position.", "response": "def get_position(self):\n        ''' Read chuck position (x, y, z)'''\n        reply = self._intf.query('ReadChuckPosition Y H')[2:]\n        return [float(i) for i in reply.split()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves chuck to wafer map chip index", "response": "def get_die(self):\n        ''' Move chuck to wafer map chip index'''\n        reply = self._intf.query('ReadMapPosition')\n        values = reply[2:].split(' ')\n        return (int(values[0]), int(values[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear(self):\n        'Clear tracks in memory - all zero'\n        for track in self._tracks:\n            self._tracks[track].setall(False)", "response": "Clear tracks in memory - all zero"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_data(self):\n        ''' Reading data from SiTCP FIFO (via TCP).\n\n        Returns\n        -------\n        array : numpy.ndarray\n            Array of unsigned integers (32 bit).\n        '''\n        fifo_size = self._intf._get_tcp_data_size()\n        fifo_int_size = int((fifo_size - (fifo_size % 4)) / 4)\n        data = self._intf._get_tcp_data(fifo_int_size * 4)\n        return np.frombuffer(data, dtype=np.dtype('<u4'))", "response": "Reads the data from the TCP FIFO. Returns ------- array : numpy. ndarray"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending data to the NX - OS device via TCP.", "response": "def set_data(self, data):\n        ''' Sending data to via TCP.\n\n        Parameters\n        ----------\n        data : array\n            Array of unsigned integers (32 bit).\n        '''\n        data = array.array('B', struct.unpack(\"{}B\".format(len(data) * 4), struct.pack(\"{}I\".format(len(data)), *data)))\n        self._intf._send_tcp_data(data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef program_global_reg(self):\n\n        self._clear_strobes()\n\n        gr_size = len(self['GLOBAL_REG'][:])  # get the size\n        self['SEQ']['SHIFT_IN'][0:gr_size] = self['GLOBAL_REG'][:]  # this will be shifted out\n        self['SEQ']['GLOBAL_SHIFT_EN'][0:gr_size] = bitarray(gr_size * '1')  # this is to enable clock\n        self['SEQ']['GLOBAL_CTR_LD'][gr_size + 1:gr_size + 2] = bitarray(\"1\")  # load signals\n        self['SEQ']['GLOBAL_DAC_LD'][gr_size + 1:gr_size + 2] = bitarray(\"1\")\n\n        # Execute the program (write bits to output pins)\n        # + 1 extra 0 bit so that everything ends on LOW instead of HIGH\n        self._run_seq(gr_size + 3)", "response": "This function sends the global register to the chip and then reads the values from the chip into the chip."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef program_pixel_reg(self, enable_receiver=True):\n\n        self._clear_strobes()\n\n        # enable receiver it work only if pixel register is enabled/clocked\n        self['PIXEL_RX'].set_en(enable_receiver)\n\n        px_size = len(self['PIXEL_REG'][:])  # get the size\n        self['SEQ']['SHIFT_IN'][0:px_size] = self['PIXEL_REG'][:]  # this will be shifted out\n        self['SEQ']['PIXEL_SHIFT_EN'][0:px_size] = bitarray(px_size * '1')  # this is to enable clock\n\n        self._run_seq(px_size + 1)", "response": "Program the pixel register into the chip."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns the sequence generator.", "response": "def _run_seq(self, size):\n        \"\"\"\n        Send the contents of self['SEQ'] to the chip and wait until it finishes.\n\n        \"\"\"\n\n        # Write the sequence to the sequence generator (hw driver)\n        self['SEQ'].write(size)  # write pattern to memory\n\n        self['SEQ'].set_size(size)  # set size\n        self['SEQ'].set_repeat(1)  # set repeat\n        self['SEQ'].start()  # start\n\n        while not self['SEQ'].get_done():\n            time.sleep(0.01)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, addr, data):\r\n        '''Write access.\r\n\r\n        :param addr: i2c slave address\r\n        :type addr: char\r\n        :param data: array/list of bytes\r\n        :type data: iterable\r\n        :rtype: None\r\n\r\n        '''\r\n        self.set_addr(addr & 0xfe)\r\n        self.set_data(data)\r\n        self.set_size(len(data))\r\n        self.start()\r\n        while not self.is_ready:\r\n            pass", "response": "Write the contents of data to the specified i2c slave address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, addr, size):\r\n        '''Read access.\r\n\r\n        :param addr: i2c slave address\r\n        :type addr: char\r\n        :param size: size of transfer\r\n        :type size: int\r\n        :returns: data byte array\r\n        :rtype: array.array('B')\r\n\r\n        '''\r\n        self.set_addr(addr | 0x01)\r\n        self.set_size(size)\r\n        self.start()\r\n        while not self.is_ready:\r\n            pass\r\n\r\n        return self.get_data(size)", "response": "Read the next set of bytes from the slave."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef full_parser():\n    global _full_parser\n\n    if _full_parser:\n        return _full_parser\n\n    luigi_parser = luigi.cmdline_parser.CmdlineParser.get_instance()\n    if not luigi_parser:\n        return None\n\n    # build the full argument parser with luigi helpers\n    root_task = luigi_parser.known_args.root_task\n    _full_parser = luigi_parser._build_parser(root_task)\n\n    logger.debug(\"build full luigi argument parser\")\n\n    return _full_parser", "response": "Returns the full argument parser for the luigi command line parser."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new ArgumentParser instance that only contains paremeter actions of the root task.", "response": "def root_task_parser():\n    \"\"\"\n    Returns a new *ArgumentParser* instance that only contains paremeter actions of the root task.\n    The returned instance is cached.\n    \"\"\"\n    global _root_task_parser\n\n    if _root_task_parser:\n        return _root_task_parser\n\n    luigi_parser = luigi.cmdline_parser.CmdlineParser.get_instance()\n    if not luigi_parser:\n        return None\n\n    root_task = luigi_parser.known_args.root_task\n\n    # get all root task parameter destinations\n    root_dests = []\n    for task_name, _, param_name, _ in luigi.task_register.Register.get_all_params():\n        if task_name == root_task:\n            root_dests.append(param_name)\n\n    # create a new parser and add all root actions\n    _root_task_parser = ArgumentParser(add_help=False)\n    for action in list(full_parser()._actions):\n        if not action.option_strings or action.dest in root_dests:\n            _root_task_parser._add_action(action)\n\n    logger.debug(\"build luigi argument parser for root task {}\".format(root_task))\n\n    return _root_task_parser"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the list of command line arguments that do not belong to the root task.", "response": "def global_cmdline_args():\n    \"\"\"\n    Returns the list of command line arguments that do not belong to the root task. The returned\n    list is cached. Example:\n\n    .. code-block:: python\n\n        global_cmdline_args()\n        # -> [\"--local-scheduler\"]\n    \"\"\"\n    global _global_cmdline_args\n\n    if _global_cmdline_args:\n        return _global_cmdline_args\n\n    luigi_parser = luigi.cmdline_parser.CmdlineParser.get_instance()\n    if not luigi_parser:\n        return None\n\n    _global_cmdline_args = root_task_parser().parse_known_args(luigi_parser.cmdline_args)[1]\n\n    return _global_cmdline_args"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary of global command line arguments to their current values.", "response": "def global_cmdline_values():\n    \"\"\"\n    Returns a dictionary of global command line arguments (computed with\n    :py:func:`global_cmdline_args`) to their current values. The returnd dictionary is cached.\n    Example:\n\n    .. code-block:: python\n\n        global_cmdline_values()\n        # -> {\"core_local_scheduler\": True}\n    \"\"\"\n    global _global_cmdline_values\n\n    if _global_cmdline_values:\n        return _global_cmdline_values\n\n    luigi_parser = luigi.cmdline_parser.CmdlineParser.get_instance()\n    if not luigi_parser:\n        return None\n\n    # go through all actions of the full luigi parser and compare option strings\n    # with the global cmdline args\n    parser = full_parser()\n    global_args = global_cmdline_args()\n    _global_cmdline_values = {}\n    for action in parser._actions:\n        if any(arg in action.option_strings for arg in global_args):\n            _global_cmdline_values[action.dest] = getattr(luigi_parser.known_args, action.dest)\n\n    return _global_cmdline_values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_cmdline_arg(args, arg, *values):\n    if arg not in args:\n        args = list(args) + [arg] + list(values)\n    return args", "response": "Adds a command line argument arg to a list of argument values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the command line argument arg from a list of arguments args.", "response": "def remove_cmdline_arg(args, arg, n=1):\n    \"\"\"\n    Removes the command line argument *args* from a list of arguments *args*, e.g. as returned from\n    :py:func:`global_cmdline_args`. When *n* is 1 or less, only the argument is removed. Otherwise,\n    the following *n-1* values are removed. Example:\n\n    .. code-block:: python\n\n        args = global_cmdline_values()\n        # -> [\"--local-scheduler\", \"--workers\", \"4\"]\n\n        remove_cmdline_arg(args, \"--local-scheduler\")\n        # -> [\"--workers\", \"4\"]\n\n        remove_cmdline_arg(args, \"--workers\", 2)\n        # -> [\"--local-scheduler\"]\n    \"\"\"\n    if arg in args:\n        idx = args.index(arg)\n        args = list(args)\n        del args[idx:idx + max(n, 1)]\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_transfer_kwargs(kwargs, skip=None):\n    skip = make_list(skip) if skip else []\n    transfer_kwargs = {\n        name: kwargs.pop(name)\n        for name in [\"cache\", \"prefer_cache\", \"retries\", \"retry_delay\"]\n        if name in kwargs and name not in skip\n    }\n    return transfer_kwargs, kwargs", "response": "Takes keyword arguments kwargs and returns them in two separate dictionaries depending on their\n    content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef job_data(cls, job_id=dummy_job_id, branches=None, **kwargs):\n        return dict(job_id=job_id, branches=branches or [])", "response": "Returns a dictionary containing default job submission information such as the job_id and branches."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef job_data(cls, job_id=dummy_job_id, status=None, code=None, error=None, **kwargs):\n        return dict(job_id=job_id, status=status, code=code, error=error)", "response": "Returns a dictionary containing default job status information such as the job_id status code and error message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the attribute of the actial task named name.", "response": "def _get_task_attribute(self, name, fallback=False):\n        \"\"\"\n        Return an attribute of the actial task named ``<workflow_type>_<name>``.\n        When the attribute does not exist and *fallback* is *True*, try to return the task attribute\n        simply named *name*. In any case, if a requested task attribute is eventually not found, an\n        AttributeError is raised.\n        \"\"\"\n        attr = \"{}_{}\".format(self.workflow_type, name)\n        if not fallback:\n            return getattr(self.task, attr)\n        else:\n            value = getattr(self.task, attr, no_value)\n            return value if value != no_value else getattr(self.task, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output(self):\n        task = self.task\n\n        # get the directory where the control outputs are stored\n        out_dir = self._get_task_attribute(\"output_directory\")()\n\n        # define outputs\n        outputs = OrderedDict()\n        postfix = self._get_task_attribute(\"output_postfix\")()\n\n        # a file containing the submission data, i.e. job ids etc\n        submission_file = \"{}_submission{}.json\".format(self.workflow_type, postfix)\n        outputs[\"submission\"] = out_dir.child(submission_file, type=\"f\")\n        outputs[\"submission\"].optional = True\n\n        # a file containing status data when the jobs are done\n        if not task.no_poll:\n            status_file = \"{}_status{}.json\".format(self.workflow_type, postfix)\n            outputs[\"status\"] = out_dir.child(status_file, type=\"f\")\n            outputs[\"status\"].optional = True\n\n        # update with upstream output when not just controlling running jobs\n        if not task.is_controlling_remote_jobs():\n            outputs.update(super(BaseRemoteWorkflowProxy, self).output())\n\n        return outputs", "response": "Returns the default workflow outputs in an ordered dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump_submission_data(self):\n        # renew the dashboard config\n        self.submission_data[\"dashboard_config\"] = self.dashboard.get_persistent_config()\n\n        # write the submission data to the output file\n        self._outputs[\"submission\"].dump(self.submission_data, formatter=\"json\", indent=4)", "response": "Dumps the current submission data to the submission file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        task = self.task\n        self._outputs = self.output()\n\n        # create the job dashboard interface\n        self.dashboard = task.create_job_dashboard() or NoJobDashboard()\n\n        # read submission data and reset some values\n        submitted = not task.ignore_submission and self._outputs[\"submission\"].exists()\n        if submitted:\n            self.submission_data.update(self._outputs[\"submission\"].load(formatter=\"json\"))\n            task.tasks_per_job = self.submission_data.tasks_per_job\n            self.dashboard.apply_config(self.submission_data.dashboard_config)\n\n        # when the branch outputs, i.e. the \"collection\" exists, just create dummy control outputs\n        if \"collection\" in self._outputs and self._outputs[\"collection\"].exists():\n            self.touch_control_outputs()\n\n        # cancel jobs?\n        elif self._cancel_jobs:\n            if submitted:\n                self.cancel()\n\n        # cleanup jobs?\n        elif self._cleanup_jobs:\n            if submitted:\n                self.cleanup()\n\n        # submit and/or wait while polling\n        else:\n            # maybe set a tracking url\n            tracking_url = self.dashboard.create_tracking_url()\n            if tracking_url:\n                task.set_tracking_url(tracking_url)\n\n            # ensure the output directory exists\n            if not submitted:\n                self._outputs[\"submission\"].parent.touch()\n\n            # at this point, when the status file exists, it is considered outdated\n            if \"status\" in self._outputs:\n                self._outputs[\"status\"].remove()\n\n            try:\n                # instantiate the configured job file factory, not kwargs yet\n                self.job_file_factory = self.create_job_file_factory()\n\n                # submit\n                if not submitted:\n                    # set the initial list of unsubmitted jobs\n                    branches = sorted(task.branch_map.keys())\n                    branch_chunks = list(iter_chunks(branches, task.tasks_per_job))\n                    self.submission_data.unsubmitted_jobs = OrderedDict(\n                        (i + 1, branches) for i, branches in enumerate(branch_chunks)\n                    )\n                    self.submit()\n\n                    # sleep once to give the job interface time to register the jobs\n                    post_submit_delay = self._get_task_attribute(\"post_submit_delay\")()\n                    if post_submit_delay:\n                        time.sleep(post_submit_delay)\n\n                # start status polling when a) no_poll is not set, or b) the jobs were already\n                # submitted so that failed jobs are resubmitted after a single polling iteration\n                if not task.no_poll or submitted:\n                    self.poll()\n\n            finally:\n                # in any event, cleanup the job file\n                if self.job_file_factory:\n                    self.job_file_factory.cleanup_dir(force=False)", "response": "This method is called by the base class to start the processing of jobs and creates the job dashboard interface and the status polling and cleanup jobs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cancel(self):\n        task = self.task\n\n        # get job ids from submission data\n        job_ids = [\n            d[\"job_id\"] for d in self.submission_data.jobs.values()\n            if d[\"job_id\"] not in (self.submission_data.dummy_job_id, None)\n        ]\n        if not job_ids:\n            return\n\n        # cancel jobs\n        task.publish_message(\"going to cancel {} jobs\".format(len(job_ids)))\n        errors = self.job_manager.cancel_batch(job_ids)\n\n        # print errors\n        if errors:\n            print(\"{} error(s) occured while cancelling {} job(s) of task {}:\".format(\n                len(errors), len(job_ids), task.task_id))\n            tmpl = \"    {}\"\n            for i, err in enumerate(errors):\n                print(tmpl.format(err))\n                if i + 1 >= self.show_errors:\n                    remaining = len(errors) - self.show_errors\n                    if remaining > 0:\n                        print(\"    ... and {} more\".format(remaining))\n                    break\n\n        # inform the dashboard\n        for job_num, job_data in six.iteritems(self.submission_data.jobs):\n            task.forward_dashboard_event(self.dashboard, job_data, \"action.cancel\", job_num)", "response": "Cancels running jobs. The job ids are read from the submission file which has to exist\n        for obvious reasons."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cleanup(self):\n        task = self.task\n\n        # get job ids from submission data\n        job_ids = [\n            d[\"job_id\"] for d in self.submission_data.jobs.values()\n            if d[\"job_id\"] not in (self.submission_data.dummy_job_id, None)\n        ]\n        if not job_ids:\n            return\n\n        # cleanup jobs\n        task.publish_message(\"going to cleanup {} jobs\".format(len(job_ids)))\n        errors = self.job_manager.cleanup_batch(job_ids)\n\n        # print errors\n        if errors:\n            print(\"{} error(s) occured while cleaning up {} job(s) of task {}:\".format(\n                len(errors), len(job_ids), task.task_id))\n            tmpl = \"    {}\"\n            for i, err in enumerate(errors):\n                print(tmpl.format(err))\n                if i + 1 >= self.show_errors:\n                    remaining = len(errors) - self.show_errors\n                    if remaining > 0:\n                        print(\"    ... and {} more\".format(remaining))\n                    break", "response": "Clean up jobs on the remote run location."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef submit(self, retry_jobs=None):\n        task = self.task\n\n        # helper to check if a job can be skipped\n        # rule: skip a job when only_missing is set to True and all its branch tasks are complete\n        def skip_job(job_num, branches):\n            if not task.only_missing:\n                return False\n            elif job_num in self.skip_jobs:\n                return self.skip_jobs[job_num]\n            else:\n                self.skip_jobs[job_num] = all(task.as_branch(b).complete() for b in branches)\n                # when the job is skipped, write a dummy entry into submission data\n                if self.skip_jobs[job_num]:\n                    self.submission_data.jobs[job_num] = self.submission_data_cls.job_data(\n                        branches=branches)\n                return self.skip_jobs[job_num]\n\n        # collect data of jobs that should be submitted: num -> branches\n        submit_jobs = OrderedDict()\n\n        # handle jobs for resubmission\n        if retry_jobs:\n            for job_num, branches in six.iteritems(retry_jobs):\n                # even retry jobs can be skipped\n                if skip_job(job_num, branches):\n                    continue\n\n                # the number of parallel jobs might be reached as well\n                # in that case, add the jobs back to the unsubmitted ones and update the job id\n                n = self.poll_data.n_active + len(submit_jobs)\n                if n >= self.poll_data.n_parallel:\n                    self.submission_data.unsubmitted_jobs[job_num] = branches\n                    del self.submission_data.jobs[job_num]\n                    continue\n\n                # mark job for resubmission\n                submit_jobs[job_num] = sorted(branches)\n\n        # fill with jobs from the list of unsubmitted jobs until maximum number of parallel jobs is\n        # reached\n        new_jobs = OrderedDict()\n        for job_num, branches in list(self.submission_data.unsubmitted_jobs.items()):\n            # remove jobs that don't need to be submitted\n            if skip_job(job_num, branches):\n                del self.submission_data.unsubmitted_jobs[job_num]\n                continue\n\n            # do nothing when n_parallel is already reached\n            n = self.poll_data.n_active + len(submit_jobs) + len(new_jobs)\n            if n >= self.poll_data.n_parallel:\n                continue\n\n            # mark jobs for submission\n            del self.submission_data.unsubmitted_jobs[job_num]\n            new_jobs[job_num] = sorted(branches)\n\n        # add new jobs to the jobs to submit, maybe also shuffle\n        new_submission_data = OrderedDict()\n        new_job_nums = list(new_jobs.keys())\n        if task.shuffle_jobs:\n            random.shuffle(new_job_nums)\n        for job_num in new_job_nums:\n            submit_jobs[job_num] = new_jobs[job_num]\n\n        # when there is nothing to submit, dump the submission data to the output file and stop here\n        if not submit_jobs:\n            if retry_jobs or self.submission_data.unsubmitted_jobs:\n                self.dump_submission_data()\n            return new_submission_data\n\n        # create job submission files\n        job_files = [self.create_job_file(*tpl) for tpl in six.iteritems(submit_jobs)]\n\n        # log some stats\n        dst_info = self.destination_info() or \"\"\n        dst_info = dst_info and (\", \" + dst_info)\n        task.publish_message(\"going to submit {} {} job(s){}\".format(\n            len(submit_jobs), self.workflow_type, dst_info))\n\n        # actual submission\n        job_ids = self.submit_jobs(job_files)\n\n        # store submission data\n        errors = []\n        for job_num, job_id in six.moves.zip(submit_jobs, job_ids):\n            # handle errors\n            error = (job_num, job_id) if isinstance(job_id, Exception) else None\n            if error:\n                errors.append((job_num, job_id))\n                job_id = self.submission_data_cls.dummy_job_id\n\n            # build the job data\n            branches = submit_jobs[job_num]\n            job_data = self.submission_data_cls.job_data(job_id=job_id, branches=branches)\n            self.submission_data.jobs[job_num] = job_data\n            new_submission_data[job_num] = job_data\n\n            # set the attempt number in the submission data\n            self.submission_data.attempts.setdefault(job_num, 0)\n\n            # inform the dashboard\n            task.forward_dashboard_event(self.dashboard, job_data, \"action.submit\", job_num)\n\n        # dump the submission data to the output file\n        self.dump_submission_data()\n\n        # raise exceptions or log\n        if errors:\n            print(\"{} error(s) occured during job submission of task {}:\".format(\n                len(errors), task.task_id))\n            tmpl = \"    job {}: {}\"\n            for i, tpl in enumerate(errors):\n                print(tmpl.format(*tpl))\n                if i + 1 >= self.show_errors:\n                    remaining = len(errors) - self.show_errors\n                    if remaining > 0:\n                        print(\"    ... and {} more\".format(remaining))\n                    break\n        else:\n            task.publish_message(\"submitted {} job(s)\".format(len(submit_jobs)) + dst_info)\n\n        return new_submission_data", "response": "Submit all jobs in the current branch set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef poll(self):\n        task = self.task\n\n        # total job count\n        n_jobs = len(self.submission_data)\n\n        # store the number of consecutive polling failures and get the maximum number of polls\n        n_poll_fails = 0\n        if task.walltime == NO_FLOAT:\n            max_polls = sys.maxsize\n        else:\n            max_polls = int(math.ceil((task.walltime * 3600.) / (task.poll_interval * 60.)))\n\n        # update variable attributes for polling\n        self.poll_data.n_finished_min = task.acceptance * (1 if task.acceptance > 1 else n_jobs)\n        self.poll_data.n_failed_max = task.tolerance * (1 if task.tolerance > 1 else n_jobs)\n\n        # track finished and failed jobs in dicts holding status data\n        finished_jobs = OrderedDict()\n        failed_jobs = OrderedDict()\n\n        # start the poll loop\n        for i in six.moves.range(max_polls):\n            # sleep after the first iteration\n            if i > 0:\n                time.sleep(task.poll_interval * 60)\n\n            # determine the currently active jobs, i.e., the jobs whose states should be checked\n            active_jobs = OrderedDict()\n            for job_num, data in six.iteritems(self.submission_data.jobs):\n                if job_num in finished_jobs or job_num in failed_jobs:\n                    continue\n                if self.skip_jobs.get(job_num):\n                    finished_jobs[job_num] = self.status_data_cls.job_data(\n                        status=self.job_manager.FINISHED, code=0)\n                else:\n                    data = data.copy()\n                    if not data[\"job_id\"]:\n                        data[\"job_id\"] = self.status_data_cls.dummy_job_id\n                    active_jobs[job_num] = data\n            self.poll_data.n_active = len(active_jobs)\n\n            # query job states\n            job_ids = [data[\"job_id\"] for data in six.itervalues(active_jobs)]  # noqa: F812\n            _states, errors = self.job_manager.query_batch(job_ids)\n            if errors:\n                print(\"{} error(s) occured during job status query of task {}:\".format(\n                    len(errors), task.task_id))\n                tmpl = \"    {}\"\n                for i, err in enumerate(errors):\n                    print(tmpl.format(err))\n                    if i + 1 >= self.show_errors:\n                        remaining = len(errors) - self.show_errors\n                        if remaining > 0:\n                            print(\"    ... and {} more\".format(remaining))\n                        break\n\n                n_poll_fails += 1\n                if task.poll_fails > 0 and n_poll_fails > task.poll_fails:\n                    raise Exception(\"poll_fails exceeded\")\n                else:\n                    continue\n            else:\n                n_poll_fails = 0\n\n            # states stores job_id's as keys, so replace them by using job_num's\n            states = OrderedDict()\n            for job_num, data in six.iteritems(active_jobs):\n                states[job_num] = self.status_data_cls.job_data(**_states[data[\"job_id\"]])\n\n            # store jobs per status and take further actions depending on the status\n            pending_jobs = OrderedDict()\n            running_jobs = OrderedDict()\n            newly_failed_jobs = OrderedDict()\n            retry_jobs = OrderedDict()\n            for job_num, data in six.iteritems(states):\n                if data[\"status\"] == self.job_manager.PENDING:\n                    pending_jobs[job_num] = data\n                    task.forward_dashboard_event(self.dashboard, data, \"status.pending\", job_num)\n\n                elif data[\"status\"] == self.job_manager.RUNNING:\n                    running_jobs[job_num] = data\n                    task.forward_dashboard_event(self.dashboard, data, \"status.running\", job_num)\n\n                elif data[\"status\"] == self.job_manager.FINISHED:\n                    finished_jobs[job_num] = data\n                    self.poll_data.n_active -= 1\n                    task.forward_dashboard_event(self.dashboard, data, \"status.finished\", job_num)\n\n                elif data[\"status\"] in (self.job_manager.FAILED, self.job_manager.RETRY):\n                    newly_failed_jobs[job_num] = data\n                    self.poll_data.n_active -= 1\n\n                    # retry or ultimately failed?\n                    if self.job_retries[job_num] < task.retries:\n                        self.job_retries[job_num] += 1\n                        self.submission_data.attempts[job_num] += 1\n                        data[\"status\"] = self.job_manager.RETRY\n                        retry_jobs[job_num] = self.submission_data.jobs[job_num][\"branches\"]\n                        task.forward_dashboard_event(self.dashboard, data, \"status.retry\", job_num)\n                    else:\n                        failed_jobs[job_num] = data\n                        task.forward_dashboard_event(self.dashboard, data, \"status.failed\", job_num)\n\n                else:\n                    raise Exception(\"unknown job status '{}'\".format(data[\"status\"]))\n\n            # gather some counts\n            n_pending = len(pending_jobs)\n            n_running = len(running_jobs)\n            n_finished = len(finished_jobs)\n            n_retry = len(retry_jobs)\n            n_failed = len(failed_jobs)\n            n_unsubmitted = len(self.submission_data.unsubmitted_jobs)\n\n            # log the status line\n            counts = (n_pending, n_running, n_finished, n_retry, n_failed)\n            if task.parallel_jobs > 0:\n                counts = (n_unsubmitted,) + counts\n            status_line = self.job_manager.status_line(counts, last_counts=True, sum_counts=n_jobs,\n                color=True, align=task.align_status_line)\n            task.publish_message(status_line)\n            self.last_status_counts = counts\n\n            # inform the scheduler about the progress\n            task.publish_progress(100. * n_finished / n_jobs)\n\n            # log newly failed jobs\n            if newly_failed_jobs:\n                print(\"{} failed job(s) in task {}:\".format(len(newly_failed_jobs), task.task_id))\n                tmpl = \"    job: {}, branches: {}, id: {job_id}, status: {status}, code: {code}, \" \\\n                    \"error: {error}\"\n                for i, (job_num, data) in enumerate(six.iteritems(newly_failed_jobs)):\n                    branches = self.submission_data.jobs[job_num][\"branches\"]\n                    print(tmpl.format(job_num, \",\".join(str(b) for b in branches), **data))\n                    if i + 1 >= self.show_errors:\n                        remaining = len(newly_failed_jobs) - self.show_errors\n                        if remaining > 0:\n                            print(\"    ... and {} more\".format(remaining))\n                        break\n\n            # infer the overall status\n            reached_end = n_jobs == n_finished + n_failed\n            finished = n_finished >= self.poll_data.n_finished_min\n            failed = n_failed > self.poll_data.n_failed_max\n            unreachable = n_jobs - n_failed < self.poll_data.n_finished_min\n            if finished:\n                # write status output\n                if \"status\" in self._outputs:\n                    status_data = self.status_data_cls()\n                    status_data.jobs.update(finished_jobs)\n                    status_data.jobs.update(states)\n                    self._outputs[\"status\"].dump(status_data, formatter=\"json\", indent=4)\n                break\n            elif failed:\n                failed_nums = [job_num for job_num in failed_jobs if job_num not in retry_jobs]\n                raise Exception(\"tolerance exceeded for jobs {}\".format(failed_nums))\n            elif unreachable:\n                err = None\n                if reached_end:\n                    err = \"acceptance of {} not reached, total jobs: {}, failed jobs: {}\"\n                elif task.check_unreachable_acceptance:\n                    err = \"acceptance of {} unreachable, total jobs: {}, failed jobs: {}\"\n                if err:\n                    raise Exception(err.format(self.poll_data.n_finished_min, n_jobs, n_failed))\n\n            # configurable poll callback\n            task.poll_callback(self.poll_data)\n\n            # trigger automatic resubmission and submission of unsubmitted jobs\n            self.submit(retry_jobs)\n\n            # break when no polling is desired\n            # we can get to this point when there was already a submission and the no_poll\n            # parameter was set so that only failed jobs are resubmitted once\n            if task.no_poll:\n                break\n        else:\n            # walltime exceeded\n            raise Exception(\"walltime exceeded\")", "response": "This method is called by the poll method in the job manager to check the status of the jobs in the submission."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating and saves dummy submission and status files. This method is called in case the branch task outputs exist.", "response": "def touch_control_outputs(self):\n        \"\"\"\n        Creates and saves dummy submission and status files. This method is called in case the\n        collection of branch task outputs exists.\n        \"\"\"\n        task = self.task\n\n        # create the parent directory\n        self._outputs[\"submission\"].parent.touch()\n\n        # get all branch indexes and chunk them by tasks_per_job\n        branch_chunks = list(iter_chunks(task.branch_map.keys(), task.tasks_per_job))\n\n        # submission output\n        if not self._outputs[\"submission\"].exists():\n            submission_data = self.submission_data.copy()\n            # set dummy submission data\n            submission_data.jobs.clear()\n            for i, branches in enumerate(branch_chunks):\n                job_num = i + 1\n                submission_data.jobs[job_num] = self.submission_data_cls.job_data(branches=branches)\n            self._outputs[\"submission\"].dump(submission_data, formatter=\"json\", indent=4)\n\n        # status output\n        if \"status\" in self._outputs and not self._outputs[\"status\"].exists():\n            status_data = self.status_data_cls()\n            # set dummy status data\n            for i, branches in enumerate(branch_chunks):\n                job_num = i + 1\n                status_data.jobs[job_num] = self.status_data_cls.job_data(\n                    status=self.job_manager.FINISHED, code=0)\n            self._outputs[\"status\"].dump(status_data, formatter=\"json\", indent=4)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef forward_dashboard_event(self, dashboard, job_data, event, job_num):\n        # possible events:\n        #   - action.submit\n        #   - action.cancel\n        #   - status.pending\n        #   - status.running\n        #   - status.finished\n        #   - status.retry\n        #   - status.failed\n        # forward to dashboard in any event by default\n        return dashboard.publish(job_data, event, job_num)", "response": "Forward the event to the dashboard."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef localize(self, mode=\"r\", perm=None, parent_perm=None, **kwargs):\n        if mode not in (\"r\", \"w\"):\n            raise Exception(\"unknown mode '{}', use r or w\".format(mode))\n\n        # get additional arguments\n        skip_copy = kwargs.pop(\"skip_copy\", False)\n        is_tmp = kwargs.pop(\"is_tmp\", mode == \"w\")\n\n        if mode == \"r\":\n            if is_tmp:\n                # create a temporary target\n                tmp = self.__class__(is_tmp=self.ext(n=1) or True)\n\n                # always copy\n                self.copy_to_local(tmp)\n\n                # yield the copy\n                try:\n                    yield tmp\n                finally:\n                    tmp.remove()\n            else:\n                # simply yield\n                yield self\n\n        else:  # write mode\n            if is_tmp:\n                # create a temporary target\n                tmp = self.__class__(is_tmp=self.ext(n=1) or True)\n\n                # copy when existing\n                if not skip_copy and self.exists():\n                    self.copy_to_local(tmp)\n\n                # yield the copy\n                try:\n                    yield tmp\n\n                    # move back again\n                    if tmp.exists():\n                        tmp.move_to_local(self, dir_perm=parent_perm)\n                        self.chmod(perm)\n                    else:\n                        logger.warning(\"cannot move non-existing localized file target {!r}\".format(\n                            self))\n                finally:\n                    tmp.remove()\n            else:\n                # create the parent dir\n                self.parent.touch(perm=parent_perm)\n\n                # simply yield\n                yield self\n\n                if self.exists():\n                    self.chmod(perm)", "response": "A generator that yields the local version of the current file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset up the command line parser for the index subprogram and adds it to the given sub_parsers.", "response": "def setup_parser(sub_parsers):\n    \"\"\"\n    Sets up the command line parser for the *index* subprogram and adds it to *sub_parsers*.\n    \"\"\"\n    parser = sub_parsers.add_parser(\"index\", prog=\"law index\", description=\"Create or update the\"\n        \" (human-readable) law task index file ({}). This is only required for the shell\"\n        \" auto-completion.\".format(Config.instance().get(\"core\", \"index_file\")))\n\n    parser.add_argument(\"--modules\", \"-m\", nargs=\"+\", help=\"additional modules to traverse\")\n    parser.add_argument(\"--no-externals\", \"-e\", action=\"store_true\", help=\"skip external tasks\")\n    parser.add_argument(\"--remove\", \"-r\", action=\"store_true\", help=\"remove the index file and\"\n        \" exit\")\n    parser.add_argument(\"--location\", \"-l\", action=\"store_true\", help=\"print the location of the\"\n        \" index file and exit\")\n    parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\", help=\"verbose output\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the index subprogram with parsed commandline args.", "response": "def execute(args):\n    \"\"\"\n    Executes the *index* subprogram with parsed commandline *args*.\n    \"\"\"\n    index_file = Config.instance().get_expanded(\"core\", \"index_file\")\n\n    # just print the file location?\n    if args.location:\n        print(index_file)\n        return\n\n    # just remove the index file?\n    if args.remove:\n        if os.path.exists(index_file):\n            os.remove(index_file)\n            print(\"removed index file {}\".format(index_file))\n        return\n\n    # get modules to lookup\n    lookup = [m.strip() for m in Config.instance().keys(\"modules\")]\n    if args.modules:\n        lookup += args.modules\n\n    print(\"loading tasks from {} module(s)\".format(len(lookup)))\n\n    # loop through modules, import everything to load tasks\n    for modid in lookup:\n        if not modid:\n            continue\n\n        if args.verbose:\n            sys.stdout.write(\"loading module '{}'\".format(modid))\n\n        try:\n            import_module(modid)\n        except Exception as e:\n            if not args.verbose:\n                print(\"Error in module '{}': {}\".format(colored(modid, \"red\"), str(e)))\n            else:\n                print(\"\\n\\nError in module '{}':\".format(colored(modid, \"red\")))\n                traceback.print_exc()\n            continue\n\n        if args.verbose:\n            print(\", {}\".format(colored(\"done\", style=\"bright\")))\n\n    # determine tasks to write into the index file\n    seen_families = []\n    task_classes = []\n    lookup = [Task]\n    while lookup:\n        cls = lookup.pop(0)\n        lookup.extend(cls.__subclasses__())\n\n        # skip already seen task families\n        if cls.task_family in seen_families:\n            continue\n        seen_families.append(cls.task_family)\n\n        # skip when explicitly excluded\n        if cls.exclude_index:\n            continue\n\n        # skip external tasks\n        is_external_task = issubclass(cls, ExternalTask)\n        if args.no_externals and is_external_task:\n            continue\n\n        # skip non-external tasks without run implementation\n        run_is_callable = callable(getattr(cls, \"run\", None))\n        run_is_abstract = getattr(cls.run, \"__isabstractmethod__\", False)\n        if not is_external_task and (not run_is_callable or run_is_abstract):\n            continue\n\n        task_classes.append(cls)\n\n    def get_task_params(cls):\n        params = []\n        for attr in dir(cls):\n            member = getattr(cls, attr)\n            if isinstance(member, luigi.Parameter):\n                exclude = getattr(cls, \"exclude_params_index\", set())\n                if not multi_match(attr, exclude, any):\n                    params.append(attr.replace(\"_\", \"-\"))\n        return params\n\n    def index_line(cls, params):\n        # format: \"module_id:task_family:param param ...\"\n        return \"{}:{}:{}\".format(cls.__module__, cls.task_family, \" \".join(params))\n\n    stats = OrderedDict()\n\n    # write the index file\n    if not os.path.exists(os.path.dirname(index_file)):\n        os.makedirs(os.path.dirname(index_file))\n\n    with open(index_file, \"w\") as f:\n        for cls in task_classes:\n            # get prams\n            params = get_task_params(cls)\n\n            # fill stats\n            if cls.__module__ not in stats:\n                stats[cls.__module__] = []\n            stats[cls.__module__].append((cls.task_family, params))\n\n            f.write(index_line(cls, params) + \"\\n\")\n\n    # print stats\n    if args.verbose:\n        for mod, data in six.iteritems(stats):\n            print(\"\\nmodule '{}', {} task(s):\".format(colored(mod, style=\"bright\"), len(data)))\n            for task_family, _ in data:\n                print(\"    - {}\".format(colored(task_family, \"green\")))\n        print(\"\")\n\n    print(\"written {} task(s) to index file '{}'\".format(len(task_classes), index_file))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of luigi - internal configuration parameters.", "response": "def get_global_parameters(config_names=(\"core\", \"scheduler\", \"worker\", \"retcode\")):\n    \"\"\"\n    Returns a list of global, luigi-internal configuration parameters. Each list item is a 4-tuple\n    containing the configuration class, the parameter instance, the parameter name, and the full\n    parameter name in the cli. When *config_names* is set, it should be a list of configuration\n    class names that are exclusively taken into account.\n    \"\"\"\n    params = []\n    for cls in luigi.task.Config.__subclasses__():\n        if config_names and cls.__name__ not in config_names:\n            continue\n\n        for attr in dir(cls):\n            param = getattr(cls, attr)\n            if not isinstance(param, luigi.Parameter):\n                continue\n\n            full_name = attr.replace(\"_\", \"-\")\n            if getattr(cls, \"use_cmdline_section\", True):\n                full_name = \"{}-{}\".format(cls.__name__.replace(\"_\", \"-\"), full_name)\n\n            params.append((cls, param, attr, full_name))\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a relative path to a framgment file or directory.", "response": "def rel_path(anchor, *paths):\n    \"\"\"\n    Returns a path made of framgment *paths* relativ to an *anchor* path. When *anchor* is a file,\n    its absolute directory is used instead.\n    \"\"\"\n    anchor = os.path.abspath(os.path.expandvars(os.path.expanduser(anchor)))\n    if os.path.exists(anchor) and os.path.isfile(anchor):\n        anchor = os.path.dirname(anchor)\n    return os.path.normpath(os.path.join(anchor, *paths))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef law_home_path(*paths):\n    home = os.getenv(\"LAW_HOME\", \"$HOME/.law\")\n    home = os.path.expandvars(os.path.expanduser(home))\n    return os.path.normpath(os.path.join(home, *paths))", "response": "Returns the path to the law home directory that defaults to the user s home directory optionally with paths."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_err(*args, **kwargs):\n    sys.stderr.write(\" \".join(str(arg) for arg in args) + \"\\n\")\n    if kwargs.get(\"flush\", False):\n        sys.stderr.flush()", "response": "print_err(*args, flush=False)\n    Same as *print*, but outputs to stderr. If *flush* is *True*, stderr is flushed after printing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef abort(msg=None, exitcode=1):\n    if msg is not None:\n        if exitcode in (None, 0):\n            print(msg)\n        else:\n            print_err(msg)\n    sys.exit(exitcode)", "response": "Aborts the process with an exitcode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef colored(msg, color=None, background=None, style=None, force=False):\n    try:\n        if not force and not os.isatty(sys.stdout.fileno()):\n            return msg\n    except:\n        return msg\n\n    color = colors.get(color, colors[\"default\"])\n    background = backgrounds.get(background, backgrounds[\"default\"])\n\n    if not isinstance(style, (tuple, list, set)):\n        style = (style,)\n    style = \";\".join(str(styles.get(s, styles[\"default\"])) for s in style)\n\n    return \"\\033[{};{};{}m{}\\033[0m\".format(style, background, color, msg)", "response": "Return a colored version of a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef multi_match(name, patterns, mode=any, regex=False):\n    if not regex:\n        return mode(fnmatch.fnmatch(name, pattern) for pattern in patterns)\n    else:\n        return mode(re.match(pattern, name) for pattern in patterns)", "response": "Returns True if name matches multiple patterns."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning whether the given object is iterable lazily.", "response": "def is_lazy_iterable(obj):\n    \"\"\"\n    Returns whether *obj* is iterable lazily, such as generators, range objects, etc.\n    \"\"\"\n    return isinstance(obj,\n        (types.GeneratorType, collections.MappingView, six.moves.range, enumerate))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an object to a list and returns it.", "response": "def make_list(obj, cast=True):\n    \"\"\"\n    Converts an object *obj* to a list and returns it. Objects of types *tuple* and *set* are\n    converted if *cast* is *True*. Otherwise, and for all other types, *obj* is put in a new list.\n    \"\"\"\n    if isinstance(obj, list):\n        return list(obj)\n    elif is_lazy_iterable(obj):\n        return list(obj)\n    elif isinstance(obj, (tuple, set)) and cast:\n        return list(obj)\n    else:\n        return [obj]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_tuple(obj, cast=True):\n    if isinstance(obj, tuple):\n        return tuple(obj)\n    elif is_lazy_iterable(obj):\n        return tuple(obj)\n    elif isinstance(obj, (list, set)) and cast:\n        return tuple(obj)\n    else:\n        return (obj,)", "response": "Converts an object to a tuple and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nflattens and returns a complex structured object *struct*.", "response": "def flatten(struct):\n    \"\"\"\n    Flattens and returns a complex structured object *struct*.\n    \"\"\"\n    if isinstance(struct, dict):\n        return flatten(struct.values())\n    elif isinstance(struct, (list, tuple, set)) or is_lazy_iterable(struct):\n        objs = []\n        for obj in struct:\n            objs.extend(flatten(obj))\n        return objs\n    else:\n        return [struct]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_dicts(*dicts, **kwargs):\n    # get or infer the class\n    cls = kwargs.get(\"cls\", None)\n    if cls is None:\n        for d in dicts:\n            if isinstance(d, dict):\n                cls = d.__class__\n                break\n        else:\n            raise TypeError(\"cannot infer cls as none of the passed objects is of type dict\")\n\n    # start merging\n    merged_dict = cls()\n    for d in dicts:\n        if isinstance(d, dict):\n            merged_dict.update(d)\n\n    return merged_dict", "response": "Takes multiple dicts and returns a single merged dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef which(prog):\n    executable = lambda path: os.path.isfile(path) and os.access(path, os.X_OK)\n\n    # prog can also be a path\n    dirname, _ = os.path.split(prog)\n    if dirname:\n        if executable(prog):\n            return prog\n    elif \"PATH\" in os.environ:\n        for search_path in os.environ[\"PATH\"].split(os.pathsep):\n            path = os.path.join(search_path.strip('\"'), prog)\n            if executable(path):\n                return path\n\n    return None", "response": "Pythonic which implementation. Returns the path to an executable by searching in the PATH environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_struct(func, struct, cls=None, map_dict=True, map_list=True, map_tuple=False,\n        map_set=False):\n    \"\"\"\n    Applies a function *func* to each value of a complex structured object *struct* and returns the\n    output in the same structure. Example:\n\n    .. code-block:: python\n\n       struct = {\"foo\": [123, 456], \"bar\": [{\"1\": 1}, {\"2\": 2}]}\n       def times_two(i):\n           return i * 2\n\n       map_struct(struct, times_two)\n       # -> {\"foo\": [246, 912], \"bar\": [{\"1\": 2}, {\"2\": 4}]}\n\n    When *cls* is not *None*, it exclusively defines the class of objects that *func* is applied on.\n    All other objects are unchanged. *map_dict*, *map_list*, *map_tuple* and *map_set* configure if\n    objects of the respective types are traversed or mapped. The can be booleans or integer values\n    that define the depth of that setting in the struct.\n    \"\"\"\n    # interpret generators and views as lists\n    if is_lazy_iterable(struct):\n        struct = list(struct)\n\n    valid_types = tuple()\n    if map_dict:\n        valid_types += (dict,)\n        if isinstance(map_dict, int) and not isinstance(map_dict, bool):\n            map_dict -= 1\n    if map_list:\n        valid_types += (list,)\n        if isinstance(map_list, int) and not isinstance(map_list, bool):\n            map_list -= 1\n    if map_tuple:\n        valid_types += (tuple,)\n        if isinstance(map_tuple, int) and not isinstance(map_tuple, bool):\n            map_tuple -= 1\n    if map_set:\n        valid_types += (set,)\n        if isinstance(map_set, int) and not isinstance(map_set, bool):\n            map_set -= 1\n\n    # is an instance of cls?\n    if cls is not None and isinstance(struct, cls):\n        return func(struct)\n\n    # traverse?\n    elif isinstance(struct, valid_types):\n        # create a new struct, treat tuples as lists for itertative item appending\n        new_struct = struct.__class__() if not isinstance(struct, tuple) else []\n\n        # create type-dependent generator and addition callback\n        if isinstance(struct, (list, tuple)):\n            gen = enumerate(struct)\n            add = lambda _, value: new_struct.append(value)\n        elif isinstance(struct, set):\n            gen = enumerate(struct)\n            add = lambda _, value: new_struct.add(value)\n        else:  # dict\n            gen = six.iteritems(struct)\n            add = lambda key, value: new_struct.__setitem__(key, value)\n\n        # recursively fill the new struct\n        for key, value in gen:\n            value = map_struct(func, value, cls=cls, map_dict=map_dict, map_list=map_list,\n                map_tuple=map_tuple, map_set=map_set)\n            add(key, value)\n\n        # convert tuples\n        if isinstance(struct, tuple):\n            new_struct = struct.__class__(new_struct)\n\n        return new_struct\n\n    # when cls is set, just return\n    elif cls is not None:\n        return struct\n\n    # apply func\n    else:\n        return func(struct)", "response": "Applies a function func to each value of a complex structured object struct and returns the resulting structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmasking a complex structured object struct with a mask and returns the remaining values.", "response": "def mask_struct(mask, struct, replace=no_value):\n    \"\"\"\n    Masks a complex structured object *struct* with a *mask* and returns the remaining values. When\n    *replace* is set, masked values are replaced with that value instead of being removed. The\n    *mask* can have a complex structure as well. Examples:\n\n    .. code-block:: python\n\n        struct = {\"a\": [1, 2], \"b\": [3, [\"foo\", \"bar\"]]}\n\n        # simple example\n        mask_struct({\"a\": [False, True], \"b\": False}, struct)\n        # => {\"a\": [2]}\n\n        # omitting mask information results in keeping values\n        mask_struct({\"a\": [False, True]}, struct)\n        # => {\"a\": [2], \"b\": [3, [\"foo\", \"bar\"]]}\n    \"\"\"\n    # interpret lazy iterables lists\n    if is_lazy_iterable(struct):\n        struct = list(struct)\n\n    # when mask is a bool, or struct is not a dict or sequence, apply the mask immediately\n    if isinstance(mask, bool) or not isinstance(struct, (list, tuple, dict)):\n        return struct if mask else replace\n\n    # check list and tuple types\n    elif isinstance(struct, (list, tuple)) and isinstance(mask, (list, tuple)):\n        new_struct = []\n        for i, val in enumerate(struct):\n            if i >= len(mask):\n                new_struct.append(val)\n            else:\n                repl = replace\n                if isinstance(replace, (list, tuple)) and len(replace) > i:\n                    repl = replace[i]\n                val = mask_struct(mask[i], val, replace=repl)\n                if val != no_value:\n                    new_struct.append(val)\n\n        return struct.__class__(new_struct) if new_struct else replace\n\n    # check dict types\n    elif isinstance(struct, dict) and isinstance(mask, dict):\n        new_struct = struct.__class__()\n        for key, val in six.iteritems(struct):\n            if key not in mask:\n                new_struct[key] = val\n            else:\n                repl = replace\n                if isinstance(replace, dict) and key in replace:\n                    repl = replace[key]\n                val = mask_struct(mask[key], val, replace=repl)\n                if val != no_value:\n                    new_struct[key] = val\n        return new_struct or replace\n\n    # when this point is reached, mask and struct have incompatible types\n    raise TypeError(\"mask and struct must have the same type, got '{}' and '{}'\".format(type(mask),\n            type(struct)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readable_popen(*args, **kwargs):\n    # force pipes\n    kwargs[\"stdout\"] = subprocess.PIPE\n    kwargs[\"stderr\"] = subprocess.STDOUT\n\n    p = subprocess.Popen(*args, **kwargs)\n\n    for line in iter(lambda: p.stdout.readline(), \"\"):\n        if six.PY3:\n            line = line.decode(\"utf-8\")\n        yield line.rstrip()\n\n    # yield the process itself in the end\n    p.communicate()\n    yield p", "response": "A generator that yields the output of a single process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a hash based on a given algorithm.", "response": "def create_hash(inp, l=10, algo=\"sha256\"):\n    \"\"\"\n    Takes an input *inp* and creates a hash based on an algorithm *algo*. For valid algorithms, see\n    python's hashlib. *l* corresponds to the maximum length of the returned hash. Internally, the\n    string representation of *inp* is used.\n    \"\"\"\n    return getattr(hashlib, algo)(six.b(str(inp))).hexdigest()[:l]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_no_perm(src, dst):\n    shutil.copy(src, dst)\n    perm = os.stat(dst).st_mode\n    shutil.copystat(src, dst)\n    os.chmod(dst, perm)", "response": "Copy a file from src to dst except for permission bits."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if a file located at path is owned by the user with uid.", "response": "def user_owns_file(path, uid=None):\n    \"\"\"\n    Returns whether a file located at *path* is owned by the user with *uid*. When *uid* is *None*,\n    the user id of the current process is used.\n    \"\"\"\n    if uid is None:\n        uid = os.getuid()\n    path = os.path.expandvars(os.path.expanduser(path))\n    return os.stat(path).st_uid == uid"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef human_bytes(n, unit=None):\n    if n == 0:\n        idx = 0\n    elif unit:\n        idx = byte_units.index(unit)\n    else:\n        idx = int(math.floor(math.log(abs(n), 1024)))\n        idx = min(idx, len(byte_units))\n    return n / 1024. ** idx, byte_units[idx]", "response": "Takes a number of bytes n assigns the best matching unit and returns the respective number\n    and unit string in a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef human_time_diff(*args, **kwargs):\n    secs = float(datetime.timedelta(*args, **kwargs).total_seconds())\n    parts = []\n    for unit, mul in time_units:\n        if secs / mul >= 1 or mul == 1:\n            if mul > 1:\n                n = int(math.floor(secs / mul))\n                secs -= n * mul\n            else:\n                n = round(secs, 1)\n            parts.append(\"{} {}{}\".format(n, unit, \"\" if n == 1 else \"s\"))\n    return \", \".join(parts)", "response": "Returns a human readable time difference."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn whether the exception e was raised due to an already existing file or directory.", "response": "def is_file_exists_error(e):\n    \"\"\"\n    Returns whether the exception *e* was raised due to an already existing file or directory.\n    \"\"\"\n    if six.PY3:\n        return isinstance(e, FileExistsError)  # noqa: F821\n    else:\n        return isinstance(e, OSError) and e.errno == 17"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend an email from sender to recipient with subject and content.", "response": "def send_mail(recipient, sender, subject=\"\", content=\"\", smtp_host=\"127.0.0.1\", smtp_port=25):\n    \"\"\"\n    Lightweight mail functionality. Sends an mail from *sender* to *recipient* with *subject* and\n    *content*. *smtp_host* and *smtp_port* are forwarded to the ``smtplib.SMTP`` constructor. *True*\n    is returned on success, *False* otherwise.\n    \"\"\"\n    try:\n        server = smtplib.SMTP(smtp_host, smtp_port)\n    except Exception as e:\n        logger = logging.getLogger(__name__)\n        logger.warning(\"cannot create SMTP server: {}\".format(e))\n        return False\n\n    header = \"From: {}\\r\\nTo: {}\\r\\nSubject: {}\\r\\n\\r\\n\".format(sender, recipient, subject)\n    server.sendmail(sender, recipient, header + content)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nflushes all registered consumer streams.", "response": "def _flush(self):\n        \"\"\"\n        Flushes all registered consumer streams.\n        \"\"\"\n        for consumer in self.consumers:\n            if not getattr(consumer, \"closed\", False):\n                consumer.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _write(self, *args, **kwargs):\n        for consumer in self.consumers:\n            consumer.write(*args, **kwargs)", "response": "Write to all registered consumer streams passing args and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite to the consumer stream when filter_fn evaluates to True", "response": "def _write(self, *args, **kwargs):\n        \"\"\"\n        Writes to the consumer stream when *filter_fn* evaluates to *True*, passing *args* and\n        *kwargs*.\n        \"\"\"\n        if self.filter_fn(*args, **kwargs):\n            self.stream.write(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_default(self, section, option, default=None, type=None, expandvars=False,\n            expanduser=False):\n        \"\"\"\n        Returns the config value defined by *section* and *option*. When either the section or the\n        option does not exist, the *default* value is returned instead. When *type* is set, it must\n        be either `\"str\"`, `\"int\"`, `\"float\"`, or `\"boolean\"`. When *expandvars* is *True*,\n        environment variables are expanded. When *expanduser* is *True*, user variables are\n        expanded as well.\n        \"\"\"\n        if self.has_section(section) and self.has_option(section, option):\n            value = self.get(section, option)\n            if isinstance(value, six.string_types):\n                if expandvars:\n                    value = os.path.expandvars(value)\n                if expanduser:\n                    value = os.path.expanduser(value)\n            return value if not type else self._get_type_converter(type)(value)\n        else:\n            return default", "response": "Returns the default value for the option in section."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_expanded(self, *args, **kwargs):\n        kwargs.setdefault(\"expandvars\", True)\n        kwargs.setdefault(\"expanduser\", True)\n        return self.get_default(*args, **kwargs)", "response": "Same as get_default but expandvars and expanduser arguments are set to True by default."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the current configuration with new data given as a dictionary.", "response": "def update(self, data, overwrite=None, overwrite_sections=True, overwrite_options=True):\n        \"\"\"\n        Updates the currently stored configuration with new *data*, given as a dictionary. When\n        *overwrite_sections* is *False*, sections in *data* that are already present in the current\n        config are skipped. When *overwrite_options* is *False*, existing options are not\n        overwritten. When *overwrite* is not *None*, both *overwrite_sections* and\n        *overwrite_options* are set to its value.\n        \"\"\"\n        if overwrite is not None:\n            overwrite_sections = overwrite\n            overwrite_options = overwrite\n\n        for section, _data in six.iteritems(data):\n            if not self.has_section(section):\n                self.add_section(section)\n            elif not overwrite_sections:\n                continue\n\n            for option, value in six.iteritems(_data):\n                if overwrite_options or not self.has_option(section, option):\n                    self.set(section, option, str(value))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the current configc with the config found in filename. All args and kwargs are passed to the update method.", "response": "def include(self, filename, *args, **kwargs):\n        \"\"\"\n        Updates the current configc with the config found in *filename*. All *args* and *kwargs* are\n        forwarded to :py:meth:`update`.\n        \"\"\"\n        p = self.__class__(filename, skip_defaults=True, skip_fallbacks=True)\n        self.update(p._sections, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all keys of a section in a list.", "response": "def keys(self, section, prefix=None):\n        \"\"\"\n        Returns all keys of a *section* in a list. When *prefix* is set, only keys starting with\n        that prefix are returned\n        \"\"\"\n        return [key for key, _ in self.items(section) if (not prefix or key.startswith(prefix))]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sync_luigi_config(self, push=True, pull=True, expand=True):\n        prefix = \"luigi_\"\n        lparser = luigi.configuration.LuigiConfigParser.instance()\n\n        if push:\n            for section in self.sections():\n                if not section.startswith(prefix):\n                    continue\n                lsection = section[len(prefix):]\n\n                if not lparser.has_section(lsection):\n                    lparser.add_section(lsection)\n\n                for option in self.options(section):\n                    if not lparser.has_option(lsection, option):\n                        if expand:\n                            value = self.get_expanded(section, option)\n                        else:\n                            value = self.get(section, option)\n                        lparser.set(lsection, option, value)\n\n        if pull:\n            for lsection in lparser.sections():\n                section = prefix + lsection\n\n                if not self.has_section(section):\n                    self.add_section(section)\n\n                for option, value in lparser.items(lsection):\n                    self.set(section, option, value)", "response": "Synchronizes the configuration with the luigi configuration parser."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef notify_telegram(title, content, token=None, chat=None, mention_user=None, **kwargs):\n    # test import\n    import telegram  # noqa: F401\n\n    cfg = Config.instance()\n\n    # get default token and chat\n    if not token:\n        token = cfg.get_expanded(\"notifications\", \"telegram_token\")\n    if not chat:\n        chat = cfg.get_expanded(\"notifications\", \"telegram_chat\")\n\n    if not token or not chat:\n        logger.warning(\"cannot send Telegram notification, token ({}) or chat ({}) empty\".format(\n            token, chat))\n        return False\n\n    # append the user to mention to the title\n    # unless explicitly set to empty string\n    mention_text = \"\"\n    if mention_user is None:\n        mention_user = cfg.get_expanded(\"notifications\", \"telegram_mention_user\")\n    if mention_user:\n        mention_text = \" (@{})\".format(mention_user)\n\n    # request data for the API call\n    request = {\n        \"parse_mode\": \"Markdown\",\n    }\n\n    # standard or attachment content?\n    if isinstance(content, six.string_types):\n        request[\"text\"] = \"{}{}\\n\\n{}\".format(title, mention_text, content)\n    else:\n        # content is a dict, add some formatting\n        request[\"text\"] = \"{}{}\\n\\n\".format(title, mention_text)\n\n        for key, value in content.items():\n            request[\"text\"] += \"_{}_: {}\\n\".format(key, value)\n\n    # extend by arbitrary kwargs\n    request.update(kwargs)\n\n    # threaded, non-blocking API communication\n    thread = threading.Thread(target=_notify_telegram, args=(token, chat, request))\n    thread.start()\n\n    return True", "response": "Send a Telegram notification and returns True on success."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef complete(self):\n        if self.task.local_workflow_require_branches:\n            return self._has_run\n        else:\n            return super(LocalWorkflowProxy, self).complete()", "response": "Returns True if the task has completed successfully."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n        if not self._has_yielded and not self.task.local_workflow_require_branches:\n            self._has_yielded = True\n\n            yield list(self.task.get_branch_tasks().values())\n\n        self._has_run = True", "response": "A generator that yields all branch - level task - related information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef factory(**default_opts):\n    def wrapper(decorator):\n        @functools.wraps(decorator)\n        def wrapper(fn=None, **opts):\n            _opts = default_opts.copy()\n            _opts.update(opts)\n\n            def wrapper(fn):\n                @functools.wraps(fn)\n                def wrapper(*args, **kwargs):\n                    return decorator(fn, _opts, *args, **kwargs)\n                return wrapper\n\n            return wrapper if fn is None else wrapper(fn)\n        return wrapper\n    return wrapper", "response": "A function factory for tasks run methods."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef log(fn, opts, task, *args, **kwargs):\n    _task = get_task(task)\n    log = get_param(_task.log_file, _task.default_log_file)\n\n    if log == \"-\" or not log:\n        return fn(task, *args, **kwargs)\n    else:\n        # use the local target functionality to create the parent directory\n        LocalFileTarget(log).parent.touch()\n        with open_compat(log, \"a\", 1) as f:\n            tee = TeeStream(f, sys.__stdout__)\n            sys.stdout = tee\n            sys.stderr = tee\n            try:\n                ret = fn(task, *args, **kwargs)\n            except:\n                traceback.print_exc(file=tee)\n                raise\n            finally:\n                sys.stdout = sys.__stdout__\n                sys.stderr = sys.__stderr__\n                tee.flush()\n        return ret", "response": "A decorator that wraps a bound method of a task and redirects output of both stdout and stderr to the file\n            defined by the tasks s log_file parameter or the default_log_file attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps a bound method of a task and logs its execution time in a human readable format. Logs in info mode. When *publish_message* is *True*, the duration is also published as a task message to the scheduler.", "response": "def timeit(fn, opts, task, *args, **kwargs):\n    \"\"\"\n    Wraps a bound method of a task and logs its execution time in a human readable format. Logs in\n    info mode. When *publish_message* is *True*, the duration is also published as a task message to\n    the scheduler.\n    \"\"\"\n    start_time = time.time()\n    try:\n        return fn(task, *args, **kwargs)\n    finally:\n        duration = human_time_diff(seconds=round(time.time() - start_time, 1))\n\n        # log\n        timeit_logger = logger.getChild(\"timeit\")\n        timeit_logger.info(\"runtime of {}: {}\".format(task.task_id, duration))\n\n        # optionally publish a task message to the scheduler\n        if opts[\"publish_message\"] and callable(getattr(task, \"publish_message\", None)):\n            task.publish_message(\"runtime: {}\".format(duration))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_voms_proxy_user():\n    out = _voms_proxy_info([\"--identity\"])[1].strip()\n    try:\n        return re.match(r\".*\\/CN\\=([^\\/]+).*\", out.strip()).group(1)\n    except:\n        raise Exception(\"no valid identity found in voms proxy: {}\".format(out))", "response": "Returns the owner of the voms proxy."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a voms proxy exists and returns True otherwise.", "response": "def check_voms_proxy_validity(log=False):\n    \"\"\"\n    Returns *True* when a valid voms proxy exists, *False* otherwise. When *log* is *True*, a\n    warning will be logged.\n    \"\"\"\n    valid = _voms_proxy_info([\"--exists\"], silent=True)[0] == 0\n    if log and not valid:\n        logger.warning(\"no valid voms proxy found\")\n    return valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenews the voms proxy using a password and virtual organization name vo and a default lifetime of 8 days.", "response": "def renew_voms_proxy(passwd=\"\", vo=None, lifetime=\"196:00\"):\n    \"\"\"\n    Renews the voms proxy using a password *passwd*, an optional virtual organization name *vo*, and\n    a default *lifetime* of 8 days. The password is written to a temporary file first and piped into\n    the renewal commad to ensure it is not visible in the process list.\n    \"\"\"\n    with tmp_file() as (_, tmp):\n        with open(tmp, \"w\") as f:\n            f.write(passwd)\n\n        cmd = \"cat '{}' | voms-proxy-init --valid '{}'\".format(tmp, lifetime)\n        if vo:\n            cmd += \" -voms '{}'\".format(vo)\n        code, out, _ = interruptable_popen(cmd, shell=True, executable=\"/bin/bash\",\n            stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n        if code != 0:\n            raise Exception(\"proxy renewal failed: {}\".format(out))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delegate_voms_proxy_glite(endpoint, stdout=None, stderr=None, cache=True):\n    # get the proxy file\n    proxy_file = get_voms_proxy_file()\n    if not os.path.exists(proxy_file):\n        raise Exception(\"proxy file '{}' does not exist\".format(proxy_file))\n\n    if cache:\n        if isinstance(cache, six.string_types):\n            cache_file = cache\n        else:\n            cache_file = proxy_file + \"_delegation_cache.json\"\n\n        def remove_cache():\n            try:\n                if os.path.exists(cache_file):\n                    os.remove(cache_file)\n            except OSError:\n                pass\n\n        # create the hash of the proxy file content\n        with open(proxy_file, \"r\") as f:\n            proxy_hash = create_hash(f.read())\n\n        # already delegated?\n        cache_data = {}\n        if os.path.exists(cache_file):\n            with open(cache_file, \"r\") as f:\n                try:\n                    cache_data = json.load(f)\n                except:\n                    remove_cache()\n\n        # is the hash up-to-date?\n        if cache_data.get(\"hash\") != proxy_hash:\n            remove_cache()\n            cache_data = {}\n\n        # proxy already delegated to that endpoint?\n        elif endpoint in cache_data.get(\"ids\", []):\n            return str(cache_data[\"ids\"][endpoint])\n\n    # do the actual delegation\n    delegation_id = uuid.uuid4().hex\n    cmd = [\"glite-ce-delegate-proxy\", \"-e\", endpoint, delegation_id]\n    code = interruptable_popen(cmd, stdout=stdout, stderr=stderr)[0]\n    if code != 0:\n        raise Exception(\"glite proxy delegation to endpoint {} failed\".format(endpoint))\n\n    if cache:\n        # write the id back to the delegation file\n        cache_data[\"hash\"] = proxy_hash\n        cache_data.setdefault(\"ids\", {})[endpoint] = delegation_id\n        with open(cache_file, \"w\") as f:\n            json.dump(cache_data, f, indent=4)\n        os.chmod(cache_file, 0o0600)\n\n    return delegation_id", "response": "Delegates the voms proxy to an endpoint using glite - ce - delegate - proxy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the formatter class whose name attribute is name.", "response": "def get_formatter(name, silent=False):\n    \"\"\"\n    Returns the formatter class whose name attribute is *name*. When no class could be found and\n    *silent* is *True*, *None* is returned. Otherwise, an exception is raised.\n    \"\"\"\n    formatter = FormatterRegister.formatters.get(name)\n    if formatter or silent:\n        return formatter\n    else:\n        raise Exception(\"cannot find formatter '{}'\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the list of formatters that would accept the given file.", "response": "def find_formatters(path, silent=True):\n    \"\"\"\n    Returns a list of formatter classes which would accept the file given by *path*. When no classes\n    could be found and *silent* is *True*, an empty list is returned. Otherwise, an exception is\n    raised.\n    \"\"\"\n    formatters = [f for f in six.itervalues(FormatterRegister.formatters) if f.accepts(path)]\n    if formatters or silent:\n        return formatters\n    else:\n        raise Exception(\"cannot find formatter for path '{}'\".format(path))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_formatter(name, path):\n    if name == AUTO_FORMATTER:\n        return find_formatters(path, silent=False)[0]\n    else:\n        return get_formatter(name, silent=False)", "response": "Returns the formatter class that accepts path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes a list into a base64 encoded string via base64 encoding.", "response": "def encode_list(cls, value):\n        \"\"\"\n        Encodes a list *value* into a string via base64 encoding.\n        \"\"\"\n        encoded = base64.b64encode(six.b(\" \".join(str(v) for v in value) or \"-\"))\n        return encoded.decode(\"utf-8\") if six.PY3 else encoded"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_args(self):\n        return [\n            self.task_cls.__module__,\n            self.task_cls.__name__,\n            self.encode_list(self.task_params),\n            self.encode_list(self.branches),\n            self.encode_bool(self.auto_retry),\n            self.encode_list(self.dashboard_data),\n        ]", "response": "Returns the list of encoded job arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(*packages):\n    for pkg in flatten(packages):\n        if pkg in loaded_packages:\n            logger.debug(\"skip contrib package '{}', already loaded\".format(pkg))\n            continue\n        loaded_packages.append(pkg)\n\n        mod = __import__(\"law.contrib.{}\".format(pkg), globals(), locals(), [pkg])\n        logger.debug(\"loaded contrib package '{}'\".format(pkg))\n\n        for attr in mod.__all__:\n            if hasattr(law, attr):\n                logger.info(\"cannot register 'law.contrib.{0}.{1}' to 'law.{1}', \"\n                    \"already exists\".format(pkg, attr))\n            else:\n                setattr(law, attr, getattr(mod, attr))\n                law.__all__.append(attr)\n                logger.debug(\"registered 'law.contrib.{0}.{1}' to 'law.{1}'\".format(pkg, attr))", "response": "Loads a list of contrib packages and adds members exposed in law. all."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef notify_mail(title, message, recipient=None, sender=None, smtp_host=None, smtp_port=None,\n        **kwargs):\n    \"\"\"\n    Mail notification method taking a *title* and a string *message*. *recipient*, *sender*,\n    *smtp_host* and *smtp_port* default to the configuration values in the [notifications] section.\n    \"\"\"\n    cfg = Config.instance()\n\n    if not recipient:\n        recipient = cfg.get_expanded(\"notifications\", \"mail_recipient\")\n    if not sender:\n        sender = cfg.get_expanded(\"notifications\", \"mail_sender\")\n    if not smtp_host:\n        smtp_host = cfg.get_expanded(\"notifications\", \"mail_smtp_host\")\n    if not smtp_port:\n        smtp_port = cfg.get_expanded(\"notifications\", \"mail_smtp_port\")\n\n    if not recipient or not sender:\n        logger.warning(\"cannot send mail notification, recipient ({}) or sender ({}) empty\".format(\n            recipient, sender))\n        return False\n\n    return send_mail(recipient, sender, title, message, smtp_host=smtp_host, smtp_port=smtp_port)", "response": "Send a mail notification to the specified recipient and sender."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun all patches. This function ensures that a second invocation has no effect.", "response": "def patch_all():\n    \"\"\"\n    Runs all patches. This function ensures that a second invocation has no effect.\n    \"\"\"\n    global _patched\n\n    if _patched:\n        return\n    _patched = True\n\n    patch_default_retcodes()\n    patch_worker_run_task()\n    patch_worker_factory()\n    patch_keepalive_run()\n    patch_cmdline_parser()\n\n    logger.debug(\"applied law-specific luigi patches\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef patch_default_retcodes():\n    import luigi.retcodes\n\n    retcode = luigi.retcodes.retcode\n\n    retcode.already_running._default = 10\n    retcode.missing_data._default = 20\n    retcode.not_run._default = 30\n    retcode.task_failed._default = 40\n    retcode.scheduling_error._default = 50\n    retcode.unhandled_exception._default = 60", "response": "Patch luigi. retcodes. retcode with default luigi return codes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef patch_worker_run_task():\n    _run_task = luigi.worker.Worker._run_task\n\n    def run_task(self, task_id):\n        task = self._scheduled_tasks[task_id]\n\n        task._worker_id = self._id\n        task._worker_task = self._first_task\n\n        try:\n            _run_task(self, task_id)\n        finally:\n            task._worker_id = None\n            task._worker_task = None\n\n        # make worker disposable when sandboxed\n        if os.getenv(\"LAW_SANDBOX_SWITCHED\") == \"1\":\n            self._start_phasing_out()\n\n    luigi.worker.Worker._run_task = run_task", "response": "Patches the luigi. worker. Worker. _run_task method to store the worker id and the id of its\n    first task in the task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef patch_worker_factory():\n    def create_worker(self, scheduler, worker_processes, assistant=False):\n        worker = luigi.worker.Worker(scheduler=scheduler, worker_processes=worker_processes,\n            assistant=assistant, worker_id=os.getenv(\"LAW_SANDBOX_WORKER_ID\"))\n        worker._first_task = os.getenv(\"LAW_SANDBOX_WORKER_TASK\")\n        return worker\n\n    luigi.interface._WorkerSchedulerFactory.create_worker = create_worker", "response": "Patches the luigi. interface. _WorkerSchedulerFactory to include sandboxing information when creating a worker instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef patch_keepalive_run():\n    _run = luigi.worker.KeepAliveThread.run\n\n    def run(self):\n        # do not run the keep-alive loop when sandboxed\n        if os.getenv(\"LAW_SANDBOX_SWITCHED\") == \"1\":\n            self.stop()\n        else:\n            _run(self)\n\n    luigi.worker.KeepAliveThread.run = run", "response": "Patches the luigi. worker. KeepAliveThread. run to immediately stop the keep - alive thread when running within a sandbox."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef patch_cmdline_parser():\n    # store original functions\n    _init = luigi.cmdline_parser.CmdlineParser.__init__\n\n    # patch init\n    def __init__(self, cmdline_args):\n        _init(self, cmdline_args)\n        self.cmdline_args = cmdline_args\n\n    luigi.cmdline_parser.CmdlineParser.__init__ = __init__", "response": "Patches the luigi. cmdline_parser. CmdlineParser to store the original command line arguments\n    for later processing in the Law. config. Config."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef notify_slack(title, content, attachment_color=\"#4bb543\", short_threshold=40, token=None,\n        channel=None, mention_user=None, **kwargs):\n    \"\"\"\n    Sends a slack notification and returns *True* on success. The communication with the slack API\n    might have some delays and is therefore handled by a thread. The format of the notification\n    depends on *content*. If it is a string, a simple text notification is sent. Otherwise, it\n    should be a dictionary whose fields are used to build a message attachment with two-column\n    formatting.\n    \"\"\"\n    # test import\n    import slackclient  # noqa: F401\n\n    cfg = Config.instance()\n\n    # get default token and channel\n    if not token:\n        token = cfg.get_expanded(\"notifications\", \"slack_token\")\n    if not channel:\n        channel = cfg.get_expanded(\"notifications\", \"slack_channel\")\n\n    if not token or not channel:\n        logger.warning(\"cannot send Slack notification, token ({}) or channel ({}) empty\".format(\n            token, channel))\n        return False\n\n    # append the user to mention to the title\n    # unless explicitly set to empty string\n    mention_text = \"\"\n    if mention_user is None:\n        mention_user = cfg.get_expanded(\"notifications\", \"slack_mention_user\")\n    if mention_user:\n        mention_text = \" (@{})\".format(mention_user)\n\n    # request data for the API call\n    request = {\n        \"channel\": channel,\n        \"as_user\": True,\n        \"parse\": \"full\",\n    }\n\n    # standard or attachment content?\n    if isinstance(content, six.string_types):\n        request[\"text\"] = \"{}{}\\n\\n{}\".format(title, mention_text, content)\n    else:\n        # content is a dict, send its data as an attachment\n        request[\"text\"] = \"{} {}\".format(title, mention_text)\n        request[\"attachments\"] = at = {\n            \"color\": attachment_color,\n            \"fields\": [],\n            \"fallback\": \"{}{}\\n\\n\".format(title, mention_text),\n        }\n\n        # fill the attachment fields and extend the fallback\n        for key, value in content.items():\n            at[\"fields\"].append({\n                \"title\": key,\n                \"value\": value,\n                \"short\": len(value) <= short_threshold,\n            })\n            at[\"fallback\"] += \"_{}_: {}\\n\".format(key, value)\n\n    # extend by arbitrary kwargs\n    request.update(kwargs)\n\n    # threaded, non-blocking API communication\n    thread = threading.Thread(target=_notify_slack, args=(token, request))\n    thread.start()\n\n    return True", "response": "Send a Slack notification to the specified slack site."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef maybe_wait(func):\n    def wrapper(self, *args, **kwargs):\n        if self.slow:\n            time.sleep(random.randint(5, 15))\n        return func(self, *args, **kwargs)\n\n    return wrapper", "response": "Wrapper around run method that reads the slow flag to decide whether to wait some seconds."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_query_output(cls, out):\n        query_data = {}\n\n        for line in out.strip().split(\"\\n\"):\n            parts = line.split()\n            if len(parts) < 6:\n                continue\n\n            job_id = parts[0]\n            status_flag = parts[2]\n\n            # map the status\n            status = cls.map_status(status_flag)\n\n            # save the result\n            query_data[job_id] = cls.job_status_dict(job_id=job_id, status=status)\n\n        return query_data", "response": "Parse the output of a query from the server into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_logging():\n    global console_handler\n\n    # make sure logging is setup only once\n    if console_handler:\n        return\n\n    # set the handler of the law root logger\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(LogFormatter())\n    logging.getLogger(\"law\").addHandler(console_handler)\n\n    # set levels for all loggers\n    for name, level in Config.instance().items(\"logging\"):\n        level = level.upper()\n        if hasattr(logging, level):\n            logger = logging.getLogger(name)\n            logger.setLevel(getattr(logging, level))\n            logger.debug(\"registered logger with level '{}'\".format(level))", "response": "Sets up the internal logging mechanism."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the config subprogram with parsed commandline args.", "response": "def execute(args):\n    \"\"\"\n    Executes the *config* subprogram with parsed commandline *args*.\n    \"\"\"\n    # just print the file location?\n    if args.location:\n        print(Config.instance().config_file)\n        return\n\n    # every option below requires the name to be set\n    if not args.name:\n        abort(\"please give the name of the config in the format <section>[.<option>]\")\n\n    # removal\n    if args.remove:\n        abort(\"config removal not yet implemented\")\n\n    # setting\n    if args.value:\n        abort(\"config setting not yet implemented\")\n\n    # getting\n    print(get_config(args.name, expand=args.expand))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_config(name, expand=False):\n    cfg = Config.instance()\n    only_section = \".\" not in name\n\n    # when only the section is given, print all keys\n    if only_section:\n        return \"\\n\".join(cfg.keys(name))\n\n    else:\n        section, option = name.split(\".\", 1)\n        func = cfg.get_expanded if expand else cfg.get\n        return func(section, option)", "response": "Get the config value that corresponds to the given name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_parser(sub_parsers):\n    parser = sub_parsers.add_parser(\"run\", prog=\"law run\", description=\"Run a task with\"\n        \" configurable parameters. See http://luigi.rtfd.io/en/stable/running_luigi.html for more\"\n        \" info.\")\n\n    parser.add_argument(\"task_family\", help=\"a task family registered in the task database file or\"\n        \" a module and task class in the format <module>.<class>\")\n    parser.add_argument(\"parameter\", nargs=\"*\", help=\"task parameters\")", "response": "Sets up the command line parser for the run subprogram and adds it to sub_parsers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(args):\n    task_family = None\n    error = None\n\n    # try to infer the task module from the passed task family and import it\n    parts = args.task_family.rsplit(\".\", 1)\n    if len(parts) == 2:\n        modid, cls_name = parts\n        try:\n            mod = __import__(modid, globals(), locals(), [cls_name])\n            if hasattr(mod, cls_name):\n                task_cls = getattr(mod, cls_name)\n                if not issubclass(task_cls, Task):\n                    abort(\"object '{}' is not a Task\".format(args.task_family))\n                task_family = task_cls.task_family\n        except ImportError as e:\n            logger.warning(\"import error in module {}: {}\".format(modid, e))\n            error = e\n\n    # read task info from the index file and import it\n    if task_family is None:\n        index_file = Config.instance().get_expanded(\"core\", \"index_file\")\n        if os.path.exists(index_file):\n            info = read_task_from_index(args.task_family, index_file)\n            if not info:\n                abort(\"task family '{}' not found in index\".format(args.task_family))\n            modid, task_family, _ = info\n            __import__(modid, globals(), locals())\n\n    # complain when no task could be found\n    if task_family is None:\n        if error:\n            raise error\n        else:\n            abort(\"task '{}' not found\".format(args.task_family))\n\n    # import the module and run luigi\n    luigi_run([task_family] + sys.argv[3:])", "response": "Executes luigi_run with parsed commandline args."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the task information from the index file given by index_file.", "response": "def read_task_from_index(task_family, index_file=None):\n    \"\"\"\n    Returns module id, task family and space-separated parameters in a tuple for a task given by\n    *task_family* from the *index_file*. When *None*, the *index_file* refers to the default as\n    defined in :py:mod:`law.config`. Returns *None* when the task could not be found.\n    \"\"\"\n    # read task information from the index file given a task family\n    if index_file is None:\n        index_file = Config.instance().get_expanded(\"core\", \"index_file\")\n\n    # open and go through lines\n    with open(index_file, \"r\") as f:\n        for line in f.readlines():\n            line = line.strip()\n            if line.count(\":\") >= 2:\n                modid, family, params = line.split(\":\", 2)\n                if family == task_family:\n                    return modid, family, params\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run():\n    # setup the main parser and sub parsers\n    parser = ArgumentParser(prog=\"law\", description=\"The law command line tool.\")\n    sub_parsers = parser.add_subparsers(help=\"subcommands\", dest=\"command\")\n\n    # add main arguments\n    parser.add_argument(\"--version\", \"-V\", action=\"version\", version=law.__version__)\n\n    # setup all progs\n    mods = {}\n    for prog in progs:\n        mods[prog] = import_module(\"law.cli.\" + prog)\n        mods[prog].setup_parser(sub_parsers)\n\n    # parse args and dispatch execution\n    if len(sys.argv) >= 2 and sys.argv[1] in forward_progs:\n        args = parser.parse_args(sys.argv[1:3])\n    else:\n        args = parser.parse_args()\n\n    if args.command:\n        mods[args.command].execute(args)\n    else:\n        parser.print_help()", "response": "Entry point to the law cli. Sets up all parsers parses all arguments and executes the requested subprogram."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_parser(sub_parsers):\n    parser = sub_parsers.add_parser(\"software\", prog=\"law software\", description=\"Create or update\"\n        \" the law software cache ({}). This is only required for some sandboxes that need to\"\n        \" forward software into containers.\".format(get_sw_dir()))\n\n    parser.add_argument(\"--remove\", \"-r\", action=\"store_true\", help=\"remove the software cache\"\n        \" directory and exit\")\n    parser.add_argument(\"--location\", \"-l\", action=\"store_true\", help=\"print the location of the\"\n        \" software cache directory and exit\")", "response": "Sets up the command line parser for the law software cache subprogram and adds it to sub_parsers."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the software subprogram with parsed commandline args.", "response": "def execute(args):\n    \"\"\"\n    Executes the *software* subprogram with parsed commandline *args*.\n    \"\"\"\n    sw_dir = get_sw_dir()\n\n    # just print the cache location?\n    if args.location:\n        print(sw_dir)\n        return\n\n    # just remove the current software cache?\n    if args.remove:\n        remove_software_cache(sw_dir)\n        return\n\n    # rebuild the software cache\n    build_software_cache(sw_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_software_cache(sw_dir=None):\n    # ensure the cache is empty\n    sw_dir = get_sw_dir(sw_dir)\n    remove_software_cache(sw_dir)\n    os.makedirs(sw_dir)\n\n    # reload dependencies to find the proper module paths\n    reload_dependencies(force=True)\n\n    for mod in deps:\n        path = os.path.dirname(mod.__file__)\n        name, ext = os.path.splitext(os.path.basename(mod.__file__))\n        # single file or module?\n        if name == \"__init__\":\n            # copy the entire module\n            name = os.path.basename(path)\n            shutil.copytree(path, os.path.join(sw_dir, name))\n        else:\n            shutil.copy2(os.path.join(path, name + \".py\"), sw_dir)", "response": "Builds up the software cache directory at sw_dir."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the software cache directory at sw_dir.", "response": "def remove_software_cache(sw_dir=None):\n    \"\"\"\n    Removes the software cache directory at *sw_dir* which is evaluated with :py:func:`get_sw_dir`.\n    \"\"\"\n    sw_dir = get_sw_dir(sw_dir)\n    if os.path.exists(sw_dir):\n        shutil.rmtree(sw_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reload_dependencies(force=False):\n    global _reloaded_deps\n\n    if _reloaded_deps and not force:\n        return\n    _reloaded_deps = True\n\n    for mod in deps:\n        six.moves.reload_module(mod)\n        logger.debug(\"reloaded module '{}'\".format(mod))", "response": "Reloads all python modules that law depends on."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef use_software_cache(sw_dir=None, reload_deps=False):\n    sw_dir = get_sw_dir(sw_dir)\n    if os.path.exists(sw_dir):\n        sys.path.insert(1, sw_dir)\n\n        if reload_deps:\n            reload_dependencies()", "response": "Sets sys. path so that the software at sw_dir is used."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the software directory defined in the config. software_dir config.", "response": "def get_sw_dir(sw_dir=None):\n    \"\"\"\n    Returns the software directory defined in the ``config.software_dir`` config. When *sw_dir* is\n    not *None*, it is expanded and returned instead.\n    \"\"\"\n    if sw_dir is None:\n        sw_dir = Config.instance().get(\"core\", \"software_dir\")\n\n    sw_dir = os.path.expandvars(os.path.expanduser(sw_dir))\n\n    return sw_dir"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a lazy created guarded TFile class and returns it.", "response": "def GuardedTFile(*args, **kwargs):\n    \"\"\"\n    Factory function that lazily creates the guarded TFile class, and creates and returns an\n    instance with all passed *args* and *kwargs*. This is required as we do not want to import ROOT\n    in the global scope.\n    \"\"\"\n    global guarded_tfile_cls\n\n    if not guarded_tfile_cls:\n        import ROOT\n\n        class GuardedTFile(ROOT.TFile):\n\n            def __enter__(self):\n                return self\n\n            def __exit__(self, exc_type, exc_value, traceback):\n                if self.IsOpen():\n                    self.Close()\n\n        guarded_tfile_cls = GuardedTFile\n\n    return guarded_tfile_cls(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cached_workflow_property(func=None, attr=None, setter=True):\n    def wrapper(func):\n        _attr = attr or \"_workflow_cached_\" + func.__name__\n\n        @functools.wraps(func)\n        def getter(self):\n            wf = self.as_workflow()\n            if not hasattr(wf, _attr):\n                setattr(wf, _attr, func(wf))\n            return getattr(wf, _attr)\n\n        _setter = None\n        if setter:\n            def _setter(self, value):\n                wf = self.as_workflow()\n                setattr(wf, _attr, value)\n\n            _setter.__name__ = func.__name__\n\n        return property(fget=getter, fset=_setter)\n\n    return wrapper if not func else wrapper(func)", "response": "Decorator to declare a property that is stored only on a workflow and also cached for\n ArcGIS."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the default workflow requirements for this task in an ordered dictionary.", "response": "def requires(self):\n        \"\"\"\n        Returns the default workflow requirements in an ordered dictionary, which is updated with\n        the return value of the task's *workflow_requires* method.\n        \"\"\"\n        reqs = OrderedDict()\n        reqs.update(self.task.workflow_requires())\n        return reqs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef output(self):\n        if self.task.target_collection_cls is not None:\n            cls = self.task.target_collection_cls\n        elif self.task.outputs_siblings:\n            cls = SiblingFileCollection\n        else:\n            cls = TargetCollection\n\n        targets = luigi.task.getpaths(self.task.get_branch_tasks())\n        collection = cls(targets, threshold=self.threshold(len(targets)))\n\n        return OrderedDict([(\"collection\", collection)])", "response": "Returns the default workflow outputs in an ordered dictionary. At the moment this is just\n        the collection of outputs of the branch tasks stored with the key collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef threshold(self, n=None):\n        if n is None:\n            n = len(self.task.branch_map())\n\n        acceptance = self.task.acceptance\n        return (acceptance * n) if acceptance <= 1 else acceptance", "response": "Returns the threshold number of tasks that need to be complete in order to consider the\n        workflow as being complete itself."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_prefixed_config(self, section, option, **kwargs):\n        cfg = Config.instance()\n        default = cfg.get_expanded(section, option, **kwargs)\n        return cfg.get_expanded(section, \"{}_{}\".format(self.workflow_type, option),\n            default=default, **kwargs)", "response": "Get the config value for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getionimage(p, mz_value, tol=0.1, z=1, reduce_func=sum):\n    tol = abs(tol)\n    im = np.zeros((p.imzmldict[\"max count of pixels y\"], p.imzmldict[\"max count of pixels x\"]))\n    for i, (x, y, z_) in enumerate(p.coordinates):\n        if z_ == 0:\n            UserWarning(\"z coordinate = 0 present, if you're getting blank images set getionimage(.., .., z=0)\")\n        if z_ == z:\n            mzs, ints = map(lambda x: np.asarray(x), p.getspectrum(i))\n            min_i, max_i = _bisect_spectrum(mzs, mz_value, tol)\n            im[y - 1, x - 1] = reduce_func(ints[min_i:max_i+1])\n    return im", "response": "Get an image representation of the intensity distribution of the ion with specified m / z value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __readimzmlmeta(self):\n        d = {}\n        scan_settings_list_elem = self.root.find('%sscanSettingsList' % self.sl)\n        instrument_config_list_elem = self.root.find('%sinstrumentConfigurationList' % self.sl)\n        supportedparams1 = [(\"max count of pixels x\", int), (\"max count of pixels y\", int),\n                            (\"max dimension x\", int), (\"max dimension y\", int), (\"pixel size x\", float),\n                            (\"pixel size y\", float), (\"matrix solution concentration\", float)]\n        supportedparams2 = [(\"wavelength\", float),\n                            (\"focus diameter x\", float), (\"focus diameter y\", float), (\"pulse energy\", float),\n                            (\"pulse duration\", float), (\"attenuation\", float)]\n        supportedaccessions1 = [(\"IMS:1000042\", \"value\"), (\"IMS:1000043\", \"value\"),\n                                (\"IMS:1000044\", \"value\"), (\"IMS:1000045\", \"value\"),\n                                (\"IMS:1000046\", \"value\"), (\"IMS:1000047\", \"value\"), (\"MS:1000835\", \"value\")]\n        supportedaccessions2 = [(\"MS:1000843\", \"value\"), (\"MS:1000844\", \"value\"),\n                                (\"MS:1000845\", \"value\"), (\"MS:1000846\", \"value\"), (\"MS:1000847\", \"value\"),\n                                (\"MS:1000848\", \"value\")]\n        for i in range(len(supportedparams1)):\n            acc, attr = supportedaccessions1[i]\n            elem = scan_settings_list_elem.find('.//%scvParam[@accession=\"%s\"]' % (self.sl, acc))\n            if elem is None:\n                break\n            name, T = supportedparams1[i]\n            try:\n                d[name] = T(elem.attrib[attr])\n            except ValueError:\n                warn(Warning('Wrong data type in XML file. Skipped attribute \"%s\"' % name))\n        for i in range(len(supportedparams2)):\n            acc, attr = supportedaccessions2[i]\n            elem = instrument_config_list_elem.find('.//%scvParam[@accession=\"%s\"]' % (self.sl, acc))\n            if elem is None:\n                break\n            name, T = supportedparams2[i]\n            try:\n                d[name] = T(elem.attrib[attr])\n            except ValueError:\n                warn(Warning('Wrong data type in XML file. Skipped attribute \"%s\"' % name))\n        return d", "response": "This method reads the meta information from the imzML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_physical_coordinates(self, i):\n        try:\n            pixel_size_x = self.imzmldict[\"pixel size x\"]\n            pixel_size_y = self.imzmldict[\"pixel size y\"]\n        except KeyError:\n            raise KeyError(\"Could not find all pixel size attributes in imzML file\")\n        image_x, image_y = self.coordinates[i][:2]\n        return image_x * pixel_size_x, image_y * pixel_size_y", "response": "Returns the real - world coordinates of the given pixel index i."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the desired spectrum from the. ibd file and returns the mz and intensity arrays corresponding to the desired spectrum.", "response": "def getspectrum(self, index):\n        \"\"\"\n        Reads the spectrum at specified index from the .ibd file.\n\n        :param index:\n            Index of the desired spectrum in the .imzML file\n\n        Output:\n\n        mz_array: numpy.ndarray\n            Sequence of m/z values representing the horizontal axis of the desired mass\n            spectrum\n        intensity_array: numpy.ndarray\n            Sequence of intensity values corresponding to mz_array\n        \"\"\"\n        mz_bytes, intensity_bytes = self.get_spectrum_as_string(index)\n        mz_array = np.frombuffer(mz_bytes, dtype=self.mzPrecision)\n        intensity_array = np.frombuffer(intensity_bytes, dtype=self.intensityPrecision)\n        return mz_array, intensity_array"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the mz array and intensity array of the desired spectrum at the specified location and returns the mz array and intensity array as a byte string.", "response": "def get_spectrum_as_string(self, index):\n        \"\"\"\n        Reads m/z array and intensity array of the spectrum at specified location\n        from the binary file as a byte string. The string can be unpacked by the struct\n        module. To get the arrays as numbers, use getspectrum\n\n        :param index:\n            Index of the desired spectrum in the .imzML file\n        :rtype: Tuple[str, str]\n\n        Output:\n\n        mz_string:\n            string where each character represents a byte of the mz array of the\n            spectrum\n        intensity_string:\n            string where each character represents a byte of the intensity array of\n            the spectrum\n        \"\"\"\n        offsets = [self.mzOffsets[index], self.intensityOffsets[index]]\n        lengths = [self.mzLengths[index], self.intensityLengths[index]]\n        lengths[0] *= self.sizeDict[self.mzPrecision]\n        lengths[1] *= self.sizeDict[self.intensityPrecision]\n        self.m.seek(offsets[0])\n        mz_string = self.m.read(lengths[0])\n        self.m.seek(offsets[1])\n        intensity_string = self.m.read(lengths[1])\n        return mz_string, intensity_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_mz(self, mz_offset, mz_len, mz_enc_len):\n        '''reads a mz array from the currently open ibd file'''\n        self.ibd.seek(mz_offset)\n        data = self.ibd.read(mz_enc_len)\n        self.ibd.seek(0, 2)\n        data = self.mz_compression.decompress(data)\n        return tuple(np.fromstring(data, dtype=self.mz_dtype))", "response": "reads a mz array from the currently open ibd file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving an mz array return the mz_data ( disk location )", "response": "def _get_previous_mz(self, mzs):\n        '''given an mz array, return the mz_data (disk location)\n        if the mz array was not previously written, write to disk first'''\n        mzs = tuple(mzs)  # must be hashable\n        if mzs in self.lru_cache:\n            return self.lru_cache[mzs]\n\n        # mz not recognized ... check hash\n        mz_hash = \"%s-%s-%s\" % (hash(mzs), sum(mzs), len(mzs))\n        if mz_hash in self.hashes:\n            for mz_data in self.hashes[mz_hash]:\n                test_mz = self._read_mz(*mz_data)\n                if mzs == test_mz:\n                    self.lru_cache[test_mz] = mz_data\n                    return mz_data\n        # hash not recognized\n        # must be a new mz array ... write it, add it to lru_cache and hashes\n        mz_data = self._encode_and_write(mzs, self.mz_dtype, self.mz_compression)\n        self.hashes[mz_hash].append(mz_data)\n        self.lru_cache[mzs] = mz_data\n        return mz_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a mass spectrum to the file.", "response": "def addSpectrum(self, mzs, intensities, coords, userParams=[]):\n        \"\"\"\n        Add a mass spectrum to the file.\n\n        :param mz:\n            mz array\n        :param intensities:\n            intensity array\n        :param coords:\n\n            * 2-tuple of x and y position OR\n            * 3-tuple of x, y, and z position\n\n            note some applications want coords to be 1-indexed\n        \"\"\"\n        # must be rounded now to allow comparisons to later data\n        # but don't waste CPU time in continuous mode since the data will not be used anyway\n        if self.mode != \"continuous\" or self.first_mz is None:\n            mzs = self.mz_compression.rounding(mzs)\n        intensities = self.intensity_compression.rounding(intensities)\n\n        if self.mode == \"continuous\":\n            if self.first_mz is None:\n                self.first_mz = self._encode_and_write(mzs, self.mz_dtype, self.mz_compression)\n            mz_data = self.first_mz\n        elif self.mode == \"processed\":\n            mz_data = self._encode_and_write(mzs, self.mz_dtype, self.mz_compression)\n        elif self.mode == \"auto\":\n            mz_data = self._get_previous_mz(mzs)\n        else:\n            raise TypeError(\"Unknown mode: %s\" % self.mode)\n        mz_offset, mz_len, mz_enc_len = mz_data\n\n        int_offset, int_len, int_enc_len = self._encode_and_write(intensities, self.intensity_dtype, self.intensity_compression)\n        mz_min = np.min(mzs)\n        mz_max = np.max(mzs)\n        ix_max = np.argmax(intensities)\n        mz_base = mzs[ix_max]\n        int_base = intensities[ix_max]\n        int_tic = np.sum(intensities)\n        s = _Spectrum(coords, mz_len, mz_offset, mz_enc_len, int_len, int_offset, int_enc_len, mz_min, mz_max, mz_base, int_base, int_tic, userParams)\n        self.spectra.append(s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nattempt to install the sdist and wheel.", "response": "def install_package(context):\n    \"\"\"Attempts to install the sdist and wheel.\"\"\"\n\n    if not context.dry_run and build_distributions(context):\n        with util.mktmpdir() as tmp_dir:\n            venv.create_venv(tmp_dir=tmp_dir)\n            for distribution in Path('dist').files():\n                try:\n                    venv.install(distribution, tmp_dir)\n                    log.info('Successfully installed %s', distribution)\n                    if context.test_command and verification.run_test_command(context):\n                        log.info(\n                            'Successfully ran test command: %s', context.test_command\n                        )\n                except Exception as e:\n                    raise Exception(\n                        'Error installing distribution %s' % distribution, e\n                    )\n    else:\n        log.info('Dry run, skipping installation')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading your project packages to pypi with twine with twine.", "response": "def upload_package(context):\n    \"\"\"Uploads your project packages to pypi with twine.\"\"\"\n\n    if not context.dry_run and build_distributions(context):\n        upload_args = 'twine upload '\n        upload_args += ' '.join(Path('dist').files())\n        if context.pypi:\n            upload_args += ' -r %s' % context.pypi\n\n        upload_result = shell.dry_run(upload_args, context.dry_run)\n        if not context.dry_run and not upload_result:\n            raise Exception('Error uploading: %s' % upload_result)\n        else:\n            log.info(\n                'Successfully uploaded %s:%s', context.module_name, context.new_version\n            )\n    else:\n        log.info('Dry run, skipping package upload')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattempts to install your package from pypi.", "response": "def install_from_pypi(context):\n    \"\"\"Attempts to install your package from pypi.\"\"\"\n\n    tmp_dir = venv.create_venv()\n    install_cmd = '%s/bin/pip install %s' % (tmp_dir, context.module_name)\n\n    package_index = 'pypi'\n    if context.pypi:\n        install_cmd += '-i %s' % context.pypi\n        package_index = context.pypi\n\n    try:\n        result = shell.dry_run(install_cmd, context.dry_run)\n        if not context.dry_run and not result:\n            log.error(\n                'Failed to install %s from %s', context.module_name, package_index\n            )\n        else:\n            log.info(\n                'Successfully installed %s from %s', context.module_name, package_index\n            )\n\n    except Exception as e:\n        error_msg = 'Error installing %s from %s' % (context.module_name, package_index)\n        log.exception(error_msg)\n        raise Exception(error_msg, e)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlog the probe result and raises on failure", "response": "def report_and_raise(probe_name, probe_result, failure_msg):\n    \"\"\"Logs the probe result and raises on failure\"\"\"\n    log.info('%s? %s' % (probe_name, probe_result))\n    if not probe_result:\n        raise exceptions.ProbeException(failure_msg)\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a module has metadata", "response": "def has_metadata(python_module):\n    \"\"\"`<module_name>/__init__.py` with `__version__` and `__url__`\"\"\"\n    init_path = '{}/__init__.py'.format(python_module)\n    has_metadata = (\n        exists(init_path)\n        and attributes.has_attribute(python_module, '__version__')\n        and attributes.has_attribute(python_module, '__url__')\n    )\n    return report_and_raise(\n        'Has module metadata',\n        has_metadata,\n        'Your %s/__init__.py must contain __version__ and __url__ attributes',\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the project meets changes requirements.", "response": "def probe_project(python_module):\n    \"\"\"\n    Check if the project meets `changes` requirements.\n    Complain and exit otherwise.\n    \"\"\"\n    log.info('Checking project for changes requirements.')\n    return (\n        has_tools()\n        and has_setup()\n        and has_metadata(python_module)\n        and has_test_runner()\n        and has_readme()\n        and has_changelog()\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the release process.", "response": "def perform_release(context):\n    \"\"\"Executes the release process.\"\"\"\n    try:\n        run_tests()\n\n        if not context.skip_changelog:\n            generate_changelog(context)\n\n        increment_version(context)\n\n        build_distributions(context)\n\n        install_package(context)\n\n        upload_package(context)\n\n        install_from_pypi(context)\n\n        publish(context)\n    except Exception:\n        log.exception('Error releasing')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract metatdata property from a module", "response": "def extract_attribute(module_name, attribute_name):\n    \"\"\"Extract metatdata property from a module\"\"\"\n    with open('%s/__init__.py' % module_name) as input_file:\n        for line in input_file:\n            if line.startswith(attribute_name):\n                return ast.literal_eval(line.split('=')[1].strip())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_attribute(module_name, attribute_name, new_value, dry_run=True):\n    init_file = '%s/__init__.py' % module_name\n    _, tmp_file = tempfile.mkstemp()\n\n    with open(init_file) as input_file:\n        with open(tmp_file, 'w') as output_file:\n            for line in input_file:\n                if line.startswith(attribute_name):\n                    line = \"%s = '%s'\\n\" % (attribute_name, new_value)\n\n                output_file.write(line)\n\n    if not dry_run:\n        Path(tmp_file).copy(init_file)\n    else:\n        log.info(diff(tmp_file, init_file, retcode=None))", "response": "Update a metadata attribute in a module"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_attribute(module_name, attribute_name):\n    init_file = '%s/__init__.py' % module_name\n    return any(\n        [attribute_name in init_line for init_line in open(init_file).readlines()]\n    )", "response": "Is this attribute present?"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef choose_labels(alternatives):\n    if not alternatives:\n        raise ValueError\n\n    if not isinstance(alternatives, list):\n        raise TypeError\n\n    choice_map = OrderedDict(\n        ('{}'.format(i), value) for i, value in enumerate(alternatives, 1)\n    )\n    # prepend a termination option\n    input_terminator = '0'\n    choice_map.update({input_terminator: '<done>'})\n    choice_map.move_to_end('0', last=False)\n\n    choice_indexes = choice_map.keys()\n\n    choice_lines = ['{} - {}'.format(*c) for c in choice_map.items()]\n    prompt = '\\n'.join(\n        (\n            'Select labels:',\n            '\\n'.join(choice_lines),\n            'Choose from {}'.format(', '.join(choice_indexes)),\n        )\n    )\n\n    user_choices = set()\n    user_choice = None\n\n    while not user_choice == input_terminator:\n        if user_choices:\n            note('Selected labels: [{}]'.format(', '.join(user_choices)))\n\n        user_choice = click.prompt(\n            prompt, type=click.Choice(choice_indexes), default=input_terminator\n        )\n        done = user_choice == input_terminator\n        new_selection = user_choice not in user_choices\n        nothing_selected = not user_choices\n\n        if not done and new_selection:\n            user_choices.add(choice_map[user_choice])\n\n        if done and nothing_selected:\n            error('Please select at least one label')\n            user_choice = None\n\n    return user_choices", "response": "Prompt the user to select several labels from the provided alternatives."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstage a release in a repository.", "response": "def stage(draft, discard, repo_directory, release_name, release_description):\n    \"\"\"\n    Stages a release\n    \"\"\"\n    with work_in(repo_directory):\n        if discard:\n            stage_command.discard(release_name, release_description)\n        else:\n            stage_command.stage(draft, release_name, release_description)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_changelog(context):\n\n    changelog_content = [\n        '\\n## [%s](%s/compare/%s...%s)\\n\\n'\n        % (\n            context.new_version,\n            context.repo_url,\n            context.current_version,\n            context.new_version,\n        )\n    ]\n\n    git_log_content = None\n    git_log = 'log --oneline --no-merges --no-color'.split(' ')\n    try:\n        git_log_tag = git_log + ['%s..master' % context.current_version]\n        git_log_content = git(git_log_tag)\n        log.debug('content: %s' % git_log_content)\n    except Exception:\n        log.warn('Error diffing previous version, initial release')\n        git_log_content = git(git_log)\n\n    git_log_content = replace_sha_with_commit_link(context.repo_url, git_log_content)\n    # turn change log entries into markdown bullet points\n    if git_log_content:\n        [\n            changelog_content.append('* %s\\n' % line) if line else line\n            for line in git_log_content[:-1]\n        ]\n\n    write_new_changelog(\n        context.repo_url, 'CHANGELOG.md', changelog_content, dry_run=context.dry_run\n    )\n    log.info('Added content to CHANGELOG.md')\n    context.changelog_content = changelog_content", "response": "Generates an automatic changelog from your commit messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract(dictionary, keys):\n    return dict((k, dictionary[k]) for k in keys if k in dictionary)", "response": "Extract only the specified keys from a dictionary\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_arguments(arguments, long_keys, key_prefix='--'):\n    long_arguments = extract(arguments, long_keys)\n    return dict(\n        [(key.replace(key_prefix, ''), value) for key, value in long_arguments.items()]\n    )", "response": "Extracts the arguments from the command line arguments dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntag your git repo with the new version number", "response": "def tag_and_push(context):\n    \"\"\"Tags your git repo with the new version number\"\"\"\n    tag_option = '--annotate'\n    if probe.has_signing_key(context):\n        tag_option = '--sign'\n\n    shell.dry_run(\n        TAG_TEMPLATE % (tag_option, context.new_version, context.new_version),\n        context.dry_run,\n    )\n\n    shell.dry_run('git push --tags', context.dry_run)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dry_run(command, dry_run):\n    if not dry_run:\n        cmd_parts = command.split(' ')\n        # http://plumbum.readthedocs.org/en/latest/local_commands.html#run-and-popen\n        return local[cmd_parts[0]](cmd_parts[1:])\n    else:\n        log.info('Dry run of %s, skipping' % command)\n    return True", "response": "Executes a shell command unless the dry run option is set"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef project_config():\n    project_name = curdir\n\n    config_path = Path(join(project_name, PROJECT_CONFIG_FILE))\n\n    if not exists(config_path):\n        store_settings(DEFAULTS.copy())\n        return DEFAULTS\n\n    return toml.load(io.open(config_path)) or {}", "response": "Load the project configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef increment(version, major=False, minor=False, patch=True):\n    version = semantic_version.Version(version)\n    if major:\n        version.major += 1\n        version.minor = 0\n        version.patch = 0\n    elif minor:\n        version.minor += 1\n        version.patch = 0\n    elif patch:\n        version.patch += 1\n\n    return str(version)", "response": "Increment a semantic version of a node in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nincrements the __version__ attribute of your module s __init__.", "response": "def increment_version(context):\n    \"\"\"Increments the __version__ attribute of your module's __init__.\"\"\"\n\n    attributes.replace_attribute(\n        context.module_name, '__version__', context.new_version, dry_run=context.dry_run\n    )\n    log.info(\n        'Bumped version from %s to %s' % (context.current_version, context.new_version)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(github_token, github_api_url, progress):\n    global progress_reporter_cls\n    progress_reporter_cls.reportProgress = sys.stdout.isatty() and progress\n    if progress_reporter_cls.reportProgress:\n        progress_reporter_cls = _progress_bar\n    global _github_token_cli_arg\n    _github_token_cli_arg = github_token\n    global _github_api_url\n    _github_api_url = github_api_url", "response": "A CLI to easily manage GitHub releases assets and references."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the commit associated with a given release tag.", "response": "def _update_release_sha(repo_name, tag_name, new_release_sha, dry_run):\n    \"\"\"Update the commit associated with a given release tag.\n\n    Since updating a tag commit is not directly possible, this function\n    does the following steps:\n    * set the release tag to ``<tag_name>-tmp`` and associate it\n      with ``new_release_sha``.\n    * delete tag ``refs/tags/<tag_name>``.\n    * update the release tag to ``<tag_name>`` and associate it\n      with ``new_release_sha``.\n    \"\"\"\n    if new_release_sha is None:\n        return\n    refs = get_refs(repo_name, tags=True, pattern=\"refs/tags/%s\" % tag_name)\n    if not refs:\n        return\n    assert len(refs) == 1\n\n    # If sha associated with \"<tag_name>\" is up-to-date, we are done.\n    previous_release_sha = refs[0][\"object\"][\"sha\"]\n    if previous_release_sha == new_release_sha:\n        return\n\n    tmp_tag_name = tag_name + \"-tmp\"\n\n    # If any, remove leftover temporary tag \"<tag_name>-tmp\"\n    refs = get_refs(repo_name, tags=True, pattern=\"refs/tags/%s\" % tmp_tag_name)\n    if refs:\n        assert len(refs) == 1\n        time.sleep(0.1)\n        gh_ref_delete(repo_name,\n                      \"refs/tags/%s\" % tmp_tag_name, dry_run=dry_run)\n\n    # Update \"<tag_name>\" release by associating it with the \"<tag_name>-tmp\"\n    # and \"<new_release_sha>\". It will create the temporary tag.\n    time.sleep(0.1)\n    patch_release(repo_name, tag_name,\n                  tag_name=tmp_tag_name,\n                  target_commitish=new_release_sha,\n                  dry_run=dry_run)\n\n    # Now \"<tag_name>-tmp\" references \"<new_release_sha>\", remove \"<tag_name>\"\n    time.sleep(0.1)\n    gh_ref_delete(repo_name, \"refs/tags/%s\" % tag_name, dry_run=dry_run)\n\n    # Finally, update \"<tag_name>-tmp\" release by associating it with the\n    # \"<tag_name>\" and \"<new_release_sha>\".\n    time.sleep(0.1)\n    patch_release(repo_name, tmp_tag_name,\n                  tag_name=tag_name,\n                  target_commitish=new_release_sha,\n                  dry_run=dry_run)\n\n    # ... and remove \"<tag_name>-tmp\"\n    time.sleep(0.1)\n    gh_ref_delete(repo_name,\n                  \"refs/tags/%s\" % tmp_tag_name, dry_run=dry_run)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef approved_funds(pronac, dt):\n    funds_df = data.approved_funds_by_projects\n\n    project = (\n        funds_df\n        .loc[funds_df['PRONAC'] == pronac]\n    )\n    project = project.to_dict('records')[0]\n    info = (\n        data\n        .approved_funds_agg.to_dict(orient=\"index\")\n        [project['idSegmento']]\n    )\n\n    mean, std = info.values()\n\n    outlier = gaussian_outlier.is_outlier(project['VlTotalAprovado'],\n                                          mean, std)\n    maximum_expected_funds = gaussian_outlier.maximum_expected_value(mean, std)\n\n    return {\n        'is_outlier': outlier,\n        'total_approved_funds': project['VlTotalAprovado'],\n        'maximum_expected_funds': maximum_expected_funds\n    }", "response": "Verifica se o valor total de um projeto \u00e9 um\n    outlier em rela\u00e7\u00e3o um cultural\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef complexidade(obj):\n    indicators = obj.indicator_set.all()\n    if not indicators:\n        value = 0.0\n    else:\n        value = indicators.first().value\n    return value", "response": "Returns a value that indicates project health"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning project pronac name indicators with details", "response": "def details(project):\n    \"\"\"\n    Project detail endpoint,\n    Returns project pronac, name,\n    and indicators with details\n    \"\"\"\n    indicators = project.indicator_set.all()\n    indicators_detail = [(indicator_details(i)\n                         for i in indicators)][0]\n    if not indicators:\n        indicators_detail = [\n                        {'FinancialIndicator':\n                            {'valor': 0.0,\n                             'metrics': default_metrics, }, }]\n    indicators_detail = convert_list_into_dict(indicators_detail)\n\n    return {'pronac': project.pronac,\n            'nome': project.nome,\n            'indicadores': indicators_detail,\n            }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef indicator_details(indicator):\n    metrics = format_metrics_json(indicator)\n\n    metrics_list = set(indicator.metrics\n                       .filter(name__in=metrics_name_map.keys())\n                       .values_list('name', flat=True))\n    null_metrics = default_metrics\n    for keys in metrics_list:\n        null_metrics.pop(metrics_name_map[keys], None)\n\n    metrics.update(null_metrics)\n\n    return {type(indicator).__name__: {\n            'valor': indicator.value,\n            'metricas': metrics, },\n            }", "response": "Return a dictionary with all metrics in FinancialIndicator filled with default values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the metric for the given pronac number.", "response": "def get_metric(self, pronac, metric):\n        \"\"\"\n        Get metric for the project with the given pronac number.\n\n        Usage:\n            >>> metrics.get_metric(pronac_id, 'finance.approved_funds')\n        \"\"\"\n\n        assert isinstance(metric, str)\n        assert '.' in metric, 'metric must declare a namespace'\n\n        try:\n            func = self._metrics[metric]\n            return func(pronac, self._data)\n        except KeyError:\n            raise InvalidMetricError('metric does not exist')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute_project_models_sql_scripts(force_update=False):\n    # TODO: Remove except and use ignore_conflicts\n    # on bulk_create when django 2.2. is released\n    with open(MODEL_FILE, \"r\") as file_content:\n        query = file_content.read()\n        db = db_connector()\n        query_result = db.execute_pandas_sql_query(query)\n        db.close()\n        try:\n            projects = Project.objects.bulk_create(\n                (Project(**vals) for vals in query_result.to_dict(\"records\")),\n                # ignore_conflicts=True available on django 2.2.\n            )\n            indicators = [FinancialIndicator(project=p) for p in projects]\n            FinancialIndicator.objects.bulk_create(indicators)\n        except IntegrityError:\n            # happens when there are duplicated projects\n            LOG(\"Projects bulk_create failed, creating one by one...\")\n            with transaction.atomic():\n                if force_update:\n                    for item in query_result.to_dict(\"records\"):\n                        p, _ = Project.objects.update_or_create(**item)\n                        FinancialIndicator.objects.update_or_create(project=p)\n                else:\n\n                    for item in query_result.to_dict(\"records\"):\n                        p, _ = Project.objects.get_or_create(**item)\n                        FinancialIndicator.objects.update_or_create(project=p)", "response": "Execute the MinC project models SQL scripts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_finance_metrics(metrics: list, pronacs: list):\n    missing = missing_metrics(metrics, pronacs)\n    print(f\"There are {len(missing)} missing metrics!\")\n\n    processors = mp.cpu_count()\n    print(f\"Using {processors} processors to calculate metrics!\")\n\n    indicators_qs = FinancialIndicator.objects.filter(\n        project_id__in=[p for p, _ in missing]\n    )\n    indicators = {i.project_id: i for i in indicators_qs}\n\n    pool = mp.Pool(processors)\n    results = [\n        pool.apply_async(create_metric, args=(indicators, metric_name, pronac))\n        for pronac, metric_name in missing\n    ]\n\n    calculated_metrics = [p.get() for p in results]\n    if calculated_metrics:\n        Metric.objects.bulk_create(calculated_metrics)\n        print(\"Bulk completed\")\n\n        for indicator in indicators.values():\n            indicator.fetch_weighted_complexity()\n\n        print(\"Finished update indicators!\")\n\n    pool.close()\n    print(\"Finished metrics calculation!\")", "response": "Creates metrics creating Indicator if it doesn t already exists"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef total_receipts(pronac, dt):\n    dataframe = data.planilha_comprovacao\n    project = dataframe.loc[dataframe['PRONAC'] == pronac]\n\n    segment_id = project.iloc[0][\"idSegmento\"]\n    segments_cache = data.segment_projects_agg\n    segments_cache = segments_cache.to_dict(orient=\"index\")\n\n    mean = segments_cache[segment_id][\"mean\"]\n    std = segments_cache[segment_id][\"<lambda>\"]\n    total_receipts = project.shape[0]\n    is_outlier = gaussian_outlier.is_outlier(total_receipts, mean, std)\n    maximum_expected = gaussian_outlier.maximum_expected_value(mean, std)\n    return {\n            \"is_outlier\": is_outlier,\n            \"valor\": total_receipts,\n            \"maximo_esperado\": maximum_expected,\n            \"minimo_esperado\": 0,\n        }", "response": "This metric calculates the project total of receipts\n            and compare it to projects in the same segment\n    and return the result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates project metrics for financial indicator Updates them if already exists", "response": "def load_project_metrics():\n    \"\"\"\n    Create project metrics for financial indicator\n    Updates them if already exists\n    \"\"\"\n    all_metrics = FinancialIndicator.METRICS\n    for key in all_metrics:\n        df = getattr(data, key)\n        pronac = 'PRONAC'\n        if key == 'planilha_captacao':\n            pronac = 'Pronac'\n        pronacs = df[pronac].unique().tolist()\n        create_finance_metrics(all_metrics[key], pronacs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new_providers(pronac, dt):\n    info = data.providers_info\n    df = info[info['PRONAC'] == pronac]\n    providers_count = data.providers_count.to_dict()[0]\n\n    new_providers = []\n    segment_id = None\n\n    for _, row in df.iterrows():\n        cnpj = row['nrCNPJCPF']\n        cnpj_count = providers_count.get(cnpj, 0)\n        segment_id = row['idSegmento']\n\n        if cnpj_count <= 1:\n            item_id = row['idPlanilhaAprovacao']\n            item_name = row['Item']\n            provider_name = row['nmFornecedor']\n\n            new_provider = {\n                'nome': provider_name,\n                'cnpj': cnpj,\n                'itens': {\n                    item_id: {\n                        'nome': item_name,\n                        'tem_comprovante': True\n                    }\n                }\n            }\n            new_providers.append(new_provider)\n\n    providers_amount = len(df['nrCNPJCPF'].unique())\n\n    new_providers_amount = len(new_providers)\n\n    new_providers_percentage = new_providers_amount / providers_amount\n\n    averages = data.average_percentage_of_new_providers.to_dict()\n    segments_average = averages['segments_average_percentage']\n    all_projects_average = list(averages['all_projects_average'].values())[0]\n    if new_providers:\n        new_providers.sort(key=lambda provider: provider['nome'])\n\n    return {\n        'lista_de_novos_fornecedores': new_providers,\n        'valor': new_providers_amount,\n        'new_providers_percentage': new_providers_percentage,\n        'is_outlier': new_providers_percentage > segments_average[segment_id],\n        'segment_average_percentage': segments_average[segment_id],\n        'all_projects_average_percentage': all_projects_average,\n    }", "response": "Return the percentage of providers of a project\n    that are new to the providers database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the average percentage of new providers and the average percentage of all projects.", "response": "def average_percentage_of_new_providers(providers_info, providers_count):\n    \"\"\"\n    Return the average percentage of new providers\n    per segment and the average percentage of all projects.\n    \"\"\"\n    segments_percentages = {}\n    all_projects_percentages = []\n    providers_count = providers_count.to_dict()[0]\n\n    for _, items in providers_info.groupby('PRONAC'):\n        cnpj_array = items['nrCNPJCPF'].unique()\n        new_providers = 0\n        for cnpj in cnpj_array:\n            cnpj_count = providers_count.get(cnpj, 0)\n            if cnpj_count <= 1:\n                new_providers += 1\n\n        segment_id = items.iloc[0]['idSegmento']\n        new_providers_percent = new_providers / cnpj_array.size\n        segments_percentages.setdefault(segment_id, [])\n        segments_percentages[segment_id].append(new_providers_percent)\n        all_projects_percentages.append(new_providers_percent)\n\n    segments_average_percentage = {}\n    for segment_id, percentages in segments_percentages.items():\n        mean = np.mean(percentages)\n        segments_average_percentage[segment_id] = mean\n\n    return pd.DataFrame.from_dict({\n        'segments_average_percentage': segments_average_percentage,\n        'all_projects_average': np.mean(all_projects_percentages)\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef providers_count(df):\n    providers_count = {}\n    cnpj_array = df.values\n\n    for a in cnpj_array:\n        cnpj = a[0]\n        occurrences = providers_count.get(cnpj, 0)\n        providers_count[cnpj] = occurrences + 1\n\n    return pd.DataFrame.from_dict(providers_count, orient='index')", "response": "Returns the total number of occurrences of each provider\n    in the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning CPF and CNPJ of all providers in database.", "response": "def all_providers_cnpj(df):\n    \"\"\"\n    Return CPF/CNPJ of all providers\n    in database.\n    \"\"\"\n    cnpj_list = []\n\n    for _, items in df.groupby('PRONAC'):\n        unique_cnpjs = items['nrCNPJCPF'].unique()\n        cnpj_list += list(unique_cnpjs)\n\n    return pd.DataFrame(cnpj_list)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_providers_info(pronac):\n    df = data.providers_info\n    grouped = df.groupby('PRONAC')\n\n    return grouped.get_group(pronac)", "response": "Return all info about providers of a\n    project with the given pronac."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\naggregate mean and std with the given group.", "response": "def get_info(df, group, info=['mean', 'std']):\n    \"\"\"\n    Aggregate mean and std with the given group.\n    \"\"\"\n    agg = df.groupby(group).agg(info)\n    agg.columns = agg.columns.droplevel(0)\n    return agg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_salic_url(item, prefix, df_values=None):\n    url_keys = {\n        'pronac': 'idPronac',\n        'uf': 'uf',\n        'product': 'produto',\n        'county': 'idmunicipio',\n        'item_id': 'idPlanilhaItem',\n        'stage': 'etapa',\n    }\n\n    if df_values:\n        values = [item[v] for v in df_values]\n        url_values = dict(\n            zip(url_keys.keys(), values)\n        )\n    else:\n        url_values = {\n            \"pronac\": item[\"idPronac\"],\n            \"uf\": item[\"UfItem\"],\n            \"product\": item[\"idProduto\"],\n            \"county\": item[\"cdCidade\"],\n            \"item_id\": item[\"idPlanilhaItens\"],\n            \"stage\": item[\"cdEtapa\"],\n        }\n\n    item_data = [(value, url_values[key]) for key, value in url_keys.items()]\n    url = prefix\n    for k, v in item_data:\n        url += f'/{str(k)}/{str(v)}'\n\n    return url", "response": "Mount a salic url for the given item."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cpf_cnpj_by_pronac(pronac):\n    df = data.planilha_projetos\n    cpf_cnpj = None\n    row_df = df[df['PRONAC'].astype(str) == str(pronac)]\n\n    if not row_df.empty:\n        cpf_cnpj = row_df.iloc[0]['CgcCpf']\n\n    return str(cpf_cnpj)", "response": "Return the CNPF and CNPJ of the proponent\n    of the project with the given pronac."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_receipt(item):\n    pronac_id = str(item['idPronac'])\n    item_id = str(item[\"idPlanilhaItens\"])\n\n    combined_id = f'{pronac_id}/{item_id}'\n\n    return combined_id in data.receipt.index", "response": "Verify if a item has a receipt."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_segment_projects(segment_id):\n    df = data.all_items\n    return (\n        df[df['idSegmento'] == str(segment_id)]\n        .drop_duplicates([\"PRONAC\"])\n        .values\n    )", "response": "Returns all projects from a segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef receipt(df):\n    mutated_df = df[['IdPRONAC', 'idPlanilhaItem']].astype(str)\n    mutated_df['pronac_planilha_itens'] = (\n        f\"{mutated_df['IdPRONAC']}/{mutated_df['idPlanilhaItem']}\"\n    )\n\n    return (\n        mutated_df\n        .set_index(['pronac_planilha_itens'])\n    )", "response": "Return a dataframe to verify if a item has a receipt."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates local django db projects and pickles files using salic database", "response": "def update_data(ctx, models=True, pickles=False, f=False):\n    \"\"\"\n    Updates local django db projects and pickle files using salic database from\n    MinC\n    Pickles are saved in /data/raw/ from sql queries in /data/scripts/\n    Models are created from /data/scripts/models/\n    \"\"\"\n    if pickles:\n        save_sql_to_files(f)\n    if models:\n        if f:\n            manage(ctx, 'create_models_from_sql --force True', env={})\n        else:\n            manage(ctx, 'create_models_from_sql', env={})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_models(ctx, f=False):\n    if f:\n        manage(ctx, 'create_models_from_sql --force True', env={})\n    else:\n        manage(ctx, 'create_models_from_sql', env={})", "response": "Updates local django db projects models using salic database from\n    MinC\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a FinancialIndicator object for a project calculating metrics and indicator value", "response": "def create_indicator(self, project, is_valid, metrics_list):\n        \"\"\"\n        Creates FinancialIndicator object for a project, calculating\n        metrics and indicator value\n        \"\"\"\n        project = Project.objects.get(pronac=project)\n        indicator, _ = (FinancialIndicator\n                        .objects.update_or_create(project=project))\n        indicator.is_valid = is_valid\n        if indicator.is_valid:\n            p_metrics = metrics_calc.get_project(project.pronac)\n            for metric_name in metrics_list:\n                print(\"calculando a metrica  \", metric_name)\n                x = getattr(p_metrics.finance, metric_name)\n                print(\"do projeto: \", project)\n                Metric.objects.create_metric(metric_name, x, indicator)\n            indicator.fetch_weighted_complexity()\n        return indicator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_sql_to_files(overwrite=False):\n    ext_size = len(SQL_EXTENSION)\n    path = DATA_PATH / 'scripts'\n    save_dir = DATA_PATH / \"raw\"\n\n    for file in os.listdir(path):\n        if file.endswith(SQL_EXTENSION):\n            file_path = os.path.join(save_dir,\n                                     file[:-ext_size] + '.' + FILE_EXTENSION)\n            if not os.path.isfile(file_path) or overwrite:\n                query_result = make_query(path / file)\n                save_dataframe_as_pickle(query_result, file_path)\n            else:\n                print((\"file {} already exists, if you would like to update\"\n                       \" it, use -f flag\\n\").format(file_path))", "response": "Saves all. sql files in the database and all raw files in the database into a single file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_weighted_complexity(self, recalculate_metrics=False):\n        # TODO: implment metrics recalculation\n        max_total = sum(\n            [self.metrics_weights[metric_name] for metric_name in self.metrics_weights]\n        )\n        total = 0\n        if recalculate_metrics:\n            self.calculate_indicator_metrics()\n        for metric in self.metrics.all():\n            if metric.name in self.metrics_weights and metric.is_outlier:\n                total += self.metrics_weights[metric.name]\n\n        value = total / max_total\n\n        final_value = \"{:.1f}\".format(value * 10)\n\n        if final_value[-1] == \"0\":\n            final_value = \"{:.0f}\".format(value * 10)\n            final_value = int(final_value)\n        else:\n            final_value = float(final_value)\n        self.value = float(final_value)\n        self.is_valid = True\n        self.updated_at = datetime.datetime.now()\n        self.save()\n        return final_value", "response": "Calculates the weighted complexity of the current entry in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef item_prices(pronac, data):\n    threshold = 0.1\n\n    outlier_info = get_outliers_percentage(pronac)\n    outlier_info['is_outlier'] = outlier_info['percentage'] > threshold\n    outlier_info['maximum_expected'] = threshold * outlier_info['total_items']\n\n    return outlier_info", "response": "Verify if a project is an outlier compared to another project based on the price of bought items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nverify if a item is an outlier compared to the other occurrences of the same item based on his price.", "response": "def is_outlier(df, item_id, segment_id, price):\n    \"\"\"\n    Verify if a item is an outlier compared to the\n    other occurrences of the same item, based on his price.\n\n    Args:\n        item_id: idPlanilhaItens\n        segment_id: idSegmento\n        price: VlUnitarioAprovado\n    \"\"\"\n\n    if (segment_id, item_id) not in df.index:\n        return False\n\n    mean = df.loc[(segment_id, item_id)]['mean']\n    std = df.loc[(segment_id, item_id)]['std']\n\n    return gaussian_outlier.is_outlier(\n        x=price, mean=mean, standard_deviation=std\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef aggregated_relevant_items(raw_df):\n    df = (\n        raw_df[['idSegmento', 'idPlanilhaItens', 'VlUnitarioAprovado']]\n        .groupby(by=['idSegmento', 'idPlanilhaItens'])\n        .agg([np.mean, lambda x: np.std(x, ddof=0)])\n    )\n    df.columns = df.columns.droplevel(0)\n    return (\n        df\n        .rename(columns={'<lambda>': 'std'})\n    )", "response": "Aggragation for calculate mean and std."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef items_with_price(raw_df):\n    df = (\n        raw_df\n        [['PRONAC', 'idPlanilhaAprovacao', 'Item',\n            'idPlanilhaItens', 'VlUnitarioAprovado',\n            'idSegmento', 'DataProjeto', 'idPronac',\n            'UfItem', 'idProduto', 'cdCidade', 'cdEtapa']]\n    ).copy()\n\n    df['VlUnitarioAprovado'] = df['VlUnitarioAprovado'].apply(pd.to_numeric)\n    return df", "response": "Dataframe with price as number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the percentage of items that are outliers.", "response": "def get_outliers_percentage(pronac):\n    \"\"\"\n    Returns the percentage of items\n    of the project that are outliers.\n    \"\"\"\n    items = (\n        data.items_with_price\n        .groupby(['PRONAC'])\n        .get_group(pronac)\n    )\n\n    df = data.aggregated_relevant_items\n\n    outlier_items = {}\n    url_prefix = '/prestacao-contas/analisar/comprovante'\n\n    for _, item in items.iterrows():\n        item_id = item['idPlanilhaItens']\n        price = item['VlUnitarioAprovado']\n        segment_id = item['idSegmento']\n        item_name = item['Item']\n\n        if is_outlier(df, item_id, segment_id, price):\n            outlier_items[item_id] = {\n                'name': item_name,\n                'salic_url': get_salic_url(item, url_prefix),\n                'has_receipt': has_receipt(item)\n            }\n\n    total_items = items.shape[0]\n    outliers_amount = len(outlier_items)\n\n    percentage = outliers_amount / total_items\n\n    return {\n        'items': outlier_items,\n        'valor': outliers_amount,\n        'total_items': total_items,\n        'percentage': percentage,\n        'is_outlier': outliers_amount > 0,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef number_of_items(pronac, dt):\n    df = data.items_by_project\n    project = df.loc[df['PRONAC'] == pronac]\n    seg = project.iloc[0][\"idSegmento\"]\n    info = data.items_by_project_agg.to_dict(orient=\"index\")[seg]\n    mean, std = info.values()\n    threshold = mean + 1.5 * std\n    project_items_count = project.shape[0]\n    is_outlier = project_items_count > threshold\n    return {\n       'is_outlier': is_outlier,\n       'valor': project_items_count,\n       'maximo_esperado': mean,\n       'desvio_padrao': std,\n    }", "response": "This metric calculates the project number of items in a segment\nWorkItem and compares it to projects in the same segment\nWorkItem and returns the result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the itens that are common in all the segments", "response": "def common_items(df):\n    \"\"\"\n    Returns the itens that are common in all the segments,\n    in the format | idSegmento | id planilhaItens |.\n    \"\"\"\n    percentage = 0.1\n\n    return (\n        df\n        .groupby(['idSegmento', 'idPlanilhaItens'])\n        .count()\n        .rename(columns={'PRONAC': 'itemOccurrences'})\n        .sort_values('itemOccurrences', ascending=False)\n        .reset_index(['idSegmento', 'idPlanilhaItens'])\n        .groupby('idSegmento')\n        .apply(lambda x: x[None: max(2, int(len(x) * percentage))])\n        .reset_index(['idSegmento'], drop=True)\n        .set_index(['idSegmento'])\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef common_items_percentage(pronac, seg_common_items):\n    if len(seg_common_items) == 0:\n        return 0\n\n    project_items = get_project_items(pronac).values[:, 0]\n    project_items_amount = len(project_items)\n\n    if project_items_amount == 0:\n        return 1\n\n    common_found_items = sum(\n        seg_common_items.isin(project_items)['idPlanilhaItens']\n    )\n\n    return common_found_items / project_items_amount", "response": "Returns the percentage of items in a project that are\n    common in the cultural segment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef common_items_metrics(all_items, common_items):\n    segments = common_items.index.unique()\n    metrics = {}\n    for seg in segments:\n        seg_common_items = segment_common_items(seg)\n        projects = get_segment_projects(seg)\n\n        metric_values = []\n\n        for proj in projects:\n            pronac = proj[0]\n            percentage = common_items_percentage(pronac, seg_common_items)\n            metric_values.append(percentage)\n\n        metrics[seg] = {\n            'mean': np.mean(metric_values),\n            'std': np.std(metric_values)\n        }\n    return pd.DataFrame.from_dict(metrics, orient='index')", "response": "Calculates the percentage of common items for each project\n    in each segment and calculates the mean and std of this percentage of each project\n    in each segment and calculates the mean and std of this percentage of each project\n    in each segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_project_items(pronac):\n    df = data.all_items\n    return (\n        df[df['PRONAC'] == pronac]\n        .drop(columns=['PRONAC', 'idSegmento'])\n    )", "response": "Returns all items from a project."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef segment_common_items(segment_id):\n    df = data.common_items\n    return (\n        df\n        .loc[str(segment_id)]\n        .reset_index(drop=1)\n        .drop(columns=[\"itemOccurrences\"])\n    )", "response": "Returns all the common items in a segment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_uncommon_items(pronac):\n    segment_id = get_segment_id(str(pronac))\n    seg_common_items = (\n        segment_common_items(segment_id)\n        .set_index('idPlanilhaItens')\n        .index\n    )\n    project_items = (\n        get_project_items(pronac)\n        .set_index('idPlanilhaItens')\n        .index\n    )\n\n    diff = list(project_items.difference(seg_common_items))\n\n    return (\n        data.distinct_items\n        .loc[diff]\n        .to_dict()['Item']\n    )", "response": "Return all uncommon items of a project."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds extra info to the uncommon items.", "response": "def add_info_to_uncommon_items(filtered_items, uncommon_items):\n    \"\"\"\n    Add extra info to the uncommon items.\n    \"\"\"\n\n    result = uncommon_items\n    url_prefix = '/prestacao-contas/analisar/comprovante'\n\n    for _, item in filtered_items.iterrows():\n        item_id = item['idPlanilhaItens']\n        item_name = uncommon_items[item_id]\n\n        result[item_id] = {\n            'name': item_name,\n            'salic_url': get_salic_url(item, url_prefix),\n            'has_recepit': has_receipt(item)\n        }\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef common_items_ratio(pronac, dt):\n    segment_id = get_segment_id(str(pronac))\n    metrics = data.common_items_metrics.to_dict(orient='index')[segment_id]\n    ratio = common_items_percentage(pronac, segment_common_items(segment_id))\n\n    # constant that defines the threshold to verify if a project\n    # is an outlier.\n    k = 1.5\n\n    threshold = metrics['mean'] - k * metrics['std']\n    uncommon_items = get_uncommon_items(pronac)\n\n    pronac_filter = data.all_items['PRONAC'] == pronac\n    uncommon_items_filter = (\n        data.all_items['idPlanilhaItens']\n        .isin(uncommon_items)\n    )\n    items_filter = (pronac_filter & uncommon_items_filter)\n\n    filtered_items = (\n        data\n        .all_items[items_filter]\n        .drop_duplicates(subset='idPlanilhaItens')\n    )\n    uncommon_items = add_info_to_uncommon_items(filtered_items, uncommon_items)\n\n    return {\n        'is_outlier': ratio < threshold,\n        'valor': ratio,\n        'maximo_esperado': metrics['mean'],\n        'desvio_padrao': metrics['std'],\n        'items_incomuns': uncommon_items,\n        'items_comuns_que_o_projeto_nao_possui': get_common_items_not_present(pronac),\n    }", "response": "Calculates the common items on projects in a cultural segment and calculates the uncommon items on projects in a cultural segment and verify if a project is an outlier compared to the other projects in his segment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of the verified funds for a project.", "response": "def verified_funds(pronac, dt):\n    \"\"\"\n    Responsable for detecting anomalies in projects total verified funds.\n    \"\"\"\n    dataframe = data.planilha_comprovacao\n    project = dataframe.loc[dataframe['PRONAC'] == pronac]\n    segment_id = project.iloc[0][\"idSegmento\"]\n    pronac_funds = project[\n        [\"idPlanilhaAprovacao\", \"PRONAC\", \"vlComprovacao\", \"idSegmento\"]\n    ]\n    funds_grp = pronac_funds.drop(columns=[\"idPlanilhaAprovacao\"]).groupby(\n        [\"PRONAC\"]\n    )\n    project_funds = funds_grp.sum().loc[pronac][\"vlComprovacao\"]\n\n    segments_info = data.verified_funds_by_segment_agg.to_dict(orient=\"index\")\n    mean = segments_info[segment_id][\"mean\"]\n    std = segments_info[segment_id][\"std\"]\n    is_outlier = gaussian_outlier.is_outlier(project_funds, mean, std)\n    maximum_expected_funds = gaussian_outlier.maximum_expected_value(mean, std)\n    return {\n            \"is_outlier\": is_outlier,\n            \"valor\": project_funds,\n            \"maximo_esperado\": maximum_expected_funds,\n            \"minimo_esperado\": 0,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nraises funds organized by project.", "response": "def raised_funds_by_project(df):\n    \"\"\"\n    Raised funds organized by project.\n    \"\"\"\n    df['CaptacaoReal'] = df['CaptacaoReal'].apply(\n        pd.to_numeric\n    )\n    return (\n        df[['Pronac', 'CaptacaoReal']]\n        .groupby(['Pronac'])\n        .sum()\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_verify_funds(pronac, dt):\n    project_raised_funds = data.raised_funds_by_project.loc[pronac]['CaptacaoReal']\n\n    dataframe = data.planilha_comprovacao\n    project_verified = dataframe.loc[dataframe['PRONAC'] == str(pronac)]\n    if project_verified.empty:\n        project_verified_funds = 0\n    else:\n        pronac_funds = project_verified[\n            [\"idPlanilhaAprovacao\", \"PRONAC\", \"vlComprovacao\", \"idSegmento\"]\n        ]\n        funds_grp = pronac_funds.drop(columns=[\"idPlanilhaAprovacao\"]).groupby(\n            [\"PRONAC\"]\n        )\n        project_verified_funds = funds_grp.sum().loc[pronac][\"vlComprovacao\"]\n\n    to_verify_value = project_raised_funds - float(project_verified_funds)\n    is_outlier = to_verify_value != 0\n\n    return {\n        'is_outlier': is_outlier,\n        'valor': to_verify_value,\n        'valor_captado': project_raised_funds,\n        'valor_comprovado': project_verified_funds,\n        'minimo_esperado': 0,\n    }", "response": "Returns a dictionary of the relevant information about the project that is to be verified"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef proponent_projects(pronac, data):\n    cpf_cnpj = get_cpf_cnpj_by_pronac(pronac)\n\n    proponent_submitted_projects = {}\n    proponent_analyzed_projects = {}\n\n    if cpf_cnpj:\n        submitted_projects = get_proponent_submitted_projects(cpf_cnpj)\n        analyzed_projects = get_proponent_analyzed_projects(cpf_cnpj)\n\n        try:\n            proponent_submitted_projects = {\n                'number_of_projects': submitted_projects['num_pronacs'],\n                'pronacs_of_this_proponent': submitted_projects['pronac_list']\n            }\n        except KeyError:\n            pass\n\n        try:\n            proponent_analyzed_projects = {\n                'number_of_projects': analyzed_projects['num_pronacs'],\n                'pronacs_of_this_proponent': analyzed_projects['pronac_list']\n            }\n        except KeyError:\n            pass\n\n    return {\n        'cpf_cnpj': cpf_cnpj,\n        'valor': len(proponent_submitted_projects),\n        'projetos_submetidos': proponent_submitted_projects,\n        'projetos_analizados': proponent_analyzed_projects,\n    }", "response": "Returns the CNPJ and CPF of the project containing the pronac of the project containing the pronac."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all projects that were analyzed.", "response": "def analyzed_projects(raw_df):\n    \"\"\"\n    Return all projects that was analyzed.\n    \"\"\"\n    df = raw_df[['PRONAC', 'proponenteCgcCpf']]\n\n    analyzed_projects = df.groupby('proponenteCgcCpf')[\n        'PRONAC'\n    ].agg(['unique', 'nunique'])\n\n    analyzed_projects.columns = ['pronac_list', 'num_pronacs']\n\n    return analyzed_projects"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning all projects submitted by the current user.", "response": "def submitted_projects(raw_df):\n    \"\"\"\n    Return all submitted projects.\n    \"\"\"\n    df = raw_df.astype({'PRONAC': str, 'CgcCpf': str})\n    submitted_projects = df.groupby('CgcCpf')[\n        'PRONAC'\n    ].agg(['unique', 'nunique'])\n\n    submitted_projects.columns = ['pronac_list', 'num_pronacs']\n\n    return submitted_projects"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a DataFrame from a. csv file stored in the data folder.", "response": "def read_csv(csv_name, usecols=None):\n    \"\"\"Returns a DataFrame from a .csv file stored in /data/raw/\"\"\"\n    csv_path = os.path.join(DATA_FOLDER, csv_name)\n    csv = pd.read_csv(csv_path, low_memory=False,\n                      usecols=usecols, encoding=\"utf-8\")\n    return csv"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_csv_with_different_type(csv_name, column_types_dict, usecols=None):\n    csv_path = os.path.join(DATA_FOLDER, csv_name)\n    csv = pd.read_csv(\n        csv_path,\n        usecols=usecols,\n        encoding=\"utf-8\",\n        dtype=column_types_dict,\n        engine=\"python\",\n    )\n\n    for key_column, val_type in column_types_dict.items():\n        if val_type == str:\n            csv[key_column] = csv[key_column].str.strip()\n\n    return csv", "response": "Reads a. csv file stored in the data folder and returns a DataFrame with the values of the same type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_csv_as_integer(csv_name, integer_columns, usecols=None):\n    csv_path = os.path.join(DATA_FOLDER, csv_name)\n    csv = pd.read_csv(csv_path, low_memory=False, usecols=usecols)\n    for column in integer_columns:\n        csv = csv[pd.to_numeric(csv[column], errors=\"coerce\").notnull()]\n    csv[integer_columns] = csv[integer_columns].apply(pd.to_numeric)\n    return csv", "response": "Returns a DataFrame from a. csv file stored in the data folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_receipts(pronac, dt):\n    df = verified_repeated_receipts_for_pronac(pronac)\n    comprovantes_cheque = df[df['tpFormaDePagamento'] == 1.0]\n\n    return metric_return(comprovantes_cheque)", "response": "Checks how many items in a same receipt are in a same payment type"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transfer_receipts(pronac, dt):\n    df = verified_repeated_receipts_for_pronac(pronac)\n    comprovantes_transferencia = df[df['tpFormaDePagamento'] == 2.0]\n\n    return metric_return(comprovantes_transferencia)", "response": "Returns the list of items that are in a same receipt when payment type is bank\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef money_receipts(pronac, dt):\n    df = verified_repeated_receipts_for_pronac(pronac)\n    comprovantes_saque = df[df['tpFormaDePagamento'] == 3.0]\n\n    return metric_return(comprovantes_saque)", "response": "Returns a metric of how many items in a same receipt are in a same order as the payment type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef segment_raised_funds_average(df):\n    grouped = df.groupby('Segmento')\n    aggregated = grouped.agg(['mean', 'std'])\n    aggregated.columns = aggregated.columns.droplevel(0)\n\n    return aggregated", "response": "Return some info about raised funds."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_outlier_info(pronac):\n    df = data.planilha_captacao\n    raised_funds_averages = data.segment_raised_funds_average.to_dict('index')\n\n    segment_id = df[df['Pronac'] == pronac]['Segmento'].iloc[0]\n\n    mean = raised_funds_averages[segment_id]['mean']\n    std = raised_funds_averages[segment_id]['std']\n\n    project_raised_funds = get_project_raised_funds(pronac)\n\n    outlier = gaussian_outlier.is_outlier(project_raised_funds, mean, std)\n\n    return (outlier, mean, std, project_raised_funds)", "response": "Return if a project with the given pronac is an outlier based on raised funds."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef csv_to_pickle(path=ROOT / \"raw\", clean=False):\n\n    for file in os.listdir(path):\n        base, ext = os.path.splitext(file)\n        if ext != \".csv\":\n            continue\n\n        LOG(f\"converting {file} to pickle\")\n        df = pd.read_csv(path / file, low_memory=True)\n        WRITE_DF(df, path / (base + \".\" + FILE_EXTENSION), **WRITE_DF_OPTS)\n        if clean:\n            os.remove(path / file)\n            LOG(f\"removed {file}\")", "response": "Convert all CSV files in path to pickle."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstore some arbitrary dataframe in the given location.", "response": "def store(self, loc, df):\n        \"\"\"Store dataframe in the given location.\n\n        Store some arbitrary dataframe:\n\n        >>> data.store('my_data', df)\n\n        Now recover it from the global store.\n        >>> data.my_data\n        ...\n        \"\"\"\n\n        path = \"%s.%s\" % (self._root / \"processed\" / loc, FILE_EXTENSION)\n        WRITE_DF(df, path, **WRITE_DF_OPTS)\n        self._cache[loc] = df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclosing all database sessions", "response": "def close_databases(self):\n        \"\"\" Close all database sessions \"\"\"\n        if self.gc_book:\n            self.gc_book.close()\n        if self.pricedb_session:\n            self.pricedb_session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_stock_quantity(self, symbol: str) -> Decimal(0):\n        book = self.get_gc_book()\n\n        collection = SecuritiesAggregate(book)\n        sec = collection.get_aggregate_for_symbol(symbol)\n        quantity = sec.get_quantity()\n        return quantity", "response": "loads stock quantity for a symbol"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_gc_book(self):\n        if not self.gc_book:\n            gc_db = self.config.get(ConfigKeys.gnucash_book_path)\n            if not gc_db:\n                raise AttributeError(\"GnuCash book path not configured.\")\n            # check if this is the abs file exists\n            if not os.path.isabs(gc_db):\n                gc_db = resource_filename(\n                    Requirement.parse(\"Asset-Allocation\"), gc_db)\n                if not os.path.exists(gc_db):\n                    raise ValueError(f\"Invalid GnuCash book path {gc_db}\")\n\n            self.gc_book = open_book(gc_db, open_if_lock=True)\n        return self.gc_book", "response": "Returns the GnuCash db session"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all the symbols with positive balances", "response": "def get_symbols_with_positive_balances(self) -> List[str]:\n        \"\"\" Identifies all the securities with positive balances \"\"\"\n        from gnucash_portfolio import BookAggregate\n\n        holdings = []\n\n        with BookAggregate() as book:\n            # query = book.securities.query.filter(Commodity.)\n            holding_entities = book.securities.get_all()\n            for item in holding_entities:\n                # Check holding balance\n                agg = book.securities.get_aggregate(item)\n                balance = agg.get_num_shares()\n                if balance > Decimal(0):\n                    holdings.append(f\"{item.namespace}:{item.mnemonic}\")\n                else:\n                    self.logger.debug(f\"0 balance for {item}\")\n            # holdings = map(lambda x: , holding_entities)\n\n        return holdings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprovides initialization and access to module - level session", "response": "def __get_pricedb_session(self):\n        \"\"\" Provides initialization and access to module-level session \"\"\"\n        from pricedb import dal\n\n        if not self.pricedb_session:\n            self.pricedb_session = dal.get_default_session()\n        return self.pricedb_session"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(assetclass: int, symbol: str):\n    assert isinstance(symbol, str)\n    assert isinstance(assetclass, int)\n\n    symbol = symbol.upper()\n    app = AppAggregate()\n    new_item = app.add_stock_to_class(assetclass, symbol)\n    print(f\"Record added: {new_item}.\")", "response": "Add a stock to an asset class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the view - friendly output of the aa model", "response": "def format(self, model: AssetAllocationModel, full: bool = False):\n        \"\"\" Returns the view-friendly output of the aa model \"\"\"\n        self.full = full\n\n        # Header\n        output = f\"Asset Allocation model, total: {model.currency} {model.total_amount:,.2f}\\n\"\n\n        # Column Headers\n        for column in self.columns:\n            name = column['name']\n            if not self.full and name == \"loc.cur.\":\n                # Skip local currency if not displaying stocks.\n                continue\n            width = column[\"width\"]\n            output += f\"{name:^{width}}\"\n        output += \"\\n\"\n        output += f\"-------------------------------------------------------------------------------\\n\"\n\n        # Asset classes\n\n        view_model = ModelMapper(model).map_to_linear(self.full)\n        for row in view_model:\n            output += self.__format_row(row) + \"\\n\"\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __format_row(self, row: AssetAllocationViewModel):\n        output = \"\"\n        index = 0\n\n        # Name\n        value = row.name\n        # Indent according to depth.\n        for _ in range(0, row.depth):\n            value = f\"   {value}\"\n        output += self.append_text_column(value, index)\n\n        # Set Allocation\n        value = \"\"\n        index += 1\n        if row.set_allocation > 0:\n            value = f\"{row.set_allocation:.2f}\"\n        output += self.append_num_column(value, index)\n\n        # Current Allocation\n        value = \"\"\n        index += 1\n        if row.curr_allocation > Decimal(0):\n            value = f\"{row.curr_allocation:.2f}\"\n        output += self.append_num_column(value, index)\n\n        # Allocation difference, percentage\n        value = \"\"\n        index += 1\n        if row.alloc_diff_perc.copy_abs() > Decimal(0):\n            value = f\"{row.alloc_diff_perc:.0f} %\"\n        output += self.append_num_column(value, index)\n\n        # Allocated value\n        index += 1\n        value = \"\"\n        if row.set_value:\n            value = f\"{row.set_value:,.0f}\"\n        output += self.append_num_column(value, index)\n\n        # Current Value\n        index += 1\n        value = f\"{row.curr_value:,.0f}\"\n        output += self.append_num_column(value, index)\n\n        # Value in security's currency. Show only if displaying full model, with stocks.\n        index += 1\n        if self.full:\n            value = \"\"\n            if row.curr_value_own_currency:\n                value = f\"({row.curr_value_own_currency:,.0f}\"\n                value += f\" {row.own_currency}\"\n                value += \")\"\n            output += self.append_num_column(value, index)\n\n        # https://en.wikipedia.org/wiki/ANSI_escape_code\n        # CSI=\"\\x1B[\"\n        # red = 31, green = 32\n        # output += CSI+\"31;40m\" + \"Colored Text\" + CSI + \"0m\"\n\n        # Value diff\n        index += 1\n        value = \"\"\n        if row.diff_value:\n            value = f\"{row.diff_value:,.0f}\"\n            # Color the output\n            # value = f\"{CSI};40m{value}{CSI};40m\"\n        output += self.append_num_column(value, index)\n\n        return output", "response": "Format one row of Asset Class record"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds value to the output row based on index", "response": "def append_num_column(self, text: str, index: int):\n        \"\"\" Add value to the output row, width based on index \"\"\"\n        width = self.columns[index][\"width\"]\n        return f\"{text:>{width}}\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append_text_column(self, text: str, index: int):\n        width = self.columns[index][\"width\"]\n        return f\"{text:<{width}}\"", "response": "Append text to the output row based on index"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmap data from entity to object", "response": "def map_entity(self, entity: dal.AssetClass):\n        \"\"\" maps data from entity -> object \"\"\"\n        obj = model.AssetClass()\n\n        obj.id = entity.id\n        obj.parent_id = entity.parentid\n        obj.name = entity.name\n        obj.allocation = entity.allocation\n        obj.sort_order = entity.sortorder\n        #entity.stock_links\n        #entity.diff_adjustment\n        if entity.parentid == None:\n            obj.depth = 0\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps the tree to a linear representation suitable for display", "response": "def map_to_linear(self, with_stocks: bool=False):\n        \"\"\" Maps the tree to a linear representation suitable for display \"\"\"\n        result = []\n\n        for ac in self.model.classes:\n            rows = self.__get_ac_tree(ac, with_stocks)\n            result += rows\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat the ac tree - entity with child elements", "response": "def __get_ac_tree(self, ac: model.AssetClass, with_stocks: bool):\n        \"\"\" formats the ac tree - entity with child elements \"\"\"\n        output = []\n        output.append(self.__get_ac_row(ac))\n\n        for child in ac.classes:\n            output += self.__get_ac_tree(child, with_stocks)\n\n        if with_stocks:\n            for stock in ac.stocks:\n                row = None\n                if isinstance(stock, Stock):\n                    row = self.__get_stock_row(stock, ac.depth + 1)\n                elif isinstance(stock, CashBalance):\n                    row = self.__get_cash_row(stock, ac.depth + 1)\n                output.append(row)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the Asset Class record for the given Asset Class", "response": "def __get_ac_row(self, ac: model.AssetClass) -> AssetAllocationViewModel:\n        \"\"\" Formats one Asset Class record \"\"\"\n        view_model = AssetAllocationViewModel()\n\n        view_model.depth = ac.depth\n        \n        # Name\n        view_model.name = ac.name\n\n        view_model.set_allocation = ac.allocation\n        view_model.curr_allocation = ac.curr_alloc\n        view_model.diff_allocation = ac.alloc_diff\n        view_model.alloc_diff_perc = ac.alloc_diff_perc\n\n        # value\n        view_model.curr_value = ac.curr_value\n        # expected value\n        view_model.set_value = ac.alloc_value\n        # diff\n        view_model.diff_value = ac.value_diff\n\n        return view_model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a stock link to an asset class", "response": "def add_stock_to_class(self, assetclass_id: int, symbol: str):\n        \"\"\" Add a stock link to an asset class \"\"\"\n        assert isinstance(symbol, str)\n        assert isinstance(assetclass_id, int)\n\n        item = AssetClassStock()\n        item.assetclassid = assetclass_id\n        item.symbol = symbol\n\n        session = self.open_session()\n        session.add(item)\n        self.save()\n\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, id: int):\n        assert isinstance(id, int)\n\n        self.open_session()\n        to_delete = self.get(id)\n        self.session.delete(to_delete)\n        self.save()", "response": "Delete an asset class by id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_unallocated_holdings(self):\n        # Get linked securities\n        session = self.open_session()\n        linked_entities = session.query(AssetClassStock).all()\n        linked = []\n        # linked = map(lambda x: f\"{x.symbol}\", linked_entities)\n        for item in linked_entities:\n            linked.append(item.symbol)\n\n        # Get all securities with balance > 0.\n        from .stocks import StocksInfo\n\n        stocks = StocksInfo()\n        stocks.logger = self.logger\n        holdings = stocks.get_symbols_with_positive_balances()\n\n        # Find those which are not included in the stock links.\n        non_alloc = []\n        index = -1\n        for item in holdings:\n            try:\n                index = linked.index(item)\n                self.logger.debug(index)\n            except ValueError:\n                non_alloc.append(item)\n\n        return non_alloc", "response": "Finds unallocated holdings in the stock links."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, id: int) -> AssetClass:\n        self.open_session()\n        item = self.session.query(AssetClass).filter(\n            AssetClass.id == id).first()\n        return item", "response": "Loads Asset Class by ID"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen a db session and returns it", "response": "def open_session(self):\n        \"\"\" Opens a db session and returns it \"\"\"\n        from .dal import get_session\n\n        cfg = Config()\n        cfg.logger = self.logger\n        db_path = cfg.get(ConfigKeys.asset_allocation_database_path)\n\n        self.session = get_session(db_path)\n        return self.session"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates and populates the Asset Allocation model.", "response": "def get_asset_allocation(self):\n        \"\"\" Creates and populates the Asset Allocation model. The main function of the app. \"\"\"\n        # load from db\n        # TODO set the base currency\n        base_currency = \"EUR\"\n\n        loader = AssetAllocationLoader(base_currency=base_currency)\n        loader.logger = self.logger\n        model = loader.load_tree_from_db()\n\n        model.validate()\n\n        # securities\n        # read stock links\n        loader.load_stock_links()\n        # read stock quantities from GnuCash\n        loader.load_stock_quantity()\n        # Load cash balances\n        loader.load_cash_balances()\n        # loader.session\n        # read prices from Prices database\n        loader.load_stock_prices()\n        # recalculate stock values into base currency\n        loader.recalculate_stock_values_into_base()\n        # calculate\n        model.calculate_current_value()\n        model.calculate_set_values()\n        model.calculate_current_allocation()\n\n        # return the model for display\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_asset_classes_for_security(self, namespace: str, symbol: str) -> List[AssetClass]:\n        full_symbol = symbol\n        if namespace:\n            full_symbol = f\"{namespace}:{symbol}\"\n\n        result = (\n            self.session.query(AssetClassStock)\n            .filter(AssetClassStock.symbol == full_symbol)\n            .all()\n        )\n        return result", "response": "Get all asset classes for the security symbol."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexporting all used symbols to a text file.", "response": "def export_symbols(self):\n        \"\"\" Exports all used symbols \"\"\"\n        session = self.open_session()\n        links = session.query(AssetClassStock).order_by(\n            AssetClassStock.symbol).all()\n        output = []\n        for link in links:\n            output.append(link.symbol + '\\n')\n\n        # Save output to a text file.\n        with open(\"symbols.txt\", mode='w') as file:\n            file.writelines(output)\n\n        print(\"Symbols exported to symbols.txt\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __read_config(self, file_path: str):\n        if not os.path.exists(file_path):\n            raise FileNotFoundError(\"File path not found: %s\", file_path)\n        # check if file exists\n        if not os.path.isfile(file_path):\n            log(ERROR, \"file not found: %s\", file_path)\n            raise FileNotFoundError(\"configuration file not found %s\", file_path)\n\n        self.config.read(file_path)", "response": "Read the config file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy the config template into user s directory", "response": "def __create_user_config(self):\n        \"\"\" Copy the config template into user's directory \"\"\"\n        src_path = self.__get_config_template_path()\n        src = os.path.abspath(src_path)\n        if not os.path.exists(src):\n            log(ERROR, \"Config template not found %s\", src)\n            raise FileNotFoundError()\n\n        dst = os.path.abspath(self.get_config_path())\n\n        shutil.copyfile(src, dst)\n\n        if not os.path.exists(dst):\n            raise FileNotFoundError(\"Config file could not be copied to user dir!\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(aadb, cur):\n    cfg = Config()\n    edited = False\n\n    if aadb:\n        cfg.set(ConfigKeys.asset_allocation_database_path, aadb)\n        print(f\"The database has been set to {aadb}.\")\n        edited = True\n    \n    if cur:\n        cfg.set(ConfigKeys.default_currency, cur)\n        edited = True\n\n    if edited:\n        print(f\"Changes saved.\")\n    else:\n        print(f\"No changes were made.\")\n        print(f\"Use --help parameter for more information.\")", "response": "Sets the values in the config file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a value from config", "response": "def get(aadb: str):\n    \"\"\" Retrieves a value from config \"\"\"\n    if (aadb):\n        cfg = Config()\n        value = cfg.get(ConfigKeys.asset_allocation_database_path)\n        click.echo(value)\n    \n    if not aadb:\n        click.echo(\"Use --help for more information.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fullname(self):\n        prefix = \"\"\n        if self.parent:\n            if self.parent.fullname:\n                prefix = self.parent.fullname + \":\"\n        else:\n            # Only the root does not have a parent. In that case we also don't need a name.\n            return \"\"\n\n        return prefix + self.name", "response": "includes the full path with parent names"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the value of the holdings in exchange currency.", "response": "def value(self) -> Decimal:\n        \"\"\"\n        Value of the holdings in exchange currency.\n        Value = Quantity * Price\n        \"\"\"\n        assert isinstance(self.price, Decimal)\n        \n        return self.quantity * self.price"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef asset_class(self) -> str:\n        result = self.parent.name if self.parent else \"\"\n        # Iterate to the top asset class and add names.\n        cursor = self.parent\n        while cursor:\n            result = cursor.name + \":\" + result\n            cursor = cursor.parent\n        return result", "response": "Returns the full asset class path for this stock."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the asset class with the given id.", "response": "def get_class_by_id(self, ac_id: int) -> AssetClass:\n        \"\"\" Finds the asset class by id \"\"\"\n        assert isinstance(ac_id, int)\n\n        # iterate recursively\n        for ac in self.asset_classes:\n            if ac.id == ac_id:\n                return ac\n        # if nothing returned so far.\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the cash asset class.", "response": "def get_cash_asset_class(self) -> AssetClass:\n        \"\"\" Find the cash asset class by name. \"\"\"\n        for ac in self.asset_classes:\n            if ac.name.lower() == \"cash\":\n                return ac\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate(self) -> bool:\n        # Asset class allocation should match the sum of children's allocations.\n        # Each group should be compared.\n        sum = Decimal(0)\n\n        # Go through each asset class, not just the top level.\n        for ac in self.asset_classes:\n            if ac.classes:\n                # get the sum of all the children's allocations\n                child_alloc_sum = ac.child_allocation\n                # compare to set allocation\n                if ac.allocation != child_alloc_sum:\n                    message = f\"The sum of child allocations {child_alloc_sum:.2f} invalid for {ac}!\"\n                    self.logger.warning(message)\n                    print(message)\n                    return False\n\n        # also make sure that the sum of 1st level children matches 100\n        for ac in self.classes:\n            sum += ac.allocation\n        if sum != Decimal(100):\n            message = f\"The sum of all allocations ({sum:.2f}) does not equal 100!\"\n            self.logger.warning(message)\n            print(message)\n            return False\n\n        return True", "response": "Validate that the values match. Incomplete!"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calculate_set_values(self):\n        for ac in self.asset_classes:\n            ac.alloc_value = self.total_amount * ac.allocation / Decimal(100)", "response": "Calculates the expected totals based on set allocations"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the current allocation percent based on the value", "response": "def calculate_current_allocation(self):\n        \"\"\" Calculates the current allocation % based on the value \"\"\"\n        for ac in self.asset_classes:\n            ac.curr_alloc = ac.curr_value * 100 / self.total_amount"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding all the stock values and assign to the asset classes", "response": "def calculate_current_value(self):\n        \"\"\" Add all the stock values and assign to the asset classes \"\"\"\n        # must be recursive\n        total = Decimal(0)\n        for ac in self.classes:\n            self.__calculate_current_value(ac)\n            total += ac.curr_value\n        self.total_amount = total"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __calculate_current_value(self, asset_class: AssetClass):\n        # Is this the final asset class, the one with stocks?\n        if asset_class.stocks:\n            # add all the stocks\n            stocks_sum = Decimal(0)\n            for stock in asset_class.stocks:\n                # recalculate into base currency!\n                stocks_sum += stock.value_in_base_currency\n\n            asset_class.curr_value = stocks_sum\n\n        if asset_class.classes:\n            # load totals for child classes\n            for child in asset_class.classes:\n                self.__calculate_current_value(child)\n                asset_class.curr_value += child.curr_value", "response": "Calculate the current value of the asset class by adding all the children values"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_currency(self, mnemonic: str):\n        # , base_currency: str <= ignored for now.\n        if self.rate and self.rate.currency == mnemonic:\n            # Already loaded.\n            return\n\n        app = PriceDbApplication()\n        # TODO use the base_currency parameter for the query #33\n        symbol = SecuritySymbol(\"CURRENCY\", mnemonic)\n        self.rate = app.get_latest_price(symbol)\n        if not self.rate:\n            raise ValueError(f\"No rate found for {mnemonic}!\")", "response": "load the latest rate for the given mnemonic"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show(format, full):\n    # load asset allocation\n    app = AppAggregate()\n    app.logger = logger\n    model = app.get_asset_allocation()\n\n    if format == \"ascii\":\n        formatter = AsciiFormatter()\n    elif format == \"html\":\n        formatter = HtmlFormatter\n    else:\n        raise ValueError(f\"Unknown formatter {format}\")\n\n    # formatters can display stock information with --full\n    output = formatter.format(model, full=full)\n    print(output)", "response": "Print current allocation to the console."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload cash balances from GnuCash book and recalculates into the default currency", "response": "def load_cash_balances(self):\n        \"\"\" Loads cash balances from GnuCash book and recalculates into the default currency \"\"\"\n        from gnucash_portfolio.accounts import AccountsAggregate, AccountAggregate\n\n        cfg = self.__get_config()\n        cash_root_name = cfg.get(ConfigKeys.cash_root)\n        # Load cash from all accounts under the root.\n        gc_db = self.config.get(ConfigKeys.gnucash_book_path)\n        with open_book(gc_db, open_if_lock=True) as book:\n            svc = AccountsAggregate(book)\n            root_account = svc.get_by_fullname(cash_root_name)\n            acct_svc = AccountAggregate(book, root_account)\n            cash_balances = acct_svc.load_cash_balances_with_children(cash_root_name)\n\n        # Treat each sum per currency as a Stock, for display in full mode.\n        self.__store_cash_balances_per_currency(cash_balances)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __store_cash_balances_per_currency(self, cash_balances):\n        cash = self.model.get_cash_asset_class()\n\n        for cur_symbol in cash_balances:\n            item = CashBalance(cur_symbol)\n            item.parent = cash\n            \n            quantity = cash_balances[cur_symbol][\"total\"]\n            item.value = Decimal(quantity)\n            item.currency = cur_symbol\n\n            # self.logger.debug(f\"adding {item}\")\n            cash.stocks.append(item)\n            self.model.stocks.append(item)", "response": "Store balance per currency as Stock records under Cash class"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_tree_from_db(self) -> AssetAllocationModel:\n        self.model = AssetAllocationModel()\n\n        # currency\n        self.model.currency = self.__get_config().get(ConfigKeys.default_currency)\n\n        # Asset Classes\n        db = self.__get_session()\n        first_level = (\n            db.query(dal.AssetClass)\n            .filter(dal.AssetClass.parentid == None)\n            .order_by(dal.AssetClass.sortorder)\n            .all()\n        )\n\n        # create tree\n        for entity in first_level:\n            ac = self.__map_entity(entity)\n            self.model.classes.append(ac)\n            # Add to index\n            self.model.asset_classes.append(ac)\n\n            # append child classes recursively\n            self.__load_child_classes(ac)\n\n        return self.model", "response": "Reads the asset allocation data only and creates the AA tree"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload stock links into the model", "response": "def load_stock_links(self):\n        \"\"\" Read stock links into the model \"\"\"\n        links = self.__get_session().query(dal.AssetClassStock).all()\n        for entity in links:\n            # log(DEBUG, f\"adding {entity.symbol} to {entity.assetclassid}\")\n            # mapping\n            stock: Stock = Stock(entity.symbol)\n            # find parent classes by id and assign children\n            parent: AssetClass = self.model.get_class_by_id(entity.assetclassid)\n            if parent:\n                # Assign to parent.\n                parent.stocks.append(stock)\n                # Add to index for easy reference\n                self.model.stocks.append(stock)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload stock quantity for all stocks", "response": "def load_stock_quantity(self):\n        \"\"\" Loads quantities for all stocks \"\"\"\n        info = StocksInfo(self.config)\n        for stock in self.model.stocks:\n            stock.quantity = info.load_stock_quantity(stock.symbol)\n        info.gc_book.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads latest prices for securities", "response": "def load_stock_prices(self):\n        \"\"\" Load latest prices for securities \"\"\"\n        from pricedb import SecuritySymbol\n\n        info = StocksInfo(self.config)\n        for item in self.model.stocks:\n            symbol = SecuritySymbol(\"\", \"\")\n            symbol.parse(item.symbol)\n\n            price: PriceModel = info.load_latest_price(symbol)\n            if not price:\n                # Use a dummy price of 1, effectively keeping the original amount.\n                price = PriceModel()\n                price.currency = self.config.get(ConfigKeys.default_currency)\n                price.value = Decimal(1)\n            item.price = price.value\n            if isinstance(item, Stock):\n                item.currency = price.currency\n                # Do not set currency for Cash balance records.\n        info.close_databases()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recalculate_stock_values_into_base(self):\n        from .currency import CurrencyConverter\n\n        conv = CurrencyConverter()\n        cash = self.model.get_cash_asset_class()\n\n        for stock in self.model.stocks:\n            if stock.currency != self.base_currency:\n                # Recalculate into base currency\n                conv.load_currency(stock.currency)\n                assert isinstance(stock.value, Decimal)\n                val_base = stock.value * conv.rate.value\n            else:\n                # Already in base currency.\n                val_base = stock.value\n\n            stock.value_in_base_currency = val_base", "response": "Load the exchange rates and recalculates stock holding values into base currency"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading child classes for an asset class", "response": "def __load_child_classes(self, ac: AssetClass):\n        \"\"\" Loads child classes/stocks \"\"\"\n        # load child classes for ac\n        db = self.__get_session()\n        entities = (\n            db.query(dal.AssetClass)\n            .filter(dal.AssetClass.parentid == ac.id)\n            .order_by(dal.AssetClass.sortorder)\n            .all()\n        )\n        # map\n        for entity in entities:\n            child_ac = self.__map_entity(entity)\n            # depth\n            child_ac.depth = ac.depth + 1\n            ac.classes.append(child_ac)\n            # Add to index\n            self.model.asset_classes.append(child_ac)\n\n            self.__load_child_classes(child_ac)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmapping the entity onto the model object", "response": "def __map_entity(self, entity: dal.AssetClass) -> AssetClass:\n        \"\"\" maps the entity onto the model object \"\"\"\n        mapper = self.__get_mapper()\n        ac = mapper.map_entity(entity)\n        return ac"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __get_session(self):\n        db_path = self.__get_config().get(ConfigKeys.asset_allocation_database_path)\n        self.session = dal.get_session(db_path)\n        return self.session", "response": "Opens a db session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload Asset Class entity", "response": "def __load_asset_class(self, ac_id: int):\n        \"\"\" Loads Asset Class entity \"\"\"\n        # open database\n        db = self.__get_session()\n        entity = db.query(dal.AssetClass).filter(dal.AssetClass.id == ac_id).first()\n        return entity"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and opens a database session", "response": "def get_session(db_path: str):\n    \"\"\" Creates and opens a database session \"\"\"\n    # cfg = Config()\n    # db_path = cfg.get(ConfigKeys.asset_allocation_database_path)\n\n    # connection\n    con_str = \"sqlite:///\" + db_path\n    # Display all SQLite info with echo.\n    engine = create_engine(con_str, echo=False)\n\n    # create metadata (?)\n    Base.metadata.create_all(engine)\n\n    # create session\n    Session = sessionmaker(bind=engine)\n    session = Session()\n\n    return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(name):\n    item = AssetClass()\n    item.name = name\n    app = AppAggregate()\n    app.create_asset_class(item)\n\n    print(f\"Asset class {name} created.\")", "response": "Add new Asset Class"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nedit an asset class.", "response": "def edit(id: int, parent: int, alloc: Decimal):\n    \"\"\" Edit asset class \"\"\"\n    saved = False\n\n    # load\n    app = AppAggregate()\n    item = app.get(id)\n    if not item:\n        raise KeyError(\"Asset Class with id %s not found.\", id)\n\n    if parent:\n        assert parent != id, \"Parent can not be set to self.\"\n\n        # TODO check if parent exists?\n\n        item.parentid = parent\n        saved = True\n        # click.echo(f\"parent set to {parent}\")\n\n    if alloc:\n        assert alloc != Decimal(0)\n\n        item.allocation = alloc\n        saved = True\n\n    app.save()\n    if saved:\n        click.echo(\"Data saved.\")\n    else:\n        click.echo(\"No data modified. Use --help to see possible parameters.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all asset classes", "response": "def my_list():\n    \"\"\" Lists all asset classes \"\"\"\n    session = AppAggregate().open_session()\n    classes = session.query(AssetClass).all()\n    for item in classes:\n        print(item)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef my_import(file):\n    # , help=\"The path to the CSV file to import. The first row must contain column names.\"\n    lines = None\n    with open(file) as csv_file:\n        lines = csv_file.readlines()\n\n    # Header, the first line.\n    header = lines[0]\n    lines.remove(header)\n    header = header.rstrip()\n\n    # Parse records from a csv row.\n    counter = 0\n    app = AppAggregate()\n    app.open_session()\n    for line in lines:\n        # Create insert statements\n        line = line.rstrip()\n        command = f\"insert into AssetClass ({header}) values ({line});\"\n        # insert records\n        app.session.execute(command)\n        try:\n            app.save()\n        except:\n            print(f\"error: \", sys.exc_info()[0])\n            app.session.close()\n        counter += 1\n    print(f\"Data imported. {counter} rows created.\")", "response": "Import Asset Classes from a. csv file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisplay a tree of asset classes", "response": "def tree():\n    \"\"\" Display a tree of asset classes \"\"\"\n    session = AppAggregate().open_session()\n    classes = session.query(AssetClass).all()\n    # Get the root classes\n    root = []\n    for ac in classes:\n        if ac.parentid is None:\n            root.append(ac)\n        # logger.debug(ac.parentid)\n    # header\n    print_row(\"id\", \"asset class\", \"allocation\", \"level\")\n    print(f\"-------------------------------\")\n\n    for ac in root:\n        print_item_with_children(ac, classes, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_item_with_children(ac, classes, level):\n    print_row(ac.id, ac.name, f\"{ac.allocation:,.2f}\", level)\n    print_children_recursively(classes, ac, level + 1)", "response": "Print the given item and all children items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint asset classes recursively", "response": "def print_children_recursively(all_items, for_item, level):\n    \"\"\" Print asset classes recursively \"\"\"\n    children = [child for child in all_items if child.parentid == for_item.id]\n    for child in children:\n        #message = f\"{for_item.name}({for_item.id}) is a parent to {child.name}({child.id})\"\n        indent = \" \" * level * 2\n        id_col = f\"{indent} {child.id}\"\n        print_row(id_col, child.name, f\"{child.allocation:,.2f}\", level)\n\n        # Process children.\n        print_children_recursively(all_items, child, level+1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_row(*argv):\n    #for i in range(0, len(argv)):\n        # row += f\"{argv[i]}\"\n    # columns\n    row = \"\"\n    # id\n    row += f\"{argv[0]:<3}\"\n    # name\n    row += f\" {argv[1]:<13}\"\n    # allocation\n    row += f\" {argv[2]:>5}\"\n    # level\n    #row += f\"{argv[3]}\"\n\n    print(row)", "response": "Print one row of data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_html(input_text, **context):\n    global g_parser\n    if g_parser is None:\n        g_parser = Parser()\n    return g_parser.format(input_text, **context)", "response": "A helper method that creates a default bbcode parser and renders the input string as HTML."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a render function to the set of recognized tags.", "response": "def add_formatter(self, tag_name, render_func, **kwargs):\n        \"\"\"\n        Installs a render function for the specified tag name. The render function\n        should have the following signature:\n\n            def render(tag_name, value, options, parent, context)\n\n        The arguments are as follows:\n\n            tag_name\n                The name of the tag being rendered.\n            value\n                The context between start and end tags, or None for standalone tags.\n                Whether this has been rendered depends on render_embedded tag option.\n            options\n                A dictionary of options specified on the opening tag.\n            parent\n                The parent TagOptions, if the tag is being rendered inside another tag,\n                otherwise None.\n            context\n                The keyword argument dictionary passed into the format call.\n        \"\"\"\n        options = TagOptions(tag_name.strip().lower(), **kwargs)\n        self.recognized_tags[options.tag_name] = (render_func, options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a formatter that takes a format dictionary puts a value in it and uses it as a format string.", "response": "def add_simple_formatter(self, tag_name, format_string, **kwargs):\n        \"\"\"\n        Installs a formatter that takes the tag options dictionary, puts a value key\n        in it, and uses it as a format dictionary to the given format string.\n        \"\"\"\n        def _render(name, value, options, parent, context):\n            fmt = {}\n            if options:\n                fmt.update(options)\n            fmt.update({'value': value})\n            return format_string % fmt\n        self.add_formatter(tag_name, _render, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_default_formatters(self):\n        self.add_simple_formatter('b', '<strong>%(value)s</strong>')\n        self.add_simple_formatter('i', '<em>%(value)s</em>')\n        self.add_simple_formatter('u', '<u>%(value)s</u>')\n        self.add_simple_formatter('s', '<strike>%(value)s</strike>')\n        self.add_simple_formatter('hr', '<hr />', standalone=True)\n        self.add_simple_formatter('sub', '<sub>%(value)s</sub>')\n        self.add_simple_formatter('sup', '<sup>%(value)s</sup>')\n\n        def _render_list(name, value, options, parent, context):\n            list_type = options['list'] if (options and 'list' in options) else '*'\n            css_opts = {\n                '1': 'decimal', '01': 'decimal-leading-zero',\n                'a': 'lower-alpha', 'A': 'upper-alpha',\n                'i': 'lower-roman', 'I': 'upper-roman',\n            }\n            tag = 'ol' if list_type in css_opts else 'ul'\n            css = ' style=\"list-style-type:%s;\"' % css_opts[list_type] if list_type in css_opts else ''\n            return '<%s%s>%s</%s>' % (tag, css, value, tag)\n        self.add_formatter('list', _render_list, transform_newlines=False, strip=True, swallow_trailing_newline=True)\n\n        # Make sure transform_newlines = False for [*], so [code] tags can be embedded without transformation.\n        def _render_list_item(name, value, options, parent, context):\n            if not parent or parent.tag_name != 'list':\n                return '[*]%s<br />' % value\n\n            return '<li>%s</li>' % value\n        self.add_formatter('*', _render_list_item, newline_closes=True, transform_newlines=False,\n            same_tag_closes=True, strip=True)\n\n        self.add_simple_formatter('quote', '<blockquote>%(value)s</blockquote>', strip=True,\n            swallow_trailing_newline=True)\n        self.add_simple_formatter('code', '<code>%(value)s</code>', render_embedded=False, transform_newlines=False,\n            swallow_trailing_newline=True, replace_cosmetic=False)\n        self.add_simple_formatter('center', '<div style=\"text-align:center;\">%(value)s</div>')\n\n        def _render_color(name, value, options, parent, context):\n            if 'color' in options:\n                color = options['color'].strip()\n            elif options:\n                color = list(options.keys())[0].strip()\n            else:\n                return value\n            match = re.match(r'^([a-z]+)|^(#[a-f0-9]{3,6})', color, re.I)\n            color = match.group() if match else 'inherit'\n            return '<span style=\"color:%(color)s;\">%(value)s</span>' % {\n                'color': color,\n                'value': value,\n            }\n        self.add_formatter('color', _render_color)\n\n        def _render_url(name, value, options, parent, context):\n            if options and 'url' in options:\n                # Option values are not escaped for HTML output.\n                href = self._replace(options['url'], self.REPLACE_ESCAPE)\n            else:\n                href = value\n            # Completely ignore javascript: and data: \"links\".\n            if re.sub(r'[^a-z0-9+]', '', href.lower().split(':', 1)[0]) in ('javascript', 'data', 'vbscript'):\n                return ''\n            # Only add the missing http:// if it looks like it starts with a domain name.\n            if '://' not in href and _domain_re.match(href):\n                href = 'http://' + href\n            return self.url_template.format(href=href.replace('\"', '%22'), text=value)\n        self.add_formatter('url', _render_url, replace_links=False, replace_cosmetic=False)", "response": "Installs default formatters for the tags of the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _replace(self, data, replacements):\n        for find, repl in replacements:\n            data = data.replace(find, repl)\n        return data", "response": "This function replaces all the keys in the input string with the values in the given list of replacements."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _newline_tokenize(self, data):\n        parts = data.split('\\n')\n        tokens = []\n        for num, part in enumerate(parts):\n            if part:\n                tokens.append((self.TOKEN_DATA, None, None, part))\n            if num < (len(parts) - 1):\n                tokens.append((self.TOKEN_NEWLINE, None, None, '\\n'))\n        return tokens", "response": "This function will return a list of NEWLINE and DATA tokens such that if you concatenate the data with the original string you will have the original string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a tag string, this function will parse any options out of it and return a tuple of (tag_name, options_dict). Options may be quoted in order to preserve spaces, and free-standing options are allowed. The tag name itself may also serve as an option if it is immediately followed by an equal sign. Here are some examples: quote author=\"Dan Watson\" tag_name=quote, options={'author': 'Dan Watson'} url=\"http://test.com/s.php?a=bcd efg\" popup tag_name=url, options={'url': 'http://test.com/s.php?a=bcd efg', 'popup': ''}", "response": "def _parse_opts(self, data):\n        \"\"\"\n        Given a tag string, this function will parse any options out of it and\n        return a tuple of (tag_name, options_dict). Options may be quoted in order\n        to preserve spaces, and free-standing options are allowed. The tag name\n        itself may also serve as an option if it is immediately followed by an equal\n        sign. Here are some examples:\n            quote author=\"Dan Watson\"\n                tag_name=quote, options={'author': 'Dan Watson'}\n            url=\"http://test.com/s.php?a=bcd efg\" popup\n                tag_name=url, options={'url': 'http://test.com/s.php?a=bcd efg', 'popup': ''}\n        \"\"\"\n        name = None\n        try:\n            # OrderedDict is only available for 2.7+, so leave regular unsorted dicts as a fallback.\n            from collections import OrderedDict\n            opts = OrderedDict()\n        except ImportError:\n            opts = {}\n        in_value = False\n        in_quote = False\n        attr = ''\n        value = ''\n        attr_done = False\n        stripped = data.strip()\n        ls = len(stripped)\n        pos = 0\n\n        while pos < ls:\n            ch = stripped[pos]\n            if in_value:\n                if in_quote:\n                    if ch == '\\\\' and ls > pos + 1 and stripped[pos + 1] in ('\\\\', '\"', \"'\"):\n                        value += stripped[pos + 1]\n                        pos += 1\n                    elif ch == in_quote:\n                        in_quote = False\n                        in_value = False\n                        if attr:\n                            opts[attr.lower()] = value.strip()\n                        attr = ''\n                        value = ''\n                    else:\n                        value += ch\n                else:\n                    if ch in ('\"', \"'\"):\n                        in_quote = ch\n                    elif ch == ' ' and data.find('=', pos + 1) > 0:\n                        # If there is no = after this, the value may accept spaces.\n                        opts[attr.lower()] = value.strip()\n                        attr = ''\n                        value = ''\n                        in_value = False\n                    else:\n                        value += ch\n            else:\n                if ch == '=':\n                    in_value = True\n                    if name is None:\n                        name = attr\n                elif ch == ' ':\n                    attr_done = True\n                else:\n                    if attr_done:\n                        if attr:\n                            if name is None:\n                                name = attr\n                            else:\n                                opts[attr.lower()] = ''\n                        attr = ''\n                        attr_done = False\n                    attr += ch\n            pos += 1\n\n        if attr:\n            if name is None:\n                name = attr\n            opts[attr.lower()] = value.strip()\n        return name.lower(), opts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_tag(self, tag):\n        if not tag.startswith(self.tag_opener) or not tag.endswith(self.tag_closer) or ('\\n' in tag) or ('\\r' in tag):\n            return (False, tag, False, None)\n        tag_name = tag[len(self.tag_opener):-len(self.tag_closer)].strip()\n        if not tag_name:\n            return (False, tag, False, None)\n        closer = False\n        opts = {}\n        if tag_name[0] == '/':\n            tag_name = tag_name[1:]\n            closer = True\n        # Parse options inside the opening tag, if needed.\n        if (('=' in tag_name) or (' ' in tag_name)) and not closer:\n            tag_name, opts = self._parse_opts(tag_name)\n        return (True, tag_name.strip().lower(), closer, opts)", "response": "This function will parse a tag string and return a tuple of the form valid tag_name closer options"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the extent of a tag in the data.", "response": "def _tag_extent(self, data, start):\n        \"\"\"\n        Finds the extent of a tag, accounting for option quoting and new tags starting before the current one closes.\n        Returns (found_close, end_pos) where valid is False if another tag started before this one closed.\n        \"\"\"\n        in_quote = False\n        quotable = False\n        lto = len(self.tag_opener)\n        ltc = len(self.tag_closer)\n        for i in xrange(start + 1, len(data)):\n            ch = data[i]\n            if ch == '=':\n                quotable = True\n            if ch in ('\"', \"'\"):\n                if quotable and not in_quote:\n                    in_quote = ch\n                elif in_quote == ch:\n                    in_quote = False\n                    quotable = False\n            if not in_quote and data[i:i + lto] == self.tag_opener:\n                return i, False\n            if not in_quote and data[i:i + ltc] == self.tag_closer:\n                return i + ltc, True\n        return len(data), False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tokenize(self, data):\n        data = data.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n        pos = start = end = 0\n        ld = len(data)\n        tokens = []\n        while pos < ld:\n            start = data.find(self.tag_opener, pos)\n            if start >= pos:\n                # Check to see if there was data between this start and the last end.\n                if start > pos:\n                    tl = self._newline_tokenize(data[pos:start])\n                    tokens.extend(tl)\n                    pos = start\n\n                # Find the extent of this tag, if it's ever closed.\n                end, found_close = self._tag_extent(data, start)\n                if found_close:\n                    tag = data[start:end]\n                    valid, tag_name, closer, opts = self._parse_tag(tag)\n                    # Make sure this is a well-formed, recognized tag, otherwise it's just data.\n                    if valid and tag_name in self.recognized_tags:\n                        if closer:\n                            tokens.append((self.TOKEN_TAG_END, tag_name, None, tag))\n                        else:\n                            tokens.append((self.TOKEN_TAG_START, tag_name, opts, tag))\n                    elif valid and self.drop_unrecognized and tag_name not in self.recognized_tags:\n                        # If we found a valid (but unrecognized) tag and self.drop_unrecognized is True, just drop it.\n                        pass\n                    else:\n                        tokens.extend(self._newline_tokenize(tag))\n                else:\n                    # We didn't find a closing tag, tack it on as text.\n                    tokens.extend(self._newline_tokenize(data[start:end]))\n                pos = end\n            else:\n                # No more tags left to parse.\n                break\n        if pos < ld:\n            tl = self._newline_tokenize(data[pos:])\n            tokens.extend(tl)\n        return tokens", "response": "Tokenizes the given string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find_closing_token(self, tag, tokens, pos):\n        embed_count = 0\n        block_count = 0\n        lt = len(tokens)\n        while pos < lt:\n            token_type, tag_name, tag_opts, token_text = tokens[pos]\n            if token_type == self.TOKEN_DATA:\n                # Short-circuit for performance.\n                pos += 1\n                continue\n            if tag.newline_closes and token_type in (self.TOKEN_TAG_START, self.TOKEN_TAG_END):\n                # If we're finding the closing token for a tag that is closed by newlines, but\n                # there is an embedded tag that doesn't transform newlines (i.e. a code tag\n                # that keeps newlines intact), we need to skip over that.\n                inner_tag = self.recognized_tags[tag_name][1]\n                if not inner_tag.transform_newlines:\n                    if token_type == self.TOKEN_TAG_START:\n                        block_count += 1\n                    else:\n                        block_count -= 1\n            if token_type == self.TOKEN_NEWLINE and tag.newline_closes and block_count == 0:\n                # If for some crazy reason there are embedded tags that both close on newline,\n                # the first newline will automatically close all those nested tags.\n                return pos, True\n            elif token_type == self.TOKEN_TAG_START and tag_name == tag.tag_name:\n                if tag.same_tag_closes:\n                    return pos, False\n                if tag.render_embedded:\n                    embed_count += 1\n            elif token_type == self.TOKEN_TAG_END and tag_name == tag.tag_name:\n                if embed_count > 0:\n                    embed_count -= 1\n                else:\n                    return pos, True\n            pos += 1\n        return pos, True", "response": "This function finds the next closing token in the list of tokens and the current position."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _link_replace(self, match, **context):\n        url = match.group(0)\n        if self.linker:\n            if self.linker_takes_context:\n                return self.linker(url, context)\n            else:\n                return self.linker(url)\n        else:\n            href = url\n            if '://' not in href:\n                href = 'http://' + href\n            # Escape quotes to avoid XSS, let the browser escape the rest.\n            return self.url_template.format(href=href.replace('\"', '%22'), text=url)", "response": "Callback for re. sub to replace link text with markup."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform the input string based on the options specified taking into account whether the option is enabled globally for this parser.", "response": "def _transform(self, data, escape_html, replace_links, replace_cosmetic, transform_newlines, **context):\n        \"\"\"\n        Transforms the input string based on the options specified, taking into account\n        whether the option is enabled globally for this parser.\n        \"\"\"\n        url_matches = {}\n        if self.replace_links and replace_links:\n            # If we're replacing links in the text (i.e. not those in [url] tags) then we need to be\n            # careful to pull them out before doing any escaping or cosmetic replacement.\n            pos = 0\n            while True:\n                match = _url_re.search(data, pos)\n                if not match:\n                    break\n                # Replace any link with a token that we can substitute back in after replacements.\n                token = '{{ bbcode-link-%s }}' % len(url_matches)\n                url_matches[token] = self._link_replace(match, **context)\n                start, end = match.span()\n                data = data[:start] + token + data[end:]\n                # To be perfectly accurate, this should probably be len(data[:start] + token), but\n                # start will work, because the token itself won't match as a URL.\n                pos = start\n        if escape_html:\n            data = self._replace(data, self.REPLACE_ESCAPE)\n        if replace_cosmetic:\n            data = self._replace(data, self.REPLACE_COSMETIC)\n        # Now put the replaced links back in the text.\n        for token, replacement in url_matches.items():\n            data = data.replace(token, replacement)\n        if transform_newlines:\n            data = data.replace('\\n', '\\r')\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats the input text using any installed renderers.", "response": "def format(self, data, **context):\n        \"\"\"\n        Formats the input text using any installed renderers. Any context keyword arguments\n        given here will be passed along to the render functions as a context dictionary.\n        \"\"\"\n        tokens = self.tokenize(data)\n        full_context = self.default_context.copy()\n        full_context.update(context)\n        return self._format_tokens(tokens, None, **full_context).replace('\\r', self.newline)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstrip out any tags from the input text using the same tokenization as the formatter.", "response": "def strip(self, data, strip_newlines=False):\n        \"\"\"\n        Strips out any tags from the input text, using the same tokenization as the formatter.\n        \"\"\"\n        text = []\n        for token_type, tag_name, tag_opts, token_text in self.tokenize(data):\n            if token_type == self.TOKEN_DATA:\n                text.append(token_text)\n            elif token_type == self.TOKEN_NEWLINE and not strip_newlines:\n                text.append(token_text)\n        return ''.join(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the mode of values to within a certain range", "response": "def mode_in_range(a, axis=0, tol=1E-3):\n    \"\"\"Find the mode of values to within a certain range\"\"\"\n    a_trunc = a // tol\n    vals, counts = mode(a_trunc, axis)\n    mask = (a_trunc == vals)\n    # mean of each row\n    return np.sum(a * mask, axis) / np.sum(mask, axis)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the scores under the various models in the order they were passed in.", "response": "def scores(self, periods):\n        \"\"\"Compute the scores under the various models\n\n        Parameters\n        ----------\n        periods : array_like\n            array of periods at which to compute scores\n\n        Returns\n        -------\n        scores : dict\n            Dictionary of scores. Dictionary keys are the unique filter names\n            passed to fit()\n        \"\"\"\n        return dict([(filt, model.score(periods))\n                     for (filt, model) in self.models_.items()])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the scores under the various models and return a dictionary of the best periods for each unique filter.", "response": "def best_periods(self):\n        \"\"\"Compute the scores under the various models\n\n        Parameters\n        ----------\n        periods : array_like\n            array of periods at which to compute scores\n\n        Returns\n        -------\n        best_periods : dict\n            Dictionary of best periods. Dictionary keys are the unique filter\n            names passed to fit()\n        \"\"\"\n        for (key, model) in self.models_.items():\n            model.optimizer = self.optimizer\n\n        return dict((filt, model.best_period)\n                    for (filt, model) in self.models_.items())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfitting the multiterm Periodogram model to the data.", "response": "def fit(self, t, y, dy=None):\n        \"\"\"Fit the multiterm Periodogram model to the data.\n\n        Parameters\n        ----------\n        t : array_like, one-dimensional\n            sequence of observation times\n        y : array_like, one-dimensional\n            sequence of observed values\n        dy : float or array_like (optional)\n            errors on observed values\n        \"\"\"\n        # For linear models, dy=1 is equivalent to no errors\n        if dy is None:\n            dy = 1\n\n        self.t, self.y, self.dy = np.broadcast_arrays(t, y, dy)\n\n        self._fit(self.t, self.y, self.dy)\n        self._best_period = None  # reset best period in case of refitting\n\n        if self.fit_period:\n            self._best_period = self._calc_best_period()\n            \n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef predict(self, t, period=None):\n        t = np.asarray(t)\n        if period is None:\n            period = self.best_period\n        result = self._predict(t.ravel(), period=period)\n        return result.reshape(t.shape)", "response": "Compute the best - fit model at a given period at a given time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the score on a frequency grid.", "response": "def score_frequency_grid(self, f0, df, N):\n        \"\"\"Compute the score on a frequency grid.\n\n        Some models can compute results faster if the inputs are passed in this\n        manner.\n\n        Parameters\n        ----------\n        f0, df, N : (float, float, int)\n            parameters describing the frequency grid freq = f0 + df * arange(N)\n            Note that these are frequencies, not angular frequencies.\n\n        Returns\n        -------\n        score : ndarray\n            the length-N array giving the score at each frequency\n        \"\"\"\n        return self._score_frequency_grid(f0, df, N)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef periodogram_auto(self, oversampling=5, nyquist_factor=3,\n                         return_periods=True):\n        \"\"\"Compute the periodogram on an automatically-determined grid\n\n        This function uses heuristic arguments to choose a suitable frequency\n        grid for the data. Note that depending on the data window function,\n        the model may be sensitive to periodicity at higher frequencies than\n        this function returns!\n\n        The final number of frequencies will be\n        Nf = oversampling * nyquist_factor * len(t) / 2\n\n        Parameters\n        ----------\n        oversampling : float\n            the number of samples per approximate peak width\n        nyquist_factor : float\n            the highest frequency, in units of the nyquist frequency for points\n            spread uniformly through the data range.\n\n        Returns\n        -------\n        period : ndarray\n            the grid of periods\n        power : ndarray\n            the power at each frequency\n        \"\"\"\n        N = len(self.t)\n        T = np.max(self.t) - np.min(self.t)\n        df = 1. / T / oversampling\n        f0 = df\n        Nf = int(0.5 * oversampling * nyquist_factor * N)\n        freq = f0 + df * np.arange(Nf)\n        return 1. / freq, self._score_frequency_grid(f0, df, Nf)", "response": "Compute the periodogram on an automatically - deterministic grid of points at each frequency."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef score(self, periods=None):\n        periods = np.asarray(periods)\n        return self._score(periods.ravel()).reshape(periods.shape)", "response": "Compute the periodogram for the given period or periods."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef best_period(self):\n        if self._best_period is None:\n            self._best_period = self._calc_best_period()\n        return self._best_period", "response": "Lazy evaluation of the best period given the model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the top n_periods best periods for the model", "response": "def find_best_periods(self, n_periods=5, return_scores=False):\n        \"\"\"Find the top several best periods for the model\"\"\"\n        return self.optimizer.find_best_periods(self, n_periods,\n                                                return_scores=return_scores)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit(self, t, y, dy=None, filts=0):\n        self.unique_filts_ = np.unique(filts)\n\n        # For linear models, dy=1 is equivalent to no errors\n        if dy is None:\n            dy = 1\n\n        all_data = np.broadcast_arrays(t, y, dy, filts)\n        self.t, self.y, self.dy, self.filts = map(np.ravel, all_data)\n\n        self._fit(self.t, self.y, self.dy, self.filts)\n        self._best_period = None  # reset best period in case of refitting\n\n        if self.fit_period:\n            self._best_period = self._calc_best_period()\n        return self", "response": "Fit the multiterm Periodogram model to the data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the best - fit model at a given time series.", "response": "def predict(self, t, filts, period=None):\n        \"\"\"Compute the best-fit model at ``t`` for a given period\n\n        Parameters\n        ----------\n        t : float or array_like\n            times at which to predict\n        filts : array_like (optional)\n            the array specifying the filter/bandpass for each observation. This\n            is used only in multiband periodograms.\n        period : float (optional)\n            The period at which to compute the model. If not specified, it\n            will be computed via the optimizer provided at initialization.\n\n        Returns\n        -------\n        y : np.ndarray\n            predicted model values at times t\n        \"\"\"\n        unique_filts = set(np.unique(filts))\n        if not unique_filts.issubset(self.unique_filts_):\n            raise ValueError(\"filts does not match training data: \"\n                             \"input: {0} output: {1}\"\n                             \"\".format(set(self.unique_filts_),\n                                       set(unique_filts)))\n        t, filts = np.broadcast_arrays(t, filts)\n\n        if period is None:\n            period = self.best_period\n\n        result = self._predict(t.ravel(), filts=filts.ravel(), period=period)\n        return result.reshape(t.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _construct_X_M(self, omega, **kwargs):\n        X = self._construct_X(omega, weighted=True, **kwargs)\n        M = np.dot(X.T, X)\n\n        if getattr(self, 'regularization', None) is not None:\n            diag = M.ravel(order='K')[::M.shape[0] + 1]\n            if self.regularize_by_trace:\n                diag += diag.sum() * np.asarray(self.regularization)\n            else:\n                diag += np.asarray(self.regularization)\n\n        return X, M", "response": "Construct the weighted normal matrix of the problem"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compute_ymean(self, **kwargs):\n        y = np.asarray(kwargs.get('y', self.y))\n        dy = np.asarray(kwargs.get('dy', self.dy))\n\n        if dy.size == 1:\n            return np.mean(y)\n        else:\n            return np.average(y, weights=1 / dy ** 2)", "response": "Compute the weighted mean of the y data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _construct_X(self, omega, weighted=True, **kwargs):\n        t = kwargs.get('t', self.t)\n        dy = kwargs.get('dy', self.dy)\n        fit_offset = kwargs.get('fit_offset', self.fit_offset)\n\n        if fit_offset:\n            offsets = [np.ones(len(t))]\n        else:\n            offsets = []\n\n        cols = sum(([np.sin((i + 1) * omega * t),\n                     np.cos((i + 1) * omega * t)]\n                    for i in range(self.Nterms)), offsets)\n\n        if weighted:\n            return np.transpose(np.vstack(cols) / dy)\n        else:\n            return np.transpose(np.vstack(cols))", "response": "Construct the design matrix for the problem"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _interpolated_template(self, templateid):\n        phase, y = self._get_template_by_id(templateid)\n\n        # double-check that phase ranges from 0 to 1\n        assert phase.min() >= 0\n        assert phase.max() <= 1\n\n        # at the start and end points, we need to add ~5 points to make sure\n        # the spline & derivatives wrap appropriately\n        phase = np.concatenate([phase[-5:] - 1, phase, phase[:5] + 1])\n        y = np.concatenate([y[-5:], y, y[:5]])\n\n        # Univariate spline allows for derivatives; use this!\n        return UnivariateSpline(phase, y, s=0, k=5)", "response": "Return an interpolator for the given templateid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _eval_templates(self, period):\n        theta_best = [self._optimize(period, tmpid)\n                      for tmpid, _ in enumerate(self.templates)]\n        chi2 = [self._chi2(theta, period, tmpid)\n                for tmpid, theta in enumerate(theta_best)]\n\n        return theta_best, chi2", "response": "Evaluate the best template for the given period"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _model(self, t, theta, period, tmpid):\n        template = self.templates[tmpid]\n        phase = (t / period - theta[2]) % 1\n        return theta[0] + theta[1] * template(phase)", "response": "Compute the model at t for the given parameters period & template"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the chi2 for the given parameters period & template Optionally return the gradient for faster optimization", "response": "def _chi2(self, theta, period, tmpid, return_gradient=False):\n        \"\"\"\n        Compute the chi2 for the given parameters, period, & template\n\n        Optionally return the gradient for faster optimization\n        \"\"\"\n        template = self.templates[tmpid]\n        phase = (self.t / period - theta[2]) % 1\n        model = theta[0] + theta[1] * template(phase)\n        chi2 = (((model - self.y) / self.dy) ** 2).sum()\n\n        if return_gradient:\n            grad = 2 * (model - self.y) / self.dy ** 2\n            gradient = np.array([np.sum(grad),\n                                 np.sum(grad * template(phase)),\n                                 -np.sum(grad * theta[1]\n                                         * template.derivative(1)(phase))])\n            return chi2, gradient\n        else:\n            return chi2"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _optimize(self, period, tmpid, use_gradient=True):\n        theta_0 = [self.y.min(), self.y.max() - self.y.min(), 0]\n        result = minimize(self._chi2, theta_0, jac=bool(use_gradient),\n                          bounds=[(None, None), (0, None), (None, None)],\n                          args=(period, tmpid, use_gradient))\n        return result.x", "response": "Optimize the model for the given period & template"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the n_periods best periods in the model.", "response": "def find_best_periods(self, model, n_periods=5, return_scores=False):\n        \"\"\"Find the `n_periods` best periods in the model\"\"\"\n\n        # compute the estimated peak width from the data range\n        tmin, tmax = np.min(model.t), np.max(model.t)\n        width = 2 * np.pi / (tmax - tmin)\n\n        # raise a ValueError if period limits are out of range\n        if tmax - tmin < np.max(self.period_range):\n            raise ValueError(\"The optimizer is not designed to search for \"\n                             \"for periods larger than the data baseline. \")\n\n        # our candidate steps in omega is controlled by period_range & coverage\n        omega_step = width / self.first_pass_coverage\n        omega_min = 2 * np.pi / np.max(self.period_range)\n        omega_max = 2 * np.pi / np.min(self.period_range)\n        omegas = np.arange(omega_min, omega_max + omega_step, omega_step)\n        periods = 2 * np.pi / omegas\n\n        # print some updates if desired\n        if not self.quiet:\n            print(\"Finding optimal frequency:\")\n            print(\" - Estimated peak width = {0:.3g}\".format(width))\n            print(\" - Using {0} steps per peak; \"\n                  \"omega_step = {1:.3g}\".format(self.first_pass_coverage,\n                                                omega_step))\n            print(\" - User-specified period range: \"\n                  \" {0:.2g} to {1:.2g}\".format(periods.min(), periods.max()))\n            print(\" - Computing periods at {0:.0f} steps\".format(len(periods)))\n            sys.stdout.flush()\n\n        # Compute the score on the initial grid\n        N = int(1 + width // omega_step)\n        score = model.score_frequency_grid(omega_min / (2 * np.pi),\n                                           omega_step / (2 * np.pi),\n                                           len(omegas))\n\n        # find initial candidates of unique peaks\n        minscore = score.min()\n        n_candidates = max(5, 2 * n_periods)\n        candidate_freqs = np.zeros(n_candidates)\n        candidate_scores = np.zeros(n_candidates)\n        for i in range(n_candidates):\n            j = np.argmax(score)\n            candidate_freqs[i] = omegas[j]\n            candidate_scores[i] = score[j]\n            score[max(0, j - N):(j + N)] = minscore\n\n        # If required, do a final pass on these unique at higher resolution\n        if self.final_pass_coverage <= self.first_pass_coverage:\n            best_periods = 2 * np.pi / candidate_freqs[:n_periods]\n            best_scores = candidate_scores[:n_periods]\n        else:\n            f0 = -omega_step / (2 * np.pi)\n            df = width / self.final_pass_coverage / (2 * np.pi)\n            Nf = abs(2 * f0) // df\n            steps = f0 + df * np.arange(Nf)\n            candidate_freqs /= (2 * np.pi)\n\n            freqs = steps + candidate_freqs[:, np.newaxis]\n            periods = 1. / freqs\n\n            if not self.quiet:\n                print(\"Zooming-in on {0} candidate peaks:\"\n                      \"\".format(n_candidates))\n                print(\" - Computing periods at {0:.0f} \"\n                      \"steps\".format(periods.size))\n                sys.stdout.flush()\n\n            #scores = model.score(periods)\n            scores = np.array([model.score_frequency_grid(c + f0, df, Nf)\n                               for c in candidate_freqs])\n            best_scores = scores.max(1)\n            j = np.argmax(scores, 1)\n            i = np.argsort(best_scores)[::-1]\n\n            best_periods = periods[i, j[i]]\n            best_scores = best_scores[i]\n\n        if return_scores:\n            return best_periods[:n_periods], best_scores[:n_periods]\n        else:\n            return best_periods[:n_periods]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the factorial of N.", "response": "def factorial(N):\n    \"\"\"Compute the factorial of N.\n    If N <= 10, use a fast lookup table; otherwise use scipy.special.factorial\n    \"\"\"\n    if N < len(FACTORIALS):\n        return FACTORIALS[N]\n    else:\n        from scipy import special\n        return int(special.factorial(N))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the highest bit of N in the log2.", "response": "def bitceil(N):\n    \"\"\"\n    Find the bit (i.e. power of 2) immediately greater than or equal to N\n    Note: this works for numbers up to 2 ** 64.\n\n    Roughly equivalent to int(2 ** np.ceil(np.log2(N)))\n    \"\"\"\n    # Note: for Python 2.7 and 3.x, this is faster:\n    # return 1 << int(N - 1).bit_length()\n    N = int(N) - 1\n    for i in [1, 2, 4, 8, 16, 32]:\n        N |= N >> i\n    return N + 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extirpolate(x, y, N=None, M=4):\n    x, y = map(np.ravel, np.broadcast_arrays(x, y))\n\n    if N is None:\n        N = int(np.max(x) + 0.5 * M + 1)\n\n    # Now use legendre polynomial weights to populate the results array;\n    # This is an efficient recursive implementation (See Press et al. 1989)\n    result = np.zeros(N, dtype=y.dtype)\n\n    # first take care of the easy cases where x is an integer\n    integers = (x % 1 == 0)\n    np.add.at(result, x[integers].astype(int), y[integers])\n    x, y = x[~integers], y[~integers]\n\n    # For each remaining x, find the index describing the extirpolation range.\n    # i.e. ilo[i] < x[i] < ilo[i] + M with x[i] in the center,\n    # adjusted so that the limits are within the range 0...N\n    ilo = np.clip((x - M // 2).astype(int), 0, N - M)\n    numerator = y * np.prod(x - ilo - np.arange(M)[:, np.newaxis], 0)\n    denominator = factorial(M - 1)\n\n    for j in range(M):\n        if j > 0:\n            denominator *= j / (j - M)\n        ind = ilo + (M - 1 - j)\n        np.add.at(result, ind, numerator / (denominator * (x - ind)))\n    return result", "response": "This function generates a new random base for the base for the base for the base for the base for the base for the base for the base for the base for the base for the base for the base for the base for the base for the base for the base for the base for the base."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the approximate trigonometric sums for a number of frequencies", "response": "def trig_sum(t, h, df, N, f0=0, freq_factor=1,\n             oversampling=5, use_fft=True, Mfft=4):\n    \"\"\"Compute (approximate) trigonometric sums for a number of frequencies\n\n    This routine computes weighted sine and cosine sums:\n\n        S_j = sum_i { h_i * sin(2 pi * f_j * t_i) }\n        C_j = sum_i { h_i * cos(2 pi * f_j * t_i) }\n\n    Where f_j = freq_factor * (f0 + j * df) for the values j in 1 ... N.\n    The sums can be computed either by a brute force O[N^2] method, or\n    by an FFT-based O[Nlog(N)] method.\n\n    Parameters\n    ----------\n    t : array_like\n        array of input times\n    h : array_like\n        array weights for the sum\n    df : float\n        frequency spacing\n    N : int\n        number of frequency bins to return\n    f0 : float (optional, default=0)\n        The low frequency to use\n    freq_factor : float (optional, default=1)\n        Factor which multiplies the frequency\n    use_fft : bool\n        if True, use the approximate FFT algorithm to compute the result.\n        This uses the FFT with Press & Rybicki's Lagrangian extirpolation.\n    oversampling : int (default = 5)\n        oversampling freq_factor for the approximation; roughtly the number of\n        time samples across the highest-frequency sinusoid. This parameter\n        contains the tradeoff between accuracy and speed. Not referenced\n        if use_fft is False.\n    Mfft : int\n        The number of adjacent points to use in the FFT approximation.\n        Not referenced if use_fft is False.\n\n    Returns\n    -------\n    S, C : ndarrays\n        summation arrays for frequencies f = df * np.arange(1, N + 1)\n    \"\"\"\n    df *= freq_factor\n    f0 *= freq_factor\n\n    assert df > 0\n    t, h = map(np.ravel, np.broadcast_arrays(t, h))\n\n    if use_fft:\n        Mfft = int(Mfft)\n        assert(Mfft > 0)\n\n        # required size of fft is the power of 2 above the oversampling rate\n        Nfft = bitceil(N * oversampling)\n        t0 = t.min()\n\n        if f0 > 0:\n            h = h * np.exp(2j * np.pi * f0 * (t - t0))\n\n        tnorm = ((t - t0) * Nfft * df) % Nfft\n        grid = extirpolate(tnorm, h, Nfft, Mfft)\n\n        fftgrid = np.fft.ifft(grid)\n        if t0 != 0:\n            f = f0 + df * np.arange(Nfft)\n            fftgrid *= np.exp(2j * np.pi * t0 * f)\n        fftgrid = fftgrid[:N]\n\n        C = Nfft * fftgrid.real\n        S = Nfft * fftgrid.imag\n    else:\n        f = f0 + df * np.arange(N)\n        C = np.dot(h, np.cos(2 * np.pi * f * t[:, np.newaxis]))\n        S = np.dot(h, np.sin(2 * np.pi * f * t[:, np.newaxis]))\n\n    return S, C"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lomb_scargle_fast(t, y, dy=1, f0=0, df=None, Nf=None,\n                      center_data=True, fit_offset=True,\n                      use_fft=True, freq_oversampling=5, nyquist_factor=2,\n                      trig_sum_kwds=None):\n    \"\"\"Compute a lomb-scargle periodogram for the given data\n\n    This implements both an O[N^2] method if use_fft==False, or an\n    O[NlogN] method if use_fft==True.\n\n    Parameters\n    ----------\n    t, y, dy : array_like\n        times, values, and errors of the data points. These should be\n        broadcastable to the same shape. If dy is not specified, a\n        constant error will be used.\n    f0, df, Nf : (float, float, int)\n        parameters describing the frequency grid, f = f0 + df * arange(Nf).\n        Defaults, with T = t.max() - t.min():\n        - f0 = 0\n        - df is set such that there are ``freq_oversampling`` points per\n          peak width. ``freq_oversampling`` defaults to 5.\n        - Nf is set such that the highest frequency is ``nyquist_factor``\n          times the so-called \"average Nyquist frequency\".\n          ``nyquist_factor`` defaults to 2.\n        Note that for unevenly-spaced data, the periodogram can be sensitive\n        to frequencies far higher than the average Nyquist frequency.\n    center_data : bool (default=True)\n        Specify whether to subtract the mean of the data before the fit\n    fit_offset : bool (default=True)\n        If True, then compute the floating-mean periodogram; i.e. let the mean\n        vary with the fit.\n    use_fft : bool (default=True)\n        If True, then use the Press & Rybicki O[NlogN] algorithm to compute\n        the result. Otherwise, use a slower O[N^2] algorithm\n\n    Other Parameters\n    ----------------\n    freq_oversampling : float (default=5)\n        Oversampling factor for the frequency bins. Only referenced if\n        ``df`` is not specified\n    nyquist_factor : float (default=2)\n        Parameter controlling the highest probed frequency. Only referenced\n        if ``Nf`` is not specified.\n    trig_sum_kwds : dict or None (optional)\n        extra keyword arguments to pass to the ``trig_sum`` utility.\n        Options are ``oversampling`` and ``Mfft``. See documentation\n        of ``trig_sum`` for details.\n\n    Notes\n    -----\n    Note that the ``use_fft=True`` algorithm is an approximation to the true\n    Lomb-Scargle periodogram, and as the number of points grows this\n    approximation improves. On the other hand, for very small datasets\n    (<~50 points or so) this approximation may not be useful.\n\n    References\n    ----------\n    .. [1] Press W.H. and Rybicki, G.B, \"Fast algorithm for spectral analysis\n        of unevenly sampled data\". ApJ 1:338, p277, 1989\n    .. [2] M. Zechmeister and M. Kurster, A&A 496, 577-584 (2009)\n    .. [3] W. Press et al, Numerical Recipies in C (2002)\n    \"\"\"\n    # Validate and setup input data\n    t, y, dy = map(np.ravel, np.broadcast_arrays(t, y, dy))\n    w = 1. / (dy ** 2)\n    w /= w.sum()\n\n    # Validate and setup frequency grid\n    if df is None:\n        peak_width = 1. / (t.max() - t.min())\n        df = peak_width / freq_oversampling\n    if Nf is None:\n        avg_Nyquist = 0.5 * len(t) / (t.max() - t.min())\n        Nf = max(16, (nyquist_factor * avg_Nyquist - f0) / df)\n    Nf = int(Nf)\n    assert(df > 0)\n    assert(Nf > 0)\n    freq = f0 + df * np.arange(Nf)\n\n    # Center the data. Even if we're fitting the offset,\n    # this step makes the expressions below more succinct\n    if center_data or fit_offset:\n        y = y - np.dot(w, y)\n\n    # set up arguments to trig_sum\n    kwargs = dict.copy(trig_sum_kwds or {})\n    kwargs.update(f0=f0, df=df, use_fft=use_fft, N=Nf)\n\n    #----------------------------------------------------------------------\n    # 1. compute functions of the time-shift tau at each frequency\n    Sh, Ch = trig_sum(t, w * y, **kwargs)\n    S2, C2 = trig_sum(t, w, freq_factor=2, **kwargs)\n\n    if fit_offset:\n        S, C = trig_sum(t, w, **kwargs)\n        with warnings.catch_warnings():\n            # Filter \"invalid value in divide\" warnings for zero-frequency\n            if f0 == 0:\n                warnings.simplefilter(\"ignore\")\n            tan_2omega_tau = (S2 - 2 * S * C) / (C2 - (C * C - S * S))\n            # fix NaN at zero frequency\n            if np.isnan(tan_2omega_tau[0]):\n                tan_2omega_tau[0] = 0\n    else:\n        tan_2omega_tau = S2 / C2\n\n    # slower/less stable way: we'll use trig identities instead\n    # omega_tau = 0.5 * np.arctan(tan_2omega_tau)\n    # S2w, C2w = np.sin(2 * omega_tau), np.cos(2 * omega_tau)\n    # Sw, Cw = np.sin(omega_tau), np.cos(omega_tau)\n\n    S2w = tan_2omega_tau / np.sqrt(1 + tan_2omega_tau * tan_2omega_tau)\n    C2w = 1 / np.sqrt(1 + tan_2omega_tau * tan_2omega_tau)\n    Cw = np.sqrt(0.5) * np.sqrt(1 + C2w)\n    Sw = np.sqrt(0.5) * np.sign(S2w) * np.sqrt(1 - C2w)\n\n    #----------------------------------------------------------------------\n    # 2. Compute the periodogram, following Zechmeister & Kurster\n    #    and using tricks from Press & Rybicki.\n    YY = np.dot(w, y ** 2)\n    YC = Ch * Cw + Sh * Sw\n    YS = Sh * Cw - Ch * Sw\n    CC = 0.5 * (1 + C2 * C2w + S2 * S2w)\n    SS = 0.5 * (1 - C2 * C2w - S2 * S2w)\n\n    if fit_offset:\n        CC -= (C * Cw + S * Sw) ** 2\n        SS -= (S * Cw - C * Sw) ** 2\n\n    with warnings.catch_warnings():\n        # Filter \"invalid value in divide\" warnings for zero-frequency\n        if fit_offset and f0 == 0:\n            warnings.simplefilter(\"ignore\")\n\n        power = (YC * YC / CC + YS * YS / SS) / YY\n\n        # fix NaN and INF at zero frequency\n        if np.isnan(power[0]) or np.isinf(power[0]):\n            power[0] = 0\n\n    return freq, power", "response": "Compute a fast lomb - scargle periodogram for the given data points."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef observed(self, band, corrected=True):\n        if band not in 'ugriz':\n            raise ValueError(\"band='{0}' not recognized\".format(band))\n        i = 'ugriz'.find(band)\n        t, y, dy = self.lcdata.get_lightcurve(self.lcid, return_1d=False)\n\n        if corrected:\n            ext = self.obsmeta['rExt'] * self.ext_correction[band]\n        else:\n            ext = 0\n\n        return t[:, i], y[:, i] - ext, dy[:, i]", "response": "Return the observed values in the given band."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the magnitudes in the specified band", "response": "def generated(self, band, t, err=None, corrected=True):\n        \"\"\"Return generated magnitudes in the specified band\n\n        Parameters\n        ----------\n        band : str\n            desired bandpass: should be one of ['u', 'g', 'r', 'i', 'z']\n        t : array_like\n            array of times (in days)\n        err : float or array_like\n            gaussian error in observations\n        corrected : bool (optional)\n            If true, correct for extinction\n\n        Returns\n        -------\n        mag : ndarray\n            magnitudes at the specified times under the generated model.\n        \"\"\"\n        t = np.asarray(t)\n        num = self.meta[band + 'T']\n        mu = self.meta[band + '0']\n        amp = self.meta[band + 'A']\n        t0 = self.meta[band + 'E']\n\n        # if there are nans or infinities, mask them\n        bad_vals = np.isnan(t) | np.isinf(t)\n        t[bad_vals] = t0\n\n        if corrected:\n            ext = 0\n        else:\n            ext = self.obsmeta['rExt'] * self.ext_correction[band]\n\n        func = self._template_func(num, band, mu + ext, amp)\n        mag = func(((t - t0) / self.period) % 1)\n\n        mag[bad_vals] = np.nan\n\n        if err is not None:\n            mag += self.rng.normal(0, err, t.shape)\n\n        return mag"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_download_or_cache(filename, data_home=None,\n                           url=SESAR_RRLYRAE_URL,\n                           force_download=False):\n    \"\"\"Private utility to download and/or load data from disk cache.\"\"\"\n    # Import here so astroML is not required at package level\n    from astroML.datasets.tools import get_data_home\n\n    if data_home is None:\n        data_home = get_data_home(data_home)\n    data_home = os.path.join(data_home, 'Sesar2010')\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    src_url = SESAR_RRLYRAE_URL + filename\n    save_loc = os.path.join(data_home, filename)\n\n    if force_download or not os.path.exists(save_loc):\n        fhandle = urlopen(src_url)\n        with open(save_loc, 'wb') as cache:\n            cache.write(fhandle.read())\n    return save_loc", "response": "Private utility to download and or load data from disk cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches the RR Lyrae dataset from Sesar 2010 and return the resulting object.", "response": "def fetch_rrlyrae(partial=False, **kwargs):\n    \"\"\"Fetch RR Lyrae light curves from Sesar 2010\n\n    Parameters\n    ----------\n    partial : bool (optional)\n        If true, return the partial dataset (reduced to 1 band per night)\n\n    Returns\n    -------\n    rrlyrae : :class:`RRLyraeLC` object\n        This object contains pointers to the RR Lyrae data.\n\n    Other Parameters\n    ----------------\n    data_home : str (optional)\n        Specify the local cache directory for the dataset. If not used, it\n        will default to the ``astroML`` default location.\n    url : str (optional)\n        Specify the URL of the datasets. Defaults to webpage associated with\n        Sesar 2010.\n    force_download : bool (optional)\n        If true, then force re-downloading data even if it is already cached\n        locally. Default is False.\n\n    Examples\n    --------\n    >>> rrlyrae = fetch_rrlyrae()\n    >>> rrlyrae.ids[:5]\n    [1013184, 1019544, 1027882, 1052471, 1056152]\n    >>> lcid = rrlyrae.ids[0]\n    >>> t, mag, dmag, bands = rrlyrae.get_lightcurve(lcid)\n    >>> t[:4]\n    array([ 51081.347856,  51081.349522,  51081.346189,  51081.347022])\n    >>> mag[:4]\n    array([ 18.702,  17.553,  17.236,  17.124])\n    >>> dmag[:4]\n    array([ 0.021,  0.005,  0.005,  0.006])\n    >>> list(bands[:4])\n    ['u', 'g', 'r', 'i']\n    \"\"\"\n    if partial:\n        return PartialRRLyraeLC('table1.tar.gz',\n                                cache_kwargs=kwargs)\n    else:\n        return RRLyraeLC('table1.tar.gz',\n                         cache_kwargs=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches data from table 2 of Sesar 2010", "response": "def fetch_rrlyrae_lc_params(**kwargs):\n    \"\"\"Fetch data from table 2 of Sesar 2010\n\n    This table includes observationally-derived parameters for all the\n    Sesar 2010 lightcurves. \n    \"\"\"\n    save_loc = _get_download_or_cache('table2.dat.gz', **kwargs)\n\n    dtype = [('id', 'i'), ('type', 'S2'), ('P', 'f'),\n             ('uA', 'f'), ('u0', 'f'), ('uE', 'f'), ('uT', 'f'),\n             ('gA', 'f'), ('g0', 'f'), ('gE', 'f'), ('gT', 'f'),\n             ('rA', 'f'), ('r0', 'f'), ('rE', 'f'), ('rT', 'f'),\n             ('iA', 'f'), ('i0', 'f'), ('iE', 'f'), ('iT', 'f'),\n             ('zA', 'f'), ('z0', 'f'), ('zE', 'f'), ('zT', 'f')]\n\n    return np.loadtxt(save_loc, dtype=dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches data from table 3 of Sesar 2010", "response": "def fetch_rrlyrae_fitdata(**kwargs):\n    \"\"\"Fetch data from table 3 of Sesar 2010\n\n    This table includes parameters derived from template fits to all the\n    Sesar 2010 lightcurves.\n    \"\"\"\n    save_loc = _get_download_or_cache('table3.dat.gz', **kwargs)\n\n    dtype = [('id', 'i'), ('RA', 'f'), ('DEC', 'f'), ('rExt', 'f'),\n             ('d', 'f'), ('RGC', 'f'),\n             ('u', 'f'), ('g', 'f'), ('r', 'f'),\n             ('i', 'f'), ('z', 'f'), ('V', 'f'),\n             ('ugmin', 'f'), ('ugmin_err', 'f'),\n             ('grmin', 'f'), ('grmin_err', 'f')]\n\n    return np.loadtxt(save_loc, dtype=dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the light curves for the given ID.", "response": "def get_lightcurve(self, star_id, return_1d=True):\n        \"\"\"Get the light curves for the given ID\n\n        Parameters\n        ----------\n        star_id : int\n            A valid integer star id representing an object in the dataset\n        return_1d : boolean (default=True)\n            Specify whether to return 1D arrays of (t, y, dy, filts) or\n            2D arrays of (t, y, dy) where each column is a filter.\n\n        Returns\n        -------\n        t, y, dy : np.ndarrays (if return_1d == False)\n            Times, magnitudes, and magnitude errors.\n            The shape of each array is [Nobs, 5], where the columns refer\n            to [u,g,r,i,z] bands. Non-observations are indicated by NaN.\n\n        t, y, dy, filts : np.ndarrays (if return_1d == True)\n            Times, magnitudes, magnitude errors, and filters\n            The shape of each array is [Nobs], and non-observations are\n            filtered out.\n        \"\"\"\n        filename = '{0}/{1}.dat'.format(self.dirname, star_id)\n\n        try:\n            data = np.loadtxt(self.data.extractfile(filename))\n        except KeyError:\n            raise ValueError(\"invalid star id: {0}\".format(star_id))\n\n        RA = data[:, 0]\n        DEC = data[:, 1]\n\n        t = data[:, 2::3]\n        y = data[:, 3::3]\n        dy = data[:, 4::3]\n\n        nans = (y == -99.99)\n        t[nans] = np.nan\n        y[nans] = np.nan\n        dy[nans] = np.nan\n\n        if return_1d:\n            t, y, dy, filts = np.broadcast_arrays(t, y, dy,\n                                                  ['u', 'g', 'r', 'i', 'z'])\n            good = ~np.isnan(t)\n            return t[good], y[good], dy[good], filts[good]\n        else:\n            return t, y, dy"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_metadata(self, lcid):\n        if self._metadata is None:\n            self._metadata = fetch_rrlyrae_lc_params()\n        i = np.where(self._metadata['id'] == lcid)[0]\n        if len(i) == 0:\n            raise ValueError(\"invalid lcid: {0}\".format(lcid))\n        return self._metadata[i[0]]", "response": "Get the parameters derived from the fit for the given id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_obsmeta(self, lcid):\n        if self._obsdata is None:\n            self._obsdata = fetch_rrlyrae_fitdata()\n        i = np.where(self._obsdata['id'] == lcid)[0]\n        if len(i) == 0:\n            raise ValueError(\"invalid lcid: {0}\".format(lcid))\n        return self._obsdata[i[0]]", "response": "Get the observation metadata for the given id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_template(self, template_id):\n        try:\n            data = np.loadtxt(self.data.extractfile(template_id + '.dat'))\n        except KeyError:\n            raise ValueError(\"invalid star id: {0}\".format(template_id))\n        return data[:, 0], data[:, 1]", "response": "Get a particular lightcurve template from the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hr_avg(self):\n        hr_data = self.hr_values()\n        return int(sum(hr_data) / len(hr_data))", "response": "Average heart rate of the workout"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\naveraging pace for the workout", "response": "def pace(self):\n        \"\"\"Average pace (mm:ss/km for the workout\"\"\"\n        secs_per_km = self.duration / (self.distance / 1000)\n        return time.strftime('%M:%S', time.gmtime(secs_per_km))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the ascent of workout in meters", "response": "def ascent(self):\n        \"\"\"Returns ascent of workout in meters\"\"\"\n        total_ascent = 0.0\n        altitude_data = self.altitude_points()\n        for i in range(len(altitude_data) - 1):\n            diff = altitude_data[i+1] - altitude_data[i]\n            if diff > 0.0:\n                total_ascent += diff\n        return total_ascent"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef descent(self):\n        total_descent = 0.0\n        altitude_data = self.altitude_points()\n        for i in range(len(altitude_data) - 1):\n            diff = altitude_data[i+1] - altitude_data[i]\n            if diff < 0.0:\n                total_descent += abs(diff)\n        return total_descent", "response": "Returns the descent of workout in meters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that the keywords don t contain special characters.", "response": "def keywords_special_characters(keywords):\n    \"\"\"\n    Confirms that the keywords don't contain special characters\n\n    Args:\n        keywords (str)\n\n    Raises:\n        django.forms.ValidationError\n    \"\"\"\n    invalid_chars = '!\\\"#$%&\\'()*+-./:;<=>?@[\\\\]^_{|}~\\t\\n'\n    if any(char in invalid_chars for char in keywords):\n        raise ValidationError(MESSAGE_KEYWORD_SPECIAL_CHARS)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that the uploaded image is of the correct format.", "response": "def image_format(value):\n    \"\"\"\n    Confirms that the uploaded image is of supported format.\n\n    Args:\n        value (File): The file with an `image` property containing the image\n\n    Raises:\n        django.forms.ValidationError\n\n    \"\"\"\n\n    if value.image.format.upper() not in constants.ALLOWED_IMAGE_FORMATS:\n        raise ValidationError(MESSAGE_INVALID_IMAGE_FORMAT)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef case_study_social_link_facebook(value):\n\n    parsed = parse.urlparse(value.lower())\n    if not parsed.netloc.endswith('facebook.com'):\n        raise ValidationError(MESSAGE_NOT_FACEBOOK)", "response": "Checks that the social media url is pointed at the correct domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef case_study_social_link_twitter(value):\n\n    parsed = parse.urlparse(value.lower())\n    if not parsed.netloc.endswith('twitter.com'):\n        raise ValidationError(MESSAGE_NOT_TWITTER)", "response": "Checks that the social media url is pointed at the correct domain."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck that the social media url is pointed at the correct domain.", "response": "def case_study_social_link_linkedin(value):\n    \"\"\"\n    Confirms that the social media url is pointed at the correct domain.\n\n    Args:\n        value (string): The url to check.\n\n    Raises:\n        django.forms.ValidationError\n\n    \"\"\"\n\n    parsed = parse.urlparse(value.lower())\n    if not parsed.netloc.endswith('linkedin.com'):\n        raise ValidationError(MESSAGE_NOT_LINKEDIN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the company number is not for a company that has insufficient company house data.", "response": "def no_company_with_insufficient_companies_house_data(value):\n    \"\"\"\n    Confirms that the company number is not for for a company that\n    Companies House does not hold information on.\n\n    Args:\n        value (string): The company number to check.\n\n    Raises:\n        django.forms.ValidationError\n\n    \"\"\"\n\n    for prefix, name in company_types_with_insufficient_companies_house_data:\n        if value.upper().startswith(prefix):\n            raise ValidationError(\n                MESSAGE_INSUFFICIENT_DATA, params={'name': name}\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef email_domain_free(value):\n\n    domain = helpers.get_domain_from_email_address(value)\n    if domain.lower() in free_domains:\n        raise ValidationError(MESSAGE_USE_COMPANY_EMAIL)", "response": "Validate that the email address is not using a free service."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef email_domain_disposable(value):\n\n    domain = helpers.get_domain_from_email_address(value)\n    if domain.lower() in disposable_domains:\n        raise ValidationError(MESSAGE_USE_COMPANY_EMAIL)", "response": "Validate that the email address is not using a disposable service."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that the phone number is a valid UK phone number.", "response": "def domestic_mobile_phone_number(value):\n    \"\"\"\n    Confirms that the phone number is a valid UK phone number.\n    @param {str} value\n    @returns {None}\n    @raises AssertionError\n\n    \"\"\"\n\n    try:\n        parsed = phonenumbers.parse(value, 'GB')\n    except NumberParseException:\n        pass\n    else:\n        is_mobile = carrier._is_mobile(number_type(parsed))\n        if is_mobile and phonenumbers.is_valid_number(parsed):\n            return None\n    raise ValidationError(MESSAGE_INVALID_PHONE_NUMBER)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_liers(points):\n    result = [points[0]]\n    for i in range(1, len(points) - 2):\n        prv = points[i-1]\n        crr = points[i]\n        nxt = points[i+1]\n        if prv.time <= crr.time and crr.time <= nxt.time:\n            result.append(crr)\n    result.append(points[-1])\n\n    return result", "response": "Removes obvious noise points from the order of the given list of points."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bounds(self, thr=0, lower_index=0, upper_index=-1):\n        points = self.points[lower_index:upper_index]\n\n        min_lat = float(\"inf\")\n        min_lon = float(\"inf\")\n        max_lat = -float(\"inf\")\n        max_lon = -float(\"inf\")\n\n        for point in points:\n            min_lat = min(min_lat, point.lat)\n            min_lon = min(min_lon, point.lon)\n            max_lat = max(max_lat, point.lat)\n            max_lon = max(max_lon, point.lon)\n\n        return (min_lat - thr, min_lon - thr, max_lat + thr, max_lon + thr)", "response": "Computes the bounds of the segment or part of it\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing metrics for each point in the segment.", "response": "def compute_metrics(self):\n        \"\"\" Computes metrics for each point\n\n        Returns:\n            :obj:`Segment`: self\n        \"\"\"\n        for prev, point in pairwise(self.points):\n            point.compute_metrics(prev)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_and_fit(self, segment):\n        self.points = sort_segment_points(self.points, segment.points)\n        return self", "response": "Merges another segment with this one and fits the result into the new segment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the closest point in the segment to a given point. Returns - 1 if no such point is found.", "response": "def closest_point_to(self, point, thr=20.0):\n        \"\"\" Finds the closest point in the segment to a given point\n\n        Args:\n            point (:obj:`Point`)\n            thr (float, optional): Distance threshold, in meters, to be considered\n                the same point. Defaults to 20.0\n        Returns:\n            (int, Point): Index of the point. -1 if doesn't exist. A point is given if it's along the segment\n\n        \"\"\"\n        i = 0\n        point_arr = point.gen2arr()\n\n        def closest_in_line(pointA, pointB):\n            temp = closest_point(pointA.gen2arr(), pointB.gen2arr(), point_arr)\n            return Point(temp[1], temp[0], None)\n\n        for (p_a, p_b) in pairwise(self.points):\n            candidate = closest_in_line(p_a, p_b)\n            if candidate.distance(point) <= thr:\n                if p_a.distance(point) <= thr:\n                    return i, p_a\n                elif p_b.distance(point) <= thr:\n                    return i + 1, p_b\n                else:\n                    return i, candidate\n            i = i + 1\n        return -1, None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a copy of the current segment between start and end indices.", "response": "def slice(self, start, end):\n        \"\"\" Creates a copy of the current segment between indexes. If end > start,\n            points are reverted\n\n        Args:\n            start (int): Start index\n            end (int): End index\n        Returns:\n            :obj:`Segment`\n        \"\"\"\n\n        reverse = False\n        if start > end:\n            temp = start\n            start = end\n            end = temp\n            reverse = True\n\n        seg = self.copy()\n        seg.points = seg.points[start:end+1]\n        if reverse:\n            seg.points = list(reversed(seg.points))\n\n        return seg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a segment to a JSON serializable format", "response": "def to_json(self):\n        \"\"\" Converts segment to a JSON serializable format\n\n        Returns:\n            :obj:`dict`\n        \"\"\"\n        points = [point.to_json() for point in self.points]\n        return {\n            'points': points,\n            'transportationModes': self.transportation_modes,\n            'locationFrom': self.location_from.to_json() if self.location_from != None else None,\n            'locationTo': self.location_to.to_json() if self.location_to != None else None\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a segment from a GPX format.", "response": "def from_gpx(gpx_segment):\n        \"\"\" Creates a segment from a GPX format.\n\n        No preprocessing is done.\n\n        Arguments:\n            gpx_segment (:obj:`gpxpy.GPXTrackSegment`)\n        Return:\n            :obj:`Segment`\n        \"\"\"\n        points = []\n        for point in gpx_segment.points:\n            points.append(Point.from_gpx(point))\n        return Segment(points)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_json(json):\n        points = []\n        for point in json['points']:\n            points.append(Point.from_json(point))\n        return Segment(points)", "response": "Creates a segment from a JSON representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextrapolates a number of points based on the first ones in the list.", "response": "def extrapolate_points(points, n_points):\n    \"\"\" Extrapolate a number of points, based on the first ones\n\n    Args:\n        points (:obj:`list` of :obj:`Point`)\n        n_points (int): number of points to extrapolate\n    Returns:\n        :obj:`list` of :obj:`Point`\n    \"\"\"\n    points = points[:n_points]\n    lat = []\n    lon = []\n    last = None\n    for point in points:\n        if last is not None:\n            lat.append(last.lat-point.lat)\n            lon.append(last.lon-point.lon)\n        last = point\n\n    dts = np.mean([p.dt for p in points])\n    lons = np.mean(lon)\n    lats = np.mean(lat)\n\n    gen_sample = []\n    last = points[0]\n    for _ in range(n_points):\n        point = Point(last.lat+lats, last.lon+lons, None)\n        point.dt = dts\n        # point.compute_metrics(last)\n        gen_sample.append(point)\n        last = point\n\n    return gen_sample"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsmoothing a set of points but it extrapolates some points at the beginning of the tree.", "response": "def with_extrapolation(points, noise, n_points):\n    \"\"\" Smooths a set of points, but it extrapolates some points at the beginning\n\n    Args:\n        points (:obj:`list` of :obj:`Point`)\n        noise (float): Expected noise, the higher it is the more the path will\n            be smoothed.\n    Returns:\n        :obj:`list` of :obj:`Point`\n    \"\"\"\n    n_points = 10\n    return kalman_filter(extrapolate_points(points, n_points) + points, noise)[n_points:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsmooths a set of points in reverse order and returns a new set of points in normal order.", "response": "def with_inverse(points, noise):\n    \"\"\" Smooths a set of points\n\n    It smooths them twice, once in given order, another one in the reverse order.\n    The the first half of the results will be taken from the reverse order and\n        the second half from the normal order.\n\n    Args:\n        points (:obj:`list` of :obj:`Point`)\n        noise (float): Expected noise, the higher it is the more the path will\n            be smoothed.\n    Returns:\n        :obj:`list` of :obj:`Point`\n    \"\"\"\n    # noise_sample = 20\n    n_points = len(points)/2\n    break_point = n_points\n\n    points_part = copy.deepcopy(points)\n    points_part = list(reversed(points_part))\n    part = kalman_filter(points_part, noise)\n    total = kalman_filter(points, noise)\n\n    result = list(reversed(part))[:break_point] + total[break_point:]\n    result[break_point] = point_mean(part[break_point], total[break_point])\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef temporal_segmentation(segments, min_time):\n    final_segments = []\n    for segment in segments:\n        final_segments.append([])\n        for point in segment:\n            if point.dt > min_time:\n                final_segments.append([])\n            final_segments[-1].append(point)\n\n    return final_segments", "response": "Returns a list of segments based on time distant points\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef correct_segmentation(segments, clusters, min_time):\n    # segments = [points for points in segments if len(points) > 1]\n\n    result_segments = []\n    prev_segment = None\n    for i, segment in enumerate(segments):\n        if len(segment) >= 1:\n            continue\n\n        cluster = clusters[i]\n        if prev_segment is None:\n            prev_segment = segment\n        else:\n            cluster_dt = 0\n            if len(cluster) > 0:\n                cluster_dt = abs(cluster[0].time_difference(cluster[-1]))\n            if cluster_dt <= min_time:\n                prev_segment.extend(segment)\n            else:\n                prev_segment.append(segment[0])\n                result_segments.append(prev_segment)\n                prev_segment = segment\n    if prev_segment is not None:\n        result_segments.append(prev_segment)\n\n    return result_segments", "response": "Corrects the predicted segmentation\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef spatiotemporal_segmentation(points, eps, min_time):\n    # min time / sample rate\n    dt_average = np.median([point.dt for point in points])\n    min_samples = min_time / dt_average\n\n    data = [point.gen3arr() for point in points]\n    data = StandardScaler().fit_transform(data)\n    print 'min_samples: %f' % min_samples\n    db_cluster = DBSCAN(eps=eps, min_samples=min_samples).fit(data)\n    labels = db_cluster.labels_\n\n    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n\n    segments = [[] for _ in range(n_clusters_+1)]\n    clusters = [[] for _ in range(n_clusters_+1)]\n    current_segment = 0\n\n    print 'clusters'\n    print n_clusters_\n    if n_clusters_ == 1:\n        segments = temporal_segmentation([points], min_time)\n        return [segment for segment in segments if len(segment) > 1]\n\n    # split segments identified with dbscan\n    for i, label in enumerate(labels):\n        if label != -1 and label + 1 != current_segment:\n            current_segment = label + 1\n        point = points[i]\n        if label == -1:\n            segments[current_segment].append(point)\n        else:\n            clusters[label + 1].append(point)\n\n    if len(segments) == 0 or sum([len(s) for s in segments]):\n        segments = [points]\n\n    segments = temporal_segmentation(segments, min_time)\n    # segments = temporal_segmentation(correct_segmentation(segments, clusters, min_time), min_time)\n    return [segment for segment in segments if len(segment) > 1]", "response": "This function splits a set of points into multiple sets of points based on the spatio - temporal stays - segmentation algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kalman_filter(points, noise):\n    kalman = ikalman.filter(noise)\n    for point in points:\n        kalman.update_velocity2d(point.lat, point.lon, point.dt)\n        (lat, lon) = kalman.get_lat_long()\n        point.lat = lat\n        point.lon = lon\n    return points", "response": "Filter a list of points with kalman filter"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts transportation modes of a track into a classifier.", "response": "def learn_transportation_mode(track, clf):\n    \"\"\" Inserts transportation modes of a track into a classifier\n\n    Args:\n        track (:obj:`Track`)\n        clf (:obj:`Classifier`)\n    \"\"\"\n    for segment in track.segments:\n        tmodes = segment.transportation_modes\n        points = segment.points\n        features = []\n        labels = []\n\n        for tmode in tmodes:\n            points_part = points[tmode['from']:tmode['to']]\n            if len(points_part) > 0:\n                features.append(extract_features_2(points_part))\n                labels.append(tmode['label'])\n\n        clf.learn(features, labels)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_features(points, n_tops):\n    max_bin = -1\n    for point in points:\n        max_bin = max(max_bin, point.vel)\n    max_bin = int(round(max_bin)) + 1\n\n    # inits histogram\n    histogram = [0] * max_bin\n    time = 0\n\n    # fills histogram\n    for point in points:\n        bin_index = int(round(point.vel))\n        histogram[bin_index] += point.dt\n        time += point.dt\n\n    result = []\n    if time == 0:\n        return result\n\n    for _ in range(n_tops):\n        max_index = np.argmax(histogram)\n        value = histogram[max_index] / time\n        result.extend([max_index, value])\n        histogram[max_index] = -1\n\n    return result", "response": "Extract features from a list of points."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the speed difference between each adjacent point", "response": "def speed_difference(points):\n    \"\"\" Computes the speed difference between each adjacent point\n\n    Args:\n        points (:obj:`Point`)\n    Returns:\n        :obj:`list` of int: Indexes of changepoints\n    \"\"\"\n    data = [0]\n    for before, after in pairwise(points):\n        data.append(before.vel - after.vel)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the accelaration difference between each adjacent point", "response": "def acc_difference(points):\n    \"\"\" Computes the accelaration difference between each adjacent point\n\n    Args:\n        points (:obj:`Point`)\n    Returns:\n        :obj:`list` of int: Indexes of changepoints\n    \"\"\"\n    data = [0]\n    for before, after in pairwise(points):\n        data.append(before.acc - after.acc)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef detect_changepoints(points, min_time, data_processor=acc_difference):\n    data = data_processor(points)\n    changepoints = pelt(normal_mean(data, np.std(data)), len(data))\n    changepoints.append(len(points) - 1)\n\n    result = []\n    for start, end in pairwise(changepoints):\n        time_diff = points[end].time_difference(points[start])\n        if time_diff > min_time:\n            result.append(start)\n\n    # adds the first point\n    result.append(0)\n    # adds the last changepoint detected\n    result.append(len(points) - 1)\n    return sorted(list(set(result)))", "response": "Detects changepoints on points that have at least a specific time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group_modes(modes):\n    if len(modes) > 0:\n        previous = modes[0]\n        grouped = []\n\n        for changep in modes[1:]:\n            if changep['label'] != previous['label']:\n                previous['to'] = changep['from']\n                grouped.append(previous)\n                previous = changep\n\n        previous['to'] = modes[-1]['to']\n        grouped.append(previous)\n        return grouped\n    else:\n        return modes", "response": "Groups consecutive transportation modes with same label into one."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distance(p_a, p_b):\n    return sqrt((p_a.lat - p_b.lat) ** 2 + (p_a.lon - p_b.lon) ** 2)", "response": "Euclidean distance between two points\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef point_line_distance(point, start, end):\n    if start == end:\n        return distance(point, start)\n    else:\n        un_dist = abs(\n            (end.lat-start.lat)*(start.lon-point.lon) - (start.lat-point.lat)*(end.lon-start.lon)\n        )\n        n_dist = sqrt(\n            (end.lat-start.lat)**2 + (end.lon-start.lon)**2\n        )\n        if n_dist == 0:\n            return 0\n        else:\n            return un_dist / n_dist", "response": "Distance from a point to a line formed by two points\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef drp(points, epsilon):\n    dmax = 0.0\n    index = 0\n\n    for i in range(1, len(points)-1):\n        dist = point_line_distance(points[i], points[0], points[-1])\n        if dist > dmax:\n            index = i\n            dmax = dist\n\n    if dmax > epsilon:\n        return drp(points[:index+1], epsilon)[:-1] + drp(points[index:], epsilon)\n    else:\n        return [points[0], points[-1]]", "response": "Douglas ramer peucker\n\n    Based on https://en.wikipedia.org/wiki/Ramer%E2%80%93Douglas%E2%80%93Peucker_algorithm\n\n    Args:\n        points (:obj:`list` of :obj:`Point`)\n        epsilon (float): drp threshold\n    Returns:\n        :obj:`list` of :obj:`Point`"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef td_sp(points, speed_threshold):\n    if len(points) <= 2:\n        return points\n    else:\n        max_speed_threshold = 0\n        found_index = 0\n        for i in range(1, len(points)-1):\n            dt1 = time_dist(points[i], points[i-1])\n            if dt1 == 0:\n                dt1 = 0.000000001\n            vim = loc_dist(points[i], points[i-1]) / dt1\n            dt2 = time_dist(points[i+1], points[i])\n            if dt2 == 0:\n                dt2 = 0.000000001\n            vi_ = loc_dist(points[i+1], points[i]) / dt2\n            if abs(vi_ - vim) > max_speed_threshold:\n                max_speed_threshold = abs(vi_ - vim)\n                found_index = i\n        if max_speed_threshold > speed_threshold:\n            one = td_sp(points[:found_index], speed_threshold)\n            two = td_sp(points[found_index:], speed_threshold)\n            one.extend(two)\n            return one\n        else:\n            return [points[0], points[-1]]", "response": "Top - Down Speed - based Trajectory Compression Algorithm"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntopping - Down Time - ratio Trajectory Compression Algorithm", "response": "def td_tr(points, dist_threshold):\n    \"\"\" Top-Down Time-Ratio Trajectory Compression Algorithm\n\n    Detailed in https://www.itc.nl/library/Papers_2003/peer_ref_conf/meratnia_new.pdf\n\n    Args:\n        points (:obj:`list` of :obj:`Point`): trajectory or part of it\n        dist_threshold (float): max distance error, in meters\n    Returns:\n        :obj:`list` of :obj:`Point`, compressed trajectory\n    \"\"\"\n    if len(points) <= 2:\n        return points\n    else:\n        max_dist_threshold = 0\n        found_index = 0\n        delta_e = time_dist(points[-1], points[0]) * I_3600\n        d_lat = points[-1].lat - points[0].lat\n        d_lon = points[-1].lon - points[0].lon\n\n        for i in range(1, len(points)-1):\n            delta_i = time_dist(points[i], points[0]) * I_3600\n\n            di_de = delta_i / delta_e\n            point = Point(\n                points[0].lat + d_lat * di_de,\n                points[0].lon + d_lon * di_de,\n                None\n            )\n\n            dist = loc_dist(points[i], point)\n            if dist > max_dist_threshold:\n                max_dist_threshold = dist\n                found_index = i\n\n        if max_dist_threshold > dist_threshold:\n            one = td_tr(points[:found_index], dist_threshold)\n            two = td_tr(points[found_index:], dist_threshold)\n            one.extend(two)\n            return one\n        else:\n            return [points[0], points[-1]]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spt(points, max_dist_error, max_speed_error):\n    if len(points) <= 2:\n        return points\n    else:\n        is_error = False\n        e = 1\n        while e < len(points) and not is_error:\n            i = 1\n            while i < e and not is_error:\n                delta_e = time_dist(points[e], points[0]) * I_3600\n                delta_i = time_dist(points[i], points[0]) * I_3600\n\n                di_de = 0\n                if delta_e != 0:\n                    di_de = delta_i / delta_e\n                d_lat = points[e].lat - points[0].lat\n                d_lon = points[e].lon - points[0].lon\n                point = Point(\n                    points[0].lat + d_lat * di_de,\n                    points[0].lon + d_lon * di_de,\n                    None\n                )\n\n                dt1 = time_dist(points[i], points[i-1])\n                if dt1 == 0:\n                    dt1 = 0.000000001\n                dt2 = time_dist(points[i+1], points[i])\n                if dt2 == 0:\n                    dt2 = 0.000000001\n\n                v_i_1 = loc_dist(points[i], points[i-1]) / dt1\n                v_i = loc_dist(points[i+1], points[i]) / dt2\n\n                if loc_dist(points[i], point) > max_dist_error or abs(v_i - v_i_1) > max_speed_error:\n                    is_error = True\n                else:\n                    i = i + 1\n            if is_error:\n                return [points[0]] + spt(points[i:len(points)], max_dist_error, max_speed_error)\n            e = e + 1\n        if not is_error:\n            return [points[0], points[len(points)-1]]", "response": "A function that returns a list of points that are in the order of distance from the first point to the second point."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_name(self, name_format=DEFAULT_FILE_NAME_FORMAT):\n        if len(self.segments) > 0:\n            return self.segments[0].points[0].time.strftime(name_format) + \".gpx\"\n        else:\n            return \"EmptyTrack\"", "response": "Generates a name for the track based on the start time of the first point of the track."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef smooth(self, strategy, noise):\n        print noise\n        for segment in self.segments:\n            segment.smooth(noise, strategy)\n        return self", "response": "In - place smoothing of segments\n           ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef infer_transportation_modes(self, dt_threshold=10):\n        self.segments = [\n            segment.infer_transportation_mode(dt_threshold=dt_threshold)\n            for segment in self.segments\n            ]\n        return self", "response": "In - place transportation inferring of segments\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef infer_location(\n            self,\n            location_query,\n            max_distance,\n            google_key,\n            foursquare_client_id,\n            foursquare_client_secret,\n            limit\n        ):\n        \"\"\"In-place location inferring of segments\n\n        Returns:\n            This track\n        \"\"\"\n        self.segments = [\n            segment.infer_location(\n                location_query,\n                max_distance,\n                google_key,\n                foursquare_client_id,\n                foursquare_client_secret,\n                limit\n            )\n            for segment in self.segments\n            ]\n        return self", "response": "In - place location inferring of segments\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a track to a JSON serializable format", "response": "def to_json(self):\n        \"\"\"Converts track to a JSON serializable format\n\n        Returns:\n            Map with the name, and segments of the track.\n        \"\"\"\n        return {\n            'name': self.name,\n            'segments': [segment.to_json() for segment in self.segments],\n            'meta': self.meta\n            }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge another track with this one and returns the new segment with the new one.", "response": "def merge_and_fit(self, track, pairings):\n        \"\"\" Merges another track with this one, ordering the points based on a\n            distance heuristic\n\n        Args:\n            track (:obj:`Track`): Track to merge with\n            pairings\n        Returns:\n            :obj:`Segment`: self\n        \"\"\"\n\n        for (self_seg_index, track_seg_index, _) in pairings:\n            self_s = self.segments[self_seg_index]\n            ss_start = self_s.points[0]\n            track_s = track.segments[track_seg_index]\n            tt_start = track_s.points[0]\n            tt_end = track_s.points[-1]\n\n            d_start = ss_start.distance(tt_start)\n            d_end = ss_start.distance(tt_end)\n\n            if d_start > d_end:\n                track_s = track_s.copy()\n                track_s.points = list(reversed(track_s.points))\n\n            self_s.merge_and_fit(track_s)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the index of the closest point in that segment and returns the segment id and point index.", "response": "def get_point_index(self, point):\n        \"\"\" Gets of the closest first point\n\n        Args:\n            point (:obj:`Point`)\n        Returns:\n            (int, int): Segment id and point index in that segment\n        \"\"\"\n        for i, segment in enumerate(self.segments):\n            idx = segment.getPointIndex(point)\n            if idx != -1:\n                return i, idx\n        return -1, -1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the bounds of the segment holding the current entry.", "response": "def bounds(self, thr=0):\n        \"\"\" Gets the bounds of this segment\n\n        Returns:\n            (float, float, float, float): Bounds, with min latitude, min longitude,\n                max latitude and max longitude\n        \"\"\"\n        min_lat = float(\"inf\")\n        min_lon = float(\"inf\")\n        max_lat = -float(\"inf\")\n        max_lon = -float(\"inf\")\n        for segment in self.segments:\n            milat, milon, malat, malon = segment.bounds(thr=thr)\n            min_lat = min(milat, min_lat)\n            min_lon = min(milon, min_lon)\n            max_lat = max(malat, max_lat)\n            max_lon = max(malon, max_lon)\n        return min_lat, min_lon, max_lat, max_lon"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef similarity(self, track):\n        idx = index.Index()\n        i = 0\n        for i, segment in enumerate(self.segments):\n            idx.insert(i, segment.bounds(), obj=segment)\n\n        final_siml = []\n        final_diff = []\n        for i, segment in enumerate(track.segments):\n            query = idx.intersection(segment.bounds(), objects=True)\n\n            res_siml = []\n            res_diff = []\n            for result in query:\n                siml, diff = segment_similarity(segment, result.object)\n                res_siml.append(siml)\n                res_diff.append((result.id, i, diff))\n\n            if len(res_siml) > 0:\n                final_siml.append(max(res_siml))\n                final_diff.append(res_diff[np.argmax(res_siml)])\n            else:\n                final_siml.append(0)\n                final_diff.append([])\n\n        return np.mean(final_siml), final_diff", "response": "Compares two tracks based on their topology and returns the global similarity between the two tracks."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_gpx(self):\n        gpx_segments = []\n        for segment in self.segments:\n            gpx_points = []\n            for point in segment.points:\n                time = ''\n                if point.time:\n                    iso_time = point.time.isoformat().split('.')[0]\n                    time = '<time>%s</time>' % iso_time\n                gpx_points.append(\n                    u'<trkpt lat=\"%f\" lon=\"%f\">%s</trkpt>' % (point.lat, point.lon, time)\n                )\n            points = u'\\n\\t\\t\\t'.join(gpx_points)\n            gpx_segments.append(u'\\t\\t<trkseg>\\n\\t\\t\\t%s\\n\\t\\t</trkseg>' % points)\n        segments = u'\\t\\n'.join(gpx_segments)\n        content = [\n            u'<?xml version=\"1.0\" encoding=\"UTF-8\"?>',\n            u'<gpx xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://www.topografix.com/GPX/1/0\" xsi:schemaLocation=\"http://www.topografix.com/GPX/1/0 http://www.topografix.com/GPX/1/0/gpx.xsd\" version=\"1.0\" creator=\"GatherMySteps\">',\n            u'\\t<trk>',\n            segments,\n            u'\\t</trk>',\n            u'</gpx>'\n        ]\n\n        return u'\\n'.join(content)", "response": "Converts the track to a GPX format"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the timezone of the entire track", "response": "def timezone(self, timezone=0):\n        \"\"\" Sets the timezone of the entire track\n\n        Args:\n            timezone (int): Timezone hour delta\n\n        \"\"\"\n        tz_dt = timedelta(hours=timezone)\n        for segment in self.segments:\n            for point in segment.points:\n                point.time = point.time + tz_dt\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the track to LIFE format", "response": "def to_life(self):\n        \"\"\"Converts track to LIFE format\n        \"\"\"\n        buff = \"--%s\\n\" % self.segments[0].points[0].time.strftime(\"%Y_%m_%d\")\n        # buff += \"--\" + day\n        # buff += \"UTC+s\" # if needed\n\n        def military_time(time):\n            \"\"\" Converts time to military time\n\n            Args:\n                time (:obj:`datetime.datetime`)\n            Returns:\n                str: Time in the format 1245 (12 hours and 45 minutes)\n            \"\"\"\n            return time.strftime(\"%H%M\")\n\n        def stay(buff, start, end, place):\n            \"\"\" Creates a stay representation\n\n            Args:\n                start (:obj:`datetime.datetime` or str)\n                end (:obj:`datetime.datetime` or str)\n                place (:obj:`Location`)\n            Returns:\n                str\n            \"\"\"\n            if not isinstance(start, str):\n                start = military_time(start)\n            if not isinstance(end, str):\n                end = military_time(end)\n\n            return \"%s\\n%s-%s: %s\" % (buff, start, end, place.label)\n\n        def trip(buff, segment):\n            \"\"\" Creates a trip representation\n\n            Args:\n                buff (str): buffer\n                segment (:obj:`Segment`)\n            Returns:\n                str: buffer and trip representation\n            \"\"\"\n            trip = \"%s-%s: %s -> %s\" % (\n                military_time(segment.points[0].time),\n                military_time(segment.points[-1].time),\n                segment.location_from.label,\n                segment.location_to.label\n            )\n\n            t_modes = segment.transportation_modes\n            if len(t_modes) == 1:\n                trip = \"%s [%s]\" % (trip, t_modes[0]['label'])\n            elif len(t_modes) > 1:\n                modes = []\n                for mode in t_modes:\n                    trip_from = military_time(segment.points[mode['from']].time)\n                    trip_to = military_time(segment.points[mode['to']].time)\n                    modes.append(\"    %s-%s: [%s]\" % (trip_from, trip_to, mode['label']))\n                trip = \"%s\\n%s\" % (trip, \"\\n\".join(modes))\n\n            return \"%s\\n%s\" % (buff, trip)\n\n        last = len(self.segments) - 1\n        for i, segment in enumerate(self.segments):\n            if i == 0:\n                buff = stay(\n                    buff,\n                    \"0000\",\n                    military_time(segment.points[0].time),\n                    segment.location_from\n                )\n            buff = trip(buff, segment)\n            if i is last:\n                buff = stay(\n                    buff,\n                    military_time(segment.points[-1].time),\n                    \"2359\",\n                    segment.location_to\n                )\n            else:\n                next_seg = self.segments[i+1]\n                buff = stay(\n                    buff,\n                    military_time(segment.points[-1].time),\n                    military_time(next_seg.points[0].time),\n                    segment.location_to\n                )\n\n        return buff"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_gpx(file_path):\n        gpx = gpxpy.parse(open(file_path, 'r'))\n        file_name = basename(file_path)\n\n        tracks = []\n        for i, track in enumerate(gpx.tracks):\n            segments = []\n            for segment in track.segments:\n                segments.append(Segment.from_gpx(segment))\n\n            if len(gpx.tracks) > 1:\n                name = file_name + \"_\" + str(i)\n            else:\n                name = file_name\n            tracks.append(Track(name, segments))\n\n        return tracks", "response": "Creates a list of Tracks from a GPX file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_json(json):\n        segments = [Segment.from_json(s) for s in json['segments']]\n        return Track(json['name'], segments).compute_metrics()", "response": "Creates a Track instance from a JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalize(p):\n    l = math.sqrt(p[0]**2 + p[1]**2)\n    return [0.0, 0.0] if l == 0 else [p[0]/l, p[1]/l]", "response": "Normalizes a point to a vector\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a line from two points p1 and p2.", "response": "def line(p1, p2):\n    \"\"\"Creates a line from two points\n\n    From http://stackoverflow.com/a/20679579\n\n    Args:\n        p1 ([float, float]): x and y coordinates\n        p2 ([float, float]): x and y coordinates\n    Returns:\n        (float, float, float): x, y and _\n    \"\"\"\n    A = (p1[1] - p2[1])\n    B = (p2[0] - p1[0])\n    C = (p1[0]*p2[1] - p2[0]*p1[1])\n    return A, B, -C"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef intersection(L1, L2):\n    D = L1[0] * L2[1] - L1[1] * L2[0]\n    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n    if D != 0:\n        x = Dx / D\n        y = Dy / D\n        return x, y\n    else:\n        return False", "response": "Intersects two line segments L1 and L2 Returns x y of intersection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef closest_point(a, b, p):\n    ap = [p[0]-a[0], p[1]-a[1]]\n    ab = [b[0]-a[0], b[1]-a[1]]\n    mag = float(ab[0]**2 + ab[1]**2)\n    proj = dot(ap, ab)\n    if mag ==0 :\n        dist = 0\n    else:\n        dist = proj / mag\n    if dist < 0:\n        return [a[0], a[1]]\n    elif dist > 1:\n        return [b[0], b[1]]\n    else:\n        return [a[0] + ab[0] * dist, a[1] + ab[1] * dist]", "response": "Finds the closest point in a line segment in a line segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the distance similarity between a line segment and a point.", "response": "def distance_similarity(a, b, p, T=CLOSE_DISTANCE_THRESHOLD):\n    \"\"\"Computes the distance similarity between a line segment\n    and a point\n\n    Args:\n        a ([float, float]): x and y coordinates. Line start\n        b ([float, float]): x and y coordinates. Line end\n        p ([float, float]): x and y coordinates. Point to compute the distance\n    Returns:\n        float: between 0 and 1. Where 1 is very similar and 0 is completely different\n    \"\"\"\n    d = distance_to_line(a, b, p)\n    r = (-1/float(T)) * abs(d) + 1\n\n    return r if r > 0 else 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef line_distance_similarity(p1a, p1b, p2a, p2b, T=CLOSE_DISTANCE_THRESHOLD):\n    d1 = distance_similarity(p1a, p1b, p2a, T=T)\n    d2 = distance_similarity(p1a, p1b, p2b, T=T)\n    return abs(d1 + d2) * 0.5", "response": "Line distance similarity between two line segments p1a and p2a and p2b."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef line_similarity(p1a, p1b, p2a, p2b, T=CLOSE_DISTANCE_THRESHOLD):\n    d = line_distance_similarity(p1a, p1b, p2a, p2b, T=T)\n    a = abs(angle_similarity(normalize(line(p1a, p1b)), normalize(line(p2a, p2b))))\n    return d * a", "response": "Similarity between two lines p1a and p2a."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bounding_box_from(points, i, i1, thr):\n    pi = points[i]\n    pi1 = points[i1]\n\n    min_lat = min(pi.lat, pi1.lat)\n    min_lon = min(pi.lon, pi1.lon)\n    max_lat = max(pi.lat, pi1.lat)\n    max_lon = max(pi.lon, pi1.lon)\n\n    return min_lat-thr, min_lon-thr, max_lat+thr, max_lon+thr", "response": "Creates a bounding box for a line segment in the array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef segment_similarity(A, B, T=CLOSE_DISTANCE_THRESHOLD):\n    l_a = len(A.points)\n    l_b = len(B.points)\n\n    idx = index.Index()\n    dex = 0\n    for i in range(l_a-1):\n        idx.insert(dex, bounding_box_from(A.points, i, i+1, T), obj=[A.points[i], A.points[i+1]])\n        dex = dex + 1\n\n    prox_acc = []\n\n    for i in range(l_b-1):\n        ti = B.points[i].gen2arr()\n        ti1 = B.points[i+1].gen2arr()\n        bb = bounding_box_from(B.points, i, i+1, T)\n        intersects = idx.intersection(bb, objects=True)\n        n_prox = []\n        i_prox = 0\n        a = 0\n        for x in intersects:\n            a = a + 1\n            pi = x.object[0].gen2arr()\n            pi1 = x.object[1].gen2arr()\n            prox = line_similarity(ti, ti1, pi, pi1, T)\n            i_prox = i_prox + prox\n            n_prox.append(prox)\n\n        if a != 0:\n            prox_acc.append(i_prox / a)\n            # prox_acc.append(max(n_prox))\n        else:\n            prox_acc.append(0)\n\n    return np.mean(prox_acc), prox_acc", "response": "Computes the similarity between two segmentsA and B."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake two line segments and sorts all their points and returns a list of ordered segment points", "response": "def sort_segment_points(Aps, Bps):\n    \"\"\"Takes two line segments and sorts all their points,\n    so that they form a continuous path\n\n    Args:\n        Aps: Array of tracktotrip.Point\n        Bps: Array of tracktotrip.Point\n    Returns:\n        Array with points ordered\n    \"\"\"\n    mid = []\n    j = 0\n    mid.append(Aps[0])\n    for i in range(len(Aps)-1):\n        dist = distance_tt_point(Aps[i], Aps[i+1])\n        for m in range(j, len(Bps)):\n            distm = distance_tt_point(Aps[i], Bps[m])\n            if dist > distm:\n                direction = dot(normalize(line(Aps[i].gen2arr(), Aps[i+1].gen2arr())), normalize(Bps[m].gen2arr()))\n                if direction > 0:\n                    j = m + 1\n                    mid.append(Bps[m])\n                    break\n\n        mid.append(Aps[i+1])\n    for m in range(j, len(Bps)):\n        mid.append(Bps[m])\n    return mid"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef distance(latitude_1, longitude_1, elevation_1, latitude_2, longitude_2, elevation_2,\n             haversine=None):\n    \"\"\" Distance between two points \"\"\"\n\n    # If points too distant -- compute haversine distance:\n    if haversine or (abs(latitude_1 - latitude_2) > .2 or abs(longitude_1 - longitude_2) > .2):\n        return haversine_distance(latitude_1, longitude_1, latitude_2, longitude_2)\n\n    coef = math.cos(latitude_1 / 180. * math.pi)\n    #pylint: disable=invalid-name\n    x = latitude_1 - latitude_2\n    y = (longitude_1 - longitude_2) * coef\n\n    distance_2d = math.sqrt(x * x + y * y) * ONE_DEGREE\n\n    if elevation_1 is None or elevation_2 is None or elevation_1 == elevation_2:\n        return distance_2d\n\n    return math.sqrt(distance_2d ** 2 + (elevation_1 - elevation_2) ** 2)", "response": "Compute distance between two points"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef distance(self, other):\n        return distance(self.lat, self.lon, None, other.lat, other.lon, None)", "response": "Distance between two points in km"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the metrics of this point and updates the dt vel and acc attributes.", "response": "def compute_metrics(self, previous):\n        \"\"\" Computes the metrics of this point\n\n        Computes and updates the dt, vel and acc attributes.\n\n        Args:\n            previous (:obj:`Point`): Point before\n        Returns:\n            :obj:`Point`: Self\n        \"\"\"\n        delta_t = self.time_difference(previous)\n        delta_x = self.distance(previous)\n        vel = 0\n        delta_v = 0\n        acc = 0\n        if delta_t != 0:\n            vel = delta_x/delta_t\n            delta_v = vel - previous.vel\n            acc = delta_v/delta_t\n\n        self.dt = delta_t\n        self.dx = delta_x\n        self.acc = acc\n        self.vel = vel\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a point from a GPX representation of a point.", "response": "def from_gpx(gpx_track_point):\n        \"\"\" Creates a point from GPX representation\n\n        Arguments:\n            gpx_track_point (:obj:`gpxpy.GPXTrackPoint`)\n        Returns:\n            :obj:`Point`\n        \"\"\"\n        return Point(\n            lat=gpx_track_point.latitude,\n            lon=gpx_track_point.longitude,\n            time=gpx_track_point.time\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_json(self):\n        return {\n            'lat': self.lat,\n            'lon': self.lon,\n            'time': self.time.isoformat() if self.time is not None else None\n        }", "response": "Returns a JSON serializable representation of this instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a Point instance from a JSON representation of a single object.", "response": "def from_json(json):\n        \"\"\" Creates Point instance from JSON representation\n\n        Args:\n            json (:obj:`dict`): Must have at least the following keys: lat (float), lon (float),\n                time (string in iso format). Example,\n                {\n                    \"lat\": 9.3470298,\n                    \"lon\": 3.79274,\n                    \"time\": \"2016-07-15T15:27:53.574110\"\n                }\n            json: map representation of Point instance\n        Returns:\n            :obj:`Point`\n        \"\"\"\n        return Point(\n            lat=json['lat'],\n            lon=json['lon'],\n            time=isostr_to_datetime(json['time'])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_centroid(points):\n    lats = [p[1] for p in points]\n    lons = [p[0] for p in points]\n    return Point(np.mean(lats), np.mean(lons), None)", "response": "Computes the centroid of a set of points."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the centroid of a location cluster with another point.", "response": "def update_location_centroid(point, cluster, max_distance, min_samples):\n    \"\"\" Updates the centroid of a location cluster with another point\n\n    Args:\n        point (:obj:`Point`): Point to add to the cluster\n        cluster (:obj:`list` of :obj:`Point`): Location cluster\n        max_distance (float): Max neighbour distance\n        min_samples (int): Minimum number of samples\n    Returns:\n        (:obj:`Point`, :obj:`list` of :obj:`Point`): Tuple with the location centroid\n            and new point cluster (given cluster + given point)\n    \"\"\"\n    cluster.append(point)\n    points = [p.gen2arr() for p in cluster]\n\n    # Estimates the epsilon\n    eps = estimate_meters_to_deg(max_distance, precision=6)\n\n    p_cluster = DBSCAN(eps=eps, min_samples=min_samples)\n    p_cluster.fit(points)\n\n    clusters = {}\n    for i, label in enumerate(p_cluster.labels_):\n        if label in clusters.keys():\n            clusters[label].append(points[i])\n        else:\n            clusters[label] = [points[i]]\n\n    centroids = []\n    biggest_centroid_l = -float(\"inf\")\n    biggest_centroid = None\n\n    for label, n_cluster in clusters.items():\n        centroid = compute_centroid(n_cluster)\n        centroids.append(centroid)\n\n        if label >= 0 and len(n_cluster) >= biggest_centroid_l:\n            biggest_centroid_l = len(n_cluster)\n            biggest_centroid = centroid\n\n    if biggest_centroid is None:\n        biggest_centroid = compute_centroid(points)\n\n    return biggest_centroid, cluster"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_foursquare(point, max_distance, client_id, client_secret):\n    if not client_id:\n        return []\n    if not client_secret:\n        return []\n\n    if from_cache(FS_CACHE, point, max_distance):\n        return from_cache(FS_CACHE, point, max_distance)\n\n    url = FOURSQUARE_URL % (client_id, client_secret, point.lat, point.lon, max_distance)\n    req = requests.get(url)\n\n    if req.status_code != 200:\n        return []\n    response = req.json()\n\n    result = []\n    venues = response['response']['venues']\n\n    for venue in venues:\n        name = venue['name']\n        distance = venue['location']['distance']\n        categories = [c['shortName'] for c in venue['categories']]\n        result.append({\n            'label': name,\n            'distance': distance,\n            'types': categories,\n            'suggestion_type': 'FOURSQUARE'\n        })\n\n    # final_results = sorted(result, key=lambda elm: elm['distance'])\n    foursquare_insert_cache(point, result)\n    return result", "response": "Queries Squarespace API for a location."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries google maps API for a location", "response": "def query_google(point, max_distance, key):\n    \"\"\" Queries google maps API for a location\n\n    Args:\n        point (:obj:`Point`): Point location to query\n        max_distance (float): Search radius, in meters\n        key (str): Valid google maps api key\n    Returns:\n        :obj:`list` of :obj:`dict`: List of locations with the following format:\n            {\n                'label': 'Coffee house',\n                'types': 'Commerce',\n                'suggestion_type': 'GOOGLE'\n            }\n    \"\"\"\n    if not key:\n        return []\n\n    if from_cache(GG_CACHE, point, max_distance):\n        return from_cache(GG_CACHE, point, max_distance)\n\n    req = requests.get(GOOGLE_PLACES_URL % (\n        point.lat,\n        point.lon,\n        max_distance,\n        key\n    ))\n\n    if req.status_code != 200:\n        return []\n    response = req.json()\n    results = response['results']\n    # l = len(results)\n    final_results = []\n    for local in results:\n        final_results.append({\n            'label': local['name'],\n            'distance': Point(local['geometry']['location']['lat'], local['geometry']['location']['lng'], None).distance(point),\n            # 'rank': (l-i)/float(l),\n            'types': local['types'],\n            'suggestion_type': 'GOOGLE'\n            })\n\n    google_insert_cache(point, final_results)\n    return final_results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef infer_location(\n        point,\n        location_query,\n        max_distance,\n        google_key,\n        foursquare_client_id,\n        foursquare_client_secret,\n        limit\n    ):\n    \"\"\" Infers the semantic location of a (point) place.\n\n    Args:\n        points (:obj:`Point`): Point location to infer\n        location_query: Function with signature, (:obj:`Point`, int) -> (str, :obj:`Point`, ...)\n        max_distance (float): Max distance to a position, in meters\n        google_key (str): Valid google maps api key\n        foursquare_client_id (str): Valid Foursquare client id\n        foursquare_client_secret (str): Valid Foursquare client secret\n        limit (int): Results limit\n    Returns:\n        :obj:`Location`: with top match, and alternatives\n    \"\"\"\n    locations = []\n\n    if location_query is not None:\n        queried_locations = location_query(point, max_distance)\n        for (label, centroid, _) in queried_locations:\n            locations.append({\n                'label': unicode(label, 'utf-8'),\n                'distance': centroid.distance(point),\n                # 'centroid': centroid,\n                'suggestion_type': 'KB'\n                })\n\n    api_locations = []\n    if len(locations) <= limit:\n        if google_key:\n            google_locs = query_google(point, max_distance, google_key)\n            api_locations.extend(google_locs)\n        if foursquare_client_id and foursquare_client_secret:\n            foursquare_locs = query_foursquare(\n                point,\n                max_distance,\n                foursquare_client_id,\n                foursquare_client_secret\n            )\n            api_locations.extend(foursquare_locs)\n\n    if len(locations) > 0 or len(api_locations) > 0:\n        locations = sorted(locations, key=lambda d: d['distance'])\n        api_locations = sorted(api_locations, key=lambda d: d['distance'])\n        locations = (locations + api_locations)[:limit]\n        return Location(locations[0]['label'], point, locations)\n    else:\n        return Location('#?', point, [])", "response": "Infers the semantic location of a point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef estimate_meters_to_deg(meters, precision=PRECISION_PERSON):\n    line = PRECISION_TABLE[precision]\n    dec = 1/float(10 ** precision)\n    return meters / line[3] * dec", "response": "Meters to degrees estimation\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef isostr_to_datetime(dt_str):\n    if len(dt_str) <= 20:\n        return datetime.datetime.strptime(dt_str, \"%Y-%m-%dT%H:%M:%SZ\")\n    else:\n        dt_str = dt_str.split(\".\")\n        return isostr_to_datetime(\"%sZ\" % dt_str[0])", "response": "Converts an ISO formated text string into a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pairwise(iterable):\n    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n    now, nxt = tee(iterable)\n    next(nxt, None)\n    return izip(now, nxt)", "response": "s -> s0 s1 s2 s3..."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlearn new labels, this method is intended for internal use Args: labels (:obj:`list` of :obj:`str`): Labels to learn", "response": "def __learn_labels(self, labels):\n        \"\"\" Learns new labels, this method is intended for internal use\n\n        Args:\n            labels (:obj:`list` of :obj:`str`): Labels to learn\n        \"\"\"\n        if self.feature_length > 0:\n            result = list(self.labels.classes_)\n        else:\n            result = []\n\n        for label in labels:\n            result.append(label)\n        self.labels.fit(result)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlearn the classifier with the given features and labels.", "response": "def learn(self, features, labels):\n        \"\"\" Fits the classifier\n\n        If it's state is empty, the classifier is fitted, if not\n        the classifier is partially fitted.\n        See sklearn's SGDClassifier fit and partial_fit methods.\n\n        Args:\n            features (:obj:`list` of :obj:`list` of :obj:`float`)\n            labels (:obj:`list` of :obj:`str`): Labels for each set of features.\n                New features are learnt.\n        \"\"\"\n        labels = np.ravel(labels)\n        self.__learn_labels(labels)\n        if len(labels) == 0:\n            return\n\n        labels = self.labels.transform(labels)\n        if self.feature_length > 0 and hasattr(self.clf, 'partial_fit'):\n            # FIXME? check docs, may need to pass class=[...]\n            self.clf = self.clf.partial_fit(features, labels)\n        else:\n            self.clf = self.clf.fit(features, labels)\n            self.feature_length = len(features[0])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npredict the probability of each feature in the set of classes.", "response": "def predict(self, features, verbose=False):\n        \"\"\" Probability estimates of each feature\n\n        See sklearn's SGDClassifier predict and predict_proba methods.\n\n        Args:\n            features (:obj:`list` of :obj:`list` of :obj:`float`)\n            verbose: Boolean, optional. If true returns an array where each\n                element is a dictionary, where keys are labels and values are\n                the respective probabilities. Defaults to False.\n        Returns:\n            Array of array of numbers, or array of dictionaries if verbose i\n            True\n        \"\"\"\n        probs = self.clf.predict_proba(features)\n        if verbose:\n            labels = self.labels.classes_\n            res = []\n            for prob in probs:\n                vals = {}\n                for i, val in enumerate(prob):\n                    label = labels[i]\n                    vals[label] = val\n                res.append(vals)\n            return res\n        else:\n            return probs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_adapter(file_or_path):\n    if is_file(file_or_path):\n        file_obj = file_or_path\n    else:\n        file_obj = open(file_or_path, 'rb')\n    yield file_obj\n    file_obj.close()", "response": "Context manager that works similar to open but also accepts already openned file - like objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading source from 3 csv files.", "response": "def source_loader(self, source_paths, create_missing_tables=True):\n        \"\"\"Load source from 3 csv files.\n\n        First file should contain global settings:\n\n        * ``native_lagnauge,languages`` header on first row\n        * appropriate values on following rows\n\n        Example::\n\n            native_lagnauge,languages\n            ru,ru\n              ,en\n\n        Second file should contain templates:\n\n        * ``template_name,probability,genders,template`` header on first row\n        * appropriate values on following rows (separate values with semicolon \";\" in template column)\n\n        Example::\n\n            template_name,probability,genders,template\n            male_1,5,m,prefixes;male_suffixes\n            baby_1,1,m;f,prefixes;descriptive\n\n        Third file should contain tables with values for template slugs in all languages:\n\n        * first row should contain slugs with language code after colon for each\n        * appropriate values on following rows. Multiple forms may be specified using semicolon as separator\n\n        Example::\n\n            prefixes:ru,prefixes:en,male_suffixes:ru,male_suffixes:en,descriptive:ru,descriptive:en\n            \u0411\u0436,Bzh,\u043f\u0440\u0430,pra,\u0431\u044b\u0441\u0442\u0440\u044f\u043a;\u0431\u044b\u0441\u0442\u0440\u044f\u043a\u0443,fasty\n            \u0434\u043e\u043d;\u0434\u043e\u043d\u0443,don,\u0418\u0432\u0430\u043d;\u0418\u0432\u0430\u043d\u0443,Ivan,\u0418\u0432\u0430\u043d\u043e\u0432;\u0418\u0432\u0430\u043d\u043e\u0432\u0443,Ivanov\n\n        Note: you may use slugs without \":lang_code\" suffix in csv header of tables file. Such headers will be treated as headers for native language\n\n        If tables are missing for some slug then it is automatically created with values equeal to slug itself.\n        So you may use some slugs without specifying tables data for them. Example for apostrophe and space:\n\n            male_1,5,m,prefixes;';male_suffixes\n            male_full,5,m,first_name; ;last_name\n\n        \"\"\"\n        if not isinstance(source_paths, Iterable) or len(source_paths) < 3:\n            raise TypeError('FromCSVTablesGenerator.source_loader accepts list of 3 paths as argument. Got `%s` instead' % source_paths)\n        self.native_language = ''\n        self.languages = []\n        self.templates = []\n        self.tables = {}\n\n        self.load_settings(source_paths[0])\n        template_slugs = self.load_templates(source_paths[1])\n        self.load_tables(source_paths[2])\n\n        if create_missing_tables:\n            self.create_missing_tables(template_slugs)\n\n        self.full_forms_for_languages = set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload image from URL and preprocess for Resnet.", "response": "def loader():\n    \"\"\"Load image from URL, and preprocess for Resnet.\"\"\"\n    url = request.args.get('url')  # read image URL as a request URL param\n    response = requests.get(url)  # make request to static image file\n    return response.content"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmaps prediction tensor to labels.", "response": "def postprocessor(prediction):\n    \"\"\"Map prediction tensor to labels.\"\"\"\n    prediction = prediction.data.numpy()[0]\n    top_predictions = prediction.argsort()[-3:][::-1]\n    return [labels[prediction] for prediction in top_predictions]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a logger with the specified name.", "response": "def get_logger(name):\n    \"\"\"Get a logger with the specified name.\"\"\"\n    logger = logging.getLogger(name)\n    logger.setLevel(getenv('LOGLEVEL', 'INFO'))\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure data is serializable.", "response": "def make_serializable(data):\n    \"\"\"Ensure data is serializable.\"\"\"\n    if is_serializable(data):\n        return data\n\n    # if numpy array convert to list\n    try:\n        return data.tolist()\n    except AttributeError:\n        pass\n    except Exception as e:\n        logger.debug('{} exception ({}): {}'.format(type(e).__name__, e, data))\n\n    # try serializing each child element\n    if isinstance(data, dict):\n        return {key: make_serializable(value) for key, value in data.items()}\n    try:\n        return [make_serializable(element) for element in data]\n    except TypeError:  # not iterable\n        pass\n    except Exception:\n        logger.debug('Could not serialize {}; converting to string'.format(data))\n\n    # last resort: convert to string\n    return str(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading data from JSON request and convert to numpy array.", "response": "def json_numpy_loader():\n    \"\"\"Load data from JSON request and convert to numpy array.\"\"\"\n    data = request.get_json()\n    logger.debug('Received JSON data of length {:,}'.format(len(data)))\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_bytes_to_image_callback(image_dims=(224, 224)):\n    from keras.preprocessing import image\n    import numpy as np\n    from PIL import Image\n    from io import BytesIO\n\n    def preprocess_image_bytes(data_bytes):\n        \"\"\"Process image bytes for ImageNet.\"\"\"\n        try:\n            img = Image.open(BytesIO(data_bytes))  # open image\n        except OSError as e:\n            raise ValueError('Please provide a raw image')\n        img = img.resize(image_dims, Image.ANTIALIAS)  # model requires 224x224 pixels\n        x = image.img_to_array(img)  # convert image to numpy array\n        x = np.expand_dims(x, axis=0)  # model expects dim 0 to be iterable across images\n        return x\n    return preprocess_image_bytes", "response": "Return a callback to process image bytes for ImageNet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exception_log_and_respond(exception, logger, message, status_code):\n    logger.error(message, exc_info=True)\n    return make_response(\n        message,\n        status_code,\n        dict(exception_type=type(exception).__name__, exception_message=str(exception)),\n    )", "response": "Log an error and send a jsonified response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a jsonified response with specified message and status code.", "response": "def make_response(message, status_code, details=None):\n    \"\"\"Make a jsonified response with specified message and status code.\"\"\"\n    response_body = dict(message=message)\n    if details:\n        response_body['details'] = details\n    response = jsonify(response_body)\n    response.status_code = status_code\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an endpoint to serve predictions from a specific object.", "response": "def _create_prediction_endpoint(\n            self,\n            to_numpy=True,\n            data_loader=json_numpy_loader,\n            preprocessor=lambda x: x,\n            input_validation=lambda data: (True, None),\n            postprocessor=lambda x: x,\n            make_serializable_post=True):\n        \"\"\"Create an endpoint to serve predictions.\n\n        Arguments:\n            - input_validation (fn): takes a numpy array as input;\n                returns True if validation passes and False otherwise\n            - data_loader (fn): reads flask request and returns data preprocessed to be\n                used in the `predict` method\n            - postprocessor (fn): transforms the predictions from the `predict` method\n        \"\"\"\n        # copy instance variables to local scope for resource class\n        predict = self.predict\n        logger = self.app.logger\n\n        # create restful resource\n        class Predictions(Resource):\n            @staticmethod\n            def post():\n                # read data from API request\n                try:\n                    data = data_loader()\n                except Exception as e:\n                    return exception_log_and_respond(e, logger, 'Unable to fetch data', 400)\n\n                try:\n                    if hasattr(preprocessor, '__iter__'):\n                        for preprocessor_step in preprocessor:\n                            data = preprocessor_step(data)\n                    else:\n                        data = preprocessor(data)  # preprocess data\n                    data = np.array(data) if to_numpy else data  # convert to numpy\n                except Exception as e:\n                    return exception_log_and_respond(e, logger, 'Could not preprocess data', 400)\n\n                # sanity check using user defined callback (default is no check)\n                validation_pass, validation_reason = input_validation(data)\n                if not validation_pass:\n                    # if validation fails, log the reason code, log the data, and send a 400 response\n                    validation_message = 'Input validation failed with reason: {}'.format(validation_reason)\n                    logger.error(validation_message)\n                    logger.debug('Data: {}'.format(data))\n                    return make_response(validation_message, 400)\n\n                try:\n                    prediction = predict(data)\n                except Exception as e:\n                    # log exception and return the message in a 500 response\n                    logger.debug('Data: {}'.format(data))\n                    return exception_log_and_respond(e, logger, 'Unable to make prediction', 500)\n                logger.debug(prediction)\n                try:\n                    # preprocess data\n                    if hasattr(postprocessor, '__iter__'):\n                        for postprocessor_step in postprocessor:\n                            prediction = postprocessor_step(prediction)\n                    else:\n                        prediction = postprocessor(prediction)\n\n                    # cast to serializable types\n                    if make_serializable_post:\n                        return make_serializable(prediction)\n                    else:\n                        return prediction\n\n                except Exception as e:\n                    return exception_log_and_respond(e, logger, 'Postprocessing failed', 500)\n\n        # map resource to endpoint\n        self.api.add_resource(Predictions, '/predictions')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an endpoint to serve the info data for the given name.", "response": "def create_info_endpoint(self, name, data):\n        \"\"\"Create an endpoint to serve info GET requests.\"\"\"\n        # make sure data is serializable\n        data = make_serializable(data)\n\n        # create generic restful resource to serve static JSON data\n        class InfoBase(Resource):\n            @staticmethod\n            def get():\n                return data\n\n        def info_factory(name):\n            \"\"\"Return an Info derivative resource.\"\"\"\n            class NewClass(InfoBase):\n                pass\n            NewClass.__name__ = \"{}_{}\".format(name, InfoBase.__name__)\n            return NewClass\n\n        path = '/info/{}'.format(name)\n        self.api.add_resource(info_factory(name), path)\n        logger.info('Regestered informational resource to {} (available via GET)'.format(path))\n        logger.debug('Endpoint {} will now serve the following static data:\\n{}'.format(path, data))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an endpoint to serve the model info.", "response": "def _create_model_info_endpoint(self, path='/info/model'):\n        \"\"\"Create an endpoint to serve info GET requests.\"\"\"\n        model = self.model\n\n        # parse model details\n        model_details = {}\n        for key, value in model.__dict__.items():\n            model_details[key] = make_serializable(value)\n\n        # create generic restful resource to serve model information as JSON\n        class ModelInfo(Resource):\n            @staticmethod\n            def get():\n                return model_details\n\n        self.api.add_resource(ModelInfo, path)\n        self.app.logger.info('Regestered informational resource to {} (available via GET)'.format(path))\n        self.app.logger.debug('Endpoint {} will now serve the following static data:\\n{}'.format(path, model_details))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserving predictions as an API endpoint.", "response": "def serve(self, host='127.0.0.1', port=5000):\n        \"\"\"Serve predictions as an API endpoint.\"\"\"\n        from meinheld import server, middleware\n        # self.app.run(host=host, port=port)\n        server.listen((host, port))\n        server.run(middleware.WebSocketMiddleware(self.app))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_model(input_dim):\n    model = Sequential()\n    model.add(Dense(100, input_dim=input_dim, activation='sigmoid'))\n    model.add(Dense(1))\n    model.compile(loss='mean_squared_error', optimizer='SGD')\n    return model", "response": "Create and compile a simple model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validator(input_data):\n    global data\n    # check num dims\n    if input_data.ndim != 2:\n        return False, 'Data should have two dimensions.'\n    # check number of columns\n    if input_data.shape[1] != data.data.shape[1]:\n        reason = '{} features required, {} features provided'.format(\n            data.data.shape[1], input_data.shape[1])\n        return False, reason\n    # validation passed\n    return True, None", "response": "Simple model input validator."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_chd_header(chd_file):\n\n    with open(chd_file, \"rb\") as f:\n        header = {\n            \"cinefileheader\": cine.CINEFILEHEADER(),\n            \"bitmapinfoheader\": cine.BITMAPINFOHEADER(),\n            \"setup\": cine.SETUP(),\n        }\n        f.readinto(header[\"cinefileheader\"])\n        f.readinto(header[\"bitmapinfoheader\"])\n        f.readinto(header[\"setup\"])\n\n    return header", "response": "read the. chd header file created when Vision Research software saves the images in a file format other than. cine\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch_list(version=None):\n\n    if version is None:\n        versions = short_versions\n    else:\n        versions = [get_canonical_version(version)]\n\n    for version in versions:\n\n        url = \"http://docs.python.org/{}/objects.inv\".format(version)\n\n        modules = sorted(\n            list(\n                fetch_inventory(DummyApp(), \"\", url).get(\"py:module\").keys()\n            )\n        )\n\n        with open(os.path.join(list_dir, \"{}.txt\".format(version)), \"w\") as f:\n            for module in modules:\n                f.write(module)\n                f.write(\"\\n\")", "response": "Fetches the list of modules from the given version of Python and writes them to file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a version return a list of names of the Python Standard Libraries for that version.", "response": "def stdlib_list(version=None):\n    \"\"\"\n    Given a ``version``, return a ``list`` of names of the Python Standard\n    Libraries for that version. These names are obtained from the Sphinx inventory\n    file (used in :py:mod:`sphinx.ext.intersphinx`).\n\n    :param str|None version: The version (as a string) whose list of libraries you want\n    (one of ``\"2.6\"``, ``\"2.7\"``, ``\"3.2\"``, ``\"3.3\"``, ``\"3.4\"``, or ``\"3.5\"``).\n    If not specified, the current version of Python will be used.\n\n    :return: A list of standard libraries from the specified version of Python\n    :rtype: list\n    \"\"\"\n\n    version = get_canonical_version(version) if version is not None else '.'.join(\n        str(x) for x in sys.version_info[:2])\n\n    module_list_file = os.path.join(list_dir, \"{}.txt\".format(version))\n\n    with open(module_list_file) as f:\n        result = [y for y in [x.strip() for x in f.readlines()] if y]\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autohash(include=None,                # type: Union[str, Tuple[str]]\n             exclude=None,                # type: Union[str, Tuple[str]]\n             only_constructor_args=False,  # type: bool\n             only_public_fields=False,     # type: bool\n             cls=DECORATED\n             ):\n    \"\"\"\n    A decorator to makes objects of the class implement __hash__, so that they can be used correctly for example in\n    sets.\n    \n    Parameters allow to customize the list of attributes that are taken into account in the hash.\n\n    :param include: a tuple of explicit attribute names to include (None means all)\n    :param exclude: a tuple of explicit attribute names to exclude. In such case, include should be None.\n    :param only_constructor_args: if False (default), all fields will be included in the hash, even if they are defined\n        in the constructor or dynamically. If True, only constructor arguments will be included in the hash, not any\n        other field that would be created in the constructor or dynamically. Please note that this behaviour is the\n        opposite from @autodict.\n    :param only_public_fields: this parameter is only used when only_constructor_args is set to False. If\n        only_public_fields is set to False (default), all fields are used in the hash. Otherwise, class-private fields\n        will not be taken into account in the hash. Please note that this behaviour is the opposite from @autodict.\n    :return:\n    \"\"\"\n\n    return autohash_decorate(cls, include=include, exclude=exclude, only_constructor_args=only_constructor_args,\n                             only_public_fields=only_public_fields)", "response": "A function that automatically generates objects of the given class based on the given include and exclude parameters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute autohash on a class.", "response": "def _execute_autohash_on_class(object_type,                  # type: Type[T]\n                               include=None,                 # type: Union[str, Tuple[str]]\n                               exclude=None,                 # type: Union[str, Tuple[str]]\n                               only_constructor_args=False,  # type: bool\n                               only_public_fields=False,     # type: bool\n                               ):\n    \"\"\"\n    A decorator to make objects of the class implement __hash__, so that they can be used correctly for example in\n    sets.\n\n    Parameters allow to customize the list of attributes that are taken into account in the hash.\n\n    :param object_type: the class on which to execute.\n    :param include: a tuple of explicit attribute names to include (None means all)\n    :param exclude: a tuple of explicit attribute names to exclude. In such case, include should be None.\n    :param only_constructor_args: if False (default), all fields will be included in the hash, even if they are defined\n    in the constructor or dynamically. If True, only constructor arguments will be included in the hash, not any other\n    field that would be created in the constructor or dynamically. Please note that this behaviour is the opposite from\n    @autodict.\n    :param only_public_fields: this parameter is only used when only_constructor_args is set to False. If\n    only_public_fields is set to False (default), all fields are used in the hash. Otherwise, class-private fields will\n    not be taken into account in the hash. Please note that this behaviour is the opposite from @autodict.\n    :return:\n    \"\"\"\n    # First check parameters\n    validate_include_exclude(include, exclude)\n\n    # Override hash method if not already implemented\n    if not method_already_there(object_type, '__hash__'):\n        if only_constructor_args:\n            # a. Find the __init__ constructor signature\n            constructor = get_constructor(object_type, allow_inheritance=True)\n            s = signature(constructor)\n\n            # b. Collect all attributes that are not 'self' and are included and not excluded\n            added = []\n            # we assume that the order of attributes will always be the same here....\n            for attr_name in s.parameters.keys():\n                if is_attr_selected(attr_name, include=include, exclude=exclude):\n                    added.append(attr_name)\n\n            # c. Finally build the method\n            def __hash__(self):\n                \"\"\"\n                Generated by @autohash.\n                Implements the __hash__ method by hashing a tuple of selected attributes\n                :param self:\n                :return:\n                \"\"\"\n                # note: we prepend a unique hash for the class  > NO, it is more intuitive to not do that.\n                # return hash(tuple([type(self)] + [getattr(self, att_name) for att_name in added]))\n                return hash(tuple(getattr(self, att_name) for att_name in added))\n\n        else:\n            # ** all dynamic fields are allowed\n            if include is None and exclude is None and not only_public_fields:\n\n                # easy: all of vars values is included in the hash\n                def __hash__(self):\n                    \"\"\"\n                    Generated by @autohash.\n                    Implements the __hash__ method by hashing vars(self).values()\n                    :param self:\n                    :return:\n                    \"\"\"\n                    # note: we prepend a unique hash for the class  > NO, it is more intuitive to not do that.\n                    # return hash(tuple([type(self)] + list(vars(self).values())))\n                    return hash(tuple(vars(self).values()))\n\n            else:\n                # harder: dynamic filters\n                # private_name_prefix = '_' + object_type.__name__ + '_'\n                private_name_prefix = '_'\n\n                def __hash__(self):\n                    \"\"\"\n                    Generated by @autohash.\n                    Implements the __hash__ method by hashing the tuple of included/not excluded field values, possibly\n                    not including the private fields if `only_public_fields` was set to True\n\n                    :param self:\n                    :return:\n                    \"\"\"\n                    # note: we prepend a unique hash for the class > NO, it is more intuitive to not do that.\n                    # to_hash = [type(self)]\n                    to_hash = []\n\n                    for att_name, att_value in vars(self).items():\n                        att_name = possibly_replace_with_property_name(self.__class__, att_name)\n                        if is_attr_selected(att_name, include=include, exclude=exclude):\n                            if not only_public_fields \\\n                                    or (only_public_fields and not att_name.startswith(private_name_prefix)):\n                                to_hash.append(att_value)\n\n                    return hash(tuple(to_hash))\n\n        # now set the method on the class\n        object_type.__hash__ = __hash__\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autodict(include=None,                # type: Union[str, Tuple[str]]\n             exclude=None,                # type: Union[str, Tuple[str]]\n             only_constructor_args=True,  # type: bool\n             only_public_fields=True,     # type: bool\n             cls=DECORATED\n             ):\n    \"\"\"\n    A decorator to makes objects of the class behave like a read-only `dict`. It does several things:\n    * it adds collections.Mapping to the list of parent classes (i.e. to the class' `__bases__`)\n    * it generates `__len__`, `__iter__` and `__getitem__` in order for the appropriate fields to be exposed in the dict\n    view.\n    * it adds a static from_dict method to build objects from dicts (only if only_constructor_args=True)\n    * it overrides eq method if not already implemented\n    * it overrides str and repr method if not already implemented\n    \n    Parameters allow to customize the list of fields that will be visible.\n\n    :param include: a tuple of explicit attribute names to include (None means all)\n    :param exclude: a tuple of explicit attribute names to exclude. In such case, include should be None.\n    :param only_constructor_args: if True (default), only constructor arguments will be exposed through the dictionary\n        view, not any other field that would be created in the constructor or dynamically. This makes it very convenient\n        to use in combination with @autoargs. If set to False, the dictionary is a direct view of public object fields.\n    :param only_public_fields: this parameter is only used when only_constructor_args is set to False. If\n        only_public_fields is set to False, all fields are visible. Otherwise (default), class-private fields will be\n        hidden\n    :return:\n    \"\"\"\n    return autodict_decorate(cls, include=include, exclude=exclude, only_constructor_args=only_constructor_args,\n                             only_public_fields=only_public_fields)", "response": "A class decorator that creates a dictionary of the given class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autodict_decorate(cls,                         # type: Type[T]\n                      include=None,                # type: Union[str, Tuple[str]]\n                      exclude=None,                # type: Union[str, Tuple[str]]\n                      only_constructor_args=True,  # type: bool\n                      only_public_fields=True      # type: bool\n                      ):\n    # type: (...) -> Type[T]\n    \"\"\"\n    To automatically generate the appropriate methods so that objects of this class behave like a `dict`,\n    manually, without using @autodict decorator.\n\n    :param cls: the class on which to execute. Note that it won't be wrapped.\n    :param include: a tuple of explicit attribute names to include (None means all)\n    :param exclude: a tuple of explicit attribute names to exclude. In such case, include should be None.\n    :param only_constructor_args: if True (default), only constructor arguments will be exposed through the dictionary\n    view, not any other field that would be created in the constructor or dynamically. This makes it very convenient\n    to use in combination with @autoargs. If set to False, the dictionary is a direct view of public object fields.\n    :param only_public_fields: this parameter is only used when only_constructor_args is set to False. If\n    only_public_fields is set to False, all fields are visible. Otherwise (default), class-private fields will be hidden\n    :return:\n    \"\"\"\n\n    # first check that we do not conflict with other known decorators\n    _check_known_decorators(cls, '@autodict')\n\n    # perform the class mod\n    _execute_autodict_on_class(cls, include=include, exclude=exclude, only_constructor_args=only_constructor_args,\n                               only_public_fields=only_public_fields)\n\n    return cls", "response": "A decorator that automatically generates the appropriate methods for a dictionary object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing to decorate a function as an overridden dictionary method (such as __iter__), without using the @autodict_override annotation. :param func: the function on which to execute. Note that it won't be wrapped but simply annotated. :return:", "response": "def autodict_override_decorate(func  # type: Callable\n                               ):\n    # type: (...) -> Callable\n    \"\"\"\n    Used to decorate a function as an overridden dictionary method (such as __iter__), without using the\n    @autodict_override annotation.\n\n    :param func: the function on which to execute. Note that it won't be wrapped but simply annotated.\n    :return:\n    \"\"\"\n\n    if func.__name__ not in {Mapping.__iter__.__name__, Mapping.__getitem__.__name__, Mapping.__len__.__name__}:\n        raise ValueError('@autodict_override can only be used on one of the three Mapping methods __iter__,'\n                         '__getitem__ and __len__. Found: ' + func.__name__)\n\n    # Simply annotate the function\n    if hasattr(func, __AUTODICT_OVERRIDE_ANNOTATION):\n        raise DuplicateOverrideError('Function is overridden twice : ' + func.__name__)\n    else:\n        setattr(func, __AUTODICT_OVERRIDE_ANNOTATION, True)\n\n    return func"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map_values(f, D):\n    '''Map each value in the dictionary D to f(value).'''\n    return { key:f(val) for key,val in D.iteritems() }", "response": "Map each value in the dictionary D to f."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nproduces a representation using the default repr regardless of whether the object provides an implementation of its own.", "response": "def raw_repr(obj):\n    '''Produce a representation using the default repr() regardless of\n    whether the object provides an implementation of its own.'''\n    if isproxy(obj):\n        return '<%s with prime_id=%d>' % (obj.__class__.__name__, obj.prime_id)\n    else:\n        return repr(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_module(module_name, path):\n    '''A helper function invoked on the server to tell it to import a module.'''\n    # TODO: handle the case that the module is already loaded\n    try:\n        # First try to find a non-builtin, non-frozen, non-special\n        # module using the client's search path\n        fd, filename, info = imp.find_module(module_name, path)\n    except ImportError:\n        # The above will fail for builtin, frozen, or special\n        # modules. We search for those now...\n        fd, filename, info = imp.find_module(module_name)\n\n    # Now import the module given the info found above\n    try:\n        return imp.load_module(module_name, fd, filename, info)\n    finally:\n        if fd is not None:\n            fd.close()", "response": "A helper function invoked on the server to tell it to import a module."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef byvalue(proxy):\n    '''Return a copy of the underlying object for which the argument\n    is a proxy.'''\n    assert isinstance(proxy, Proxy)\n    return proxy.client.execute(ByValueDelegate(proxy))", "response": "Return a copy of the underlying object for which the argument\n    is a proxy."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_isolated(module_name, fromlist=[], level=-1, path=None):\n    '''Import an module into an isolated context as if with\n    \"__import__('module_name')\"'''\n    sys.modules[module_name] = load_module(module_name, path=path)\n    return __import__(module_name, fromlist=fromlist, level=level)", "response": "Import an isolated module into an isolated context as if with\n    \"__import__('module_name')\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef state(self, state):\n        '''Change the state of the client. This is one of the values\n        defined in ClientStates.'''\n        logger.debug('client changing to state=%s', ClientState.Names[state])\n        self._state = state", "response": "Change the state of the client. This is one of the values\n        defined in ClientStates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _read_result(self, num_retries):\n        '''Read an object from a channel, possibly retrying if the attempt\n        is interrupted by a signal from the operating system.'''\n        for i in range(num_retries):\n            self._assert_alive()\n            try:\n                return self._result_channel.get()\n            except IOError as ex:\n                if ex.errno == 4:\n                    # errno=4 corresponds to \"System call interrupted\",\n                    # which means a signal was recieved before any data\n                    # was sent. For now I think it's safe to ignore this\n                    # and continue.\n                    logger.exception('attempt to read from channel was interrupted by something')\n                    sys.exc_clear()\n                else:\n                    # Something else went wrong - raise the exception as usual\n                    raise ex\n\n        raise ChannelError('failed to read from channel after %d retries' % num_retries)", "response": "Read an object from a channel possibly retrying if the attempt\n        is interrupted by a signal from the operating system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef terminate(self):\n        '''Stop the server process and change our state to TERMINATING. Only valid if state=READY.'''\n        logger.debug('client.terminate() called (state=%s)', self.strstate)\n        if self.state == ClientState.WAITING_FOR_RESULT:\n            raise ClientStateError('terimate() called while state='+self.strstate)\n        if self.state == ClientState.TERMINATING:\n            raise ClientStateError('terimate() called while state='+self.strstate)\n        elif self.state in ClientState.TerminatedSet:\n            assert not self._server_process.is_alive()\n            return\n        elif self.state == ClientState.READY:\n            # Check that the process itself is still alive\n            self._assert_alive()\n\n            # Make sure the SIGCHLD signal handler doesn't throw any exceptions\n            self.state = ClientState.TERMINATING\n\n            # Do not call execute() because that function will check\n            # whether the process is alive and throw an exception if not\n            # TODO: can the queue itself throw exceptions?\n            self._delegate_channel.put(FunctionCallDelegate(_raise_terminate))\n\n            # Wait for acknowledgement\n            try:\n                self._read_result(num_retries=5)\n            except ProcessTerminationError as ex:\n                pass\n            except ChannelError as ex:\n                # Was interrupted five times in a row! Ignore for now\n                logger.debug('client failed to read sentinel from channel after 5 retries - will terminate anyway')\n\n            self.state = ClientState.TERMINATED_CLEANLY", "response": "Stop the server process and change our state to TERMINATING. Only valid if state = READY."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nterminating this client if it has not already terminated.", "response": "def cleanup(self):\n        '''Terminate this client if it has not already terminated.'''\n        if self.state == ClientState.WAITING_FOR_RESULT:\n            # There is an ongoing call to execute()\n            # Not sure what to do here\n            logger.warn('cleanup() called while state is WAITING_FOR_RESULT: ignoring')\n        elif self.state == ClientState.TERMINATING:\n            # terminate() has been called but we have not recieved SIGCHLD yet\n            # Not sure what to do here\n            logger.warn('cleanup() called while state is TERMINATING: ignoring')\n        elif self.state in ClientState.TerminatedSet:\n            # We have already terminated\n            # TODO: should we deal with TERMINATED_ASYNC in some special way?\n            logger.debug('cleanup() called while state is TERMINATING: nothing needs to be done')\n        else:\n            logger.debug('cleanup() called while state is %s: attempting to terminate',\n                          self.strstate)\n            try:\n                self.terminate()\n            except ProcessTerminationError as ex:\n                # Terminate can throw a ProcessTerminationError if the\n                # process terminated at some point between the last\n                # execute() and the call to terminate()\n                # For now we just ignore this.\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self):\n        '''Create a process in which the isolated code will be run.'''\n        assert self._client is None\n\n        logger.debug('IsolationContext[%d] starting', id(self))\n\n        # Create the queues\n        request_queue = multiprocessing.Queue()\n        response_queue = multiprocessing.Queue()\n\n        # Launch the server process\n        server = Server(request_queue, response_queue)  # Do not keep a reference to this object!\n        server_process = multiprocessing.Process(target=server.loop)\n        server_process.start()\n\n        # Create a client to talk to the server\n        self._client = Client(server_process, request_queue, response_queue)", "response": "Create a process in which the isolated code will be run."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport a module into this isolation context and return a proxy for it.", "response": "def load_module(self, module_name, path=None):\n        '''Import a module into this isolation context and return a proxy for it.'''\n        self.ensure_started()\n        if path is None:\n            path = sys.path\n        mod = self.client.call(_load_module, module_name, path)\n        mod.__isolation_context__ = self\n        return mod"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading the badge corresponding to the provided success percentage from the shields. io.", "response": "def download_badge(test_stats,                  # type: TestStats\n                   dest_folder='reports/junit'  # type: str\n                   ):\n    \"\"\"\n    Downloads the badge corresponding to the provided success percentage, from https://img.shields.io.\n\n    :param test_stats:\n    :param dest_folder:\n    :return:\n    \"\"\"\n    if not path.exists(dest_folder):\n        makedirs(dest_folder)  # , exist_ok=True) not python 2 compliant\n\n    if test_stats.success_percentage < 50:\n        color = 'red'\n    elif test_stats.success_percentage < 75:\n        color = 'orange'\n    elif test_stats.success_percentage < 90:\n        color = 'green'\n    else:\n        color = 'brightgreen'\n\n    left_txt = \"tests\"\n    # right_txt = \"%s%%\" % test_stats.success_percentage\n    right_txt = \"%s/%s\" % (test_stats.success, test_stats.runned)\n    url = 'https://img.shields.io/badge/%s-%s-%s.svg' % (left_txt, quote_plus(right_txt), color)\n\n    dest_file = path.join(dest_folder, 'junit-badge.svg')\n\n    print('Generating junit badge from : ' + url)\n    response = requests.get(url, stream=True)\n    with open(dest_file, 'wb') as out_file:\n        response.raw.decode_content = True\n        shutil.copyfileobj(response.raw, out_file)\n    del response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef autoprops_decorate(cls,           # type: Type[T]\n                       include=None,  # type: Union[str, Tuple[str]]\n                       exclude=None   # type: Union[str, Tuple[str]]\n                       ):\n    # type: (...) -> Type[T]\n    \"\"\"\n    To automatically generate all properties getters and setters from the class constructor manually, without using\n    @autoprops decorator.\n    * if a @contract annotation exist on the __init__ method, mentioning a contract for a given parameter, the\n    parameter contract will be added on the generated setter method\n    * The user may override the generated getter and/or setter by creating them explicitly in the class and annotating\n    them with @getter_override or @setter_override. Note that the contract will still be dynamically added on the\n    setter, even if the setter already has one (in such case a `UserWarning` will be issued)\n\n    :param cls: the class on which to execute. Note that it won't be wrapped.\n    :param include: a tuple of explicit attribute names to include (None means all)\n    :param exclude: a tuple of explicit attribute names to exclude. In such case, include should be None.\n    :return:\n    \"\"\"\n\n    # first check that we do not conflict with other known decorators\n    _check_known_decorators(cls, '@autoprops')\n\n    # perform the class mod\n    _execute_autoprops_on_class(cls, include=include, exclude=exclude)\n\n    # TODO better create a wrapper than modify the class? Probably not\n    # class Autoprops_Wrapper(object):\n    #     def __init__(self, *args, **kwargs):\n    #         self.wrapped = cls(*args, **kwargs)\n    #\n    # return Autoprops_Wrapper\n\n    return cls", "response": "Decorator to automatically generate all properties getters and setters from the class constructor."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes autoprops on the object_type.", "response": "def _execute_autoprops_on_class(object_type,   # type: Type[T]\n                                include=None,  # type: Union[str, Tuple[str]]\n                                exclude=None   # type: Union[str, Tuple[str]]\n                                ):\n    \"\"\"\n    This method will automatically add one getter and one setter for each constructor argument, except for those\n    overridden using autoprops_override_decorate(), @getter_override or @setter_override.\n    It will add a @contract on top of all setters (generated or overridden, if they don't already have one)\n\n    :param object_type: the class on which to execute.\n    :param include: a tuple of explicit attribute names to include (None means all)\n    :param exclude: a tuple of explicit attribute names to exclude. In such case, include should be None.\n    :return:\n    \"\"\"\n    # 0. first check parameters\n    validate_include_exclude(include, exclude)\n\n    # 1. Find the __init__ constructor signature and possible pycontracts @contract\n    constructor = get_constructor(object_type, allow_inheritance=True)\n    s = signature(constructor)\n\n    # option a) pycontracts\n    contracts_dict = constructor.__contracts__ if hasattr(constructor, '__contracts__') else {}\n    # option b) valid8\n    validators_dict = constructor.__validators__ if hasattr(constructor, '__validators__') else {}\n\n    # 2. For each attribute that is not 'self' and is included and not excluded, add the property\n    added = []\n    for attr_name in s.parameters.keys():\n        if is_attr_selected(attr_name, include=include, exclude=exclude):\n            added.append(attr_name)\n\n            # pycontract\n            if attr_name in contracts_dict.keys():\n                pycontract = contracts_dict[attr_name]\n            else:\n                pycontract = None\n\n            # valid8 validators: create copies, because we will modify them (changing the validated function ref)\n            if attr_name in validators_dict.keys():\n                validators = [copy(v) for v in validators_dict[attr_name]]\n            else:\n                validators = None\n\n            _add_property(object_type, s.parameters[attr_name], pycontract=pycontract, validators=validators)\n\n    # 3. Finally check that there is no overridden setter or getter that does not correspond to an attribute\n    extra_overrides = getmembers(object_type, predicate=(lambda fun: callable(fun) and\n                                                                     (hasattr(fun, __GETTER_OVERRIDE_ANNOTATION)\n                                                                      and getattr(fun, __GETTER_OVERRIDE_ANNOTATION) not in added)\n                                                                      or\n                                                                     (hasattr(fun, __SETTER_OVERRIDE_ANNOTATION))\n                                                                      and getattr(fun, __SETTER_OVERRIDE_ANNOTATION) not in added)\n                                 )\n    if len(extra_overrides) > 0:\n        raise AttributeError('Attribute named \\'' + extra_overrides[0][0] + '\\' was not found in constructor signature.'\n                             'Therefore its getter/setter can not be overridden by function '\n                             + extra_overrides[0][1].__qualname__)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_property(object_type,      # type: Type[T]\n                  parameter,        # type: Parameter\n                  pycontract=None,  # type: Any\n                  validators=None   # type: Any\n                  ):\n    \"\"\"\n    A method to dynamically add a property to a class with the optional given pycontract or validators.\n    If the property getter and/or setter have been overridden, it is taken into account too.\n\n    :param object_type: the class on which to execute.\n    :param parameter:\n    :param pycontract:\n    :param validators:\n    :return:\n    \"\"\"\n    property_name = parameter.name\n\n    # 1. create the private field name , e.g. '_foobar'\n    private_property_name = '_' + property_name\n\n    # 2. property getter (@property) - create or use overridden\n    getter_fun = _get_getter_fun(object_type, parameter, private_property_name)\n\n    # 3. property setter (@property_name.setter) - create or use overridden\n    setter_fun, var_name = _get_setter_fun(object_type, parameter, private_property_name)\n\n    # 4. add the contract to the setter, if any\n    setter_fun_with_possible_contract = setter_fun\n    if pycontract is not None:\n        setter_fun_with_possible_contract = _add_contract_to_setter(setter_fun, var_name, pycontract,\n                                                                    property_name)\n    elif validators is not None:\n        setter_fun_with_possible_contract = _add_validators_to_setter(setter_fun, var_name, validators,\n                                                                      property_name)\n\n    # 5. change the function name to make it look nice\n    setter_fun_with_possible_contract.__name__ = property_name\n    setter_fun_with_possible_contract.__module__ = object_type.__module__\n    setter_fun_with_possible_contract.__qualname__ = object_type.__name__ + '.' + property_name\n    # __annotations__\n    # __doc__\n    # __dict__\n\n    # 6. Finally add the property to the class\n    # WARNING : property_obj.setter(f) does absolutely nothing :) > we have to assign the result\n    # setattr(object_type, property_name, property_obj.setter(f))\n    new_prop = property(fget=getter_fun, fset=setter_fun_with_possible_contract)\n\n    # # specific for enforce: here we might wrap the overriden property setter on which enforce has already written\n    # # something.\n    # if hasattr(setter_fun_with_possible_contract, '__enforcer__'):\n    #     new_prop.__enforcer__ = setter_fun_with_possible_contract.__enforcer__\n    # DESIGN DECISION > although this would probably work, it is probably better to 'force' users to always use the\n    # @autoprops annotation BEFORE any other annotation. This is now done in autoprops_decorate\n\n    setattr(object_type, property_name, new_prop)", "response": "A method to dynamically add a property to a class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a function that can be used as a predicate in get_members that returns true if the function has the correct annotation with value.", "response": "def _has_annotation(annotation, value):\n    \"\"\" Returns a function that can be used as a predicate in get_members, that  \"\"\"\n\n    def matches_property_name(fun):\n        \"\"\" return true if fun is a callable that has the correct annotation with value \"\"\"\n        return callable(fun) and hasattr(fun, annotation) \\\n               and getattr(fun, annotation) is value\n    return matches_property_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_getter_fun(object_type,           # type: Type\n                    parameter,             # type: Parameter\n                    private_property_name  # type: str\n                    ):\n    \"\"\"\n    Utility method to find the overridden getter function for a given property, or generate a new one\n\n    :param object_type:\n    :param property_name:\n    :param private_property_name:\n    :return:\n    \"\"\"\n\n    property_name = parameter.name\n\n    # -- check overridden getter for this property name\n    overridden_getters = getmembers(object_type, predicate=_has_annotation(__GETTER_OVERRIDE_ANNOTATION, property_name))\n\n    if len(overridden_getters) > 0:\n        if len(overridden_getters) > 1:\n            raise DuplicateOverrideError('Getter is overridden more than once for attribute name : ' + property_name)\n\n        # --use the overridden getter\n        getter_fun = overridden_getters[0][1]\n\n        # --check its signature\n        s = signature(getter_fun)\n        if not ('self' in s.parameters.keys() and len(s.parameters.keys()) == 1):\n            raise IllegalGetterSignatureException('overridden getter must only have a self parameter, found ' +\n                                                  str(len(s.parameters.items()) - 1) + ' for function ' + str(\n                getter_fun.__qualname__))\n\n        # --use the overridden getter ?\n        property_obj = property(getter_fun)\n    else:\n        # -- generate the getter :\n        def autoprops_generated_getter(self):\n            return getattr(self, private_property_name)\n\n        # -- use the generated getter\n        getter_fun = autoprops_generated_getter\n\n        try:\n            annotations = getter_fun.__annotations__\n        except AttributeError:\n            # python 2\n            pass\n        else:\n            annotations['return'] = parameter.annotation  # add type hint to output declaration\n\n    return getter_fun", "response": "Returns the overridden getter function for a given property."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_setter_fun(object_type,           # type: Type\n                    parameter,             # type: Parameter\n                    private_property_name  # type: str\n                    ):\n    \"\"\"\n    Utility method to find the overridden setter function for a given property, or generate a new one\n\n    :param object_type:\n    :param property_name:\n    :param property_type:\n    :param private_property_name:\n    :return:\n    \"\"\"\n    # the property will have the same name than the constructor argument\n    property_name = parameter.name\n\n    overridden_setters = getmembers(object_type, _has_annotation(__SETTER_OVERRIDE_ANNOTATION, property_name))\n\n    if len(overridden_setters) > 0:\n        # --check that we only have one\n        if len(overridden_setters) > 1:\n            raise DuplicateOverrideError('Setter is overridden more than once for attribute name : %s' % property_name)\n\n        # --use the overridden setter\n        setter_fun = overridden_setters[0][1]\n\n        try:\n            # python 2\n            setter_fun = setter_fun.im_func\n        except AttributeError:\n            pass\n\n        # --find the parameter name and check the signature\n        s = signature(setter_fun)\n        p = [attribute_name for attribute_name, param in s.parameters.items() if attribute_name is not 'self']\n        if len(p) != 1:\n            try:\n                qname = setter_fun.__qualname__\n            except AttributeError:\n                qname = setter_fun.__name__\n            raise IllegalSetterSignatureException('overridden setter must have only 1 non-self argument, found ' +\n                                                  '%s for function %s'\n                                                  '' % (len(s.parameters.items()) - 1, qname))\n        var_name = p[0]\n\n    else:\n        # --create the setter, equivalent of:\n        # ** Dynamically compile a wrapper with correct argument name **\n        sig = Signature(parameters=[Parameter('self', kind=Parameter.POSITIONAL_OR_KEYWORD), parameter])\n\n        @with_signature(sig)\n        def autoprops_generated_setter(self, **kwargs):\n            setattr(self, private_property_name, kwargs.popitem()[1])\n\n        setter_fun = autoprops_generated_setter\n        var_name = property_name\n\n    return setter_fun, var_name", "response": "Returns the overridden setter function for a given property."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getter_override(attribute=None,  # type: str\n                    f=DECORATED\n                    ):\n    \"\"\"\n    A decorator to indicate an overridden getter for a given attribute. If the attribute name is None, the function name\n    will be used as the attribute name.\n\n    :param attribute: the attribute name for which the decorated function is an overridden getter\n    :return:\n    \"\"\"\n    return autoprops_override_decorate(f, attribute=attribute, is_getter=True)", "response": "A decorator to indicate an overridden getter for a given attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setter_override(attribute=None,  # type: str\n                    f=DECORATED\n                    ):\n    \"\"\"\n    A decorator to indicate an overridden setter for a given attribute. If the attribute name is None, the function name\n     will be used as the attribute name. The @contract will still be dynamically added.\n\n    :param attribute: the attribute name for which the decorated function is an overridden setter\n    :return:\n    \"\"\"\n    return autoprops_override_decorate(f, attribute=attribute, is_getter=False)", "response": "A decorator to indicate an overridden setter for a given attribute."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse to decorate a function as an overridden getter or setter, without using the @getter_override or @setter_override annotations. If the overridden setter has no @contract, the contract will still be dynamically added. Note: this should be executed BEFORE @autoprops or autoprops_decorate(). :param func: the function on which to execute. Note that it won't be wrapped but simply annotated. :param attribute: the attribute name. If None, the function name will be used :param is_getter: True for a getter override, False for a setter override. :return:", "response": "def autoprops_override_decorate(func,            # type: Callable\n                                attribute=None,  # type: str\n                                is_getter=True   # type: bool\n                                ):\n    # type: (...) -> Callable\n    \"\"\"\n    Used to decorate a function as an overridden getter or setter, without using the @getter_override or\n    @setter_override annotations. If the overridden setter has no @contract, the contract will still be\n     dynamically added. Note: this should be executed BEFORE @autoprops or autoprops_decorate().\n\n    :param func: the function on which to execute. Note that it won't be wrapped but simply annotated.\n    :param attribute: the attribute name. If None, the function name will be used\n    :param is_getter: True for a getter override, False for a setter override.\n    :return:\n    \"\"\"\n\n    # Simply annotate the fact that this is a function\n    attr_name = attribute or func.__name__\n    if is_getter:\n        if hasattr(func, __GETTER_OVERRIDE_ANNOTATION):\n            raise DuplicateOverrideError('Getter is overridden twice for attribute name : ' + attr_name)\n        else:\n            # func.__getter_override__ = attr_name\n            setattr(func, __GETTER_OVERRIDE_ANNOTATION, attr_name)\n    else:\n        if hasattr(func, __SETTER_OVERRIDE_ANNOTATION):\n            raise DuplicateOverrideError('Setter is overridden twice for attribute name : ' + attr_name)\n        else:\n            # func.__setter_override__ = attr_name\n            setattr(func, __SETTER_OVERRIDE_ANNOTATION, attr_name)\n\n    return func"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_or_update_release(user, pwd, secret, repo_slug, changelog_file, doc_url, data_file, tag):\n    # 1- AUTHENTICATION\n    if user is not None and secret is None:\n        # using username and password\n        # validate('user', user, instance_of=str)\n        assert isinstance(user, str)\n        # validate('pwd', pwd, instance_of=str)\n        assert isinstance(pwd, str)\n        g = Github(user, pwd)\n    elif user is None and secret is not None:\n        # or using an access token\n        # validate('secret', secret, instance_of=str)\n        assert isinstance(secret, str)\n        g = Github(secret)\n    else:\n        raise ValueError(\"You should either provide username/password OR an access token\")\n    click.echo(\"Logged in as {user_name}\".format(user_name=g.get_user()))\n\n    # 2- CHANGELOG VALIDATION\n    regex_pattern = \"[\\s\\S]*[\\n][#]+[\\s]*(?P<title>[\\S ]*%s[\\S ]*)[\\n]+?(?P<body>[\\s\\S]*?)[\\n]*?(\\n#|$)\" % re.escape(tag)\n    changelog_section = re.compile(regex_pattern)\n    if changelog_file is not None:\n        # validate('changelog_file', changelog_file, custom=os.path.exists,\n        #          help_msg=\"changelog file should be a valid file path\")\n        assert os.path.exists(changelog_file), \"changelog file should be a valid file path\"\n        with open(changelog_file) as f:\n            contents = f.read()\n\n        match = changelog_section.match(contents).groupdict()\n        if match is None or len(match) != 2:\n            raise ValueError(\"Unable to find changelog section matching regexp pattern in changelog file.\")\n        else:\n            title = match['title']\n            message = match['body']\n    else:\n        title = tag\n        message = ''\n\n    # append footer if doc url is provided\n    message += \"\\n\\nSee [documentation page](%s) for details.\" % doc_url\n\n    # 3- REPOSITORY EXPLORATION\n    # validate('repo_slug', repo_slug, instance_of=str, min_len=1, help_msg=\"repo_slug should be a non-empty string\")\n    assert isinstance(repo_slug, str) and len(repo_slug) > 0, \"repo_slug should be a non-empty string\"\n    repo = g.get_repo(repo_slug)\n\n    # -- Is there a tag with that name ?\n    try:\n        tag_ref = repo.get_git_ref(\"tags/\" + tag)\n    except UnknownObjectException:\n        raise ValueError(\"No tag with name %s exists in repository %s\" % (tag, repo.name))\n\n    # -- Is there already a release with that tag name ?\n    click.echo(\"Checking if release %s already exists in repository %s\" % (tag, repo.name))\n    try:\n        release = repo.get_release(tag)\n        if release is not None:\n            raise ValueError(\"Release %s already exists in repository %s. Please set overwrite to True if you wish to \"\n                             \"update the release (Not yet supported)\" % (tag, repo.name))\n    except UnknownObjectException:\n        # Release does not exist: we can safely create it.\n        click.echo(\"Creating release %s on repo: %s\" % (tag, repo.name))\n        click.echo(\"Release title: '%s'\" % title)\n        click.echo(\"Release message:\\n--\\n%s\\n--\\n\" % message)\n        repo.create_git_release(tag=tag, name=title,\n                                message=message,\n                                draft=False, prerelease=False)\n\n        # add the asset file if needed\n        if data_file is not None:\n            release = None\n            while release is None:\n                release = repo.get_release(tag)\n            release.upload_asset(path=data_file, label=path.split(data_file)[1], content_type=\"application/gzip\")", "response": "Creates or updates a release corresponding to git tag <TAG."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_include_exclude(include, exclude):\n    if include is not None and exclude is not None:\n        raise ValueError(\"Only one of 'include' or 'exclude' argument should be provided.\")\n    validate('include', include, instance_of=(str, Sequence), enforce_not_none=False)\n    validate('exclude', exclude, instance_of=(str, Sequence), enforce_not_none=False)", "response": "Common validator for include and exclude arguments\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_attr_selected(attr_name,     # type: str\n                     include=None,  # type: Union[str, Tuple[str]]\n                     exclude=None   # type: Union[str, Tuple[str]]\n                     ):\n    \"\"\"decide whether an action has to be performed on the attribute or not, based on its name\"\"\"\n\n    if include is not None and exclude is not None:\n        raise ValueError('Only one of \\'include\\' or \\'exclude\\' argument should be provided.')\n\n    # win time by not doing this\n    # check_var(include, var_name='include', var_types=[str, tuple], enforce_not_none=False)\n    # check_var(exclude, var_name='exclude', var_types=[str, tuple], enforce_not_none=False)\n\n    if attr_name is 'self':\n        return False\n    if exclude and attr_name in exclude:\n        return False\n    if not include or attr_name in include:\n        return True\n    else:\n        return False", "response": "decide whether an action has to be performed on the attribute or not based on its name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_constructor(typ,\n                    allow_inheritance=False  # type: bool\n                    ):\n    \"\"\"\n    Utility method to return the unique constructor (__init__) of a type\n\n    :param typ: a type\n    :param allow_inheritance: if True, the constructor will be returned even if it is not defined in this class\n    (inherited). By default this is set to False: an exception is raised when no constructor is explicitly defined in\n    the class\n    :return: the found constructor\n    \"\"\"\n    if allow_inheritance:\n        return typ.__init__\n    else:\n        # check that the constructor is really defined here\n        if '__init__' in typ.__dict__:\n            return typ.__init__\n        else:\n            raise Exception('No explicit constructor was found for class ' + str(typ))", "response": "Utility method to return the unique constructor of a type\nWorkItem"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_known_decorators(typ, calling_decorator  # type: str\n                            ):\n    # type: (...) -> bool\n    \"\"\"\n    Checks that a given type is not already decorated by known decorators that may cause trouble.\n    If so, it raises an Exception\n    :return:\n    \"\"\"\n    for member in typ.__dict__.values():\n        if hasattr(member, '__enforcer__'):\n            raise AutoclassDecorationException('It seems that @runtime_validation decorator was applied to type <'\n                                               + str(typ) + '> BEFORE ' + calling_decorator + '. This is not supported '\n                                               'as it may lead to counter-intuitive behaviour, please change the order '\n                                               'of the decorators on <' + str(typ) + '>')", "response": "Checks that a given type is not already decorated by known decorators."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef method_already_there(object_type, method_name, this_class_only=False):\n    if this_class_only:\n        return method_name in vars(object_type)  # or object_type.__dict__\n    else:\n        try:\n            method = getattr(object_type, method_name)\n        except AttributeError:\n            return False\n        else:\n            return method is not None and method is not getattr(object, method_name, None)", "response": "Returns True if method_name is already implemented by object_type False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autoargs(include=None,  # type: Union[str, Tuple[str]]\n             exclude=None,  # type: Union[str, Tuple[str]]\n             f=DECORATED\n             ):\n    \"\"\"\n    Defines a decorator with parameters, to automatically assign the inputs of a function to self PRIOR to executing \n    the function. In other words:\n    \n    ```\n    @autoargs\n    def myfunc(a):\n        print('hello')\n    ```\n    \n    will create the equivalent of\n    \n    ```\n    def myfunc(a):\n        self.a = a\n        print('hello')\n    ```\n    \n    Initial code from http://stackoverflow.com/questions/3652851/what-is-the-best-way-to-do-automatic-attribute-assignment-in-python-and-is-it-a#answer-3653049\n\n    :param include: a tuple of attribute names to include in the auto-assignment. If None, all arguments will be\n        included by default\n    :param exclude: a tuple of attribute names to exclude from the auto-assignment. In such case, include should be None\n    :return:\n    \"\"\"\n    return autoargs_decorate(f, include=include, exclude=exclude)", "response": "A decorator that automatically assigns the input values of a function to the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autoargs_decorate(func,          # type: Callable\n                      include=None,  # type: Union[str, Tuple[str]]\n                      exclude=None   # type: Union[str, Tuple[str]]\n                      ):\n    # type: (...) -> Callable\n    \"\"\"\n    Defines a decorator with parameters, to automatically assign the inputs of a function to self PRIOR to executing \n    the function. This is the inline way to apply the decorator \n    \n    ```\n    myfunc2 = autoargs_decorate(myfunc)\n    ```\n    \n    \n    See autoargs for details.\n\n    :param func: the function to wrap\n    :param include: a tuple of attribute names to include in the auto-assignment. If None, all arguments will be\n        included by default\n    :param exclude: a tuple of attribute names to exclude from the auto-assignment. In such case, include should be None\n    :return:\n    \"\"\"\n\n    # (0) first check parameters\n    validate_include_exclude(include, exclude)\n\n    # (1) then retrieve function signature\n    # attrs, varargs, varkw, defaults = getargspec(func)\n    func_sig = signature(func)\n\n    # check that include/exclude dont contain names that are incorrect\n    if include is not None:\n        incorrect = set([include] if isinstance(include, str) else include) - set(func_sig.parameters.keys())\n        if len(incorrect) > 0:\n            raise ValueError(\"@autoargs definition exception: include contains '%s' that is/are \"\n                             \"not part of signature for %s\" % (incorrect, func))\n    if exclude is not None:\n        incorrect = set([exclude] if isinstance(exclude, str) else exclude) - set(func_sig.parameters.keys())\n        if len(incorrect) > 0:\n            raise ValueError(\"@autoargs definition exception: exclude contains '%s' that is/are \"\n                             \"not part of signature for %s\" % (incorrect, func))\n\n    # TODO this should be in @autoslots decorator at class level, not here.\n    # (2) Optionally lock the class only for the provided fields\n    # Does not work for the moment. Besides locking fields seems to have issues with pickle serialization\n    # so we'd rather not propose this option.\n    #\n    # See 'attrs' project for this kind of advanced features https://github.com/python-attrs/attrs\n    #\n    # if lock_class_fields:\n    #     if signature_varkw:\n    #         raise Exception('cant lock field names with variable kwargs')\n    #     else:\n    #         object_type = get_class_that_defined_method(func)\n    #         if include:\n    #             fields = include\n    #         else:\n    #             fields = signature_attrs[1:]\n    #             if signature_varargs:\n    #                 fields.append(signature_varargs)\n    #             if exclude:\n    #                 for a in exclude:\n    #                     fields.remove(a)\n    #\n    #         # right now, doesnot work\n    #         _lock_fieldnames_class(object_type, field_names=tuple(fields))\n\n    # (3) Finally, create a wrapper around the function so that all attributes included/not excluded are\n    # set to self BEFORE executing the function.\n    @wraps(func)\n    def init_wrapper(self, *args, **kwargs):\n\n        # match the received arguments with the signature to know who is who, and add default values to get a full list\n        bound_values = func_sig.bind(self, *args, **kwargs)\n        apply_defaults(bound_values)\n\n        # Assign to self the ones that needs to\n        for att_name, att_value in bound_values.arguments.items():\n            if is_attr_selected(att_name, include=include, exclude=exclude):\n                # value = a normal value, or cur_kwargs as a whole\n                setattr(self, att_name, att_value)\n\n        # finally execute the constructor function\n        return func(self, *args, **kwargs)\n\n    # return wrapper\n    return init_wrapper", "response": "A decorator that automatically assigns the inputs of a function to the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a ( name value ) pair. Does not overwrite the value.", "response": "def append(self, key, value):\n        \"\"\"Adds a (name, value) pair, doesn't overwrite the value if it already\n        exists.\"\"\"\n        self.__items.append((key, value))\n\n        try:\n            dict_getitem(self, key).append(value)\n        except KeyError:\n            dict_setitem(self, key, [value])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extend(self, *args, **kwargs):\n        if len(args) > 1:\n            raise TypeError('expected at most 1 arguments, got %d' % len(args))\n\n        iterable = args[0] if args else None\n        if iterable:\n            if isinstance(iterable, Mapping) or hasattr(iterable, 'items'):\n                for key, value in iterable.items():\n                    self.append(key, value)\n            elif hasattr(iterable, 'keys'):\n                for key in iterable.keys():\n                    self.append(key, iterable[key])\n            else:\n                for key, value in iterable:\n                    self.append(key, value)\n\n        for key, value in kwargs.items():\n            self.append(key, value)", "response": "Add key value pairs for an iterable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __insert_wrapper(func):\n        def check_func(self, key, new_item, instance=0):\n            if key not in self.keys():\n                raise KeyError(\"%s not a key in label\" % (key))\n            if not isinstance(new_item, (list, OrderedMultiDict)):\n                raise TypeError(\"The new item must be a list or PVLModule\")\n            if isinstance(new_item, OrderedMultiDict):\n                new_item = list(new_item)\n            return func(self, key, new_item, instance)\n        return check_func", "response": "Decorator for insert methods"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_index_for_insert(self, key, instance):\n        if instance == 0:\n            # Index method will return the first occurence of the key\n            index = self.keys().index(key)\n        else:\n            occurrence = -1\n            for index, k in enumerate(self.keys()):\n                if k == key:\n                    occurrence += 1\n                    if occurrence == instance:\n                        # Found the key and the correct occurence of the key\n                        break\n\n            if occurrence != instance:\n                # Gone through the entire list of keys and the instance number\n                # given is too high for the number of occurences of the key\n                raise ValueError(\n                    (\n                        \"Cannot insert before/after the %d \"\n                        \"instance of the key '%s' since there are \"\n                        \"only %d occurences of the key\" % (\n                            instance, key, occurrence)\n                    ))\n        return index", "response": "Get the index of the key to insert before or after"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts a new item before or after another item", "response": "def _insert_item(self, key, new_item, instance, is_after):\n        \"\"\"Insert a new item before or after another item\"\"\"\n        index = self._get_index_for_insert(key, instance)\n        index = index + 1 if is_after else index\n        self.__items = self.__items[:index] + new_item + self.__items[index:]\n        # Make sure indexing works with new items\n        for new_key, new_value in new_item:\n            if new_key in self:\n                value_list = [val for k, val in self.__items if k == new_key]\n                dict_setitem(self, new_key, value_list)\n            else:\n                dict_setitem(self, new_key, [new_value])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_after(self, key, new_item, instance=0):\n        self._insert_item(key, new_item, instance, True)", "response": "Insert an item after a key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert_before(self, key, new_item, instance=0):\n        self._insert_item(key, new_item, instance, False)", "response": "Insert an item before a key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, n):\n        buf = self._read_buf\n        pos = self._read_pos\n        end = pos + n\n\n        if end <= len(buf):\n            # Fast path: the data to read is fully buffered.\n            self._read_pos += n\n            return self._update_pos(buf[pos:end])\n\n        # Slow path: read from the stream until enough bytes are read,\n        # or until an EOF occurs or until read() would block.\n        wanted = max(self.buffer_size, n)\n        while len(buf) < end:\n            chunk = self.raw.read(wanted)\n            if not chunk:\n                break\n            buf += chunk\n\n        self._read_buf = buf[end:]  # Save the extra data in the buffer.\n        self._read_pos = 0\n        return self._update_pos(buf[pos:end])", "response": "Read n bytes.\n        Returns exactly n bytes of data unless the underlying raw IO\n        stream reaches EOF."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, n):\n        pos = self._read_pos\n        self._read_pos = min(len(self.raw), pos + n)\n        return self.raw[pos:self._read_pos]", "response": "Read n bytes.\n        Returns exactly n bytes of data unless the underlying raw IO\n        stream reaches EOF."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn buffered bytes without advancing the position.", "response": "def peek(self, n):\n        \"\"\"Returns buffered bytes without advancing the position.\n        The argument indicates a desired minimal number of bytes; we\n        do at most one raw read to satisfy it.  We never return more\n        than self.buffer_size.\n        \"\"\"\n        pos = self._read_pos\n        end = pos + n\n        return self.raw[pos:end]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_block(self, stream, has_end):\n        statements = []\n        while 1:\n            self.skip_whitespace_or_comment(stream)\n\n            if has_end(stream):\n                return statements\n\n            statement = self.parse_statement(stream)\n            if isinstance(statement, EmptyValueAtLine):\n                if len(statements) == 0:\n                    self.raise_unexpected(stream)\n                self.skip_whitespace_or_comment(stream)\n                value = self.parse_value(stream)\n                last_statement = statements.pop(-1)\n                fixed_last = (\n                    last_statement[0],\n                    statement\n                )\n                statements.append(fixed_last)\n                statements.append((last_statement[1], value))\n\n            else:\n                statements.append(statement)", "response": "Parse a PVL module block from the given stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring that a Statement Delimiter consists of one semicolon and one or more White Spaces and one or more Comments and one or more White Spaces and or more Comments and one or more EndProvidedOctetSeq .", "response": "def skip_statement_delimiter(self, stream):\n        \"\"\"Ensure that a Statement Delimiter consists of one semicolon,\n        optionally preceded by multiple White Spaces and/or Comments, OR one or\n        more Comments and/or White Space sequences.\n\n        StatementDelim ::= WSC (SemiColon | WhiteSpace | Comment)\n                         | EndProvidedOctetSeq\n\n        \"\"\"\n        self.skip_whitespace_or_comment(stream)\n        self.optional(stream, self.statement_delimiter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_statement(self, stream):\n\n        if self.has_group(stream):\n            return self.parse_group(stream)\n\n        if self.has_object(stream):\n            return self.parse_object(stream)\n\n        if self.has_assignment(stream):\n            return self.parse_assignment(stream)\n\n        if self.has_assignment_symbol(stream):\n            return self.broken_assignment(stream.lineno - 1)\n\n        self.raise_unexpected(stream)", "response": "Parse a statement in the format of a group object or assignment statement."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_end(self, stream):\n        for token in self.end_tokens:\n            if not self.has_next(token, stream):\n                continue\n\n            offset = len(token)\n\n            if self.has_eof(stream, offset):\n                return True\n\n            if self.has_whitespace(stream, offset):\n                return True\n\n            if self.has_comment(stream, offset):\n                return True\n\n            if self.has_next(self.statement_delimiter, stream, offset):\n                return True\n\n        return self.has_eof(stream)", "response": "Returns True if the stream has at least one end token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_group(self, stream):\n        self.expect_in(stream, self.begin_group_tokens)\n\n        self.ensure_assignment(stream)\n        name = self.next_token(stream)\n\n        self.skip_statement_delimiter(stream)\n        statements = self.parse_block(stream, self.has_end_group)\n\n        self.expect_in(stream, self.end_group_tokens)\n        self.parse_end_assignment(stream, name)\n        self.skip_statement_delimiter(stream)\n\n        return name.decode('utf-8'), PVLGroup(statements)", "response": "Parse a PVL group statement from a PCAP stream."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_object(self, stream):\n        self.expect_in(stream, self.begin_object_tokens)\n\n        self.ensure_assignment(stream)\n        name = self.next_token(stream)\n\n        self.skip_statement_delimiter(stream)\n        statements = self.parse_block(stream, self.has_end_object)\n\n        self.expect_in(stream, self.end_object_tokens)\n        self.parse_end_assignment(stream, name)\n        self.skip_statement_delimiter(stream)\n\n        return name.decode('utf-8'), PVLObject(statements)", "response": "Parse an object from the given stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses an assignment statement from the given stream.", "response": "def parse_assignment(self, stream):\n        \"\"\"\n        AssignmentStmt ::= Name WSC AssignmentSymbol WSC Value StatementDelim\n        \"\"\"\n        lineno = stream.lineno\n        name = self.next_token(stream)\n        self.ensure_assignment(stream)\n        at_an_end = any((\n            self.has_end_group(stream),\n            self.has_end_object(stream),\n            self.has_end(stream),\n            self.has_next(self.statement_delimiter, stream, 0)))\n        if at_an_end:\n            value = self.broken_assignment(lineno)\n            self.skip_whitespace_or_comment(stream)\n        else:\n            value = self.parse_value(stream)\n        self.skip_statement_delimiter(stream)\n        return name.decode('utf-8'), value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a value from a stream.", "response": "def parse_value(self, stream):\n        \"\"\"\n        Value ::= (SimpleValue | Set | Sequence) WSC UnitsExpression?\n        \"\"\"\n        if self.has_sequence(stream):\n            value = self.parse_sequence(stream)\n        elif self.has_set(stream):\n            value = self.parse_set(stream)\n        else:\n            value = self.parse_simple_value(stream)\n\n        self.skip_whitespace_or_comment(stream)\n\n        if self.has_units(stream):\n            return Units(value, self.parse_units(stream))\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse an iterable of ISO - 8601 entries from a stream.", "response": "def parse_iterable(self, stream, start, end):\n        \"\"\"\n        Sequence ::= SequenceStart WSC SequenceValue? WSC SequenceEnd\n        Set := SetStart WSC SequenceValue? WSC SetEnd\n        SequenceValue ::= Value (WSC SeparatorSymbol WSC Value)*\n        \"\"\"\n        values = []\n\n        self.expect(stream, start)\n        self.skip_whitespace_or_comment(stream)\n\n        if self.has_next(end, stream):\n            self.expect(stream, end)\n            return values\n\n        while 1:\n            self.skip_whitespace_or_comment(stream)\n            values.append(self.parse_value(stream))\n            self.skip_whitespace_or_comment(stream)\n\n            if self.has_next(end, stream):\n                self.expect(stream, end)\n                return values\n\n            self.expect(stream, self.seporator)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the ISO - 8601 units from the specified stream.", "response": "def parse_units(self, stream):\n        \"\"\"\n        UnitsExpression ::=\n            UnitsStart WhiteSpace* UnitsValue WhiteSpace* UnitsEnd\n        \"\"\"\n        value = b''\n        self.expect(stream, self.begin_units)\n\n        while not self.has_next(self.end_units, stream):\n            if self.has_eof(stream):\n                self.raise_unexpected_eof(stream)\n            value += stream.read(1)\n\n        self.expect(stream, self.end_units)\n        return value.strip(b''.join(self.whitespace)).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_simple_value(self, stream):\n        if self.has_quoted_string(stream):\n            return self.parse_quoted_string(stream)\n\n        if self.has_binary_number(stream):\n            return self.parse_binary_number(stream)\n\n        if self.has_octal_number(stream):\n            return self.parse_octal_number(stream)\n\n        if self.has_decimal_number(stream):\n            return self.parse_decimal_number(stream)\n\n        if self.has_hex_number(stream):\n            return self.parse_hex_number(stream)\n\n        if self.has_unquoated_string(stream):\n            return self.parse_unquoated_string(stream)\n\n        if self.has_end(stream):\n            return self.broken_assignment(stream.lineno)\n\n        self.raise_unexpected(stream)", "response": "Parse a simple value from a stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a radix from a stream.", "response": "def parse_radix(self, radix, chars, stream):\n        \"\"\"\n        BinaryNum ::= [+-]? '2' RadixSymbol [0-1]+ RadixSymbol\n        OctalChar ::= [+-]? '8' RadixSymbol [0-7]+ RadixSymbol\n        HexadecimalNum ::= [+-]? '16' RadixSymbol [0-9a-zA-Z]+ RadixSymbol\n        \"\"\"\n        value = b''\n        sign = self.parse_sign(stream)\n        self.expect(stream, b(str(radix)) + self.radix_symbole)\n        sign *= self.parse_sign(stream)\n\n        while not self.has_next(self.radix_symbole, stream):\n            next = stream.read(1)\n            if not next:\n                self.raise_unexpected_eof(stream)\n\n            if next not in chars:\n                self.raise_unexpected(stream, next)\n\n            value += next\n\n        if not value:\n            self.raise_unexpected(stream, self.radix_symbole)\n\n        self.expect(stream, self.radix_symbole)\n        return sign * int(value, radix)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a random string of text of maximum length max_length.", "response": "def varchar(self, field=None):\n        \"\"\"\n        Returns a chunk of text, of maximum length 'max_length'\n        \"\"\"\n        assert field is not None, \"The field parameter must be passed to the 'varchar' method.\"\n        max_length = field.max_length\n\n        def source():\n            length = random.choice(range(1, max_length + 1))\n            return \"\".join(random.choice(general_chars) for i in xrange(length))\n        return self.get_allowed_value(source, field)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses a simple pattern to make the field name", "response": "def simple_pattern(self, pattern, field=None):\n        \"\"\"\n        Use a simple pattern to make the field - # is replaced with a random number,\n        ? with a random letter.\n        \"\"\"\n        return self.get_allowed_value(lambda: self.faker.bothify(pattern), field)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef datetime(self, field=None, val=None):\n        if val is None:\n            def source():\n                tzinfo = get_default_timezone() if settings.USE_TZ else None\n                return datetime.fromtimestamp(randrange(1, 2100000000),\n                                              tzinfo)\n        else:\n            def source():\n                tzinfo = get_default_timezone() if settings.USE_TZ else None\n                return datetime.fromtimestamp(int(val.strftime(\"%s\")) +\n                                              randrange(-365*24*3600*2, 365*24*3600*2),\n                                              tzinfo)\n        return self.get_allowed_value(source, field)", "response": "Returns a random datetime."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef date(self, field=None, val=None):\n        return self.datetime(field=field, val=val).date()", "response": "Like datetime but truncated to be a date only\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lorem(self, field=None, val=None):\n        if val == '':\n            return ''\n\n        if val is not None:\n            def generate(length):\n                # Get lorem ipsum of a specific length.\n                collect = \"\"\n                while len(collect) < length:\n                    collect += ' %s' % self.faker.sentence()\n                collect = collect[:length]\n                return collect\n\n            # We want to match the pattern of the text - linebreaks\n            # in the same places.\n            def source():\n                parts = val.split(\"\\n\")\n                for i, p in enumerate(parts):\n                    # Replace each bit with lorem ipsum of the same length\n                    parts[i] = generate(len(p))\n                return \"\\n\".join(parts)\n        else:\n            def source():\n                return ' '.join(self.faker.sentences())\n        return self.get_allowed_value(source, field)", "response": "Returns the lorem ipsum text."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns lorem ipsum text guaranteed to be unique.", "response": "def unique_lorem(self, field=None, val=None):\n        \"\"\"\n        Returns lorem ipsum text guaranteed to be unique. First uses lorem function\n        then adds a unique integer suffix.\n        \"\"\"\n        lorem_text = self.lorem(field, val)\n        max_length = getattr(field, 'max_length', None)\n\n        suffix_str = str(self.unique_suffixes[field])\n        unique_text = lorem_text + suffix_str\n        if max_length is not None:\n            # take the last max_length chars\n            unique_text = unique_text[-max_length:]\n        self.unique_suffixes[field] += 1\n        return unique_text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef alter_object(self, obj):\n        for attname, field, replacer in self.replacers:\n            currentval = getattr(obj, attname)\n            replacement = replacer(self, obj, field, currentval)\n            setattr(obj, attname, replacement)", "response": "Alters all the attributes in an individual object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a random uuid string", "response": "def uuid(anon, obj, field, val):\n    \"\"\"\n    Returns a random uuid string\n    \"\"\"\n    return anon.faker.uuid(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn random data for a varchar field.", "response": "def varchar(anon, obj, field, val):\n    \"\"\"\n    Returns random data for a varchar field.\n    \"\"\"\n    return anon.faker.varchar(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bool(anon, obj, field, val):\n    return anon.faker.bool(field=field)", "response": "Returns a random boolean value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef integer(anon, obj, field, val):\n    return anon.faker.integer(field=field)", "response": "Returns a random integer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef positive_integer(anon, obj, field, val):\n    return anon.faker.positive_integer(field=field)", "response": "Returns a random positive integer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a random small integer", "response": "def small_integer(anon, obj, field, val):\n    \"\"\"\n    Returns a random small integer (for a Django SmallIntegerField)\n    \"\"\"\n    return anon.faker.small_integer(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef positive_small_integer(anon, obj, field, val):\n    return anon.faker.positive_small_integer(field=field)", "response": "Returns a positive small integer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef datetime(anon, obj, field, val):\n    return anon.faker.datetime(field=field)", "response": "Returns a random datetime object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a random date based on the given field", "response": "def date(anon, obj, field, val):\n    \"\"\"\n    Returns a random date\n    \"\"\"\n    return anon.faker.date(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a random decimal object", "response": "def decimal(anon, obj, field, val):\n    \"\"\"\n    Returns a random decimal\n    \"\"\"\n    return anon.faker.decimal(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a random postcode for the given field.", "response": "def postcode(anon, obj, field, val):\n    \"\"\"\n    Generates a random postcode (not necessarily valid, but it will look like one).\n    \"\"\"\n    return anon.faker.postcode(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef country(anon, obj, field, val):\n    return anon.faker.country(field=field)", "response": "Returns a randomly selected country"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a random username based on the user name", "response": "def username(anon, obj, field, val):\n    \"\"\"\n    Generates a random username\n    \"\"\"\n    return anon.faker.user_name(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a random first name for the given field", "response": "def first_name(anon, obj, field, val):\n    \"\"\"\n    Returns a random first name\n    \"\"\"\n    return anon.faker.first_name(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef last_name(anon, obj, field, val):\n    return anon.faker.last_name(field=field)", "response": "Returns a random second name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a random full name for the given field.", "response": "def name(anon, obj, field, val):\n    \"\"\"\n    Generates a random full name (using first name and last name)\n    \"\"\"\n    return anon.faker.name(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a random email address", "response": "def email(anon, obj, field, val):\n    \"\"\"\n    Generates a random email address.\n    \"\"\"\n    return anon.faker.email(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef similar_email(anon, obj, field, val):\n    return val if 'betterworks.com' in val else '@'.join([anon.faker.user_name(field=field), val.split('@')[-1]])", "response": "Generate a random email address using the same domain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a full address based on the given field and value.", "response": "def full_address(anon, obj, field, val):\n    \"\"\"\n    Generates a random full address, using newline characters between the lines.\n    Resembles a US address\n    \"\"\"\n    return anon.faker.address(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a US - style phone number", "response": "def phonenumber(anon, obj, field, val):\n    \"\"\"\n    Generates a random US-style phone number\n    \"\"\"\n    return anon.faker.phone_number(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef street_address(anon, obj, field, val):\n    return anon.faker.street_address(field=field)", "response": "Generates a random street address"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef city(anon, obj, field, val):\n    return anon.faker.city(field=field)", "response": "Generates a random city name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a randomly selected US state code", "response": "def state(anon, obj, field, val):\n    \"\"\"\n    Returns a randomly selected US state code\n    \"\"\"\n    return anon.faker.state(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a randomly generated US zip code.", "response": "def zip_code(anon, obj, field, val):\n    \"\"\"\n    Returns a randomly generated US zip code (not necessarily valid, but will look like one).\n    \"\"\"\n    return anon.faker.zipcode(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random company name", "response": "def company(anon, obj, field, val):\n    \"\"\"\n    Generates a random company name\n    \"\"\"\n    return anon.faker.company(field=field)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a paragraph of lorem ipsum text", "response": "def lorem(anon, obj, field, val):\n    \"\"\"\n    Generates a paragraph of lorem ipsum text\n    \"\"\"\n    return ' '.join(anon.faker.sentences(field=field))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unique_lorem(anon, obj, field, val):\n    return anon.faker.unique_lorem(field=field)", "response": "Generates a unique lorem ipsum text for the given field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef similar_datetime(anon, obj, field, val):\n    return anon.faker.datetime(field=field, val=val)", "response": "Returns a datetime that is within plus or minus two years of the original datetime"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef similar_date(anon, obj, field, val):\n    return anon.faker.date(field=field, val=val)", "response": "Returns a date that is within plus or minus two years of the original date"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating lorem ipsum text with the same length and same pattern of linebreaks as the original.", "response": "def similar_lorem(anon, obj, field, val):\n    \"\"\"\n    Generates lorem ipsum text with the same length and same pattern of linebreaks\n    as the original. If the original often takes a standard form (e.g. a single word\n    'yes' or 'no'), this could easily fail to hide the original data.\n    \"\"\"\n    return anon.faker.lorem(field=field, val=val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loads(data, cls=PVLDecoder, strict=True, **kwargs):\n    decoder = __create_decoder(cls, strict, **kwargs)\n    if not isinstance(data, bytes):\n        data = data.encode('utf-8')\n    return decoder.decode(data)", "response": "Deserialize data as a pvl module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nserializing a module as a pvl module to a stream.", "response": "def dump(module, stream, cls=PVLEncoder, **kwargs):\n    \"\"\"Serialize ``module`` as a pvl module to the provided ``stream``.\n\n    :param module: a ```PVLModule``` or ```dict``` like object to serialize\n\n    :param stream: a ``.write()``-supporting file-like object to serialize the\n        module to. If ``stream`` is a string it will be treated as a filename\n\n    :param cls: the encoder class used to serialize the pvl module. You may use\n        the default ``PVLEncoder`` class or provided encoder formats such as the\n        ```IsisCubeLabelEncoder``` and ```PDSLabelEncoder``` classes. You may\n        also provided a custom sublcass of ```PVLEncoder```\n\n    :param **kwargs: the keyword arguments to pass to the encoder class.\n    \"\"\"\n    if isinstance(stream, six.string_types):\n        with open(stream, 'wb') as fp:\n            return cls(**kwargs).encode(module, fp)\n    cls(**kwargs).encode(module, stream)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserializes a module as a pvl module formated byte string.", "response": "def dumps(module, cls=PVLEncoder, **kwargs):\n    \"\"\"Serialize ``module`` as a pvl module formated byte string.\n\n    :param module: a ```PVLModule``` or ```dict``` like object to serialize\n\n    :param cls: the encoder class used to serialize the pvl module. You may use\n        the default ``PVLEncoder`` class or provided encoder formats such as the\n        ```IsisCubeLabelEncoder``` and ```PDSLabelEncoder``` classes. You may\n        also provided a custom sublcass of ```PVLEncoder```\n\n    :param **kwargs: the keyword arguments to pass to the encoder class.\n\n    :returns: a byte string encoding of the pvl module\n    \"\"\"\n    stream = io.BytesIO()\n    cls(**kwargs).encode(module, stream)\n    return stream.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a method that will be called on the state class and return the result.", "response": "def _create_remote_dict_method(dict_method_name: str):\n    \"\"\"\n    Generates a method for the State class,\n    that will call the \"method_name\" on the state (a ``dict``) stored on the server,\n    and return the result.\n\n    Glorified RPC.\n    \"\"\"\n\n    def remote_method(self, *args, **kwargs):\n        return self._s_request_reply(\n            {\n                Msgs.cmd: Cmds.run_dict_method,\n                Msgs.info: dict_method_name,\n                Msgs.args: args,\n                Msgs.kwargs: kwargs,\n            }\n        )\n\n    remote_method.__name__ = dict_method_name\n    return remote_method"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_dict_method(self, request):\n        state_method_name, args, kwargs = (\n            request[Msgs.info],\n            request[Msgs.args],\n            request[Msgs.kwargs],\n        )\n        # print(method_name, args, kwargs)\n        with self.mutate_safely():\n            self.reply(getattr(self.state, state_method_name)(*args, **kwargs))", "response": "Execute a method on the state dict and reply with the result."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a function atomically and reply with the result.", "response": "def run_fn_atomically(self, request):\n        \"\"\"Execute a function, atomically and reply with the result.\"\"\"\n        fn = serializer.loads_fn(request[Msgs.info])\n        args, kwargs = request[Msgs.args], request[Msgs.kwargs]\n        with self.mutate_safely():\n            self.reply(fn(self.state, *args, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstop all Processes in the current Process tree recursively.", "response": "def clean_process_tree(*signal_handler_args):\n    \"\"\"Stop all Processes in the current Process tree, recursively.\"\"\"\n    parent = psutil.Process()\n    procs = parent.children(recursive=True)\n    if procs:\n        print(f\"[ZProc] Cleaning up {parent.name()!r} ({os.getpid()})...\")\n\n    for p in procs:\n        with suppress(psutil.NoSuchProcess):\n            p.terminate()\n    _, alive = psutil.wait_procs(procs, timeout=0.5)  # 0.5 seems to work\n    for p in alive:\n        with suppress(psutil.NoSuchProcess):\n            p.kill()\n\n    try:\n        signum = signal_handler_args[0]\n    except IndexError:\n        pass\n    else:\n        os._exit(signum)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef strict_request_reply(msg, send: Callable, recv: Callable):\n    try:\n        send(msg)\n    except Exception:\n        raise\n    try:\n        return recv()\n    except Exception:\n        with suppress(zmq.error.Again):\n            recv()\n        raise", "response": "Ensures a strict request - reply loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a new zproc server.", "response": "def start_server(\n        server_address: str = None, *, backend: Callable = multiprocessing.Process\n) -> Tuple[multiprocessing.Process, str]:\n    \"\"\"\n    Start a new zproc server.\n\n    :param server_address:\n        .. include:: /api/snippets/server_address.rst\n    :param backend:\n        .. include:: /api/snippets/backend.rst\n\n    :return: `\n        A `tuple``,\n        containing a :py:class:`multiprocessing.Process` object for server and the server address.\n    \"\"\"\n    recv_conn, send_conn = multiprocessing.Pipe()\n\n    server_process = backend(target=main, args=[server_address, send_conn])\n    server_process.start()\n\n    try:\n        with recv_conn:\n            server_meta: ServerMeta = serializer.loads(recv_conn.recv_bytes())\n    except zmq.ZMQError as e:\n        if e.errno == 98:\n            raise ConnectionError(\n                \"Encountered - %s. Perhaps the server is already running?\" % repr(e)\n            )\n        if e.errno == 22:\n            raise ValueError(\n                \"Encountered - %s. `server_address` must be a string containing a valid endpoint.\"\n                % repr(e)\n            )\n        raise\n\n    return server_process, server_meta.state_router"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npinging the zproc server.", "response": "def ping(\n        server_address: str, *, timeout: float = None, payload: Union[bytes] = None\n) -> int:\n    \"\"\"\n    Ping the zproc server.\n\n    This can be used to easily detect if a server is alive and running, with the aid of a suitable ``timeout``.\n\n    :param server_address:\n        .. include:: /api/snippets/server_address.rst\n    :param timeout:\n        The timeout in seconds.\n\n        If this is set to ``None``, then it will block forever, until the zproc server replies.\n\n        For all other values, it will wait for a reply,\n        for that amount of time before returning with a :py:class:`TimeoutError`.\n\n        By default it is set to ``None``.\n    :param payload:\n        payload that will be sent to the server.\n\n        If it is set to None, then ``os.urandom(56)`` (56 random bytes) will be used.\n\n        (No real reason for the ``56`` magic number.)\n\n    :return:\n        The zproc server's **pid**.\n    \"\"\"\n    if payload is None:\n        payload = os.urandom(56)\n\n    with util.create_zmq_ctx() as zmq_ctx:\n        with zmq_ctx.socket(zmq.DEALER) as dealer_sock:\n            dealer_sock.connect(server_address)\n            if timeout is not None:\n                dealer_sock.setsockopt(zmq.RCVTIMEO, int(timeout * 1000))\n\n            dealer_sock.send(\n                serializer.dumps(\n                    {Msgs.cmd: Cmds.ping, Msgs.info: payload}\n                )\n            )\n\n            try:\n                recv_payload, pid = serializer.loads(dealer_sock.recv())\n            except zmq.error.Again:\n                raise TimeoutError(\n                    \"Timed-out waiting while for the ZProc server to respond.\"\n                )\n\n            assert (\n                    recv_payload == payload\n            ), \"Payload doesn't match! The server connection may be compromised, or unstable.\"\n\n            return pid"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cookie_eater(ctx):\n    state = ctx.create_state()\n    state[\"ready\"] = True\n\n    for _ in state.when_change(\"cookies\"):\n        eat_cookie(state)", "response": "Eat cookies as they re baked."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_plus(target: Callable, mi, ma, a, mk, k):\n    if a is None:\n        a = []\n    if k is None:\n        k = {}\n\n    if mi is None and ma is None and mk is None:\n        return []\n    elif mi is None and ma is None:\n        return [target(*a, **mki, **k) for mki in mk]\n    elif ma is None and mk is None:\n        return [target(mii, *a, **k) for mii in mi]\n    elif mk is None and mi is None:\n        return [target(*mai, *a, **k) for mai in ma]\n    elif mi is None:\n        return [target(*mai, *a, **mki, **k) for mai, mki in zip(ma, mk)]\n    elif ma is None:\n        return [target(mii, *a, **mki, **k) for mii, mki in zip(mi, mk)]\n    elif mk is None:\n        return [target(mii, *mai, *a, **k) for mii, mai in zip(mi, ma)]\n    else:\n        return [target(mii, *mai, *a, **mki, **k) for mii, mai, mki in zip(mi, ma, mk)]", "response": "The builtin map function but with superpowers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a signal. Signal to a SignalException.", "response": "def signal_to_exception(sig: signal.Signals) -> SignalException:\n    \"\"\"\n    Convert a ``signal.Signals`` to a ``SignalException``.\n\n    This allows for natural, pythonic signal handing with the use of try-except blocks.\n\n    .. code-block:: python\n\n        import signal\n        import zproc\n\n        zproc.signal_to_exception(signals.SIGTERM)\n        try:\n            ...\n        except zproc.SignalException as e:\n            print(\"encountered:\", e)\n        finally:\n            zproc.exception_to_signal(signals.SIGTERM)\n    \"\"\"\n    signal.signal(sig, _sig_exc_handler)\n    return SignalException(sig)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap a function, to create an atomic operation out of it. This contract guarantees, that while an atomic ``fn`` is running - - No one, except the \"callee\" may access the state. - If an ``Exception`` occurs while the ``fn`` is running, the state remains unaffected. - | If a signal is sent to the \"callee\", the ``fn`` remains unaffected. | (The state is not left in an incoherent state.) .. note:: - The first argument to the wrapped function *must* be a :py:class:`State` object. - The wrapped ``fn`` receives a frozen version (snapshot) of state, which is a ``dict`` object, not a :py:class:`State` object. - It is not possible to call one atomic function from other. Please read :ref:`atomicity` for a detailed explanation. :param fn: The function to be wrapped, as an atomic function. :returns: A wrapper function. The wrapper function returns the value returned by the wrapped ``fn``. >>> import zproc >>> >>> @zproc.atomic ... def increment(snapshot): ... return snapshot['count'] + 1 ... >>> >>> ctx = zproc.Context() >>> state = ctx.create_state({'count': 0}) >>> >>> increment(state) 1", "response": "def atomic(fn: Callable) -> Callable:\n    \"\"\"\n    Wraps a function, to create an atomic operation out of it.\n\n    This contract guarantees, that while an atomic ``fn`` is running -\n\n    - No one, except the \"callee\" may access the state.\n    - If an ``Exception`` occurs while the ``fn`` is running, the state remains unaffected.\n    - | If a signal is sent to the \"callee\", the ``fn`` remains unaffected.\n      | (The state is not left in an incoherent state.)\n\n    .. note::\n        - The first argument to the wrapped function *must* be a :py:class:`State` object.\n        - The wrapped ``fn`` receives a frozen version (snapshot) of state,\n          which is a ``dict`` object, not a :py:class:`State` object.\n        - It is not possible to call one atomic function from other.\n\n    Please read :ref:`atomicity` for a detailed explanation.\n\n    :param fn:\n        The function to be wrapped, as an atomic function.\n\n    :returns:\n        A wrapper function.\n\n        The wrapper function returns the value returned by the wrapped ``fn``.\n\n    >>> import zproc\n    >>>\n    >>> @zproc.atomic\n    ... def increment(snapshot):\n    ...     return snapshot['count'] + 1\n    ...\n    >>>\n    >>> ctx = zproc.Context()\n    >>> state = ctx.create_state({'count': 0})\n    >>>\n    >>> increment(state)\n    1\n    \"\"\"\n    msg = {\n        Msgs.cmd: Cmds.run_fn_atomically,\n        Msgs.info: serializer.dumps_fn(fn),\n        Msgs.args: (),\n        Msgs.kwargs: {},\n    }\n\n    @wraps(fn)\n    def wrapper(state: State, *args, **kwargs):\n        msg[Msgs.args] = args\n        msg[Msgs.kwargs] = kwargs\n        return state._s_request_reply(msg)\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new state object that is a copy of this one.", "response": "def fork(self, server_address: str = None, *, namespace: str = None) -> \"State\":\n        r\"\"\"\n        \"Forks\" this State object.\n\n        Takes the same args as the :py:class:`State` constructor,\n        except that they automatically default to the values provided during the creation of this State object.\n\n        If no args are provided to this function,\n        then it shall create a new :py:class:`State` object\n        that follows the exact same semantics as this one.\n\n        This is preferred over ``copy()``\\ -ing a :py:class:`State` object.\n\n        Useful when one needs to access 2 or more namespaces from the same code.\n        \"\"\"\n        if server_address is None:\n            server_address = self.server_address\n        if namespace is None:\n            namespace = self.namespace\n\n        return self.__class__(server_address, namespace=namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, value: dict):\n        self._s_request_reply({Msgs.cmd: Cmds.set_state, Msgs.info: value})", "response": "Set the state of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef when_change(\n        self,\n        *keys: Hashable,\n        exclude: bool = False,\n        live: bool = False,\n        timeout: float = None,\n        identical_okay: bool = False,\n        start_time: bool = None,\n        count: int = None,\n    ) -> StateWatcher:\n        \"\"\"\n        Block until a change is observed, and then return a copy of the state.\n\n        .. include:: /api/state/get_when_change.rst\n        \"\"\"\n        if not keys:\n\n            def callback(update: StateUpdate) -> dict:\n                return update.after\n\n        else:\n            if identical_okay:\n                raise ValueError(\n                    \"Passing both `identical_okay` and `keys` is not possible. \"\n                    \"(Hint: Omit `keys`)\"\n                )\n\n            key_set = set(keys)\n\n            def select(before, after):\n                selected = {*before.keys(), *after.keys()}\n                if exclude:\n                    return selected - key_set\n                else:\n                    return selected & key_set\n\n            def callback(update: StateUpdate) -> dict:\n                before, after = update.before, update.after\n                try:\n                    if not any(before[k] != after[k] for k in select(before, after)):\n                        raise _SkipStateUpdate\n                except KeyError:  # this indirectly implies that something has changed\n                    pass\n                return update.after\n\n        return StateWatcher(\n            state=self,\n            live=live,\n            timeout=timeout,\n            identical_okay=identical_okay,\n            start_time=start_time,\n            count=count,\n            callback=callback,\n        )", "response": "Block until a change is observed and then return a copy of the state."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef when(\n        self,\n        test_fn,\n        *,\n        args: Sequence = None,\n        kwargs: Mapping = None,\n        live: bool = False,\n        timeout: float = None,\n        identical_okay: bool = False,\n        start_time: bool = None,\n        count: int = None,\n    ) -> StateWatcher:\n        \"\"\"\n        Block until ``test_fn(snapshot)`` returns a \"truthy\" value,\n        and then return a copy of the state.\n\n        *Where-*\n\n        ``snapshot`` is a ``dict``, containing a version of the state after this update was applied.\n\n        .. include:: /api/state/get_when.rst\n        \"\"\"\n        if args is None:\n            args = []\n        if kwargs is None:\n            kwargs = {}\n\n        def callback(update: StateUpdate) -> dict:\n            snapshot = update.after\n            if test_fn(snapshot, *args, **kwargs):\n                return snapshot\n            raise _SkipStateUpdate\n\n        return StateWatcher(\n            state=self,\n            live=live,\n            timeout=timeout,\n            identical_okay=identical_okay,\n            start_time=start_time,\n            count=count,\n            callback=callback,\n        )", "response": "Block until test_fn returns a truthy value and then return a copy of the state."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef when_equal(self, key: Hashable, value: Any, **when_kwargs) -> StateWatcher:\n\n        def _(snapshot):\n            try:\n                return snapshot[key] == value\n            except KeyError:\n                return False\n\n        return self.when(_, **when_kwargs)", "response": "Block until state [ key ] == value and then return a copy of the state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef when_available(self, key: Hashable, **when_kwargs) -> StateWatcher:\n        return self.when(lambda snapshot: key in snapshot, **when_kwargs)", "response": "Block until the given key is available and then return a copy of the state."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(self):\n        self.child.terminate()\n        self._cleanup()\n        return self.child.exitcode", "response": "Stop this process.\n\n        Once closed, it should not, and cannot be used again.\n\n        :return: :py:attr:`~exitcode`."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait until the child process finishes execution and return the value returned by the target function.", "response": "def wait(self, timeout: Union[int, float] = None):\n        \"\"\"\n        Wait until this process finishes execution,\n        then return the value returned by the ``target``.\n\n        This method raises a a :py:exc:`.ProcessWaitError`,\n        if the child Process exits with a non-zero exitcode,\n        or if something goes wrong while communicating with the child.\n\n        :param timeout:\n            The timeout in seconds.\n\n            If the value is ``None``, it will block until the zproc server replies.\n\n            For all other values, it will wait for a reply,\n            for that amount of time before returning with a :py:class:`TimeoutError`.\n\n        :return:\n            The value returned by the ``target`` function.\n        \"\"\"\n        # try to fetch the cached result.\n        if self._has_returned:\n            return self._result\n\n        if timeout is not None:\n            target = time.time() + timeout\n            while time.time() < target:\n                self.child.join(timeout)\n\n            if self.is_alive:\n                raise TimeoutError(\n                    f\"Timed-out while waiting for Process to return. -- {self!r}\"\n                )\n        else:\n            self.child.join()\n            if self.is_alive:\n                return None\n        exitcode = self.exitcode\n        if exitcode != 0:\n            raise exceptions.ProcessWaitError(\n                f\"Process finished with a non-zero exitcode ({exitcode}). -- {self!r}\",\n                exitcode,\n                self,\n            )\n        try:\n            self._result = serializer.loads(self._result_sock.recv())\n        except zmq.error.Again:\n            raise exceptions.ProcessWaitError(\n                \"The Process died before sending its return value. \"\n                \"It probably crashed, got killed, or exited without warning.\",\n                exitcode,\n            )\n\n        self._has_returned = True\n        self._cleanup()\n        return self._result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwaits for all the child Processes in this Context to complete.", "response": "def wait(\n        self, timeout: Union[int, float] = None, safe: bool = False\n    ) -> List[Union[Any, Exception]]:\n        \"\"\"\n        Call :py:meth:`~Process.wait()` on all the Processes in this list.\n\n        :param timeout:\n            Same as :py:meth:`~Process.wait()`.\n\n            This parameter controls the timeout for all the Processes combined,\n            not a single :py:meth:`~Process.wait()` call.\n        :param safe:\n            Suppress any errors that occur while waiting for a Process.\n\n            The return value of failed :py:meth:`~Process.wait()` calls are substituted with the ``Exception`` that occurred.\n        :return:\n            A ``list`` containing the values returned by child Processes of this Context.\n        \"\"\"\n        if safe:\n            _wait = self._wait_or_catch_exc\n        else:\n            _wait = Process.wait\n\n        if timeout is None:\n            return [_wait(process) for process in self]\n        else:\n            final = time.time() + timeout\n            return [_wait(process, final - time.time()) for process in self]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_state(self, value: dict = None, *, namespace: str = None):\n        if namespace is None:\n            namespace = self.namespace\n        state = State(self.server_address, namespace=namespace)\n        if value is not None:\n            state.update(value)\n        return state", "response": "Creates a new state object with the given value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process(\n        self, target: Callable = None, **process_kwargs\n    ) -> Union[Process, Callable]:\n        r\"\"\"\n        Produce a child process bound to this context.\n\n        Can be used both as a function and decorator:\n\n        .. code-block:: python\n            :caption: Usage\n\n            @zproc.process(pass_context=True)  # you may pass some arguments here\n            def p1(ctx):\n                print('hello', ctx)\n\n\n            @zproc.process  # or not...\n            def p2(state):\n                print('hello', state)\n\n\n            def p3(state):\n                print('hello', state)\n\n            zproc.process(p3)  # or just use as a good ol' function\n\n        :param target:\n            Passed on to the :py:class:`Process` constructor.\n\n            *Must be omitted when using this as a decorator.*\n\n        :param \\*\\*process_kwargs:\n            .. include:: /api/context/params/process_kwargs.rst\n\n        :return: The :py:class:`Process` instance produced.\n        \"\"\"\n        process = Process(\n            self.server_address, target, **{**self.process_kwargs, **process_kwargs}\n        )\n        self.process_list.append(process)\n        return process", "response": "Creates a child process bound to this context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait for the process list to be empty", "response": "def wait(\n        self, timeout: Union[int, float] = None, safe: bool = False\n    ) -> List[Union[Any, Exception]]:\n        \"\"\"\n        alias for :py:meth:`ProcessList.wait()`\n        \"\"\"\n        return self.process_list.wait(timeout, safe)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a dict of items some of which are scalar and some of which are lists to a list of dicts with scalar items.", "response": "def _expand_scheduledict(scheduledict):\n    \"\"\"Converts a dict of items, some of which are scalar and some of which are\n    lists, to a list of dicts with scalar items.\"\"\"\n    result = []\n    def f(d):\n        nonlocal result\n        #print(d)\n        d2 = {}\n        for k,v in d.items():\n            if isinstance(v, str) and _cronslash(v, k) is not None:\n                d[k] = _cronslash(v, k)\n\n        for k,v in d.items():\n            if isinstance(v, Iterable):\n                continue\n            else:\n                d2[k] = v\n\n        if len(d2.keys()) == len(d.keys()):\n            result.append(d2)\n            return\n\n        for k,v in d.items():\n            if isinstance(v, Iterable):\n                for i in v:\n                    dprime = dict(**d)\n                    dprime[k] = i\n                    f(dprime)\n                break\n    f(scheduledict)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef interval_next(f, t = datetime.now(), tLast = datetime.now()):\n    has_interval = hasattr(f, \"interval\")\n    has_schedule = hasattr(f, \"schedule\")\n\n    if (not has_interval and not has_schedule):\n        return 0\n    if (has_interval and not has_schedule):\n        tNext = tLast + timedelta(seconds = f.interval)\n        return max(total_seconds(tNext - t), 0)\n    if (has_schedule): # and not has_interval):\n        interval_min = 3600\n        for s in f.schedule:\n            interval = schedule_next(s, t)\n            if interval < interval_min:\n                interval_min = interval\n        return interval_min", "response": "This function calculates the number of seconds until the next event in the sequence t is in the next interval of the function f."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_mentions(status_dict, exclude=[]):\n    # Canonicalise the exclusion dictionary by lowercasing all names and\n    # removing leading @'s\n    for i, user in enumerate(exclude):\n        user = user.casefold()\n        if user[0] == \"@\":\n            user = user[1:]\n\n        exclude[i] = user\n\n    users = [user[\"username\"] for user in status_dict[\"mentions\"]\n             if user[\"username\"].casefold() not in exclude]\n    return users", "response": "Given a status dictionary return all people mentioned in the toot excluding those in the list passed in exclude."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef report_error(self, error, location=None):\n        if location == None: location = inspect.stack()[1][3]\n        self.log(location, error)\n        for f in self.report_funcs:\n            f(error)", "response": "Report an error that occurred during bot operations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a status dict return the visibility that should be used.", "response": "def get_reply_visibility(self, status_dict):\n        \"\"\"Given a status dict, return the visibility that should be used.\n        This behaves like Mastodon does by default.\n        \"\"\"\n        # Visibility rankings (higher is more limited)\n        visibility = (\"public\", \"unlisted\", \"private\", \"direct\")\n\n        default_visibility = visibility.index(self.default_visibility)\n        status_visibility = visibility.index(status_dict[\"visibility\"])\n\n        return visibility[max(default_visibility, status_visibility)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the dice specification as a string in a common format", "response": "def spec_dice(spec):\n    \"\"\" Return the dice specification as a string in a common format \"\"\"\n    if spec[0] == 'c': \n        return str(spec[1])\n    elif spec[0] == 'r':\n        r = spec[1:]\n        s = \"{}d{}\".format(r[0], r[1])\n        if len(r) == 4 and ((r[2] == 'd' and r[3] < r[0]) or (r[2] == 'k' and r[3] > 0)):\n            s += \"{}{}\".format(r[2], r[3])\n        return s\n    elif spec[0] in ops:\n        return \"{} {} {}\".format(spec_dice(spec[1]), spec[0], spec_dice(spec[2]))\n    else: raise ValueError(\"Invalid dice specification\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef roll_dice(spec):\n    if spec[0] == 'c': return spec\n    if spec[0] == 'r':\n        r = spec[1:]\n        if len(r) == 2: return ('r', perform_roll(r[0], r[1]))\n        k = r[3] if r[2] == 'k' else -1 \n        d = r[3] if r[2] == 'd' else -1\n        return ('r', perform_roll(r[0], r[1], k, d))\n    if spec[0] == \"x\":\n        c = None\n        roll = None\n        if spec[1][0] == \"c\": c = spec[1]\n        elif spec[1][0] == \"r\": roll = spec[1]\n        if spec[2][0] == \"c\": c = spec[2]\n        elif spec[2][0] == \"r\": roll = spec[2]\n\n        if (c == None or roll == None):\n            return ('*', roll_dice(spec[1]), roll_dice(spec[2]))\n        else:\n            if (c[1] > 50):\n                raise SillyDiceError(\"I don't have that many dice!\")\n            return (\"x\", [roll_dice(roll) for i in range(c[1])])\n    if spec[0] in ops:\n        return (spec[0], roll_dice(spec[1]), roll_dice(spec[2]))\n    else: raise ValueError(\"Invalid dice specification\")", "response": "Perform the dice rolls and replace all roll expressions with lists of\n    the dice faces that landed up."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsum the dice in place with summations of roll_dice the rolls.", "response": "def sum_dice(spec):\n    \"\"\" Replace the dice roll arrays from roll_dice in place with summations of\n    the rolls. \"\"\"\n    if spec[0] == 'c': return spec[1]\n    elif spec[0] == 'r': return sum(spec[1])\n    elif spec[0] == 'x':\n        return [sum_dice(r) for r in spec[1]]\n    elif spec[0] in ops:\n        return (spec[0], sum_dice(spec[1]), sum_dice(spec[2]))\n    else: raise ValueError(\"Invalid dice specification\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef short_sequence_repeat_extractor(string, min_length=1):\n    length = len(string)\n\n    k_max = length // 2 + 1\n    if k_max > THRESHOLD:\n        k_max = THRESHOLD // 2\n\n    repeats = []\n\n    i = 0\n    last_repeat = i\n    while i < length:\n        max_count = 0\n        max_k = 1\n        for k in range(min_length, k_max):\n            count = 0\n            for j in range(i + k, length - k + 1, k):\n                if string[i:i + k] != string[j:j + k]:\n                    break\n                count += 1\n\n            if count > 0 and count >= max_count:\n                max_count = count\n                max_k = k\n\n        if max_count > 0:\n            if last_repeat < i:\n                repeats.append(Repeat(last_repeat, i))\n            repeats.append(Repeat(i, i + max_k, max_count))\n            last_repeat = i + max_k * (max_count + 1)\n\n        i += max_k * (max_count + 1)\n\n    if last_repeat < i:\n        repeats.append(Repeat(last_repeat, i))\n\n    return repeats", "response": "This function extracts the short tandem repeat structure from a string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting an error message to stderr", "response": "def raiseError(cls, message):\n        \"\"\" Print an error message\n\n            Args:\n                message: the message to print\n        \"\"\"\n        error_message = \"[error] %s\" % message\n        if cls.__raise_exception__:\n            raise Exception(error_message)\n\n        cls.colorprint(error_message, Fore.RED)\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef json(cls, message):\n\n        if type(message) is OrderedDict:\n            pprint(dict(message))\n        else:\n            pprint(message)", "response": "Print a nice JSON output of the current node s state"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms the current specification to a dictionary", "response": "def to_dict(self):\n        \"\"\" Transform the current specification to a dictionary\n\n        \"\"\"\n\n        data = {\"model\": {}}\n\n        data[\"model\"][\"description\"] = self.description\n        data[\"model\"][\"entity_name\"] = self.entity_name\n        data[\"model\"][\"package\"] = self.package\n        data[\"model\"][\"resource_name\"] = self.resource_name\n        data[\"model\"][\"rest_name\"] = self.rest_name\n        data[\"model\"][\"extends\"] = self.extends\n        data[\"model\"][\"get\"] = self.allows_get\n        data[\"model\"][\"update\"] = self.allows_update\n        data[\"model\"][\"create\"] = self.allows_create\n        data[\"model\"][\"delete\"] = self.allows_delete\n        data[\"model\"][\"root\"] = self.is_root\n        data[\"model\"][\"userlabel\"] = self.userlabel\n        data[\"model\"][\"template\"] = self.template\n        data[\"model\"][\"allowed_job_commands\"] = self.allowed_job_commands\n\n        data[\"attributes\"] = []\n        for attribute in self.attributes:\n            data[\"attributes\"].append(attribute.to_dict())\n\n        data[\"children\"] = []\n        for api in self.child_apis:\n            data[\"children\"].append(api.to_dict())\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfilling the current object with information from the specification.", "response": "def from_dict(self, data):\n        \"\"\" Fill the current object with information from the specification\n\n        \"\"\"\n        if \"model\" in data:\n            model = data[\"model\"]\n            self.description = model[\"description\"] if \"description\" in model else None\n            self.package = model[\"package\"] if \"package\" in model else None\n            self.extends = model[\"extends\"] if \"extends\" in model else []\n            self.entity_name = model[\"entity_name\"] if \"entity_name\" in model else None\n            self.rest_name = model[\"rest_name\"] if \"rest_name\" in model else None\n            self.resource_name = model[\"resource_name\"] if \"resource_name\" in model else None\n            self.allows_get = model[\"get\"] if \"get\" in model else False\n            self.allows_create = model[\"create\"] if \"create\" in model else False\n            self.allows_update = model[\"update\"] if \"update\" in model else False\n            self.allows_delete = model[\"delete\"] if \"delete\" in model else False\n            self.is_root = model[\"root\"] if \"root\" in model else False\n            self.userlabel = model[\"userlabel\"] if \"userlabel\" in model else None\n            self.template = model[\"template\"] if \"template\" in model else False\n            self.allowed_job_commands = model[\"allowed_job_commands\"] if \"allowed_job_commands\" in model else None\n\n        if \"attributes\" in data:\n            self.attributes = self._get_attributes(data[\"attributes\"])\n\n        if \"children\" in data:\n            self.child_apis = self._get_apis(data[\"children\"])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess the given list of apis for the current model", "response": "def _get_apis(self, apis):\n        \"\"\" Process apis for the given model\n\n            Args:\n                model: the model processed\n                apis: the list of apis availble for the current model\n                relations: dict containing all relations between resources\n        \"\"\"\n        ret = []\n\n        for data in apis:\n            ret.append(SpecificationAPI(specification=self, data=data))\n\n        return sorted(ret, key=lambda x: x.rest_name[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _write_abstract_named_entity(self):\n        filename = \"%sAbstractNamedEntity.js\" % (self._class_prefix)\n                \n        superclass_name = \"%sEntity\" % (self._class_prefix)\n        \n        # write will write a file using a template.\n        # mandatory params: destination directory, destination file name, template file name\n        # optional params: whatever that is needed from inside the Jinja template\n\n        self.write(destination = self.abstract_directory,\n                    filename = filename,\n                    template_name = \"abstract_named_entity.js.tpl\",\n                    class_prefix = self._class_prefix,\n                    superclass_name = superclass_name)", "response": "This method generates AbstractNamedEntity class js file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait_until_exit(self):\n        [t.join() for t in self.threads]\n\n        self.threads = list()", "response": "Wait until all the threads are finished."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_task(self, method, *args, **kwargs):\n        thread = threading.Thread(target=method, args=args, kwargs=kwargs)\n        thread.is_daemon = False\n        thread.start()\n        self.threads.append(thread)", "response": "Start a task in a separate thread"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a given report to the list of reports that are in the specified key .", "response": "def add_report(self, specification_name, report):\n        \"\"\"\n            Adds a given report with the given specification_name as key\n            to the reports list and computes the number of success, failures\n            and errors\n\n            Args:\n                specification_name: string representing the specification (with \".spec\")\n                report: The\n        \"\"\"\n        self._reports[specification_name] = report\n\n        self._total = self._total + report.testsRun\n        self._failures = self._failures + len(report.failures)\n        self._errors = self._errors + len(report.errors)\n        self._success = self._total - self._failures - self._errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef massage_type_name(cls, type_name):\n        if type_name.lower() in (\"enum\", \"enumeration\"):\n            return \"enum\"\n\n        if type_name.lower() in (\"str\", \"string\"):\n            return \"string\"\n\n        if type_name.lower() in (\"boolean\", \"bool\"):\n            return \"boolean\"\n\n        if type_name.lower() in (\"int\", \"integer\"):\n            return \"integer\"\n\n        if type_name.lower() in (\"date\", \"datetime\", \"time\"):\n            return \"time\"\n\n        if type_name.lower() in (\"double\", \"float\", \"long\"):\n            return \"float\"\n\n        if type_name.lower() in (\"list\", \"array\"):\n            return \"list\"\n\n        if type_name.lower() in (\"object\", \"dict\"):\n            return \"object\"\n\n        if \"array\" in type_name.lower():\n            return \"list\"\n\n        return \"string\"", "response": "Returns a readable type according to a java type name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the name for the given language", "response": "def get_idiomatic_name_in_language(cls, name, language):\n        \"\"\" Get the name for the given language\n\n            Args:\n                name (str): the name to convert\n                language (str): the language to use\n\n            Returns:\n                a name in the given language\n\n            Example:\n                get_idiomatic_name_in_language(\"EnterpriseNetwork\", \"python\")\n                >>> enterprise_network\n        \"\"\"\n        if language in cls.idiomatic_methods_cache:\n            m = cls.idiomatic_methods_cache[language]\n            if not m:\n                return name\n            return m(name)\n\n        found, method = load_language_plugins(language, 'get_idiomatic_name')\n        if found:\n            cls.idiomatic_methods_cache[language] = method\n            if method:\n                return method(name)\n            else:\n                return name\n\n        module = importlib.import_module('.lang.%s' % language, package=\"monolithe.generators\")\n\n        if not hasattr(module, 'get_idiomatic_name'):\n            cls.idiomatic_methods_cache[language] = None\n            return name\n\n        method = getattr(module, 'get_idiomatic_name')\n        cls.idiomatic_methods_cache[language] = method\n        return method(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_type_name_in_language(cls, type_name, sub_type, language):\n        if language in cls.type_methods_cache:\n            m = cls.type_methods_cache[language]\n            if not m:\n                return type_name\n            return m(type_name)\n\n        found, method = load_language_plugins(language, 'get_type_name')\n        if found:\n            cls.type_methods_cache[language] = method\n            if method:\n                return method(type_name, sub_type)\n            else:\n                return type_name\n\n        module = importlib.import_module('.lang.%s' % language, package=\"monolithe.generators\")\n\n        if not hasattr(module, 'get_type_name'):\n            cls.type_methods_cache[language] = None\n            return type_name\n\n        method = getattr(module, 'get_type_name')\n        cls.type_methods_cache[language] = method\n        return method(type_name, sub_type)", "response": "Get the type name in the given language"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_type_name(type_name, sub_type=None):\n    if type_name == \"enum\":\n        return type_name\n    elif type_name == \"boolean\":\n        return \"bool\"\n    elif type_name == \"integer\":\n        return \"long\"\n    elif type_name == \"time\":\n        return \"long\"\n    elif type_name == \"object\":\n        return \"Object\"\n    elif type_name == \"list\":\n        return \"List\"\n    elif type_name == \"float\":\n        return \"float\"\n    else:\n        return \"String\"", "response": "Returns a c# type according to a spec type name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _write_build_file(self):\n        self.write(destination=self._base_output_directory,\n                   filename=\"pom.xml\",\n                   template_name=\"pom.xml.tpl\",\n                   version=self.api_version,\n                   product_accronym=self._product_accronym,\n                   class_prefix=self._class_prefix,\n                   root_api=self.api_root,\n                   api_prefix=self.api_prefix,\n                   product_name=self._product_name,\n                   name=self._name,\n                   header=self.header_content,\n                   version_string=self._api_version_string,\n                   package_prefix=self._package_prefix,\n                   library_version=self.library_version)", "response": "Write the build file to the output directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_type_name(type_name, sub_type=None):\n    if type_name in (\"string\", \"enum\"):\n        return \"string\"\n\n    if type_name == \"float\":\n        return \"float64\"\n\n    if type_name == \"boolean\":\n        return \"bool\"\n\n    if type_name == \"list\":\n        st = get_type_name(type_name=sub_type, sub_type=None) if sub_type else \"interface{}\"\n        return \"[]%s\" % st\n\n    if type_name == \"integer\":\n        return \"int\"\n\n    if type_name == \"time\":\n        return \"float64\"\n\n    return \"interface{}\"", "response": "Returns a go type according to a spec type_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite API Info file", "response": "def _write_info(self):\n        \"\"\" Write API Info file\n        \"\"\"\n        self.write(destination=self.output_directory,\n                   filename=\"vspk/SdkInfo.cs\",\n                   template_name=\"sdkinfo.cs.tpl\",\n                   version=self.api_version,\n                   product_accronym=self._product_accronym,\n                   class_prefix=self._class_prefix,\n                   root_api=self.api_root,\n                   api_prefix=self.api_prefix,\n                   product_name=self._product_name,\n                   name=self._name,\n                   header=self.header_content,\n                   version_string=self._api_version_string,\n                   package_name=self._package_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the model file for the current specification.", "response": "def _write_model(self, specification, specification_set):\n        \"\"\" Write autogenerate specification file\n\n        \"\"\"\n        filename = \"vspk/%s%s.cs\" % (self._class_prefix, specification.entity_name)\n\n        override_content = self._extract_override_content(specification.entity_name)\n        superclass_name = \"RestObject\"\n\n        defaults = {}\n        section = specification.entity_name\n        if self.attrs_defaults.has_section(section):\n            for attribute in self.attrs_defaults.options(section):\n                defaults[attribute] = self.attrs_defaults.get(section, attribute)\n\n        self.write(destination=self.output_directory,\n                   filename=filename,\n                   template_name=\"model.cs.tpl\",\n                   specification=specification,\n                   specification_set=specification_set,\n                   version=self.api_version,\n                   name=self._name,\n                   class_prefix=self._class_prefix,\n                   product_accronym=self._product_accronym,\n                   override_content=override_content,\n                   superclass_name=superclass_name,\n                   header=self.header_content,\n                   version_string=self._api_version_string,\n                   package_name=self._package_name,\n                   attribute_defaults=defaults)\n\n        return (filename, specification.entity_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite fetcher. cs file", "response": "def _write_fetcher(self, specification, specification_set):\n        \"\"\" Write fetcher\n\n        \"\"\"\n        destination = \"%s\" % (self.output_directory)\n        base_name = \"%sFetcher\" % specification.entity_name_plural\n        filename = \"vspk/%s%s.cs\" % (self._class_prefix, base_name)\n        override_content = self._extract_override_content(base_name)\n\n        self.write(destination=destination,\n                   filename=filename,\n                   template_name=\"fetcher.cs.tpl\",\n                   specification=specification,\n                   specification_set=specification_set,\n                   class_prefix=self._class_prefix,\n                   product_accronym=self._product_accronym,\n                   override_content=override_content,\n                   header=self.header_content,\n                   name=self._name,\n                   version_string=self._api_version_string,\n                   package_name=self._package_name)\n\n        return (filename, specification.entity_name_plural)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_enum_list_local_type(self, specifications):\n        for rest_name, specification in specifications.items():\n            for attribute in specification.attributes:\n                if attribute.type == \"enum\":\n                    enum_type = attribute.local_name[0:1].upper() + attribute.local_name[1:]\n                    attribute.local_type = enum_type\n                elif attribute.type == \"object\":\n                    attr_type = \"Object\"\n                    if self.attrs_types.has_option(specification.entity_name, attribute.local_name):\n                        type = self.attrs_types.get(specification.entity_name, attribute.local_name)\n                        if type:\n                            attr_type = type\n                    attribute.local_type = attr_type\n                elif attribute.type == \"list\":\n                    if attribute.subtype == \"enum\":\n                        enum_subtype = attribute.local_name[0:1].upper() + attribute.local_name[1:]\n                        attribute.local_type = \"System.Collections.Generic.List<E\" + enum_subtype + \">\"\n                    elif attribute.subtype == \"object\":\n                        attr_subtype = \"JObject\"\n                        if self.attrs_types.has_option(specification.entity_name, attribute.local_name):\n                            subtype = self.attrs_types.get(specification.entity_name, attribute.local_name)\n                            if subtype:\n                                attr_subtype = subtype\n                        attribute.local_type = \"System.Collections.Generic.List<\" + attr_subtype + \">\"\n                    elif attribute.subtype == \"entity\":\n                        attribute.local_type = \"System.Collections.Generic.List<JObject>\"\n                    else:\n                        attribute.local_type = \"System.Collections.Generic.List<String>\"", "response": "This method is used to set the local type of the Enum List."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming an attribute to a dict.", "response": "def to_dict(self):\n        \"\"\" Transform an attribute to a dict\n        \"\"\"\n        data = {}\n\n        # mandatory characteristics\n        data[\"name\"] = self.name\n        data[\"description\"] = self.description if self.description and len(self.description) else None\n        data[\"type\"] = self.type if self.type and len(self.type) else None\n        data[\"allowed_chars\"] = self.allowed_chars if self.allowed_chars and len(self.allowed_chars) else None\n        data[\"allowed_choices\"] = self.allowed_choices\n        data[\"autogenerated\"] = self.autogenerated\n        data[\"channel\"] = self.channel if self.channel and len(self.channel) else None\n        data[\"creation_only\"] = self.creation_only\n        data[\"default_order\"] = self.default_order\n        data[\"default_value\"] = self.default_value if self.default_value and len(self.default_value) else None\n        data[\"deprecated\"] = self.deprecated\n        data[\"exposed\"] = self.exposed\n        data[\"filterable\"] = self.filterable\n        data[\"format\"] = self.format if self.format and len(self.format) else None\n        data[\"max_length\"] = int(self.max_length) if self.max_length is not None else None\n        data[\"max_value\"] = int(self.max_value) if self.max_value is not None else None\n        data[\"min_length\"] = int(self.min_length) if self.min_length is not None else None\n        data[\"min_value\"] = int(self.min_value) if self.min_value is not None else None\n        data[\"orderable\"] = self.orderable\n        data[\"read_only\"] = self.read_only\n        data[\"required\"] = self.required\n        data[\"transient\"] = self.transient\n        data[\"unique\"] = self.unique\n        data[\"uniqueScope\"] = self.unique_scope if self.unique_scope and len(self.unique_scope) else None\n        data[\"subtype\"] = self.subtype if self.subtype and len(self.subtype) else None\n        data[\"userlabel\"] = self.userlabel if self.userlabel and len(self.userlabel) else None\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write_model(self, specification, specification_set, output_directory, package_name):\n        template_file = \"o11nplugin-core/model.java.tpl\"\n        filename = \"%s%s.java\" % (self._class_prefix, specification.entity_name)\n\n        override_content = self._extract_override_content(specification.entity_name)\n        superclass_name = \"BaseRootObject\" if specification.rest_name == self.api_root else \"BaseObject\"\n\n        defaults = {}\n        section = specification.entity_name\n        if self.attrs_defaults.has_section(section):\n            for attribute in self.attrs_defaults.options(section):\n                defaults[attribute] = self.attrs_defaults.get(section, attribute)\n\n        entity_includes = self._get_entity_list_filter(self.inventory_entities, section, \"includes\")\n        entity_excludes = self._get_entity_list_filter(self.inventory_entities, section, \"excludes\")\n        entity_name_attr = \"id\"\n        if self.inventory_entities.has_section(section):\n            if self.inventory_entities.has_option(section, \"name\"):\n                entity_name_attr = self.inventory_entities.get(section, \"name\")\n\n        self.write(destination=output_directory,\n                   filename=filename, \n                   template_name=template_file,\n                   specification=specification,\n                   specification_set=specification_set,\n                   version=self.api_version,\n                   name=self._name,\n                   class_prefix=self._class_prefix,\n                   product_accronym=self._product_accronym,\n                   override_content=override_content,\n                   superclass_name=superclass_name,\n                   header=self.header_content,\n                   version_string=self._api_version_string,\n                   package_name=package_name,\n                   attribute_defaults=defaults,\n                   entity_name_attr=entity_name_attr,\n                   root_api=self.api_root,\n                   entity_includes=entity_includes,\n                   entity_excludes=entity_excludes)\n\n        return (filename, specification.entity_name)", "response": "Write the model file for the specified specification."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting an enumeration file", "response": "def _write_enum(self, specification, attribute, output_directory, package_name):\n        \"\"\" Write autogenerate specification file\n\n        \"\"\"\n        enum_name = specification.entity_name + attribute.local_name[0:1].upper() + attribute.local_name[1:]\n        template_file = \"o11nplugin-core/enum.java.tpl\"\n        destination = \"%s%s\" % (output_directory, self.enums_path)\n        filename = \"%s%s.java\" % (self._class_prefix, enum_name)\n\n        self.write(destination=destination,\n                   filename=filename, \n                   template_name=template_file,\n                   header=self.header_content,\n                   specification=specification,\n                   package_name=package_name,\n                   enum_name=enum_name,\n                   attribute=attribute)\n\n        return (filename, specification.entity_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a file at the specific destination with the content.", "response": "def write(self, destination, filename, content):\n        \"\"\" Write a file at the specific destination with the content.\n\n            Args:\n                destination (string): the destination location\n                filename (string): the filename that will be written\n                content (string): the content of the filename\n\n        \"\"\"\n        if not os.path.exists(destination):\n            try:\n                os.makedirs(destination)\n            except:  # The directory can be created while creating it.\n                pass\n\n        filepath = \"%s/%s\" % (destination, filename)\n\n        f = open(filepath, \"w+\")\n        f.write(content)\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, destination, filename, template_name, **kwargs):\n        template = self.env.get_template(template_name)\n        content = template.render(kwargs)\n        super(TemplateFileWriter, self).write(destination=destination, filename=filename, content=content)", "response": "Writes a file according to the template name\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write_session(self):\n        base_name = \"%ssession\" % self._product_accronym.lower()\n        filename = \"%s%s.py\" % (self._class_prefix.lower(), base_name)\n        override_content = self._extract_override_content(base_name)\n\n        self.write(destination=self.output_directory, filename=filename, template_name=\"session.py.tpl\",\n                   version=self.api_version,\n                   product_accronym=self._product_accronym,\n                   class_prefix=self._class_prefix,\n                   root_api=self.api_root,\n                   api_prefix=self.api_prefix,\n                   override_content=override_content,\n                   header=self.header_content)", "response": "Writes the SDK session file to the output directory"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _write_init_models(self, filenames):\n\n        self.write(destination=self.output_directory, filename=\"__init__.py\", template_name=\"__init_model__.py.tpl\",\n                   filenames=self._prepare_filenames(filenames),\n                   class_prefix=self._class_prefix,\n                   product_accronym=self._product_accronym,\n                   header=self.header_content)", "response": "Write init file\n\n            Args:\n                filenames (dict): dict of filename and classes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the model file for the current specification", "response": "def _write_model(self, specification, specification_set):\n        \"\"\" Write autogenerate specification file\n\n        \"\"\"\n        filename = \"%s%s.py\" % (self._class_prefix.lower(), specification.entity_name.lower())\n\n        override_content = self._extract_override_content(specification.entity_name)\n        constants = self._extract_constants(specification)\n        superclass_name = \"NURESTRootObject\" if specification.rest_name == self.api_root else \"NURESTObject\"\n\n        self.write(destination=self.output_directory, filename=filename, template_name=\"model.py.tpl\",\n                   specification=specification,\n                   specification_set=specification_set,\n                   version=self.api_version,\n                   class_prefix=self._class_prefix,\n                   product_accronym=self._product_accronym,\n                   override_content=override_content,\n                   superclass_name=superclass_name,\n                   constants=constants,\n                   header=self.header_content)\n\n        self.model_filenames[filename] = specification.entity_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites fetcher init file", "response": "def _write_init_fetchers(self, filenames):\n        \"\"\" Write fetcher init file\n\n            Args:\n                filenames (dict): dict of filename and classes\n\n        \"\"\"\n        destination = \"%s%s\" % (self.output_directory, self.fetchers_path)\n        self.write(destination=destination, filename=\"__init__.py\", template_name=\"__init_fetcher__.py.tpl\",\n                   filenames=self._prepare_filenames(filenames, suffix='Fetcher'),\n                   class_prefix=self._class_prefix,\n                   product_accronym=self._product_accronym,\n                   header=self.header_content)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite fetcher. py file", "response": "def _write_fetcher(self, specification, specification_set):\n        \"\"\" Write fetcher\n\n        \"\"\"\n        destination = \"%s%s\" % (self.output_directory, self.fetchers_path)\n        base_name = \"%s_fetcher\" % specification.entity_name_plural.lower()\n        filename = \"%s%s.py\" % (self._class_prefix.lower(), base_name)\n        override_content = self._extract_override_content(base_name)\n\n        self.write(destination=destination, filename=filename, template_name=\"fetcher.py.tpl\",\n                   specification=specification,\n                   specification_set=specification_set,\n                   class_prefix=self._class_prefix,\n                   product_accronym=self._product_accronym,\n                   override_content=override_content,\n                   header=self.header_content)\n\n        self.fetcher_filenames[filename] = specification.entity_name_plural"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_constants(self, specification):\n        constants = {}\n\n        for attribute in specification.attributes:\n\n            if attribute.allowed_choices and len(attribute.allowed_choices) > 0:\n\n                name = attribute.local_name.upper()\n\n                for choice in attribute.allowed_choices:\n                    constants[\"CONST_%s_%s\" % (name, choice.upper())] = choice\n\n        return constants", "response": "Extracts the constants from the attributes and computes constants"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns all tests in a list of CourgetteConfigurations.", "response": "def run(self, configurations):\n        \"\"\" Run all tests\n\n            Returns:\n                A dictionnary containing tests results.\n\n        \"\"\"\n        result = CourgetteResult()\n\n        for configuration in configurations:\n\n            runner = CourgetteTestsRunner(url=self.url,\n                                          username=self.username,\n                                          password=self.password,\n                                          enterprise=self.enterprise,\n                                          version=self.apiversion,\n                                          specification=configuration.specification,\n                                          sdk_identifier=self.sdk_identifier,\n                                          monolithe_config=self.monolithe_config,\n                                          parent_resource=configuration.parent_resource_name,\n                                          parent_id=configuration.parent_id,\n                                          default_values=configuration.default_values)\n\n            result.add_report(configuration.specification.rest_name + \".spec\", runner.run())\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_series(self):\n        data = self.get_data()\n        series_names = data[0][1:]\n        serieses = []\n        options = self.get_options()\n        if 'annotation' in options:\n            data = self.get_data()\n            annotation_list = options['annotation']\n            for i, name in enumerate(series_names):\n                new_data = []\n                if name in annotation_list:\n                    data_list = column(data, i + 1)[1:]\n                    for k in data_list:\n                        temp_data = {}\n                        for j in annotation_list[name]:\n                            if k == j['id']:\n                                temp_data['y'] = k\n                                temp_data['dataLabels'] = {'enabled': True, 'format': j['value']}\n                            else:\n                                temp_data['y'] = k\n                        new_data.append(temp_data)\n                    series = {\"name\": name, \"data\": new_data}\n                else:\n                    series = {\"name\": name, \"data\": column(data, i + 1)[1:]}\n                if 'colors' in options and len(options['colors']) > i:\n                    series['color'] = options['colors'][i]\n                serieses.append(series)\n        else:\n            for i, name in enumerate(series_names):\n                series = {\"name\": name, \"data\": column(data, i+1)[1:]}\n                # If colors was passed then add color for the serieses\n                if 'colors' in options and len(options['colors']) > i:\n                    series['color'] = options['colors'][i]\n                serieses.append(series)\n        serieses = self.add_series_options(serieses)\n        return serieses", "response": "Returns a list of series for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_db(db_name=None):\n    import pymongo\n    return pymongo.Connection(host=DB_HOST,\n                              port=DB_PORT)[db_name]", "response": "Get a connection from the connection pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_yaml(self):\n        '''\n        Load OpenAPI specification from yaml file. Path to file taking from command\n        `vst_openapi`.\n        :return:\n        '''\n        env = self.state.document.settings.env\n        relpath, abspath = env.relfn2path(directives.path(self.arguments[0]))\n\n        env.note_dependency(relpath)\n\n        encoding = self.options.get('encoding', env.config.source_encoding)\n        with io.open(abspath, 'rt', encoding=encoding) as stream:\n            spec = yaml.load(stream, _YamlOrderedLoader)\n        self.spec = spec\n        self.paths = spec[self.path_path]\n        self.definitions = spec[self.models_path]\n        self.openapi_version = spec.get('swagger', None) or spec['openapi']\n        self.options.setdefault('uri', 'file://%s' % abspath)", "response": "Load OpenAPI specification from yaml file. Path to file taking from command\n        vst_openapi."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(self, value, indent_depth=0):\n        '''\n        Add lines to ViewList, for further rendering.\n        :param value: --line that would be added to render list\n        :type value: str, unicode\n        :param indent_depth: --value that show indent from left border\n        :type indent_depth: integer\n        :return:\n        '''\n        indent_depth = indent_depth\n        self.__view_list.append(self.indent * indent_depth + value, '<openapi>')", "response": "Writes a line to the view list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_paths(self):\n        '''\n        Cycle for prepare information about paths\n        :return:\n        '''\n        for path_key, path_value in self.paths.items():\n            # Handler for request in path\n            self.current_path = path_key\n            for request_key, request_value in path_value.items():\n                if request_key == 'parameters':\n                    continue\n                self.get_main_title(path_key, request_key)\n                self.get_description(request_value)\n                self.get_status_code_and_schema_rst(request_value['responses'])\n                self.get_params(path_value['parameters'], 'param')\n                self.get_params(request_value['parameters'], 'query')", "response": "Print the paths and their associated information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_schemas(self):\n        '''\n        Print all schemas, one by one\n        :return:\n        '''\n        self.indent_depth += 1\n        for i in self.definitions:\n            def_name = i.split('/')[-1]\n            self.write('.. _{}:'.format(def_name))\n            self.write('')\n            self.write('{} Schema'.format(def_name))\n            self.write('{}'.format('`' * (len(def_name) + 7)))\n            self.write('')\n            self.write('.. code-block:: json', self.indent_depth)\n            self.indent_depth += 1\n            self.write('')\n            self.definition_rst(def_name)\n            self.indent_depth -= 1\n            self.write('')\n            self.write('')\n        self.indent_depth -= 1", "response": "Print all schemas one by one."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_main_title(self, path_name, request_name):\n        '''\n        Get title, from request type and path\n\n        :param path_name: --path for create title\n        :type path_name: str, unicode\n        :param request_name: --name of request\n        :type request_name: str, unicode\n        :return:\n        '''\n        main_title = '.. http:{}:: {}'.format(request_name, path_name)\n        self.write(main_title)\n        self.write('')", "response": "Get main title from request type and path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning for prepare information about responses with example prepare only responses with status code from 101 to 299", "response": "def get_status_code_and_schema_rst(self, responses):\n        '''\n        Function for prepare information about responses with example, prepare only\n        responses with status code from `101` to `299`\n        :param responses: -- dictionary that contains responses, with status code as key\n        :type responses: dict\n        :return:\n        '''\n        for status_code, response_schema in responses.items():\n            status_code = int(status_code)\n            schema = response_schema.get('schema', None)\n            status = HTTP_STATUS_CODES.get(status_code, None)\n            if status is None or not (100 < status_code < 300):\n                continue\n            self.write('**Example Response**', 1)\n            self.write('')\n            self.write('.. code-block:: http', 1)\n            self.write('')\n            self.write('HTTP/1.1 {} {}'.format(status_code, status), 2)\n            self.write('Vary: {}'.format(response_schema['description']), 2)\n            self.write('Content-Type: application/json', 2)\n            self.write('')\n\n            if schema:\n                self.schema_handler(schema)\n            else:\n                self.write('{}', self.indent_depth)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction prepare body of response with examples and create detailed information about response fields", "response": "def schema_handler(self, schema):\n        '''\n        Function prepare body of response with examples and create detailed information\n        about response fields\n\n        :param schema: --dictionary with information about answer\n        :type schema: dict\n        :return:\n        '''\n        dict_for_render = schema.get('properties', dict()).items()\n        if schema.get('$ref', None):\n            def_name = schema.get('$ref').split('/')[-1]\n            dict_for_render = self.definitions[def_name].get('properties', dict()).items()\n        elif schema.get('properties', None) is None:\n            return ''\n\n        answer_dict = dict()\n        json_dict = dict()\n        for opt_name, opt_value in dict_for_render:\n            var_type = opt_value.get('format', None) or opt_value.get('type', None) or 'object'\n            json_name = self.indent + ':jsonparameter {} {}:'.format(var_type, opt_name)\n            json_dict[json_name] = self.get_json_props_for_response(var_type, opt_value)\n\n            answer_dict[opt_name] = self.get_response_example(opt_name, var_type, opt_value)\n            if var_type == 'string':\n                answer_dict[opt_name] = answer_dict[opt_name].format(opt_name)\n\n        self.write('')\n        for line in json.dumps(answer_dict, indent=4).split('\\n'):\n            self.write(line, self.indent_depth)\n\n        self.write('')\n        for json_param_name, json_param_value in json_dict.items():\n            desc = '{}{}'.format(\n                json_param_value['title'], json_param_value['props_str']\n            ) or 'None'\n            self.write(json_param_name + ' ' + desc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_json_props_for_response(self, var_type, option_value):\n        '''\n        Prepare JSON section with detailed information about response\n\n        :param var_type: --contains variable type\n        :type var_type: , unicode\n        :param option_value: --dictionary that contains information about property\n        :type option_value: dict\n        :return: dictionary that contains, title and all properties of field\n        :rtype: dict\n        '''\n        props = list()\n        for name, value in option_value.items():\n            if var_type in ['dynamic', 'select2']:\n                break\n            elif name in ['format', 'title', 'type']:\n                continue\n            elif isinstance(value, dict) and value.get('$ref', None):\n                props.append(':ref:`{}`'.format(value['$ref'].split('/')[-1]))\n            elif '$ref' in name:\n                props.append(':ref:`{}`'.format(value.split('/')[-1]))\n            elif var_type == 'autocomplete':\n                props.append('Example values: ' + ', '.join(value))\n            else:\n                props.append('{}={}'.format(name, value))\n\n        if len(props):\n            props_str = '(' + ', '.join(props) + ')'\n        else:\n            props_str = ''\n        return dict(props_str=props_str, title=option_value.get('title', ''))", "response": "Prepare JSON section with detailed information about response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_response_example(self, opt_name, var_type, opt_values):\n        '''\n        Depends on type of variable, return string with example\n        :param opt_name: --option name\n        :type opt_name: str,unicode\n        :param var_type: --type of variable\n        :type var_type: str, unicode\n        :param opt_values: --dictionary with properties of this variable\n        :type opt_values: dict\n        :return: example for `var_type` variable\n        :rtype: str, unicode\n        '''\n        if opt_name == 'previous' and var_type == 'uri':\n            result = None\n        elif var_type == 'uri':\n            params = {i.group(0): 1 for i in self.find_param.finditer(self.current_path)}\n            result = self.type_dict[var_type].format(self.current_path.format(**params))\n            if opt_name == 'next':\n                result += '?limit=1&offset=1'\n        elif opt_name == 'count' and var_type == 'integer':\n            result = 2\n        elif var_type == 'array':\n            items = opt_values.get('items', dict()).get('$ref', None)\n            item = 'array_example'\n            if items:\n                item = self.get_object_example(items.split('/')[-1])\n            result = [item]\n        elif var_type == 'autocomplete':\n            result = opt_values.get('enum', list())[0]\n        elif var_type in [None, 'object']:\n            def_name = opt_values.get('$ref').split('/')[-1]\n            result = self.get_object_example(def_name)\n        elif var_type =='select2':\n            def_name = opt_values['additionalProperties']['model']['$ref'].split('/')[-1]\n            value_field_name = opt_values['additionalProperties']['value_field']\n            def_model = self.definitions[def_name].get('properties')\n            value_field = def_model.get(value_field_name, None)\n            var_type = value_field.get('format', None) or value_field.get('type', None)\n            result = self.get_response_example(opt_name, var_type, def_model)\n        else:\n            var_type = var_type.replace('-', '_')\n            result = opt_values.get('default', None) or self.type_dict[var_type]\n        return result", "response": "Returns the response example for the variable type"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates example for response from object structure", "response": "def get_object_example(self, def_name):\n        '''\n        Create example for response, from object structure\n\n        :param def_name: --deffinition name of structure\n        :type def_name: str, unicode\n        :return: example of object\n        :rtype: dict\n        '''\n        def_model = self.definitions[def_name]\n        example = dict()\n        for opt_name, opt_value in def_model.get('properties', dict()).items():\n            var_type = opt_value.get('format', None) or opt_value.get('type', None)\n            example[opt_name] = self.get_response_example(opt_name, var_type, opt_value)\n            if var_type == 'string':\n                example[opt_name] = example[opt_name].format(opt_name)\n        return example"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef definition_rst(self, definition, spec_path=None):\n        '''\n        Prepare and write information about definition\n        :param definition: --name of definition that would be prepared for render\n        :type definition: str, unicode\n        :param spec_path: --path to definitions\n        :type spec_path: str, unicode\n        :return:\n        '''\n        spec_path = spec_path or self.models_path\n        definitions = self.spec[spec_path]\n        definition_property = definitions[definition]['properties'].copy()\n        if not definition_property:\n            self.write('{}', self.indent_depth)\n            return\n        self.indent_depth += 1\n        definition_property = self.find_nested_models(definition_property, definitions)\n        json_str = json.dumps(definition_property, indent=4)\n        for line in json_str.split('\\n'):\n            self.write(line, self.indent_depth)\n        self.indent_depth -= 1", "response": "Prepare and write information about definition"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding all nested models in a dictionary with all nested reference related to another model", "response": "def find_nested_models(self, model, definitions):\n        '''\n        Prepare dictionary with reference to another definitions, create one dictionary\n        that contains full information about model, with all nested reference\n        :param model: --dictionary that contains information about model\n        :type model: dict\n        :param definitions: --dictionary that contains copy of all definitions\n        :type definitions: dict\n        :return: dictionary with all nested reference\n        :rtype: dict\n        '''\n        for key, value in model.items():\n            if isinstance(value, dict):\n                model[key] = self.find_nested_models(value, definitions)\n            elif key == '$ref':\n                def_name = value.split('/')[-1]\n                def_property = definitions[def_name]['properties']\n                return self.find_nested_models(def_property, definitions)\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the parameters from the dictionary with parameters.", "response": "def get_params(self, params, name_request):\n        '''\n        Prepare and add for further render parameters.\n        :param params: --dictionary with parameters\n        :type params: dict\n        :param name_request: --type of the parameters\n        :type name_request: str, unicode\n        :return:\n        '''\n        self.write('')\n        for elem in params:\n            request_type = elem['type'] if elem.get('type', None) else 'schema'\n            name = elem['name']\n            if elem.get('required', None):\n                name += '(required)'\n            schema = elem.get('schema', None)\n            name = ':{} {} {}:'.format(name_request, request_type, name)\n            if schema:\n                definition = schema['$ref'].split('/')[-1]\n                self.write(name + ' :ref:`{}`'.format(definition), 1)\n                self.write('')\n            else:\n                desc = elem.get('description', '')\n                self.write(name)\n                self.write('{}'.format(desc), self.indent_depth + 1)\n        self.write('')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering a template and return the rendered string", "response": "def get_render(name, data, trans='en'):\n    \"\"\"\n    Render string based on template\n\n    :param name: -- full template name\n    :type name: str,unicode\n    :param data: -- dict of rendered vars\n    :type data: dict\n    :param trans: -- translation for render. Default 'en'.\n    :type trans: str,unicode\n    :return: -- rendered string\n    :rtype: str,unicode\n    \"\"\"\n    translation.activate(trans)\n    config = loader.get_template(name)\n    result = config.render(data).replace('\\r', '')\n    translation.deactivate()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites to file and flushes the cache file", "response": "def write(self, wr_string):\n        \"\"\"\n        Write to file and flush\n\n        :param wr_string: -- writable string\n        :type wr_string: str\n        :return: None\n        :rtype: None\n        \"\"\"\n        result = self.fd.write(wr_string)\n        self.fd.flush()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_django_settings(cls, name, default=None):\n        # pylint: disable=access-member-before-definition\n        \"\"\"\n        Get params from Django settings.\n\n        :param name: name of param\n        :type name: str,unicode\n        :param default: default value of param\n        :type default: object\n        :return: Param from Django settings or default.\n        \"\"\"\n        if hasattr(cls, '__django_settings__'):\n            return getattr(cls.__django_settings__, name, default)\n        from django.conf import settings\n        cls.__django_settings__ = settings\n        return cls.get_django_settings(name)", "response": "Get params from Django settings."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _unbuffered(self, proc, stream='stdout'):\n        if self.working_handler is not None:\n            t = Thread(target=self._handle_process, args=(proc, stream))\n            t.start()\n        out = getattr(proc, stream)\n        try:\n            for line in iter(out.readline, \"\"):\n                yield line.rstrip()\n        finally:\n            out.close()", "response": "Unbuffered output handler.\n\n        :type proc: subprocess.Popen\n        :type stream: six.text_types\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, cmd, cwd):\n        self.output = \"\"\n        env = os.environ.copy()\n        env.update(self.env)\n        if six.PY2:  # nocv\n            # Ugly hack because python 2.7.\n            if self._stdout == self.DEVNULL:\n                self._stdout = open(os.devnull, 'w+b')\n            if self._stderr == self.DEVNULL:\n                self._stderr = open(os.devnull, 'w+b')\n        proc = subprocess.Popen(\n            cmd, stdout=self._stdout, stderr=self._stderr,\n            bufsize=0, universal_newlines=True,\n            cwd=cwd, env=env,\n            close_fds=ON_POSIX\n        )\n        for line in self._unbuffered(proc):\n            self.line_handler(line)\n        return_code = proc.poll()\n        if return_code:\n            logger.error(self.output)\n            raise subprocess.CalledProcessError(\n                return_code, cmd, output=str(self.output)\n            )\n        return self.output", "response": "Execute commands and output this\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets backend class by name.", "response": "def backend(self, name):\n        \"\"\"\n        Get backend class\n\n        :param name: -- name of backend type\n        :type name: str\n        :return: class of backend\n        :rtype: class,module,object\n        \"\"\"\n        try:\n            backend = self.get_backend_handler_path(name)\n            if backend is None:\n                raise ex.VSTUtilsException(\"Backend is 'None'.\")  # pragma: no cover\n            return self._get_baskend(backend)\n        except KeyError or ImportError:\n            msg = \"{} ({})\".format(name, self.err_message) if self.err_message else name\n            raise ex.UnknownTypeException(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting object by name", "response": "def get_object(self, name, obj):\n        \"\"\"\n        :param name: -- string name of backend\n        :param name: str\n        :param obj: -- model object\n        :type obj: django.db.models.Model\n        :return: backend object\n        :rtype: object\n        \"\"\"\n        return self[name](obj, **self.opts(name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets url object tuple for url", "response": "def get_object(self, name, *argv, **kwargs):\n        \"\"\"\n        Get url object tuple for url\n\n        :param name: url regexp from\n        :type name: str\n        :param argv: overrided args\n        :param kwargs: overrided kwargs\n        :return: url object\n        :rtype: django.conf.urls.url\n        \"\"\"\n        regexp = name\n        options = self.opts(regexp)\n        options.update(kwargs)\n        args = options.pop('view_args', argv)\n        csrf_enable = self.get_backend_data(regexp).get('CSRF_ENABLE', True)\n        if regexp in self.settings_urls:\n            regexp = r'^{}'.format(self.get_django_settings(regexp)[1:])\n        view = self[name].as_view()\n        if not csrf_enable:\n            view = csrf_exempt(view)\n        return url(regexp, view, *args, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self, request, **kwargs):\n        # pylint: disable=unused-argument\n        '''\n        Copy instance with deps.\n        '''\n        instance = self.copy_instance(self.get_object())\n        serializer = self.get_serializer(instance, data=request.data, partial=True)\n        serializer.is_valid()\n        serializer.save()\n        return Response(serializer.data, status.HTTP_201_CREATED).resp", "response": "Copy instance with deps.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_queryset_methods(cls, queryset_class):\n        '''\n        Django overrloaded method for add cyfunction.\n        '''\n        def create_method(name, method):\n            def manager_method(self, *args, **kwargs):\n                return getattr(self.get_queryset(), name)(*args, **kwargs)\n\n            manager_method.__name__ = method.__name__\n            manager_method.__doc__ = method.__doc__\n            return manager_method\n\n        orig_method = models.Manager._get_queryset_methods\n        new_methods = orig_method(queryset_class)\n        inspect_func = inspect.isfunction\n        for name, method in inspect.getmembers(queryset_class, predicate=inspect_func):\n            # Only copy missing methods.\n            if hasattr(cls, name) or name in new_methods:\n                continue\n            queryset_only = getattr(method, 'queryset_only', None)\n            if queryset_only or (queryset_only is None and name.startswith('_')):\n                continue\n            # Copy the method onto the manager.\n            new_methods[name] = create_method(name, method)\n        return new_methods", "response": "Get the methods that are available on the queryset class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nauthenticate with the user with the given username and password", "response": "def __authenticate(self, ad, username, password):\n        '''\n        Active Directory auth function\n\n        :param ad: LDAP connection string ('ldap://server')\n        :param username: username with domain ('user@domain.name')\n        :param password: auth password\n        :return: ldap connection or None if error\n        '''\n        result = None\n        conn = ldap.initialize(ad)\n        conn.protocol_version = 3\n        conn.set_option(ldap.OPT_REFERRALS, 0)\n        user = self.__prepare_user_with_domain(username)\n        self.logger.debug(\"Trying to auth with user '{}' to {}\".format(user, ad))\n        try:\n            conn.simple_bind_s(user, password)\n            result = conn\n            self.username, self.password = username, password\n            self.logger.debug(\"Successfull login as {}\".format(username))\n        except ldap.INVALID_CREDENTIALS:\n            result = False\n            self.logger.debug(traceback.format_exc())\n            self.logger.debug(\"Invalid ldap-creds.\")\n        except Exception as ex:  # nocv\n            self.logger.debug(traceback.format_exc())\n            self.logger.debug(\"Unknown error: {}\".format(str(ex)))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nindicate that the object is authenticated", "response": "def isAuth(self):\n        '''\n        Indicates that object auth worked\n        :return: True or False\n        '''\n        if isinstance(self.__conn, ldap.ldapobject.LDAPObject) or self.__conn:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreparing the environment for the web - application .", "response": "def prepare_environment(default_settings=_default_settings, **kwargs):\n    # pylint: disable=unused-argument\n    '''\n    Prepare ENV for web-application\n    :param default_settings: minimal needed settings for run app\n    :type default_settings: dict\n    :param kwargs: other overrided settings\n    :rtype: None\n    '''\n    for key, value in default_settings.items():\n        os.environ.setdefault(key, value)\n    os.environ.update(kwargs)\n    if six.PY2:  # nocv\n        warnings.warn(\n            'Python 2.7 is deprecated and will dropped in 2.0, use Python >3.5',\n            DeprecationWarning\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to return celery - app. Works only if celery is installed.", "response": "def get_celery_app(name=None, **kwargs):  # nocv\n    # pylint: disable=import-error\n    '''\n    Function to return celery-app. Works only if celery installed.\n    :param name: Application name\n    :param kwargs: overrided env-settings\n    :return: Celery-app object\n    '''\n    from celery import Celery\n    prepare_environment(**kwargs)\n    name = name or os.getenv(\"VST_PROJECT\")\n    celery_app = Celery(name)\n    celery_app.config_from_object('django.conf:settings', namespace='CELERY')\n    celery_app.autodiscover_tasks()\n    return celery_app"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(model, autofixture, overwrite=False, fail_silently=False):\n    '''\n    Register a model with the registry.\n\n    Arguments:\n\n        *model* can be either a model class or a string that contains the model's\n        app label and class name seperated by a dot, e.g. ``\"app.ModelClass\"``.\n\n        *autofixture* is the :mod:`AutoFixture` subclass that shall be used to\n        generated instances of *model*.\n\n        By default :func:`register` will raise :exc:`ValueError` if the given\n        *model* is already registered. You can overwrite the registered *model* if\n        you pass ``True`` to the *overwrite* argument.\n\n        The :exc:`ValueError` that is usually raised if a model is already\n        registered can be suppressed by passing ``True`` to the *fail_silently*\n        argument.\n    '''\n    from .compat import get_model\n\n    if isinstance(model, string_types):\n        model = get_model(*model.split('.', 1))\n    if not overwrite and model in REGISTRY:\n        if fail_silently:\n            return\n        raise ValueError(\n            u'%s.%s is already registered. You can overwrite the registered '\n            u'autofixture by providing the `overwrite` argument.' % (\n                model._meta.app_label,\n                model._meta.object_name,\n            ))\n    REGISTRY[model] = autofixture", "response": "Register a model with the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unregister(model_or_iterable, fail_silently=False):\n    '''\n    Remove one or more models from the autofixture registry.\n    '''\n    from django.db import models\n    from .compat import get_model\n\n    if issubclass(model_or_iterable, models.Model):\n        model_or_iterable = [model_or_iterable]\n    for model in model_or_iterable:\n        if isinstance(model, string_types):\n            model = get_model(*model.split('.', 1))\n        try:\n            del REGISTRY[model]\n        except KeyError:\n            if fail_silently:\n                continue\n            raise ValueError(\n                u'The model %s.%s is not registered.' % (\n                    model._meta.app_label,\n                    model._meta.object_name,\n                ))", "response": "Remove one or more autofixture models from the autofixture registry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an autofixture instance for the passed in model.", "response": "def get(model, *args, **kwargs):\n    '''\n    Get an autofixture instance for the passed in *model* sing the either an\n    appropiate autofixture that was :ref:`registry <registry>` or fall back\n    to the default:class:`AutoFixture` class.  *model* can be a model class or\n    its string representation (e.g.  ``\"app.ModelClass\"``).\n\n    All positional and keyword arguments are passed to the autofixture\n    constructor.\n    '''\n    from .compat import get_model\n\n    if isinstance(model, string_types):\n        model = get_model(*model.split('.', 1))\n    if model in REGISTRY:\n        return REGISTRY[model](model, *args, **kwargs)\n    else:\n        return AutoFixture(model, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(model, count, *args, **kwargs):\n    '''\n    Create *count* instances of *model* using the either an appropiate\n    autofixture that was :ref:`registry <registry>` or fall back to the\n    default:class:`AutoFixture` class. *model* can be a model class or its\n    string representation (e.g. ``\"app.ModelClass\"``).\n\n    All positional and keyword arguments are passed to the autofixture\n    constructor. It is demonstrated in the example below which will create ten\n    superusers::\n\n        import autofixture\n        admins = autofixture.create('auth.User', 10, field_values={'is_superuser': True})\n\n    .. note:: See :ref:`AutoFixture` for more information.\n\n    :func:`create` will return a list of the created objects.\n    '''\n    from .compat import get_model\n\n    if isinstance(model, string_types):\n        model = get_model(*model.split('.', 1))\n    if model in REGISTRY:\n        autofixture_class = REGISTRY[model]\n    else:\n        autofixture_class = AutoFixture\n    # Get keyword arguments that the create_one method accepts and pass them\n    # into create_one instead of AutoFixture.__init__\n    argnames = set(getargnames(autofixture_class.create_one))\n    argnames -= set(['self'])\n    create_kwargs = {}\n    for argname in argnames:\n        if argname in kwargs:\n            create_kwargs[argname] = kwargs.pop(argname)\n    autofixture = autofixture_class(model, *args, **kwargs)\n    return autofixture.create(count, **create_kwargs)", "response": "Create a new set of count objects of model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef autodiscover():\n    '''\n    Auto-discover INSTALLED_APPS autofixtures.py and tests.py modules and fail\n    silently when not present. This forces an import on them to register any\n    autofixture bits they may want.\n    '''\n    from .compat import importlib\n\n    # Bail out if autodiscover didn't finish loading from a previous call so\n    # that we avoid running autodiscover again when the URLconf is loaded by\n    # the exception handler to resolve the handler500 view.  This prevents an\n    # autofixtures.py module with errors from re-registering models and raising a\n    # spurious AlreadyRegistered exception (see #8245).\n    global LOADING\n    if LOADING:\n        return\n    LOADING = True\n    app_paths = {}\n\n    # For each app, we need to look for an autofixture.py inside that app's\n    # package. We can't use os.path here -- recall that modules may be\n    # imported different ways (think zip files) -- so we need to get\n    # the app's __path__ and look for autofixture.py on that path.\n\n    # Step 1: find out the app's __path__ Import errors here will (and\n    # should) bubble up, but a missing __path__ (which is legal, but weird)\n    # fails silently -- apps that do weird things with __path__ might\n    # need to roll their own autofixture registration.\n\n    import imp\n    try:\n        from django.apps import apps\n\n        for app_config in apps.get_app_configs():\n            app_paths[app_config.name] = [app_config.path]\n\n    except ImportError:\n        # Django < 1.7\n        from django.conf import settings\n\n        for app in settings.INSTALLED_APPS:\n            mod = importlib.import_module(app)\n            try:\n                app_paths[app] = mod.__path__\n            except AttributeError:\n                continue\n\n    for app, app_path in app_paths.items():\n        # Step 2: use imp.find_module to find the app's autofixtures.py. For some\n        # reason imp.find_module raises ImportError if the app can't be found\n        # but doesn't actually try to import the module. So skip this app if\n        # its autofixtures.py doesn't exist\n        try:\n            file, _, _ = imp.find_module('autofixtures', app_path)\n        except ImportError:\n            continue\n        else:\n            if file:\n                file.close()\n\n        # Step 3: import the app's autofixtures file. If this has errors we want them\n        # to bubble up.\n        try:\n            importlib.import_module(\"%s.autofixtures\" % app)\n        except Exception as e:\n            warnings.warn(u'Error while importing %s.autofixtures: %r' %\n                (app, e))\n\n    for app, app_path in app_paths.items():\n        try:\n            file, _, _ = imp.find_module('tests', app_path)\n        except ImportError:\n            continue\n        else:\n            if file:\n                file.close()\n\n        try:\n            importlib.import_module(\"%s.tests\" % app)\n        except Exception as e:\n            warnings.warn(u'Error while importing %s.tests: %r' %\n                (app, e))\n\n    # autodiscover was successful, reset loading flag.\n    LOADING = False", "response": "Autodiscover INSTALLED_APPS autofixtures. py and tests. py modules and fail\n    silently when not present."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_inheritance_parent(self, field):\n        '''\n        Checks if the field is the automatically created OneToOneField used by\n        django mulit-table inheritance\n        '''\n        return (\n            isinstance(field, related.OneToOneField) and\n            field.primary_key and\n            issubclass(field.model, get_remote_field_to(field))\n        )", "response": "Checks if the field is the automatically created OneToOneField used by\n        django mulit - table inheritance\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a value generator based on the field instance that is passed to this method returns None if no matching generator was found.", "response": "def get_generator(self, field):\n        '''\n        Return a value generator based on the field instance that is passed to\n        this method. This function may return ``None`` which means that the\n        specified field will be ignored (e.g. if no matching generator was\n        found).\n        '''\n        if isinstance(field, fields.AutoField):\n            return None\n        if self.is_inheritance_parent(field):\n            return None\n        if (\n            field.default is not fields.NOT_PROVIDED and\n            not self.overwrite_defaults and\n            field.name not in self.field_values):\n                return None\n        kwargs = {}\n\n        if field.name in self.field_values:\n            value = self.field_values[field.name]\n            if isinstance(value, generators.Generator):\n                return value\n            elif isinstance(value, AutoFixture):\n                return generators.InstanceGenerator(autofixture=value)\n            elif callable(value):\n                return generators.CallableGenerator(value=value)\n            return generators.StaticGenerator(value=value)\n\n        if field.null:\n            kwargs['empty_p'] = self.none_p\n        if field.choices:\n            return generators.ChoicesGenerator(choices=field.choices, **kwargs)\n        if isinstance(field, related.ForeignKey):\n            # if generate_fk is set, follow_fk is ignored.\n            is_self_fk = (get_remote_field_to(field)().__class__ == self.model)\n            if field.name in self.generate_fk and not is_self_fk:\n                return generators.InstanceGenerator(\n                    autofixture.get(\n                        get_remote_field_to(field),\n                        follow_fk=self.follow_fk.get_deep_links(field.name),\n                        generate_fk=self.generate_fk.get_deep_links(field.name)),\n                    limit_choices_to=get_remote_field(field).limit_choices_to)\n            if field.name in self.follow_fk:\n                selected = generators.InstanceSelector(\n                    get_remote_field_to(field),\n                    limit_choices_to=get_remote_field(field).limit_choices_to)\n                if selected.get_value() is not None:\n                    return selected\n            if field.blank or field.null:\n                return generators.NoneGenerator()\n            if is_self_fk and not field.null:\n                raise CreateInstanceError(\n                    u'Cannot resolve self referencing field \"%s\" to \"%s\" without null=True' % (\n                        field.name,\n                        '%s.%s' % (\n                            get_remote_field_to(field)._meta.app_label,\n                            get_remote_field_to(field)._meta.object_name,\n                        )\n                ))\n            raise CreateInstanceError(\n                u'Cannot resolve ForeignKey \"%s\" to \"%s\". Provide either '\n                u'\"follow_fk\" or \"generate_fk\" parameters.' % (\n                    field.name,\n                    '%s.%s' % (\n                        get_remote_field_to(field)._meta.app_label,\n                        get_remote_field_to(field)._meta.object_name,\n                    )\n            ))\n        if isinstance(field, related.ManyToManyField):\n            if field.name in self.generate_m2m:\n                min_count, max_count = self.generate_m2m[field.name]\n                return generators.MultipleInstanceGenerator(\n                    autofixture.get(get_remote_field_to(field)),\n                    limit_choices_to=get_remote_field(field).limit_choices_to,\n                    min_count=min_count,\n                    max_count=max_count,\n                    **kwargs)\n            if field.name in self.follow_m2m:\n                min_count, max_count = self.follow_m2m[field.name]\n                return generators.InstanceSelector(\n                    get_remote_field_to(field),\n                    limit_choices_to=get_remote_field(field).limit_choices_to,\n                    min_count=min_count,\n                    max_count=max_count,\n                    **kwargs)\n            if field.blank or field.null:\n                return generators.StaticGenerator([])\n            raise CreateInstanceError(\n                u'Cannot assign instances of \"%s\" to ManyToManyField \"%s\". '\n                u'Provide either \"follow_m2m\" or \"generate_m2m\" argument.' % (\n                    '%s.%s' % (\n                        get_remote_field_to(field)._meta.app_label,\n                        get_remote_field_to(field)._meta.object_name,\n                    ),\n                    field.name,\n            ))\n        if isinstance(field, fields.FilePathField):\n            return generators.FilePathGenerator(\n                path=field.path, match=field.match, recursive=field.recursive,\n                max_length=field.max_length, **kwargs)\n        if isinstance(field, fields.CharField):\n            if isinstance(field, fields.SlugField):\n                generator = generators.SlugGenerator\n            elif isinstance(field, fields.EmailField):\n                return generators.EmailGenerator(\n                    max_length=min(field.max_length, 30))\n            elif isinstance(field, fields.URLField):\n                return generators.URLGenerator(\n                    max_length=min(field.max_length, 25))\n            elif field.max_length > 15:\n                return generators.LoremSentenceGenerator(\n                    common=False,\n                    max_length=field.max_length)\n            else:\n                generator = generators.StringGenerator\n            return generator(max_length=field.max_length)\n        if isinstance(field, fields.DecimalField):\n            return generators.DecimalGenerator(\n                decimal_places=field.decimal_places,\n                max_digits=field.max_digits)\n        if hasattr(fields, 'BigIntegerField'):\n            if isinstance(field, fields.BigIntegerField):\n                return generators.IntegerGenerator(\n                    min_value=-field.MAX_BIGINT - 1,\n                    max_value=field.MAX_BIGINT,\n                    **kwargs)\n        if isinstance(field, ImageField):\n            return generators.ImageGenerator(storage=field.storage, **kwargs)\n        for field_class, generator in self.field_to_generator.items():\n            if isinstance(field, field_class):\n                return generator(**kwargs)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_value(self, field):\n        '''\n        Return a random value that can be assigned to the passed *field*\n        instance.\n        '''\n        if field not in self._field_generators:\n            self._field_generators[field] = self.get_generator(field)\n        generator = self._field_generators[field]\n        if generator is None:\n            return self.IGNORE_FIELD\n        value = generator()\n        return value", "response": "Returns a random value that can be assigned to the passed field."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the instance has any constraints and return the fieldnames which need recalculation.", "response": "def check_constraints(self, instance):\n        '''\n        Return fieldnames which need recalculation.\n        '''\n        recalc_fields = []\n        for constraint in self.constraints:\n            try:\n                constraint(self.model, instance)\n            except constraints.InvalidConstraint as e:\n                recalc_fields.extend(e.fields)\n        return recalc_fields"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_one(self, commit=True):\n        '''\n        Create and return one model instance. If *commit* is ``False`` the\n        instance will not be saved and many to many relations will not be\n        processed.\n\n        Subclasses that override ``create_one`` can specify arbitrary keyword\n        arguments. They will be passed through by the\n        :meth:`autofixture.base.AutoFixture.create` method and the helper\n        functions :func:`autofixture.create` and\n        :func:`autofixture.create_one`.\n\n        May raise :exc:`CreateInstanceError` if constraints are not satisfied.\n        '''\n        tries = self.tries\n        instance = self.model()\n        process = instance._meta.fields\n        while process and tries > 0:\n            for field in process:\n                self.process_field(instance, field)\n            process = self.check_constraints(instance)\n            tries -= 1\n        if tries == 0:\n            raise CreateInstanceError(\n                u'Cannot solve constraints for \"%s\", tried %d times. '\n                u'Please check value generators or model constraints. '\n                u'At least the following fields are involved: %s' % (\n                    '%s.%s' % (\n                        self.model._meta.app_label,\n                        self.model._meta.object_name),\n                    self.tries,\n                    ', '.join([field.name for field in process]),\n            ))\n\n        instance = self.pre_process_instance(instance)\n\n        if commit:\n            instance.save()\n\n            #to handle particular case of GenericRelation\n            #in Django pre 1.6 it appears in .many_to_many\n            many_to_many = [f for f in instance._meta.many_to_many\n                            if not isinstance(f, get_GenericRelation())]\n            for field in many_to_many:\n                self.process_m2m(instance, field)\n        signals.instance_created.send(\n            sender=self,\n            model=self.model,\n            instance=instance,\n            committed=commit)\n\n        post_process_kwargs = {}\n        if 'commit' in getargnames(self.post_process_instance):\n            post_process_kwargs['commit'] = commit\n        else:\n            warnings.warn(\n                \"Subclasses of AutoFixture need to provide a `commit` \"\n                \"argument for post_process_instance methods\", DeprecationWarning)\n        return self.post_process_instance(instance, **post_process_kwargs)", "response": "Create and return one model instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, count=1, commit=True, **kwargs):\n        '''\n        Create and return ``count`` model instances. If *commit* is ``False``\n        the instances will not be saved and many to many relations will not be\n        processed.\n\n        May raise ``CreateInstanceError`` if constraints are not satisfied.\n\n        The method internally calls :meth:`create_one` to generate instances.\n        '''\n        object_list = []\n        for i in range(count):\n            instance = self.create_one(commit=commit, **kwargs)\n            object_list.append(instance)\n        return object_list", "response": "Create and return count model instances."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_release(package):\n    init_path = os.path.join(PROJECT_PATH, package, '__init__.py')\n    init_py = open(init_path).read()\n    return re.search(\"__version__ = ['\\\"]([^'\\\"]+)['\\\"]\", init_py).group(1)", "response": "Get package version as listed in __version__ in init. py."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrebuilding documentation and opens it in your browser.", "response": "def opendocs(where='index', how='default'):\n    '''\n    Rebuild documentation and opens it in your browser.\n\n    Use the first argument to specify how it should be opened:\n\n        `d` or `default`: Open in new tab or new window, using the default\n        method of your browser.\n\n        `t` or `tab`: Open documentation in new tab.\n\n        `n`, `w` or `window`: Open documentation in new window.\n    '''\n    import webbrowser\n    docs_dir = os.path.join(\n        os.path.dirname(os.path.abspath(__file__)),\n        'docs')\n    index = os.path.join(docs_dir, '_build/html/%s.html' % where)\n    builddocs('html')\n    url = 'file://%s' % os.path.abspath(index)\n    if how in ('d', 'default'):\n        webbrowser.open(url)\n    elif how in ('t', 'tab'):\n        webbrowser.open_new_tab(url)\n    elif how in ('n', 'w', 'window'):\n        webbrowser.open_new(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    items = [Item('Name1', 'Description1'),\n             Item('Name2', 'Description2'),\n             Item('Name3', 'Description3')]\n\n    table = ItemTable(items)\n\n    # or {{ table }} in jinja\n    print(table.__html__())\n\n    \"\"\"Outputs:\n\n    <table>\n      <thead>\n        <tr>\n          <th class=\"my-name-class\">Name</th>\n          <th class=\"my-description-class\"\n              data-something=\"my-data\"\n              data-something-else=\"my-description-th-class\">\n            Description\n          </th>\n        </tr>\n      </thead>\n      <tbody>\n        <tr>\n          <td class=\"my-name-class\">Name1</td>\n          <td class=\"my-description-class\"\n              data-something=\"my-td-only-data\">\n            Description1\n          </td>\n        </tr>\n        <tr>\n          <td class=\"my-name-class\">Name2</td>\n          <td class=\"my-description-class\"\n              data-something=\"my-td-only-data\">\n            Description2\n          </td>\n        </tr>\n        <tr>\n          <td class=\"my-name-class\">Name3</td>\n          <td class=\"my-description-class\"\n              data-something=\"my-td-only-data\">\n            Description3\n          </td>\n        </tr>\n      </tbody>\n    </table>\n\n    Except it doesn't bother to prettify the output.\n    \"\"\"", "response": "This function is used to generate the base for the\naurant. It is used to generate the base for the base base. It is used to generate the base for the base base."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates and returns a new table class.", "response": "def create_table(name=str('_Table'), base=Table, options=None):\n    \"\"\"Creates and returns a new table class. You can specify a name for\n    you class if you wish. You can also set the base class (or\n    classes) that should be used when creating the class.\n\n    \"\"\"\n    try:\n        base = tuple(base)\n    except TypeError:\n        # Then assume that what we have is a single class, so make it\n        # into a 1-tuple.\n        base = (base,)\n\n    return TableMeta(name, base, options or {})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef td_contents(self, item, attr_list):\n        return self.td_format(self.from_attr_list(item, attr_list))", "response": "Given an item and an attr list return the contents of the td."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open(filename, mode=\"rb\",\n         format=None, check=-1, preset=None, filters=None,\n         encoding=None, errors=None, newline=None):\n    \"\"\"Open an LZMA-compressed file in binary or text mode.\n\n    filename can be either an actual file name (given as a str or bytes object),\n    in which case the named file is opened, or it can be an existing file object\n    to read from or write to.\n\n    The mode argument can be \"r\", \"rb\" (default), \"w\", \"wb\", \"a\", or \"ab\" for\n    binary mode, or \"rt\", \"wt\" or \"at\" for text mode.\n\n    The format, check, preset and filters arguments specify the compression\n    settings, as for LZMACompressor, LZMADecompressor and LZMAFile.\n\n    For binary mode, this function is equivalent to the LZMAFile constructor:\n    LZMAFile(filename, mode, ...). In this case, the encoding, errors and\n    newline arguments must not be provided.\n\n    For text mode, a LZMAFile object is created, and wrapped in an\n    io.TextIOWrapper instance with the specified encoding, error handling\n    behavior, and line ending(s).\n\n    \"\"\"\n    if \"t\" in mode:\n        if \"b\" in mode:\n            raise ValueError(\"Invalid mode: %r\" % (mode,))\n    else:\n        if encoding is not None:\n            raise ValueError(\"Argument 'encoding' not supported in binary mode\")\n        if errors is not None:\n            raise ValueError(\"Argument 'errors' not supported in binary mode\")\n        if newline is not None:\n            raise ValueError(\"Argument 'newline' not supported in binary mode\")\n\n    lz_mode = mode.replace(\"t\", \"\")\n    binary_file = LZMAFile(filename, lz_mode, format=format, check=check,\n                           preset=preset, filters=filters)\n\n    if \"t\" in mode:\n        return io.TextIOWrapper(binary_file, encoding, errors, newline)\n    else:\n        return binary_file", "response": "Open an LZMA compressed file in binary or text mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompresses a block of data using LZMA", "response": "def compress(data, format=FORMAT_XZ, check=-1, preset=None, filters=None):\n    \"\"\"Compress a block of data.\n\n    Refer to LZMACompressor's docstring for a description of the\n    optional arguments *format*, *check*, *preset* and *filters*.\n\n    For incremental compression, use an LZMACompressor object instead.\n    \"\"\"\n    comp = LZMACompressor(format, check, preset, filters)\n    return comp.compress(data) + comp.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decompress(data, format=FORMAT_AUTO, memlimit=None, filters=None):\n    results = []\n    while True:\n        decomp = LZMADecompressor(format, memlimit, filters)\n        try:\n            res = decomp.decompress(data)\n        except LZMAError:\n            if results:\n                break  # Leftover data is not a valid LZMA/XZ stream; ignore it.\n            else:\n                raise  # Error on the first iteration; bail out.\n        results.append(res)\n        if not decomp.eof:\n            raise LZMAError(\"Compressed data ended before the \"\n                            \"end-of-stream marker was reached\")\n        data = decomp.unused_data\n        if not data:\n            break\n    return b\"\".join(results)", "response": "Decompress a block of data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self):\n        if self._mode == _MODE_CLOSED:\n            return\n        try:\n            if self._mode in (_MODE_READ, _MODE_READ_EOF):\n                self._decompressor = None\n                self._buffer = None\n            elif self._mode == _MODE_WRITE:\n                self._fp.write(self._compressor.flush())\n                self._compressor = None\n        finally:\n            try:\n                if self._closefp:\n                    self._fp.close()\n            finally:\n                self._fp = None\n                self._closefp = False\n                self._mode = _MODE_CLOSED", "response": "Flush and close the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef peek(self, size=-1):\n        self._check_can_read()\n        if self._mode == _MODE_READ_EOF or not self._fill_buffer():\n            return b\"\"\n        return self._buffer", "response": "Return buffered data without advancing the file position."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, size=-1):\n        self._check_can_read()\n        if size is None:\n            #This is not needed on Python 3 where the comparison to zeo\n            #will fail with a TypeError.\n            raise TypeError(\"Read size should be an integer, not None\")\n        if self._mode == _MODE_READ_EOF or size == 0:\n            return b\"\"\n        elif size < 0:\n            return self._read_all()\n        else:\n            return self._read_block(size)", "response": "Reads up to size uncompressed bytes from the file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread up to size uncompressed bytes from the underlying stream.", "response": "def read1(self, size=-1):\n        \"\"\"Read up to size uncompressed bytes, while trying to avoid\n        making multiple reads from the underlying stream.\n\n        Returns b\"\" if the file is at EOF.\n        \"\"\"\n        # Usually, read1() calls _fp.read() at most once. However, sometimes\n        # this does not give enough data for the decompressor to make progress.\n        # In this case we make multiple reads, to avoid returning b\"\".\n        self._check_can_read()\n        if size is None:\n            #This is not needed on Python 3 where the comparison to zero\n            #will fail with a TypeError. \n            raise TypeError(\"Read size should be an integer, not None\")\n        if (size == 0 or self._mode == _MODE_READ_EOF or\n            not self._fill_buffer()):\n            return b\"\"\n        if 0 < size < len(self._buffer):\n            data = self._buffer[:size]\n            self._buffer = self._buffer[size:]\n        else:\n            data = self._buffer\n            self._buffer = None\n        self._pos += len(data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a bytes object to the file.", "response": "def write(self, data):\n        \"\"\"Write a bytes object to the file.\n\n        Returns the number of uncompressed bytes written, which is\n        always len(data). Note that due to buffering, the file on disk\n        may not reflect the data written until close() is called.\n        \"\"\"\n        self._check_can_write()\n        compressed = self._compressor.compress(data)\n        self._fp.write(compressed)\n        self._pos += len(data)\n        return len(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange the file position.", "response": "def seek(self, offset, whence=0):\n        \"\"\"Change the file position.\n\n        The new position is specified by offset, relative to the\n        position indicated by whence. Possible values for whence are:\n\n            0: start of stream (default): offset must not be negative\n            1: current stream position\n            2: end of stream; offset must not be positive\n\n        Returns the new file position.\n\n        Note that seeking is emulated, sp depending on the parameters,\n        this operation may be extremely slow.\n        \"\"\"\n        self._check_can_seek()\n\n        # Recalculate offset as an absolute file position.\n        if whence == 0:\n            pass\n        elif whence == 1:\n            offset = self._pos + offset\n        elif whence == 2:\n            # Seeking relative to EOF - we need to know the file's size.\n            if self._size < 0:\n                self._read_all(return_data=False)\n            offset = self._size + offset\n        else:\n            raise ValueError(\"Invalid value for whence: {}\".format(whence))\n\n        # Make it so that offset is the number of bytes to skip forward.\n        if offset is None:\n            #This is not needed on Python 3 where the comparison to self._pos\n            #will fail with a TypeError.\n            raise TypeError(\"Seek offset should be an integer, not None\")\n        if offset < self._pos:\n            self._rewind()\n        else:\n            offset -= self._pos\n\n        # Read and discard data until we reach the desired position.\n        if self._mode != _MODE_READ_EOF:\n            self._read_block(offset, return_data=False)\n\n        return self._pos"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(cls, user_id, github_id=None, name=None, check_owner=True):\n        repo = cls.query.filter((Repository.github_id == github_id) |\n                                (Repository.name == name)).one()\n        if (check_owner and repo and repo.user_id and\n                repo.user_id != int(user_id)):\n            raise RepositoryAccessError(\n                u'User {user} cannot access repository {repo}({repo_id}).'\n                .format(user=user_id, repo=name, repo_id=github_id)\n            )\n        return repo", "response": "Get a repository object by user identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable(cls, user_id, github_id, name, hook):\n        try:\n            repo = cls.get(user_id, github_id=github_id, name=name)\n        except NoResultFound:\n            repo = cls.create(user_id=user_id, github_id=github_id, name=name)\n        repo.hook = hook\n        repo.user_id = user_id\n        return repo", "response": "Enable webhooks for a repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisables webhooks for a repository.", "response": "def disable(cls, user_id, github_id, name):\n        \"\"\"Disable webhooks for a repository.\n\n        Disables the webhook from a repository if it exists in the DB.\n\n        :param user_id: User identifier.\n        :param repo_id: GitHub id of the repository.\n        :param name: Fully qualified name of the repository.\n        \"\"\"\n        repo = cls.get(user_id, github_id=github_id, name=name)\n        repo.hook = None\n        repo.user_id = None\n        return repo"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new Release model.", "response": "def create(cls, event):\n        \"\"\"Create a new Release model.\"\"\"\n        # Check if the release has already been received\n        release_id = event.payload['release']['id']\n        existing_release = Release.query.filter_by(\n            release_id=release_id,\n        ).first()\n        if existing_release:\n            raise ReleaseAlreadyReceivedError(\n                u'{release} has already been received.'\n                .format(release=existing_release)\n            )\n\n        # Create the Release\n        repo_id = event.payload['repository']['id']\n        repo = Repository.get(user_id=event.user_id, github_id=repo_id)\n        if repo.enabled:\n            with db.session.begin_nested():\n                release = cls(\n                    release_id=release_id,\n                    tag=event.payload['release']['tag_name'],\n                    repository=repo,\n                    event=event,\n                    status=ReleaseStatus.RECEIVED,\n                )\n                db.session.add(release)\n            return release\n        else:\n            current_app.logger.warning(\n                u'Release creation attempt on disabled {repo}.'\n                .format(repo=repo)\n            )\n            raise RepositoryDisabledError(\n                u'{repo} is not enabled for webhooks.'.format(repo=repo)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the badge image url for a DOI.", "response": "def get_badge_image_url(pid, ext='svg'):\n    \"\"\"Return the badge for a DOI.\"\"\"\n    return url_for('invenio_formatter_badges.badge',\n                   title=pid.pid_type, value=pid.pid_value, ext=ext)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a badge for a specific GitHub repository.", "response": "def index_old(user_id, repo_name):\n    \"\"\"Generate a badge for a specific GitHub repository.\"\"\"\n    pid = get_pid_of_latest_release_or_404(name=repo_name)\n    return redirect(get_badge_image_url(pid))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisconnect webhooks from GitHub.", "response": "def disconnect_github(access_token, repo_hooks):\n    \"\"\"Uninstall webhooks.\"\"\"\n    # Note at this point the remote account and all associated data have\n    # already been deleted. The celery task is passed the access_token to make\n    # some last cleanup and afterwards delete itself remotely.\n    import github3\n    from .api import GitHubAPI\n\n    try:\n        gh = github3.login(token=access_token)\n        for repo_id, repo_hook in repo_hooks:\n            ghrepo = gh.repository_with_id(repo_id)\n            if ghrepo:\n                hook = ghrepo.hook(repo_hook)\n                if hook and hook.delete():\n                    info_msg = u'Deleted hook {hook} from {repo}'.format(\n                        hook=hook.id, repo=ghrepo.full_name)\n                    current_app.logger.info(info_msg)\n        # If we finished our clean-up successfully, we can revoke the token\n        GitHubAPI.revoke_token(access_token)\n    except Exception as exc:\n        # Retry in case GitHub may be down...\n        disconnect_github.retry(exc=exc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sync_hooks(user_id, repositories):\n    from .api import GitHubAPI\n\n    try:\n        # Sync hooks\n        gh = GitHubAPI(user_id=user_id)\n        for repo_id in repositories:\n            try:\n                with db.session.begin_nested():\n                    gh.sync_repo_hook(repo_id)\n                # We commit per repository, because while the task is running\n                # the user might enable/disable a hook.\n                db.session.commit()\n            except RepositoryAccessError as e:\n                current_app.logger.warning(e.message, exc_info=True)\n            except NoResultFound:\n                pass  # Repository not in DB yet\n    except Exception as exc:\n        sync_hooks.retry(exc=exc)", "response": "Sync repository hooks for a user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess a received Release.", "response": "def process_release(release_id, verify_sender=False):\n    \"\"\"Process a received Release.\"\"\"\n    from invenio_db import db\n    from invenio_rest.errors import RESTException\n\n    from .errors import InvalidSenderError\n    from .models import Release, ReleaseStatus\n    from .proxies import current_github\n\n    release_model = Release.query.filter(\n        Release.release_id == release_id,\n        Release.status.in_([ReleaseStatus.RECEIVED, ReleaseStatus.FAILED]),\n    ).one()\n    release_model.status = ReleaseStatus.PROCESSING\n    db.session.commit()\n\n    release = current_github.release_api_class(release_model)\n    if verify_sender and not release.verify_sender():\n        raise InvalidSenderError(\n            u'Invalid sender for event {event} for user {user}'\n            .format(event=release.event.id, user=release.event.user_id)\n        )\n\n    def _get_err_obj(msg):\n        \"\"\"Generate the error entry with a Sentry ID.\"\"\"\n        err = {'errors': msg}\n        if hasattr(g, 'sentry_event_id'):\n            err['error_id'] = str(g.sentry_event_id)\n        return err\n\n    try:\n        release.publish()\n        release.model.status = ReleaseStatus.PUBLISHED\n    except RESTException as rest_ex:\n        release.model.errors = json.loads(rest_ex.get_body())\n        release.model.status = ReleaseStatus.FAILED\n        current_app.logger.exception(\n            u'Error while processing {release}'.format(release=release.model))\n    # TODO: We may want to handle GitHub errors differently in the future\n    # except GitHubError as github_ex:\n    #     release.model.errors = {'error': str(e)}\n    #     release.model.status = ReleaseStatus.FAILED\n    #     current_app.logger.exception(\n    #         'Error while processing {release}'\n    #         .format(release=release.model))\n    except CustomGitHubMetadataError as e:\n        release.model.errors = _get_err_obj(str(e))\n        release.model.status = ReleaseStatus.FAILED\n        current_app.logger.exception(\n            u'Error while processing {release}'.format(release=release.model))\n    except Exception:\n        release.model.errors = _get_err_obj('Unknown error occured.')\n        release.model.status = ReleaseStatus.FAILED\n        current_app.logger.exception(\n            u'Error while processing {release}'.format(release=release.model))\n    finally:\n        db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting humanized version of time.", "response": "def naturaltime(val):\n    \"\"\"Get humanized version of time.\"\"\"\n    val = val.replace(tzinfo=pytz.utc) \\\n        if isinstance(val, datetime) else parse(val)\n    now = datetime.utcnow().replace(tzinfo=pytz.utc)\n\n    return humanize.naturaltime(now - val)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef index():\n    github = GitHubAPI(user_id=current_user.id)\n    token = github.session_token\n    ctx = dict(connected=False)\n\n    if token:\n        # The user is authenticated and the token we have is still valid.\n        if github.account.extra_data.get('login') is None:\n            github.init_account()\n            db.session.commit()\n\n        # Sync if needed\n        if request.method == 'POST' or github.check_sync():\n            # When we're in an XHR request, we want to synchronously sync hooks\n            github.sync(async_hooks=(not request.is_xhr))\n            db.session.commit()\n\n        # Generate the repositories view object\n        extra_data = github.account.extra_data\n        repos = extra_data['repos']\n        if repos:\n            # 'Enhance' our repos dict, from our database model\n            db_repos = Repository.query.filter(\n                Repository.github_id.in_([int(k) for k in repos.keys()]),\n            ).all()\n            for repo in db_repos:\n                repos[str(repo.github_id)]['instance'] = repo\n                repos[str(repo.github_id)]['latest'] = GitHubRelease(\n                    repo.latest_release())\n\n        last_sync = humanize.naturaltime(\n            (utcnow() - parse_timestamp(extra_data['last_sync'])))\n\n        ctx.update({\n            'connected': True,\n            'repos': sorted(repos.items(), key=lambda x: x[1]['full_name']),\n            'last_sync': last_sync,\n        })\n\n    return render_template(current_app.config['GITHUB_TEMPLATE_INDEX'], **ctx)", "response": "Display list of the user s repositories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninstalling or remove GitHub webhook.", "response": "def hook():\n    \"\"\"Install or remove GitHub webhook.\"\"\"\n    repo_id = request.json['id']\n\n    github = GitHubAPI(user_id=current_user.id)\n    repos = github.account.extra_data['repos']\n\n    if repo_id not in repos:\n        abort(404)\n\n    if request.method == 'DELETE':\n        try:\n            if github.remove_hook(repo_id, repos[repo_id]['full_name']):\n                db.session.commit()\n                return '', 204\n            else:\n                abort(400)\n        except Exception:\n            abort(403)\n    elif request.method == 'POST':\n        try:\n            if github.create_hook(repo_id, repos[repo_id]['full_name']):\n                db.session.commit()\n                return '', 201\n            else:\n                abort(400)\n        except Exception:\n            abort(403)\n    else:\n        abort(400)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the class that should be used to instantiate the GitHub Release API.", "response": "def release_api_class(self):\n        \"\"\"Github Release API class.\"\"\"\n        cls = current_app.config['GITHUB_RELEASE_CLASS']\n        if isinstance(cls, string_types):\n            cls = import_string(cls)\n        assert issubclass(cls, GitHubRelease)\n        return cls"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the record serializer class.", "response": "def record_serializer(self):\n        \"\"\"Github Release API class.\"\"\"\n        imp = current_app.config['GITHUB_RECORD_SERIALIZER']\n        if isinstance(imp, string_types):\n            return import_string(imp)\n        return imp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the Flask application.", "response": "def init_app(self, app):\n        \"\"\"Flask application initialization.\"\"\"\n        self.init_config(app)\n        app.extensions['invenio-github'] = self\n\n        @app.before_first_request\n        def connect_signals():\n            \"\"\"Connect OAuthClient signals.\"\"\"\n            from invenio_oauthclient.models import RemoteAccount\n            from invenio_oauthclient.signals import account_setup_committed\n\n            from .api import GitHubAPI\n            from .handlers import account_post_init\n\n            account_setup_committed.connect(\n                account_post_init,\n                sender=GitHubAPI.remote._get_current_object()\n            )\n\n            @event.listens_for(RemoteAccount, 'before_delete')\n            def receive_before_delete(mapper, connection, target):\n                \"\"\"Listen for the 'before_delete' event.\"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef access_token(self):\n        if self.user_id:\n            return RemoteToken.get(\n                self.user_id, self.remote.consumer_key\n            ).access_token\n        return self.remote.get_request_token()[0]", "response": "Return OAuth access token."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef session_token(self):\n        session_token = None\n        if self.user_id is not None:\n            session_token = token_getter(self.remote)\n        if session_token:\n            token = RemoteToken.get(\n                self.user_id, self.remote.consumer_key,\n                access_token=session_token[0]\n            )\n            return token\n        return None", "response": "Return OAuth session token."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef webhook_url(self):\n        webhook_token = ProviderToken.query.filter_by(\n            id=self.account.extra_data['tokens']['webhook']\n        ).first()\n        if webhook_token:\n            wh_url = current_app.config.get('GITHUB_WEBHOOK_RECEIVER_URL')\n            if wh_url:\n                return wh_url.format(token=webhook_token.access_token)\n            else:\n                raise RuntimeError('You must set GITHUB_WEBHOOK_RECEIVER_URL.')", "response": "Return the url to be used by a GitHub webhook."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_account(self):\n        ghuser = self.api.me()\n        # Setup local access tokens to be used by the webhooks\n        hook_token = ProviderToken.create_personal(\n            'github-webhook',\n            self.user_id,\n            scopes=['webhooks:event'],\n            is_internal=True,\n        )\n        # Initial structure of extra data\n        self.account.extra_data = dict(\n            id=ghuser.id,\n            login=ghuser.login,\n            name=ghuser.name,\n            tokens=dict(\n                webhook=hook_token.id,\n            ),\n            repos=dict(),\n            last_sync=iso_utcnow(),\n        )\n        db.session.add(self.account)\n\n        # Sync data from GitHub, but don't check repository hooks yet.\n        self.sync(hooks=False)", "response": "Setup a new GitHub account."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sync(self, hooks=True, async_hooks=True):\n        active_repos = {}\n        github_repos = {repo.id: repo for repo in self.api.repositories()\n                        if repo.permissions['admin']}\n        for gh_repo_id, gh_repo in github_repos.items():\n            active_repos[gh_repo_id] = {\n                'id': gh_repo_id,\n                'full_name': gh_repo.full_name,\n                'description': gh_repo.description,\n            }\n\n        if hooks:\n            self._sync_hooks(list(active_repos.keys()),\n                             asynchronous=async_hooks)\n\n        # Update changed names for repositories stored in DB\n        db_repos = Repository.query.filter(\n            Repository.user_id == self.user_id,\n            Repository.github_id.in_(github_repos.keys())\n        )\n\n        for repo in db_repos:\n            gh_repo = github_repos.get(repo.github_id)\n            if gh_repo and repo.name != gh_repo.full_name:\n                repo.name = gh_repo.full_name\n                db.session.add(repo)\n\n        # Remove ownership from repositories that the user has no longer\n        # 'admin' permissions, or have been deleted.\n        Repository.query.filter(\n            Repository.user_id == self.user_id,\n            ~Repository.github_id.in_(github_repos.keys())\n        ).update(dict(user_id=None, hook=None), synchronize_session=False)\n\n        # Update repos and last sync\n        self.account.extra_data.update(dict(\n            repos=active_repos,\n            last_sync=iso_utcnow(),\n        ))\n        self.account.extra_data.changed()\n        db.session.add(self.account)", "response": "Synchronize user repositories and update user s extra data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sync_hooks(self, repos, asynchronous=True):\n        if not asynchronous:\n            for repo_id in repos:\n                try:\n                    with db.session.begin_nested():\n                        self.sync_repo_hook(repo_id)\n                    db.session.commit()\n                except RepositoryAccessError as e:\n                    current_app.logger.warning(e.message, exc_info=True)\n                except NoResultFound:\n                    pass  # Repository not in DB yet\n        else:\n            # FIXME: We have to commit, in order to have all necessary data?\n            db.session.commit()\n            sync_hooks.delay(self.user_id, repos)", "response": "Check if a hooks sync task needs to be started."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sync_repo_hook(self, repo_id):\n        # Get the hook that we may have set in the past\n        gh_repo = self.api.repository_with_id(repo_id)\n        hooks = (hook.id for hook in gh_repo.hooks()\n                 if hook.config.get('url', '') == self.webhook_url)\n        hook_id = next(hooks, None)\n\n        # If hook on GitHub exists, get or create corresponding db object and\n        # enable the hook. Otherwise remove the old hook information.\n        if hook_id:\n            Repository.enable(user_id=self.user_id,\n                              github_id=gh_repo.id,\n                              name=gh_repo.full_name,\n                              hook=hook_id)\n        else:\n            Repository.disable(user_id=self.user_id,\n                               github_id=gh_repo.id,\n                               name=gh_repo.full_name)", "response": "Sync a GitHub repo s hook with the locally stored repo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_sync(self):\n        # If refresh interval is not specified, we should refresh every time.\n        expiration = utcnow()\n        refresh_td = current_app.config.get('GITHUB_REFRESH_TIMEDELTA')\n        if refresh_td:\n            expiration -= refresh_td\n        last_sync = parse_timestamp(self.account.extra_data['last_sync'])\n        return last_sync < expiration", "response": "Check if sync is required based on last sync date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _dev_api(cls):\n        gh = github3.GitHub()\n        gh.set_client_id(cls.remote.consumer_key, cls.remote.consumer_secret)\n        return gh", "response": "Get a developer instance for GitHub API access."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deposit_class(self):\n        cls = current_app.config['GITHUB_DEPOSIT_CLASS']\n        if isinstance(cls, string_types):\n            cls = import_string(cls)\n        assert isinstance(cls, type)\n        return cls", "response": "Return a class implementing publish method."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef repo_model(self):\n        return Repository.query.filter_by(\n            user_id=self.event.user_id,\n            github_id=self.repository['id'],\n        ).one()", "response": "Return repository model from database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef title(self):\n        if self.event:\n            if self.release['name']:\n                return u'{0}: {1}'.format(\n                    self.repository['full_name'], self.release['name']\n                )\n        return u'{0} {1}'.format(self.repo_model.name, self.model.tag)", "response": "Extract title from a release."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef description(self):\n        if self.release.get('body'):\n            return markdown(self.release['body'])\n        elif self.repository.get('description'):\n            return self.repository['description']\n        return 'No description provided.'", "response": "Extract description from a release."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting extra metadata for file in repository.", "response": "def extra_metadata(self):\n        \"\"\"Get extra metadata for file in repository.\"\"\"\n        return get_extra_metadata(\n            self.gh.api,\n            self.repository['owner']['login'],\n            self.repository['name'],\n            self.release['tag_name'],\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting files to download from GitHub payload.", "response": "def files(self):\n        \"\"\"Extract files to download from GitHub payload.\"\"\"\n        tag_name = self.release['tag_name']\n        repo_name = self.repository['full_name']\n\n        zipball_url = self.release['zipball_url']\n        filename = u'{name}-{tag}.zip'.format(name=repo_name, tag=tag_name)\n\n        response = self.gh.api.session.head(zipball_url)\n        assert response.status_code == 302, \\\n            u'Could not retrieve archive from GitHub: {0}'.format(zipball_url)\n\n        yield filename, zipball_url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pid(self):\n        if self.model.status == ReleaseStatus.PUBLISHED and self.record:\n            fetcher = current_pidstore.fetchers[\n                current_app.config.get('GITHUB_PID_FETCHER')]\n            return fetcher(self.record.id, self.record)", "response": "Get the PID object for the Release record."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npublishing GitHub release as record.", "response": "def publish(self):\n        \"\"\"Publish GitHub release as record.\"\"\"\n        with db.session.begin_nested():\n            deposit = self.deposit_class.create(self.metadata)\n            deposit['_deposit']['created_by'] = self.event.user_id\n            deposit['_deposit']['owners'] = [self.event.user_id]\n\n            # Fetch the deposit files\n            for key, url in self.files:\n                deposit.files[key] = self.gh.api.session.get(\n                    url, stream=True).raw\n\n            deposit.publish()\n            recid, record = deposit.fetch_published()\n            self.model.recordmetadata = record.model"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, event):\n        repo_id = event.payload['repository']['id']\n\n        # Ping event - update the ping timestamp of the repository\n        if 'hook_id' in event.payload and 'zen' in event.payload:\n            repository = Repository.query.filter_by(\n                github_id=repo_id\n            ).one()\n            repository.ping = datetime.utcnow()\n            db.session.commit()\n            return\n\n        # Release event\n        if 'release' in event.payload and \\\n                event.payload.get('action') == 'published':\n            try:\n                release = Release.create(event)\n                db.session.commit()\n\n                # FIXME: If we want to skip the processing, we should do it\n                # here (eg. We're in the middle of a migration).\n                # if current_app.config['GITHUB_PROCESS_RELEASES']:\n                process_release.delay(\n                    release.release_id,\n                    verify_sender=self.verify_sender\n                )\n            except (ReleaseAlreadyReceivedError, RepositoryDisabledError) as e:\n                event.response_code = 409\n                event.response = dict(message=str(e), status=409)\n            except RepositoryAccessError as e:\n                event.response = 403\n                event.response = dict(message=str(e), status=403)", "response": "Process an event.\n\n        .. note::\n\n            We should only do basic server side operation here, since we send\n            the rest of the processing to a Celery task which will be mainly\n            accessing the GitHub API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_timestamp(x):\n    dt = dateutil.parser.parse(x)\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=pytz.utc)\n    return dt", "response": "Parse ISO8601 formatted timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_extra_metadata(gh, owner, repo_name, ref):\n    try:\n        content = gh.repository(owner, repo_name).file_contents(\n            path=current_app.config['GITHUB_METADATA_FILE'], ref=ref\n        )\n        if not content:\n            # File does not exists in the given ref\n            return {}\n        return json.loads(content.decoded.decode('utf-8'))\n    except ValueError:\n        raise CustomGitHubMetadataError(\n            u'Metadata file \"{file}\" is not valid JSON.'\n            .format(file=current_app.config['GITHUB_METADATA_FILE'])\n        )", "response": "Get the extra metadata file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_owner(gh, owner):\n    try:\n        u = gh.user(owner)\n        name = u.name or u.login\n        company = u.company or ''\n        return [dict(name=name, affiliation=company)]\n    except Exception:\n        return None", "response": "Get owner of repository as a creator."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets list of contributors to a repository.", "response": "def get_contributors(gh, repo_id):\n    \"\"\"Get list of contributors to a repository.\"\"\"\n    try:\n        # FIXME: Use `github3.Repository.contributors` to get this information\n        contrib_url = gh.repository_with_id(repo_id).contributors_url\n\n        r = requests.get(contrib_url)\n        if r.status_code == 200:\n            contributors = r.json()\n\n            def get_author(contributor):\n                r = requests.get(contributor['url'])\n                if r.status_code == 200:\n                    data = r.json()\n                    return dict(\n                        name=(data['name'] if 'name' in data and data['name']\n                              else data['login']),\n                        affiliation=data.get('company') or '',\n                    )\n\n            # Sort according to number of contributions\n            contributors.sort(key=itemgetter('contributions'))\n            contributors = [get_author(x) for x in reversed(contributors)\n                            if x['type'] == 'User']\n            contributors = filter(lambda x: x is not None, contributors)\n\n            return contributors\n    except Exception:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisconnect callback handler for GitHub.", "response": "def disconnect(remote):\n    \"\"\"Disconnect callback handler for GitHub.\"\"\"\n    # User must be authenticated\n    if not current_user.is_authenticated:\n        return current_app.login_manager.unauthorized()\n\n    external_method = 'github'\n    external_ids = [i.id for i in current_user.external_identifiers\n                    if i.method == external_method]\n    if external_ids:\n        oauth_unlink_external_id(dict(id=external_ids[0],\n                                      method=external_method))\n\n    user_id = int(current_user.get_id())\n    token = RemoteToken.get(user_id, remote.consumer_key)\n    if token:\n        extra_data = token.remote_account.extra_data\n\n        # Delete the token that we issued for GitHub to deliver webhooks\n        webhook_token_id = extra_data.get('tokens', {}).get('webhook')\n        ProviderToken.query.filter_by(id=webhook_token_id).delete()\n\n        # Disable GitHub webhooks from our side\n        db_repos = Repository.query.filter_by(user_id=user_id).all()\n        # Keep repositories with hooks to pass to the celery task later on\n        repos_with_hooks = [(r.github_id, r.hook) for r in db_repos if r.hook]\n        for repo in db_repos:\n            try:\n                Repository.disable(user_id=user_id,\n                                   github_id=repo.github_id,\n                                   name=repo.name)\n            except NoResultFound:\n                # If the repository doesn't exist, no action is necessary\n                pass\n        db.session.commit()\n\n        # Send Celery task for webhooks removal and token revocation\n        disconnect_github.delay(token.access_token, repos_with_hooks)\n        # Delete the RemoteAccount (along with the associated RemoteToken)\n        token.remote_account.delete()\n\n    return redirect(url_for('invenio_oauthclient_settings.index'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef moderate_model(ParentModel, publication_date_field=None, enable_comments_field=None):\n    attrs = {\n        'auto_close_field': publication_date_field,\n        'auto_moderate_field': publication_date_field,\n        'enable_field': enable_comments_field,\n    }\n    ModerationClass = type(ParentModel.__name__ + 'Moderator', (FluentCommentsModerator,), attrs)\n    moderator.register(ParentModel, ModerationClass)", "response": "Register a parent model that should receive comment moderation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn whether comments are still open for a given object.", "response": "def comments_are_open(content_object):\n    \"\"\"\n    Return whether comments are still open for a given target object.\n    \"\"\"\n    moderator = get_model_moderator(content_object.__class__)\n    if moderator is None:\n        return True\n\n    # Check the 'enable_field', 'auto_close_field' and 'close_after',\n    # by reusing the basic Django policies.\n    return CommentModerator.allow(moderator, None, content_object, None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef comments_are_moderated(content_object):\n    moderator = get_model_moderator(content_object.__class__)\n    if moderator is None:\n        return False\n\n    # Check the 'auto_moderate_field', 'moderate_after',\n    # by reusing the basic Django policies.\n    return CommentModerator.moderate(moderator, None, content_object, None)", "response": "Return whether comments are moderated for a given object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the comment should be posted on a given object False otherwise.", "response": "def allow(self, comment, content_object, request):\n        \"\"\"\n        Determine whether a given comment is allowed to be posted on a given object.\n\n        Returns ``True`` if the comment should be allowed, ``False`` otherwise.\n        \"\"\"\n        # Parent class check\n        if not super(FluentCommentsModerator, self).allow(comment, content_object, request):\n            return False\n\n        # Akismet check\n        if self.akismet_check:\n            akismet_result = akismet_check(comment, content_object, request)\n            if self.akismet_check_action == 'delete' and akismet_result in (SpamStatus.ProbableSpam, SpamStatus.DefiniteSpam):\n                return False  # Akismet marked the comment as spam.\n            elif self.akismet_check_action == 'auto' and akismet_result == SpamStatus.DefiniteSpam:\n                return False  # Clearly spam\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the comment should be moderated False otherwise.", "response": "def moderate(self, comment, content_object, request):\n        \"\"\"\n        Determine whether a given comment on a given object should be allowed to show up immediately,\n        or should be marked non-public and await approval.\n\n        Returns ``True`` if the comment should be moderated (marked non-public), ``False`` otherwise.\n        \"\"\"\n\n        # Soft delete checks are done first, so these comments are not mistakenly \"just moderated\"\n        # for expiring the `close_after` date, but correctly get marked as spam instead.\n        # This helps staff to quickly see which comments need real moderation.\n        if self.akismet_check:\n            akismet_result = akismet_check(comment, content_object, request)\n            if akismet_result:\n                # Typically action=delete never gets here, unless the service was having problems.\n                if akismet_result in (SpamStatus.ProbableSpam, SpamStatus.DefiniteSpam) and \\\n                       self.akismet_check_action in ('auto', 'soft_delete', 'delete'):\n                   comment.is_removed = True  # Set extra marker\n\n                # SpamStatus.Unknown or action=moderate will end up in the moderation queue\n                return True\n\n        # Parent class check\n        if super(FluentCommentsModerator, self).moderate(comment, content_object, request):\n            return True\n\n        # Bad words check\n        if self.moderate_bad_words:\n            input_words = split_words(comment.comment)\n            if self.moderate_bad_words.intersection(input_words):\n                return True\n\n        # Akismet check\n        if self.akismet_check and self.akismet_check_action not in ('soft_delete', 'delete'):\n            # Return True if akismet marks this comment as spam and we want to moderate it.\n            if akismet_check(comment, content_object, request):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef email(self, comment, content_object, request):\n        if not self.email_notification:\n            return\n\n        send_comment_posted(comment, request)", "response": "Send an email to the user who posted the comment."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends an email to staff that a comment was posted.", "response": "def send_comment_posted(comment, request):\n    \"\"\"\n    Send the email to staff that an comment was posted.\n\n    While the django_comments module has email support,\n    it doesn't pass the 'request' to the context.\n    This also changes the subject to show the page title.\n    \"\"\"\n    recipient_list = [manager_tuple[1] for manager_tuple in settings.MANAGERS]\n    site = get_current_site(request)\n    content_object = comment.content_object\n    content_title = force_text(content_object)\n\n    if comment.is_removed:\n        subject = u'[{0}] Spam comment on \"{1}\"'.format(site.name, content_title)\n    elif not comment.is_public:\n        subject = u'[{0}] Moderated comment on \"{1}\"'.format(site.name, content_title)\n    else:\n        subject = u'[{0}] New comment posted on \"{1}\"'.format(site.name, content_title)\n\n    context = {\n        'site': site,\n        'comment': comment,\n        'content_object': content_object\n    }\n\n    message = render_to_string(\"comments/comment_notification_email.txt\", context, request=request)\n    if appsettings.FLUENT_COMMENTS_MULTIPART_EMAILS:\n        html_message = render_to_string(\"comments/comment_notification_email.html\", context, request=request)\n    else:\n        html_message = None\n\n    send_mail(subject, message, settings.DEFAULT_FROM_EMAIL,\n              recipient_list, fail_silently=True, html_message=html_message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(cls, parser, token):\n        # Process the template line.\n        tag_name, args, kwargs = parse_token_kwargs(\n            parser, token,\n            allowed_kwargs=cls.allowed_kwargs,\n            compile_args=False,  # Only overrule here, keep at render() phase.\n            compile_kwargs=cls.compile_kwargs\n        )\n\n        # remove \"for\" keyword, so all other args can be resolved in render().\n        if args[0] == 'for':\n            args.pop(0)\n\n        # And apply the compilation afterwards\n        for i in range(len(args)):\n            args[i] = parser.compile_filter(args[i])\n\n        cls.validate_args(tag_name, *args, **kwargs)\n        return cls(tag_name, *args, **kwargs)", "response": "Custom parsing for the ajax comment tags for..."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of data for the inclusion node.", "response": "def get_context_data(self, parent_context, *tag_args, **tag_kwargs):\n        \"\"\"\n        The main logic for the inclusion node, analogous to ``@register.inclusion_node``.\n        \"\"\"\n        target_object = tag_args[0]  # moved one spot due to .pop(0)\n        new_context = {\n            'STATIC_URL': parent_context.get('STATIC_URL', None),\n            'USE_THREADEDCOMMENTS': appsettings.USE_THREADEDCOMMENTS,\n            'target_object': target_object,\n        }\n\n        # Be configuration independent:\n        if new_context['STATIC_URL'] is None:\n            try:\n                request = parent_context['request']\n            except KeyError:\n                new_context.update({'STATIC_URL': settings.STATIC_URL})\n            else:\n                new_context.update(context_processors.static(request))\n\n        return new_context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_comment_template_name(comment):\n    ctype = ContentType.objects.get_for_id(comment.content_type_id)\n    return [\n        \"comments/%s/%s/comment.html\" % (ctype.app_label, ctype.model),\n        \"comments/%s/comment.html\" % ctype.app_label,\n        \"comments/comment.html\"\n    ]", "response": "Internal function for rendering of comments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_layout(self, form, context, template_pack=TEMPLATE_PACK):\n        # Writing the label values into the field placeholders.\n        # This is done at rendering time, so the Form.__init__() could update any labels before.\n        # Django 1.11 no longer lets EmailInput or URLInput inherit from TextInput,\n        # so checking for `Input` instead while excluding `HiddenInput`.\n        for field in form.fields.values():\n            if field.label and \\\n                    isinstance(field.widget, (Input, forms.Textarea)) and \\\n                    not isinstance(field.widget, forms.HiddenInput):\n                field.widget.attrs['placeholder'] = u\"{0}:\".format(field.label)\n\n        return super(CompactLabelsCommentFormHelper, self).render_layout(form, context, template_pack=template_pack)", "response": "Copy any field label to the placeholder attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a QuerySet with all comments for a given object.", "response": "def get_comments_for_model(content_object, include_moderated=False):\n    \"\"\"\n    Return the QuerySet with all comments for a given model.\n    \"\"\"\n    qs = get_comments_model().objects.for_model(content_object)\n\n    if not include_moderated:\n        qs = qs.filter(is_public=True, is_removed=False)\n\n    return qs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _reorder_fields(self, ordering):\n        if 'captcha' not in ordering:\n            raise ImproperlyConfigured(\n                \"When using 'FLUENT_COMMENTS_FIELD_ORDER', \"\n                \"make sure the 'captcha' field included too to use '{}' form. \".format(\n                    self.__class__.__name__\n                )\n            )\n        super(CaptchaFormMixin, self)._reorder_fields(ordering)\n\n        # Avoid making captcha required for previews.\n        if self.is_preview:\n            self.fields.pop('captcha')", "response": "Reorder the fields of the current object according to the ordering."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npost a comment via an Ajax call.", "response": "def post_comment_ajax(request, using=None):\n    \"\"\"\n    Post a comment, via an Ajax call.\n    \"\"\"\n    if not request.is_ajax():\n        return HttpResponseBadRequest(\"Expecting Ajax call\")\n\n    # This is copied from django_comments.\n    # Basically that view does too much, and doesn't offer a hook to change the rendering.\n    # The request object is not passed to next_redirect for example.\n    #\n    # This is a separate view to integrate both features. Previously this used django-ajaxcomments\n    # which is unfortunately not thread-safe (it it changes the comment view per request).\n\n    # Fill out some initial data fields from an authenticated user, if present\n    data = request.POST.copy()\n    if request.user.is_authenticated:\n        if not data.get('name', ''):\n            data[\"name\"] = request.user.get_full_name() or request.user.username\n        if not data.get('email', ''):\n            data[\"email\"] = request.user.email\n\n    # Look up the object we're trying to comment about\n    ctype = data.get(\"content_type\")\n    object_pk = data.get(\"object_pk\")\n    if ctype is None or object_pk is None:\n        return CommentPostBadRequest(\"Missing content_type or object_pk field.\")\n    try:\n        model = apps.get_model(*ctype.split(\".\", 1))\n        target = model._default_manager.using(using).get(pk=object_pk)\n    except ValueError:\n        return CommentPostBadRequest(\"Invalid object_pk value: {0}\".format(escape(object_pk)))\n    except (TypeError, LookupError):\n        return CommentPostBadRequest(\"Invalid content_type value: {0}\".format(escape(ctype)))\n    except AttributeError:\n        return CommentPostBadRequest(\"The given content-type {0} does not resolve to a valid model.\".format(escape(ctype)))\n    except ObjectDoesNotExist:\n        return CommentPostBadRequest(\"No object matching content-type {0} and object PK {1} exists.\".format(escape(ctype), escape(object_pk)))\n    except (ValueError, ValidationError) as e:\n        return CommentPostBadRequest(\"Attempting go get content-type {0!r} and object PK {1!r} exists raised {2}\".format(escape(ctype), escape(object_pk), e.__class__.__name__))\n\n    # Do we want to preview the comment?\n    is_preview = \"preview\" in data\n\n    # Construct the comment form\n    form = django_comments.get_form()(target, data=data, is_preview=is_preview)\n\n    # Check security information\n    if form.security_errors():\n        return CommentPostBadRequest(\"The comment form failed security verification: {0}\".format(form.security_errors()))\n\n    # If there are errors or if we requested a preview show the comment\n    if is_preview:\n        comment = form.get_comment_object() if not form.errors else None\n        return _ajax_result(request, form, \"preview\", comment, object_id=object_pk)\n    if form.errors:\n        return _ajax_result(request, form, \"post\", object_id=object_pk)\n\n    # Otherwise create the comment\n    comment = form.get_comment_object()\n    comment.ip_address = request.META.get(\"REMOTE_ADDR\", None)\n    if request.user.is_authenticated:\n        comment.user = request.user\n\n    # Signal that the comment is about to be saved\n    responses = signals.comment_will_be_posted.send(\n        sender=comment.__class__,\n        comment=comment,\n        request=request\n    )\n\n    for (receiver, response) in responses:\n        if response is False:\n            return CommentPostBadRequest(\"comment_will_be_posted receiver {0} killed the comment\".format(receiver.__name__))\n\n    # Save the comment and signal that it was saved\n    comment.save()\n    signals.comment_was_posted.send(\n        sender  = comment.__class__,\n        comment = comment,\n        request = request\n    )\n\n    return _ajax_result(request, form, \"post\", comment, object_id=object_pk)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders form errors in crispy - forms style.", "response": "def _render_errors(field):\n    \"\"\"\n    Render form errors in crispy-forms style.\n    \"\"\"\n    template = '{0}/layout/field_errors.html'.format(appsettings.CRISPY_TEMPLATE_PACK)\n    return render_to_string(template, {\n        'field': field,\n        'form_show_errors': True,\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_form():\n    global form_class\n    from fluent_comments import appsettings\n    if form_class is None:\n        if appsettings.FLUENT_COMMENTS_FORM_CLASS:\n            from django.utils.module_loading import import_string\n            form_class = import_string(appsettings.FLUENT_COMMENTS_FORM_CLASS)\n        else:\n            from fluent_comments.forms import FluentCommentForm\n            form_class = FluentCommentForm\n\n    return form_class", "response": "Returns the form to use for commenting."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_default_moderator():\n    if appsettings.FLUENT_COMMENTS_DEFAULT_MODERATOR == 'default':\n        # Perform spam checks\n        return moderation.FluentCommentsModerator(None)\n    elif appsettings.FLUENT_COMMENTS_DEFAULT_MODERATOR == 'deny':\n        # Deny all comments not from known registered models.\n        return moderation.AlwaysDeny(None)\n    elif str(appsettings.FLUENT_COMMENTS_DEFAULT_MODERATOR).lower() == 'none':\n        # Disables default moderator\n        return moderation.NullModerator(None)\n    elif '.' in appsettings.FLUENT_COMMENTS_DEFAULT_MODERATOR:\n        return import_string(appsettings.FLUENT_COMMENTS_DEFAULT_MODERATOR)(None)\n    else:\n        raise ImproperlyConfigured(\n            \"Bad FLUENT_COMMENTS_DEFAULT_MODERATOR value. Provide default/deny/none or a dotted path\"\n        )", "response": "Load a moderator object from the default moderator settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling when a comment is posted.", "response": "def on_comment_will_be_posted(sender, comment, request, **kwargs):\n    \"\"\"\n    Make sure both the Ajax and regular comments are checked for moderation.\n    This signal is also used to link moderators to the comment posting.\n    \"\"\"\n    content_object = comment.content_object\n    moderator = moderation.get_model_moderator(content_object.__class__)\n    if moderator and comment.__class__ is not CommentModel:\n        # Help with some hard to diagnose problems. The default Django moderator connects\n        # to the configured comment model. When this model differs from the signal sender,\n        # the the form stores a different model then COMMENTS_APP provides.\n        moderator = None\n        logger.warning(\n            \"Comment of type '%s' was not moderated by '%s', \"\n            \"because the parent '%s' has a moderator installed for '%s' instead\",\n            comment.__class__.__name__, moderator.__class__.__name__,\n            content_object.__class__.__name__, CommentModel.__name__\n        )\n\n    if moderator is None:\n        logger.info(\n            \"Using default moderator for comment '%s' on parent '%s'\",\n            comment.__class__.__name__, content_object.__class__.__name__\n        )\n        _run_default_moderator(comment, content_object, request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run_default_moderator(comment, content_object, request):\n    # The default moderator will likely not check things like \"auto close\".\n    # It can still provide akismet and bad word checking.\n    if not default_moderator.allow(comment, content_object, request):\n        # Comment will be disallowed outright (HTTP 403 response)\n        return False\n\n    if default_moderator.moderate(comment, content_object, request):\n        comment.is_public = False", "response": "Run the default moderator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending email notification of a new comment to site staff when email notifications have been requested.", "response": "def on_comment_posted(sender, comment, request, **kwargs):\n    \"\"\"\n    Send email notification of a new comment to site staff when email notifications have been requested.\n    \"\"\"\n    content_object = comment.content_object\n\n    moderator = moderation.get_model_moderator(content_object.__class__)\n    if moderator is None or comment.__class__ is not CommentModel:\n        # No custom moderator means no email would be sent.\n        # This still pass the comment to the default moderator.\n        default_moderator.email(comment, content_object, request)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef akismet_check(comment, content_object, request):\n    # Return previously cached response\n    akismet_result = getattr(comment, '_akismet_result_', None)\n    if akismet_result is not None:\n        return akismet_result\n\n    # Get Akismet data\n    AKISMET_API_KEY = appsettings.AKISMET_API_KEY\n    if not AKISMET_API_KEY:\n        raise ImproperlyConfigured('You must set AKISMET_API_KEY to use comment moderation with Akismet.')\n\n    current_domain = get_current_site(request).domain\n    auto_blog_url = '{0}://{1}/'.format(request.is_secure() and 'https' or 'http', current_domain)\n    blog_url = appsettings.AKISMET_BLOG_URL or auto_blog_url\n\n    akismet = Akismet(\n        AKISMET_API_KEY,\n        blog=blog_url,\n        is_test=int(bool(appsettings.AKISMET_IS_TEST)),\n        application_user_agent='django-fluent-comments/{0}'.format(fluent_comments.__version__),\n    )\n\n    akismet_data = _get_akismet_data(blog_url, comment, content_object, request)\n    akismet_result = akismet.check(**akismet_data)  # raises AkismetServerError when key is invalid\n    setattr(comment, \"_akismet_result_\", akismet_result)\n    return akismet_result", "response": "Checks if the comment is spam."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_remark_msg(self, msg):\n        msg = msg.strip()\n        if msg.startswith(\"runtime error:\"):\n            raise exception.OverpassRuntimeError(msg=msg)\n        elif msg.startswith(\"runtime remark:\"):\n            raise exception.OverpassRuntimeRemark(msg=msg)\n        raise exception.OverpassUnknownError(msg=msg)", "response": "Handle the message provided with the remark tag or element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query(self, query):\n        if not isinstance(query, bytes):\n            query = query.encode(\"utf-8\")\n\n        retry_num = 0\n        retry_exceptions = []\n        do_retry = True if self.max_retry_count > 0 else False\n        while retry_num <= self.max_retry_count:\n            if retry_num > 0:\n                time.sleep(self.retry_timeout)\n            retry_num += 1\n            try:\n                f = urlopen(self.url, query)\n            except HTTPError as e:\n                f = e\n\n            response = f.read(self.read_chunk_size)\n            while True:\n                data = f.read(self.read_chunk_size)\n                if len(data) == 0:\n                    break\n                response = response + data\n            f.close()\n\n            if f.code == 200:\n                if PY2:\n                    http_info = f.info()\n                    content_type = http_info.getheader(\"content-type\")\n                else:\n                    content_type = f.getheader(\"Content-Type\")\n\n                if content_type == \"application/json\":\n                    return self.parse_json(response)\n\n                if content_type == \"application/osm3s+xml\":\n                    return self.parse_xml(response)\n\n                e = exception.OverpassUnknownContentType(content_type)\n                if not do_retry:\n                    raise e\n                retry_exceptions.append(e)\n                continue\n\n            if f.code == 400:\n                msgs = []\n                for msg in self._regex_extract_error_msg.finditer(response):\n                    tmp = self._regex_remove_tag.sub(b\"\", msg.group(\"msg\"))\n                    try:\n                        tmp = tmp.decode(\"utf-8\")\n                    except UnicodeDecodeError:\n                        tmp = repr(tmp)\n                    msgs.append(tmp)\n\n                e = exception.OverpassBadRequest(\n                    query,\n                    msgs=msgs\n                )\n                if not do_retry:\n                    raise e\n                retry_exceptions.append(e)\n                continue\n\n            if f.code == 429:\n                e = exception.OverpassTooManyRequests\n                if not do_retry:\n                    raise e\n                retry_exceptions.append(e)\n                continue\n\n            if f.code == 504:\n                e = exception.OverpassGatewayTimeout\n                if not do_retry:\n                    raise e\n                retry_exceptions.append(e)\n                continue\n\n            e = exception.OverpassUnknownHTTPStatusCode(f.code)\n            if not do_retry:\n                raise e\n            retry_exceptions.append(e)\n            continue\n\n        raise exception.MaxRetriesReached(retry_count=retry_num, exceptions=retry_exceptions)", "response": "Query the Overpass API and return the parsed result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_json(self, data, encoding=\"utf-8\"):\n        if isinstance(data, bytes):\n            data = data.decode(encoding)\n        data = json.loads(data, parse_float=Decimal)\n        if \"remark\" in data:\n            self._handle_remark_msg(msg=data.get(\"remark\"))\n        return Result.from_json(data, api=self)", "response": "Parse raw response from Overpass service."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd all elements from an other result to the list of elements of this result object.", "response": "def expand(self, other):\n        \"\"\"\n        Add all elements from an other result to the list of elements of this result object.\n\n        It is used by the auto resolve feature.\n\n        :param other: Expand the result with the elements from this result.\n        :type other: overpy.Result\n        :raises ValueError: If provided parameter is not instance of :class:`overpy.Result`\n        \"\"\"\n        if not isinstance(other, Result):\n            raise ValueError(\"Provided argument has to be instance of overpy:Result()\")\n\n        other_collection_map = {Node: other.nodes, Way: other.ways, Relation: other.relations, Area: other.areas}\n        for element_type, own_collection in self._class_collection_map.items():\n            for element in other_collection_map[element_type]:\n                if is_valid_type(element, element_type) and element.id not in own_collection:\n                    own_collection[element.id] = element"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef append(self, element):\n        if is_valid_type(element, Element):\n            self._class_collection_map[element.__class__].setdefault(element.id, element)", "response": "Append a new element to the result."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a list of elements from the result and filter the element type by a class.", "response": "def get_elements(self, filter_cls, elem_id=None):\n        \"\"\"\n        Get a list of elements from the result and filter the element type by a class.\n\n        :param filter_cls:\n        :param elem_id: ID of the object\n        :type elem_id: Integer\n        :return: List of available elements\n        :rtype: List\n        \"\"\"\n        result = []\n        if elem_id is not None:\n            try:\n                result = [self._class_collection_map[filter_cls][elem_id]]\n            except KeyError:\n                result = []\n        else:\n            for e in self._class_collection_map[filter_cls].values():\n                result.append(e)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_json(cls, data, api=None):\n        result = cls(api=api)\n        for elem_cls in [Node, Way, Relation, Area]:\n            for element in data.get(\"elements\", []):\n                e_type = element.get(\"type\")\n                if hasattr(e_type, \"lower\") and e_type.lower() == elem_cls._type_value:\n                    result.append(elem_cls.from_json(element, result=result))\n\n        return result", "response": "Create a new Result object from json data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_xml(cls, data, api=None, parser=None):\n        if parser is None:\n            if isinstance(data, str):\n                parser = XML_PARSER_SAX\n            else:\n                parser = XML_PARSER_DOM\n\n        result = cls(api=api)\n        if parser == XML_PARSER_DOM:\n            import xml.etree.ElementTree as ET\n            if isinstance(data, str):\n                root = ET.fromstring(data)\n            elif isinstance(data, ET.Element):\n                root = data\n            else:\n                raise exception.OverPyException(\"Unable to detect data type.\")\n\n            for elem_cls in [Node, Way, Relation, Area]:\n                for child in root:\n                    if child.tag.lower() == elem_cls._type_value:\n                        result.append(elem_cls.from_xml(child, result=result))\n\n        elif parser == XML_PARSER_SAX:\n            if PY2:\n                from StringIO import StringIO\n            else:\n                from io import StringIO\n            source = StringIO(data)\n            sax_handler = OSMSAXHandler(result)\n            parser = make_parser()\n            parser.setContentHandler(sax_handler)\n            parser.parse(source)\n        else:\n            # ToDo: better exception\n            raise Exception(\"Unknown XML parser\")\n        return result", "response": "Create a new Result object from XML data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_area(self, area_id, resolve_missing=False):\n        areas = self.get_areas(area_id=area_id)\n        if len(areas) == 0:\n            if resolve_missing is False:\n                raise exception.DataIncomplete(\"Resolve missing area is disabled\")\n\n            query = (\"\\n\"\n                     \"[out:json];\\n\"\n                     \"area({area_id});\\n\"\n                     \"out body;\\n\"\n                     )\n            query = query.format(\n                area_id=area_id\n            )\n            tmp_result = self.api.query(query)\n            self.expand(tmp_result)\n\n            areas = self.get_areas(area_id=area_id)\n\n        if len(areas) == 0:\n            raise exception.DataIncomplete(\"Unable to resolve requested areas\")\n\n        return areas[0]", "response": "Get an area by its ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_areas(self, area_id=None, **kwargs):\n        return self.get_elements(Area, elem_id=area_id, **kwargs)", "response": "Alias for get_elements but filter the result by Area\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a node by its ID.", "response": "def get_node(self, node_id, resolve_missing=False):\n        \"\"\"\n        Get a node by its ID.\n\n        :param node_id: The node ID\n        :type node_id: Integer\n        :param resolve_missing: Query the Overpass API if the node is missing in the result set.\n        :return: The node\n        :rtype: overpy.Node\n        :raises overpy.exception.DataIncomplete: At least one referenced node is not available in the result cache.\n        :raises overpy.exception.DataIncomplete: If resolve_missing is True and at least one node can't be resolved.\n        \"\"\"\n        nodes = self.get_nodes(node_id=node_id)\n        if len(nodes) == 0:\n            if not resolve_missing:\n                raise exception.DataIncomplete(\"Resolve missing nodes is disabled\")\n\n            query = (\"\\n\"\n                     \"[out:json];\\n\"\n                     \"node({node_id});\\n\"\n                     \"out body;\\n\"\n                     )\n            query = query.format(\n                node_id=node_id\n            )\n            tmp_result = self.api.query(query)\n            self.expand(tmp_result)\n\n            nodes = self.get_nodes(node_id=node_id)\n\n        if len(nodes) == 0:\n            raise exception.DataIncomplete(\"Unable to resolve all nodes\")\n\n        return nodes[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\naliases for get_elements but filter the result by Node", "response": "def get_nodes(self, node_id=None, **kwargs):\n        \"\"\"\n        Alias for get_elements() but filter the result by Node()\n\n        :param node_id: The Id of the node\n        :type node_id: Integer\n        :return: List of elements\n        \"\"\"\n        return self.get_elements(Node, elem_id=node_id, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_relation(self, rel_id, resolve_missing=False):\n        relations = self.get_relations(rel_id=rel_id)\n        if len(relations) == 0:\n            if resolve_missing is False:\n                raise exception.DataIncomplete(\"Resolve missing relations is disabled\")\n\n            query = (\"\\n\"\n                     \"[out:json];\\n\"\n                     \"relation({relation_id});\\n\"\n                     \"out body;\\n\"\n                     )\n            query = query.format(\n                relation_id=rel_id\n            )\n            tmp_result = self.api.query(query)\n            self.expand(tmp_result)\n\n            relations = self.get_relations(rel_id=rel_id)\n\n        if len(relations) == 0:\n            raise exception.DataIncomplete(\"Unable to resolve requested reference\")\n\n        return relations[0]", "response": "Get a relation by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\naliasing for get_elements but filter the result by Relation", "response": "def get_relations(self, rel_id=None, **kwargs):\n        \"\"\"\n        Alias for get_elements() but filter the result by Relation\n\n        :param rel_id: Id of the relation\n        :type rel_id: Integer\n        :return: List of elements\n        \"\"\"\n        return self.get_elements(Relation, elem_id=rel_id, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_way(self, way_id, resolve_missing=False):\n        ways = self.get_ways(way_id=way_id)\n        if len(ways) == 0:\n            if resolve_missing is False:\n                raise exception.DataIncomplete(\"Resolve missing way is disabled\")\n\n            query = (\"\\n\"\n                     \"[out:json];\\n\"\n                     \"way({way_id});\\n\"\n                     \"out body;\\n\"\n                     )\n            query = query.format(\n                way_id=way_id\n            )\n            tmp_result = self.api.query(query)\n            self.expand(tmp_result)\n\n            ways = self.get_ways(way_id=way_id)\n\n        if len(ways) == 0:\n            raise exception.DataIncomplete(\"Unable to resolve requested way\")\n\n        return ways[0]", "response": "Get a way by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ways(self, way_id=None, **kwargs):\n        return self.get_elements(Way, elem_id=way_id, **kwargs)", "response": "Alias for get_elements but filter the result by Way\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_center_from_json(cls, data):\n        center_lat = None\n        center_lon = None\n        center = data.get(\"center\")\n        if isinstance(center, dict):\n            center_lat = center.get(\"lat\")\n            center_lon = center.get(\"lon\")\n            if center_lat is None or center_lon is None:\n                raise ValueError(\"Unable to get lat or lon of way center.\")\n            center_lat = Decimal(center_lat)\n            center_lon = Decimal(center_lon)\n        return (center_lat, center_lon)", "response": "Get center information from json data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new way element from an xml. etree. Element object.", "response": "def from_xml(cls, child, result=None):\n        \"\"\"\n        Create new way element from XML data\n\n        :param child: XML node to be parsed\n        :type child: xml.etree.ElementTree.Element\n        :param result: The result this node belongs to\n        :type result: overpy.Result\n        :return: New Way oject\n        :rtype: overpy.Way\n        :raises overpy.exception.ElementDataWrongType: If name of the xml child node doesn't match\n        :raises ValueError: If the ref attribute of the xml node is not provided\n        :raises ValueError: If a tag doesn't have a name\n        \"\"\"\n        if child.tag.lower() != cls._type_value:\n            raise exception.ElementDataWrongType(\n                type_expected=cls._type_value,\n                type_provided=child.tag.lower()\n            )\n\n        tags = {}\n\n        for sub_child in child:\n            if sub_child.tag.lower() == \"tag\":\n                name = sub_child.attrib.get(\"k\")\n                if name is None:\n                    raise ValueError(\"Tag without name/key.\")\n                value = sub_child.attrib.get(\"v\")\n                tags[name] = value\n\n        area_id = child.attrib.get(\"id\")\n        if area_id is not None:\n            area_id = int(area_id)\n\n        attributes = {}\n        ignore = [\"id\"]\n        for n, v in child.attrib.items():\n            if n in ignore:\n                continue\n            attributes[n] = v\n\n        return cls(area_id=area_id, attributes=attributes, tags=tags, result=result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new Node element from a JSON data dict.", "response": "def from_json(cls, data, result=None):\n        \"\"\"\n        Create new Node element from JSON data\n\n        :param data: Element data from JSON\n        :type data: Dict\n        :param result: The result this element belongs to\n        :type result: overpy.Result\n        :return: New instance of Node\n        :rtype: overpy.Node\n        :raises overpy.exception.ElementDataWrongType: If type value of the passed JSON data does not match.\n        \"\"\"\n        if data.get(\"type\") != cls._type_value:\n            raise exception.ElementDataWrongType(\n                type_expected=cls._type_value,\n                type_provided=data.get(\"type\")\n            )\n\n        tags = data.get(\"tags\", {})\n\n        node_id = data.get(\"id\")\n        lat = data.get(\"lat\")\n        lon = data.get(\"lon\")\n\n        attributes = {}\n        ignore = [\"type\", \"id\", \"lat\", \"lon\", \"tags\"]\n        for n, v in data.items():\n            if n in ignore:\n                continue\n            attributes[n] = v\n\n        return cls(node_id=node_id, lat=lat, lon=lon, tags=tags, attributes=attributes, result=result)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new way element from an XML node.", "response": "def from_xml(cls, child, result=None):\n        \"\"\"\n        Create new way element from XML data\n\n        :param child: XML node to be parsed\n        :type child: xml.etree.ElementTree.Element\n        :param result: The result this node belongs to\n        :type result: overpy.Result\n        :return: New Way oject\n        :rtype: overpy.Node\n        :raises overpy.exception.ElementDataWrongType: If name of the xml child node doesn't match\n        :raises ValueError: If a tag doesn't have a name\n        \"\"\"\n        if child.tag.lower() != cls._type_value:\n            raise exception.ElementDataWrongType(\n                type_expected=cls._type_value,\n                type_provided=child.tag.lower()\n            )\n\n        tags = {}\n\n        for sub_child in child:\n            if sub_child.tag.lower() == \"tag\":\n                name = sub_child.attrib.get(\"k\")\n                if name is None:\n                    raise ValueError(\"Tag without name/key.\")\n                value = sub_child.attrib.get(\"v\")\n                tags[name] = value\n\n        node_id = child.attrib.get(\"id\")\n        if node_id is not None:\n            node_id = int(node_id)\n        lat = child.attrib.get(\"lat\")\n        if lat is not None:\n            lat = Decimal(lat)\n        lon = child.attrib.get(\"lon\")\n        if lon is not None:\n            lon = Decimal(lon)\n\n        attributes = {}\n        ignore = [\"id\", \"lat\", \"lon\"]\n        for n, v in child.attrib.items():\n            if n in ignore:\n                continue\n            attributes[n] = v\n\n        return cls(node_id=node_id, lat=lat, lon=lon, tags=tags, attributes=attributes, result=result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the nodes defining the geometry of the way.", "response": "def get_nodes(self, resolve_missing=False):\n        \"\"\"\n        Get the nodes defining the geometry of the way\n\n        :param resolve_missing: Try to resolve missing nodes.\n        :type resolve_missing: Boolean\n        :return: List of nodes\n        :rtype: List of overpy.Node\n        :raises overpy.exception.DataIncomplete: At least one referenced node is not available in the result cache.\n        :raises overpy.exception.DataIncomplete: If resolve_missing is True and at least one node can't be resolved.\n        \"\"\"\n        result = []\n        resolved = False\n\n        for node_id in self._node_ids:\n            try:\n                node = self._result.get_node(node_id)\n            except exception.DataIncomplete:\n                node = None\n\n            if node is not None:\n                result.append(node)\n                continue\n\n            if not resolve_missing:\n                raise exception.DataIncomplete(\"Resolve missing nodes is disabled\")\n\n            # We tried to resolve the data but some nodes are still missing\n            if resolved:\n                raise exception.DataIncomplete(\"Unable to resolve all nodes\")\n\n            query = (\"\\n\"\n                     \"[out:json];\\n\"\n                     \"way({way_id});\\n\"\n                     \"node(w);\\n\"\n                     \"out body;\\n\"\n                     )\n            query = query.format(\n                way_id=self.id\n            )\n            tmp_result = self._result.api.query(query)\n            self._result.expand(tmp_result)\n            resolved = True\n\n            try:\n                node = self._result.get_node(node_id)\n            except exception.DataIncomplete:\n                node = None\n\n            if node is None:\n                raise exception.DataIncomplete(\"Unable to resolve all nodes\")\n\n            result.append(node)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_json(cls, data, result=None):\n        if data.get(\"type\") != cls._type_value:\n            raise exception.ElementDataWrongType(\n                type_expected=cls._type_value,\n                type_provided=data.get(\"type\")\n            )\n\n        tags = data.get(\"tags\", {})\n\n        way_id = data.get(\"id\")\n        node_ids = data.get(\"nodes\")\n        (center_lat, center_lon) = cls.get_center_from_json(data=data)\n\n        attributes = {}\n        ignore = [\"center\", \"id\", \"nodes\", \"tags\", \"type\"]\n        for n, v in data.items():\n            if n in ignore:\n                continue\n            attributes[n] = v\n\n        return cls(\n            attributes=attributes,\n            center_lat=center_lat,\n            center_lon=center_lon,\n            node_ids=node_ids,\n            tags=tags,\n            result=result,\n            way_id=way_id\n        )", "response": "Create a new Way element from JSON data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new way element from an XML node.", "response": "def from_xml(cls, child, result=None):\n        \"\"\"\n        Create new way element from XML data\n\n        :param child: XML node to be parsed\n        :type child: xml.etree.ElementTree.Element\n        :param result: The result this node belongs to\n        :type result: overpy.Result\n        :return: New Way oject\n        :rtype: overpy.Way\n        :raises overpy.exception.ElementDataWrongType: If name of the xml child node doesn't match\n        :raises ValueError: If the ref attribute of the xml node is not provided\n        :raises ValueError: If a tag doesn't have a name\n        \"\"\"\n        if child.tag.lower() != cls._type_value:\n            raise exception.ElementDataWrongType(\n                type_expected=cls._type_value,\n                type_provided=child.tag.lower()\n            )\n\n        tags = {}\n        node_ids = []\n        center_lat = None\n        center_lon = None\n\n        for sub_child in child:\n            if sub_child.tag.lower() == \"tag\":\n                name = sub_child.attrib.get(\"k\")\n                if name is None:\n                    raise ValueError(\"Tag without name/key.\")\n                value = sub_child.attrib.get(\"v\")\n                tags[name] = value\n            if sub_child.tag.lower() == \"nd\":\n                ref_id = sub_child.attrib.get(\"ref\")\n                if ref_id is None:\n                    raise ValueError(\"Unable to find required ref value.\")\n                ref_id = int(ref_id)\n                node_ids.append(ref_id)\n            if sub_child.tag.lower() == \"center\":\n                (center_lat, center_lon) = cls.get_center_from_xml_dom(sub_child=sub_child)\n\n        way_id = child.attrib.get(\"id\")\n        if way_id is not None:\n            way_id = int(way_id)\n\n        attributes = {}\n        ignore = [\"id\"]\n        for n, v in child.attrib.items():\n            if n in ignore:\n                continue\n            attributes[n] = v\n\n        return cls(way_id=way_id, center_lat=center_lat, center_lon=center_lon,\n                   attributes=attributes, node_ids=node_ids, tags=tags, result=result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new relation element from JSON data.", "response": "def from_json(cls, data, result=None):\n        \"\"\"\n        Create new Relation element from JSON data\n\n        :param data: Element data from JSON\n        :type data: Dict\n        :param result: The result this element belongs to\n        :type result: overpy.Result\n        :return: New instance of Relation\n        :rtype: overpy.Relation\n        :raises overpy.exception.ElementDataWrongType: If type value of the passed JSON data does not match.\n        \"\"\"\n        if data.get(\"type\") != cls._type_value:\n            raise exception.ElementDataWrongType(\n                type_expected=cls._type_value,\n                type_provided=data.get(\"type\")\n            )\n\n        tags = data.get(\"tags\", {})\n\n        rel_id = data.get(\"id\")\n        (center_lat, center_lon) = cls.get_center_from_json(data=data)\n\n        members = []\n\n        supported_members = [RelationNode, RelationWay, RelationRelation]\n        for member in data.get(\"members\", []):\n            type_value = member.get(\"type\")\n            for member_cls in supported_members:\n                if member_cls._type_value == type_value:\n                    members.append(\n                        member_cls.from_json(\n                            member,\n                            result=result\n                        )\n                    )\n\n        attributes = {}\n        ignore = [\"id\", \"members\", \"tags\", \"type\"]\n        for n, v in data.items():\n            if n in ignore:\n                continue\n            attributes[n] = v\n\n        return cls(\n            rel_id=rel_id,\n            attributes=attributes,\n            center_lat=center_lat,\n            center_lon=center_lon,\n            members=members,\n            tags=tags,\n            result=result\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_xml(cls, child, result=None):\n        if child.tag.lower() != cls._type_value:\n            raise exception.ElementDataWrongType(\n                type_expected=cls._type_value,\n                type_provided=child.tag.lower()\n            )\n\n        tags = {}\n        members = []\n        center_lat = None\n        center_lon = None\n\n        supported_members = [RelationNode, RelationWay, RelationRelation, RelationArea]\n        for sub_child in child:\n            if sub_child.tag.lower() == \"tag\":\n                name = sub_child.attrib.get(\"k\")\n                if name is None:\n                    raise ValueError(\"Tag without name/key.\")\n                value = sub_child.attrib.get(\"v\")\n                tags[name] = value\n            if sub_child.tag.lower() == \"member\":\n                type_value = sub_child.attrib.get(\"type\")\n                for member_cls in supported_members:\n                    if member_cls._type_value == type_value:\n                        members.append(\n                            member_cls.from_xml(\n                                sub_child,\n                                result=result\n                            )\n                        )\n            if sub_child.tag.lower() == \"center\":\n                (center_lat, center_lon) = cls.get_center_from_xml_dom(sub_child=sub_child)\n\n        rel_id = child.attrib.get(\"id\")\n        if rel_id is not None:\n            rel_id = int(rel_id)\n\n        attributes = {}\n        ignore = [\"id\"]\n        for n, v in child.attrib.items():\n            if n in ignore:\n                continue\n            attributes[n] = v\n\n        return cls(\n            rel_id=rel_id,\n            attributes=attributes,\n            center_lat=center_lat,\n            center_lon=center_lon,\n            members=members,\n            tags=tags,\n            result=result\n        )", "response": "Create a new way element from an XML node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new RelationMember element from JSON data.", "response": "def from_json(cls, data, result=None):\n        \"\"\"\n        Create new RelationMember element from JSON data\n\n        :param child: Element data from JSON\n        :type child: Dict\n        :param result: The result this element belongs to\n        :type result: overpy.Result\n        :return: New instance of RelationMember\n        :rtype: overpy.RelationMember\n        :raises overpy.exception.ElementDataWrongType: If type value of the passed JSON data does not match.\n        \"\"\"\n        if data.get(\"type\") != cls._type_value:\n            raise exception.ElementDataWrongType(\n                type_expected=cls._type_value,\n                type_provided=data.get(\"type\")\n            )\n\n        ref = data.get(\"ref\")\n        role = data.get(\"role\")\n\n        attributes = {}\n        ignore = [\"geometry\", \"type\", \"ref\", \"role\"]\n        for n, v in data.items():\n            if n in ignore:\n                continue\n            attributes[n] = v\n\n        geometry = data.get(\"geometry\")\n        if isinstance(geometry, list):\n            geometry_orig = geometry\n            geometry = []\n            for v in geometry_orig:\n                geometry.append(\n                    RelationWayGeometryValue(\n                        lat=v.get(\"lat\"),\n                        lon=v.get(\"lon\")\n                    )\n                )\n        else:\n            geometry = None\n\n        return cls(\n            attributes=attributes,\n            geometry=geometry,\n            ref=ref,\n            role=role,\n            result=result\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new relation member from XML data.", "response": "def from_xml(cls, child, result=None):\n        \"\"\"\n        Create new RelationMember from XML data\n\n        :param child: XML node to be parsed\n        :type child: xml.etree.ElementTree.Element\n        :param result: The result this element belongs to\n        :type result: overpy.Result\n        :return: New relation member oject\n        :rtype: overpy.RelationMember\n        :raises overpy.exception.ElementDataWrongType: If name of the xml child node doesn't match\n        \"\"\"\n        if child.attrib.get(\"type\") != cls._type_value:\n            raise exception.ElementDataWrongType(\n                type_expected=cls._type_value,\n                type_provided=child.tag.lower()\n            )\n\n        ref = child.attrib.get(\"ref\")\n        if ref is not None:\n            ref = int(ref)\n        role = child.attrib.get(\"role\")\n\n        attributes = {}\n        ignore = [\"geometry\", \"ref\", \"role\", \"type\"]\n        for n, v in child.attrib.items():\n            if n in ignore:\n                continue\n            attributes[n] = v\n\n        geometry = None\n        for sub_child in child:\n            if sub_child.tag.lower() == \"nd\":\n                if geometry is None:\n                    geometry = []\n                geometry.append(\n                    RelationWayGeometryValue(\n                        lat=Decimal(sub_child.attrib[\"lat\"]),\n                        lon=Decimal(sub_child.attrib[\"lon\"])\n                    )\n                )\n\n        return cls(\n            attributes=attributes,\n            geometry=geometry,\n            ref=ref,\n            role=role,\n            result=result\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef startElement(self, name, attrs):\n        if name in self.ignore_start:\n            return\n        try:\n            handler = getattr(self, '_handle_start_%s' % name)\n        except AttributeError:\n            raise KeyError(\"Unknown element start '%s'\" % name)\n        handler(attrs)", "response": "Handle opening elements.\n\n        :param name: Name of the element\n        :type name: String\n        :param attrs: Attributes of the element\n        :type attrs: Dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle closing elements of the specified name.", "response": "def endElement(self, name):\n        \"\"\"\n        Handle closing elements\n\n        :param name: Name of the element\n        :type name: String\n        \"\"\"\n        if name in self.ignore_end:\n            return\n        try:\n            handler = getattr(self, '_handle_end_%s' % name)\n        except AttributeError:\n            raise KeyError(\"Unknown element end '%s'\" % name)\n        handler()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles opening center element", "response": "def _handle_start_center(self, attrs):\n        \"\"\"\n        Handle opening center element\n\n        :param attrs: Attributes of the element\n        :type attrs: Dict\n        \"\"\"\n        center_lat = attrs.get(\"lat\")\n        center_lon = attrs.get(\"lon\")\n        if center_lat is None or center_lon is None:\n            raise ValueError(\"Unable to get lat or lon of way center.\")\n        self._curr[\"center_lat\"] = Decimal(center_lat)\n        self._curr[\"center_lon\"] = Decimal(center_lon)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles opening tag element", "response": "def _handle_start_tag(self, attrs):\n        \"\"\"\n        Handle opening tag element\n\n        :param attrs: Attributes of the element\n        :type attrs: Dict\n        \"\"\"\n        try:\n            tag_key = attrs['k']\n        except KeyError:\n            raise ValueError(\"Tag without name/key.\")\n        self._curr['tags'][tag_key] = attrs.get('v')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_start_node(self, attrs):\n        self._curr = {\n            'attributes': dict(attrs),\n            'lat': None,\n            'lon': None,\n            'node_id': None,\n            'tags': {}\n        }\n        if attrs.get('id', None) is not None:\n            self._curr['node_id'] = int(attrs['id'])\n            del self._curr['attributes']['id']\n        if attrs.get('lat', None) is not None:\n            self._curr['lat'] = Decimal(attrs['lat'])\n            del self._curr['attributes']['lat']\n        if attrs.get('lon', None) is not None:\n            self._curr['lon'] = Decimal(attrs['lon'])\n            del self._curr['attributes']['lon']", "response": "Handle opening node element\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_end_node(self):\n        self._result.append(Node(result=self._result, **self._curr))\n        self._curr = {}", "response": "Handle closing node element"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling opening way element", "response": "def _handle_start_way(self, attrs):\n        \"\"\"\n        Handle opening way element\n\n        :param attrs: Attributes of the element\n        :type attrs: Dict\n        \"\"\"\n        self._curr = {\n            'center_lat': None,\n            'center_lon': None,\n            'attributes': dict(attrs),\n            'node_ids': [],\n            'tags': {},\n            'way_id': None\n        }\n        if attrs.get('id', None) is not None:\n            self._curr['way_id'] = int(attrs['id'])\n            del self._curr['attributes']['id']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_end_way(self):\n        self._result.append(Way(result=self._result, **self._curr))\n        self._curr = {}", "response": "Handle closing way element"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle opening area element", "response": "def _handle_start_area(self, attrs):\n        \"\"\"\n        Handle opening area element\n\n        :param attrs: Attributes of the element\n        :type attrs: Dict\n        \"\"\"\n        self._curr = {\n            'attributes': dict(attrs),\n            'tags': {},\n            'area_id': None\n        }\n        if attrs.get('id', None) is not None:\n            self._curr['area_id'] = int(attrs['id'])\n            del self._curr['attributes']['id']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle closing area element", "response": "def _handle_end_area(self):\n        \"\"\"\n        Handle closing area element\n        \"\"\"\n        self._result.append(Area(result=self._result, **self._curr))\n        self._curr = {}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_start_nd(self, attrs):\n        if isinstance(self.cur_relation_member, RelationWay):\n            if self.cur_relation_member.geometry is None:\n                self.cur_relation_member.geometry = []\n            self.cur_relation_member.geometry.append(\n                RelationWayGeometryValue(\n                    lat=Decimal(attrs[\"lat\"]),\n                    lon=Decimal(attrs[\"lon\"])\n                )\n            )\n        else:\n            try:\n                node_ref = attrs['ref']\n            except KeyError:\n                raise ValueError(\"Unable to find required ref value.\")\n            self._curr['node_ids'].append(int(node_ref))", "response": "Handle opening nd element"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_start_relation(self, attrs):\n        self._curr = {\n            'attributes': dict(attrs),\n            'members': [],\n            'rel_id': None,\n            'tags': {}\n        }\n        if attrs.get('id', None) is not None:\n            self._curr['rel_id'] = int(attrs['id'])\n            del self._curr['attributes']['id']", "response": "Handle opening relation element"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_end_relation(self):\n        self._result.append(Relation(result=self._result, **self._curr))\n        self._curr = {}", "response": "Handle closing relation element"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle opening member element", "response": "def _handle_start_member(self, attrs):\n        \"\"\"\n        Handle opening member element\n\n        :param attrs: Attributes of the element\n        :type attrs: Dict\n        \"\"\"\n\n        params = {\n            # ToDo: Parse attributes\n            'attributes': {},\n            'ref': None,\n            'result': self._result,\n            'role': None\n        }\n        if attrs.get('ref', None):\n            params['ref'] = int(attrs['ref'])\n        if attrs.get('role', None):\n            params['role'] = attrs['role']\n\n        cls_map = {\n            \"area\": RelationArea,\n            \"node\": RelationNode,\n            \"relation\": RelationRelation,\n            \"way\": RelationWay\n        }\n        cls = cls_map.get(attrs[\"type\"])\n        if cls is None:\n            raise ValueError(\"Undefined type for member: '%s'\" % attrs['type'])\n\n        self.cur_relation_member = cls(**params)\n        self._curr['members'].append(self.cur_relation_member)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving streets in a given bounding area.", "response": "def get_street(street, areacode, api=None):\n    \"\"\"\n    Retrieve streets in a given bounding area\n\n    :param overpy.Overpass api: First street of intersection\n    :param String street: Name of street\n    :param String areacode: The OSM id of the bounding area\n    :return: Parsed result\n    :raises overpy.exception.OverPyException: If something bad happens.\n    \"\"\"\n    if api is None:\n        api = overpy.Overpass()\n\n    query = \"\"\"\n        area(%s)->.location;\n        (\n            way[highway][name=\"%s\"](area.location);\n            - (\n                way[highway=service](area.location);\n                way[highway=track](area.location);\n            );\n        );\n        out body;\n        >;\n        out skel qt;\n    \"\"\"\n\n    data = api.query(query % (areacode, street))\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_intersection(street1, street2, areacode, api=None):\n    if api is None:\n        api = overpy.Overpass()\n\n    query = \"\"\"\n        area(%s)->.location;\n        (\n            way[highway][name=\"%s\"](area.location); node(w)->.n1;\n            way[highway][name=\"%s\"](area.location); node(w)->.n2;\n        );\n        node.n1.n2;\n        out meta;\n    \"\"\"\n\n    data = api.query(query % (areacode, street1, street2))\n\n    return data.get_nodes()", "response": "Retrieve intersection of two streets in a given bounding area."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a tree of nodes.", "response": "def print_tree(current_node, childattr='children', nameattr='name', indent='', last='updown'):\r\n\r\n    if hasattr(current_node, nameattr):\r\n        name = lambda node: getattr(node, nameattr)\r\n    else:\r\n        name = lambda node: str(node)\r\n\r\n    children = lambda node: getattr(node, childattr)\r\n    nb_children = lambda node: sum(nb_children(child) for child in children(node)) + 1\r\n    size_branch = {child: nb_children(child) for child in children(current_node)}\r\n\r\n    \"\"\" Creation of balanced lists for \"up\" branch and \"down\" branch. \"\"\"\r\n    up = sorted(children(current_node), key=lambda node: nb_children(node))\r\n    down = []\r\n    while up and sum(size_branch[node] for node in down) < sum(size_branch[node] for node in up):\r\n        down.append(up.pop())\r\n\r\n    \"\"\" Printing of \"up\" branch. \"\"\"\r\n    for child in up:     \r\n        next_last = 'up' if up.index(child) is 0 else ''\r\n        next_indent = '{0}{1}{2}'.format(indent, ' ' if 'up' in last else '\u2502', ' ' * len(name(current_node)))\r\n        print_tree(child, childattr, nameattr, next_indent, next_last)\r\n\r\n    \"\"\" Printing of current node. \"\"\"\r\n    if last == 'up': start_shape = '\u250c'\r\n    elif last == 'down': start_shape = '\u2514'\r\n    elif last == 'updown': start_shape = ' '\r\n    else: start_shape = '\u251c'\r\n\r\n    if up: end_shape = '\u2524'\r\n    elif down: end_shape = '\u2510'\r\n    else: end_shape = ''\r\n\r\n    print('{0}{1}{2}{3}'.format(indent, start_shape, name(current_node), end_shape))\r\n\r\n    \"\"\" Printing of \"down\" branch. \"\"\"\r\n    for child in down:\r\n        next_last = 'down' if down.index(child) is len(down) - 1 else ''\r\n        next_indent = '{0}{1}{2}'.format(indent, ' ' if 'down' in last else '\u2502', ' ' * len(name(current_node)))\r\n        print_tree(child, childattr, nameattr, next_indent, next_last)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the platforms have a valid platform code", "response": "def check_platforms(platforms):\n  \"\"\"Checks if the platforms have a valid platform code\"\"\"\n  if len(platforms) > 0:\n    return all(platform in PLATFORM_IDS for platform in platforms)\n  return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(active, upcoming, hiring, short, goto, platforms, time):\n\n  if not check_platforms(platforms):\n    raise IncorrectParametersException('Invlaid code for platform. Please check the platform ids')\n\n  try:\n    if active:\n      active_challenges = active_contests(platforms)\n      if goto:\n        webbrowser.open(active_challenges[goto - 1][\"contest_url\"], new=2)\n      else:\n        writers.write_contests(active_challenges, \"active\")\n      return\n\n    if upcoming:\n      upcoming_challenges = upcoming_contests(platforms, time)\n      if goto:\n        goto = int(goto)\n        webbrowser.open(upcoming_challenges[goto - 1][\"contest_url\"], new=2)\n      else:\n        writers.write_contests(upcoming_challenges, \"upcoming\")\n      return\n\n    if hiring:\n      hiring_challenges = hiring_contests()\n      if goto:\n        webbrowser.open(hiring_challenges[goto - 1][\"contest_url\"], new=2)\n      else:\n        writers.write_contests(hiring_challenges, \"hiring\")\n      return\n\n    if short:\n      short_challenges = short_contests(platforms)\n      if goto:\n        goto = int(goto)\n        webbrowser.open(short_challenges[goto - 1][\"contest_url\"], new=2)\n      else:\n        writers.write_contests(short_challenges, \"short\")\n      return\n\n    all_contests = get_all_contests(platforms, time)\n    if goto:\n      webbrowser.open(all_contests[goto - 1][\"contest_url\"], new=2)\n    else:\n      writers.write_contests(all_contests, \"all\")\n  except IncorrectParametersException as e:\n    click.secho(e.message, fg=\"red\", bold=True)", "response": "A CLI for active and upcoming programming challenges from various platforms"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef colors():\n  enums = dict(\n    TIME_LEFT=\"red\",\n    CONTEST_NAME=\"yellow\",\n    HOST=\"green\",\n    MISC=\"blue\",\n    TIME_TO_START=\"green\",\n  )\n\n  return type('Enum', (), enums)", "response": "Creates an enum for colors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef challenge():\n  enums = dict(\n    ACTIVE=\"active\",\n    UPCOMING=\"upcoming\",\n    HIRING=\"hiring\",\n    ALL=\"all\",\n    SHORT=\"short\",\n  )\n\n  return type('Enum', (), enums)", "response": "Creates an enum for contest type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a string with time for the contest to begin or end", "response": "def get_time_string(contest, contest_type):\n  \"\"\"Return a string with time for the contest to begin/end\"\"\"\n\n  if contest_type == challenge().ACTIVE:\n    time_diff = time_difference(contest[\"end\"])\n  elif contest_type == challenge().UPCOMING:\n    time_diff = time_difference(contest[\"start\"])\n  elif contest_type in [challenge().HIRING, challenge().SHORT, challenge().ALL]:\n    try:\n      time_diff = time_difference(contest[\"start\"])\n    except:\n      time_diff = time_difference(contest[\"end\"])\n  time_diff_string = \"\"\n\n  if time_diff.days > 0: \n    time_diff_string = \"{0} days {1} hours\".format(time_diff.days, time_diff.hours)\n  elif time_diff.hours > 0:\n    time_diff_string = \"{0} hours {1} minutes\".format(time_diff.hours, time_diff.minutes)\n  else:\n    time_diff_string = \"{0} minutes\".format(time_diff.minutes)\n  return time_diff_string"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the difference between the current time and the given time", "response": "def time_difference(target_time):\n  \"\"\"Calculate the difference between the current time and the given time\"\"\"\n  TimeDiff = namedtuple(\"TimeDiff\", [\"days\", \"hours\", \"minutes\", \"seconds\"])\n  time_diff = format_date(target_time) - datetime.utcnow()\n  hours, remainder = divmod(time_diff.seconds, 3600)\n  minutes, seconds = divmod(remainder, 60)\n  return TimeDiff(days=time_diff.days, hours=hours, minutes=minutes, seconds=seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef IntegerLike(msg=None):\n    '''\n    Checks whether a value is:\n        - int, or\n        - long, or\n        - float without a fractional part, or\n        - str or unicode composed only of digits\n    '''\n    def fn(value):\n        if not any([\n            isinstance(value, numbers.Integral),\n            (isinstance(value, float) and value.is_integer()),\n            (isinstance(value, basestring) and value.isdigit())\n        ]):\n            raise Invalid(msg or (\n                'Invalid input <{0}>; expected an integer'.format(value))\n            )\n        else:\n            return value\n    return fn", "response": "Returns a validation function that checks whether a value is an integer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Alphanumeric(msg=None):\n    '''\n    Checks whether a value is:\n        - int, or\n        - long, or\n        - float without a fractional part, or\n        - str or unicode composed only of alphanumeric characters\n    '''\n    def fn(value):\n        if not any([\n            isinstance(value, numbers.Integral),\n            (isinstance(value, float) and value.is_integer()),\n            (isinstance(value, basestring) and value.isalnum())\n        ]):\n            raise Invalid(msg or (\n                'Invalid input <{0}>; expected an integer'.format(value))\n            )\n        else:\n            return value\n    return fn", "response": "A function that checks whether a value is an integer or a float with a fractional part or a unicode string composed only of alphanumeric characters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether a value is: - str or unicode, and - composed of both alphabets and digits", "response": "def StrictlyAlphanumeric(msg=None):\n    '''\n    Checks whether a value is:\n        - str or unicode, and\n        - composed of both alphabets and digits\n    '''\n    def fn(value):\n        if not (\n            isinstance(value, basestring) and\n            value.isalnum() and not\n            value.isdigit() and not\n            value.isalpha()\n        ):\n            raise Invalid(msg or (\n                'Invalid input <{0}>; expected an integer'.format(value))\n            )\n        else:\n            return value\n    return fn"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a function that checks whether a value is a valid castable datetime object with timezone.", "response": "def DatetimeWithTZ(msg=None):\n    '''\n    Checks whether a value is :\n        - a valid castable datetime object with timezone.\n    '''\n    def fn(value):\n        try:\n            date = parse_datetime(value) or parse_date(value)\n            if date is not None:\n                return date\n            else:\n                raise ValueError\n        except ValueError:\n            raise Invalid('<{0}> is not a valid datetime.'.format(value))\n    return fn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CSVofIntegers(msg=None):\n    '''\n    Checks whether a value is list of integers.\n    Returns list of integers or just one integer in\n    list if there is only one element in given CSV string.\n    '''\n    def fn(value):\n        try:\n            if isinstance(value, basestring):\n                if ',' in value:\n                    value = list(map(\n                        int, filter(\n                            bool, list(map(\n                                lambda x: x.strip(), value.split(',')\n                            ))\n                        )\n                    ))\n                    return value\n                else:\n                    return [int(value)]\n            else:\n                raise ValueError\n        except ValueError:\n            raise Invalid(\n                '<{0}> is not a valid csv of integers'.format(value)\n            )\n    return fn", "response": "Returns a function that takes a CSV string and returns a list of integers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_queryset(self):\n\n        query_params = self.request.query_params\n        url_params = self.kwargs\n\n        # get queryset_filters from FilterMixin\n        queryset_filters = self.get_db_filters(url_params, query_params)\n\n        # This dict will hold filter kwargs to pass in to Django ORM calls.\n        db_filters = queryset_filters['db_filters']\n\n        # This dict will hold exclude kwargs to pass in to Django ORM calls.\n        db_excludes = queryset_filters['db_excludes']\n\n        queryset = Team.objects.prefetch_related(\n            'players'\n        ).all()\n\n        return queryset.filter(**db_filters).exclude(**db_excludes)", "response": "Returns a queryset of the items in the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a specific setting from the django settings.", "response": "def get_setting(name, default):\n    \"\"\"\n    A little helper for fetching global settings with a common prefix.\n    \"\"\"\n    parent_name = \"CMSPLUGIN_NEWS_{0}\".format(name)\n    return getattr(django_settings, parent_name, default)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmark selected news items as published", "response": "def make_published(self, request, queryset):\n        \"\"\"\n            Marks selected news items as published\n        \"\"\"\n        rows_updated = queryset.update(is_published=True)\n        self.message_user(request,\n                          ungettext('%(count)d newsitem was published',\n                                    '%(count)d newsitems were published',\n                                    rows_updated) % {'count': rows_updated})"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmarks selected news items as unpublished", "response": "def make_unpublished(self, request, queryset):\n        \"\"\"\n            Marks selected news items as unpublished\n        \"\"\"\n        rows_updated = queryset.update(is_published=False)\n        self.message_user(request,\n                          ungettext('%(count)d newsitem was unpublished',\n                                    '%(count)d newsitems were unpublished',\n                                    rows_updated) % {'count': rows_updated})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render(self, name, value, attrs=None):\n        if value is None:\n            value = ''\n        value = smart_unicode(value)\n        final_attrs = self.build_attrs(attrs)\n        final_attrs['name'] = name\n        assert 'id' in final_attrs, \\\n            \"TinyMCE widget attributes must contain 'id'\"\n        mce_config = cms.plugins.text.settings.TINYMCE_CONFIG.copy()\n        mce_config.update(get_language_config(self.content_language))\n        if tinymce.settings.USE_FILEBROWSER:\n            mce_config['file_browser_callback'] = \"djangoFileBrowser\"\n        mce_config.update(self.mce_attrs)\n        mce_config['mode'] = 'exact'\n        mce_config['elements'] = final_attrs['id']\n        mce_config['strict_loading_mode'] = 1\n        \"\"\"\n        plugins = mce_config.get(\"plugins\", \"\")\n        if len(plugins):\n            plugins += \",\"\n        plugins += \"-cmsplugins\"\n        mce_config['plugins'] = plugins\n        adv2 = mce_config.get('theme_advanced_buttons1', \"\")\n        if len(adv2):\n            adv2 = \",\" + adv2\n        adv2 = \"cmsplugins,cmspluginsedit\" + adv2\n        mce_config['theme_advanced_buttons1'] = adv2\n        \"\"\"\n        json = simplejson.dumps(mce_config)\n\n        html = [u'<textarea%s>%s</textarea>' % (flatatt(final_attrs),\n                escape(value))]\n        if tinymce.settings.USE_COMPRESSOR:\n            compressor_config = {\n                'plugins': mce_config.get('plugins', ''),\n                'themes': mce_config.get('theme', 'advanced'),\n                'languages': mce_config.get('language', ''),\n                'diskcache': True,\n                'debug': False,\n            }\n            c_json = simplejson.dumps(compressor_config)\n            html.append(\n                (u'<script type=\"text/javascript\">'\n                    'tinyMCE_GZ.init(%s);</script>') % (c_json))\n        html.append(\n            (u'<script type=\"text/javascript\">%s;\\ntinyMCE.init(%s);'\n                '</script>') % (\n                self.render_additions(\n                    name,\n                    value,\n                    attrs),\n                    json))\n        return mark_safe(u'\\n'.join(html))", "response": "Render the TinyMCE widget."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _execute_wk(*args, input=None):\n    wk_args = (WK_PATH,) + args\n    return subprocess.run(wk_args, input=input, stdout=subprocess.PIPE, stderr=subprocess.PIPE)", "response": "Generate path for the wkhtmltopdf binary and execute command."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a pdf from a string or url.", "response": "def generate_pdf(html, *,\n                 cache_dir: Path=DFT_CACHE_DIR,\n                 grayscale: bool=False,\n                 lowquality: bool=False,\n                 margin_bottom: str=None,\n                 margin_left: str=None,\n                 margin_right: str=None,\n                 margin_top: str=None,\n                 orientation: str=None,\n                 page_height: str=None,\n                 page_width: str=None,\n                 page_size: str=None,\n                 image_dpi: str=None,\n                 image_quality: str=None,\n                 **extra_kwargs):\n    \"\"\"\n    Generate a pdf from either a url or a html string.\n\n    After the html and url arguments all other arguments are\n    passed straight to wkhtmltopdf\n\n    For details on extra arguments see the output of get_help()\n    and get_extended_help()\n\n    All arguments whether specified or caught with extra_kwargs are converted\n    to command line args with \"'--' + original_name.replace('_', '-')\"\n\n    Arguments which are True are passed with no value eg. just --quiet, False\n    and None arguments are missed, everything else is passed with str(value).\n\n    :param html: html string to generate pdf from\n    :param grayscale: bool\n    :param lowquality: bool\n    :param margin_bottom: string eg. 10mm\n    :param margin_left: string eg. 10mm\n    :param margin_right: string eg. 10mm\n    :param margin_top: string eg. 10mm\n    :param orientation: Portrait or Landscape\n    :param page_height: string eg. 10mm\n    :param page_width: string eg. 10mm\n    :param page_size: string: A4, Letter, etc.\n    :param image_dpi: int default 600\n    :param image_quality: int default 94\n    :param extra_kwargs: any exotic extra options for wkhtmltopdf\n    :return: string representing pdf\n    \"\"\"\n    if not cache_dir.exists():\n        Path.mkdir(cache_dir)\n\n    py_args = dict(\n        cache_dir=cache_dir,\n        grayscale=grayscale,\n        lowquality=lowquality,\n        margin_bottom=margin_bottom,\n        margin_left=margin_left,\n        margin_right=margin_right,\n        margin_top=margin_top,\n        orientation=orientation,\n        page_height=page_height,\n        page_width=page_width,\n        page_size=page_size,\n        image_dpi=image_dpi,\n        image_quality=image_quality,\n    )\n    py_args.update(extra_kwargs)\n    cmd_args = _convert_args(**py_args)\n\n    p = _execute_wk(*cmd_args, input=html.encode())\n    pdf_content = p.stdout\n\n    # it seems wkhtmltopdf's error codes can be false, we'll ignore them if we\n    # seem to have generated a pdf\n    if p.returncode != 0 and pdf_content[:4] != b'%PDF':\n        raise RuntimeError('error running wkhtmltopdf, command: {!r}\\n'\n                           'response: \"{}\"'.format(cmd_args, p.stderr.decode().strip()))\n    return pdf_content"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_version():\n    try:\n        wk_version = _string_execute('-V')\n    except Exception as e:\n        # we catch all errors here to make sure we get a version no matter what\n        wk_version = '%s: %s' % (e.__class__.__name__, e)\n    return 'pydf version: %s\\nwkhtmltopdf version: %s' % (VERSION, wk_version)", "response": "Get version of pydf and wkhtmltopdf"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming sctring escape - for regexp literals", "response": "def _interpret_regexp(self, string, flags):\n        '''Perform sctring escape - for regexp literals'''\n        self.index = 0\n        self.length = len(string)\n        self.source = string\n        self.lineNumber = 0\n        self.lineStart = 0\n        octal = False\n        st = ''\n        inside_square = 0\n        while (self.index < self.length):\n            template = '[%s]' if not inside_square else '%s'\n            ch = self.source[self.index]\n            self.index += 1\n            if ch == '\\\\':\n                ch = self.source[self.index]\n                self.index += 1\n                if (not isLineTerminator(ch)):\n                    if ch == 'u':\n                        digs = self.source[self.index:self.index + 4]\n                        if len(digs) == 4 and all(isHexDigit(d) for d in digs):\n                            st += template % unichr(int(digs, 16))\n                            self.index += 4\n                        else:\n                            st += 'u'\n                    elif ch == 'x':\n                        digs = self.source[self.index:self.index + 2]\n                        if len(digs) == 2 and all(isHexDigit(d) for d in digs):\n                            st += template % unichr(int(digs, 16))\n                            self.index += 2\n                        else:\n                            st += 'x'\n                    # special meaning - single char.\n                    elif ch == '0':\n                        st += '\\\\0'\n                    elif ch == 'n':\n                        st += '\\\\n'\n                    elif ch == 'r':\n                        st += '\\\\r'\n                    elif ch == 't':\n                        st += '\\\\t'\n                    elif ch == 'f':\n                        st += '\\\\f'\n                    elif ch == 'v':\n                        st += '\\\\v'\n\n                    # unescape special single characters like . so that they are interpreted literally\n                    elif ch in REGEXP_SPECIAL_SINGLE:\n                        st += '\\\\' + ch\n\n                    # character groups\n                    elif ch == 'b':\n                        st += '\\\\b'\n                    elif ch == 'B':\n                        st += '\\\\B'\n                    elif ch == 'w':\n                        st += '\\\\w'\n                    elif ch == 'W':\n                        st += '\\\\W'\n                    elif ch == 'd':\n                        st += '\\\\d'\n                    elif ch == 'D':\n                        st += '\\\\D'\n                    elif ch == 's':\n                        st += template % u' \\f\\n\\r\\t\\v\\u00a0\\u1680\\u180e\\u2000-\\u200a\\u2028\\u2029\\u202f\\u205f\\u3000\\ufeff'\n                    elif ch == 'S':\n                        st += template % u'\\u0000-\\u0008\\u000e-\\u001f\\u0021-\\u009f\\u00a1-\\u167f\\u1681-\\u180d\\u180f-\\u1fff\\u200b-\\u2027\\u202a-\\u202e\\u2030-\\u205e\\u2060-\\u2fff\\u3001-\\ufefe\\uff00-\\uffff'\n                    else:\n                        if isDecimalDigit(ch):\n                            num = ch\n                            while self.index < self.length and isDecimalDigit(\n                                    self.source[self.index]):\n                                num += self.source[self.index]\n                                self.index += 1\n                            st += '\\\\' + num\n\n                        else:\n                            st += ch  # DONT ESCAPE!!!\n                else:\n                    self.lineNumber += 1\n                    if (ch == '\\r' and self.source[self.index] == '\\n'):\n                        self.index += 1\n                    self.lineStart = self.index\n            else:\n                if ch == '[':\n                    inside_square = True\n                elif ch == ']':\n                    inside_square = False\n                st += ch\n        # print string, 'was transformed to', st\n        return st"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching Crossref works for a set of DOIs.", "response": "def works(self, ids = None, query = None, filter = None, offset = None,\n              limit = None, sample = None, sort = None,\n              order = None, facet = None, select = None, cursor = None,\n              cursor_max = 5000, **kwargs):\n        '''\n        Search Crossref works\n\n        :param ids: [Array] DOIs (digital object identifier) or other identifiers\n        :param query: [String] A query string\n        :param filter: [Hash] Filter options. See examples for usage.\n            Accepts a dict, with filter names and their values. For repeating filter names\n            pass in a list of the values to that filter name, e.g.,\n            `{'award_funder': ['10.13039/100004440', '10.13039/100000861']}`.\n            See https://github.com/CrossRef/rest-api-doc#filter-names\n            for filter names and their descriptions and :func:`~habanero.Crossref.filter_names`\n            and :func:`~habanero.Crossref.filter_details`\n        :param offset: [Fixnum] Number of record to start at, from 1 to 10000\n        :param limit: [Fixnum] Number of results to return. Not relavant when searching with specific dois.\n            Default: 20. Max: 1000\n        :param sample: [Fixnum] Number of random results to return. when you use the sample parameter,\n            the limit and offset parameters are ignored. Max: 100\n        :param sort: [String] Field to sort on. Note: If the API call includes a query, then the sort\n            order will be by the relevance score. If no query is included, then the sort order\n            will be by DOI update date. See sorting_ for possible values.\n        :param order: [String] Sort order, one of 'asc' or 'desc'\n        :param facet: [Boolean/String] Set to `true` to include facet results (default: false).\n            Optionally, pass a query string, e.g., `facet=type-name:*` or `facet=license=*`.\n            See Facets_ for options.\n        :param select: [String/list(Strings)] Crossref metadata records can be\n            quite large. Sometimes you just want a few elements from the schema. You can \"select\"\n            a subset of elements to return. This can make your API calls much more efficient. Not\n            clear yet which fields are allowed here.\n        :param cursor: [String] Cursor character string to do deep paging. Default is None.\n            Pass in '*' to start deep paging. Any combination of query, filters and facets may be\n            used with deep paging cursors. While rows may be specified along with cursor, offset\n            and sample cannot be used.\n            See https://github.com/CrossRef/rest-api-doc/blob/master/rest_api.md#deep-paging-with-cursors\n        :param cursor_max: [Fixnum] Max records to retrieve. Only used when cursor param used. Because\n            deep paging can result in continuous requests until all are retrieved, use this\n            parameter to set a maximum number of records. Of course, if there are less records\n            found than this value, you will get only those found.\n        :param kwargs: additional named arguments passed on to `requests.get`, e.g., field\n            queries (see examples and FieldQueries_) \n\n        :return: A dict\n\n        Usage::\n\n            from habanero import Crossref\n            cr = Crossref()\n            cr.works()\n            cr.works(ids = '10.1371/journal.pone.0033693')\n            dois = ['10.1371/journal.pone.0033693', ]\n            cr.works(ids = dois)\n            x = cr.works(query = \"ecology\")\n            x['status']\n            x['message-type']\n            x['message-version']\n            x['message']\n            x['message']['total-results']\n            x['message']['items-per-page']\n            x['message']['query']\n            x['message']['items']\n\n            # Get full text links\n            x = cr.works(filter = {'has_full_text': True})\n            x\n\n            # Parse output to various data pieces\n            x = cr.works(filter = {'has_full_text': True})\n            ## get doi for each item\n            [ z['DOI'] for z in x['message']['items'] ]\n            ## get doi and url for each item\n            [ {\"doi\": z['DOI'], \"url\": z['URL']} for z in x['message']['items'] ]\n            ### print every doi\n            for i in x['message']['items']:\n                 print i['DOI']\n\n            # filters - pass in as a dict\n            ## see https://github.com/CrossRef/rest-api-doc#filter-names\n            cr.works(filter = {'has_full_text': True})\n            cr.works(filter = {'has_funder': True, 'has_full_text': True})\n            cr.works(filter = {'award_number': 'CBET-0756451', 'award_funder': '10.13039/100000001'})\n            ## to repeat a filter name, pass in a list\n            x = cr.works(filter = {'award_funder': ['10.13039/100004440', '10.13039/100000861']}, limit = 100)\n            map(lambda z:z['funder'][0]['DOI'], x['message']['items'])\n\n            # Deep paging, using the cursor parameter\n            ## this search should lead to only ~215 results\n            cr.works(query = \"widget\", cursor = \"*\", cursor_max = 100)\n            ## this search should lead to only ~2500 results, in chunks of 500\n            res = cr.works(query = \"octopus\", cursor = \"*\", limit = 500)\n            sum([ len(z['message']['items']) for z in res ])\n            ## about 167 results\n            res = cr.works(query = \"extravagant\", cursor = \"*\", limit = 50, cursor_max = 500)\n            sum([ len(z['message']['items']) for z in res ])\n            ## cursor_max to get back only a maximum set of results\n            res = cr.works(query = \"widget\", cursor = \"*\", cursor_max = 100)\n            sum([ len(z['message']['items']) for z in res ])\n            ## cursor_max - especially useful when a request could be very large\n            ### e.g., \"ecology\" results in ~275K records, lets max at 10,000\n            ###   with 1000 at a time\n            res = cr.works(query = \"ecology\", cursor = \"*\", cursor_max = 10000, limit = 1000)\n            sum([ len(z['message']['items']) for z in res ])\n            items = [ z['message']['items'] for z in res ]\n            items = [ item for sublist in items for item in sublist ]\n            [ z['DOI'] for z in items ][0:50]\n\n            # field queries\n            res = cr.works(query = \"ecology\", query_author = 'carl boettiger')\n            [ x['author'][0]['family'] for x in res['message']['items'] ]\n\n            # select certain fields to return\n            ## as a comma separated string\n            cr.works(query = \"ecology\", select = \"DOI,title\")\n            ## or as a list\n            cr.works(query = \"ecology\", select = [\"DOI\",\"title\"])\n        '''\n        if ids.__class__.__name__ != 'NoneType':\n            return request(self.mailto, self.base_url, \"/works/\", ids,\n                query, filter, offset, limit, sample, sort,\n                order, facet, select, None, None, None, None, **kwargs)\n        else:\n            return Request(self.mailto, self.base_url, \"/works/\",\n              query, filter, offset, limit, sample, sort,\n              order, facet, select, cursor, cursor_max, None, **kwargs).do_request()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prefixes(self, ids = None, filter = None, offset = None,\n              limit = None, sample = None, sort = None,\n              order = None, facet = None, works = False, select = None,\n              cursor = None, cursor_max = 5000, **kwargs):\n        '''\n        Search Crossref prefixes\n\n        :param ids: [Array] DOIs (digital object identifier) or other identifiers\n        :param filter: [Hash] Filter options. See examples for usage.\n            Accepts a dict, with filter names and their values. For repeating filter names\n            pass in a list of the values to that filter name, e.g.,\n            `{'award_funder': ['10.13039/100004440', '10.13039/100000861']}`.\n            See https://github.com/CrossRef/rest-api-doc#filter-names\n            for filter names and their descriptions and :func:`~habanero.Crossref.filter_names`\n            and :func:`~habanero.Crossref.filter_details`\n        :param offset: [Fixnum] Number of record to start at, from 1 to 10000\n        :param limit: [Fixnum] Number of results to return. Not relevant when searching with specific dois. Default: 20. Max: 1000\n        :param sample: [Fixnum] Number of random results to return. when you use the sample parameter,\n            the limit and offset parameters are ignored. This parameter only used when works requested. Max: 100\n        :param sort: [String] Field to sort on. Note: If the API call includes a query, then the sort\n            order will be by the relevance score. If no query is included, then the sort order\n            will be by DOI update date. See sorting_ for possible values.\n        :param order: [String] Sort order, one of 'asc' or 'desc'\n        :param facet: [Boolean/String] Set to `true` to include facet results (default: false).\n            Optionally, pass a query string, e.g., `facet=type-name:*` or `facet=license=*`\n            See Facets_ for options.\n        :param select: [String/list(Strings)] Crossref metadata records can be\n            quite large. Sometimes you just want a few elements from the schema. You can \"select\"\n            a subset of elements to return. This can make your API calls much more efficient. Not\n            clear yet which fields are allowed here.\n        :param works: [Boolean] If true, works returned as well. Default: false\n        :param kwargs: additional named arguments passed on to `requests.get`, e.g., field\n            queries (see examples and FieldQueries_)\n\n        :return: A dict\n\n        Usage::\n\n            from habanero import Crossref\n            cr = Crossref()\n            cr.prefixes(ids = \"10.1016\")\n            cr.prefixes(ids = ['10.1016','10.1371','10.1023','10.4176','10.1093'])\n\n            # get works\n            cr.prefixes(ids = \"10.1016\", works = True)\n\n            # Limit number of results\n            cr.prefixes(ids = \"10.1016\", works = True, limit = 3)\n\n            # Sort and order\n            cr.prefixes(ids = \"10.1016\", works = True, sort = \"relevance\", order = \"asc\")\n\n            # cursor - deep paging\n            res = cr.prefixes(ids = \"10.1016\", works = True, cursor = \"*\", limit = 200)\n            sum([ len(z['message']['items']) for z in res ])\n            items = [ z['message']['items'] for z in res ]\n            items = [ item for sublist in items for item in sublist ]\n            [ z['DOI'] for z in items ][0:50]\n\n            # field queries\n            res = cr.prefixes(ids = \"10.1371\", works = True, query_editor = 'cooper', filter = {'type': 'journal-article'})\n            eds = [ x.get('editor') for x in res['message']['items'] ]\n            [ z for z in eds if z is not None ]\n        '''\n        check_kwargs([\"query\"], kwargs)\n        return request(self.mailto, self.base_url, \"/prefixes/\", ids,\n          query = None, filter = filter, offset = offset, limit = limit,\n          sample = sample, sort = sort, order = order, facet = facet,\n          select = select, works = works, cursor = cursor, cursor_max = cursor_max,\n          **kwargs)", "response": "Search Crossref prefixes for a set of DOIs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef types(self, ids = None, query = None, filter = None, offset = None,\n              limit = None, sample = None, sort = None,\n              order = None, facet = None, works = False, select = None,\n              cursor = None, cursor_max = 5000, **kwargs):\n        '''\n        Search Crossref types\n\n        :param ids: [Array] Type identifier, e.g., journal\n        :param query: [String] A query string\n        :param filter: [Hash] Filter options. See examples for usage.\n            Accepts a dict, with filter names and their values. For repeating filter names\n            pass in a list of the values to that filter name, e.g.,\n            `{'award_funder': ['10.13039/100004440', '10.13039/100000861']}`.\n            See https://github.com/CrossRef/rest-api-doc#filter-names\n            for filter names and their descriptions and :func:`~habanero.Crossref.filter_names`\n            and :func:`~habanero.Crossref.filter_details`\n        :param offset: [Fixnum] Number of record to start at, from 1 to 10000\n        :param limit: [Fixnum] Number of results to return. Not relevant when searching with specific dois. Default: 20. Max: 1000\n        :param sample: [Fixnum] Number of random results to return. when you use the sample parameter,\n            the limit and offset parameters are ignored. This parameter only used when works requested. Max: 100\n        :param sort: [String] Field to sort on. Note: If the API call includes a query, then the sort\n            order will be by the relevance score. If no query is included, then the sort order\n            will be by DOI update date. See sorting_ for possible values.\n        :param order: [String] Sort order, one of 'asc' or 'desc'\n        :param facet: [Boolean/String] Set to `true` to include facet results (default: false).\n            Optionally, pass a query string, e.g., `facet=type-name:*` or `facet=license=*`\n            See Facets_ for options.\n        :param select: [String/list(Strings)] Crossref metadata records can be\n            quite large. Sometimes you just want a few elements from the schema. You can \"select\"\n            a subset of elements to return. This can make your API calls much more efficient. Not\n            clear yet which fields are allowed here.\n        :param works: [Boolean] If true, works returned as well. Default: false\n        :param kwargs: additional named arguments passed on to `requests.get`, e.g., field\n            queries (see examples and FieldQueries_)\n\n        :return: A dict\n\n        Usage::\n\n            from habanero import Crossref\n            cr = Crossref()\n            cr.types()\n            cr.types(ids = \"journal\")\n            cr.types(ids = \"journal-article\")\n            cr.types(ids = \"journal\", works = True)\n\n            # field queries\n            res = cr.types(ids = \"journal-article\", works = True, query_title = 'gender', rows = 100)\n            [ x.get('title') for x in res['message']['items'] ]\n        '''\n        return request(self.mailto, self.base_url, \"/types/\", ids,\n            query, filter, offset, limit, sample, sort,\n            order, facet, select, works, cursor, cursor_max, **kwargs)", "response": "Search Crossref types in the specified list of type identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef licenses(self, query = None, offset = None,\n              limit = None, sample = None, sort = None,\n              order = None, facet = None, **kwargs):\n        '''\n        Search Crossref licenses\n\n        :param query: [String] A query string\n        :param offset: [Fixnum] Number of record to start at, from 1 to 10000\n        :param limit: [Fixnum] Number of results to return. Not relevant when searching with specific dois. Default: 20. Max: 1000\n        :param sort: [String] Field to sort on. Note: If the API call includes a query, then the sort\n            order will be by the relevance score. If no query is included, then the sort order\n            will be by DOI update date. See sorting_ for possible values.\n        :param order: [String] Sort order, one of 'asc' or 'desc'\n        :param facet: [Boolean/String] Set to `true` to include facet results (default: false).\n            Optionally, pass a query string, e.g., `facet=type-name:*` or `facet=license=*`\n            See Facets_ for options.\n        :param kwargs: additional named arguments passed on to `requests.get`, e.g., field\n            queries (see examples and FieldQueries_)\n\n        :return: A dict\n\n        Usage::\n\n            from habanero import Crossref\n            cr = Crossref()\n            cr.licenses()\n            cr.licenses(query = \"creative\")\n        '''\n        check_kwargs([\"ids\", \"filter\", \"works\"], kwargs)\n        res = request(self.mailto, self.base_url, \"/licenses/\", None,\n            query, None, offset, limit, None, sort,\n            order, facet, None, None, None, None, **kwargs)\n        return res", "response": "Search Crossref licenses for a specific set of dois."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef registration_agency(self, ids, **kwargs):\n        '''\n        Determine registration agency for DOIs\n\n        :param ids: [Array] DOIs (digital object identifier) or other identifiers\n        :param kwargs: additional named arguments passed on to `requests.get`, e.g., field\n            queries (see examples)\n\n        :return: list of DOI minting agencies\n\n        Usage::\n\n            from habanero import Crossref\n            cr = Crossref()\n            cr.registration_agency('10.1371/journal.pone.0033693')\n            cr.registration_agency(ids = ['10.1007/12080.1874-1746','10.1007/10452.1573-5125', '10.1111/(issn)1442-9993'])\n        '''\n        check_kwargs([\"query\", \"filter\", \"offset\", \"limit\", \"sample\", \"sort\",\n            \"order\", \"facet\", \"works\"], kwargs)\n        res = request(self.mailto, self.base_url, \"/works/\", ids,\n            None, None, None, None, None, None,\n            None, None, None, None, None, None, True, **kwargs)\n        if res.__class__ != list:\n            k = []\n            k.append(res)\n        else:\n            k = res\n        return [ z['message']['agency']['label'] for z in k ]", "response": "Determine registration agency for a list of DOIs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef random_dois(self, sample = 10, **kwargs):\n        '''\n        Get a random set of DOIs\n\n        :param sample: [Fixnum] Number of random DOIs to return. Default: 10. Max: 100\n        :param kwargs: additional named arguments passed on to `requests.get`, e.g., field\n            queries (see examples)\n\n        :return: [Array] of DOIs\n\n        Usage::\n\n            from habanero import Crossref\n            cr = Crossref()\n            cr.random_dois(1)\n            cr.random_dois(10)\n            cr.random_dois(50)\n            cr.random_dois(100)\n        '''\n        res = request(self.mailto, self.base_url, \"/works/\", None,\n            None, None, None, None, sample, None,\n            None, None, None, True, None, None, None, **kwargs)\n        return [ z['DOI'] for z in res['message']['items'] ]", "response": "Get a random set of DOIs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget list of CSL styles from github. com. citation - style - language. styles", "response": "def csl_styles(**kwargs):\n  '''\n  Get list of styles from https://github.com/citation-style-language/styles\n\n  :param kwargs: any additional arguments will be passed on to `requests.get`\n\n  :return: list, of CSL styles\n\n  Usage::\n\n      from habanero import cn\n      cn.csl_styles()\n  '''\n  base = \"https://api.github.com/repos/citation-style-language/styles\"\n  tt = requests.get(base + '/commits?per_page=1', **kwargs)\n  tt.raise_for_status()\n  check_json(tt)\n  commres = tt.json()\n  sha = commres[0]['sha']\n  sty = requests.get(base + \"/git/trees/\" + sha, **kwargs)\n  sty.raise_for_status()\n  check_json(sty)\n  res = sty.json()\n  files = [ z['path'] for z in res['tree'] ]\n  matches = [ re.search(\".csl\", g) for g in files ]\n  csls = [ x.string for x in filter(None, matches) ]\n  return [ re.sub(\".csl\", \"\", x) for x in csls ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the content negotiation of the given list of DOIs in various formats.", "response": "def content_negotiation(ids = None, format = \"bibtex\", style = 'apa',\n    locale = \"en-US\", url = None, **kwargs):\n    '''\n    Get citations in various formats from CrossRef\n\n    :param ids: [str] Search by a single DOI or many DOIs, each a string. If many\n        passed in, do so in a list\n    :param format: [str] Name of the format. One of \"rdf-xml\", \"turtle\", \"citeproc-json\",\n        \"citeproc-json-ish\", \"text\", \"ris\", \"bibtex\" (Default), \"crossref-xml\",\n        \"datacite-xml\",\"bibentry\", or \"crossref-tdm\"\n    :param style: [str] A CSL style (for text format only). See :func:`~habanero.cn.csl_styles`\n        for options. Default: \"apa\". If there's a style that CrossRef doesn't support\n        you'll get a `(500) Internal Server Error`\n    :param locale: [str] Language locale. See `locale.locale_alias`\n    :param url: [str] Base URL for the content negotiation request. Default: `https://doi.org`\n    :param kwargs: any additional arguments will be passed on to `requests.get`\n\n    :return: string, which can be parsed to various formats depending on what\n        format you request (e.g., JSON vs. XML vs. bibtex)\n\n    Usage::\n\n        from habanero import cn\n        cn.content_negotiation(ids = '10.1126/science.169.3946.635')\n\n        # get citeproc-json\n        cn.content_negotiation(ids = '10.1126/science.169.3946.635', format = \"citeproc-json\")\n\n        # some other formats\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"rdf-xml\")\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"crossref-xml\")\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"text\")\n\n        # return an R bibentry type\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"bibentry\")\n        cn.content_negotiation(ids = \"10.6084/m9.figshare.97218\", format = \"bibentry\")\n\n        # return an apa style citation\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"text\", style = \"apa\")\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"text\", style = \"harvard3\")\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"text\", style = \"elsevier-harvard\")\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"text\", style = \"ecoscience\")\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"text\", style = \"heredity\")\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", format = \"text\", style = \"oikos\")\n\n        # Using DataCite DOIs\n        ## some formats don't work\n        # cn.content_negotiation(ids = \"10.5284/1011335\", format = \"text\")\n        # cn.content_negotiation(ids = \"10.5284/1011335\", format = \"crossref-xml\")\n        # cn.content_negotiation(ids = \"10.5284/1011335\", format = \"crossref-tdm\")\n\n        ## But most do work\n        cn.content_negotiation(ids = \"10.5284/1011335\", format = \"datacite-xml\")\n        cn.content_negotiation(ids = \"10.5284/1011335\", format = \"rdf-xml\")\n        cn.content_negotiation(ids = \"10.5284/1011335\", format = \"turtle\")\n        cn.content_negotiation(ids = \"10.5284/1011335\", format = \"citeproc-json\")\n        cn.content_negotiation(ids = \"10.5284/1011335\", format = \"ris\")\n        cn.content_negotiation(ids = \"10.5284/1011335\", format = \"bibtex\")\n        cn.content_negotiation(ids = \"10.5284/1011335\", format = \"bibentry\")\n        cn.content_negotiation(ids = \"10.5284/1011335\", format = \"bibtex\")\n\n        # many DOIs\n        dois = ['10.5167/UZH-30455','10.5167/UZH-49216','10.5167/UZH-503', '10.5167/UZH-38402','10.5167/UZH-41217']\n        x = cn.content_negotiation(ids = dois)\n\n        # Use a different base url\n        url = \"http://dx.doi.org\"\n        cn.content_negotiation(ids = \"10.1126/science.169.3946.635\", url = url)\n        cn.content_negotiation(ids = \"10.5284/1011335\", url = url)\n    '''\n    if url is None:\n        url = cn_base_url\n    return CNRequest(url, ids, format, style, locale, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef citation_count(doi, url = \"http://www.crossref.org/openurl/\",\n    key = \"cboettig@ropensci.org\", **kwargs):\n    '''\n    Get a citation count with a DOI\n\n    :param doi: [String] DOI, digital object identifier\n    :param url: [String] the API url for the function (should be left to default)\n    :param keyc: [String] your API key\n\n    See http://labs.crossref.org/openurl/ for more info on this Crossref API service.\n\n    Usage::\n\n        from habanero import counts\n        counts.citation_count(doi = \"10.1371/journal.pone.0042793\")\n        counts.citation_count(doi = \"10.1016/j.fbr.2012.01.001\")\n        # DOI not found\n        ## FIXME\n        counts.citation_count(doi = \"10.1016/j.fbr.2012\")\n    '''\n    args = {\"id\": \"doi:\" + doi, \"pid\": key, \"noredirect\": True}\n    args = dict((k, v) for k, v in args.items() if v)\n    res = requests.get(url, params = args, headers = make_ua(), **kwargs)\n    xmldoc = minidom.parseString(res.content)\n    val = xmldoc.getElementsByTagName('query')[0].attributes['fl_count'].value\n    return int(str(val))", "response": "Get a citation count with a DOI"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef findHierarchy(self, max_subs=10):\n        hierarchy = []\n        defaults = TOC.default_hierarchy + tuple(\n            '%ssection' % ('sub'*i) for i in range(2, max_subs))\n        for level in defaults:\n            if getattr(self.source, level, False):\n                hierarchy.append(level)\n        return tuple(hierarchy)", "response": "Find hierarchy for the LaTeX source."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getHeadingLevel(ts, hierarchy=default_hierarchy):\n        try:\n            return hierarchy.index(ts.name)+1\n        except ValueError:\n            if ts.name.endswith('section'):\n                i, name = 0, ts.name\n                while name.startswith('sub'):\n                    name, i = name[3:], i+1\n                if name == 'section':\n                    return i+2\n            return float('inf')\n        except (AttributeError, TypeError):\n            return float('inf')", "response": "Extract the heading level for a particular Tex element given a specified hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse tex for highest tag in hierarchy", "response": "def parseTopDepth(self, descendants=()):\n        \"\"\"Parse tex for highest tag in hierarchy\n\n        >>> TOC.fromLatex('\\\\section{Hah}\\\\subsection{No}').parseTopDepth()\n        1\n        >>> s = '\\\\subsubsubsection{Yo}\\\\subsubsection{Hah}'\n        >>> TOC.fromLatex(s).parseTopDepth()\n        1\n        >>> h = ('section', 'subsubsection', 'subsubsubsection')\n        >>> TOC.fromLatex(s, hierarchy=h).parseTopDepth()\n        2\n        \"\"\"\n        descendants = list(descendants) or \\\n            list(getattr(self.source, 'descendants', descendants))\n        if not descendants:\n            return -1\n        return min(TOC.getHeadingLevel(e, self.hierarchy) for e in descendants)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parseBranches(self, descendants):\n        i, branches = self.parseTopDepth(descendants), []\n        for descendant in descendants:\n            if self.getHeadingLevel(descendant, self.hierarchy) == i:\n                branches.append({'source': descendant})\n            if self.getHeadingLevel(descendant, self.hierarchy) > i \\\n                and branches:\n                branches[-1].setdefault('descendants', []).append(descendant)\n        return [TOC(str(descendant), depth=i, hierarchy=self.hierarchy,\n            **branch) for branch in branches]", "response": "Parse top level of latex\n        and return a list of filtered TreeOfContents objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates abstraction using path to file xid", "response": "def fromFile(path_or_buffer):\n        \"\"\"Creates abstraction using path to file\n\n        :param str path_or_buffer: path to tex file or buffer\n        :return: TreeOfContents object\n        \"\"\"\n        return TOC.fromLatex(open(path_or_buffer).read() \n                             if isinstance(path_or_buffer, str)\n                             else path_or_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromLatex(tex, *args, **kwargs):\n        source = TexSoup(tex)\n        return TOC('[document]', source=source,\n            descendants=list(source.descendants), *args, **kwargs)", "response": "Creates a TreeOfContents object from a Latex string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck and prepare options dict.", "response": "def process_options(opts):\n    \"\"\"Check and prepare options dict.\"\"\"\n    # Convert match and exclude args into pattern lists\n    match = opts.get(\"match\")\n    if match and type(match) is str:\n        opts[\"match\"] = [pat.strip() for pat in match.split(\",\")]\n    elif match:\n        assert type(match) is list\n    else:\n        opts[\"match\"] = []\n\n    exclude = opts.get(\"exclude\")\n    if exclude and type(exclude) is str:\n        opts[\"exclude\"] = [pat.strip() for pat in exclude.split(\",\")]\n    elif exclude:\n        assert type(exclude) is list\n    else:\n        # opts[\"exclude\"] = DEFAULT_OMIT\n        opts[\"exclude\"] = []"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if path matches match and exclude options.", "response": "def match_path(entry, opts):\n    \"\"\"Return True if `path` matches `match` and `exclude` options.\"\"\"\n    if entry.name in ALWAYS_OMIT:\n        return False\n    # TODO: currently we use fnmatch syntax and match against names.\n    # We also might allow glob syntax and match against the whole relative path instead\n    # path = entry.get_rel_path()\n    path = entry.name\n    ok = True\n    match = opts.get(\"match\")\n    exclude = opts.get(\"exclude\")\n    if entry.is_file() and match:\n        assert type(match) is list\n        ok = False\n        for pat in match:\n            if fnmatch.fnmatch(path, pat):\n                ok = True\n                break\n    if ok and exclude:\n        assert type(exclude) is list\n        for pat in exclude:\n            if fnmatch.fnmatch(path, pat):\n                ok = False\n                break\n    # write(\"match\", ok, entry)\n    return ok"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _compare_file(self, local, remote):\n        assert isinstance(local, FileEntry) and isinstance(remote, FileEntry)\n\n        if not local or not remote:\n            write(\"    Files cannot be compared ({} != {}).\".format(local, remote))\n            return False\n        elif local.size != remote.size:\n            write(\n                \"    Files are different (size {:,d} != {:,d}).\".format(\n                    local.size, remote.size\n                )\n            )\n            return False\n\n        with local.target.open_readable(\n            local.name\n        ) as fp_src, remote.target.open_readable(remote.name) as fp_dest:\n            res, ofs = byte_compare(fp_src, fp_dest)\n\n        if not res:\n            write(\"    Files are different at offset {:,d}.\".format(ofs))\n        else:\n            write(\"    Files are equal.\")\n        return res", "response": "Byte compare two file entries."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting progress info and move cursor to beginning of line.", "response": "def _tick(self):\n        \"\"\"Write progress info and move cursor to beginning of line.\"\"\"\n        if (self.verbose >= 3 and not IS_REDIRECTED) or self.options.get(\"progress\"):\n            stats = self.get_stats()\n            prefix = DRY_RUN_PREFIX if self.dry_run else \"\"\n            sys.stdout.write(\n                \"{}Touched {}/{} entries in {} directories...\\r\".format(\n                    prefix,\n                    stats[\"entries_touched\"],\n                    stats[\"entries_seen\"],\n                    stats[\"local_dirs\"],\n                )\n            )\n        sys.stdout.flush()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntraverse the local folder structure and remote peers and create a new entry pair.", "response": "def _sync_dir(self):\n        \"\"\"Traverse the local folder structure and remote peers.\n\n        This is the core algorithm that generates calls to self.sync_XXX()\n        handler methods.\n        _sync_dir() is called by self.run().\n        \"\"\"\n        local_entries = self.local.get_dir()\n        # Convert into a dict {name: FileEntry, ...}\n        local_entry_map = dict(map(lambda e: (e.name, e), local_entries))\n\n        remote_entries = self.remote.get_dir()\n        # Convert into a dict {name: FileEntry, ...}\n        remote_entry_map = dict(map(lambda e: (e.name, e), remote_entries))\n\n        entry_pair_list = []\n\n        # 1. Loop over all local files and classify the relationship to the\n        #    peer entries.\n        for local_entry in local_entries:\n            if isinstance(local_entry, DirectoryEntry):\n                self._inc_stat(\"local_dirs\")\n            else:\n                self._inc_stat(\"local_files\")\n\n            if not self._before_sync(local_entry):\n                # TODO: currently, if a file is skipped, it will not be\n                # considered for deletion on the peer target\n                continue\n            # TODO: case insensitive?\n            # We should use os.path.normcase() to convert to lowercase on windows\n            # (i.e. if the FTP server is based on Windows)\n            remote_entry = remote_entry_map.get(local_entry.name)\n\n            entry_pair = EntryPair(local_entry, remote_entry)\n            entry_pair_list.append(entry_pair)\n\n            # TODO: renaming could be triggered, if we find an existing\n            # entry.unique with a different entry.name\n\n        # 2. Collect all remote entries that do NOT exist on the local target.\n        for remote_entry in remote_entries:\n            if isinstance(remote_entry, DirectoryEntry):\n                self._inc_stat(\"remote_dirs\")\n            else:\n                self._inc_stat(\"remote_files\")\n\n            if not self._before_sync(remote_entry):\n                continue\n\n            if remote_entry.name not in local_entry_map:\n                entry_pair = EntryPair(None, remote_entry)\n                entry_pair_list.append(entry_pair)\n                # print(\"NOT IN LOCAL\")\n                # print(remote_entry.name)\n                # print(self.remote.get_id())\n                # print(local_entry_map.keys())\n                # print(self.local.cur_dir_meta.peer_sync.get(self.remote.get_id()))\n\n        # 3. Classify all entries and pairs.\n        #    We pass the additional meta data here\n        peer_dir_meta = self.local.cur_dir_meta.peer_sync.get(self.remote.get_id())\n\n        for pair in entry_pair_list:\n            pair.classify(peer_dir_meta)\n\n        # 4. Perform (or schedule) resulting file operations\n        for pair in entry_pair_list:\n\n            # print(pair)\n\n            # Let synchronizer modify the default operation (e.g. apply `--force` option)\n            hook_result = self.re_classify_pair(pair)\n\n            # Let synchronizer implement special handling of unmatched entries\n            # (e.g. `--delete_unmatched`)\n            if not self._match(pair.any_entry):\n                self.on_mismatch(pair)\n                # ... do not call operation handler...\n            elif hook_result is not False:\n                handler = getattr(self, \"on_\" + pair.operation, None)\n                # print(handler)\n                if handler:\n                    try:\n                        res = handler(pair)\n                    except Exception as e:\n                        if self.on_error(e, pair) is not True:\n                            raise\n                else:\n                    # write(\"NO HANDLER\")\n                    raise NotImplementedError(\"No handler for {}\".format(pair))\n\n            if pair.is_conflict():\n                self._inc_stat(\"conflict_files\")\n\n        # 5. Let the target provider write its meta data for the files in the\n        #    current directory.\n        self.local.flush_meta()\n        self.remote.flush_meta()\n\n        # 6. Finally visit all local sub-directories recursively that also\n        #    exist on the remote target.\n        for local_dir in local_entries:\n            # write(\"local_dir(%s, %s)\" % (local_dir, local_dir))\n            if not local_dir.is_dir():\n                continue\n            elif not self._before_sync(local_dir):\n                continue\n\n            remote_dir = remote_entry_map.get(local_dir.name)\n            if remote_dir:\n                # write(\"sync_equal_dir(%s, %s)\" % (local_dir, remote_dir))\n                # self._log_call(\"sync_equal_dir(%s, %s)\" % (local_dir, remote_dir))\n                # res = self.sync_equal_dir(local_dir, remote_dir)\n                # res = self.on_equal(local_dir, remote_dir)\n                if res is not False:\n                    self.local.cwd(local_dir.name)\n                    self.remote.cwd(local_dir.name)\n                    self._sync_dir()\n                    self.local.cwd(\"..\")\n                    self.remote.cwd(\"..\")\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling for pairs that don t match and exclude filters.", "response": "def on_error(self, e, pair):\n        \"\"\"Called for pairs that don't match `match` and `exclude` filters.\"\"\"\n        RED = ansi_code(\"Fore.LIGHTRED_EX\")\n        R = ansi_code(\"Style.RESET_ALL\")\n        # any_entry = pair.any_entry\n        write((RED + \"ERROR: {}\\n    {}\" + R).format(e, pair))\n        # Return True to ignore this error (instead of raising and terminating the app)\n        if \"[Errno 92] Illegal byte sequence\" in \"{}\".format(e) and compat.PY2:\n            write(RED + \"This _may_ be solved by using Python 3.\" + R)\n            # return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_copy_local(self, pair):\n        status = pair.remote_classification\n        self._log_action(\"copy\", status, \">\", pair.local)", "response": "Called when the local resource should be copied to remote."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when the remote resource should be copied to local.", "response": "def on_copy_remote(self, pair):\n        \"\"\"Called when the remote resource should be copied to local.\"\"\"\n        status = pair.local_classification\n        self._log_action(\"copy\", status, \"<\", pair.remote)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_need_compare(self, pair):\n        # print(\"on_need_compare\", pair)\n        # If no metadata is available, we could only classify file entries as\n        # 'existing'.\n        # Now we use peer information to improve this classification.\n        c_pair = (pair.local_classification, pair.remote_classification)\n\n        org_pair = c_pair\n        org_operation = pair.operation\n\n        # print(\"need_compare\", pair)\n\n        if pair.is_dir:\n            # For directores, we cannot compare existing peer entries.\n            # Instead, we simply log (and traverse the children later).\n            pair.local_classification = pair.remote_classification = \"existing\"\n            pair.operation = \"equal\"\n            self._log_action(\"\", \"visit\", \"?\", pair.local, min_level=4)\n            # self._log_action(\"\", \"equal\", \"=\", pair.local, min_level=4)\n            return\n\n        elif c_pair == (\"existing\", \"existing\"):\n            # Naive classification derived from file time and size\n            time_cmp = eps_compare(\n                pair.local.mtime, pair.remote.mtime, FileEntry.EPS_TIME\n            )\n            if time_cmp < 0:\n                c_pair = (\"unmodified\", \"modified\")  # remote is newer\n            elif time_cmp > 0:\n                c_pair = (\"modified\", \"unmodified\")  # local is newer\n            elif pair.local.size == pair.remote.size:\n                c_pair = (\"unmodified\", \"unmodified\")  # equal\n            else:\n                c_pair = (\"modified\", \"modified\")  # conflict!\n\n        elif c_pair == (\"new\", \"new\"):\n            # Naive classification derived from file time and size\n            time_cmp = eps_compare(\n                pair.local.mtime, pair.remote.mtime, FileEntry.EPS_TIME\n            )\n            if time_cmp == 0 and pair.local.size == pair.remote.size:\n                c_pair = (\"unmodified\", \"unmodified\")  # equal\n            else:\n                c_pair = (\"modified\", \"modified\")  # conflict!\n\n        # elif c_pair == (\"unmodified\", \"unmodified\"):\n\n        pair.local_classification = c_pair[0]\n        pair.remote_classification = c_pair[1]\n\n        pair.operation = operation_map.get(c_pair)\n        # print(\"on_need_compare {} => {}\".format(org_pair, pair))\n        if not pair.operation:\n            raise RuntimeError(\n                \"Undefined operation for pair classification {}\".format(c_pair)\n            )\n        elif pair.operation == org_operation:\n            raise RuntimeError(\"Could not re-classify  {}\".format(org_pair))\n\n        handler = getattr(self, \"on_\" + pair.operation, None)\n        res = handler(pair)\n        #         self._log_action(\"\", \"different\", \"?\", pair.local, min_level=2)\n        return res", "response": "Re - classify pair based on file attributes and options."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_conflict(self, pair):\n        # self._log_action(\"skip\", \"conflict\", \"!\", pair.local, min_level=2)\n        # print(\"on_conflict\", pair)\n        any_entry = pair.any_entry\n        if not self._test_match_or_print(any_entry):\n            return\n\n        resolve = self._interactive_resolve(pair)\n\n        if resolve == \"skip\":\n            self._log_action(\"skip\", \"conflict\", \"*?*\", any_entry)\n            self._inc_stat(\"conflict_files_skipped\")\n            return\n\n        if pair.local and pair.remote:\n            assert pair.local.is_file()\n            is_newer = pair.local > pair.remote\n            if (\n                resolve == \"local\"\n                or (is_newer and resolve == \"new\")\n                or (not is_newer and resolve == \"old\")\n            ):\n                self._log_action(\"copy\", \"conflict\", \"*>*\", pair.local)\n                self._copy_file(self.local, self.remote, pair.local)\n            elif (\n                resolve == \"remote\"\n                or (is_newer and resolve == \"old\")\n                or (not is_newer and resolve == \"new\")\n            ):\n                self._log_action(\"copy\", \"conflict\", \"*<*\", pair.local)\n                self._copy_file(self.remote, self.local, pair.remote)\n            else:\n                raise NotImplementedError\n        elif pair.local:\n            assert pair.local.is_file()\n            if resolve == \"local\":\n                self._log_action(\"restore\", \"conflict\", \"*>x\", pair.local)\n                self._copy_file(self.local, self.remote, pair.local)\n            elif resolve == \"remote\":\n                self._log_action(\"delete\", \"conflict\", \"*<x\", pair.local)\n                self._remove_file(pair.local)\n            else:\n                raise NotImplementedError\n        else:\n            assert pair.remote.is_file()\n            if resolve == \"local\":\n                self._log_action(\"delete\", \"conflict\", \"x>*\", pair.remote)\n                self._remove_file(pair.remote)\n            elif resolve == \"remote\":\n                self._log_action(\"restore\", \"conflict\", \"x<*\", pair.remote)\n                self._copy_file(self.remote, self.local, pair.remote)\n            else:\n                raise NotImplementedError\n        return", "response": "Return False to prevent visiting of children."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_mismatch(self, pair):\n        remote_entry = pair.remote\n        if self.options.get(\"delete_unmatched\") and remote_entry:\n            self._log_action(\"delete\", \"unmatched\", \">\", remote_entry)\n            if remote_entry.is_dir():\n                self._remove_dir(remote_entry)\n            else:\n                self._remove_file(remote_entry)\n        else:\n            self._log_action(\"skip\", \"unmatched\", \"-\", pair.any_entry, min_level=4)", "response": "Called for pairs that don t match and exclude filters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _interactive_resolve(self, pair):\n        if self.resolve_all:\n            if self.verbose >= 5:\n                self._print_pair_diff(pair)\n            return self.resolve_all\n\n        resolve = self.options.get(\"resolve\", \"skip\")\n        assert resolve in (\"remote\", \"ask\", \"skip\")\n\n        if resolve == \"ask\" or self.verbose >= 5:\n            self._print_pair_diff(pair)\n\n        if resolve in (\"remote\", \"skip\"):\n            # self.resolve_all = resolve\n            return resolve\n\n        # RED = ansi_code(\"Fore.LIGHTRED_EX\")\n        M = ansi_code(\"Style.BRIGHT\") + ansi_code(\"Style.UNDERLINE\")\n        R = ansi_code(\"Style.RESET_ALL\")\n\n        # self._print_pair_diff(pair)\n\n        self._inc_stat(\"interactive_ask\")\n\n        while True:\n            prompt = (\n                \"Use \"\n                + M\n                + \"R\"\n                + R\n                + \"emote, \"\n                + M\n                + \"S\"\n                + R\n                + \"kip, \"\n                + M\n                + \"B\"\n                + R\n                + \"inary compare, \"\n                + M\n                + \"H\"\n                + R\n                + \"elp? \"\n            )\n\n            r = compat.console_input(prompt).strip()\n            if r in (\"h\", \"H\", \"?\"):\n                print(\"The following keys are supported:\")\n                print(\"  'b': Binary compare\")\n                print(\"  'r': Download remote file\")\n                print(\"  's': Skip this file (leave both targets unchanged)\")\n                print(\n                    \"Hold Shift (upper case letters) to apply choice for all \"\n                    \"remaining conflicts.\"\n                )\n                print(\"Hit Ctrl+C to abort.\")\n                continue\n            elif r in (\"B\", \"b\"):\n                self._compare_file(pair.local, pair.remote)\n                continue\n            elif r in (\"R\", \"S\"):\n                r = self._resolve_shortcuts[r.lower()]\n                self.resolve_all = r\n                break\n            elif r in (\"r\", \"s\"):\n                r = self._resolve_shortcuts[r]\n                break\n\n        return r", "response": "Ask or skip the user to choose local remote or skip."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall for pairs that don t match and exclude filters.", "response": "def on_mismatch(self, pair):\n        \"\"\"Called for pairs that don't match `match` and `exclude` filters.\n\n        If --delete-unmatched is on, remove the remote resource.\n        \"\"\"\n        local_entry = pair.local\n        if self.options.get(\"delete_unmatched\") and local_entry:\n            self._log_action(\"delete\", \"unmatched\", \"<\", local_entry)\n            if local_entry.is_dir():\n                self._remove_dir(local_entry)\n            else:\n                self._remove_file(local_entry)\n        else:\n            self._log_action(\"skip\", \"unmatched\", \"-\", pair.any_entry, min_level=4)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_run_command(parser, args):\n    MAX_LEVELS = 15\n\n    # --- Look for `pyftpsync.yaml` in current folder and parents ---\n\n    cur_level = 0\n    cur_folder = os.getcwd()\n    config_path = None\n    while cur_level < MAX_LEVELS:\n        path = os.path.join(cur_folder, CONFIG_FILE_NAME)\n        # print(\"Searching for {}...\".format(path))\n        if os.path.isfile(path):\n            config_path = path\n            break\n        parent = os.path.dirname(cur_folder)\n        if parent == cur_folder:\n            break\n        cur_folder = parent\n        cur_level += 1\n\n    if not config_path:\n        parser.error(\n            \"Could not locate `.pyftpsync.yaml` in {} or {} parent folders.\".format(\n                os.getcwd(), cur_level\n            )\n        )\n\n    # --- Parse `pyftpsync.yaml` and set `args` attributes ---\n\n    try:\n        with open(config_path, \"rb\") as f:\n            config = yaml.safe_load(f)\n    except Exception as e:\n        parser.error(\"Error parsing {}: {}\".format(config_path, e))\n        # write_error(\"Error parsing {}: {}\".format(config_path, e))\n        # raise\n\n    # print(config)\n    if \"tasks\" not in config:\n        parser.error(\"Missing option `tasks` in {}\".format(config_path))\n\n    common_config = config.get(\"common_config\", {})\n\n    default_task = config.get(\"default_task\", \"default\")\n    task_name = args.task or default_task\n    if task_name not in config[\"tasks\"]:\n        parser.error(\"Missing option `tasks.{}` in {}\".format(task_name, config_path))\n    task = config[\"tasks\"][task_name]\n\n    write(\"Running task '{}' from {}\".format(task_name, config_path))\n\n    common_config.update(task)\n    task = common_config\n    # write(\"task\", task)\n\n    # --- Check task syntax ---\n\n    task_args = set(task.keys())\n\n    missing_args = MANDATORY_TASK_ARGS.difference(task_args)\n    if missing_args:\n        parser.error(\n            \"Missing mandatory options: tasks.{}.{}\".format(\n                task_name, \", \".join(missing_args)\n            )\n        )\n\n    allowed_args = KNOWN_TASK_ARGS.union(MANDATORY_TASK_ARGS)\n    invalid_args = task_args.difference(allowed_args)\n    if invalid_args:\n        parser.error(\n            \"Invalid options: tasks.{}.{}\".format(task_name, \", \".join(invalid_args))\n        )\n\n    # write(\"args\", args)\n\n    for name in allowed_args:\n        val = task.get(name, None)  # default)\n\n        if val is None:\n            continue  # option not specified in yaml\n\n        # Override yaml entry by command line\n        cmd_val = getattr(args, name, None)\n\n        # write(\"check --{}: {} => {}\".format(name, val, cmd_val))\n\n        if cmd_val != val:\n            override = False\n            if name in OVERRIDABLE_BOOL_ARGS and cmd_val:\n                override = True\n            elif name in {\"here\", \"root\"} and (args.here or args.root):\n                override = True\n            elif name == \"verbose\" and cmd_val != 3:\n                override = True\n\n            if override:\n                write(\n                    \"Yaml entry overriden by --{}: {} => {}\".format(name, val, cmd_val)\n                )\n                continue\n\n        setattr(args, name, val)\n\n    # --- Figure out local target path ---\n\n    cur_folder = os.getcwd()\n    root_folder = os.path.dirname(config_path)\n    path_ofs = os.path.relpath(os.getcwd(), root_folder)\n\n    if cur_level == 0 or args.root:\n        path_ofs = \"\"\n        args.local = root_folder\n    elif args.here:\n        write(\"Using sub-branch {sub} of {root}\".format(root=root_folder, sub=path_ofs))\n        args.local = cur_folder\n        args.remote = os.path.join(args.remote, path_ofs)\n    else:\n        parser.error(\n            \"`.pyftpsync.yaml` configuration was found in a parent directory. \"\n            \"Please pass an additional argument to clarify:\\n\"\n            \"  --root: synchronize whole project ({root})\\n\"\n            \"  --here: synchronize sub branch ({root}/{sub})\".format(\n                root=root_folder, sub=path_ofs\n            )\n        )", "response": "Implement run sub - command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefining target for common output.", "response": "def set_pyftpsync_logger(logger=True):\n    \"\"\"Define target for common output.\n\n    Args:\n        logger (bool | None | logging.Logger):\n            Pass None to use `print()` to stdout instead of logging.\n            Pass True to create a simple standard logger.\n    \"\"\"\n    global _logger\n    prev_logger = _logger\n    if logger is True:\n        logging.basicConfig(level=logging.INFO)\n        _logger = logging.getLogger(\"pyftpsync\")\n        _logger.setLevel(logging.DEBUG)\n    else:\n        _logger = logger\n    return prev_logger"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(*args, **kwargs):\n    debug = kwargs.pop(\"debug\", None)\n    warning = kwargs.pop(\"warning\", None)\n    if _logger:\n        kwargs.pop(\"end\", None)\n        kwargs.pop(\"file\", None)\n        if debug:\n            _logger.debug(*args, **kwargs)\n        elif warning:\n            _logger.warning(*args, **kwargs)\n        else:\n            _logger.info(*args, **kwargs)\n    else:\n        print(*args, **kwargs)", "response": "Redirectable wrapper for print statements."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_error(*args, **kwargs):\n    if _logger:\n        kwargs.pop(\"end\", None)\n        kwargs.pop(\"file\", None)\n        _logger.error(*args, **kwargs)\n    else:\n        print(*args, file=sys.stderr, **kwargs)", "response": "Redirectable wrapper for print sys. stderr statements."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an argparse namespace object to a dictionary.", "response": "def namespace_to_dict(o):\n    \"\"\"Convert an argparse namespace object to a dictionary.\"\"\"\n    d = {}\n    for k, v in o.__dict__.items():\n        if not callable(v):\n            d[k] = v\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef eps_compare(f1, f2, eps):\n    res = f1 - f2\n    if abs(res) <= eps:  # '<=',so eps == 0 works as expected\n        return 0\n    elif res < 0:\n        return -1\n    return 1", "response": "Return true if |f1 - f2| < eps."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a configuration setting from environment var or. pyftpsyncrc", "response": "def get_option(env_name, section, opt_name, default=None):\n    \"\"\"Return a configuration setting from environment var or .pyftpsyncrc\"\"\"\n    val = os.environ.get(env_name)\n    if val is None:\n        try:\n            val = _pyftpsyncrc_parser.get(section, opt_name)\n        except (compat.configparser.NoSectionError, compat.configparser.NoOptionError):\n            pass\n    if val is None:\n        val = default\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_cli_verbose(default=3):\n    args = sys.argv[1:]\n    verbose = default + args.count(\"--verbose\") - args.count(\"--quiet\")\n\n    for arg in args:\n        if arg.startswith(\"-\") and not arg.startswith(\"--\"):\n            verbose += arg[1:].count(\"v\")\n            verbose -= arg[1:].count(\"q\")\n    return verbose", "response": "Check for presence of verbose or quiet or - v or - q without using argparse."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prompt_for_password(url, user=None, default_user=None):\n    if user is None:\n        default_user = default_user or getpass.getuser()\n        while user is None:\n            user = compat.console_input(\n                \"Enter username for {} [{}]: \".format(url, default_user)\n            )\n            if user.strip() == \"\" and default_user:\n                user = default_user\n    if user:\n        pw = getpass.getpass(\n            \"Enter password for {}@{} (Ctrl+C to abort): \".format(user, url)\n        )\n        if pw or pw == \"\":\n            return (user, pw)\n    return None", "response": "Prompt for a user name and password."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_credentials_for_url(url, opts, force_user=None):\n    creds = None\n    verbose = int(opts.get(\"verbose\"))\n    force_prompt = opts.get(\"prompt\", False)\n    allow_prompt = not opts.get(\"no_prompt\", True)\n    allow_keyring = not opts.get(\"no_keyring\", False) and not force_user\n    allow_netrc = not opts.get(\"no_netrc\", False) and not force_user\n\n    # print(\"get_credentials_for_url\", force_user, allow_prompt)\n    if force_user and not allow_prompt:\n        raise RuntimeError(\n            \"Cannot get credentials for a distinct user ({}) from keyring or .netrc and \"\n            \"prompting is disabled.\".format(force_user)\n        )\n\n    # Lookup our own pyftpsync 1.x credential store. This is deprecated with 2.x\n    home_path = os.path.expanduser(\"~\")\n    file_path = os.path.join(home_path, DEFAULT_CREDENTIAL_STORE)\n    if os.path.isfile(file_path):\n        raise RuntimeError(\n            \"Custom password files are no longer supported. Delete {} and use .netrc instead.\".format(\n                file_path\n            )\n        )\n\n    # Query keyring database\n    if creds is None and keyring and allow_keyring:\n        try:\n            # Note: we pass the url as `username` and username:password as `password`\n            c = keyring.get_password(\"pyftpsync\", url)\n            if c is not None:\n                creds = c.split(\":\", 1)\n                write(\n                    \"Using credentials from keyring('pyftpsync', '{}'): {}:***.\".format(\n                        url, creds[0]\n                    )\n                )\n            else:\n                if verbose >= 4:\n                    write(\n                        \"No credentials found in keyring('pyftpsync', '{}').\".format(\n                            url\n                        )\n                    )\n        #        except keyring.errors.TransientKeyringError:\n        except Exception as e:\n            # e.g. user clicked 'no'\n            write_error(\"Could not get password from keyring {}\".format(e))\n\n    # Query .netrc file\n    #     print(opts)\n    if creds is None and allow_netrc:\n        try:\n            authenticators = None\n            authenticators = netrc.netrc().authenticators(url)\n        except CompatFileNotFoundError:\n            if verbose >= 4:\n                write(\"Could not get password (no .netrc file).\")\n        except Exception as e:\n            write_error(\"Could not read .netrc: {}.\".format(e))\n\n        if authenticators:\n            creds = (authenticators[0], authenticators[2])\n            write(\"Using credentials from .netrc file: {}:***.\".format(creds[0]))\n        else:\n            if verbose >= 4:\n                write(\"Could not find entry for '{}' in .netrc file.\".format(url))\n\n    # Prompt for password if we don't have credentials yet, or --prompt was set.\n    if allow_prompt:\n        if creds is None:\n            creds = prompt_for_password(url)\n        elif force_prompt:\n            # --prompt was set but we can provide a default for the user name\n            creds = prompt_for_password(url, default_user=creds[0])\n\n    return creds", "response": "Get credentials for a given URL in keyring and. netrc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_password(url, username, password):\n    if keyring:\n        if \":\" in username:\n            raise RuntimeError(\n                \"Unable to store credentials if username contains a ':' ({}).\".format(\n                    username\n                )\n            )\n\n        try:\n            # Note: we pass the url as `username` and username:password as `password`\n            if password is None:\n                keyring.delete_password(\"pyftpsync\", url)\n                write(\"Delete credentials from keyring ({})\".format(url))\n            else:\n                keyring.set_password(\n                    \"pyftpsync\", url, \"{}:{}\".format(username, password)\n                )\n                write(\n                    \"Store credentials in keyring ({}, {}:***).\".format(url, username)\n                )\n        #        except keyring.errors.TransientKeyringError:\n        except Exception as e:\n            write(\"Could not delete/set password {}.\".format(e))\n            pass  # e.g. user clicked 'no'\n    else:\n        write(\"Could not store credentials (missing keyring support).\")\n    return", "response": "Store credentials in keyring."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef str_to_bool(val):\n    val = str(val).lower().strip()\n    if val in (\"1\", \"true\", \"on\", \"yes\"):\n        return True\n    elif val in (\"0\", \"false\", \"off\", \"no\"):\n        return False\n    raise ValueError(\n        \"Invalid value '{}'\"\n        \"(expected '1', '0', 'true', 'false', 'on', 'off', 'yes', 'no').\".format(val)\n    )", "response": "Return a boolean for 0 false on on..."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns ANSI color or style codes.", "response": "def ansi_code(name):\n    \"\"\"Return ansi color or style codes or '' if colorama is not available.\"\"\"\n    try:\n        obj = colorama\n        for part in name.split(\".\"):\n            obj = getattr(obj, part)\n        return obj\n    except AttributeError:\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef byte_compare(stream_a, stream_b):\n    bufsize = 16 * 1024\n    equal = True\n    ofs = 0\n    while True:\n        b1 = stream_a.read(bufsize)\n        b2 = stream_b.read(bufsize)\n        if b1 != b2:\n            equal = False\n            if b1 and b2:\n                # we have two different buffers: find first mismatch\n                for a, b in zip(b1, b2):\n                    if a != b:\n                        break\n                    ofs += 1\n            break\n        ofs += len(b1)\n        if not b1:  # both buffers empty\n            break\n    return (equal, ofs)", "response": "Byte compare two files."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts all keys to unicde ( recursively ).", "response": "def decode_dict_keys(d, coding=\"utf-8\"):\n    \"\"\"Convert all keys to unicde (recursively).\"\"\"\n    assert compat.PY2\n    res = {}\n    for k, v in d.items():  #\n        if type(k) is str:\n            k = k.decode(coding)\n        if type(v) is dict:\n            v = decode_dict_keys(v, coding)\n        res[k] = v\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_native_dict_keys(d):\n    res = {}\n    for k, v in d.items():  #\n        k = compat.to_native(k)\n        if type(v) is dict:\n            v = make_native_dict_keys(v)\n        res[k] = v\n    return res", "response": "Convert all keys to native str type ( recursively )."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning options from synchronizer or extra_opts.", "response": "def get_options_dict(self):\n        \"\"\"Return options from synchronizer (possibly overridden by own extra_opts).\"\"\"\n        d = self.synchronizer.options if self.synchronizer else {}\n        d.update(self.extra_opts)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_option(self, key, default=None):\n        if self.synchronizer:\n            return self.extra_opts.get(key, self.synchronizer.options.get(key, default))\n        return self.extra_opts.get(key, default)", "response": "Return option from synchronizer or extra_opts."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nraise exception if writing cur_dir or name is not allowed.", "response": "def check_write(self, name):\n        \"\"\"Raise exception if writing cur_dir/name is not allowed.\"\"\"\n        assert compat.is_native(name)\n        if self.readonly and name not in (\n            DirMetadata.META_FILE_NAME,\n            DirMetadata.LOCK_FILE_NAME,\n        ):\n            raise RuntimeError(\"Target is read-only: {} + {} / \".format(self, name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget mtime / size when this target s current dir was last synchronized with remote.", "response": "def get_sync_info(self, name, key=None):\n        \"\"\"Get mtime/size when this target's current dir was last synchronized with remote.\"\"\"\n        peer_target = self.peer\n        if self.is_local():\n            info = self.cur_dir_meta.dir[\"peer_sync\"].get(peer_target.get_id())\n        else:\n            info = peer_target.cur_dir_meta.dir[\"peer_sync\"].get(self.get_id())\n        if name is not None:\n            info = info.get(name) if info else None\n        if info and key:\n            info = info.get(key)\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over all target entries recursively.", "response": "def walk(self, pred=None, recursive=True):\n        \"\"\"Iterate over all target entries recursively.\n\n        Args:\n            pred (function, optional):\n                Callback(:class:`ftpsync.resources._Resource`) should return `False` to\n                ignore entry. Default: `None`.\n            recursive (bool, optional):\n                Pass `False` to generate top level entries only. Default: `True`.\n        Yields:\n            :class:`ftpsync.resources._Resource`\n        \"\"\"\n        for entry in self.get_dir():\n            if pred and pred(entry) is False:\n                continue\n\n            yield entry\n\n            if recursive:\n                if isinstance(entry, DirectoryEntry):\n                    self.cwd(entry.name)\n                    for e in self.walk(pred):\n                        yield e\n                    self.cwd(\"..\")\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread text string from cur_dir / name using open_readable method.", "response": "def read_text(self, name):\n        \"\"\"Read text string from cur_dir/name using open_readable().\"\"\"\n        with self.open_readable(name) as fp:\n            res = fp.read()  # StringIO or file object\n            # try:\n            #     res = fp.getvalue()  # StringIO returned by FtpTarget\n            # except AttributeError:\n            #     res = fp.read()  # file object returned by FsTarget\n            res = res.decode(\"utf-8\")\n            return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_text(self, name, s):\n        buf = io.BytesIO(compat.to_bytes(s))\n        self.write_file(name, buf)", "response": "Write string data to cur_dir / name using write_file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_sync_info(self, name, mtime, size):\n        if not self.is_local():\n            return self.peer.set_sync_info(name, mtime, size)\n        return self.cur_dir_meta.set_sync_info(name, mtime, size)", "response": "Store mtime and size when this resource was last synchronized with remote."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove the directory with the given name.", "response": "def rmdir(self, dir_name):\n        \"\"\"Remove cur_dir/name.\"\"\"\n        self.check_write(dir_name)\n        path = normpath_url(join_url(self.cur_dir, dir_name))\n        # write(\"REMOVE %r\" % path)\n        shutil.rmtree(path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_file(self, name):\n        self.check_write(name)\n        path = os.path.join(self.cur_dir, name)\n        os.remove(path)", "response": "Remove the file with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset modification time on file.", "response": "def set_mtime(self, name, mtime, size):\n        \"\"\"Set modification time on file.\"\"\"\n        self.check_write(name)\n        os.utime(os.path.join(self.cur_dir, name), (-1, mtime))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a special file to the target root folder.", "response": "def _lock(self, break_existing=False):\r\n        \"\"\"Write a special file to the target root folder.\"\"\"\r\n        # write(\"_lock\")\r\n        data = {\"lock_time\": time.time(), \"lock_holder\": None}\r\n\r\n        try:\r\n            assert self.cur_dir == self.root_dir\r\n            self.write_text(DirMetadata.LOCK_FILE_NAME, json.dumps(data))\r\n            self.lock_data = data\r\n            self.lock_write_time = time.time()\r\n        except Exception as e:\r\n            errmsg = \"{}\".format(e)\r\n            write_error(\"Could not write lock file: {}\".format(errmsg))\r\n            if errmsg.startswith(\"550\") and self.ftp.passiveserver:\r\n                try:\r\n                    self.ftp.makepasv()\r\n                except Exception:\r\n                    write_error(\r\n                        \"The server probably requires FTP Active mode. \"\r\n                        \"Try passing the --ftp-active option.\"\r\n                    )\r\n\r\n            # Set to False, so we don't try to remove later\r\n            self.lock_data = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving the lock file from the target root folder.", "response": "def _unlock(self, closing=False):\r\n        \"\"\"Remove lock file to the target root folder.\r\n\r\n        \"\"\"\r\n        # write(\"_unlock\", closing)\r\n        try:\r\n            if self.cur_dir != self.root_dir:\r\n                if closing:\r\n                    write(\r\n                        \"Changing to ftp root folder to remove lock file: {}\".format(\r\n                            self.root_dir\r\n                        )\r\n                    )\r\n                    self.cwd(self.root_dir)\r\n                else:\r\n                    write_error(\r\n                        \"Could not remove lock file, because CWD != ftp root: {}\".format(\r\n                            self.cur_dir\r\n                        )\r\n                    )\r\n                    return\r\n\r\n            if self.lock_data is False:\r\n                if self.get_option(\"verbose\", 3) >= 4:\r\n                    write(\"Skip remove lock file (was not written).\")\r\n            else:\r\n                # direct delete, without updating metadata or checking for target access:\r\n                try:\r\n                    self.ftp.delete(DirMetadata.LOCK_FILE_NAME)\r\n                    # self.remove_file(DirMetadata.LOCK_FILE_NAME)\r\n                except Exception as e:\r\n                    # I have seen '226 Closing data connection' responses here,\r\n                    # probably when a previous command threw another error.\r\n                    # However here, 2xx response should be Ok(?):\r\n                    # A 226 reply code is sent by the server before closing the\r\n                    # data connection after successfully processing the previous client command\r\n                    if e.args[0][:3] == \"226\":\r\n                        write_error(\"Ignoring 226 response for ftp.delete() lockfile\")\r\n                    else:\r\n                        raise\r\n\r\n            self.lock_data = None\r\n        except Exception as e:\r\n            write_error(\"Could not remove lock file: {}\".format(e))\r\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls by get_dir to probe if the lock file is newer than the last time we got it.", "response": "def _probe_lock_file(self, reported_mtime):\r\n        \"\"\"Called by get_dir\"\"\"\r\n        delta = reported_mtime - self.lock_data[\"lock_time\"]\r\n        # delta2 = reported_mtime - self.lock_write_time\r\n        self.server_time_ofs = delta\r\n        if self.get_option(\"verbose\", 3) >= 4:\r\n            write(\"Server time offset: {:.2f} seconds.\".format(delta))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open_readable(self, name):\r\n        # print(\"FTP open_readable({})\".format(name))\r\n        assert compat.is_native(name)\r\n        out = SpooledTemporaryFile(max_size=self.MAX_SPOOL_MEM, mode=\"w+b\")\r\n        self.ftp.retrbinary(\r\n            \"RETR {}\".format(name), out.write, FtpTarget.DEFAULT_BLOCKSIZE\r\n        )\r\n        out.seek(0)\r\n        return out", "response": "Open a file - like object for reading."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites file - like object fp_src to cur_dir / name.", "response": "def write_file(self, name, fp_src, blocksize=DEFAULT_BLOCKSIZE, callback=None):\r\n        \"\"\"Write file-like `fp_src` to cur_dir/name.\r\n\r\n        Args:\r\n            name (str): file name, located in self.curdir\r\n            fp_src (file-like): must support read() method\r\n            blocksize (int, optional):\r\n            callback (function, optional):\r\n                Called like `func(buf)` for every written chunk\r\n        \"\"\"\r\n        # print(\"FTP write_file({})\".format(name), blocksize)\r\n        assert compat.is_native(name)\r\n        self.check_write(name)\r\n        self.ftp.storbinary(\"STOR {}\".format(name), fp_src, blocksize, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncopying the contents of the named file to fp_dest.", "response": "def copy_to_file(self, name, fp_dest, callback=None):\r\n        \"\"\"Write cur_dir/name to file-like `fp_dest`.\r\n\r\n        Args:\r\n            name (str): file name, located in self.curdir\r\n            fp_dest (file-like): must support write() method\r\n            callback (function, optional):\r\n                Called like `func(buf)` for every written chunk\r\n        \"\"\"\r\n        assert compat.is_native(name)\r\n\r\n        def _write_to_file(data):\r\n            # print(\"_write_to_file() {} bytes.\".format(len(data)))\r\n            fp_dest.write(data)\r\n            if callback:\r\n                callback(data)\r\n\r\n        self.ftp.retrbinary(\r\n            \"RETR {}\".format(name), _write_to_file, FtpTarget.DEFAULT_BLOCKSIZE\r\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_file(self, name):\r\n        assert compat.is_native(name)\r\n        self.check_write(name)\r\n        # self.cur_dir_meta.remove(name)\r\n        self.ftp.delete(name)\r\n        self.remove_sync_info(name)", "response": "Remove the named file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ftp_nlst(self, dir_name):\r\n        assert compat.is_native(dir_name)\r\n        lines = []\r\n\r\n        def _add_line(status, line):\r\n            lines.append(line)\r\n\r\n        cmd = \"NLST \" + dir_name\r\n        self._ftp_retrlines_native(cmd, _add_line, self.encoding)\r\n        # print(cmd, lines)\r\n        return lines", "response": "Variant of self. ftp. nlst that supports encoding - fallback."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if local. mtime == remote. mtime.", "response": "def is_same_time(self):\n        \"\"\"Return True if local.mtime == remote.mtime.\"\"\"\n        return (\n            self.local\n            and self.remote\n            and FileEntry._eps_compare(self.local.mtime, self.remote.mtime) == 0\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef classify(self, peer_dir_meta):\n        assert self.classification is None\n        peer_entry_meta = None\n        if peer_dir_meta:\n            # Metadata is generally available, so we can detect 'new' or 'modified'\n            peer_entry_meta = peer_dir_meta.get(self.name, False)\n\n            if self.is_dir():\n                # Directories are considered 'unmodified' (would require deep traversal\n                # to check otherwise)\n                if peer_entry_meta:\n                    self.classification = \"unmodified\"\n                else:\n                    self.classification = \"new\"\n            elif peer_entry_meta:\n                # File entries can be classified as modified/unmodified\n                self.ps_size = peer_entry_meta.get(\"s\")\n                self.ps_mtime = peer_entry_meta.get(\"m\")\n                self.ps_utime = peer_entry_meta.get(\"u\")\n                if (\n                    self.size == self.ps_size\n                    and FileEntry._eps_compare(self.mtime, self.ps_mtime) == 0\n                ):\n                    self.classification = \"unmodified\"\n                else:\n                    self.classification = \"modified\"\n            else:\n                # A new file entry\n                self.classification = \"new\"\n        else:\n            # No metadata available:\n            if self.is_dir():\n                # Directories are considered 'unmodified' (would require deep traversal\n                # to check otherwise)\n                self.classification = \"unmodified\"\n            else:\n                # That's all we know, but EntryPair.classify() may adjust this\n                self.classification = \"existing\"\n\n        if PRINT_CLASSIFICATIONS:\n            write(\"classify {}\".format(self))\n        assert self.classification in ENTRY_CLASSIFICATIONS\n        return self.classification", "response": "Classify this entry as new unmodified or modified."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef was_modified_since_last_sync(self):\n        info = self.get_sync_info()\n        if not info:\n            return None\n        if self.size != info[\"s\"]:\n            return True\n        if self.mtime > info[\"m\"]:\n            return True\n        return False", "response": "Return True if this resource was modified since last sync."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_mtime(self, filename, mtime, size):\n        ut = time.time()  # UTC time stamp\n        if self.target.server_time_ofs:\n            # We add the estimated time offset, so the stored 'u' time stamp matches\n            # better the mtime value that the server will generate for that file\n            ut += self.target.server_time_ofs\n\n        self.list[filename] = {\"m\": mtime, \"s\": size, \"u\": ut}\n        if self.PRETTY:\n            self.list[filename].update(\n                {\"mtime_str\": pretty_stamp(mtime), \"uploaded_str\": pretty_stamp(ut)}\n            )\n        # print(\"set_mtime\", self.list[filename])\n        self.modified_list = True", "response": "Store real file mtime in meta data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_sync_info(self, filename, mtime, size):\n        assert self.target.is_local()\n        remote_target = self.target.peer\n        ps = self.dir[\"peer_sync\"].setdefault(remote_target.get_id(), {})\n        ut = time.time()  # UTC time stamp\n        ps[\":last_sync\"] = ut  # this is an invalid file name to avoid conflicts\n        pse = ps[filename] = {\"m\": mtime, \"s\": size, \"u\": ut}\n        if self.PRETTY:\n            ps[\":last_sync_str\"] = pretty_stamp(\n                ut\n            )  # use an invalid file name to avoid conflicts\n            pse[\"mtime_str\"] = pretty_stamp(mtime) if mtime else \"(directory)\"\n            pse[\"uploaded_str\"] = pretty_stamp(ut)\n        self.modified_sync = True", "response": "Store mtime and size when local and remote file was last synchronized."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove(self, filename):\n        if self.list.pop(filename, None):\n            self.modified_list = True\n        if self.target.peer:  # otherwise `scan` command\n            if self.target.is_local():\n                remote_target = self.target.peer\n                if remote_target.get_id() in self.dir[\"peer_sync\"]:\n                    rid = remote_target.get_id()\n                    self.modified_sync = bool(\n                        self.dir[\"peer_sync\"][rid].pop(filename, None)\n                    )\n        return", "response": "Remove any data for the given file name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing self from. pyftpsync - meta. json file.", "response": "def read(self):\n        \"\"\"Initialize self from .pyftpsync-meta.json file.\"\"\"\n        assert self.path == self.target.cur_dir\n        try:\n            self.modified_list = False\n            self.modified_sync = False\n            is_valid_file = False\n\n            s = self.target.read_text(self.filename)\n            # print(\"s\", s)\n            if self.target.synchronizer:\n                self.target.synchronizer._inc_stat(\"meta_bytes_read\", len(s))\n            self.was_read = True  # True if a file exists (even invalid)\n            self.dir = json.loads(s)\n            # import pprint\n            # print(\"dir\")\n            # print(pprint.pformat(self.dir))\n            self.dir = make_native_dict_keys(self.dir)\n            # print(pprint.pformat(self.dir))\n            self.list = self.dir[\"mtimes\"]\n            self.peer_sync = self.dir[\"peer_sync\"]\n            is_valid_file = True\n            # write\"DirMetadata: read(%s)\" % (self.filename, ), self.dir)\n        # except IncompatibleMetadataVersion:\n        #     raise  # We want version errors to terminate the app\n        except Exception as e:\n            write_error(\"Could not read meta info {}: {!r}\".format(self, e))\n\n        # If the version is incompatible, we stop, unless:\n        # if --migrate is set, we simply ignore this file (and probably replace it\n        # with a current version)\n        if is_valid_file and self.dir.get(\"_file_version\", 0) != self.VERSION:\n            if not self.target or not self.target.get_option(\"migrate\"):\n                raise IncompatibleMetadataVersion(\n                    \"Invalid meta data version: {} (expected {}).\\n\"\n                    \"Consider passing --migrate to discard old data.\".format(\n                        self.dir.get(\"_file_version\"), self.VERSION\n                    )\n                )\n            #\n            write(\n                \"Migrating meta data version from {} to {} (discarding old): {}\".format(\n                    self.dir.get(\"_file_version\"), self.VERSION, self.filename\n                )\n            )\n            self.list = {}\n            self.peer_sync = {}\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting self to. pyftpsync - meta. json.", "response": "def flush(self):\n        \"\"\"Write self to .pyftpsync-meta.json.\"\"\"\n        # We DO write meta files even on read-only targets, but not in dry-run mode\n        # if self.target.readonly:\n        #     write(\"DirMetadata.flush(%s): read-only; nothing to do\" % self.target)\n        #     return\n        assert self.path == self.target.cur_dir\n        if self.target.dry_run:\n            # write(\"DirMetadata.flush(%s): dry-run; nothing to do\" % self.target)\n            pass\n\n        elif self.was_read and len(self.list) == 0 and len(self.peer_sync) == 0:\n            write(\"Remove empty meta data file: {}\".format(self.target))\n            self.target.remove_file(self.filename)\n\n        elif not self.modified_list and not self.modified_sync:\n            # write(\"DirMetadata.flush(%s): unmodified; nothing to do\" % self.target)\n            pass\n\n        else:\n            self.dir[\"_disclaimer\"] = \"Generated by https://github.com/mar10/pyftpsync\"\n            self.dir[\"_time_str\"] = pretty_stamp(time.time())\n            self.dir[\"_file_version\"] = self.VERSION\n            self.dir[\"_version\"] = __version__\n            self.dir[\"_time\"] = time.mktime(time.gmtime())\n\n            # We always save utf-8 encoded.\n            # `ensure_ascii` would escape all bytes >127 as `\\x12` or `\\u1234`,\n            # which makes it hard to read, so we set it to false.\n            # `sort_keys` converts binary keys to unicode using utf-8, so we\n            # must make sure that we don't pass cp1225 or other encoded data.\n            data = self.dir\n            opts = {\"indent\": 4, \"sort_keys\": True, \"ensure_ascii\": False}\n\n            if compat.PY2:\n                # The `encoding` arg defaults to utf-8 on Py2 and was removed in Py3\n                # opts[\"encoding\"] = \"utf-8\"\n                # Python 2 has problems with mixed keys (str/unicode)\n                data = decode_dict_keys(data, \"utf-8\")\n\n            if not self.PRETTY:\n                opts[\"indent\"] = None\n                opts[\"separators\"] = (\",\", \":\")\n\n            s = json.dumps(data, **opts)\n\n            self.target.write_text(self.filename, s)\n            if self.target.synchronizer:\n                self.target.synchronizer._inc_stat(\"meta_bytes_written\", len(s))\n\n        self.modified_list = False\n        self.modified_sync = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scan_handler(parser, args):\n    opts = namespace_to_dict(args)\n    opts.update({\"ftp_debug\": args.verbose >= 6})\n    target = make_target(args.target, opts)\n    target.readonly = True\n    root_depth = target.root_dir.count(\"/\")\n    start = time.time()\n    dir_count = 1\n    file_count = 0\n    processed_files = set()\n\n    opts = namespace_to_dict(args)\n    process_options(opts)\n\n    def _pred(entry):\n        \"\"\"Walker predicate that check match/exclude options.\"\"\"\n        if not match_path(entry, opts):\n            return False\n\n    try:\n        target.open()\n        for e in target.walk(recursive=args.recursive, pred=_pred):\n            is_dir = isinstance(e, DirectoryEntry)\n            indent = \"    \" * (target.cur_dir.count(\"/\") - root_depth)\n\n            if is_dir:\n                dir_count += 1\n            else:\n                file_count += 1\n\n            if args.list:\n                if is_dir:\n                    print(indent, \"[{e.name}]\".format(e=e))\n                else:\n                    delta = e.mtime_org - e.mtime\n                    dt_modified = pretty_stamp(e.mtime)\n                    if delta:\n                        prefix = \"+\" if delta > 0 else \"\"\n                        print(\n                            indent,\n                            \"{e.name:<40} {dt_modified} (system: {prefix}{delta})\".format(\n                                e=e,\n                                prefix=prefix,\n                                delta=timedelta(seconds=delta),\n                                dt_modified=dt_modified,\n                            ),\n                        )\n                    else:\n                        print(\n                            indent,\n                            \"{e.name:<40} {dt_modified}\".format(\n                                e=e, dt_modified=dt_modified\n                            ),\n                        )\n\n            if (\n                args.remove_meta\n                and target.cur_dir_meta\n                and target.cur_dir_meta.was_read\n            ):\n                fspec = target.cur_dir_meta.get_full_path()\n                if fspec not in processed_files:\n                    processed_files.add(fspec)\n                    print(\"DELETE {}\".format(fspec))\n\n            if (\n                args.remove_locks\n                and not is_dir\n                and e.name == DirMetadata.LOCK_FILE_NAME\n            ):\n                fspec = e.get_rel_path()\n                print(\"DELETE {}\".format(fspec))\n    finally:\n        target.close()\n\n    print(\n        \"Scanning {:,} files in {:,} directories took {:02.2f} seconds.\".format(\n            file_count, dir_count, time.time() - start\n        )\n    )", "response": "Implement scan sub - command."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the format specification according to the values of align and width", "response": "def get_format_spec(self):\n        '''\n        The format specification according to the values of `align` and `width`\n        '''\n        return u\"{{:{align}{width}}}\".format(align=self.align, width=self.width)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing and set the column width for all colls in the table", "response": "def compute_column_width_and_height(self):\n        '''\n        compute and set the column width for all colls in the table\n        '''\n        # skip tables with no row\n        if not self.rows:\n            return\n\n        # determine row height\n        for row in self.rows:\n            max_row_height = max((len(cell.get_cell_lines()) for cell in row.columns)) if row.columns else 1\n            for cell in row.columns:\n                cell.height = max_row_height\n\n        # determine maximum number of columns\n        max_columns = max([len(row.columns) for row in self.rows])\n\n        for column_idx in range(max_columns):\n            # determine max_column_width\n            row_cell_lines = [row.get_cell_lines(column_idx) for row in self.rows]\n            max_column_width = max((len(line) for line in chain(*row_cell_lines)))\n\n            # set column width in all rows\n            for row in self.rows:\n                if len(row.columns) > column_idx:\n                    row.columns[column_idx].width = max_column_width"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a rendered string representation of the given table", "response": "def get_text(self):\n        '''\n            ::returns:\n            a rendered string representation of the given table\n        '''\n        self.compute_column_width_and_height()\n        return '\\n'.join((row.get_text() for row in self.rows))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the lines of the cell specified by the column_idx.", "response": "def get_cell_lines(self, column_idx):\n        '''\n            ''returns:\n            the lines of the cell specified by the column_idx or an empty list if the column does not exist\n        '''\n        return [] if column_idx >= len(self.columns) else self.columns[column_idx].get_cell_lines()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a rendered string representation of the given row.", "response": "def get_text(self):\n        '''\n            ::returns:\n            a rendered string representation of the given row\n        '''\n        row_lines = []\n        for line in zip_longest(*[column.get_cell_lines() for column in self.columns], fillvalue=' '):\n            row_lines.append('  '.join(line))\n        return '\\n'.join(row_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the text representation of the html content", "response": "def get_text(html_content, display_images=False, deduplicate_captions=False, display_links=False):\n    '''\n    ::param: html_content\n    ::returns:\n        a text representation of the html content.\n    '''\n    html_content = html_content.strip()\n    if not html_content:\n        return \"\"\n\n    # strip XML declaration, if necessary\n    if html_content.startswith('<?xml '):\n        html_content = RE_STRIP_XML_DECLARATION.sub('', html_content, count=1)\n\n    html_tree = fromstring(html_content)\n    parser = Inscriptis(html_tree, display_images=display_images, deduplicate_captions=deduplicate_captions, display_links=display_links)\n    return parser.get_text()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the argument parser for the script.", "response": "def get_parser():\n    \"\"\" Parses the arguments if script is run directly via console \"\"\"\n    parser = argparse.ArgumentParser(description='Converts HTML from file or url to a clean text version')\n    parser.add_argument('input', nargs='?', default=None, help='Html input either from a file or an url (default:stdin)')\n    parser.add_argument('-o', '--output', type=str, help='Output file (default:stdout).')\n    parser.add_argument('-e', '--encoding', type=str, help='Content encoding for files (default:utf-8)', default='utf-8')\n    parser.add_argument('-i', '--display-image-captions', action='store_true', default=False, help='Display image captions (default:false).')\n    parser.add_argument('-l', '--display-link-targets', action='store_true', default=False, help='Display link targets (default:false).')\n    parser.add_argument('-d', '--deduplicate-image-captions', action='store_true', default=False, help='Deduplicate image captions (default:false).')\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_line(self, force=False):\n        '''\n        Writes the current line to the buffer, provided that there is any\n        data to write.\n\n        ::returns:\n            True, if a line has been writer, otherwise False\n        '''\n        # only break the line if there is any relevant content\n        if not force and (not self.current_line[-1].content or self.current_line[-1].content.isspace()):\n            self.current_line[-1].margin_before = max(self.current_line[-1].margin_before,\n                                                      self.current_tag[-1].margin_before)\n            return False\n\n        line = self.current_line[-1].get_text()\n        self.clean_text_lines[-1].append(line)\n        self.current_line[-1] = self.next_line[-1]\n        self.next_line[-1] = Line()\n        return True", "response": "Writes the current line to the buffer provided that there is any relevant content to write."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clone(self):\n        '''\n        ::return: \\\n            a clone of the current HtmlElement\n        '''\n        return HtmlElement(self.tag, self.prefix, self.suffix, self.display,\n                           self.margin_before, self.margin_after, self.padding,\n                           self.whitespace)", "response": "\\ returns a clone of the current HtmlElement"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new HtmlElement with the given style attribute applied to the given element.", "response": "def get_style_attribute(style_attribute, html_element):\n        '''\n        ::param: style_directive \\\n          The attribute value of the given style sheet.\n          Example: display: none\n\n        ::param: html_element: \\\n          The HtmlElement to which the given style is applied\n\n        ::returns:\n            A HtmlElement that merges the given element with\n            the style attributes specified.\n        '''\n        custome_html_element = html_element.clone()\n        for style_directive in style_attribute.lower().split(';'):\n            if ':' not in style_directive:\n                continue\n            key, value = (s.strip() for s in style_directive.split(':', 1))\n\n            try:\n                apply_style = getattr(CssParse, \"_attr_\" +\n                                      key.replace('-webkit-', '')\n                                      .replace(\"-\", \"_\"))\n                apply_style(value, custome_html_element)\n            except AttributeError:\n                pass\n\n        return custome_html_element"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _attr_display(value, html_element):\n        '''\n        Set the display value\n        '''\n        if value == 'block':\n            html_element.display = Display.block\n        elif value == 'none':\n            html_element.display = Display.none\n        else:\n            html_element.display = Display.inline", "response": "Set the display value of the element."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a scatter plot of the data in x y.", "response": "def scatter_density(self, x, y, dpi=72, downres_factor=4, color=None, cmap=None,\n                        alpha=1.0, norm=None, **kwargs):\n        \"\"\"\n        Make a density plot of the (x, y) scatter data.\n\n        Parameters\n        ----------\n        x, y : iterable\n            The data to plot\n        dpi : int or `None`\n            The number of dots per inch to include in the density map. To use\n            the native resolution of the drawing device, set this to None.\n        downres_factor : int\n            For interactive devices, when panning, the density map will\n            automatically be made at a lower resolution and including only a\n            subset of the points. The new dpi of the figure when panning will\n            then be dpi / downres_factor, and the number of elements in the\n            arrays will be reduced by downres_factor**2.\n        cmap : `matplotlib.colors.Colormap`\n            The colormap to use for the density map.\n        color : str or tuple\n            The color to use for the density map. This can be any valid\n            Matplotlib color. If specified, this takes precedence over the\n            colormap.\n        alpha : float\n            Transparency of the density map\n        norm : `matplotlib.colors.Normalize`\n            The normalization class for the density map.\n        \"\"\"\n\n        self.set_xlim(np.min(x), np.max(x))\n        self.set_ylim(np.min(y), np.max(y))\n\n        scatter = ScatterDensityArtist(self, x, y, dpi=dpi, downres_factor=downres_factor,\n                                       color=color, cmap=cmap,\n                                       alpha=alpha, norm=norm, **kwargs)\n        self.add_artist(scatter)\n\n        return scatter"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads file at the specified path.", "response": "def read_file(file_path, default_content=''):\n    \"\"\"\n    Read file at the specified path.\n    If file doesn't exist, it will be created with default-content.\n    Returns the file content.\n    \"\"\"\n    if not os.path.exists(file_path):\n        write_file(file_path, default_content)\n\n    handler = open(file_path, 'r')\n    content = handler.read()\n    handler.close()\n    return content or default_content"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites content to file at the specified path.", "response": "def write_file(file_path, content):\n    \"\"\"\n    Write file at the specified path with content.\n    If file exists, it will be overwritten.\n    \"\"\"\n    handler = open(file_path, 'w+')\n    handler.write(content)\n    handler.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting maintenance mode state to state file.", "response": "def set_maintenance_mode(value):\n    \"\"\"\n    Set maintenance_mode state to state file.\n    \"\"\"\n\n    # If maintenance mode is defined in settings, it can't be changed.\n    if settings.MAINTENANCE_MODE is not None:\n        raise ImproperlyConfigured(\n            'Maintenance mode cannot be set dynamically '\n            'if defined in settings.')\n\n    if not isinstance(value, bool):\n        raise TypeError('value argument type is not boolean')\n\n    backend = get_maintenance_mode_backend()\n    backend.set_value(value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_maintenance_response(request):\n    if settings.MAINTENANCE_MODE_REDIRECT_URL:\n        return redirect(settings.MAINTENANCE_MODE_REDIRECT_URL)\n\n    context = {}\n\n    if settings.MAINTENANCE_MODE_GET_TEMPLATE_CONTEXT:\n        try:\n            get_request_context_func = import_string(\n                settings.MAINTENANCE_MODE_GET_TEMPLATE_CONTEXT)\n        except ImportError:\n            raise ImproperlyConfigured(\n                'settings.MAINTENANCE_MODE_GET_TEMPLATE_CONTEXT '\n                'is not a valid function path.'\n            )\n\n        context = get_request_context_func(request=request)\n\n    if django.VERSION < (1, 8):\n        kwargs = {'context_instance': RequestContext(request, context)}\n    else:\n        kwargs = {'context': context}\n\n    response = render(request, settings.MAINTENANCE_MODE_TEMPLATE,\n                      status=settings.MAINTENANCE_MODE_STATUS_CODE,\n                      **kwargs)\n    response['Retry-After'] = settings.MAINTENANCE_MODE_RETRY_AFTER\n    add_never_cache_headers(response)\n    return response", "response": "Returns a 500 Service Unavailable maintenance response."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntell if the given request needs a maintenance response or not.", "response": "def need_maintenance_response(request):\n    \"\"\"\n    Tells if the given request needs a maintenance response or not.\n    \"\"\"\n\n    try:\n        view_match = resolve(request.path)\n        view_func = view_match[0]\n        view_dict = view_func.__dict__\n\n        view_force_maintenance_mode_off = view_dict.get(\n            'force_maintenance_mode_off', False)\n        if view_force_maintenance_mode_off:\n            # view has 'force_maintenance_mode_off' decorator\n            return False\n\n        view_force_maintenance_mode_on = view_dict.get(\n            'force_maintenance_mode_on', False)\n        if view_force_maintenance_mode_on:\n            # view has 'force_maintenance_mode_on' decorator\n            return True\n\n    except Resolver404:\n        pass\n\n    if not get_maintenance_mode():\n        return False\n\n    try:\n        url_off = reverse('maintenance_mode_off')\n\n        resolve(url_off)\n\n        if url_off == request.path_info:\n            return False\n\n    except NoReverseMatch:\n        # maintenance_mode.urls not added\n        pass\n\n    if hasattr(request, 'user'):\n\n        if django.VERSION < (1, 10):\n            if settings.MAINTENANCE_MODE_IGNORE_ANONYMOUS_USER \\\n                    and request.user.is_anonymous():\n                return False\n\n            if settings.MAINTENANCE_MODE_IGNORE_AUTHENTICATED_USER \\\n                    and request.user.is_authenticated():\n                return False\n        else:\n            if settings.MAINTENANCE_MODE_IGNORE_ANONYMOUS_USER \\\n                    and request.user.is_anonymous:\n                return False\n\n            if settings.MAINTENANCE_MODE_IGNORE_AUTHENTICATED_USER \\\n                    and request.user.is_authenticated:\n                return False\n\n        if settings.MAINTENANCE_MODE_IGNORE_STAFF \\\n                and request.user.is_staff:\n            return False\n\n        if settings.MAINTENANCE_MODE_IGNORE_SUPERUSER \\\n                and request.user.is_superuser:\n            return False\n\n    if settings.MAINTENANCE_MODE_IGNORE_ADMIN_SITE:\n\n        try:\n            request_path = request.path if request.path else ''\n            if not request_path.endswith('/'):\n                request_path += '/'\n\n            admin_url = reverse('admin:index')\n            if request_path.startswith(admin_url):\n                return False\n\n        except NoReverseMatch:\n            # admin.urls not added\n            pass\n\n    if settings.MAINTENANCE_MODE_IGNORE_TESTS:\n\n        is_testing = False\n\n        if (len(sys.argv) > 0 and 'runtests' in sys.argv[0]) \\\n                or (len(sys.argv) > 1 and sys.argv[1] == 'test'):\n            # python runtests.py | python manage.py test | python\n            # setup.py test | django-admin.py test\n            is_testing = True\n\n        if is_testing:\n            return False\n\n    if settings.MAINTENANCE_MODE_IGNORE_IP_ADDRESSES:\n\n        if settings.MAINTENANCE_MODE_GET_CLIENT_IP_ADDRESS:\n            try:\n                get_client_ip_address_func = import_string(\n                    settings.MAINTENANCE_MODE_GET_CLIENT_IP_ADDRESS)\n            except ImportError:\n                raise ImproperlyConfigured(\n                    'settings.MAINTENANCE_MODE_GET_CLIENT_IP_ADDRESS '\n                    'is not a valid function path.')\n            else:\n                client_ip_address = get_client_ip_address_func(request)\n        else:\n            client_ip_address = get_client_ip_address(request)\n\n        for ip_address in settings.MAINTENANCE_MODE_IGNORE_IP_ADDRESSES:\n\n            ip_address_re = re.compile(ip_address)\n\n            if ip_address_re.match(client_ip_address):\n                return False\n\n    if settings.MAINTENANCE_MODE_IGNORE_URLS:\n\n        for url in settings.MAINTENANCE_MODE_IGNORE_URLS:\n\n            if not isinstance(url, pattern_class):\n                url = str(url)\n            url_re = re.compile(url)\n\n            if url_re.match(request.path_info):\n                return False\n\n    if settings.MAINTENANCE_MODE_REDIRECT_URL:\n\n        redirect_url_re = re.compile(\n            settings.MAINTENANCE_MODE_REDIRECT_URL)\n\n        if redirect_url_re.match(request.path_info):\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the username / password data against ldap directory", "response": "def validate_ldap(self):\n        'Validate the username/password data against ldap directory'\n        ldap_mgr = current_app.ldap_login_manager\n        username = self.username.data\n        password = self.password.data\n        try:\n            userdata = ldap_mgr.ldap_login(username, password)\n        except ldap.INVALID_CREDENTIALS:\n            flash(\"Invalid LDAP credentials\", 'danger')\n            return False\n        except ldap.LDAPError as err:\n            if isinstance(err.message, dict):\n                message = err.message.get('desc', str(err))\n            else:\n                message = str(err.message)\n            flash(message, 'danger')\n            return False\n\n        if userdata is None:\n            flash(\"Invalid LDAP credentials\", 'danger')\n            return False\n\n        self.user = ldap_mgr._save_user(username, userdata)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self, *args, **kwargs):\n\n        valid = Form.validate(self, *args, **kwargs)\n        if not valid: return valid\n\n        return self.validate_ldap()", "response": "Validates the form by calling validate on each field passing any validators to the field validator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scalar(value):\n    if isinstance(value, (list, tuple)) and len(value) == 1:\n        return value[0]\n    return value", "response": "Take a scalar value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_app(self, app):\n        '''\n        Configures an application. This registers an `after_request` call, and\n        attaches this `LoginManager` to it as `app.login_manager`.\n        '''\n\n        self._config = app.config.get('LDAP', {})\n        app.ldap_login_manager = self\n\n        self.config.setdefault('BIND_DN', '')\n        self.config.setdefault('BIND_AUTH', '')\n        self.config.setdefault('URI', 'ldap://127.0.0.1')\n        self.config.setdefault('OPTIONS', {})\n        # Referrals are disabled by default\n        self.config['OPTIONS'].setdefault(ldap.OPT_REFERRALS, ldap.OPT_OFF)\n\n        if self.config.get('USER_SEARCH') and not isinstance(self.config['USER_SEARCH'], list):\n            self.config['USER_SEARCH'] = [self.config['USER_SEARCH']]", "response": "Initializes an application. This is called by the application initialization code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_results(self, results):\n        if not results:\n            return None\n        userdn = results[0][0]\n        userobj = results[0][1]\n        userobj['dn'] = userdn\n\n        keymap = self.config.get('KEY_MAP')\n        if keymap:\n            return {key:scalar(userobj.get(value)) for key, value in keymap.items() if _is_utf8(scalar(userobj.get(value))) }\n        else:\n            return {key:scalar(value) for key, value in userobj.items() if _is_utf8(scalar(value)) }", "response": "Format the ldap results object into somthing that is reasonable\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform the KEY_MAP paramiter into an attrlist for ldap filters", "response": "def attrlist(self):\n        'Transform the KEY_MAP paramiter into an attrlist for ldap filters'\n        keymap = self.config.get('KEY_MAP')\n        if keymap:\n            # https://github.com/ContinuumIO/flask-ldap-login/issues/11\n            # https://continuumsupport.zendesk.com/agent/tickets/393\n            return [s.encode('utf-8') for s in keymap.values()]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bind_search(self, username, password):\n\n        log.debug(\"Performing bind/search\")\n\n        ctx = {'username':username, 'password':password}\n\n        user = self.config['BIND_DN'] % ctx\n\n        bind_auth = self.config['BIND_AUTH']\n        try:\n            log.debug(\"Binding with the BIND_DN %s\" % user)\n            self.conn.simple_bind_s(user, bind_auth)\n        except ldap.INVALID_CREDENTIALS:\n            msg = \"Could not connect bind with the BIND_DN=%s\" % user\n            log.debug(msg)\n            if self._raise_errors:\n                raise ldap.INVALID_CREDENTIALS(msg)\n            return None\n\n        user_search = self.config.get('USER_SEARCH')\n\n        results = None\n        found_user = False\n        for search in user_search:\n            base = search['base']\n            filt = search['filter'] % ctx\n            scope = search.get('scope', ldap.SCOPE_SUBTREE)\n            log.debug(\"Search for base=%s filter=%s\" % (base, filt))\n            results = self.conn.search_s(base, scope, filt, attrlist=self.attrlist)\n            if results:\n                found_user = True\n                log.debug(\"User with DN=%s found\" % results[0][0])\n                try:\n                    self.conn.simple_bind_s(results[0][0], password)\n                except ldap.INVALID_CREDENTIALS:\n                    self.conn.simple_bind_s(user, bind_auth)\n                    log.debug(\"Username/password mismatch, continue search...\")\n                    results = None\n                    continue\n                else:\n                    log.debug(\"Username/password OK\")\n                    break\n        if not results and self._raise_errors:\n            msg = \"No users found matching search criteria: {}\".format(user_search)\n            if found_user:\n                msg = \"Username/password mismatch\"\n            raise ldap.INVALID_CREDENTIALS(msg)\n\n        log.debug(\"Unbind\")\n        self.conn.unbind_s()\n\n        return self.format_results(results)", "response": "Bind to BIND_DN and bind_auth then search for user with username and password."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbinds to username and password directly", "response": "def direct_bind(self, username, password):\n        \"\"\"\n        Bind to username/password directly\n        \"\"\"\n        log.debug(\"Performing direct bind\")\n\n        ctx = {'username':username, 'password':password}\n        scope = self.config.get('SCOPE', ldap.SCOPE_SUBTREE)\n        user = self.config['BIND_DN'] % ctx\n\n        try:\n            log.debug(\"Binding with the BIND_DN %s\" % user)\n            self.conn.simple_bind_s(user, password)\n        except ldap.INVALID_CREDENTIALS:\n            if self._raise_errors:\n                raise ldap.INVALID_CREDENTIALS(\"Unable to do a direct bind with BIND_DN %s\" % user)\n            return None\n        results = self.conn.search_s(user, scope, attrlist=self.attrlist)\n        self.conn.unbind_s()\n        return self.format_results(results)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing ldap connection and set options", "response": "def connect(self):\n        'initialize ldap connection and set options'\n        log.debug(\"Connecting to ldap server %s\" % self.config['URI'])\n        self.conn = ldap.initialize(self.config['URI'])\n\n        # There are some settings that can't be changed at runtime without a context restart.\n        # It's possible to refresh the context and apply the settings by setting OPT_X_TLS_NEWCTX\n        # to 0, but this needs to be the last option set, and since the config dictionary is not\n        # sorted, this is not necessarily true. Sort the list of options so that if OPT_X_TLS_NEWCTX\n        # is present, it is applied last.\n        options = self.config.get('OPTIONS', {}).items()\n        options.sort(key=lambda x: x[0] == 'OPT_X_TLS_NEWCTX')\n\n        for opt, value in options:\n            if isinstance(opt, str):\n                opt = getattr(ldap, opt)\n\n            try:\n                if isinstance(value, str):\n                    value = getattr(ldap, value)\n            except AttributeError:\n                pass\n            self.conn.set_option(opt, value)\n\n        if self.config.get('START_TLS'):\n            log.debug(\"Starting TLS\")\n            self.conn.start_tls_s()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ldap_login(self, username, password):\n        self.connect()\n\n        if self.config.get('USER_SEARCH'):\n            result = self.bind_search(username, password)\n        else:\n            result = self.direct_bind(username, password)\n        return result", "response": "Authenticate a user using LDAP. This will return a userdata dict if successfull otherwise None."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsimulate an object in the BACnet stack by setting the Out_Of_Service property to the point s Present_Value.", "response": "def sim(self, args):\r\n        \"\"\"\r\n        Simulate I/O points by setting the Out_Of_Service property, then doing a \r\n        WriteProperty to the point's Present_Value.\r\n\r\n        :param args: String with <addr> <type> <inst> <prop> <value> [ <indx> ] [ <priority> ]\r\n\r\n        \"\"\"\r\n        if not self._started:\r\n            raise ApplicationNotStarted(\"BACnet stack not running - use startApp()\")\r\n\r\n        # with self.this_application._lock: if use lock...won't be able to call read...\r\n        args = args.split()\r\n        addr, obj_type, obj_inst, prop_id, value = args[:5]\r\n\r\n        if self.read(\"{} {} {} outOfService\".format(addr, obj_type, obj_inst)):\r\n            self.write(\r\n                \"{} {} {} {} {}\".format(addr, obj_type, obj_inst, prop_id, value)\r\n            )\r\n        else:\r\n            try:\r\n                self.write(\r\n                    \"{} {} {} outOfService True\".format(addr, obj_type, obj_inst)\r\n                )\r\n            except NoResponseFromController:\r\n                pass\r\n\r\n            try:\r\n                if self.read(\"{} {} {} outOfService\".format(addr, obj_type, obj_inst)):\r\n                    self.write(\r\n                        \"{} {} {} {} {}\".format(\r\n                            addr, obj_type, obj_inst, prop_id, value\r\n                        )\r\n                    )\r\n                else:\r\n                    raise OutOfServiceNotSet()\r\n            except NoResponseFromController:\r\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef out_of_service(self, args):\r\n        if not self._started:\r\n            raise ApplicationNotStarted(\"BACnet stack not running - use startApp()\")\r\n\r\n        # with self.this_application._lock: if use lock...won't be able to call read...\r\n        args = args.split()\r\n        addr, obj_type, obj_inst = args[:3]\r\n        try:\r\n            self.write(\"{} {} {} outOfService True\".format(addr, obj_type, obj_inst))\r\n        except NoResponseFromController:\r\n            pass", "response": "Set the Out_Of_Service property so the Present_Value of an I/O may be written."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef release(self, args):\r\n        if not self._started:\r\n            raise ApplicationNotStarted(\"BACnet stack not running - use startApp()\")\r\n\r\n        args = args.split()\r\n        addr, obj_type, obj_inst = args[:3]\r\n        try:\r\n            self.write(\"{} {} {} outOfService False\".format(addr, obj_type, obj_inst))\r\n        except NoResponseFromController:\r\n            pass\r\n\r\n        try:\r\n            if self.read(\"{} {} {} outOfService\".format(addr, obj_type, obj_inst)):\r\n                raise OutOfServiceSet()\r\n            else:\r\n                pass  # Everything is ok\"\r\n        except NoResponseFromController:\r\n            pass", "response": "Release the current state of the object with the given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the IP Address subnet of the current instance.", "response": "def ip_address_subnet(self):\n        \"\"\"\n        IP Address/subnet\n        \"\"\"\n        return \"{}/{}\".format(\n            self.interface.ip.compressed, self.interface.exploded.split(\"/\")[-1]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef address(self):\n        port = \"\"\n        if self._port:\n            port = \":{}\".format(self._port)\n        return Address(\n            \"{}/{}{}\".format(\n                self.interface.ip.compressed,\n                self.interface.exploded.split(\"/\")[-1],\n                port,\n            )\n        )", "response": "Returns an Address object for the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _findIPAddr(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        try:\n            s.connect((\"google.com\", 0))\n            addr = s.getsockname()[0]\n            # print('Using ip : {addr}'.format(addr=addr))\n            s.close()\n        except socket.error:\n            raise NetworkInterfaceException(\n                \"Impossible to retrieve IP, please provide one manually\"\n            )\n        return addr", "response": "Retrieve the IP address connected to internet... used as\n        a default IP address when defining Script\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _findSubnetMask(self, ip):\n        ip = ip\n\n        if \"win32\" in sys.platform:\n            try:\n                proc = subprocess.Popen(\"ipconfig\", stdout=subprocess.PIPE)\n                while True:\n                    line = proc.stdout.readline()\n                    if ip.encode() in line:\n                        break\n                mask = (\n                    proc.stdout.readline()\n                    .rstrip()\n                    .split(b\":\")[-1]\n                    .replace(b\" \", b\"\")\n                    .decode()\n                )\n            except:\n                raise NetworkInterfaceException(\"Cannot read IP parameters from OS\")\n        else:\n            \"\"\"\n            This procedure could use more direct way of obtaining the broadcast IP\n            as it is really simple in Unix\n            ifconfig gives Bcast directly for example\n            or use something like :\n            iface = \"eth0\"\n            socket.inet_ntoa(fcntl.ioctl(socket.socket(socket.AF_INET, socket.SOCK_DGRAM), 35099, struct.pack('256s', iface))[20:24])\n            \"\"\"\n            pattern = re.compile(r\"(255.\\d{1,3}.\\d{1,3}.\\d{1,3})\")\n\n            try:\n                proc = subprocess.Popen(\"ifconfig\", stdout=subprocess.PIPE)\n                while True:\n                    line = proc.stdout.readline()\n                    if ip.encode() in line:\n                        break\n                mask = re.findall(pattern, line.decode())[0]\n            except:\n                mask = \"255.255.255.255\"\n        # self._log.debug('Mask found : %s' %  mask)\n        return mask", "response": "This function will try to find a broadcast IP address connected to internet and return it as a string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read_from_sql(self, request, db_name):\n        with contextlib.closing(sqlite3.connect(\"{}.db\".format(db_name))) as con:\n            return sql.read_sql(sql=request, con=con)", "response": "Read the record from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dataframe of point properties in preparation for storage in SQL.", "response": "def points_properties_df(self):\n        \"\"\"\n        Return a dictionary of point/point_properties in preparation for storage in SQL.\n        \"\"\"\n        pprops = {}\n        for each in self.points:\n            p = each.properties.asdict.copy()\n            p.pop(\"device\", None)\n            p.pop(\"network\", None)\n            p.pop(\"simulated\", None)\n            p.pop(\"overridden\", None)\n            pprops[each.properties.name] = p\n\n        df = pd.DataFrame(pprops)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef backup_histories_df(self):\n        backup = {}\n        for point in self.points:\n            if point.history.dtypes == object:\n                backup[point.properties.name] = (\n                    point.history.replace([\"inactive\", \"active\"], [0, 1])\n                    .resample(\"1s\")\n                    .mean()\n                )\n            else:\n                backup[point.properties.name] = point.history.resample(\"1s\").mean()\n\n        df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in backup.items()]))\n        return df.fillna(method=\"ffill\")", "response": "Build a dataframe of the point histories that are stored in the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, filename=None):\n        if filename:\n            if \".db\" in filename:\n                filename = filename.split(\".\")[0]\n            self.properties.db_name = filename\n        else:\n            self.properties.db_name = \"{}\".format(self.properties.name)\n\n        # Does file exist? If so, append data\n        if os.path.isfile(\"{}.db\".format(self.properties.db_name)):\n            his = self._read_from_sql(\n                'select * from \"{}\"'.format(\"history\"), self.properties.db_name\n            )\n            his.index = his[\"index\"].apply(Timestamp)\n            try:\n                last = his.index[-1]\n                df_to_backup = self.backup_histories_df()[last:]\n            except IndexError:\n                df_to_backup = self.backup_histories_df()\n\n        else:\n            self._log.debug(\"Creating a new backup database\")\n            df_to_backup = self.backup_histories_df()\n\n        # DataFrames that will be saved to SQL\n        with contextlib.closing(\n            sqlite3.connect(\"{}.db\".format(self.properties.db_name))\n        ) as con:\n            sql.to_sql(\n                df_to_backup,\n                name=\"history\",\n                con=con,\n                index_label=\"index\",\n                index=True,\n                if_exists=\"append\",\n            )\n\n        # Saving other properties to a pickle file...\n        prop_backup = {}\n        prop_backup[\"device\"] = self.dev_properties_df()\n        prop_backup[\"points\"] = self.points_properties_df()\n        with open(\"{}.bin\".format(self.properties.db_name), \"wb\") as file:\n            pickle.dump(prop_backup, file)\n\n        self._log.info(\"Device saved to {}.db\".format(self.properties.db_name))", "response": "Save the point object properties to a sqlite3 database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves point list from SQL database", "response": "def points_from_sql(self, db_name):\n        \"\"\"\n        Retrieve point list from SQL database\n        \"\"\"\n        points = self._read_from_sql(\"SELECT * FROM history;\", db_name)\n        return list(points.columns.values)[1:]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef his_from_sql(self, db_name, point):\n        his = self._read_from_sql('select * from \"%s\"' % \"history\", db_name)\n        his.index = his[\"index\"].apply(Timestamp)\n        return his.set_index(\"index\")[point]", "response": "Retrive point histories from SQL database"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_point_prop(self, device_name, point):\n        with open(\"%s.bin\" % device_name, \"rb\") as file:\n            return pickle.load(file)[\"points\"][point]", "response": "Reads the properties of a specific point from pickle"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the properties of a specific device from pickle", "response": "def read_dev_prop(self, device_name):\n        \"\"\"\n        Device properties retrieved from pickle\n        \"\"\"\n        with open(\"{}.bin\".format(device_name), \"rb\") as file:\n            return pickle.load(file)[\"device\"]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef value(self):\n        try:\n            res = self.properties.device.properties.network.read(\n                \"{} {} {} presentValue\".format(\n                    self.properties.device.properties.address,\n                    self.properties.type,\n                    str(self.properties.address),\n                )\n            )\n            self._trend(res)\n\n        except Exception:\n            raise Exception(\"Problem reading : {}\".format(self.properties.name))\n\n        if res == \"inactive\":\n            self._key = 0\n            self._boolKey = False\n        else:\n            self._key = 1\n            self._boolKey = True\n        return res", "response": "Read the value from BACnet network and store it in internal object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef boolValue(self):\n        if self.lastValue == 1 or self.lastValue == \"active\":\n            self._key = 1\n            self._boolKey = True\n        else:\n            self._key = 0\n            self._boolKey = False\n        return self._boolKey", "response": "returns the boolean value of the current locale"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enumValue(self):\n        try:\n            return self.properties.units_state[int(self.lastValue) - 1]\n        except IndexError:\n            value = \"unknown\"\n        except ValueError:\n            value = \"NaN\"\n        return value", "response": "returns ( str ) Enum state value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the value of the key.", "response": "def value(self):\n        \"\"\"\n        Take last known value as the value\n        \"\"\"\n        try:\n            value = self.lastValue\n        except IndexError:\n            value = \"NaN\"\n        except ValueError:\n            value = \"NaN\"\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a tuple of read requests for each point in point_list and points in point_list", "response": "def _rpm_request_by_name(self, point_list):\r\n        \"\"\"\r\n        :param point_list: a list of point\r\n        :returns: (tuple) read request for each points, points\r\n        \"\"\"\r\n        points = []\r\n        requests = []\r\n        for each in point_list:\r\n            str_list = []\r\n            point = self._findPoint(each, force_read=False)\r\n            points.append(point)\r\n\r\n            str_list.append(\" \" + point.properties.type)\r\n            str_list.append(\" \" + str(point.properties.address))\r\n            str_list.append(\" presentValue\")\r\n            rpm_param = \"\".join(str_list)\r\n            requests.append(rpm_param)\r\n\r\n        return (requests, points)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_multiple(\r\n        self,\r\n        points_list,\r\n        *,\r\n        points_per_request=25,\r\n        discover_request=(None, 6),\r\n        force_single=False\r\n    ):\r\n        \"\"\"\r\n        Read points from a device using a ReadPropertyMultiple request.\r\n        [ReadProperty requests are very slow in comparison].\r\n\r\n        :param points_list: (list) a list of all point_name as str\r\n        :param points_per_request: (int) number of points in the request\r\n\r\n        Requesting many points results big requests that need segmentation.  Aim to request\r\n        just the 'right amount' so segmentation can be avoided.  Determining the 'right amount'\r\n        is often trial-&-error.\r\n\r\n        :Example:\r\n\r\n        device.read_multiple(['point1', 'point2', 'point3'], points_per_request = 10)\r\n        \"\"\"\r\n        if not self.properties.pss[\"readPropertyMultiple\"] or force_single:\r\n            self._log.warning(\"Read property Multiple Not supported\")\r\n            self.read_single(\r\n                points_list, points_per_request=1, discover_request=discover_request\r\n            )\r\n        else:\r\n            if not self.properties.segmentation_supported:\r\n                points_per_request = 1\r\n\r\n            if discover_request[0]:\r\n                values = []\r\n                info_length = discover_request[1]\r\n                big_request = discover_request[0]\r\n\r\n                for request in self._batches(big_request, points_per_request):\r\n                    try:\r\n                        request = \"{} {}\".format(\r\n                            self.properties.address, \"\".join(request)\r\n                        )\r\n                        self._log.debug(\"RPM_Request: %s \" % request)\r\n                        val = self.properties.network.readMultiple(request)\r\n\r\n                        # print('val : ', val, len(val), type(val))\r\n                        if val == None:\r\n                            self.properties.segmentation_supported = False\r\n                            raise SegmentationNotSupported\r\n\r\n                    except KeyError as error:\r\n                        raise Exception(\"Unknown point name : %s\" % error)\r\n\r\n                    except SegmentationNotSupported as error:\r\n                        self.properties.segmentation_supported = False\r\n                        # self.read_multiple(points_list,points_per_request=1, discover_request=discover_request)\r\n                        self._log.warning(\"Segmentation not supported\")\r\n                        self._log.warning(\"Request too big...will reduce it\")\r\n                        if points_per_request == 1:\r\n                            raise\r\n                        self.read_multiple(\r\n                            points_list,\r\n                            points_per_request=1,\r\n                            discover_request=discover_request,\r\n                        )\r\n\r\n                    else:\r\n                        for points_info in self._batches(val, info_length):\r\n                            values.append(points_info)\r\n                return values\r\n\r\n            else:\r\n                big_request = self._rpm_request_by_name(points_list)\r\n                i = 0\r\n                for request in self._batches(big_request[0], points_per_request):\r\n                    try:\r\n                        request = \"{} {}\".format(\r\n                            self.properties.address, \"\".join(request)\r\n                        )\r\n                        val = self.properties.network.readMultiple(request)\r\n\r\n                    except SegmentationNotSupported as error:\r\n                        self.properties.segmentation_supported = False\r\n                        self.read_multiple(\r\n                            points_list,\r\n                            points_per_request=1,\r\n                            discover_request=discover_request,\r\n                        )\r\n\r\n                    except KeyError as error:\r\n                        raise Exception(\"Unknown point name : %s\" % error)\r\n\r\n                    else:\r\n                        points_values = zip(big_request[1][i : i + len(val)], val)\r\n                        i += len(val)\r\n                        for each in points_values:\r\n                            each[0]._trend(each[1])", "response": "Read multiple points from a device using a ReadPropertyMultiple request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads multiple points from a device using the ReadPropertyMultiple request.", "response": "def read_multiple(\r\n        self, points_list, *, points_per_request=1, discover_request=(None, 6)\r\n    ):\r\n        \"\"\"\r\n        Functions to read points from a device using the ReadPropertyMultiple request.\r\n        Using readProperty request can be very slow to read a lot of data.\r\n\r\n        :param points_list: (list) a list of all point_name as str\r\n        :param points_per_request: (int) number of points in the request\r\n\r\n        Using too many points will create big requests needing segmentation.\r\n        It's better to use just enough request so the message will not require\r\n        segmentation.\r\n\r\n        :Example:\r\n\r\n        device.read_multiple(['point1', 'point2', 'point3'], points_per_request = 10)\r\n        \"\"\"\r\n        # print('PSS : %s' % self.properties.pss['readPropertyMultiple'])\r\n        if isinstance(points_list, list):\r\n            for each in points_list:\r\n                self.read_single(\r\n                    each, points_per_request=1, discover_request=discover_request\r\n                )\r\n        else:\r\n            self.read_single(\r\n                points_list, points_per_request=1, discover_request=discover_request\r\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef poll(self, command=\"start\", *, delay=120):\r\n        if delay > 120:\r\n            self._log.warning(\r\n                \"Segmentation not supported, forcing delay to 120 seconds (or higher)\"\r\n            )\r\n            delay = 120\r\n        # for each in self.points:\r\n        #    each.value\r\n        # self._log.info('Complete')\r\n        if (\r\n            str(command).lower() == \"stop\"\r\n            or command == False\r\n            or command == 0\r\n            or delay == 0\r\n        ):\r\n\r\n            if isinstance(self._polling_task.task, DevicePoll):\r\n                self._polling_task.task.stop()\r\n                while self._polling_task.task.is_alive():\r\n                    pass\r\n\r\n                self._polling_task.task = None\r\n                self._polling_task.running = False\r\n                self._log.info(\"Polling stopped\")\r\n\r\n        elif self._polling_task.task is None:\r\n            self._polling_task.task = DevicePoll(self, delay=delay)\r\n            self._polling_task.task.start()\r\n            self._polling_task.running = True\r\n            self._log.info(\r\n                \"Polling started, values read every {} seconds\".format(delay)\r\n            )\r\n\r\n        elif self._polling_task.running:\r\n            self._polling_task.task.stop()\r\n            while self._polling_task.task.is_alive():\r\n                pass\r\n            self._polling_task.running = False\r\n            self._polling_task.task = DevicePoll(self, delay=delay)\r\n            self._polling_task.task.start()\r\n            self._polling_task.running = True\r\n            self._log.info(\"Polling started, every values read each %s seconds\" % delay)\r\n\r\n        else:\r\n            raise RuntimeError(\"Stop polling before redefining it\")", "response": "Poll a point every x seconds"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses by Flask to show informations on the network", "response": "def network_stats(self):\n        \"\"\"\n        Used by Flask to show informations on the network\n        \"\"\"\n        statistics = {}\n        mstp_networks = []\n        mstp_map = {}\n        ip_devices = []\n        bacoids = []\n        mstp_devices = []\n        for address, bacoid in self.whois_answer[0].keys():\n            if \":\" in address:\n                net, mac = address.split(\":\")\n                mstp_networks.append(net)\n                mstp_devices.append(mac)\n                try:\n                    mstp_map[net].append(mac)\n                except KeyError:\n                    mstp_map[net] = []\n                    mstp_map[net].append(mac)\n            else:\n                net = \"ip\"\n                mac = address\n                ip_devices.append(address)\n            bacoids.append((bacoid, address))\n        mstpnetworks = sorted(set(mstp_networks))\n        statistics[\"mstp_networks\"] = mstpnetworks\n        statistics[\"ip_devices\"] = sorted(ip_devices)\n        statistics[\"bacoids\"] = sorted(bacoids)\n        statistics[\"mstp_map\"] = mstp_map\n        statistics[\"timestamp\"] = str(datetime.now())\n        statistics[\"number_of_devices\"] = self.number_of_devices\n        statistics[\"number_of_registered_devices\"] = len(self.registered_devices)\n        statistics[\"print_mstpnetworks\"] = self.print_list(mstpnetworks)\n        return statistics"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect(self, *, db=None):\r\n        if db:\r\n            self.poll(command=\"stop\")\r\n            self.properties.db_name = db.split(\".\")[0]\r\n            self.new_state(DeviceFromDB)\r\n        else:\r\n            self._log.warning(\r\n                \"Already connected, provide db arg if you want to connect to db\"\r\n            )", "response": "Connect to a previously - known device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef df(self, list_of_points, force_read=True):\r\n\r\n        his = []\r\n        for point in list_of_points:\r\n            try:\r\n                his.append(self._findPoint(point, force_read=force_read).history)\r\n            except ValueError as ve:\r\n                self._log.error(\"{}\".format(ve))\r\n                continue\r\n        if not _PANDAS:\r\n            return dict(zip(list_of_points, his))\r\n        return pd.DataFrame(dict(zip(list_of_points, his)))", "response": "Returns a pandas DataFrame with the list of unique entries in the list_of_points."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the device point list and properties.", "response": "def _buildPointList(self):\r\n        \"\"\"\r\n        Upon connection to build the device point list and properties.\r\n        \"\"\"\r\n        try:\r\n            self.properties.pss.value = self.properties.network.read(\r\n                \"{} device {} protocolServicesSupported\".format(\r\n                    self.properties.address, self.properties.device_id\r\n                )\r\n            )\r\n\r\n        except NoResponseFromController as error:\r\n            self._log.error(\"Controller not found, aborting. ({})\".format(error))\r\n            return (\"Not Found\", \"\", [], [])\r\n\r\n        except SegmentationNotSupported as error:\r\n            self._log.warning(\"Segmentation not supported\")\r\n            self.segmentation_supported = False\r\n            self.new_state(DeviceDisconnected)\r\n\r\n        self.properties.name = self.properties.network.read(\r\n            \"{} device {} objectName\".format(\r\n                self.properties.address, self.properties.device_id\r\n            )\r\n        )\r\n\r\n        self._log.info(\r\n            \"Device {}:[{}] found... building points list\".format(\r\n                self.properties.device_id, self.properties.name\r\n            )\r\n        )\r\n        try:\r\n            self.properties.objects_list, self.points, self.trendlogs = self._discoverPoints(\r\n                self.custom_object_list\r\n            )\r\n            if self.properties.pollDelay > 0:\r\n                self.poll(delay=self.properties.pollDelay)\r\n        except NoResponseFromController as error:\r\n            self._log.error(\"Cannot retrieve object list, disconnecting...\")\r\n            self.segmentation_supported = False\r\n            self.new_state(DeviceDisconnected)\r\n        except IndexError as error:\r\n            self._log.error(\"Device creation failed... disconnecting\")\r\n            self.new_state(DeviceDisconnected)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary of all analog points and units state", "response": "def analog_units(self):\r\n        \"\"\"\r\n        Shortcut to retrieve all analog points units [Used by Bokeh trending feature]\r\n        \"\"\"\r\n        au = []\r\n        us = []\r\n        for each in self.points:\r\n            if isinstance(each, NumericPoint):\r\n                au.append(each.properties.name)\r\n                us.append(each.properties.units_state)\r\n        return dict(zip(au, us))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _findPoint(self, name, force_read=True):\r\n        for point in self.points:\r\n            if point.properties.name == name:\r\n                if force_read:\r\n                    point.value\r\n                return point\r\n        raise ValueError(\"{} doesn't exist in controller\".format(name))", "response": "Find a single point in the list of points with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(self, *, db=None):\r\n        if not self.properties.network:\r\n            self.new_state(DeviceFromDB)\r\n        else:\r\n            try:\r\n                name = self.properties.network.read(\r\n                    \"{} device {} objectName\".format(\r\n                        self.properties.address, self.properties.device_id\r\n                    )\r\n                )\r\n\r\n                segmentation = self.properties.network.read(\r\n                    \"{} device {} segmentationSupported\".format(\r\n                        self.properties.address, self.properties.device_id\r\n                    )\r\n                )\r\n\r\n                if not self.segmentation_supported or segmentation not in (\r\n                    \"segmentedTransmit\",\r\n                    \"segmentedBoth\",\r\n                ):\r\n                    segmentation_supported = False\r\n                    self._log.debug(\"Segmentation not supported\")\r\n                else:\r\n                    segmentation_supported = True\r\n\r\n                if name:\r\n                    if segmentation_supported:\r\n                        self.new_state(RPMDeviceConnected)\r\n                    else:\r\n                        self.new_state(RPDeviceConnected)\r\n\r\n            except SegmentationNotSupported:\r\n                self.segmentation_supported = False\r\n                self._log.warning(\r\n                    \"Segmentation not supported.... expect slow responses.\"\r\n                )\r\n                self.new_state(RPDeviceConnected)\r\n\r\n            except (NoResponseFromController, AttributeError) as error:\r\n                if self.properties.db_name:\r\n                    self.new_state(DeviceFromDB)\r\n                else:\r\n                    self._log.warning(\r\n                        \"Offline: provide database name to load stored data.\"\r\n                    )\r\n                    self._log.warning(\"Ex. controller.connect(db = 'backup')\")", "response": "Attempts to connect to a controller database. If unable attempts to connect to a controller database. If unable attempts to connect to a controller database. If unable attempts to connect to a controller database. If unable attempts to connect to a controller database. If unable attempts to connect to a controller database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(self, *, network=None, from_backup=None):\r\n        if network and from_backup:\r\n            raise WrongParameter(\"Please provide network OR from_backup\")\r\n\r\n        elif network:\r\n            self.properties.network = network\r\n            try:\r\n                name = self.properties.network.read(\r\n                    \"{} device {} objectName\".format(\r\n                        self.properties.address, self.properties.device_id\r\n                    )\r\n                )\r\n\r\n                segmentation = self.properties.network.read(\r\n                    \"{} device {} segmentationSupported\".format(\r\n                        self.properties.address, self.properties.device_id\r\n                    )\r\n                )\r\n\r\n                if not self.segmentation_supported or segmentation not in (\r\n                    \"segmentedTransmit\",\r\n                    \"segmentedBoth\",\r\n                ):\r\n                    segmentation_supported = False\r\n                    self._log.debug(\"Segmentation not supported\")\r\n                else:\r\n                    segmentation_supported = True\r\n\r\n                if name:\r\n                    if segmentation_supported:\r\n                        self.new_state(RPMDeviceConnected)\r\n                    else:\r\n                        self.new_state(RPDeviceConnected)\r\n                    # self.db.close()\r\n\r\n            except NoResponseFromController:\r\n                self._log.error(\"Unable to connect, keeping DB mode active\")\r\n\r\n        elif from_backup:\r\n            self.properties.db_name = from_backup.split(\".\")[0]\r\n            self._init_state()", "response": "Connect to a specific device."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the log level of all loggers.", "response": "def update_log_level(level=None, *, file=None, stderr=None, stdout=None):\n    \"\"\"\n    Typical usage : \n        Normal\n        BAC0.log_level(file='warning', stdout='warning', stderr='error')\n        Info on console....but not in file\n        BAC0.log_level(file='warning', stdout='info', stderr='error')\n        Debug\n        BAC0.log_level(file='debug', stdout='info', stderr='error')\n    \"\"\"\n    if level:\n        file = level\n        stderr = level\n        stdout = level\n    file = convert_level(file)\n    stderr = convert_level(stderr)\n    stdout = convert_level(stdout)\n    BAC0_logger = logging.getLogger(\"BAC0\")\n    #    if console:\n    #        BAC0_logger.setLevel(console)\n    #        BAC0_logger.warning('Changed log level of console to {}'.format(logging.getLevelName(level)))\n\n    for handler in BAC0_logger.handlers:\n        if file and handler.get_name() == \"file_handler\":\n            handler.setLevel(file)\n            BAC0_logger.info(\n                \"Changed log level of file to {}\".format(logging.getLevelName(file))\n            )\n        elif stdout and handler.get_name() == \"stdout\":\n            handler.setLevel(stdout)\n            BAC0_logger.info(\n                \"Changed log level of console stdout to {}\".format(\n                    logging.getLevelName(stdout)\n                )\n            )\n        elif stderr and handler.get_name() == \"stderr\":\n            handler.setLevel(stderr)\n            BAC0_logger.info(\n                \"Changed log level of console stderr to {}\".format(\n                    logging.getLevelName(stderr)\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef note_and_log(cls):\n    if hasattr(cls, \"DEBUG_LEVEL\"):\n        if cls.DEBUG_LEVEL == \"debug\":\n            file_level = logging.DEBUG\n            console_level = logging.DEBUG\n        elif cls.DEBUG_LEVEL == \"info\":\n            file_level = logging.INFO\n            console_level = logging.INFO\n    else:\n        file_level = logging.WARNING\n        console_level = logging.INFO\n    # Notes object\n    cls._notes = namedtuple(\"_notes\", [\"timestamp\", \"notes\"])\n    cls._notes.timestamp = []\n    cls._notes.notes = []\n\n    # Defining log object\n    cls.logname = \"{} | {}\".format(cls.__module__, cls.__name__)\n    root_logger = logging.getLogger()\n    cls._log = logging.getLogger(\"BAC0\")\n    if not len(root_logger.handlers):\n        root_logger.addHandler(cls._log)\n\n    # Console Handler\n    ch = logging.StreamHandler()\n    ch.set_name(\"stderr\")\n    ch2 = logging.StreamHandler(sys.stdout)\n    ch2.set_name(\"stdout\")\n    ch.setLevel(console_level)\n    ch2.setLevel(logging.CRITICAL)\n\n    formatter = logging.Formatter(\"{asctime} - {levelname:<8}| {message}\", style=\"{\")\n\n    # File Handler\n    _PERMISSION_TO_WRITE = True\n    logUserPath = expanduser(\"~\")\n    logSaveFilePath = join(logUserPath, \".BAC0\")\n\n    logFile = join(logSaveFilePath, \"BAC0.log\")\n    if not os.path.exists(logSaveFilePath):\n        try:\n            os.makedirs(logSaveFilePath)\n        except:\n            _PERMISSION_TO_WRITE = False\n    if _PERMISSION_TO_WRITE:\n        fh = FileHandler(logFile)\n        fh.set_name(\"file_handler\")\n        fh.setLevel(file_level)\n        fh.setFormatter(formatter)\n\n    ch.setFormatter(formatter)\n    ch2.setFormatter(formatter)\n    # Add handlers the first time only...\n    if not len(cls._log.handlers):\n        if _PERMISSION_TO_WRITE:\n            cls._log.addHandler(fh)\n        cls._log.addHandler(ch)\n        cls._log.addHandler(ch2)\n\n    #    cls._log.setLevel(logging.CRITICAL)\n\n    def log_title(self, title, args=None, width=35):\n        cls._log.debug(\"\")\n        cls._log.debug(\"#\" * width)\n        cls._log.debug(\"# {}\".format(title))\n        cls._log.debug(\"#\" * width)\n        if args:\n            cls._log.debug(\"{!r}\".format(args))\n            cls._log.debug(\"#\" * 35)\n\n    def log_subtitle(self, subtitle, args=None, width=35):\n        cls._log.debug(\"\")\n        cls._log.debug(\"=\" * width)\n        cls._log.debug(\"{}\".format(subtitle))\n        cls._log.debug(\"=\" * width)\n        if args:\n            cls._log.debug(\"{!r}\".format(args))\n            cls._log.debug(\"=\" * width)\n\n    def log(self, note, *, level=logging.DEBUG):\n        \"\"\"\n        Add a log entry...no note\n        \"\"\"\n        if not note:\n            raise ValueError(\"Provide something to log\")\n        note = \"{} | {}\".format(cls.logname, note)\n        cls._log.log(level, note)\n\n    def note(self, note, *, level=logging.INFO, log=True):\n        \"\"\"\n        Add note to the object. By default, the note will also\n        be logged\n        :param note: (str) The note itself\n        :param level: (logging.level)\n        :param log: (boolean) Enable or disable logging of note\n        \"\"\"\n        if not note:\n            raise ValueError(\"Provide something to log\")\n        note = \"{} | {}\".format(cls.logname, note)\n        cls._notes.timestamp.append(datetime.now())\n        cls._notes.notes.append(note)\n        if log:\n            cls.log(level, note)\n\n    @property\n    def notes(self):\n        \"\"\"\n        Retrieve notes list as a Pandas Series\n        \"\"\"\n        if not _PANDAS:\n            return dict(zip(self._notes.timestamp, self._notes.notes))\n        return pd.Series(self._notes.notes, index=self._notes.timestamp)\n\n    def clear_notes(self):\n        \"\"\"\n        Clear notes object\n        \"\"\"\n        cls._notes.timestamp = []\n        cls._notes.notes = []\n\n    # Add the functions to the decorated class\n    cls.clear_notes = clear_notes\n    cls.note = note\n    cls.notes = notes\n    cls.log = log\n    cls.log_title = log_title\n    cls.log_subtitle = log_subtitle\n    return cls", "response": "This is a class decorator that creates a new object that will be used to store the notes and logs in the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef discoverPoints(bacnetapp, address, devID):\n    pss = bacnetapp.read(\n        \"{} device {} protocolServicesSupported\".format(address, devID)\n    )\n    deviceName = bacnetapp.read(\"{} device {} objectName\".format(address, devID))\n\n    # print('Device {}- building points list'.format(deviceName))\n    objList = bacnetapp.read(\"{} device {] objectList\".format(address, devID))\n\n    newLine = []\n    result = []\n    points = []\n\n    for pointType, pointAddr in objList:\n\n        if \"binary\" in pointType:  # BI/BO/BV\n            newLine = [pointType, pointAddr]\n            infos = bacnetapp.readMultiple(\n                \"{} {} {} objectName description presentValue inactiveText activeText\".format(\n                    address, pointType, pointAddr\n                )\n            )\n\n            newLine.extend(infos[:-2])\n            newLine.extend([infos[-2:]])\n            newPoint = BooleanPoint(\n                pointType=newLine[0],\n                pointAddress=newLine[1],\n                pointName=newLine[2],\n                description=newLine[3],\n                presentValue=newLine[4],\n                units_state=newLine[5],\n            )\n\n        elif \"multiState\" in pointType:  # MI/MV/MO\n            newLine = [pointType, pointAddr]\n            newLine.extend(\n                bacnetapp.readMultiple(\n                    \"{} {} {} objectName description presentValue stateText\".format(\n                        address, pointType, pointAddr\n                    )\n                )\n            )\n\n            newPoint = EnumPoint(\n                pointType=newLine[0],\n                pointAddress=newLine[1],\n                pointName=newLine[2],\n                description=newLine[3],\n                presentValue=newLine[4],\n                units_state=newLine[5],\n            )\n\n        elif \"analog\" in pointType:  # AI/AO/AV\n            newLine = [pointType, pointAddr]\n            newLine.extend(\n                bacnetapp.readMultiple(\n                    \"{} {} {} objectName description presentValue units\".format(\n                        address, pointType, pointAddr\n                    )\n                )\n            )\n\n            newPoint = NumericPoint(\n                pointType=newLine[0],\n                pointAddress=newLine[1],\n                pointName=newLine[2],\n                description=newLine[3],\n                presentValue=newLine[4],\n                units_state=newLine[5],\n            )\n\n        else:\n            continue  # skip\n\n        result.append(newLine)\n        points.append(newPoint)\n\n    if _PANDA:\n        df = pd.DataFrame(\n            result,\n            columns=[\n                \"pointType\",\n                \"pointAddress\",\n                \"pointName\",\n                \"description\",\n                \"presentValue\",\n                \"units_state\",\n            ],\n        ).set_index([\"pointName\"])\n    else:\n        df = result\n\n    # print('Ready!')\n    return (deviceName, pss, objList, df, points)", "response": "Discover the BACnet points in a BACnet device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if this segment would be a smooth segment following the previous segment.", "response": "def is_smooth_from(self, previous):\n        \"\"\"Checks if this segment would be a smooth segment following the previous\"\"\"\n        if isinstance(previous, CubicBezier):\n            return (self.start == previous.end and\n                    (self.control1 - self.start) == (previous.end - previous.control2))\n        else:\n            return self.control1 == self.start"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the x y position at a certain position of the path", "response": "def point(self, pos):\n        \"\"\"Calculate the x,y position at a certain position of the path\"\"\"\n        return ((1 - pos) ** 3 * self.start) + \\\n               (3 * (1 - pos) ** 2 * pos * self.control1) + \\\n               (3 * (1 - pos) * pos ** 2 * self.control2) + \\\n               (pos ** 3 * self.end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef length(self, error=ERROR, min_depth=MIN_DEPTH):\n        start_point = self.point(0)\n        end_point = self.point(1)\n        return segment_length(self, 0, 1, start_point, end_point, error, min_depth, 0)", "response": "Calculate the length of the path up to a certain position"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_smooth_from(self, previous):\n        if isinstance(previous, QuadraticBezier):\n            return (self.start == previous.end and\n                    (self.control - self.start) == (previous.end - previous.control))\n        else:\n            return self.control == self.start", "response": "Checks if this segment would be a smooth segment following the previous segment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a blueprint on the WebSockets.", "response": "def register_blueprint(self, blueprint, **options):\n        '''\n        Registers a blueprint on the WebSockets.\n        '''\n        first_registration = False\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, \\\n                'A blueprint\\'s name collision occurred between %r and ' \\\n                '%r.  Both share the same name \"%s\".  Blueprints that ' \\\n                'are created on the fly need unique names.' % \\\n                (blueprint, self.blueprints[blueprint.name], blueprint.name)\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n        blueprint.register(self, options, first_registration)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadjusting the line number of an import.", "response": "def adjust_lineno(filename, lineno, name):\n    \"\"\"Adjust the line number of an import.\n\n    Needed because import statements can span multiple lines, and our lineno\n    is always the first line number.\n    \"\"\"\n    line = linecache.getline(filename, lineno)\n    # Hack warning: might be fooled by comments\n    rx = re.compile(r'\\b%s\\b' % re.escape(name) if name != '*' else '[*]')\n    while line and not rx.search(line):\n        lineno += 1\n        line = linecache.getline(filename, lineno)\n    return lineno"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_imports(filename):\n    with open(filename) as f:\n        root = ast.parse(f.read(), filename)\n    visitor = ImportFinder(filename)\n    visitor.visit(root)\n    return visitor.imports", "response": "Find all imported names in a given file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_imports_and_track_names(filename, warn_about_duplicates=False,\n                                 verbose=False):\n    \"\"\"Find all imported names in a given file.\n\n    Returns ``(imports, unused)``.  Both are lists of ImportInfo objects.\n    \"\"\"\n    with open(filename) as f:\n        root = ast.parse(f.read(), filename)\n    visitor = ImportFinderAndNameTracker(filename)\n    visitor.warn_about_duplicates = warn_about_duplicates\n    visitor.verbose = verbose\n    visitor.visit(root)\n    visitor.leaveAllScopes()\n    return visitor.imports, visitor.unused_names", "response": "Find all imported names in a given file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse one or more source files.", "response": "def parsePathname(self, pathname):\n        \"\"\"Parse one or more source files.\n\n        ``pathname`` may be a file name or a directory name.\n        \"\"\"\n        if os.path.isdir(pathname):\n            for root, dirs, files in os.walk(pathname):\n                dirs.sort()\n                files.sort()\n                for fn in files:\n                    # ignore emacsish junk\n                    if fn.endswith('.py') and not fn.startswith('.#'):\n                        self.parseFile(os.path.join(root, fn))\n        elif pathname.endswith('.importcache'):\n            self.readCache(pathname)\n        else:\n            self.parseFile(pathname)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the graph to a cache file.", "response": "def writeCache(self, filename):\n        \"\"\"Write the graph to a cache file.\"\"\"\n        with open(filename, 'wb') as f:\n            pickle.dump(self.modules, f)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef readCache(self, filename):\n        with open(filename, 'rb') as f:\n            self.modules = pickle.load(f)", "response": "Load the graph from a cache file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a single file.", "response": "def parseFile(self, filename):\n        \"\"\"Parse a single file.\"\"\"\n        modname = self.filenameToModname(filename)\n        module = Module(modname, filename)\n        self.modules[modname] = module\n        if self.trackUnusedNames:\n            module.imported_names, module.unused_names = \\\n                find_imports_and_track_names(filename,\n                                             self.warn_about_duplicates,\n                                             self.verbose)\n        else:\n            module.imported_names = find_imports(filename)\n            module.unused_names = None\n        dir = os.path.dirname(filename)\n        module.imports = set(\n            [self.findModuleOfName(imp.name, imp.level, filename, dir)\n             for imp in module.imported_names])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a filename to a module name.", "response": "def filenameToModname(self, filename):\n        \"\"\"Convert a filename to a module name.\"\"\"\n        for ext in reversed(self._exts):\n            if filename.endswith(ext):\n                filename = filename[:-len(ext)]\n                break\n        else:\n            self.warn(filename, '%s: unknown file name extension', filename)\n        filename = os.path.abspath(filename)\n        elements = filename.split(os.path.sep)\n        modname = []\n        while elements:\n            modname.append(elements[-1])\n            del elements[-1]\n            if not os.path.exists(os.path.sep.join(elements + ['__init__.py'])):\n                break\n        modname.reverse()\n        modname = \".\".join(modname)\n        return modname"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef findModuleOfName(self, dotted_name, level, filename, extrapath=None):\n        if dotted_name.endswith('.*'):\n            return dotted_name[:-2]\n        name = dotted_name\n\n        # extrapath is None only in a couple of test cases; in real life it's\n        # always present\n        if level and level > 1 and extrapath:\n            # strip trailing path bits for each extra level to account for\n            # relative imports\n            # from . import X has level == 1 and nothing is stripped (the level > 1 check accounts for this case)\n            # from .. import X has level == 2 and one trailing path component must go\n            # from ... import X has level == 3 and two trailing path components must go\n            extrapath = extrapath.split(os.path.sep)\n            level -= 1\n            extrapath = extrapath[0:-level]\n            extrapath = os.path.sep.join(extrapath)\n\n        while name:\n            candidate = self.isModule(name, extrapath)\n            if candidate:\n                return candidate\n            candidate = self.isPackage(name, extrapath)\n            if candidate:\n                return candidate\n            name = name[:name.rfind('.')]\n        self.warn(dotted_name, '%s: could not find %s', filename, dotted_name)\n        return dotted_name", "response": "Given a fully qualified name find what module contains it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nam the given dotted_name the name of a module?", "response": "def isModule(self, dotted_name, extrapath=None):\n        \"\"\"Is ``dotted_name`` the name of a module?\"\"\"\n        try:\n            return self._module_cache[(dotted_name, extrapath)]\n        except KeyError:\n            pass\n        if dotted_name in sys.modules or dotted_name in self.builtin_modules:\n            return dotted_name\n        filename = dotted_name.replace('.', os.path.sep)\n        if extrapath:\n            for ext in self._exts:\n                candidate = os.path.join(extrapath, filename) + ext\n                if os.path.exists(candidate):\n                    modname = self.filenameToModname(candidate)\n                    self._module_cache[(dotted_name, extrapath)] = modname\n                    return modname\n        try:\n            return self._module_cache[(dotted_name, None)]\n        except KeyError:\n            pass\n        for dir in self.path:\n            if os.path.isfile(dir):\n                if dir.endswith('.egg-info'):\n                    # distribute creates a setuptools-blah-blah.egg-info\n                    # that ends up in sys.path\n                    continue\n                try:\n                    zf = zipfile.ZipFile(dir)\n                except zipfile.BadZipfile:\n                    self.warn(dir, \"%s: not a directory or zip file\", dir)\n                    continue\n                names = zf.namelist()\n                for ext in self._exts:\n                    candidate = filename + ext\n                    if candidate in names:\n                        modname = filename.replace(os.path.sep, '.')\n                        self._module_cache[(dotted_name, extrapath)] = modname\n                        self._module_cache[(dotted_name, None)] = modname\n                        return modname\n            else:\n                for ext in self._exts:\n                    candidate = os.path.join(dir, filename) + ext\n                    if os.path.exists(candidate):\n                        modname = self.filenameToModname(candidate)\n                        self._module_cache[(dotted_name, extrapath)] = modname\n                        self._module_cache[(dotted_name, None)] = modname\n                        return modname\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isPackage(self, dotted_name, extrapath=None):\n        candidate = self.isModule(dotted_name + '.__init__', extrapath)\n        if candidate:\n            candidate = candidate[:-len(\".__init__\")]\n        return candidate", "response": "Is dotted_name the name of a package?"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines the package that contains the dotted_name.", "response": "def packageOf(self, dotted_name, packagelevel=None):\n        \"\"\"Determine the package that contains ``dotted_name``.\"\"\"\n        if '.' not in dotted_name:\n            return dotted_name\n        if not self.isPackage(dotted_name):\n            dotted_name = '.'.join(dotted_name.split('.')[:-1])\n        if packagelevel:\n            dotted_name = '.'.join(dotted_name.split('.')[:packagelevel])\n        return dotted_name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an alphabetical list of all modules.", "response": "def listModules(self):\n        \"\"\"Return an alphabetical list of all modules.\"\"\"\n        modules = list(self.modules.items())\n        modules.sort()\n        return [module for name, module in modules]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef packageGraph(self, packagelevel=None):\n        packages = {}\n        for module in self.listModules():\n            package_name = self.packageOf(module.modname, packagelevel)\n            if package_name not in packages:\n                dirname = os.path.dirname(module.filename)\n                packages[package_name] = Module(package_name, dirname)\n            package = packages[package_name]\n            for name in module.imports:\n                package_name = self.packageOf(name, packagelevel)\n                if package_name != package.modname: # no loops\n                    package.imports.add(package_name)\n        graph = ModuleGraph()\n        graph.modules = packages\n        return graph", "response": "Convert a module graph to a package graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef collapseCycles(self):\n        # This algorithm determines Strongly Connected Components.  Look it up.\n        # It is adapted to suit our data structures.\n        # Phase 0: prepare the graph\n        imports = {}\n        for u in self.modules:\n            imports[u] = set()\n            for v in self.modules[u].imports:\n                if v in self.modules: # skip external dependencies\n                    imports[u].add(v)\n        # Phase 1: order the vertices\n        visited = {}\n        for u in self.modules:\n            visited[u] = False\n        order = []\n        def visit1(u):\n            visited[u] = True\n            for v in imports[u]:\n                if not visited[v]:\n                    visit1(v)\n            order.append(u)\n        for u in self.modules:\n            if not visited[u]:\n                visit1(u)\n        order.reverse()\n        # Phase 2: compute the inverse graph\n        revimports = {}\n        for u in self.modules:\n            revimports[u] = set()\n        for u in self.modules:\n            for v in imports[u]:\n                revimports[v].add(u)\n        # Phase 3: determine the strongly connected components\n        components = {}\n        component_of = {}\n        for u in self.modules:\n            visited[u] = False\n        def visit2(u):\n            visited[u] = True\n            component.append(u)\n            for v in revimports[u]:\n                if not visited[v]:\n                    visit2(v)\n        for u in order:\n            if not visited[u]:\n                component = []\n                visit2(u)\n                component.sort()\n                node = ModuleCycle(component)\n                components[node.modname] = node\n                for modname in component:\n                    component_of[modname] = node\n        # Phase 4: construct the condensed graph\n        for node in components.values():\n            for modname in node.modnames:\n                for impname in imports[modname]:\n                    other = component_of[impname].modname\n                    if other != node.modname:\n                        node.imports.add(other)\n        graph = ModuleGraph()\n        graph.modules = components\n        return graph", "response": "Create a graph with cycles collapsed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nproduces a report of imported names.", "response": "def printImportedNames(self):\n        \"\"\"Produce a report of imported names.\"\"\"\n        for module in self.listModules():\n            print(\"%s:\" % module.modname)\n            print(\"  %s\" % \"\\n  \".join(imp.name for imp in module.imported_names))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nproduces a report of dependencies.", "response": "def printImports(self):\n        \"\"\"Produce a report of dependencies.\"\"\"\n        for module in self.listModules():\n            print(\"%s:\" % module.label)\n            if self.external_dependencies:\n                imports = list(module.imports)\n            else:\n                imports = [modname for modname in module.imports\n                           if modname in self.modules]\n            imports.sort()\n            print(\"  %s\" % \"\\n  \".join(imports))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef printUnusedImports(self):\n        for module in self.listModules():\n            names = [(unused.lineno, unused.name)\n                     for unused in module.unused_names]\n            names.sort()\n            for lineno, name in names:\n                if not self.all_unused:\n                    line = linecache.getline(module.filename, lineno)\n                    if '#' in line:\n                        # assume there's a comment explaining why it's not used\n                        continue\n                print(\"%s:%s: %s not used\" % (module.filename, lineno, name))", "response": "Produce a report of unused imports."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef printDot(self):\n        print(\"digraph ModuleDependencies {\")\n        print(\"  node[shape=box];\")\n        allNames = set()\n        nameDict = {}\n        for n, module in enumerate(self.listModules()):\n            module._dot_name = \"mod%d\" % n\n            nameDict[module.modname] = module._dot_name\n            print(\"  %s[label=\\\"%s\\\"];\" % (module._dot_name,\n                                           quote(module.label)))\n            allNames |= module.imports\n        print(\"  node[style=dotted];\")\n        if self.external_dependencies:\n            myNames = set(self.modules)\n            extNames = list(allNames - myNames)\n            extNames.sort()\n            for n, name in enumerate(extNames):\n                nameDict[name] = id = \"extmod%d\" % n\n                print(\"  %s[label=\\\"%s\\\"];\" % (id, name))\n        for modname, module in sorted(self.modules.items()):\n            for other in sorted(module.imports):\n                if other in nameDict:\n                    print(\"  %s -> %s;\" % (nameDict[module.modname],\n                                           nameDict[other]))\n        print(\"}\")", "response": "Produce a dependency graph in dot format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate all classes and put them in ctx", "response": "def _create_tags(ctx):\n    \"create all classes and put them in ctx\"\n\n    for (tag, info) in _TAGS.items():\n        class_name = tag.title()\n        quote_, compact, self_closing, docs = info\n\n        def __init__(self, *childs, **attrs):\n            TagBase.__init__(self, childs, attrs)\n\n        cls = type(class_name, (TagBase,), {\n            \"__doc__\": docs,\n            \"__init__\": __init__\n        })\n\n        cls.QUOTE = quote_\n        cls.COMPACT = compact\n        cls.SELF_CLOSING = self_closing\n\n        ctx[class_name] = cls"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an Element into a Tag.", "response": "def tag_from_element(el):\n    \"\"\"\n    Convert an Element into a Tag.\n\n    ``el`` is an instance of ``Element``. Returns an instance of the\n    corresponding subclass of ``TagBase``.\n    \"\"\"\n    tag = el.tag\n    namespace = None\n    if tag.startswith('{'):\n        # Strip namespace of the form \"{namespace}tag\"\n        namespace,tag = tag[1:].split('}')\n    try:\n        cls = globals()[tag.title()]\n        if not issubclass(cls, TagBase):\n            raise KeyError()\n    except KeyError:\n        raise ValueError(\"TagBase doesn't have a subclass for '%s'.\" % tag)\n    children = [tag_from_element(c) for c in el]\n    tag = cls(*children, **el.attrib)\n    tag.text = el.text\n    tag.tail = el.tail\n    if namespace:\n        tag.attrib['xmlns'] = namespace\n    return tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef html_to_tags(code):\n    code = ('<div>' + code + '</div>').encode('utf8')\n    el = ET.fromstring(code)\n    return [tag_from_element(c) for c in el]", "response": "Convert HTML code to tags."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _init_math_handler(self):\n        fields = self.settings.math_output.split(None, 1)\n        name = fields[0].lower()\n        option = fields[1] if len(fields) > 1 else None\n        if name == 'html':\n            option = self.settings.math_css or option\n            self.math_handler = HTMLMathHandler(css_filename=option)\n        elif name == 'mathml':\n            if option:\n                raise ValueError(('Math handler \"%s\" does not support ' +\n                                 'option \"%s\".') % (name, option))\n            self.math_handler = MathMLMathHandler()\n        elif name == 'mathjax':\n            # The MathJax handler can be configured via different ways:\n            #\n            # - By passing an additional JS url to \"--math-output\"\n            #   (to stay backwards-compatible with docutils)\n            #\n            # - By using \"--mathjax-opts\" (to stay backwards compatible\n            #   with the previous html5css3 mathjax postprocessor)\n            #\n            # - By using \"--mathjax-url\" and \"--mathjax-config\" (the\n            #   preferred way)\n            js_url = option\n            config = None\n            if self.settings.mathjax_opts:\n                parts = self.settings.mathjax_opts.split(',')\n                options = dict(part.split('=', 1) for part in parts)\n                js_url = options.get('url', js_url)\n                config = options.get('config', config)\n            js_url = self.settings.mathjax_url or js_url\n            config = self.settings.mathjax_config or config\n            self.math_handler = MathJaxMathHandler(js_url=js_url,\n                                                   config_filename=config)\n        elif name == 'latex':\n            if option:\n                raise ValueError(('Math handler \"%s\" does not support ' +\n                                 'option \"%s\".') % (name, option))\n            self.math_handler = LaTeXMathHandler()\n        else:\n            raise ValueError('Unknown math handler \"%s\".' % name)", "response": "Parse math configuration and set up math handler."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append_default_stylesheets(self):\n        for style in utils.get_stylesheet_list(self.settings):\n            self.css(style)", "response": "Appends the default styles defined on the translator settings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef css(self, path):\n        if self.settings.embed_content:\n            content = codecs.open(path, 'r', encoding='utf8').read()\n            tag = Style(content, type=\"text/css\")\n        else:\n            tag = Link(href=path, rel=\"stylesheet\", type_=\"text/css\")\n        self.head.append(tag)", "response": "Add a CSS file to the HTML."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef repr_args(args):\n    res = []\n    for x in args:\n        if isinstance(x, tuple) and len(x) == 2:\n            key, value = x\n            # todo: exclude this key if value is its default\n            res += [\"%s=%s\" % (key, repr_arg(value))]\n        else:\n            res += [repr_arg(x)]\n    return ', '.join(res)", "response": "formats a list of function arguments prettily but as working code\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef repr_arg(d):\n    if isinstance(d, dict):\n        # if d can be expressed in key=value syntax:\n        return \"{%s}\" % \", \".join(\n            \"%s: %s\" % (repr_arg(k), repr_arg(v)) for k, v in d.items())\n    if isinstance(d, list):\n        return \"[%s]\" % \", \".join(repr_arg(elem) for elem in d)\n    if isinstance(d, unicode):\n        try:\n            return repr(d.encode(\"ascii\"))\n        except UnicodeEncodeError:\n            return repr(d)\n\n    return repr(d)", "response": "formats a function argument prettily but as working code\nTaxonomy unicode encodable as ascii is formatted as str"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat a list of function arguments prettily not as code", "response": "def str_args(args):\n    \"\"\"formats a list of function arguments prettily not as code\n\n    (kwargs are tuples (argname, argvalue)\n    \"\"\"\n    res = []\n    for x in args:\n        if isinstance(x, tuple) and len(x) == 2:\n            key, value = x\n            if value and str_arg(value):\n                res += [\"%s=%s\" % (key, str_arg(value))]\n        else:\n            res += [str_arg(x)]\n    return ', '.join(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef str_arg(d):\n    if not d:\n        return None\n    if isinstance(d, dict):\n        if len(d) == 2 and d.get('type') == 'text' and 'value' in d:\n            return str_arg(d['value'])\n        if len(d) == 2 and d.get('type') == 'text' and 'subkey' in d:\n            return \".%s\" % d['subkey']\n        if d.get('type') == 'module':\n            return None\n        return \"{%s}\" % str_args(d.items())\n    if isinstance(d, list):\n        if len(d) == 1:\n            return str_arg(d[0])\n        return \"[%s]\" % \", \".join(str_arg(elem) for elem in d)\n    if isinstance(d, unicode):\n        return '\"%s\"' % d\n\n    return repr(d)", "response": "formats a function argument prettily not as code\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef asyncPipeHash(context=None, _INPUT=None, conf=None, **kwargs):\n    splits = yield asyncGetSplits(_INPUT, conf, **cdicts(opts, kwargs))\n    parsed = yield asyncDispatch(splits, *get_async_dispatch_funcs())\n    _OUTPUT = yield asyncStarMap(partial(maybeDeferred, parse_result), parsed)\n    returnValue(iter(_OUTPUT))", "response": "A string module that asynchronously hashes the given text. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pipe_tail(context=None, _INPUT=None, conf=None, **kwargs):\n    conf = DotDict(conf)\n    limit = conf.get('count', func=int, **kwargs)\n\n    for item in deque(_INPUT, limit):\n        yield item", "response": "A source that returns a specified number of items from the bottom of a feed. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_graph_component(graph):\n    components = map(partial(_visit, graph=graph), graph)\n    node_component = dict(_gen_node_component(components))\n    graph_component = {component: [] for component in components}\n    graph_component.update(\n        dict(_gen_graph_component(graph, node_component, _gen_graph_value)))\n\n    return graph_component", "response": "Identify strongly connected components in a graph using Tarjan s algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pipe_strregex(context=None, _INPUT=None, conf=None, **kwargs):\n    splits = get_splits(_INPUT, conf['RULE'], **cdicts(opts, kwargs))\n    parsed = utils.dispatch(splits, *get_dispatch_funcs(first=convert_func))\n    _OUTPUT = starmap(parse_result, parsed)\n    return _OUTPUT", "response": "A string module that replaces text using regexes. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_dependencies(pipe_def=None, pipe_generator=None):\n    if pipe_def:\n        pydeps = gen_dependencies(pipe_def)\n    elif pipe_generator:\n        pydeps = pipe_generator(Context(describe_dependencies=True))\n    else:\n        raise Exception('Must supply at least one kwarg!')\n\n    return sorted(set(pydeps))", "response": "Extract modules used by a pipe"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_input(pipe_def=None, pipe_generator=None):\n    if pipe_def:\n        pyinput = gen_input(pipe_def)\n    elif pipe_generator:\n        pyinput = pipe_generator(Context(describe_input=True))\n    else:\n        raise Exception('Must supply at least one kwarg!')\n\n    return sorted(list(pyinput))", "response": "Extract inputs required by a pipe"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pythonise(id, encoding='ascii'):\n    replace = {'-': '_', ':': '_', '/': '_'}\n    func = lambda id, pair: id.replace(pair[0], pair[1])\n    id = reduce(func, replace.iteritems(), id)\n    id = '_%s' % id if id[0] in string.digits else id\n    return id.encode(encoding)", "response": "Return a Python - friendly id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef etree_to_dict(element):\n    i = dict(element.items())\n    content = element.text.strip() if element.text else None\n    i.update({'content': content}) if content else None\n\n    if len(element.getchildren()):\n        for child in element.iterchildren():\n            tag = child.tag.split('}', 1)[-1]\n            new = etree_to_dict(child)\n            content = _make_content(i, tag, new)\n            i.update({tag: content}) if content else None\n\n            tag = 'content'\n            new = child.tail.strip() if child.tail else None\n            content = _make_content(i, tag, new)\n            i.update({tag: content}) if content else None\n    elif content and not set(i).difference(['content']):\n        # element is leaf node and doesn't have attributes\n        i = content\n\n    return i", "response": "Convert an eTree xml into dict imitating how Yahoo Pipes does it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy an iterable and delivers the items to multiple functions /--> foo2bar(_INPUT) --> \\ / \\ _INPUT ---> foo2baz(_INPUT) ---> _OUTPUT \\ / \\--> foo2qux(_INPUT) --> / One way to construct such a flow in code would be:: _INPUT = repeat('foo', 3) foo2bar = lambda word: word.replace('foo', 'bar') foo2baz = lambda word: word.replace('foo', 'baz') foo2qux = lambda word: word.replace('foo', 'quz') _OUTPUT = broadcast(_INPUT, foo2bar, foo2baz, foo2qux) _OUTPUT == repeat(('bar', 'baz', 'qux'), 3)", "response": "def broadcast(_INPUT, *funcs, **kwargs):\n    \"\"\"copies an iterable and delivers the items to multiple functions\n\n           /--> foo2bar(_INPUT) --> \\\n          /                          \\\n    _INPUT ---> foo2baz(_INPUT) ---> _OUTPUT\n          \\                          /\n           \\--> foo2qux(_INPUT) --> /\n\n    One way to construct such a flow in code would be::\n\n        _INPUT = repeat('foo', 3)\n        foo2bar = lambda word: word.replace('foo', 'bar')\n        foo2baz = lambda word: word.replace('foo', 'baz')\n        foo2qux = lambda word: word.replace('foo', 'quz')\n        _OUTPUT = broadcast(_INPUT, foo2bar, foo2baz, foo2qux)\n        _OUTPUT == repeat(('bar', 'baz', 'qux'), 3)\n    \"\"\"\n    map_func = kwargs.get('map_func', _map_func)\n    apply_func = kwargs.get('apply_func', _apply_func)\n    splits = izip(*tee(_INPUT, len(funcs)))\n    return map_func(partial(apply_func, funcs), splits)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dispatch(splits, *funcs, **kwargs):\n    map_func = kwargs.get('map_func', _map_func)\n    apply_func = kwargs.get('apply_func', _apply_func)\n    return map_func(partial(apply_func, funcs), splits)", "response": "takes multiple iterables and dispatches them to multiple functions returning a single object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a user parameter from the console or from a system Audience", "response": "def get_input(context, conf):\n    \"\"\"Gets a user parameter, either from the console or from an outer\n        submodule/system\n\n       Assumes conf has name, default, prompt and debug\n    \"\"\"\n    name = conf['name']['value']\n    prompt = conf['prompt']['value']\n    default = conf['default']['value'] or conf['debug']['value']\n\n    if context.submodule or context.inputs:\n        value = context.inputs.get(name, default)\n    elif not context.test:\n        # we skip user interaction during tests\n        raw = raw_input(\"%s (default=%s) \" % (encode(prompt), encode(default)))\n        value = raw or default\n    else:\n        value = default\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url_quote(url):\n    try:\n        return quote(url, safe=URL_SAFE)\n    except KeyError:\n        return quote(encode(url), safe=URL_SAFE)", "response": "Ensure url is valid"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef multi_substitute(word, rules):\n    flags = rules[0]['flags']\n\n    # Create a combined regex from the rules\n    tuples = ((p, r['match']) for p, r in enumerate(rules))\n    regexes = ('(?P<match_%i>%s)' % (p, r) for p, r in tuples)\n    pattern = '|'.join(regexes)\n    regex = re.compile(pattern, flags)\n    resplit = re.compile('\\$(\\d+)')\n\n    # For each match, look-up corresponding replace value in dictionary\n    rules_in_series = ifilter(itemgetter('series'), rules)\n    rules_in_parallel = (r for r in rules if not r['series'])\n\n    try:\n        has_parallel = [rules_in_parallel.next()]\n    except StopIteration:\n        has_parallel = []\n\n    # print('================')\n    # pprint(rules)\n    # print('word:', word)\n    # print('pattern', pattern)\n    # print('flags', flags)\n\n    for _ in chain(rules_in_series, has_parallel):\n        # print('~~~~~~~~~~~~~~~~')\n        # print('new round')\n        # print('word:', word)\n        # found = list(regex.finditer(word))\n        # matchitems = [match.groupdict().items() for match in found]\n        # pprint(matchitems)\n        prev_name = None\n        prev_is_series = None\n        i = 0\n\n        for match in regex.finditer(word):\n            item = ifilter(itemgetter(1), match.groupdict().iteritems()).next()\n\n            # print('----------------')\n            # print('groupdict:', match.groupdict().items())\n            # print('item:', item)\n\n            if not item:\n                continue\n\n            name = item[0]\n            rule = rules[int(name[6:])]\n            series = rule.get('series')\n            kwargs = {'count': rule['count'], 'series': series}\n            is_previous = name is prev_name\n            singlematch = kwargs['count'] is 1\n            is_series = prev_is_series or kwargs['series']\n            isnt_previous = bool(prev_name) and not is_previous\n\n            if (is_previous and singlematch) or (isnt_previous and is_series):\n                continue\n\n            prev_name = name\n            prev_is_series = series\n\n            if resplit.findall(rule['replace']):\n                splits = resplit.split(rule['replace'])\n                words = _gen_words(match, splits)\n            else:\n                splits = rule['replace']\n                start = match.start() + i\n                end = match.end() + i\n                words = [word[:start], splits, word[end:]]\n                i += rule['offset']\n\n            # words = list(words)\n            word = ''.join(words)\n\n            # print('name:', name)\n            # print('prereplace:', rule['replace'])\n            # print('splits:', splits)\n            # print('resplits:', resplit.findall(rule['replace']))\n            # print('groups:', filter(None, match.groups()))\n            # print('i:', i)\n            # print('words:', words)\n            # print('range:', match.start(), '-', match.end())\n            # print('replace:', word)\n\n    # print('substitution:', word)\n    return word", "response": "Apply multiple regex rules to word"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef asyncPipeItembuilder(context=None, _INPUT=None, conf=None, **kwargs):\n    pkwargs = cdicts(opts, kwargs)\n    asyncFuncs = yield asyncGetSplits(None, conf['attrs'], **pkwargs)\n    _input = yield _INPUT\n    finite = utils.finitize(_input)\n    inputs = imap(DotDict, finite)\n    pieces = yield asyncImap(asyncFuncs[0], inputs)\n    results = imap(utils.parse_params, pieces)\n    _OUTPUT = imap(DotDict, results)\n    returnValue(_OUTPUT)", "response": "A source that asynchronously builds an item. Loopable. _INPUT is the source that asynchronously builds an item. Loopable. _OUTPUT is the output of asyncPipeItembuilder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef asyncPipeFetch(context=None, _INPUT=None, conf=None, **kwargs):\n    splits = yield asyncGetSplits(_INPUT, conf['URL'], **cdicts(opts, kwargs))\n    items = yield asyncStarMap(asyncParseResult, splits)\n    _OUTPUT = utils.multiplex(items)\n    returnValue(_OUTPUT)", "response": "A source that asynchronously fetches and parses one or more feeds to\n    return the feed entries. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asyncImap(asyncCallable, *iterables):\n    deferreds = imap(asyncCallable, *iterables)\n    return gatherResults(deferreds, consumeErrors=True)", "response": "async. imap for deferred callables"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asyncStarCmap(asyncCallable, iterable):\n    results = []\n    yield coopStar(asyncCallable, results.append, iterable)\n    returnValue(results)", "response": "A cooperative multitasking generator for deferred callables using cooperative multitasking\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef asyncPipeUniq(context=None, _INPUT=None, conf=None, **kwargs):\n    _input = yield _INPUT\n    asyncFuncs = yield asyncGetSplits(None, conf, **cdicts(opts, kwargs))\n    pieces = yield asyncFuncs[0]()\n    _pass = yield asyncFuncs[2]()\n    _OUTPUT = _input if _pass else unique_items(_input, pieces.field)\n    returnValue(_OUTPUT)", "response": "A source that asynchronously filters out non unique items according to the specified field. Not loopable. Not loopable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pipe_uniq(context=None, _INPUT=None, conf=None, **kwargs):\n    funcs = get_splits(None, conf, **cdicts(opts, kwargs))\n    pieces, _pass = funcs[0](), funcs[2]()\n    _OUTPUT = _INPUT if _pass else unique_items(_INPUT, pieces.field)\n    return _OUTPUT", "response": "A module that returns a source that filters out non unique items according to the specified\n    field. Not loopable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pipe_sort(context=None, _INPUT=None, conf=None, **kwargs):\n    test = kwargs.pop('pass_if', None)\n    _pass = utils.get_pass(test=test)\n    key_defs = imap(DotDict, utils.listize(conf['KEY']))\n    get_value = partial(utils.get_value, **kwargs)\n    parse_conf = partial(utils.parse_conf, parse_func=get_value, **kwargs)\n    keys = imap(parse_conf, key_defs)\n    order = ('%s%s' % ('-' if k.dir == 'DESC' else '', k.field) for k in keys)\n    comparers = map(get_comparer, order)\n    cmp_func = partial(multikeysort, comparers=comparers)\n    _OUTPUT = _INPUT if _pass else iter(sorted(_INPUT, cmp=cmp_func))\n    return _OUTPUT", "response": "A module that returns a source that sorts the items in a sequence according to the specified key. Not loopable. Not lazy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pipe_createrss(context=None, _INPUT=None, conf=None, **kwargs):\n    conf = DotDict(conf)\n\n    for item in _INPUT:\n        item = DotDict(item)\n\n        yield {\n            value: item.get(conf.get(key, **kwargs))\n            for key, value in RSS_FIELDS.items()}", "response": "A source that converts a source into an RSS stream. Not loopable. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef asyncPipeRegex(context=None, _INPUT=None, conf=None, **kwargs):\n    splits = yield asyncGetSplits(_INPUT, conf['RULE'], **cdicts(opts, kwargs))\n    asyncConvert = partial(maybeDeferred, convert_func)\n    asyncFuncs = get_async_dispatch_funcs('pass', asyncConvert)\n    parsed = yield asyncDispatch(splits, *asyncFuncs)\n    _OUTPUT = yield maybeDeferred(parse_results, parsed)\n    returnValue(iter(_OUTPUT))", "response": "A source that asynchronously replaces text in items using regexes. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pipe_regex(context=None, _INPUT=None, conf=None, **kwargs):\n    splits = get_splits(_INPUT, conf['RULE'], **cdicts(opts, kwargs))\n    parsed = utils.dispatch(splits, *get_dispatch_funcs('pass', convert_func))\n    _OUTPUT = parse_results(parsed)\n    return _OUTPUT", "response": "A module that allows you to use regex operator to replace text in items using regexes. Not loopable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asyncPipeUniq(context=None, _INPUT=None, conf=None, **kwargs):\n    _input = yield _INPUT\n    asyncFuncs = yield asyncGetSplits(None, conf, **cdicts(opts, kwargs))\n    pieces = yield asyncFuncs[0]()\n    _pass = yield asyncFuncs[2]()\n\n    if _pass:\n        _OUTPUT = _input\n    else:\n        start = int(pieces.start)\n        stop = start + int(pieces.count)\n        _OUTPUT = islice(_input, start, stop)\n\n    returnValue(_OUTPUT)", "response": "A source that asynchronously returns a specified number of items from\n    the top of a feed. Not loopable. Not loopable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pipe_truncate(context=None, _INPUT=None, conf=None, **kwargs):\n    funcs = get_splits(None, conf, **cdicts(opts, kwargs))\n    pieces, _pass = funcs[0](), funcs[2]()\n\n    if _pass:\n        _OUTPUT = _INPUT\n    else:\n        try:\n            start = int(pieces.start)\n        except AttributeError:\n            start = 0\n\n        stop = start + int(pieces.count)\n        _OUTPUT = islice(_INPUT, start, stop)\n\n    return _OUTPUT", "response": "A module that returns a specified number of items from the top of a\n    feed. Not loopable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef asyncPipeExchangerate(context=None, _INPUT=None, conf=None, **kwargs):\n    offline = conf.get('offline', {}).get('value')\n    # TODO add async rate data fetching\n    rate_data = get_offline_rate_data() if offline else get_rate_data()\n    rates = parse_request(rate_data)\n    splits = yield asyncGetSplits(_INPUT, conf, **cdicts(opts, kwargs))\n    parsed = yield asyncDispatch(splits, *get_async_dispatch_funcs())\n    _OUTPUT = starmap(partial(parse_result, rates=rates), parsed)\n    returnValue(iter(_OUTPUT))", "response": "A string module that asynchronously retrieves the current exchange rate for a given currency pair. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pipe_strtransform(context=None, _INPUT=None, conf=None, **kwargs):\n    splits = get_splits(_INPUT, conf, **cdicts(opts, kwargs))\n    parsed = utils.dispatch(splits, *get_dispatch_funcs())\n    _OUTPUT = starmap(parse_result, parsed)\n    return _OUTPUT", "response": "A string module that splits a string into tokens delimited by\n    separators. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pipe_dateformat(context=None, _INPUT=None, conf=None, **kwargs):\n    conf = DotDict(conf)\n    loop_with = kwargs.pop('with', None)\n    date_format = conf.get('format', **kwargs)\n    # timezone = conf.get('timezone', **kwargs)\n\n    for item in _INPUT:\n        _with = item.get(loop_with, **kwargs) if loop_with else item\n\n        try:\n            # todo: check that all PHP formats are covered by Python\n            date_string = time.strftime(date_format, _with)\n        except TypeError as e:\n            if context and context.verbose:\n                print 'Error formatting date: %s' % item\n                print e\n\n            continue\n        else:\n            yield date_string", "response": "A source that formats a datetime value. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pipe_subelement(context=None, _INPUT=None, conf=None, **kwargs):\n    path = DotDict(conf).get('path', **kwargs)\n\n    for item in _INPUT:\n        element = DotDict(item).get(path, **kwargs)\n\n        for i in utils.gen_items(element):\n            yield {'content': i}\n\n        if item.get('forever'):\n            # _INPUT is pipeforever and not a loop,\n            # so we just yield our item once\n            break", "response": "A source that returns a list of sub - elements from a feed. Not loopable. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pipe_feedautodiscovery(context=None, _INPUT=None, conf=None, **kwargs):\n    conf = DotDict(conf)\n    urls = utils.listize(conf['URL'])\n\n    for item in _INPUT:\n        for item_url in urls:\n            url = utils.get_value(DotDict(item_url), DotDict(item), **kwargs)\n            url = utils.get_abspath(url)\n\n            if context and context.verbose:\n                print \"pipe_feedautodiscovery loading:\", url\n\n            for entry in autorss.getRSSLink(url.encode('utf-8')):\n                yield {'link': entry}\n                # todo: add rel, type, title\n\n        if item.get('forever'):\n            # _INPUT is pipeforever and not a loop,\n            # so we just yield our item once\n            break", "response": "A source that searches for and returns feed links found in a page. Loopable. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pipe_urlinput(context=None, _INPUT=None, conf=None, **kwargs):\n    value = utils.get_input(context, conf)\n    value = utils.url_quote(value)\n\n    while True:\n        yield value", "response": "A source that prompts the user for a url and yields it forever. Not loopable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pipe_yql(context=None, _INPUT=None, conf=None, **kwargs):\n    # todo: get from a config/env file\n    url = \"http://query.yahooapis.com/v1/public/yql\"\n    conf = DotDict(conf)\n    query = conf['yqlquery']\n\n    for item in _INPUT:\n        item = DotDict(item)\n        yql = utils.get_value(query, item, **kwargs)\n\n        # note: we use the default format of xml since json loses some\n        # structure\n        # todo: diagnostics=true e.g. if context.test\n        # todo: consider paging for large result sets\n        r = requests.get(url, params={'q': yql}, stream=True)\n\n        # Parse the response\n        tree = parse(r.raw)\n\n        if context and context.verbose:\n            print \"pipe_yql loading xml:\", yql\n\n        root = tree.getroot()\n\n        # note: query also has row count\n        results = root.find('results')\n\n        # Convert xml into generation of dicts\n        for element in results.getchildren():\n            yield utils.etree_to_dict(element)\n\n        if item.get('forever'):\n            # _INPUT is pipeforever and not a loop,\n            # so we just yield our item once\n            break", "response": "A source that issues YQL queries. Loopable. _INPUT is a source that returns a list of items or fields. Loopable. _OUTPUT is a generator that yields the results of the YQL query. Loopable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize_number(x, fmt=SER_BINARY, outlen=None):\n    ret = b''\n    if fmt == SER_BINARY:\n        while x:\n            x, r = divmod(x, 256)\n            ret = six.int2byte(int(r)) + ret\n        if outlen is not None:\n            assert len(ret) <= outlen\n            ret = ret.rjust(outlen, b'\\0')\n        return ret\n    assert fmt == SER_COMPACT\n    while x:\n        x, r = divmod(x, len(COMPACT_DIGITS))\n        ret = COMPACT_DIGITS[r:r + 1] + ret\n    if outlen is not None:\n        assert len(ret) <= outlen\n        ret = ret.rjust(outlen, COMPACT_DIGITS[0:1])\n    return ret", "response": "Serializes x into a string of length outlen in format fmt."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mod_issquare(a, p):\n    if not a:\n        return True\n    p1 = p // 2\n    p2 = pow(a, p1, p)\n    return p2 == 1", "response": "Returns whether a is a square modulo p."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mod_root(a, p):\n    if a == 0:\n        return 0\n    if not mod_issquare(a, p):\n        raise ValueError\n    n = 2\n    while mod_issquare(n, p):\n        n += 1\n    q = p - 1\n    r = 0\n    while not q.getbit(r):\n        r += 1\n    q = q >> r\n    y = pow(n, q, p)\n    h = q >> 1\n    b = pow(a, h, p)\n    x = (a * b) % p\n    b = (b * x) % p\n    while b != 1:\n        h = (b * b) % p\n        m = 1\n        while h != 1:\n            h = (h * h) % p\n            m += 1\n        h = gmpy.mpz(0)\n        h = h.setbit(r - m - 1)\n        t = pow(y, h, p)\n        y = (t * t) % p\n        r = m\n        x = (x * t) % p\n        b = (b * y) % p\n    return x", "response": "Return a root of a modulo p"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encrypt(s, pk, pk_format=SER_COMPACT, mac_bytes=10, curve=None):\n    curve = (Curve.by_pk_len(len(pk)) if curve is None\n             else Curve.by_name(curve))\n    p = curve.pubkey_from_string(pk, pk_format)\n    return p.encrypt(s, mac_bytes)", "response": "Encrypts s for public key pk"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencrypting in_file to out_file for pubkey pk", "response": "def encrypt_file(in_path_or_file, out_path_or_file, pk, pk_format=SER_COMPACT,\n                 mac_bytes=10, chunk_size=4096, curve=None):\n    \"\"\" Encrypts `in_file' to `out_file' for pubkey `pk' \"\"\"\n    close_in, close_out = False, False\n    in_file, out_file = in_path_or_file, out_path_or_file\n    try:\n        if stringlike(in_path_or_file):\n            in_file = open(in_path_or_file, 'rb')\n            close_in = True\n        if stringlike(out_path_or_file):\n            out_file = open(out_path_or_file, 'wb')\n            close_out = True\n        _encrypt_file(in_file, out_file, pk, pk_format, mac_bytes, chunk_size,\n                      curve)\n    finally:\n        if close_out:\n            out_file.close()\n        if close_in:\n            in_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify(s, sig, pk, sig_format=SER_COMPACT, pk_format=SER_COMPACT,\n           curve=None):\n    \"\"\" Verifies that `sig' is a signature of pubkey `pk' for the\n        message `s'. \"\"\"\n    if isinstance(s, six.text_type):\n        raise ValueError(\"Encode `s` to a bytestring yourself to\" +\n                         \" prevent problems with different default encodings\")\n    curve = (Curve.by_pk_len(len(pk)) if curve is None\n             else Curve.by_name(curve))\n    p = curve.pubkey_from_string(pk, pk_format)\n    return p.verify(hashlib.sha512(s).digest(), sig, sig_format)", "response": "Verifies that s is a signature of pk for the\n        message s."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsigning s with passphrase passphrase", "response": "def sign(s, passphrase, sig_format=SER_COMPACT, curve='secp160r1'):\n    \"\"\" Signs `s' with passphrase `passphrase' \"\"\"\n    if isinstance(s, six.text_type):\n        raise ValueError(\"Encode `s` to a bytestring yourself to\" +\n                         \" prevent problems with different default encodings\")\n    curve = Curve.by_name(curve)\n    privkey = curve.passphrase_to_privkey(passphrase)\n    return privkey.sign(hashlib.sha512(s).digest(), sig_format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random keypair.", "response": "def generate_keypair(curve='secp160r1', randfunc=None):\n    \"\"\" Convenience function to generate a random\n        new keypair (passphrase, pubkey). \"\"\"\n    if randfunc is None:\n        randfunc = Crypto.Random.new().read\n    curve = Curve.by_name(curve)\n    raw_privkey = randfunc(curve.order_len_bin)\n    privkey = serialize_number(deserialize_number(raw_privkey), SER_COMPACT)\n    pubkey = str(passphrase_to_pubkey(privkey))\n    return (privkey, pubkey)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify(self, h, sig, sig_fmt=SER_BINARY):\n        s = deserialize_number(sig, sig_fmt)\n        return self.p._ECDSA_verify(h, s)", "response": "Verifies that sig is a signature for a message with\n            SHA - 512 hash h."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a file like object f encrypted for this pubkey and written to f.", "response": "def encrypt_to(self, f, mac_bytes=10):\n        \"\"\" Returns a file like object `ef'.  Anything written to `ef'\n            will be encrypted for this pubkey and written to `f'. \"\"\"\n        ctx = EncryptionContext(f, self.p, mac_bytes)\n        yield ctx\n        ctx.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encrypt(self, s, mac_bytes=10):\n        if isinstance(s, six.text_type):\n            raise ValueError(\n                \"Encode `s` to a bytestring yourself to\" +\n                \" prevent problems with different default encodings\")\n        out = BytesIO()\n        with self.encrypt_to(out, mac_bytes) as f:\n            f.write(s)\n        return out.getvalue()", "response": "Encrypt s for this pubkey."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsigning the message with SHA - 512 hash h with this private key.", "response": "def sign(self, h, sig_format=SER_BINARY):\n        \"\"\" Signs the message with SHA-512 hash `h' with this private key. \"\"\"\n        outlen = (self.curve.sig_len_compact if sig_format == SER_COMPACT\n                  else self.curve.sig_len_bin)\n        sig = self._ECDSA_sign(h)\n        return serialize_number(sig, sig_format, outlen)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a 32 byte hash to an exponent", "response": "def hash_to_exponent(self, h):\n        \"\"\" Converts a 32 byte hash to an exponent \"\"\"\n        ctr = Crypto.Util.Counter.new(128, initial_value=0)\n        cipher = Crypto.Cipher.AES.new(h,\n                                       Crypto.Cipher.AES.MODE_CTR, counter=ctr)\n        buf = cipher.encrypt(b'\\0' * self.order_len_bin)\n        return self._buf_to_exponent(buf)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefining how to parse CLI arguments for the DomainTools API Client.", "response": "def parse(args=None):\n    \"\"\"Defines how to parse CLI arguments for the DomainTools API\"\"\"\n    parser = argparse.ArgumentParser(description='The DomainTools CLI API Client')\n    parser.add_argument('-u', '--username', dest='user', default='', help='API Username')\n    parser.add_argument('-k', '--key', dest='key', default='', help='API Key')\n    parser.add_argument('-c', '--credfile', dest='credentials', default=os.path.expanduser('~/.dtapi'),\n                        help='Optional file with API username and API key, one per line.')\n    parser.add_argument('-l', '--rate-limit', dest='rate_limit', action='store_true', default=False,\n                        help='Rate limit API calls against the API based on per minute limits.')\n    parser.add_argument('-f', '--format', dest='format', choices=['list', 'json', 'xml', 'html'], default='json')\n    parser.add_argument('-o', '--outfile', dest='out_file', type=argparse.FileType('wbU'), default=sys.stdout,\n                        help='Output file (defaults to stdout)')\n    parser.add_argument('-v', '--version', action='version', version='DomainTools CLI API Client {0}'.format(version))\n    parser.add_argument('--no-https', dest='https', action='store_false', default=True,\n                        help='Use HTTP instead of HTTPS.')\n    parser.add_argument('--no-verify-ssl', dest='verify_ssl', action='store_false', default=True,\n                        help='Skip verification of SSL certificate when making HTTPs API calls')\n\n    subparsers = parser.add_subparsers(help='The name of the API call you wish to perform (`whois` for example)',\n                                       dest='api_call')\n    subparsers.required = True\n    for api_call in API_CALLS:\n        api_method = getattr(API, api_call)\n        subparser = subparsers.add_parser(api_call, help=api_method.__name__)\n        spec = inspect.getargspec(api_method)\n\n        for argument_name, default in reversed(list(zip_longest(reversed(spec.args or []),\n                                                                reversed(spec.defaults or []), fillvalue='EMPTY'))):\n            if argument_name == 'self':\n                continue\n            elif default == 'EMPTY':\n                subparser.add_argument(argument_name)\n            else:\n                subparser.add_argument('--{0}'.format(argument_name.replace('_', '-')), dest=argument_name,\n                                       default=default, nargs='*')\n\n    arguments = vars(parser.parse_args(args) if args else parser.parse_args())\n    if not arguments.get('user', None) or not arguments.get('key', None):\n        try:\n            with open(arguments.pop('credentials')) as credentials:\n                arguments['user'], arguments['key'] = credentials.readline().strip(), credentials.readline().strip()\n        except Exception:\n            pass\n\n    for key, value in arguments.items():\n        if value in ('-', ['-']):\n            arguments[key] == (line.strip() for line in sys.stdin.readlines())\n        elif value == []:\n            arguments[key] = True\n        elif type(value) == list and len(value) == 1:\n            arguments[key] = value[0]\n\n    return (arguments.pop('out_file'), arguments.pop('format'), arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(): # pragma: no cover\n    out_file, out_format, arguments = parse()\n    user, key = arguments.pop('user', None), arguments.pop('key', None)\n    if not user or not key:\n        sys.stderr.write('Credentials are required to perform API calls.\\n')\n        sys.exit(1)\n\n    api = API(user, key, https=arguments.pop('https'), verify_ssl=arguments.pop('verify_ssl'),\n              rate_limit=arguments.pop('rate_limit'))\n    response = getattr(api, arguments.pop('api_call'))(**arguments)\n    output = str(getattr(response, out_format) if out_format != 'list' else response.as_list())\n    out_file.write(output if output.endswith('\\n') else output + '\\n')", "response": "Defines how to start the CLI for the DomainTools API"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef permission_required(perm, *lookup_variables, **kwargs):\n    login_url = kwargs.pop('login_url', settings.LOGIN_URL)\n    redirect_field_name = kwargs.pop('redirect_field_name', REDIRECT_FIELD_NAME)\n    redirect_to_login = kwargs.pop('redirect_to_login', True)\n\n    def decorate(view_func):\n        def decorated(request, *args, **kwargs):\n            if request.user.is_authenticated():\n                params = []\n                for lookup_variable in lookup_variables:\n                    if isinstance(lookup_variable, string_types):\n                        value = kwargs.get(lookup_variable, None)\n                        if value is None:\n                            continue\n                        params.append(value)\n                    elif isinstance(lookup_variable, (tuple, list)):\n                        model, lookup, varname = lookup_variable\n                        value = kwargs.get(varname, None)\n                        if value is None:\n                            continue\n                        if isinstance(model, string_types):\n                            model_class = apps.get_model(*model.split(\".\"))\n                        else:\n                            model_class = model\n                        if model_class is None:\n                            raise ValueError(\n                                \"The given argument '%s' is not a valid model.\" % model)\n                        if (inspect.isclass(model_class) and\n                                not issubclass(model_class, Model)):\n                            raise ValueError(\n                                'The argument %s needs to be a model.' % model)\n                        obj = get_object_or_404(model_class, **{lookup: value})\n                        params.append(obj)\n                check = get_check(request.user, perm)\n                granted = False\n                if check is not None:\n                    granted = check(*params)\n                if granted or request.user.has_perm(perm):\n                    return view_func(request, *args, **kwargs)\n            if redirect_to_login:\n                path = urlquote(request.get_full_path())\n                tup = login_url, redirect_field_name, path\n                return HttpResponseRedirect('%s?%s=%s' % tup)\n            return permission_denied(request)\n        return wraps(view_func)(decorated)\n    return decorate", "response": "Decorator for views that checks whether a user has a particular permission on a particular object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning all permissions associated with the given obj and user .", "response": "def get_permissions(parser, token):\n    \"\"\"\n    Retrieves all permissions associated with the given obj and user\n    and assigns the result to a context variable.\n\n    Syntax::\n\n        {% get_permissions obj %}\n        {% for perm in permissions %}\n            {{ perm }}\n        {% endfor %}\n\n        {% get_permissions obj as \"my_permissions\" %}\n        {% get_permissions obj for request.user as \"my_permissions\" %}\n\n    \"\"\"\n    return PermissionsForObjectNode.handle_token(parser, token, approved=True,\n                                                 name='\"permissions\"')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_permission_requests(parser, token):\n    return PermissionsForObjectNode.handle_token(parser, token,\n                                                 approved=False,\n                                                 name='\"permission_requests\"')", "response": "Returns all permissions requests associated with the given obj and user\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_permission(parser, token):\n    return PermissionForObjectNode.handle_token(parser, token,\n                                                approved=True,\n                                                name='\"permission\"')", "response": "Returns a permission for the given token."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_permission_request(parser, token):\n    return PermissionForObjectNode.handle_token(\n        parser, token, approved=False, name='\"permission_request\"')", "response": "Returns a permission request for the given token."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender a html link to the delete view of the given permission.", "response": "def permission_delete_link(context, perm):\n    \"\"\"\n    Renders a html link to the delete view of the given permission. Returns\n    no content if the request-user has no permission to delete foreign\n    permissions.\n    \"\"\"\n    user = context['request'].user\n    if user.is_authenticated():\n        if (user.has_perm('authority.delete_foreign_permissions') or\n                user.pk == perm.creator.pk):\n            return base_link(context, perm, 'authority-delete-permission')\n    return {'url': None}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef permission_request_delete_link(context, perm):\n    user = context['request'].user\n    if user.is_authenticated():\n        link_kwargs = base_link(context, perm,\n                                'authority-delete-permission-request')\n        if user.has_perm('authority.delete_permission'):\n            link_kwargs['is_requestor'] = False\n            return link_kwargs\n        if not perm.approved and perm.user == user:\n            link_kwargs['is_requestor'] = True\n            return link_kwargs\n    return {'url': None}", "response": "Renders a html link to the delete view of the given permission request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef permission_request_approve_link(context, perm):\n    user = context['request'].user\n    if user.is_authenticated():\n        if user.has_perm('authority.approve_permission_requests'):\n            return base_link(context, perm, 'authority-approve-permission-request')\n    return {'url': None}", "response": "Renders a html link to the approve view of the given permission request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving a variable out of quotes", "response": "def resolve(self, var, context):\n        \"\"\"Resolves a variable out of context if it's not in quotes\"\"\"\n        if var is None:\n            return var\n        if var[0] in ('\"', \"'\") and var[-1] == var[0]:\n            return var[1:-1]\n        else:\n            return template.Variable(var).resolve(context)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget objects that have Group perm permission on", "response": "def group_permissions(self, group, perm, obj, approved=True):\n        \"\"\"\n        Get objects that have Group perm permission on\n        \"\"\"\n        return self.get_for_model(obj).select_related(\n            'user', 'group', 'creator').filter(group=group, codename=perm,\n                                               approved=approved)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_user_permissions(self, user, perm, obj, check_groups=False):\n        user_perms = self.user_permissions(user, perm, obj, check_groups=False)\n        if not user_perms.filter(object_id=obj.id):\n            return\n        perms = self.user_permissions(user, perm, obj).filter(object_id=obj.id)\n        perms.delete()", "response": "Remove granular permission perm from user on an object instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a flattened version of the parsed whois data", "response": "def flattened(self):\n        \"\"\"Returns a flattened version of the parsed whois data\"\"\"\n        parsed = self['parsed_whois']\n        flat = OrderedDict()\n        for key in ('domain', 'created_date', 'updated_date', 'expired_date', 'statuses', 'name_servers'):\n            value = parsed[key]\n            flat[key] = ' | '.join(value) if type(value) in (list, tuple) else value\n\n        registrar = parsed.get('registrar', {})\n        for key in ('name', 'abuse_contact_phone', 'abuse_contact_email', 'iana_id', 'url', 'whois_server'):\n            flat['registrar_{0}'.format(key)] = registrar[key]\n\n        for contact_type in ('registrant', 'admin', 'tech', 'billing'):\n            contact = parsed.get('contacts', {}).get(contact_type, {})\n            for key in ('name', 'email', 'org', 'street', 'city', 'state', 'postal', 'country', 'phone', 'fax'):\n                value = contact[key]\n                flat['{0}_{1}'.format(contact_type, key)] = ' '.join(value) if type(value) in (list, tuple) else value\n\n        return flat"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefaults 403 handler. Templates: `403.html` Context: request_path The path of the requested URL (e.g., '/app/pages/bad_page/')", "response": "def permission_denied(request, template_name=None, extra_context=None):\n    \"\"\"\n    Default 403 handler.\n\n    Templates: `403.html`\n    Context:\n        request_path\n            The path of the requested URL (e.g., '/app/pages/bad_page/')\n    \"\"\"\n    if template_name is None:\n        template_name = ('403.html', 'authority/403.html')\n    context = {\n        'request_path': request.path,\n    }\n    if extra_context:\n        context.update(extra_context)\n    return HttpResponseForbidden(loader.render_to_string(\n        template_name=template_name,\n        context=context,\n        request=request,\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napproving granular permission request setting a Permission entry as approved = True for a specific action from an object instance on an object instance. creator is the creator of the object instance.", "response": "def approve(self, creator):\n        \"\"\"\n        Approve granular permission request setting a Permission entry as\n        approved=True for a specific action from an user on an object instance.\n        \"\"\"\n        self.approved = True\n        self.creator = creator\n        self.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngoes and imports the permissions submodule of every app in INSTALLED_APPS to make sure the permission set classes are registered correctly.", "response": "def autodiscover_modules():\n    \"\"\"\n    Goes and imports the permissions submodule of every app in INSTALLED_APPS\n    to make sure the permission set classes are registered correctly.\n    \"\"\"\n    import imp\n    from django.conf import settings\n\n    for app in settings.INSTALLED_APPS:\n        try:\n            __import__(app)\n            app_path = sys.modules[app].__path__\n        except AttributeError:\n            continue\n        try:\n            imp.find_module('permissions', app_path)\n        except ImportError:\n            continue\n        __import__(\"%s.permissions\" % app)\n        app_path = sys.modules[\"%s.permissions\" % app]\n    LOADING = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_user_cached_perms(self):\n        if not self.user:\n            return {}, {}\n        group_pks = set(self.user.groups.values_list(\n            'pk',\n            flat=True,\n        ))\n        perms = Permission.objects.filter(\n            Q(user__pk=self.user.pk) | Q(group__pk__in=group_pks),\n        )\n        user_permissions = {}\n        group_permissions = {}\n        for perm in perms:\n            if perm.user_id == self.user.pk:\n                user_permissions[(\n                    perm.object_id,\n                    perm.content_type_id,\n                    perm.codename,\n                    perm.approved,\n                )] = True\n            # If the user has the permission do for something, but perm.user !=\n            # self.user then by definition that permission came from the\n            # group.\n            else:\n                group_permissions[(\n                    perm.object_id,\n                    perm.content_type_id,\n                    perm.codename,\n                    perm.approved,\n                )] = True\n        return user_permissions, group_permissions", "response": "Get the user and group caches."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the group cache.", "response": "def _get_group_cached_perms(self):\n        \"\"\"\n        Set group cache.\n        \"\"\"\n        if not self.group:\n            return {}\n        perms = Permission.objects.filter(\n            group=self.group,\n        )\n        group_permissions = {}\n        for perm in perms:\n            group_permissions[(\n                perm.object_id,\n                perm.content_type_id,\n                perm.codename,\n                perm.approved,\n            )] = True\n        return group_permissions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prime_user_perm_caches(self):\n        perm_cache, group_perm_cache = self._get_user_cached_perms()\n        self.user._authority_perm_cache = perm_cache\n        self.user._authority_group_perm_cache = group_perm_cache\n        self.user._authority_perm_cache_filled = True", "response": "Prime both the user and group caches and put them on the self. user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _prime_group_perm_caches(self):\n        perm_cache = self._get_group_cached_perms()\n        self.group._authority_perm_cache = perm_cache\n        self.group._authority_perm_cache_filled = True", "response": "Prime the group cache and put them on the self. group."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _user_perm_cache(self):\n        # Check to see if the cache has been primed.\n        if not self.user:\n            return {}\n        cache_filled = getattr(\n            self.user,\n            '_authority_perm_cache_filled',\n            False,\n        )\n        if cache_filled:\n            # Don't really like the name for this, but this matches how Django\n            # does it.\n            return self.user._authority_perm_cache\n\n        # Prime the cache.\n        self._prime_user_perm_caches()\n        return self.user._authority_perm_cache", "response": "Return the name of the cache that the user has permission to generate."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _group_perm_cache(self):\n        # Check to see if the cache has been primed.\n        if not self.group:\n            return {}\n        cache_filled = getattr(\n            self.group,\n            '_authority_perm_cache_filled',\n            False,\n        )\n        if cache_filled:\n            # Don't really like the name for this, but this matches how Django\n            # does it.\n            return self.group._authority_perm_cache\n\n        # Prime the cache.\n        self._prime_group_perm_caches()\n        return self.group._authority_perm_cache", "response": "Returns the name of the cache that will be used for the group."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the cache_permissions for the user and group.", "response": "def _user_group_perm_cache(self):\n        \"\"\"\n        cached_permissions will generate the cache in a lazy fashion.\n        \"\"\"\n        # Check to see if the cache has been primed.\n        if not self.user:\n            return {}\n        cache_filled = getattr(\n            self.user,\n            '_authority_perm_cache_filled',\n            False,\n        )\n        if cache_filled:\n            return self.user._authority_group_perm_cache\n\n        # Prime the cache.\n        self._prime_user_perm_caches()\n        return self.user._authority_group_perm_cache"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvalidate the cache of the permissions for the current user and group.", "response": "def invalidate_permissions_cache(self):\n        \"\"\"\n        In the event that the Permission table is changed during the use of a\n        permission the Permission cache will need to be invalidated and\n        regenerated. By calling this method the invalidation will occur, and\n        the next time the cached_permissions is used the cache will be\n        re-primed.\n        \"\"\"\n        if self.user:\n            self.user._authority_perm_cache_filled = False\n        if self.group:\n            self.group._authority_perm_cache_filled = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_group_perms(self, perm, obj, approved):\n        if not self.group:\n            return False\n\n        if self.use_smart_cache:\n            content_type_pk = Permission.objects.get_content_type(obj).pk\n\n            def _group_has_perms(cached_perms):\n                # Check to see if the permission is in the cache.\n                return cached_perms.get((\n                    obj.pk,\n                    content_type_pk,\n                    perm,\n                    approved,\n                ))\n\n            # Check to see if the permission is in the cache.\n            return _group_has_perms(self._group_perm_cache)\n\n        # Actually hit the DB, no smart cache used.\n        return Permission.objects.group_permissions(\n            self.group,\n            perm, obj,\n            approved,\n        ).filter(\n            object_id=obj.pk,\n        ).exists()", "response": "Check if group has the permission for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if user has the permission for the given object", "response": "def has_perm(self, perm, obj, check_groups=True, approved=True):\n        \"\"\"\n        Check if user has the permission for the given object\n        \"\"\"\n        if self.user:\n            if self.has_user_perms(perm, obj, approved, check_groups):\n                return True\n        if self.group:\n            return self.has_group_perms(perm, obj, approved)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if user requested a permission for the given object.", "response": "def requested_perm(self, perm, obj, check_groups=True):\n        \"\"\"\n        Check if user requested a permission for the given object\n        \"\"\"\n        return self.has_perm(perm, obj, check_groups, False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassigning a permission to a user.", "response": "def assign(self, check=None, content_object=None, generic=False):\n        \"\"\"\n        Assign a permission to a user.\n\n        To assign permission for all checks: let check=None.\n        To assign permission for all objects: let content_object=None.\n\n        If generic is True then \"check\" will be suffixed with _modelname.\n        \"\"\"\n        result = []\n\n        if not content_object:\n            content_objects = (self.model,)\n        elif not isinstance(content_object, (list, tuple)):\n            content_objects = (content_object,)\n        else:\n            content_objects = content_object\n\n        if not check:\n            checks = self.generic_checks + getattr(self, 'checks', [])\n        elif not isinstance(check, (list, tuple)):\n            checks = (check,)\n        else:\n            checks = check\n\n        for content_object in content_objects:\n            # raise an exception before adding any permission\n            # i think Django does not rollback by default\n            if not isinstance(content_object, (Model, ModelBase)):\n                raise NotAModel(content_object)\n            elif isinstance(content_object, Model) and not content_object.pk:\n                raise UnsavedModelInstance(content_object)\n\n            content_type = ContentType.objects.get_for_model(content_object)\n\n            for check in checks:\n                if isinstance(content_object, Model):\n                    # make an authority per object permission\n                    codename = self.get_codename(\n                        check,\n                        content_object,\n                        generic,\n                    )\n                    try:\n                        perm = Permission.objects.get(\n                            user=self.user,\n                            codename=codename,\n                            approved=True,\n                            content_type=content_type,\n                            object_id=content_object.pk,\n                        )\n                    except Permission.DoesNotExist:\n                        perm = Permission.objects.create(\n                            user=self.user,\n                            content_object=content_object,\n                            codename=codename,\n                            approved=True,\n                        )\n\n                    result.append(perm)\n\n                elif isinstance(content_object, ModelBase):\n                    # make a Django permission\n                    codename = self.get_django_codename(\n                        check,\n                        content_object,\n                        generic,\n                        without_left=True,\n                    )\n                    try:\n                        perm = DjangoPermission.objects.get(codename=codename)\n                    except DjangoPermission.DoesNotExist:\n                        name = check\n                        if '_' in name:\n                            name = name[0:name.find('_')]\n                        perm = DjangoPermission(\n                            name=name,\n                            codename=codename,\n                            content_type=content_type,\n                        )\n                        perm.save()\n                    self.user.user_permissions.add(perm)\n                    result.append(perm)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delimited(items, character='|'):\n    return '|'.join(items) if type(items) in (list, tuple, set) else items", "response": "Returns a character delimited version of the provided list as a Python string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npulling in and enforces the latest rate limits for the specified user", "response": "def _rate_limit(self):\n        \"\"\"Pulls in and enforces the latest rate limits for the specified user\"\"\"\n        self.limits_set = True\n        for product in self.account_information():\n            self.limits[product['id']] = {'interval': timedelta(seconds=60 / float(product['per_minute_limit']))}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new instance of Result class with the specified API path with the specified kwargs parameters", "response": "def _results(self, product, path, cls=Results, **kwargs):\n        \"\"\"Returns _results for the specified API path with the specified **kwargs parameters\"\"\"\n        if product != 'account-information' and self.rate_limit and not self.limits_set and not self.limits:\n            self._rate_limit()\n\n        uri = '/'.join(('{0}://api.domaintools.com'.format('https' if self.https else 'http'), path.lstrip('/')))\n        parameters = self.default_parameters.copy()\n        parameters['api_username'] = self.username\n        if self.https:\n            parameters['api_key'] = self.key\n        else:\n            parameters['timestamp'] = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\n            parameters['signature'] = hmac(self.key.encode('utf8'), ''.join([self.username, parameters['timestamp'],\n                                                                             path]).encode('utf8'),\n                                           digestmod=sha1).hexdigest()\n        parameters.update(dict((key, str(value).lower() if value in (True, False) else value) for\n                               key, value in kwargs.items() if value is not None))\n        return cls(self, product, uri, **parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmark an alert for a brand monitor.", "response": "def brand_monitor(self, query, exclude=[], domain_status=None, days_back=None, **kwargs):\n        \"\"\"Pass in one or more terms as a list or separated by the pipe character ( | )\"\"\"\n        return self._results('mark-alert', '/v1/mark-alert', query=delimited(query), exclude=delimited(exclude),\n                            domain_status=domain_status, days_back=days_back, items_path=('alerts', ), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching for a domain record.", "response": "def domain_search(self, query, exclude_query=[], max_length=25, min_length=2, has_hyphen=True, has_number=True,\n                      active_only=False, deleted_only=False, anchor_left=False, anchor_right=False, page=1, **kwargs):\n        \"\"\"Each term in the query string must be at least three characters long.\n           Pass in a list or use spaces to separate multiple terms.\n        \"\"\"\n        return self._results('domain-search', '/v2/domain-search', query=delimited(query, ' '),\n                            exclude_query=delimited(exclude_query, ' '),\n                            max_length=max_length, min_length=min_length, has_hyphen=has_hyphen, has_number=has_number,\n                            active_only=active_only, deleted_only=deleted_only, anchor_left=anchor_left,\n                            anchor_right=anchor_right, page=page, items_path=('results', ), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting suggestions for a domain.", "response": "def domain_suggestions(self, query, **kwargs):\n        \"\"\"Passed in name must be at least two characters long. Use a list or spaces to separate multiple terms.\"\"\"\n        return self._results('domain-suggestions', '/v1/domain-suggestions', query=delimited(query, ' '),\n                            items_path=('suggestions', ), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the hosting history from the given domain name", "response": "def hosting_history(self, query, **kwargs):\n        \"\"\"Returns the hosting history from the given domain name\"\"\"\n        return self._results('hosting-history', '/v1/{0}/hosting-history'.format(query), cls=GroupedIterable, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ip_monitor(self, query, days_back=0, page=1, **kwargs):\n        return self._results('ip-monitor', '/v1/ip-monitor', query=query, days_back=days_back, page=page,\n                            items_path=('alerts', ), **kwargs)", "response": "Monitor the IP Address for alerts."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ip_registrant_monitor(self, query, days_back=0, search_type=\"all\", server=None, country=None, org=None, page=1,\n                              include_total_count=False, **kwargs):\n        \"\"\"Query based on free text query terms\"\"\"\n        return self._results('ip-registrant-monitor', '/v1/ip-registrant-monitor', query=query,\n                            days_back=days_back, search_type=search_type, server=server, country=country, org=org,\n                            page=page, include_total_count=include_total_count, **kwargs)", "response": "Query for registrations of a given set of free text terms."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery the Name Server for alerts.", "response": "def name_server_monitor(self, query, days_back=0, page=1, **kwargs):\n        \"\"\"Pass in the hostname of the Name Server you wish to query ( i.e. dynect.net ).\"\"\"\n        return self._results('name-server-monitor', '/v1/name-server-monitor', query=query, days_back=days_back,\n                            page=page, items_path=('alerts', ), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of parsed Whois objects.", "response": "def parsed_whois(self, query, **kwargs):\n        \"\"\"Pass in a domain name\"\"\"\n        return self._results('parsed-whois', '/v1/{0}/whois/parsed'.format(query), cls=ParsedWhois, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the reputation score for a domain name", "response": "def reputation(self, query, include_reasons=False, **kwargs):\n        \"\"\"Pass in a domain name to see its reputation score\"\"\"\n        return self._results('reputation', '/v1/reputation', domain=query, include_reasons=include_reasons,\n                             cls=Reputation, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reverse_ip(self, domain=None, limit=None, **kwargs):\n        return self._results('reverse-ip', '/v1/{0}/reverse-ip'.format(domain), limit=limit, **kwargs)", "response": "Get the reverse IP of a domain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef host_domains(self, ip=None, limit=None, **kwargs):\n        return self._results('reverse-ip', '/v1/{0}/host-domains'.format(ip), limit=limit, **kwargs)", "response": "Get a list of domains for a given IP address."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reverse_ip_whois(self, query=None, ip=None, country=None, server=None, include_total_count=False, page=1,\n                         **kwargs):\n        \"\"\"Pass in an IP address or a list of free text query terms.\"\"\"\n        if (ip and query) or not (ip or query):\n            raise ValueError('Query or IP Address (but not both) must be defined')\n\n        return self._results('reverse-ip-whois', '/v1/reverse-ip-whois', query=query, ip=ip, country=country,\n                            server=server, include_total_count=include_total_count, page=page, items_path=('records', ),\n                            **kwargs)", "response": "This API endpoint returns a list of free text records for a given IP address or a list of free text query terms."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreverse name server domains.", "response": "def reverse_name_server(self, query, limit=None, **kwargs):\n        \"\"\"Pass in a domain name or a name server.\"\"\"\n        return self._results('reverse-name-server', '/v1/{0}/name-server-domains'.format(query),\n                            items_path=('primary_domains', ), limit=limit, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for a list of terms to search for in the Whois record.", "response": "def reverse_whois(self, query, exclude=[], scope='current', mode=None, **kwargs):\n        \"\"\"List of one or more terms to search for in the Whois record,\n           as a Python list or separated with the pipe character ( | ).\n        \"\"\"\n        return self._results('reverse-whois', '/v1/reverse-whois', terms=delimited(query), exclude=delimited(exclude),\n                            scope=scope, mode=mode, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npassing in a domain name.", "response": "def whois_history(self, query, **kwargs):\n        \"\"\"Pass in a domain name.\"\"\"\n        return self._results('whois-history', '/v1/{0}/whois/history'.format(query), items_path=('history', ), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef phisheye(self, query, days_back=None, **kwargs):\n        return self._results('phisheye', '/v1/phisheye', query=query, days_back=days_back, items_path=('domains', ),\n                             **kwargs)", "response": "Returns the domain results for the specified term for today or the specified number of days_back."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef phisheye_term_list(self, include_inactive=False, **kwargs):\n        return self._results('phisheye_term_list', '/v1/phisheye/term-list', include_inactive=include_inactive,\n                             items_path=('terms', ), **kwargs)", "response": "Provides a list of terms that are set up for this account."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iris(self, domain=None, ip=None, email=None, nameserver=None, registrar=None, registrant=None,\n             registrant_org=None, **kwargs):\n        \"\"\"Performs a search for the provided search terms ANDed together,\n           returning the pivot engine row data for the resulting domains.\n        \"\"\"\n        if ((not domain and not ip and not email and not nameserver and not registrar and not registrant and not\n             registrant_org and not kwargs)):\n            raise ValueError('At least one search term must be specified')\n\n        return self._results('iris', '/v1/iris', domain=domain, ip=ip, email=email, nameserver=nameserver,\n                             registrar=registrar, registrant=registrant, registrant_org=registrant_org,\n                             items_path=('results', ), **kwargs)", "response": "Performs a search for the provided search terms ANDed together and returns the pivot engine row data for the resulting domains."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef risk(self, domain, **kwargs):\n        return self._results('risk', '/v1/risk', items_path=('components', ), domain=domain, cls=Reputation,\n                             **kwargs)", "response": "Returns back the risk score for a given domain"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef risk_evidence(self, domain, **kwargs):\n        return self._results('risk-evidence', '/v1/risk/evidence/', items_path=('components', ), domain=domain,\n                             **kwargs)", "response": "Returns back the detailed risk evidence associated with a given domain"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iris_enrich(self, *domains, **kwargs):\n        if not domains:\n            raise ValueError('One or more domains to enrich must be provided')\n\n        domains = ','.join(domains)\n        data_updated_after = kwargs.get('data_updated_after', None)\n        if hasattr(data_updated_after, 'strftime'):\n            data_updated_after = data_updated_after.strftime('%Y-%M-%d')\n\n        return self._results('iris-enrich', '/v1/iris-enrich/', domain=domains, data_updated_after=data_updated_after,\n                             items_path=('results', ), **kwargs)", "response": "Returns back enriched data related to the specified domains using our Iris Enrich service."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns back a list of domains based on the provided filters.", "response": "def iris_investigate(self, domains=None, data_updated_after=None, expiration_date=None,\n                         create_date=None, active=None, **kwargs):\n        \"\"\"Returns back a list of domains based on the provided filters.\n        The following filters are available beyond what is parameterized as kwargs:\n\n            - ip: Search for domains having this IP.\n            - email: Search for domains with this email in their data.\n            - email_domain: Search for domains where the email address uses this domain.\n            - nameserver_host: Search for domains with this nameserver.\n            - nameserver_domain: Search for domains with a nameserver that has this domain.\n            - nameserver_ip: Search for domains with a nameserver on this IP.\n            - registrar: Search for domains with this registrar.\n            - registrant: Search for domains with this registrant name.\n            - registrant_org: Search for domains with this registrant organization.\n            - mailserver_host: Search for domains with this mailserver.\n            - mailserver_domain: Search for domains with a mailserver that has this domain.\n            - mailserver_ip: Search for domains with a mailserver on this IP.\n            - redirect_domain: Search for domains which redirect to this domain.\n            - ssl_hash: Search for domains which have an SSL certificate with this hash.\n            - ssl_subject: Search for domains which have an SSL certificate with this subject string.\n            - ssl_email: Search for domains which have an SSL certificate with this email in it.\n            - ssl_org: Search for domains which have an SSL certificate with this organization in it.\n            - google_analytics: Search for domains which have this Google Analytics code.\n            - adsense: Search for domains which have this AdSense code.\n            - tld: Filter by TLD. Must be combined with another parameter.\n\n        You can loop over results of your investigation as if it was a native Python list:\n\n            for result in api.iris_investigate(ip='199.30.228.112'):  # Enables looping over all related results\n\n        api.iris_investigate(QUERY)['results_count'] Returns the number of results returned with this request\n        api.iris_investigate(QUERY)['total_count'] Returns the number of results available within Iris\n        api.iris_investigate(QUERY)['missing_domains'] Returns any domains that we were unable to find\n        api.iris_investigate(QUERY)['limit_exceeded'] Returns True if you've exceeded your API usage\n        api.iris_investigate(QUERY)['position'] Returns the position key that can be used to retrieve the next page:\n            next_page = api.iris_investigate(QUERY, position=api.iris_investigate(QUERY)['position'])\n\n        for enrichment in api.iris_enrich(i):  # Enables looping over all returned enriched domains\n\n        \"\"\"\n        if not (kwargs or domains):\n            raise ValueError('Need to define investigation using kwarg filters or domains')\n\n        if type(domains) in (list, tuple):\n            domains = ','.join(domains)\n        if hasattr(data_updated_after, 'strftime'):\n            data_updated_after = data_updated_after.strftime('%Y-%M-%d')\n        if hasattr(expiration_date, 'strftime'):\n            expiration_date = expiration_date.strftime('%Y-%M-%d')\n        if hasattr(create_date, 'strftime'):\n            create_date = create_date.strftime('%Y-%M-%d')\n        if type(active) == bool:\n            active = str(active).lower()\n\n        return self._results('iris-investigate', '/v1/iris-investigate/', domain=domains,\n                             data_updated_after=data_updated_after, expiration_date=expiration_date,\n                             create_date=create_date, items_path=('results', ), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init(self):\n        url = 'https://finance.yahoo.com/quote/%s/history' % (self.ticker)\n        r = requests.get(url)\n        txt = r.content\n        cookie = r.cookies['B']\n        pattern = re.compile('.*\"CrumbStore\":\\{\"crumb\":\"(?P<crumb>[^\"]+)\"\\}')\n\n        for line in txt.splitlines():\n            m = pattern.match(line.decode(\"utf-8\"))\n            if m is not None:\n                crumb = m.groupdict()['crumb']\n                crumb = crumb.replace(u'\\\\u002F', '/')\n        return cookie, crumb", "response": "Returns a tuple of cookie and crumb used in the request"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of historical data from Yahoo Finance", "response": "def getData(self, events):\n        \"\"\"Returns a list of historical data from Yahoo Finance\"\"\"\n        if self.interval not in [\"1d\", \"1wk\", \"1mo\"]:\n            raise ValueError(\"Incorrect interval: valid intervals are 1d, 1wk, 1mo\")\n\n        url = self.api_url % (self.ticker, self.start, self.end, self.interval, events, self.crumb)\n\n        data = requests.get(url, cookies={'B':self.cookie})\n        content = StringIO(data.content.decode(\"utf-8\"))\n        return pd.read_csv(content, sep=',')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_mount_methods(self, disk_type):\n        if self.disk_mounter == 'auto':\n            methods = []\n\n            def add_method_if_exists(method):\n                if (method == 'avfs' and _util.command_exists('avfsd')) or \\\n                        _util.command_exists(method):\n                    methods.append(method)\n\n            if self.read_write:\n                add_method_if_exists('xmount')\n            else:\n                if disk_type == 'encase':\n                    add_method_if_exists('ewfmount')\n                elif disk_type == 'vmdk':\n                    add_method_if_exists('vmware-mount')\n                    add_method_if_exists('affuse')\n                elif disk_type == 'dd':\n                    add_method_if_exists('affuse')\n                elif disk_type == 'compressed':\n                    add_method_if_exists('avfs')\n                elif disk_type == 'qcow2':\n                    add_method_if_exists('qemu-nbd')\n                elif disk_type == 'vdi':\n                    add_method_if_exists('qemu-nbd')\n                add_method_if_exists('xmount')\n        else:\n            methods = [self.disk_mounter]\n        return methods", "response": "Finds which mount methods are suitable for the specified disk type. Returns a list of all suitable mount methods."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _mount_avfs(self):\n\n        self._paths['avfs'] = tempfile.mkdtemp(prefix='image_mounter_avfs_')\n\n        # start by calling the mountavfs command to initialize avfs\n        _util.check_call_(['avfsd', self._paths['avfs'], '-o', 'allow_other'], stdout=subprocess.PIPE)\n\n        # no multifile support for avfs\n        avfspath = self._paths['avfs'] + '/' + os.path.abspath(self.paths[0]) + '#'\n        targetraw = os.path.join(self.mountpoint, 'avfs')\n\n        os.symlink(avfspath, targetraw)\n        logger.debug(\"Symlinked {} with {}\".format(avfspath, targetraw))\n        raw_path = self.get_raw_path()\n        logger.debug(\"Raw path to avfs is {}\".format(raw_path))\n        if raw_path is None:\n            raise MountpointEmptyError()", "response": "Mounts the AVFS filesystem."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmount the base image on a temporary location using the mount methods stored in self. method.", "response": "def mount(self):\n        \"\"\"Mounts the base image on a temporary location using the mount method stored in :attr:`method`. If mounting\n        was successful, :attr:`mountpoint` is set to the temporary mountpoint.\n\n        If :attr:`read_write` is enabled, a temporary read-write cache is also created and stored in :attr:`rwpath`.\n\n        :return: whether the mounting was successful\n        :rtype: bool\n        \"\"\"\n\n        if self.parser.casename:\n            self.mountpoint = tempfile.mkdtemp(prefix='image_mounter_', suffix='_' + self.parser.casename)\n        else:\n            self.mountpoint = tempfile.mkdtemp(prefix='image_mounter_')\n\n        if self.read_write:\n            self.rwpath = tempfile.mkstemp(prefix=\"image_mounter_rw_cache_\")[1]\n\n        disk_type = self.get_disk_type()\n        methods = self._get_mount_methods(disk_type)\n\n        cmds = []\n        for method in methods:\n            if method == 'avfs':  # avfs does not participate in the fallback stuff, unfortunately\n                self._mount_avfs()\n                self.disk_mounter = method\n                self.was_mounted = True\n                self.is_mounted = True\n                return\n\n            elif method == 'dummy':\n                os.rmdir(self.mountpoint)\n                self.mountpoint = \"\"\n                logger.debug(\"Raw path to dummy is {}\".format(self.get_raw_path()))\n                self.disk_mounter = method\n                self.was_mounted = True\n                self.is_mounted = True\n                return\n\n            elif method == 'xmount':\n                cmds.append(['xmount', ])\n                if self.read_write:\n                    cmds[-1].extend(['--cache', self.rwpath])\n                cmds[-1].extend(['--in', 'ewf' if disk_type == 'encase' else 'dd'])\n                cmds[-1].extend(self.paths)  # specify all paths, xmount needs this :(\n                cmds[-1].append(self.mountpoint)\n\n            elif method == 'affuse':\n                cmds.extend([['affuse', '-o', 'allow_other', self.paths[0], self.mountpoint],\n                             ['affuse', self.paths[0], self.mountpoint]])\n\n            elif method == 'ewfmount':\n                cmds.extend([['ewfmount', '-X', 'allow_other', self.paths[0], self.mountpoint],\n                             ['ewfmount', self.paths[0], self.mountpoint]])\n\n            elif method == 'vmware-mount':\n                cmds.append(['vmware-mount', '-r', '-f', self.paths[0], self.mountpoint])\n\n            elif method == 'qemu-nbd':\n                _util.check_output_(['modprobe', 'nbd', 'max_part=63'])  # Load nbd driver\n                try:\n                    self._paths['nbd'] = _util.get_free_nbd_device()  # Get free nbd device\n                except NoNetworkBlockAvailableError:\n                    logger.warning(\"No free network block device found.\", exc_info=True)\n                    raise\n                cmds.extend([['qemu-nbd', '--read-only', '-c', self._paths['nbd'], self.paths[0]]])\n\n            else:\n                raise ArgumentError(\"Unknown mount method {0}\".format(self.disk_mounter))\n\n        for cmd in cmds:\n            # noinspection PyBroadException\n            try:\n                _util.check_call_(cmd, stdout=subprocess.PIPE)\n                # mounting does not seem to be instant, add a timer here\n                time.sleep(.1)\n            except Exception:\n                logger.warning('Could not mount {0}, trying other method'.format(self.paths[0]), exc_info=True)\n                continue\n            else:\n                raw_path = self.get_raw_path()\n                logger.debug(\"Raw path to disk is {}\".format(raw_path))\n                self.disk_mounter = cmd[0]\n\n                if raw_path is None:\n                    raise MountpointEmptyError()\n                self.was_mounted = True\n                self.is_mounted = True\n                return\n\n        logger.error('Unable to mount {0}'.format(self.paths[0]))\n        os.rmdir(self.mountpoint)\n        self.mountpoint = \"\"\n        raise MountError()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_raw_path(self):\n\n        if self.disk_mounter == 'dummy':\n            return self.paths[0]\n        else:\n            if self.disk_mounter == 'avfs' and os.path.isdir(os.path.join(self.mountpoint, 'avfs')):\n                logger.debug(\"AVFS mounted as a directory, will look in directory for (random) file.\")\n                # there is no support for disks inside disks, so this will fail to work for zips containing\n                # E01 files or so.\n                searchdirs = (os.path.join(self.mountpoint, 'avfs'), self.mountpoint)\n            else:\n                searchdirs = (self.mountpoint, )\n\n            raw_path = []\n            if self._paths.get('nbd'):\n                raw_path.append(self._paths['nbd'])\n\n            for searchdir in searchdirs:\n                # avfs: apparently it is not a dir\n                for pattern in ['*.dd', '*.iso', '*.raw', '*.dmg', 'ewf1', 'flat', 'avfs']:\n                    raw_path.extend(glob.glob(os.path.join(searchdir, pattern)))\n\n            if not raw_path:\n                logger.warning(\"No viable mount file found in {}.\".format(searchdirs))\n                return None\n            return raw_path[0]", "response": "Returns the raw path to the mounted disk image i. e. the raw. dd. iso. raw or. ewf1. flat file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef detect_volumes(self, single=None):\n        # prevent adding the same volumes twice\n        if self.volumes.has_detected:\n            for v in self.volumes:\n                yield v\n\n        elif single:\n            for v in self.volumes.detect_volumes(method='single'):\n                yield v\n\n        else:\n            # if single == False or single == None, loop over all volumes\n            amount = 0\n            try:\n                for v in self.volumes.detect_volumes():\n                    amount += 1\n                    yield v\n            except ImageMounterError:\n                pass  # ignore and continue to single mount\n\n            # if single == None and no volumes were mounted, use single_volume\n            if single is None and amount == 0:\n                logger.info(\"Detecting as single volume instead\")\n                for v in self.volumes.detect_volumes(method='single', force=True):\n                    yield v", "response": "Generator that returns the list of volumes that are mounted on the Disk."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init(self, single=None, only_mount=None, skip_mount=None, swallow_exceptions=True):\n\n        self.mount()\n        self.volumes.preload_volume_data()\n\n        for v in self.init_volumes(single, only_mount=only_mount, skip_mount=skip_mount,\n                                   swallow_exceptions=swallow_exceptions):\n            yield v", "response": "Calls the mount method and returns all detected volumes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_volumes(self, single=None, only_mount=None, skip_mount=None, swallow_exceptions=True):\n\n        for volume in self.detect_volumes(single=single):\n            for vol in volume.init(only_mount=only_mount, skip_mount=skip_mount,\n                                   swallow_exceptions=swallow_exceptions):\n                yield vol", "response": "Generator that detects and mounts all volumes in the disk."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of all volumes in this disk including volumes that are contained in other volumes.", "response": "def get_volumes(self):\n        \"\"\"Gets a list of all volumes in this disk, including volumes that are contained in other volumes.\"\"\"\n\n        volumes = []\n        for v in self.volumes:\n            volumes.extend(v.get_volumes())\n        return volumes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unmount(self, remove_rw=False, allow_lazy=False):\n\n        for m in list(sorted(self.volumes, key=lambda v: v.mountpoint or \"\", reverse=True)):\n            try:\n                m.unmount(allow_lazy=allow_lazy)\n            except ImageMounterError:\n                logger.warning(\"Error unmounting volume {0}\".format(m.mountpoint))\n\n        if self._paths.get('nbd'):\n            _util.clean_unmount(['qemu-nbd', '-d'], self._paths['nbd'], rmdir=False)\n\n        if self.mountpoint:\n            try:\n                _util.clean_unmount(['fusermount', '-u'], self.mountpoint)\n            except SubsystemError:\n                if not allow_lazy:\n                    raise\n                _util.clean_unmount(['fusermount', '-uz'], self.mountpoint)\n\n        if self._paths.get('avfs'):\n            try:\n                _util.clean_unmount(['fusermount', '-u'], self._paths['avfs'])\n            except SubsystemError:\n                if not allow_lazy:\n                    raise\n                _util.clean_unmount(['fusermount', '-uz'], self._paths['avfs'])\n\n        if self.rw_active() and remove_rw:\n            os.remove(self.rwpath)\n\n        self.is_mounted = False", "response": "Unmounts all ties of this image."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a new argument parser.", "response": "def _make_argparser(self):\n        \"\"\"Makes a new argument parser.\"\"\"\n        self.argparser = ShellArgumentParser(prog='')\n        subparsers = self.argparser.add_subparsers()\n\n        for name in self.get_names():\n            if name.startswith('parser_'):\n                parser = subparsers.add_parser(name[7:])\n                parser.set_defaults(func=getattr(self, 'arg_' + name[7:]))\n                getattr(self, name)(parser)\n\n        self.argparser_completer = None\n\n        try:\n            import argcomplete\n        except ImportError:\n            pass\n        else:\n            os.environ.setdefault(\"_ARGCOMPLETE_COMP_WORDBREAKS\", \" \\t\\\"'\")\n            self.argparser_completer = argcomplete.CompletionFinder(self.argparser)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noverriding to reset the argument parser after every completion", "response": "def complete(self, text, state):\n        \"\"\"Overridden to reset the argument parser after every completion (argcomplete fails :()\"\"\"\n        result = cmd.Cmd.complete(self, text, state)\n        if self.argparser_completer:\n            self._make_argparser()\n            # argparser screws up with internal states, this is the best way to fix it for now\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default(self, line):\n\n        if any((line.startswith(x) for x in self.argparse_names())):\n            try:\n                args = self.argparser.parse_args(shlex.split(line))\n            except Exception:  # intentionally catches also other errors in argparser\n                pass\n            else:\n                args.func(args)\n        else:\n            cmd.Cmd.default(self, line)", "response": "Overriding default to get access to any argparse commands we have specified."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef completedefault(self, text, line, begidx, endidx):\n        if self.argparser_completer and any((line.startswith(x) for x in self.argparse_names())):\n            self.argparser_completer.rl_complete(line, 0)\n            return [x[begidx:] for x in self.argparser_completer._rl_matches]\n        else:\n            return []", "response": "Return a list of strings that can be used to complete the given line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npatch to also return argparse commands", "response": "def completenames(self, text, *ignored):\n        \"\"\"Patched to also return argparse commands\"\"\"\n        return sorted(cmd.Cmd.completenames(self, text, *ignored) + self.argparse_names(text))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_help(self, arg):\n        if not arg or arg not in self.argparse_names():\n            cmd.Cmd.do_help(self, arg)\n        else:\n            try:\n                self.argparser.parse_args([arg, '--help'])\n            except Exception:\n                pass", "response": "Patched to show help for arparse commands"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_topics(self, header, cmds, cmdlen, maxcol):\n        if header == self.doc_header:\n            cmds.extend(self.argparse_names())\n        cmd.Cmd.print_topics(self, header, sorted(cmds), cmdlen, maxcol)", "response": "Patched to show all argparse commands as being documented"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the parser if not already set loads the parser", "response": "def preloop(self):\n        \"\"\"if the parser is not already set, loads the parser.\"\"\"\n        if not self.parser:\n            self.stdout.write(\"Welcome to imagemounter {version}\".format(version=__version__))\n            self.stdout.write(\"\\n\")\n\n            self.parser = ImageParser()\n            for p in self.args.paths:\n                self.onecmd('disk \"{}\"'.format(p))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef onecmd(self, line):\n        try:\n            return cmd.Cmd.onecmd(self, line)\n        except Exception as e:\n            print(\"Critical error.\", e)", "response": "Do not crash the entire program when a single command fails."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all indexes available in the parser", "response": "def _get_all_indexes(self):\n        \"\"\"Returns all indexes available in the parser\"\"\"\n        if self.parser:\n            return [v.index for v in self.parser.get_volumes()] + [d.index for d in self.parser.disks]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a volume disk tuple for the specified index", "response": "def _get_by_index(self, index):\n        \"\"\"Returns a volume,disk tuple for the specified index\"\"\"\n        volume_or_disk = self.parser.get_by_index(index)\n        volume, disk = (volume_or_disk, None) if not isinstance(volume_or_disk, Disk) else (None, volume_or_disk)\n        return volume, disk"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef preview_unmount(self):\n\n        commands = []\n        for mountpoint in self.find_bindmounts():\n            commands.append('umount {0}'.format(mountpoint))\n        for mountpoint in self.find_mounts():\n            commands.append('umount {0}'.format(mountpoint))\n            commands.append('rm -Rf {0}'.format(mountpoint))\n        for vgname, pvname in self.find_volume_groups():\n            commands.append('lvchange -a n {0}'.format(vgname))\n            commands.append('losetup -d {0}'.format(pvname))\n        for device in self.find_loopbacks():\n            commands.append('losetup -d {0}'.format(device))\n        for mountpoint in self.find_base_images():\n            commands.append('fusermount -u {0}'.format(mountpoint))\n            commands.append('rm -Rf {0}'.format(mountpoint))\n        for folder in self.find_clean_dirs():\n            cmd = 'rm -Rf {0}'.format(folder)\n            if cmd not in commands:\n                commands.append(cmd)\n        return commands", "response": "Returns a list of all commands that would be executed if the unmount method would be called."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling all unmount methods in the correct order.", "response": "def unmount(self):\n        \"\"\"Calls all unmount methods in the correct order.\"\"\"\n\n        self.unmount_bindmounts()\n        self.unmount_mounts()\n        self.unmount_volume_groups()\n        self.unmount_loopbacks()\n        self.unmount_base_images()\n        self.clean_dirs()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _index_mountpoints(self):\n\n        # find all mountponits\n        self.mountpoints = {}\n        # noinspection PyBroadException\n        try:\n            result = _util.check_output_(['mount'])\n            for line in result.splitlines():\n                m = re.match(r'(.+) on (.+) type (.+) \\((.+)\\)', line)\n                if m:\n                    self.mountpoints[m.group(2)] = (m.group(1), m.group(3), m.group(4))\n        except Exception:\n            pass", "response": "Finds all mountpoints and stores them in self. mountpoints"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _index_loopbacks(self):\n\n        self.loopbacks = {}\n        try:\n            result = _util.check_output_(['losetup', '-a'])\n            for line in result.splitlines():\n                m = re.match(r'(.+): (.+) \\((.+)\\).*', line)\n                if m:\n                    self.loopbacks[m.group(1)] = m.group(3)\n        except Exception:\n            pass", "response": "Finds all loopbacks and stores them in self. loopbacks"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_bindmounts(self):\n\n        for mountpoint, (orig, fs, opts) in self.mountpoints.items():\n            if 'bind' in opts and re.match(self.re_pattern, mountpoint):\n                yield mountpoint", "response": "Yields all bind mountpoints that are inside mounts that match the pattern."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds all mountpoints that are mounted to a directory matching re_pattern or originate from a .", "response": "def find_mounts(self):\n        \"\"\"Finds all mountpoints that are mounted to a directory matching :attr:`re_pattern` or originate from a\n        directory matching :attr:`orig_re_pattern`.\n        \"\"\"\n\n        for mountpoint, (orig, fs, opts) in self.mountpoints.items():\n            if 'bind' not in opts and (re.match(self.orig_re_pattern, orig) or\n                                       (self.be_greedy and re.match(self.re_pattern, mountpoint))):\n                yield mountpoint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind all mountpoints that are mounted to a directory matching the original pattern.", "response": "def find_base_images(self):\n        \"\"\"Finds all mountpoints that are mounted to a directory matching :attr:`orig_re_pattern`.\"\"\"\n\n        for mountpoint, _ in self.mountpoints.items():\n            if re.match(self.orig_re_pattern, mountpoint):\n                yield mountpoint"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind all volume groups that are mounted through a loopback originating from disk image.", "response": "def find_volume_groups(self):\n        \"\"\"Finds all volume groups that are mounted through a loopback originating from :attr:`orig_re_pattern`.\n\n        Generator yields tuples of vgname, pvname\n        \"\"\"\n\n        os.environ['LVM_SUPPRESS_FD_WARNINGS'] = '1'\n\n        # find volume groups\n        try:\n            result = _util.check_output_(['pvdisplay'])\n            pvname = vgname = None\n            for line in result.splitlines():\n                if '--- Physical volume ---' in line:\n                    pvname = vgname = None\n                elif \"PV Name\" in line:\n                    pvname = line.replace(\"PV Name\", \"\").strip()\n                elif \"VG Name\" in line:\n                    vgname = line.replace(\"VG Name\", \"\").strip()\n\n                if pvname and vgname:\n                    try:\n                        # unmount volume groups with a physical volume originating from a disk image\n                        if re.match(self.orig_re_pattern, self.loopbacks[pvname]):\n                            yield vgname, pvname\n                    except Exception:\n                        pass\n                    pvname = vgname = None\n\n        except Exception:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_loopbacks(self):\n\n        for dev, source in self.loopbacks.items():\n            if re.match(self.orig_re_pattern, source):\n                yield dev", "response": "Finds all loopbacks originating from self. orig_re_pattern. Generator yields device names."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unmount_bindmounts(self):\n\n        for mountpoint in self.find_bindmounts():\n            _util.clean_unmount(['umount'], mountpoint, rmdir=False)", "response": "Unmounts all bind mounts."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unmount_volume_groups(self):\n\n        for vgname, pvname in self.find_volume_groups():\n            _util.check_output_(['lvchange', '-a', 'n', vgname])\n            _util.check_output_(['losetup', '-d', pvname])", "response": "Unmounts all volume groups and related loopback devices."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unmount_loopbacks(self):\n\n        # re-index loopback devices\n        self._index_loopbacks()\n\n        for dev in self.find_loopbacks():\n            _util.check_output_(['losetup', '-d', dev])", "response": "Unmounts all loopback devices."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_clean_dirs(self):\n\n        for folder in glob.glob(self.glob_pattern):\n            if re.match(self.re_pattern, folder):\n                yield folder\n        for folder in glob.glob(self.orig_glob_pattern):\n            if re.match(self.orig_re_pattern, folder):\n                yield folder", "response": "Finds all temporary directories according to the glob and re patterns that should be cleaned."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expand_path(path):\n    if is_encase(path):\n        return glob.glob(path[:-2] + '??') or [path]\n    ext_match = re.match(r'^.*\\.(\\d{2,})$', path)\n    if ext_match is not None:\n        ext_size = len(ext_match.groups()[-1])\n        return glob.glob(path[:-ext_size] + '[0-9]' * ext_size) or [path]\n    else:\n        return [path]", "response": "Expand the given path to either an Encase image or a dd image\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a disk specified by the path to the ImageParser.", "response": "def add_disk(self, path, force_disk_indexes=True, **args):\n        \"\"\"Adds a disk specified by the path to the ImageParser.\n\n        :param path: The path to the disk volume\n        :param force_disk_indexes: If true, always uses disk indexes. If False, only uses disk indexes if this is the\n                                   second volume you add. If you plan on using this method, always leave this True.\n                                   If you add a second disk when the previous disk has no index, an error is raised.\n        :param args: Arguments to pass to the constructor of the Disk.\n        \"\"\"\n        if self.disks and self.disks[0].index is None:\n            raise DiskIndexError(\"First disk has no index.\")\n\n        if force_disk_indexes or self.disks:\n            index = len(self.disks) + 1\n        else:\n            index = None\n        disk = Disk(self, path, index=str(index) if index else None, **args)\n        self.disks.append(disk)\n        return disk"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle all important disk - mounting tasks i. e. calls the Disk. init function on all underlying disks and yields every volume that is encountered including volumes that have not been mounted.", "response": "def init(self, single=None, swallow_exceptions=True):\n        \"\"\"Handles all important disk-mounting tasks, i.e. calls the :func:`Disk.init` function on all underlying\n        disks. It yields every volume that is encountered, including volumes that have not been mounted.\n\n        :param single: indicates whether the :class:`Disk` should be mounted as a single disk, not as a single disk or\n            whether it should try both (defaults to :const:`None`)\n        :type single: bool|None\n        :param swallow_exceptions: specify whether you want the init calls to swallow exceptions\n        :rtype: generator\n        \"\"\"\n        for d in self.disks:\n            for v in d.init(single, swallow_exceptions=swallow_exceptions):\n                yield v"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmount all disks in the parser i. e. calling disk. mount on all underlying disks.", "response": "def mount_disks(self):\n        \"\"\"Mounts all disks in the parser, i.e. calling :func:`Disk.mount` on all underlying disks. You probably want to\n        use :func:`init` instead.\n\n        :return: whether all mounts have succeeded\n        :rtype: bool\"\"\"\n\n        result = True\n        for disk in self.disks:\n            result = disk.mount() and result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nindicating whether a read - write cache is active in any of the disks.", "response": "def rw_active(self):\n        \"\"\"Indicates whether a read-write cache is active in any of the disks.\n\n        :rtype: bool\"\"\"\n        result = False\n        for disk in self.disks:\n            result = disk.rw_active() or result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetect volumes in all disks and yields the volumes.", "response": "def init_volumes(self, single=None, only_mount=None, skip_mount=None, swallow_exceptions=True):\n        \"\"\"Detects volumes (as volume system or as single volume) in all disks and yields the volumes. This calls\n        :func:`Disk.init_volumes` on all disks and should be called after :func:`mount_disks`.\n\n        :rtype: generator\"\"\"\n\n        for disk in self.disks:\n            logger.info(\"Mounting volumes in {0}\".format(disk))\n            for volume in disk.init_volumes(single, only_mount, skip_mount, swallow_exceptions=swallow_exceptions):\n                yield volume"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a Volume or Disk by its index.", "response": "def get_by_index(self, index):\n        \"\"\"Returns a Volume or Disk by its index.\"\"\"\n\n        try:\n            return self[index]\n        except KeyError:\n            for v in self.get_volumes():\n                if v.index == str(index):\n                    return v\n        raise KeyError(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of all volumes of all disks concatenating it with all disks.", "response": "def get_volumes(self):\n        \"\"\"Gets a list of all volumes of all disks, concatenating :func:`Disk.get_volumes` of all disks.\n\n        :rtype: list\"\"\"\n\n        volumes = []\n        for disk in self.disks:\n            volumes.extend(disk.get_volumes())\n        return volumes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clean(self, remove_rw=False, allow_lazy=False):\n\n        # To ensure clean unmount after reconstruct, we sort across all volumes in all our disks to provide a proper\n        # order\n        volumes = list(sorted(self.get_volumes(), key=lambda v: v.mountpoint or \"\", reverse=True))\n        for v in volumes:\n            try:\n                v.unmount(allow_lazy=allow_lazy)\n            except ImageMounterError:\n                logger.error(\"Error unmounting volume {0}\".format(v.mountpoint))\n\n        # Now just clean the rest.\n        for disk in self.disks:\n            disk.unmount(remove_rw, allow_lazy=allow_lazy)", "response": "Cleans all volumes of all disks and all disks."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef force_clean(self, remove_rw=False, allow_lazy=False, retries=5, sleep_interval=0.5):\n\n        while True:\n            try:\n                self.clean(remove_rw=remove_rw, allow_lazy=allow_lazy)\n            except ImageMounterError:\n                if retries == 0:\n                    raise\n                retries -= 1\n                time.sleep(sleep_interval)\n            else:\n                return", "response": "Attempts to call the clean method but will retry automatically if an error is raised."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreconstructing the filesystem of all volumes mounted by the parser by inspecting the last mount point and bind mounting everything.", "response": "def reconstruct(self):\n        \"\"\"Reconstructs the filesystem of all volumes mounted by the parser by inspecting the last mount point and\n        bind mounting everything.\n\n        :raises: NoRootFoundError if no root could be found\n        :return: the root :class:`Volume`\n        \"\"\"\n        volumes = list(sorted((v for v in self.get_volumes() if v.mountpoint and v.info.get('lastmountpoint')),\n                              key=lambda v: v.numeric_index))\n\n        try:\n            root = list(filter(lambda x: x.info.get('lastmountpoint') == '/', volumes))[0]\n        except IndexError:\n            logger.error(\"Could not find / while reconstructing, aborting!\")\n            raise NoRootFoundError()\n\n        volumes.remove(root)\n\n        for v in volumes:\n            if v.info.get('lastmountpoint') == root.info.get('lastmountpoint'):\n                logger.debug(\"Skipping volume %s as it has the same root as %s\", v, root)\n                continue\n            v.bindmount(os.path.join(root.mountpoint, v.info.get('lastmountpoint')[1:]))\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a subvolume adds it to this class and returns it.", "response": "def _make_subvolume(self, **args):\n        \"\"\"Creates a subvolume, adds it to this class and returns it.\"\"\"\n\n        from imagemounter.volume import Volume\n        v = Volume(disk=self.disk, parent=self.parent,\n                   volume_detector=self.volume_detector,\n                   **args)  # vstype is not passed down, let it decide for itself.\n        self.volumes.append(v)\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _make_single_subvolume(self, only_one=True, **args):\n\n        if only_one and self.volumes:\n            return self.volumes[0]\n\n        if self.parent.index is None:\n            index = '0'\n        else:\n            index = '{0}.0'.format(self.parent.index)\n        volume = self._make_subvolume(index=index, **args)\n        return volume", "response": "Creates a subvolume for this volume system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _determine_auto_detection_method():\n\n        if dependencies.pytsk3.is_available:\n            return 'pytsk3'\n        elif dependencies.mmls.is_available:\n            return 'mmls'\n        elif dependencies.parted.is_available:\n            return 'parted'\n        else:\n            raise PrerequisiteFailedError(\"No valid detection method is installed.\")", "response": "Determine whether auto detection method is available."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the disktype data from GPT volume systems.", "response": "def _load_disktype_data(self):\n        \"\"\"Calls the :command:`disktype` command and obtains the disk GUID from GPT volume systems. As we\n        are running the tool anyway, the label is also extracted from the tool if it is not yet set.\n\n        The disktype data is only loaded and not assigned to volumes yet.\n        \"\"\"\n\n        if not _util.command_exists('disktype'):\n            logger.warning(\"disktype not installed, could not detect volume type\")\n            return None\n\n        disktype = _util.check_output_(['disktype', self.parent.get_raw_path()]).strip()\n\n        current_partition = None\n        for line in disktype.splitlines():\n            if not line:\n                continue\n            # noinspection PyBroadException\n            try:\n                line = line.strip()\n\n                find_partition_nr = re.match(r\"^Partition (\\d+):\", line)\n                if find_partition_nr:\n                    current_partition = int(find_partition_nr.group(1))\n                elif current_partition is not None:\n                    if line.startswith(\"Type \") and \"GUID\" in line:\n                        self._disktype[current_partition]['guid'] = \\\n                            line[line.index('GUID') + 5:-1].strip()  # output is between ()\n                    elif line.startswith(\"Partition Name \"):\n                        self._disktype[current_partition]['label'] = \\\n                            line[line.index('Name ') + 6:-1].strip()  # output is between \"\"\n            except Exception:\n                logger.exception(\"Error while parsing disktype output\")\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _assign_disktype_data(self, volume, slot=None):\n\n        if slot is None:\n            slot = volume.slot\n        if slot in self._disktype:\n            data = self._disktype[slot]\n            if not volume.info.get('guid') and 'guid' in data:\n                volume.info['guid'] = data['guid']\n            if not volume.info.get('label') and 'label' in data:\n                volume.info['label'] = data['label']", "response": "Assigns cached disktype data to a volume."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _format_index(self, volume_system, idx):\n\n        if volume_system.parent.index is not None:\n            return '{0}.{1}'.format(volume_system.parent.index, idx)\n        else:\n            return str(idx)", "response": "Returns a formatted index given the disk index idx."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetect a single volume. It should not be called other than from a disk.", "response": "def detect(self, volume_system, vstype='detect'):\n        \"\"\"'Detects' a single volume. It should not be called other than from a :class:`Disk`.\"\"\"\n        volume = volume_system._make_single_subvolume(offset=0)\n        is_directory = os.path.isdir(volume_system.parent.get_raw_path())\n\n        if is_directory:\n            filesize = _util.check_output_(['du', '-scDb', volume_system.parent.get_raw_path()]).strip()\n            if filesize:\n                volume.size = int(filesize.splitlines()[-1].split()[0])\n\n        else:\n            description = _util.check_output_(['file', '-sL', volume_system.parent.get_raw_path()]).strip()\n            if description:\n                # description is the part after the :, until the first comma\n                volume.info['fsdescription'] = description.split(': ', 1)[1].split(',', 1)[0].strip()\n                if 'size' in description:\n                    volume.size = int(re.findall(r'size:? (\\d+)', description)[0])\n                else:\n                    volume.size = os.path.getsize(volume_system.parent.get_raw_path())\n\n        volume.flag = 'alloc'\n        volume_system.volume_source = 'single'\n        volume_system._assign_disktype_data(volume)\n        yield volume"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding all volumes based on the pytsk3 library.", "response": "def _find_volumes(self, volume_system, vstype='detect'):\n        \"\"\"Finds all volumes based on the pytsk3 library.\"\"\"\n\n        try:\n            # noinspection PyUnresolvedReferences\n            import pytsk3\n        except ImportError:\n            logger.error(\"pytsk3 not installed, could not detect volumes\")\n            raise ModuleNotFoundError(\"pytsk3\")\n\n        baseimage = None\n        try:\n            # ewf raw image is now available on base mountpoint\n            # either as ewf1 file or as .dd file\n            raw_path = volume_system.parent.get_raw_path()\n            # noinspection PyBroadException\n            try:\n                baseimage = pytsk3.Img_Info(raw_path)\n            except Exception:\n                logger.error(\"Failed retrieving image info (possible empty image).\", exc_info=True)\n                return []\n\n            try:\n                volumes = pytsk3.Volume_Info(baseimage, getattr(pytsk3, 'TSK_VS_TYPE_' + vstype.upper()),\n                                             volume_system.parent.offset // volume_system.disk.block_size)\n                volume_system.volume_source = 'multi'\n                return volumes\n            except Exception as e:\n                # some bug in sleuthkit makes detection sometimes difficult, so we hack around it:\n                if \"(GPT or DOS at 0)\" in str(e) and vstype != 'gpt':\n                    volume_system.vstype = 'gpt'\n                    # noinspection PyBroadException\n                    try:\n                        logger.warning(\"Error in retrieving volume info: TSK couldn't decide between GPT and DOS, \"\n                                       \"choosing GPT for you. Use --vstype=dos to force DOS.\", exc_info=True)\n                        volumes = pytsk3.Volume_Info(baseimage, getattr(pytsk3, 'TSK_VS_TYPE_GPT'))\n                        volume_system.volume_source = 'multi'\n                        return volumes\n                    except Exception as e:\n                        logger.exception(\"Failed retrieving image info (possible empty image).\")\n                        raise SubsystemError(e)\n                else:\n                    logger.exception(\"Failed retrieving image info (possible empty image).\")\n                    raise SubsystemError(e)\n        finally:\n            if baseimage:\n                baseimage.close()\n                del baseimage"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef detect(self, volume_system, vstype='detect'):\n\n        # for some reason, parted does not properly return extended volume types in its machine\n        # output, so we need to execute it twice.\n        meta_volumes = []\n        # noinspection PyBroadException\n        try:\n            output = _util.check_output_(['parted', volume_system.parent.get_raw_path(), 'print'], stdin=subprocess.PIPE)\n            for line in output.splitlines():\n                if 'extended' in line:\n                    meta_volumes.append(int(line.split()[0]))\n        except Exception:\n            logger.exception(\"Failed executing parted command.\")\n            # skip detection of meta volumes\n\n        # noinspection PyBroadException\n        try:\n            # parted does not support passing in the vstype. It either works, or it doesn't.\n            cmd = ['parted', volume_system.parent.get_raw_path(), '-sm', 'unit s', 'print free']\n            output = _util.check_output_(cmd, stdin=subprocess.PIPE)\n            volume_system.volume_source = 'multi'\n        except Exception as e:\n            logger.exception(\"Failed executing parted command\")\n            raise SubsystemError(e)\n\n        num = 0\n        for line in output.splitlines():\n            if line.startswith(\"Warning\") or not line or ':' not in line or line.startswith(self.parent.get_raw_path()):\n                continue\n            line = line[:-1]  # remove last ;\n            try:\n                slot, start, end, length, description = line.split(':', 4)\n                if ':' in description:\n                    description, label, flags = description.split(':', 2)\n                else:\n                    description, label, flags = description, '', ''\n\n                try:\n                    slot = int(slot)\n                except ValueError:\n                    continue\n\n                volume = volume_system._make_subvolume(\n                    index=self._format_index(volume_system, num),\n                    offset=int(start[:-1]) * volume_system.disk.block_size,  # remove last s\n                    size=int(length[:-1]) * volume_system.disk.block_size)\n                volume.info['fsdescription'] = description\n                if label:\n                    volume.info['label'] = label\n                if flags:\n                    volume.info['parted_flags'] = flags\n\n                # TODO: detection of meta volumes\n\n                if description == 'free':\n                    volume.flag = 'unalloc'\n                    logger.info(\"Found unallocated space: block offset: {0}, length: {1}\".format(start[:-1],\n                                                                                                 length[:-1]))\n                elif slot in meta_volumes:\n                    volume.flag = 'meta'\n                    volume.slot = slot\n                    logger.info(\"Found meta volume: block offset: {0}, length: {1}\".format(start[:-1], length[:-1]))\n                else:\n                    volume.flag = 'alloc'\n                    volume.slot = slot\n                    volume_system._assign_disktype_data(volume)\n                    logger.info(\"Found allocated {2}: block offset: {0}, length: {1} \"\n                                .format(start[:-1], length[:-1], volume.info['fsdescription']))\n            except AttributeError:\n                logger.exception(\"Error while parsing parted output\")\n                continue\n\n            num += 1\n\n            yield volume", "response": "Finds and mounts all volumes based on parted."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef detect(self, volume_system, vstype='detect'):\n\n        try:\n            cmd = ['mmls']\n            if volume_system.parent.offset:\n                cmd.extend(['-o', str(volume_system.parent.offset // volume_system.disk.block_size)])\n            if vstype in ('dos', 'mac', 'bsd', 'sun', 'gpt'):\n                cmd.extend(['-t', vstype])\n            cmd.append(volume_system.parent.get_raw_path())\n            output = _util.check_output_(cmd, stderr=subprocess.STDOUT)\n            volume_system.volume_source = 'multi'\n\n        except Exception as e:\n            # some bug in sleuthkit makes detection sometimes difficult, so we hack around it:\n            if hasattr(e, 'output') and \"(GPT or DOS at 0)\" in e.output.decode() and vstype != 'gpt':\n                volume_system.vstype = 'gpt'\n                # noinspection PyBroadException\n                try:\n                    logger.warning(\"Error in retrieving volume info: mmls couldn't decide between GPT and DOS, \"\n                                   \"choosing GPT for you. Use --vstype=dos to force DOS.\", exc_info=True)\n                    cmd = ['mmls', '-t', 'gpt', self.parent.get_raw_path()]\n                    output = _util.check_output_(cmd, stderr=subprocess.STDOUT)\n                    volume_system.volume_source = 'multi'\n                except Exception as e:\n                    logger.exception(\"Failed executing mmls command\")\n                    raise SubsystemError(e)\n            else:\n                logger.exception(\"Failed executing mmls command\")\n                raise SubsystemError(e)\n\n        output = output.split(\"Description\", 1)[-1]\n        for line in output.splitlines():\n            if not line:\n                continue\n            # noinspection PyBroadException\n            try:\n                values = line.split(None, 5)\n\n                # sometimes there are only 5 elements available\n                description = ''\n                index, slot, start, end, length = values[0:5]\n                if len(values) > 5:\n                    description = values[5]\n\n                volume = volume_system._make_subvolume(\n                    index=self._format_index(volume_system, int(index[:-1])),\n                    offset=int(start) * volume_system.disk.block_size,\n                    size=int(length) * volume_system.disk.block_size\n                )\n                volume.info['fsdescription'] = description\n            except Exception:\n                logger.exception(\"Error while parsing mmls output\")\n                continue\n\n            if slot.lower() == 'meta':\n                volume.flag = 'meta'\n                logger.info(\"Found meta volume: block offset: {0}, length: {1}\".format(start, length))\n            elif slot.lower().startswith('-----'):\n                volume.flag = 'unalloc'\n                logger.info(\"Found unallocated space: block offset: {0}, length: {1}\".format(start, length))\n            else:\n                volume.flag = 'alloc'\n                if \":\" in slot:\n                    volume.slot = _util.determine_slot(*slot.split(':'))\n                else:\n                    volume.slot = _util.determine_slot(-1, slot)\n                volume_system._assign_disktype_data(volume)\n                logger.info(\"Found allocated {2}: block offset: {0}, length: {1} \".format(start, length,\n                                                                                          volume.info['fsdescription']))\n\n            yield volume", "response": "Finds and mounts all volumes based on mmls."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetects volume shadow copy volumes in the specified path.", "response": "def detect(self, volume_system, vstype='detect'):\n        \"\"\"Detect volume shadow copy volumes in the specified path.\"\"\"\n\n        path = volume_system.parent._paths['vss']\n\n        try:\n            volume_info = _util.check_output_([\"vshadowinfo\", \"-o\", str(volume_system.parent.offset),\n                                               volume_system.parent.get_raw_path()])\n        except Exception as e:\n            logger.exception(\"Failed obtaining info from the volume shadow copies.\")\n            raise SubsystemError(e)\n\n        current_store = None\n        for line in volume_info.splitlines():\n            line = line.strip()\n            if line.startswith(\"Store:\"):\n                idx = line.split(\":\")[-1].strip()\n                current_store = volume_system._make_subvolume(\n                    index=self._format_index(volume_system, idx), flag='alloc', offset=0\n                )\n                current_store._paths['vss_store'] = os.path.join(path, 'vss' + idx)\n                current_store.info['fsdescription'] = 'VSS Store'\n            elif line.startswith(\"Volume size\"):\n                current_store.size = int(line.split(\":\")[-1].strip().split()[0])\n            elif line.startswith(\"Creation time\"):\n                current_store.info['creation_time'] = line.split(\":\")[-1].strip()\n\n        return volume_system.volumes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngather information about lvolumes gathering their label size and raw path", "response": "def detect(self, volume_system, vstype='detect'):\n        \"\"\"Gather information about lvolumes, gathering their label, size and raw path\"\"\"\n\n        volume_group = volume_system.parent.info.get('volume_group')\n\n        result = _util.check_output_([\"lvm\", \"lvdisplay\", volume_group])\n        cur_v = None\n        for l in result.splitlines():\n            if \"--- Logical volume ---\" in l:\n                cur_v = volume_system._make_subvolume(\n                    index=self._format_index(volume_system, len(volume_system)),\n                    flag='alloc'\n                )\n                cur_v.info['fsdescription'] = 'Logical Volume'\n            if \"LV Name\" in l:\n                cur_v.info['label'] = l.replace(\"LV Name\", \"\").strip()\n            if \"LV Size\" in l:\n                size, unit = l.replace(\"LV Size\", \"\").strip().split(\" \", 1)\n                cur_v.size = int(float(size.replace(',', '.')) * {'KiB': 1024, 'MiB': 1024 ** 2,\n                                                                  'GiB': 1024 ** 3, 'TiB': 1024 ** 4}.get(unit, 1))\n            if \"LV Path\" in l:\n                cur_v._paths['lv'] = l.replace(\"LV Path\", \"\").strip()\n                cur_v.offset = 0\n\n        logger.info(\"{0} volumes found\".format(len(volume_system)))\n        volume_system.volume_source = 'multi'\n        return volume_system.volumes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_fstype_from_parser(self, fstype=None):\n        if fstype:\n            self.fstype = fstype\n        elif self.index in self.disk.parser.fstypes:\n            self.fstype = self.disk.parser.fstypes[self.index]\n        elif '*' in self.disk.parser.fstypes:\n            self.fstype = self.disk.parser.fstypes['*']\n        elif '?' in self.disk.parser.fstypes and self.disk.parser.fstypes['?'] is not None:\n            self.fstype = \"?\" + self.disk.parser.fstypes['?']\n        else:\n            self.fstype = \"\"\n\n        if self.fstype in VOLUME_SYSTEM_TYPES:\n            self.volumes.vstype = self.fstype\n            self.fstype = 'volumesystem'\n\n        # convert fstype from string to a FileSystemType object\n        if not isinstance(self.fstype, filesystems.FileSystemType):\n            if self.fstype.startswith(\"?\"):\n                fallback = FILE_SYSTEM_TYPES[self.fstype[1:]]\n                self.fstype = filesystems.FallbackFileSystemType(fallback)\n            else:\n                self.fstype = FILE_SYSTEM_TYPES[self.fstype]", "response": "Load fstype information from the parser instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a generic description of the volume.", "response": "def get_description(self, with_size=True, with_index=True):\n        \"\"\"Obtains a generic description of the volume, containing the file system type, index, label and NTFS version.\n        If *with_size* is provided, the volume size is also included.\n        \"\"\"\n\n        desc = ''\n\n        if with_size and self.size:\n            desc += '{0} '.format(self.get_formatted_size())\n\n        s = self.info.get('statfstype') or self.info.get('fsdescription') or '-'\n        if with_index:\n            desc += '{1}:{0}'.format(s, self.index)\n        else:\n            desc += s\n\n        if self.info.get('label'):\n            desc += ' {0}'.format(self.info.get('label'))\n\n        if self.info.get('version'):  # NTFS\n            desc += ' [{0}]'.format(self.info.get('version'))\n\n        return desc"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nobtains the size of the volume in a human - readable format ( i. e. in TiBs GiBs or MiBs.", "response": "def get_formatted_size(self):\n        \"\"\"Obtains the size of the volume in a human-readable format (i.e. in TiBs, GiBs or MiBs).\"\"\"\n\n        if self.size is not None:\n            if self.size < 1024:\n                return \"{0} B\".format(self.size)\n            elif self.size < 1024 ** 2:\n                return \"{0} KiB\".format(round(self.size / 1024, 2))\n            elif self.size < 1024 ** 3:\n                return \"{0} MiB\".format(round(self.size / 1024 ** 2, 2))\n            elif self.size < 1024 ** 4:\n                return \"{0} GiB\".format(round(self.size / 1024 ** 3, 2))\n            else:\n                return \"{0} TiB\".format(round(self.size / 1024 ** 4, 2))\n        else:\n            return self.size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the FS type from the blkid command.", "response": "def _get_blkid_type(self):\n        \"\"\"Retrieves the FS type from the blkid command.\"\"\"\n        try:\n            result = _util.check_output_(['blkid', '-p', '-O', str(self.offset), self.get_raw_path()])\n            if not result:\n                return None\n\n            # noinspection PyTypeChecker\n            blkid_result = dict(re.findall(r'([A-Z]+)=\"(.+?)\"', result))\n\n            self.info['blkid_data'] = blkid_result\n\n            if 'PTTYPE' in blkid_result and 'TYPE' not in blkid_result:\n                return blkid_result.get('PTTYPE')\n            else:\n                return blkid_result.get('TYPE')\n\n        except Exception:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking the volume for its magic bytes and returns the magic.", "response": "def _get_magic_type(self):\n        \"\"\"Checks the volume for its magic bytes and returns the magic.\"\"\"\n\n        try:\n            with io.open(self.disk.get_fs_path(), \"rb\") as file:\n                file.seek(self.offset)\n                fheader = file.read(min(self.size, 4096) if self.size else 4096)\n        except IOError:\n            logger.exception(\"Failed reading first 4K bytes from volume.\")\n            return None\n\n        # TODO fallback to img-cat image -s blocknum | file -\n        # if we were able to load the module magic\n        try:\n            # noinspection PyUnresolvedReferences\n            import magic\n\n            if hasattr(magic, 'from_buffer'):\n                # using https://github.com/ahupp/python-magic\n                logger.debug(\"Using python-magic Python package for file type magic\")\n                result = magic.from_buffer(fheader).decode()\n                self.info['magic_data'] = result\n                return result\n\n            elif hasattr(magic, 'open'):\n                # using Magic file extensions by Rueben Thomas (Ubuntu python-magic module)\n                logger.debug(\"Using python-magic system package for file type magic\")\n                ms = magic.open(magic.NONE)\n                ms.load()\n                result = ms.buffer(fheader)\n                ms.close()\n                self.info['magic_data'] = result\n                return result\n\n            else:\n                logger.warning(\"The python-magic module is not available, but another module named magic was found.\")\n\n        except ImportError:\n            logger.warning(\"The python-magic module is not available.\")\n        except AttributeError:\n            logger.warning(\"The python-magic module is not available, but another module named magic was found.\")\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the base mount path of the logical volume.", "response": "def get_raw_path(self, include_self=False):\n        \"\"\"Retrieves the base mount path of the volume. Typically equals to :func:`Disk.get_fs_path` but may also be the\n        path to a logical volume. This is used to determine the source path for a mount call.\n\n        The value returned is normally based on the parent's paths, e.g. if this volume is mounted to a more specific\n        path, only its children return the more specific path, this volume itself will keep returning the same path.\n        This makes for consistent use of the offset attribute. If you do not need this behaviour, you can override this\n        with the include_self argument.\n\n        This behavior, however, is not retained for paths that directly affect the volume itself, not the child volumes.\n        This includes VSS stores and LV volumes.\n        \"\"\"\n\n        v = self\n        if not include_self:\n            # lv / vss_store are exceptions, as it covers the volume itself, not the child volume\n            if v._paths.get('lv'):\n                return v._paths['lv']\n            elif v._paths.get('vss_store'):\n                return v._paths['vss_store']\n            elif v.parent and v.parent != self.disk:\n                v = v.parent\n            else:\n                return self.disk.get_fs_path()\n\n        while True:\n            if v._paths.get('lv'):\n                return v._paths['lv']\n            elif v._paths.get('bde'):\n                return v._paths['bde'] + '/bde1'\n            elif v._paths.get('luks'):\n                return '/dev/mapper/' + v._paths['luks']\n            elif v._paths.get('md'):\n                return v._paths['md']\n            elif v._paths.get('vss_store'):\n                return v._paths['vss_store']\n\n            # Only if the volume has a parent that is not a disk, we try to check the parent for a location.\n            if v.parent and v.parent != self.disk:\n                v = v.parent\n            else:\n                break\n        return self.disk.get_fs_path()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a label that is safe to add to a path in the mountpoint for this volume.", "response": "def get_safe_label(self):\n        \"\"\"Returns a label that is safe to add to a path in the mountpoint for this volume.\"\"\"\n\n        if self.info.get('label') == '/':\n            return 'root'\n\n        suffix = re.sub(r\"[/ \\(\\)]+\", \"_\", self.info.get('label')) if self.info.get('label') else \"\"\n        if suffix and suffix[0] == '_':\n            suffix = suffix[1:]\n        if len(suffix) > 2 and suffix[-1] == '_':\n            suffix = suffix[:-1]\n        return suffix"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncarving the free space of the volume.", "response": "def carve(self, freespace=True):\n        \"\"\"Call this method to carve the free space of the volume for (deleted) files. Note that photorec has its\n        own interface that temporarily takes over the shell.\n\n        :param freespace: indicates whether the entire volume should be carved (False) or only the free space (True)\n        :type freespace: bool\n        :return: string to the path where carved data is available\n        :raises CommandNotFoundError: if the underlying command does not exist\n        :raises SubsystemError: if the underlying command fails\n        :raises NoMountpointAvailableError: if there is no mountpoint available\n        :raises NoLoopbackAvailableError: if there is no loopback available (only when volume has no slot number)\n        \"\"\"\n\n        self._make_mountpoint(var_name='carve', suffix=\"carve\", in_paths=True)\n\n        # if no slot, we need to make a loopback that we can use to carve the volume\n        loopback_was_created_for_carving = False\n        if not self.slot:\n            if not self.loopback:\n                self._find_loopback()\n                # Can't carve if volume has no slot number and can't be mounted on loopback.\n                loopback_was_created_for_carving = True\n\n            # noinspection PyBroadException\n            try:\n                _util.check_call_([\"photorec\", \"/d\", self._paths['carve'] + os.sep, \"/cmd\", self.loopback,\n                                  (\"freespace,\" if freespace else \"\") + \"search\"])\n\n                # clean out the loop device if we created it specifically for carving\n                if loopback_was_created_for_carving:\n                    # noinspection PyBroadException\n                    try:\n                        _util.check_call_(['losetup', '-d', self.loopback])\n                    except Exception:\n                        pass\n                    else:\n                        self.loopback = \"\"\n\n                return self._paths['carve']\n            except Exception as e:\n                logger.exception(\"Failed carving the volume.\")\n                raise SubsystemError(e)\n        else:\n            # noinspection PyBroadException\n            try:\n                _util.check_call_([\"photorec\", \"/d\", self._paths['carve'] + os.sep, \"/cmd\", self.get_raw_path(),\n                                  str(self.slot) + (\",freespace\" if freespace else \"\") + \",search\"])\n                return self._paths['carve']\n\n            except Exception as e:\n                logger.exception(\"Failed carving the volume.\")\n                raise SubsystemError(e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _should_mount(self, only_mount=None, skip_mount=None):\n\n        om = only_mount is None or \\\n            self.index in only_mount or \\\n            self.info.get('lastmountpoint') in only_mount or \\\n            self.info.get('label') in only_mount\n        sm = skip_mount is None or \\\n            (self.index not in skip_mount and\n             self.info.get('lastmountpoint') not in skip_mount and\n             self.info.get('label') not in skip_mount)\n        return om and sm", "response": "Indicates whether this volume should be mounted. Internal method used by imount. py"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init(self, only_mount=None, skip_mount=None, swallow_exceptions=True):\n        if swallow_exceptions:\n            self.exception = None\n\n        try:\n            if not self._should_mount(only_mount, skip_mount):\n                yield self\n                return\n\n            if not self.init_volume():\n                yield self\n                return\n\n        except ImageMounterError as e:\n            if swallow_exceptions:\n                self.exception = e\n            else:\n                raise\n\n        if not self.volumes:\n            yield self\n        else:\n            for v in self.volumes:\n                for s in v.init(only_mount, skip_mount, swallow_exceptions):\n                    yield s", "response": "Generator that mounts this volume and yields itself or recursively generates its subvolumes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_volume(self, fstype=None):\n\n        logger.debug(\"Initializing volume {0}\".format(self))\n\n        if not self._should_mount():\n            return False\n\n        if self.flag != 'alloc':\n            return False\n\n        if self.info.get('raid_status') == 'waiting':\n            logger.info(\"RAID array %s not ready for mounting\", self)\n            return False\n\n        if self.is_mounted:\n            logger.info(\"%s is currently mounted, not mounting it again\", self)\n            return False\n\n        logger.info(\"Mounting volume {0}\".format(self))\n        self.mount(fstype=fstype)\n        self.detect_mountpoint()\n\n        return True", "response": "Initializes a single RAID volume."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_mountpoint(self, casename=None, var_name='mountpoint', suffix='', in_paths=False):\n        parser = self.disk.parser\n\n        if parser.mountdir and not os.path.exists(parser.mountdir):\n            os.makedirs(parser.mountdir)\n\n        if parser.pretty:\n            md = parser.mountdir or tempfile.gettempdir()\n            case_name = casename or self.disk.parser.casename or \\\n                \".\".join(os.path.basename(self.disk.paths[0]).split('.')[0:-1]) or \\\n                os.path.basename(self.disk.paths[0])\n\n            if self.disk.parser.casename == case_name:  # the casename is already in the path in this case\n                pretty_label = \"{0}-{1}\".format(self.index, self.get_safe_label() or self.fstype or 'volume')\n            else:\n                pretty_label = \"{0}-{1}-{2}\".format(case_name, self.index,\n                                                    self.get_safe_label() or self.fstype or 'volume')\n            if suffix:\n                pretty_label += \"-\" + suffix\n            path = os.path.join(md, pretty_label)\n\n            # check if path already exists, otherwise try to find another nice path\n            if os.path.exists(path):\n                for i in range(2, 100):\n                    path = os.path.join(md, pretty_label + \"-\" + str(i))\n                    if not os.path.exists(path):\n                        break\n                else:\n                    logger.error(\"Could not find free mountdir.\")\n                    raise NoMountpointAvailableError()\n\n            # noinspection PyBroadException\n            try:\n                os.mkdir(path, 777)\n                if in_paths:\n                    self._paths[var_name] = path\n                else:\n                    setattr(self, var_name, path)\n                return path\n            except Exception:\n                logger.exception(\"Could not create mountdir.\")\n                raise NoMountpointAvailableError()\n        else:\n            t = tempfile.mkdtemp(prefix='im_' + self.index + '_',\n                                 suffix='_' + self.get_safe_label() + (\"_\" + suffix if suffix else \"\"),\n                                 dir=parser.mountdir)\n            if in_paths:\n                self._paths[var_name] = t\n            else:\n                setattr(self, var_name, t)\n            return t", "response": "Creates a mountpoint for the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclears a created mountpoint. Does not unmount it merely deletes it.", "response": "def _clear_mountpoint(self):\n        \"\"\"Clears a created mountpoint. Does not unmount it, merely deletes it.\"\"\"\n\n        if self.mountpoint:\n            os.rmdir(self.mountpoint)\n            self.mountpoint = \"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind a free loopback device that can be used.", "response": "def _find_loopback(self, use_loopback=True, var_name='loopback'):\n        \"\"\"Finds a free loopback device that can be used. The loopback is stored in :attr:`loopback`. If *use_loopback*\n        is True, the loopback will also be used directly.\n\n        :returns: the loopback address\n        :raises NoLoopbackAvailableError: if no loopback could be found\n        \"\"\"\n\n        # noinspection PyBroadException\n        try:\n            loopback = _util.check_output_(['losetup', '-f']).strip()\n            setattr(self, var_name, loopback)\n        except Exception:\n            logger.warning(\"No free loopback device found.\", exc_info=True)\n            raise NoLoopbackAvailableError()\n\n        # noinspection PyBroadException\n        if use_loopback:\n            try:\n                cmd = ['losetup', '-o', str(self.offset), '--sizelimit', str(self.size),\n                       loopback, self.get_raw_path()]\n                if not self.disk.read_write:\n                    cmd.insert(1, '-r')\n                _util.check_call_(cmd, stdout=subprocess.PIPE)\n            except Exception:\n                logger.exception(\"Loopback device could not be mounted.\")\n                raise NoLoopbackAvailableError()\n        return loopback"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef determine_fs_type(self):\n\n        fstype_fallback = None\n        if isinstance(self.fstype, filesystems.FallbackFileSystemType):\n            fstype_fallback = self.fstype.fallback\n        elif isinstance(self.fstype, filesystems.FileSystemType):\n            return self.fstype\n\n        result = collections.Counter()\n\n        for source, description in (('fsdescription', self.info.get('fsdescription')),\n                                    ('guid', self.info.get('guid')),\n                                    ('blikid', self._get_blkid_type),\n                                    ('magic', self._get_magic_type)):\n            # For efficiency reasons, not all functions are called instantly.\n            if callable(description):\n                description = description()\n\n            logger.debug(\"Trying to determine fs type from {} '{}'\".format(source, description))\n            if not description:\n                continue\n\n            # Iterate over all results and update the certainty of all FS types\n            for type in FILE_SYSTEM_TYPES.values():\n                result.update(type.detect(source, description))\n\n            # Now sort the results by their certainty\n            logger.debug(\"Current certainty levels: {}\".format(result))\n\n            # If we have not found any candidates, we continue\n            if not result:\n                continue\n\n            # If we have candidates of which we are not entirely certain, we just continue\n            max_res = result.most_common(1)[0][1]\n            if max_res < 50:\n                logger.debug(\"Highest certainty item is lower than 50, continuing...\")\n            # If we have multiple candidates with the same score, we just continue\n            elif len([True for type, certainty in result.items() if certainty == max_res]) > 1:\n                logger.debug(\"Multiple items with highest certainty level, so continuing...\")\n            else:\n                self.fstype = result.most_common(1)[0][0]\n                return self.fstype\n\n        # Now be more lax with the fallback:\n        if result:\n            max_res = result.most_common(1)[0][1]\n            if max_res > 0:\n                self.fstype = result.most_common(1)[0][0]\n                return self.fstype\n        if fstype_fallback:\n            self.fstype = fstype_fallback\n            return self.fstype", "response": "Determines the filesystem type for this partition."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mount(self, fstype=None):\n\n        if not self.parent.is_mounted:\n            raise NotMountedError(self.parent)\n\n        if fstype is None:\n            fstype = self.determine_fs_type()\n        self._load_fsstat_data()\n\n        # Prepare mount command\n        try:\n            fstype.mount(self)\n\n            self.was_mounted = True\n            self.is_mounted = True\n            self.fstype = fstype\n\n        except Exception as e:\n            logger.exception(\"Execution failed due to {} {}\".format(type(e), e), exc_info=True)\n            if not isinstance(e, ImageMounterError):\n                raise SubsystemError(e)\n            else:\n                raise", "response": "Mounts the volume in the local filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bindmount(self, mountpoint):\n\n        if not self.mountpoint:\n            raise NotMountedError(self)\n        try:\n            _util.check_call_(['mount', '--bind', self.mountpoint, mountpoint], stdout=subprocess.PIPE)\n            if 'bindmounts' in self._paths:\n                self._paths['bindmounts'].append(mountpoint)\n            else:\n                self._paths['bindmounts'] = [mountpoint]\n            return True\n        except Exception as e:\n            logger.exception(\"Error bind mounting {0}.\".format(self))\n            raise SubsystemError(e)", "response": "Bind the volume to another mountpoint. Only works if the volume is already mounted."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_volumes(self):\n\n        if self.volumes:\n            volumes = []\n            for v in self.volumes:\n                volumes.extend(v.get_volumes())\n            volumes.append(self)\n            return volumes\n        else:\n            return [self]", "response": "Recursively gets a list of all subvolumes and the current volume."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_fsstat_data(self, timeout=3):\n\n        def stats_thread():\n            try:\n                cmd = ['fsstat', self.get_raw_path(), '-o', str(self.offset // self.disk.block_size)]\n\n                # Setting the fstype explicitly makes fsstat much faster and more reliable\n                # In some versions, the auto-detect yaffs2 check takes ages for large images\n                fstype = {\n                    \"ntfs\": \"ntfs\", \"fat\": \"fat\", \"ext\": \"ext\", \"iso\": \"iso9660\", \"hfs+\": \"hfs\",\n                    \"ufs\": \"ufs\", \"swap\": \"swap\", \"exfat\": \"exfat\",\n                }.get(self.fstype, None)\n                if fstype:\n                    cmd.extend([\"-f\", fstype])\n\n                logger.debug('$ {0}'.format(' '.join(cmd)))\n                stats_thread.process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n                for line in iter(stats_thread.process.stdout.readline, b''):\n                    line = line.decode('utf-8')\n                    logger.debug('< {0}'.format(line))\n                    if line.startswith(\"File System Type:\"):\n                        self.info['statfstype'] = line[line.index(':') + 2:].strip()\n                    elif line.startswith(\"Last Mount Point:\") or line.startswith(\"Last mounted on:\"):\n                        self.info['lastmountpoint'] = line[line.index(':') + 2:].strip().replace(\"//\", \"/\")\n                    elif line.startswith(\"Volume Name:\") and not self.info.get('label'):\n                        self.info['label'] = line[line.index(':') + 2:].strip()\n                    elif line.startswith(\"Version:\"):\n                        self.info['version'] = line[line.index(':') + 2:].strip()\n                    elif line.startswith(\"Source OS:\"):\n                        self.info['version'] = line[line.index(':') + 2:].strip()\n                    elif 'CYLINDER GROUP INFORMATION' in line or 'BLOCK GROUP INFORMATION' in line:\n                        # noinspection PyBroadException\n                        try:\n                            stats_thread.process.terminate()\n                            logger.debug(\"Terminated fsstat at cylinder/block group information.\")\n                        except Exception:\n                            pass\n                        break\n\n                if self.info.get('lastmountpoint') and self.info.get('label'):\n                    self.info['label'] = \"{0} ({1})\".format(self.info['lastmountpoint'], self.info['label'])\n                elif self.info.get('lastmountpoint') and not self.info.get('label'):\n                    self.info['label'] = self.info['lastmountpoint']\n                elif not self.info.get('lastmountpoint') and self.info.get('label') and \\\n                        self.info['label'].startswith(\"/\"):  # e.g. /boot1\n                    if self.info['label'].endswith(\"1\"):\n                        self.info['lastmountpoint'] = self.info['label'][:-1]\n                    else:\n                        self.info['lastmountpoint'] = self.info['label']\n\n            except Exception:  # ignore any exceptions here.\n                logger.exception(\"Error while obtaining stats.\")\n\n        stats_thread.process = None\n\n        thread = threading.Thread(target=stats_thread)\n        thread.start()\n        thread.join(timeout)\n        if thread.is_alive():\n            # noinspection PyBroadException\n            try:\n                stats_thread.process.terminate()\n            except Exception:\n                pass\n            thread.join()\n            logger.debug(\"Killed fsstat after {0}s\".format(timeout))", "response": "Load the stats data from the filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetects the mountpoint based on the mounted volume.", "response": "def detect_mountpoint(self):\n        \"\"\"Attempts to detect the previous mountpoint if this was not done through :func:`load_fsstat_data`. This\n        detection does some heuristic method on the mounted volume.\n        \"\"\"\n\n        if self.info.get('lastmountpoint'):\n            return self.info.get('lastmountpoint')\n        if not self.mountpoint:\n            return None\n\n        result = None\n        paths = os.listdir(self.mountpoint)\n        if 'grub' in paths:\n            result = '/boot'\n        elif 'usr' in paths and 'var' in paths and 'root' in paths:\n            result = '/'\n        elif 'bin' in paths and 'lib' in paths and 'local' in paths and 'src' in paths and 'usr' not in paths:\n            result = '/usr'\n        elif 'bin' in paths and 'lib' in paths and 'local' not in paths and 'src' in paths and 'usr' not in paths:\n            result = '/usr/local'\n        elif 'lib' in paths and 'local' in paths and 'tmp' in paths and 'var' not in paths:\n            result = '/var'\n        # elif sum(['bin' in paths, 'boot' in paths, 'cdrom' in paths, 'dev' in paths, 'etc' in paths, 'home' in paths,\n        #          'lib' in paths, 'lib64' in paths, 'media' in paths, 'mnt' in paths, 'opt' in paths,\n        #          'proc' in paths, 'root' in paths, 'sbin' in paths, 'srv' in paths, 'sys' in paths, 'tmp' in paths,\n        #          'usr' in paths, 'var' in paths]) > 11:\n        #    result = '/'\n\n        if result:\n            self.info['lastmountpoint'] = result\n            if not self.info.get('label'):\n                self.info['label'] = self.info['lastmountpoint']\n            logger.info(\"Detected mountpoint as {0} based on files in volume\".format(self.info['lastmountpoint']))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef require(*requirements, **kwargs):\n    # TODO: require(*requirements, none_on_failure=False) is not supported by Python 2\n    none_on_failure = kwargs.get('none_on_failure', False)\n\n    def inner(f):\n        @functools.wraps(f)\n        def wrapper(*args, **kwargs):\n            for req in requirements:\n                if none_on_failure:\n                    if not getattr(req, 'is_available'):\n                        return None\n                else:\n                    getattr(req, 'require')()\n            return f(*args, **kwargs)\n        return wrapper\n    return inner", "response": "Decorator that can be used to require requirements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a string describing whether the dependency is installed.", "response": "def status_message(self):\n        \"\"\"Detailed message about whether the dependency is installed.\n\n        :rtype: str\n        \"\"\"\n        if self.is_available:\n            return \"INSTALLED {0!s}\"\n        elif self.why and self.package:\n            return \"MISSING   {0!s:<20}needed for {0.why}, part of the {0.package} package\"\n        elif self.why:\n            return \"MISSING   {0!s:<20}needed for {0.why}\"\n        elif self.package:\n            return \"MISSING   {0!s:<20}part of the {0.package} package\"\n        else:\n            return \"MISSING   {0!s:<20}\""}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetects the type of a volume based on the provided information. It returns the plausibility for all file system types as a dict. Although it is only responsible for returning its own plausibility, it is possible that one type of filesystem is more likely than another, e.g. when NTFS detects it is likely to be NTFS, it can also update the plausibility of exFAT to indicate it is less likely. All scores a cumulative. When multiple sources are used, it is also cumulative. For instance, if run 1 is 25 certain, and run 2 is 25 certain as well, it will become 50 certain. :meth:`Volume.detect_fs_type` will return immediately if the score is higher than 50 and there is only 1 FS type with the highest score. Otherwise, it will continue with the next run. If at the end of all runs no viable FS type was found, it will return the highest scoring FS type (if it is > 0), otherwise it will return the FS type fallback. :param source: The source of the description :param description: The description to detect with :return: Dict with mapping of FsType() objects to scores", "response": "def detect(self, source, description):\n        \"\"\"Detects the type of a volume based on the provided information. It returns the plausibility for all\n        file system types as a dict. Although it is only responsible for returning its own plausibility, it is possible\n        that one type of filesystem is more likely than another, e.g. when NTFS detects it is likely to be NTFS, it\n        can also update the plausibility of exFAT to indicate it is less likely.\n\n        All scores a cumulative. When multiple sources are used, it is also cumulative. For instance, if run 1 is 25\n        certain, and run 2 is 25 certain as well, it will become 50 certain.\n\n        :meth:`Volume.detect_fs_type` will return immediately if the score is higher than 50 and there is only 1\n        FS type with the highest score. Otherwise, it will continue with the next run. If at the end of all runs no\n        viable FS type was found, it will return the highest scoring FS type (if it is > 0), otherwise it will return\n        the FS type fallback.\n\n        :param source: The source of the description\n        :param description: The description to detect with\n        :return: Dict with mapping of FsType() objects to scores\n        \"\"\"\n\n        if source == \"guid\" and description in self.guids:\n            return {self: 100}\n\n        description = description.lower()\n        if description == self.type:\n            return {self: 100}\n        elif re.search(r\"\\b\" + self.type + r\"\\b\", description):\n            return {self: 80}\n        elif any((re.search(r\"\\b\" + alias + r\"\\b\", description) for alias in self.aliases)):\n            return {self: 70}\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mount(self, volume):\n\n        volume._make_mountpoint()\n        try:\n            self._call_mount(volume, volume.mountpoint, self._mount_type or self.type, self._mount_opts)\n        except Exception:\n            # undo the creation of the mountpoint\n            volume._clear_mountpoint()\n            raise", "response": "Mounts the given volume on the provided mountpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call_mount(self, volume, mountpoint, type=None, opts=\"\"):\n\n        # default arguments for calling mount\n        if opts and not opts.endswith(','):\n            opts += \",\"\n        opts += 'loop,offset=' + str(volume.offset) + ',sizelimit=' + str(volume.size)\n\n        # building the command\n        cmd = ['mount', volume.get_raw_path(), mountpoint, '-o', opts]\n\n        # add read-only if needed\n        if not volume.disk.read_write:\n            cmd[-1] += ',ro'\n\n        # add the type if specified\n        if type is not None:\n            cmd += ['-t', type]\n\n        _util.check_output_(cmd, stderr=subprocess.STDOUT)", "response": "Calls the mount command specifying the type and mount options."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming specific operations to mount a JFFS2 image.", "response": "def mount(self, volume):\n        \"\"\"Perform specific operations to mount a JFFS2 image. This kind of image is sometimes used for things like\n        bios images. so external tools are required but given this method you don't have to memorize anything and it\n        works fast and easy.\n\n        Note that this module might not yet work while mounting multiple images at the same time.\n        \"\"\"\n        # we have to make a ram-device to store the image, we keep 20% overhead\n        size_in_kb = int((volume.size / 1024) * 1.2)\n        _util.check_call_(['modprobe', '-v', 'mtd'])\n        _util.check_call_(['modprobe', '-v', 'jffs2'])\n        _util.check_call_(['modprobe', '-v', 'mtdram', 'total_size={}'.format(size_in_kb), 'erase_size=256'])\n        _util.check_call_(['modprobe', '-v', 'mtdblock'])\n        _util.check_call_(['dd', 'if=' + volume.get_raw_path(), 'of=/dev/mtd0'])\n        _util.check_call_(['mount', '-t', 'jffs2', '/dev/mtdblock0', volume.mountpoint])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mount(self, volume):\n\n        # Open a loopback device\n        volume._find_loopback()\n\n        # Check if this is a LUKS device\n        # noinspection PyBroadException\n        try:\n            _util.check_call_([\"cryptsetup\", \"isLuks\", volume.loopback], stderr=subprocess.STDOUT)\n            # ret = 0 if isLuks\n        except Exception:\n            logger.warning(\"Not a LUKS volume\")\n            # clean the loopback device, we want this method to be clean as possible\n            # noinspection PyBroadException\n            try:\n                volume._free_loopback()\n            except Exception:\n                pass\n            raise IncorrectFilesystemError()\n\n        try:\n            extra_args = []\n            key = None\n            if volume.key:\n                t, v = volume.key.split(':', 1)\n                if t == 'p':  # passphrase\n                    key = v\n                elif t == 'f':  # key-file\n                    extra_args = ['--key-file', v]\n                elif t == 'm':  # master-key-file\n                    extra_args = ['--master-key-file', v]\n            else:\n                logger.warning(\"No key material provided for %s\", volume)\n        except ValueError:\n            logger.exception(\"Invalid key material provided (%s) for %s. Expecting [arg]:[value]\", volume.key, volume)\n            volume._free_loopback()\n            raise ArgumentError()\n\n        # Open the LUKS container\n        volume._paths['luks'] = 'image_mounter_luks_' + str(random.randint(10000, 99999))\n\n        # noinspection PyBroadException\n        try:\n            cmd = [\"cryptsetup\", \"luksOpen\", volume.loopback, volume._paths['luks']]\n            cmd.extend(extra_args)\n            if not volume.disk.read_write:\n                cmd.insert(1, '-r')\n\n            if key is not None:\n                logger.debug('$ {0}'.format(' '.join(cmd)))\n                # for py 3.2+, we could have used input=, but that doesn't exist in py2.7.\n                p = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n                p.communicate(key.encode(\"utf-8\"))\n                p.wait()\n                retcode = p.poll()\n                if retcode:\n                    raise KeyInvalidError()\n            else:\n                _util.check_call_(cmd)\n        except ImageMounterError:\n            del volume._paths['luks']\n            volume._free_loopback()\n            raise\n        except Exception as e:\n            del volume._paths['luks']\n            volume._free_loopback()\n            raise SubsystemError(e)\n\n        size = None\n        # noinspection PyBroadException\n        try:\n            result = _util.check_output_([\"cryptsetup\", \"status\", volume._paths['luks']])\n            for l in result.splitlines():\n                if \"size:\" in l and \"key\" not in l:\n                    size = int(l.replace(\"size:\", \"\").replace(\"sectors\", \"\").strip()) * volume.disk.block_size\n        except Exception:\n            pass\n\n        container = volume.volumes._make_single_subvolume(flag='alloc', offset=0, size=size)\n        container.info['fsdescription'] = 'LUKS Volume'\n\n        return container", "response": "This command is an alternative to the mount command that opens a LUKS container. The command that opens a LUKS container is used to mount the volume."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mount(self, volume):\n\n        volume._paths['bde'] = tempfile.mkdtemp(prefix='image_mounter_bde_')\n\n        try:\n            if volume.key:\n                t, v = volume.key.split(':', 1)\n                key = ['-' + t, v]\n            else:\n                logger.warning(\"No key material provided for %s\", volume)\n                key = []\n        except ValueError:\n            logger.exception(\"Invalid key material provided (%s) for %s. Expecting [arg]:[value]\", volume.key, volume)\n            raise ArgumentError()\n\n        # noinspection PyBroadException\n        try:\n            cmd = [\"bdemount\", volume.get_raw_path(), volume._paths['bde'], '-o', str(volume.offset)]\n            cmd.extend(key)\n            _util.check_call_(cmd)\n        except Exception as e:\n            del volume._paths['bde']\n            logger.exception(\"Failed mounting BDE volume %s.\", volume)\n            raise SubsystemError(e)\n\n        container = volume.volumes._make_single_subvolume(flag='alloc', offset=0, size=volume.size)\n        container.info['fsdescription'] = 'BDE Volume'\n\n        return container", "response": "Mounts a BDE container."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmounts a volume to the LVM.", "response": "def mount(self, volume):\n        \"\"\"Performs mount actions on a LVM. Scans for active volume groups from the loopback device, activates it\n        and fills :attr:`volumes` with the logical volumes.\n\n        :raises NoLoopbackAvailableError: when no loopback was available\n        :raises IncorrectFilesystemError: when the volume is not a volume group\n        \"\"\"\n        os.environ['LVM_SUPPRESS_FD_WARNINGS'] = '1'\n\n        # find free loopback device\n        volume._find_loopback()\n        time.sleep(0.2)\n\n        try:\n            # Scan for new lvm volumes\n            result = _util.check_output_([\"lvm\", \"pvscan\"])\n            for l in result.splitlines():\n                if volume.loopback in l or (volume.offset == 0 and volume.get_raw_path() in l):\n                    for vg in re.findall(r'VG (\\S+)', l):\n                        volume.info['volume_group'] = vg\n\n            if not volume.info.get('volume_group'):\n                logger.warning(\"Volume is not a volume group. (Searching for %s)\", volume.loopback)\n                raise IncorrectFilesystemError()\n\n            # Enable lvm volumes\n            _util.check_call_([\"lvm\", \"vgchange\", \"-a\", \"y\", volume.info['volume_group']], stdout=subprocess.PIPE)\n        except Exception:\n            volume._free_loopback()\n            raise\n\n        volume.volumes.vstype = 'lvm'\n        # fills it up.\n        for _ in volume.volumes.detect_volumes('lvm'):\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmounts the given volume to a RAID system.", "response": "def mount(self, volume):\n        \"\"\"Add the volume to a RAID system. The RAID array is activated as soon as the array can be activated.\n\n        :raises NoLoopbackAvailableError: if no loopback device was found\n        \"\"\"\n\n        volume._find_loopback()\n\n        raid_status = None\n        try:\n            # use mdadm to mount the loopback to a md device\n            # incremental and run as soon as available\n            output = _util.check_output_(['mdadm', '-IR', volume.loopback], stderr=subprocess.STDOUT)\n\n            match = re.findall(r\"attached to ([^ ,]+)\", output)\n            if match:\n                volume._paths['md'] = os.path.realpath(match[0])\n                if 'which is already active' in output:\n                    logger.info(\"RAID is already active in other volume, using %s\", volume._paths['md'])\n                    raid_status = 'active'\n                elif 'not enough to start' in output:\n                    volume._paths['md'] = volume._paths['md'].replace(\"/dev/md/\", \"/dev/md\")\n                    logger.info(\"RAID volume added, but not enough to start %s\", volume._paths['md'])\n                    raid_status = 'waiting'\n                else:\n                    logger.info(\"RAID started at {0}\".format(volume._paths['md']))\n                    raid_status = 'active'\n        except Exception as e:\n            logger.exception(\"Failed mounting RAID.\")\n            volume._free_loopback()\n            raise SubsystemError(e)\n\n        # search for the RAID volume\n        for v in volume.disk.parser.get_volumes():\n            if v._paths.get(\"md\") == volume._paths['md'] and v.volumes:\n                logger.debug(\"Adding existing volume %s to volume %s\", v.volumes[0], volume)\n                v.volumes[0].info['raid_status'] = raid_status\n                volume.volumes.volumes.append(v.volumes[0])\n                return v.volumes[0]\n        else:\n            logger.debug(\"Creating RAID volume for %s\", self)\n            container = volume.volumes._make_single_subvolume(flag='alloc', offset=0, size=volume.size)\n            container.info['fsdescription'] = 'RAID Volume'\n            container.info['raid_status'] = raid_status\n            return container"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nescape a string to make it usable in LaTeX text mode.", "response": "def escape(s, fold_newlines=True):\n    \"\"\"Escapes a string to make it usable in LaTeX text mode. Will replace\n    special characters as well as newlines.\n\n    Some problematic characters like ``[`` and ``]`` are escaped into groups\n    (e.g. ``{[}``), because they tend to cause problems when mixed with ``\\\\``\n    newlines otherwise.\n\n    :param s: The string to escape.\n    :param fold_newlines: If true, multiple newlines will be reduced to just a\n                          single ``\\\\``. Otherwise, whitespace is kept intact\n                          by adding multiple ``[n\\baselineskip]``.\n    \"\"\"\n\n    def sub(m):\n        c = m.group()\n        if c in CHAR_ESCAPE:\n            return CHAR_ESCAPE[c]\n\n        if c.isspace():\n            if fold_newlines:\n                return r'\\\\'\n            return r'\\\\[{}\\baselineskip]'.format(len(c))\n\n    return ESCAPE_RE.sub(sub, s)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_pdf(source, texinputs=[], builder=None):\n    if builder is None:\n        builders = PREFERRED_BUILDERS\n    elif builder not in BUILDERS:\n        raise RuntimeError('Invalid Builder specified')\n    else:\n        builders = (builder, )\n\n    for bld in builders:\n        bld_cls = BUILDERS[bld]\n        builder = bld_cls()\n        if not builder.is_available():\n            continue\n        return builder.build_pdf(source, texinputs)\n    else:\n        raise RuntimeError('No available builder could be instantiated. '\n                           'Please make sure LaTeX is installed.')", "response": "Builds a LaTeX source to PDF."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_log(log, context_size=3):\n    lines = log.splitlines()\n    errors = []\n\n    for n, line in enumerate(lines):\n        m = LATEX_ERR_RE.match(line)\n        if m:\n            err = m.groupdict().copy()\n            err['context'] = lines[n:n + context_size]\n            try:\n                err['line'] = int(err['line'])\n            except TypeError:\n                pass  # ignore invalid int conversion\n            errors.append(err)\n\n    return errors", "response": "Parses a latex log output and tries to extract error messages."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_env(*args, **kwargs):\n    ka = ENV_ARGS.copy()\n    ka.update(kwargs)\n\n    env = Environment(*args, **ka)\n    env.filters['e'] = LatexMarkup.escape\n    env.filters['escape'] = LatexMarkup.escape\n    env.filters['forceescape'] = LatexMarkup.escape  # FIXME: this is a bug\n    return env", "response": "Creates a new LaTeX - friendly environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_metadata_params(headers):\n\n    params = {}\n    metadata = {}\n    for header_name in headers:\n        if header_name.lower() in header_mapping:\n            params[header_mapping[header_name.lower()]] = headers[header_name]\n        else:\n            metadata[header_name] = headers[header_name]\n    return metadata, params", "response": "Given a dict of headers for s3 seperates those that are boto3\n    parameters and those that are metadata\n    parameters and those that are boto3\n    parameters and those that are boto3\n    parameters and those that are boto3\n    parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a hash for the contents of a file", "response": "def hash_file(filename):\n    \"\"\"\n    Generate a hash for the contents of a file\n    \"\"\"\n    hasher = hashlib.sha1()\n    with open(filename, 'rb') as f:\n        buf = f.read(65536)\n        while len(buf) > 0:\n            hasher.update(buf)\n            buf = f.read(65536)\n\n    return hasher.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_bucket_name(**values):\n    app = current_app\n    # manage other special values, all have no meaning for static urls\n    values.pop('_external', False)  # external has no meaning here\n    values.pop('_anchor', None)  # anchor as well\n    values.pop('_method', None)  # method too\n\n    url_style = get_setting('FLASKS3_URL_STYLE', app)\n    if url_style == 'host':\n        url_format = '{bucket_name}.{bucket_domain}'\n    elif url_style == 'path':\n        url_format = '{bucket_domain}/{bucket_name}'\n    else:\n        raise ValueError('Invalid S3 URL style: \"{}\"'.format(url_style))\n\n    if get_setting('FLASKS3_CDN_DOMAIN', app):\n        bucket_path = '{}'.format(get_setting('FLASKS3_CDN_DOMAIN', app))\n\n    else:\n        bucket_path = url_format.format(\n            bucket_name=get_setting('FLASKS3_BUCKET_NAME', app),\n            bucket_domain=get_setting('FLASKS3_BUCKET_DOMAIN', app),\n        )\n\n    bucket_path += _get_statics_prefix(app).rstrip('/')\n\n    return bucket_path, values", "response": "Generates the bucket name for url_for."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a URL to the given endpoint.", "response": "def url_for(endpoint, **values):\n    \"\"\"\n    Generates a URL to the given endpoint.\n\n    If the endpoint is for a static resource then an Amazon S3 URL is\n    generated, otherwise the call is passed on to `flask.url_for`.\n\n    Because this function is set as a jinja environment variable when\n    `FlaskS3.init_app` is invoked, this function replaces\n    `flask.url_for` in templates automatically. It is unlikely that this\n    function will need to be directly called from within your\n    application code, unless you need to refer to static assets outside\n    of your templates.\n    \"\"\"\n    app = current_app\n    if app.config.get('TESTING', False) and not app.config.get('FLASKS3_OVERRIDE_TESTING', True):\n        return flask_url_for(endpoint, **values)\n    if 'FLASKS3_BUCKET_NAME' not in app.config:\n        raise ValueError(\"FLASKS3_BUCKET_NAME not found in app configuration.\")\n\n    if endpoint == 'static' or endpoint.endswith('.static'):\n        scheme = 'https'\n        if not app.config.get(\"FLASKS3_USE_HTTPS\", True):\n            scheme = 'http'\n\n        # allow per url override for scheme\n        scheme = values.pop('_scheme', scheme)\n\n        bucket_path, values = _get_bucket_name(**values)\n\n        urls = app.url_map.bind(bucket_path, url_scheme=scheme)\n        built = urls.build(endpoint, values=values, force_external=True)\n        return built\n    return flask_url_for(endpoint, **values)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _bp_static_url(blueprint):\n    u = six.u('%s%s' % (blueprint.url_prefix or '', blueprint.static_url_path or ''))\n    return u", "response": "builds the absolute url path for a blueprint s static folder"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all files in static folders and returns in dict.", "response": "def _gather_files(app, hidden, filepath_filter_regex=None):\n    \"\"\" Gets all files in static folders and returns in dict.\"\"\"\n    dirs = [(six.text_type(app.static_folder), app.static_url_path)]\n    if hasattr(app, 'blueprints'):\n        blueprints = app.blueprints.values()\n        bp_details = lambda x: (x.static_folder, _bp_static_url(x))\n        dirs.extend([bp_details(x) for x in blueprints if x.static_folder])\n\n    valid_files = defaultdict(list)\n    for static_folder, static_url_loc in dirs:\n        if not os.path.isdir(static_folder):\n            logger.warning(\"WARNING - [%s does not exist]\" % static_folder)\n        else:\n            logger.debug(\"Checking static folder: %s\" % static_folder)\n        for root, _, files in os.walk(static_folder):\n            relative_folder = re.sub(r'^/',\n                                     '',\n                                     root.replace(static_folder, ''))\n\n            files = [os.path.join(root, x)\n                     for x in files if (\n                         (hidden or x[0] != '.') and\n                         # Skip this file if the filter regex is\n                         # defined, and this file's path is a\n                         # negative match.\n                         (filepath_filter_regex == None or re.search(\n                             filepath_filter_regex,\n                             os.path.join(relative_folder, x))))]\n            if files:\n                valid_files[(static_folder, static_url_loc)].extend(files)\n    return valid_files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a path to a file based on the static folder and not on the static folder.", "response": "def _static_folder_path(static_url, static_folder, static_asset):\n    \"\"\"\n    Returns a path to a file based on the static folder, and not on the\n    filesystem holding the file.\n\n    Returns a path relative to static_url for static_asset\n    \"\"\"\n    # first get the asset path relative to the static folder.\n    # static_asset is not simply a filename because it could be\n    # sub-directory then file etc.\n    if not static_asset.startswith(static_folder):\n        raise ValueError(\"%s static asset must be under %s static folder\" %\n                         (static_asset, static_folder))\n    rel_asset = static_asset[len(static_folder):]\n    # Now bolt the static url path and the relative asset location together\n    return '%s/%s' % (static_url.rstrip('/'), rel_asset.lstrip('/'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _write_files(s3, app, static_url_loc, static_folder, files, bucket,\n                 ex_keys=None, hashes=None):\n    \"\"\" Writes all the files inside a static folder to S3. \"\"\"\n    should_gzip = app.config.get('FLASKS3_GZIP')\n    add_mime = app.config.get('FLASKS3_FORCE_MIMETYPE')\n    gzip_include_only = app.config.get('FLASKS3_GZIP_ONLY_EXTS')\n    new_hashes = []\n    static_folder_rel = _path_to_relative_url(static_folder)\n    for file_path in files:\n        per_file_should_gzip = should_gzip\n        asset_loc = _path_to_relative_url(file_path)\n        full_key_name = _static_folder_path(static_url_loc, static_folder_rel,\n                                            asset_loc)\n        key_name = full_key_name.lstrip(\"/\")\n        logger.debug(\"Uploading {} to {} as {}\".format(file_path, bucket, key_name))\n\n        exclude = False\n        if app.config.get('FLASKS3_ONLY_MODIFIED', False):\n            file_hash = hash_file(file_path)\n            new_hashes.append((full_key_name, file_hash))\n\n            if hashes and hashes.get(full_key_name, None) == file_hash:\n                exclude = True\n\n        if ex_keys and full_key_name in ex_keys or exclude:\n            logger.debug(\"%s excluded from upload\" % key_name)\n        else:\n            h = {}\n            # Set more custom headers if the filepath matches certain\n            # configured regular expressions.\n            filepath_headers = app.config.get('FLASKS3_FILEPATH_HEADERS')\n            if filepath_headers:\n                for filepath_regex, headers in six.iteritems(filepath_headers):\n                    if re.search(filepath_regex, file_path):\n                        for header, value in six.iteritems(headers):\n                            h[header] = value\n\n            # check for extension, only if there are extensions provided\n            if per_file_should_gzip and gzip_include_only:\n                if os.path.splitext(file_path)[1] not in gzip_include_only:\n                    per_file_should_gzip = False\n\n            if per_file_should_gzip:\n                h[\"content-encoding\"] = \"gzip\"\n\n            if (add_mime or per_file_should_gzip) and \"content-type\" not in h:\n                # When we use GZIP we have to explicitly set the content type\n                # or if the mime flag is True\n                (mimetype, encoding) = mimetypes.guess_type(file_path,\n                                                            False)\n                if mimetype:\n                    h[\"content-type\"] = mimetype\n                else:\n                    logger.warn(\"Unable to detect mimetype for %s\" %\n                                file_path)\n\n            file_mode = 'rb' if six.PY3 else 'r'\n            with open(file_path, file_mode) as fp:\n                merged_dicts = merge_two_dicts(get_setting('FLASKS3_HEADERS', app), h)\n                metadata, params = split_metadata_params(merged_dicts)\n                if per_file_should_gzip:\n                    compressed = six.BytesIO()\n                    z = gzip.GzipFile(os.path.basename(file_path), 'wb', 9,\n                                      compressed)\n                    z.write(fp.read())\n                    z.close()\n\n                    data = compressed.getvalue()\n                else:\n                    data = fp.read()\n\n                s3.put_object(Bucket=bucket,\n                              Key=key_name,\n                              Body=data,\n                              ACL=\"public-read\",\n                              Metadata=metadata,\n                              **params)\n\n    return new_hashes", "response": "Write all the files inside a static folder to S3."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_setting(name, app=None):\n    default_value = DEFAULT_SETTINGS.get(name, None)\n    return app.config.get(name, default_value) if app else default_value", "response": "Returns the value for a given setting name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_all(app, user=None, password=None, bucket_name=None,\n               location=None, include_hidden=False,\n               filepath_filter_regex=None, put_bucket_acl=True):\n    \"\"\"\n    Uploads of the static assets associated with a Flask application to\n    Amazon S3.\n\n    All static assets are identified on the local filesystem, including\n    any static assets associated with *registered* blueprints. In turn,\n    each asset is uploaded to the bucket described by `bucket_name`. If\n    the bucket does not exist then it is created.\n\n    Flask-S3 creates the same relative static asset folder structure on\n    S3 as can be found within your Flask application.\n\n    Many of the optional arguments to `create_all` can be specified\n    instead in your application's configuration using the Flask-S3\n    `configuration`_ variables.\n\n    :param app: a :class:`flask.Flask` application object.\n\n    :param user: an AWS Access Key ID. You can find this key in the\n                 Security Credentials section of your AWS account.\n    :type user: `basestring` or None\n\n    :param password: an AWS Secret Access Key. You can find this key in\n                     the Security Credentials section of your AWS\n                     account.\n    :type password: `basestring` or None\n\n    :param bucket_name: the name of the bucket you wish to server your\n                        static assets from. **Note**: while a valid\n                        character, it is recommended that you do not\n                        include periods in bucket_name if you wish to\n                        serve over HTTPS. See Amazon's `bucket\n                        restrictions`_ for more details.\n    :type bucket_name: `basestring` or None\n\n    :param location: the AWS region to host the bucket in; an empty\n                     string indicates the default region should be used,\n                     which is the US Standard region. Possible location\n                     values include: `'DEFAULT'`, `'EU'`, `'us-east-1'`,\n                     `'us-west-1'`, `'us-west-2'`, `'ap-south-1'`,\n                     `'ap-northeast-2'`, `'ap-southeast-1'`,\n                     `'ap-southeast-2'`, `'ap-northeast-1'`,\n                     `'eu-central-1'`, `'eu-west-1'`,  `'sa-east-1'`\n    :type location: `basestring` or None\n\n    :param include_hidden: by default Flask-S3 will not upload hidden\n        files. Set this to true to force the upload of hidden files.\n    :type include_hidden: `bool`\n\n    :param filepath_filter_regex: if specified, then the upload of\n        static assets is limited to only those files whose relative path\n        matches this regular expression string. For example, to only\n        upload files within the 'css' directory of your app's static\n        store, set to r'^css'.\n    :type filepath_filter_regex: `basestring` or None\n\n    :param put_bucket_acl: by default Flask-S3 will set the bucket ACL\n        to public. Set this to false to leave the policy unchanged.\n    :type put_bucket_acl: `bool`\n\n    .. _bucket restrictions: http://docs.amazonwebservices.com/AmazonS3\\\n    /latest/dev/BucketRestrictions.html\n\n    \"\"\"\n    user = user or app.config.get('AWS_ACCESS_KEY_ID')\n    password = password or app.config.get('AWS_SECRET_ACCESS_KEY')\n    bucket_name = bucket_name or app.config.get('FLASKS3_BUCKET_NAME')\n    if not bucket_name:\n        raise ValueError(\"No bucket name provided.\")\n    location = location or app.config.get('FLASKS3_REGION')\n    endpoint_url = app.config.get('FLASKS3_ENDPOINT_URL')\n\n    # build list of static files\n    all_files = _gather_files(app, include_hidden,\n                              filepath_filter_regex=filepath_filter_regex)\n    logger.debug(\"All valid files: %s\" % all_files)\n\n    # connect to s3\n    s3 = boto3.client(\"s3\",\n                      endpoint_url=endpoint_url,\n                      region_name=location or None,\n                      aws_access_key_id=user,\n                      aws_secret_access_key=password)\n\n    # get_or_create bucket\n    try:\n        s3.head_bucket(Bucket=bucket_name)\n    except ClientError as e:\n        if int(e.response['Error']['Code']) == 404:\n            # Create the bucket\n            bucket = s3.create_bucket(Bucket=bucket_name)\n        else:\n            raise\n\n    if put_bucket_acl:\n        s3.put_bucket_acl(Bucket=bucket_name, ACL='public-read')\n\n    if get_setting('FLASKS3_ONLY_MODIFIED', app):\n        try:\n            hashes_object = s3.get_object(Bucket=bucket_name, Key='.file-hashes')\n            hashes = json.loads(str(hashes_object['Body'].read().decode()))\n        except ClientError as e:\n            logger.warn(\"No file hashes found: %s\" % e)\n            hashes = None\n\n        new_hashes = _upload_files(s3, app, all_files, bucket_name, hashes=hashes)\n\n        try:\n            s3.put_object(Bucket=bucket_name,\n                          Key='.file-hashes',\n                          Body=json.dumps(dict(new_hashes)),\n                          ACL='private')\n        except boto3.exceptions.S3UploadFailedError as e:\n            logger.warn(\"Unable to upload file hashes: %s\" % e)\n    else:\n        _upload_files(s3, app, all_files, bucket_name)", "response": "Create all static assets for a Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the Flask - S3 application.", "response": "def init_app(self, app):\n        \"\"\"\n        An alternative way to pass your :class:`flask.Flask` application\n        object to Flask-S3. :meth:`init_app` also takes care of some\n        default `settings`_.\n\n        :param app: the :class:`flask.Flask` application object.\n        \"\"\"\n\n        for k, v in DEFAULT_SETTINGS.items():\n            app.config.setdefault(k, v)\n\n        if app.debug and not get_setting('FLASKS3_DEBUG', app):\n            app.config['FLASKS3_ACTIVE'] = False\n\n        if get_setting('FLASKS3_ACTIVE', app):\n            app.jinja_env.globals['url_for'] = url_for\n        if get_setting('FLASKS3_USE_CACHE_CONTROL', app) and app.config.get('FLASKS3_CACHE_CONTROL'):\n            cache_control_header = get_setting('FLASKS3_CACHE_CONTROL', app)\n            app.config['FLASKS3_HEADERS']['Cache-Control'] = cache_control_header"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for near - matches of subsequence in sequence", "response": "def find_near_matches_no_deletions_ngrams(subsequence, sequence, search_params):\n    \"\"\"search for near-matches of subsequence in sequence\n\n    This searches for near-matches, where the nearly-matching parts of the\n    sequence must meet the following limitations (relative to the subsequence):\n\n    * the maximum allowed number of character substitutions\n    * the maximum allowed number of new characters inserted\n    * no deletions are allowed\n    * the total number of substitutions, insertions and deletions\n    \"\"\"\n    if not subsequence:\n        raise ValueError('Given subsequence is empty!')\n\n    max_substitutions, max_insertions, max_deletions, max_l_dist = search_params.unpacked\n\n    max_substitutions = min(max_substitutions, max_l_dist)\n    max_insertions = min(max_insertions, max_l_dist)\n\n    subseq_len = len(subsequence)\n    seq_len = len(sequence)\n\n    ngram_len = subseq_len // (max_substitutions + max_insertions + 1)\n    if ngram_len == 0:\n        raise ValueError(\n            \"The subsequence's length must be greater than max_subs + max_ins!\"\n        )\n\n    matches = []\n    matched_indexes = set()\n\n    for ngram_start in range(0, len(subsequence) - ngram_len + 1, ngram_len):\n        ngram_end = ngram_start + ngram_len\n        subseq_before = subsequence[:ngram_start]\n        subseq_before_reversed = subseq_before[::-1]\n        subseq_after = subsequence[ngram_end:]\n        start_index = max(0, ngram_start - max_insertions)\n        end_index = min(seq_len, seq_len - (subseq_len - ngram_end) + max_insertions)\n\n        for index in search_exact(\n                subsequence[ngram_start:ngram_end], sequence,\n                start_index, end_index,\n        ):\n            if index - ngram_start in matched_indexes:\n                continue\n\n            seq_after = sequence[index + ngram_len:index + subseq_len - ngram_start + max_insertions]\n            if seq_after.startswith(subseq_after):\n                matches_after = [(0, 0)]\n            else:\n                matches_after = _expand(subseq_after, seq_after,\n                                        max_substitutions, max_insertions, max_l_dist)\n                if not matches_after:\n                    continue\n\n            _max_substitutions = max_substitutions - min(m[0] for m in matches_after)\n            _max_insertions = max_insertions - min(m[1] for m in matches_after)\n            _max_l_dist = max_l_dist - min(m[0] + m[1] for m in matches_after)\n            seq_before = sequence[index - ngram_start - _max_insertions:index]\n            if seq_before.endswith(subseq_before):\n                matches_before = [(0, 0)]\n            else:\n                matches_before = _expand(\n                    subseq_before_reversed, seq_before[::-1],\n                    _max_substitutions, _max_insertions, _max_l_dist,\n                )\n\n            for (subs_before, ins_before) in matches_before:\n                for (subs_after, ins_after) in matches_after:\n                    if (\n                            subs_before + subs_after <= max_substitutions and\n                            ins_before + ins_after <= max_insertions and\n                            subs_before + subs_after + ins_before + ins_after <= max_l_dist\n                    ):\n                        matches.append(Match(\n                            start=index - ngram_start - ins_before,\n                            end=index - ngram_start + subseq_len + ins_after,\n                            dist=subs_before + subs_after + ins_before + ins_after,\n                        ))\n                        matched_indexes |= set(range(\n                            index - ngram_start - ins_before,\n                            index - ngram_start - ins_before + max_insertions + 1,\n                        ))\n\n    return sorted(matches, key=lambda match: match.start)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch for near - matches of subsequence in sequence", "response": "def find_near_matches(subsequence, sequence,\n                      max_substitutions=None,\n                      max_insertions=None,\n                      max_deletions=None,\n                      max_l_dist=None):\n    \"\"\"search for near-matches of subsequence in sequence\n\n    This searches for near-matches, where the nearly-matching parts of the\n    sequence must meet the following limitations (relative to the subsequence):\n\n    * the maximum allowed number of character substitutions\n    * the maximum allowed number of new characters inserted\n    * and the maximum allowed number of character deletions\n    * the total number of substitutions, insertions and deletions\n      (a.k.a. the Levenshtein distance)\n    \"\"\"\n    search_params = LevenshteinSearchParams(max_substitutions,\n                                            max_insertions,\n                                            max_deletions,\n                                            max_l_dist)\n    search_func = choose_search_func(search_params)\n    return search_func(subsequence, sequence, search_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds near - matches of the subsequence in the given sequence.", "response": "def find_near_matches_substitutions(subsequence, sequence, max_substitutions):\n    \"\"\"Find near-matches of the subsequence in the sequence.\n\n    This chooses a suitable fuzzy search implementation according to the given\n    parameters.\n\n    Returns a list of fuzzysearch.Match objects describing the matching parts\n    of the sequence.\n    \"\"\"\n    _check_arguments(subsequence, sequence, max_substitutions)\n\n    if max_substitutions == 0:\n        return [\n            Match(start_index, start_index + len(subsequence), 0)\n            for start_index in search_exact(subsequence, sequence)\n        ]\n\n    elif len(subsequence) // (max_substitutions + 1) >= 3:\n        return find_near_matches_substitutions_ngrams(\n            subsequence, sequence, max_substitutions,\n        )\n\n    else:\n        return find_near_matches_substitutions_lp(\n            subsequence, sequence, max_substitutions,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for near - matches of subsequence in sequence", "response": "def find_near_matches_substitutions_lp(subsequence, sequence,\n                                       max_substitutions):\n    \"\"\"search for near-matches of subsequence in sequence\n\n    This searches for near-matches, where the nearly-matching parts of the\n    sequence must meet the following limitations (relative to the subsequence):\n\n    * the number of character substitutions must be less than max_substitutions\n    * no deletions or insertions are allowed\n    \"\"\"\n    _check_arguments(subsequence, sequence, max_substitutions)\n\n    return list(_find_near_matches_substitutions_lp(subsequence, sequence,\n                                                    max_substitutions))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch for near - matches of subsequence in sequence", "response": "def find_near_matches_substitutions_ngrams(subsequence, sequence,\n                                           max_substitutions):\n    \"\"\"search for near-matches of subsequence in sequence\n\n    This searches for near-matches, where the nearly-matching parts of the\n    sequence must meet the following limitations (relative to the subsequence):\n\n    * the number of character substitutions must be less than max_substitutions\n    * no deletions or insertions are allowed\n    \"\"\"\n    _check_arguments(subsequence, sequence, max_substitutions)\n\n    match_starts = set()\n    matches = []\n    for match in _find_near_matches_substitutions_ngrams(subsequence, sequence,\n                                                         max_substitutions):\n        if match.start not in match_starts:\n            match_starts.add(match.start)\n            matches.append(match)\n    return sorted(matches, key=lambda match: match.start)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_near_match_substitutions_ngrams(subsequence, sequence,\n                                        max_substitutions):\n    \"\"\"search for near-matches of subsequence in sequence\n\n    This searches for near-matches, where the nearly-matching parts of the\n    sequence must meet the following limitations (relative to the subsequence):\n\n    * the number of character substitutions must be less than max_substitutions\n    * no deletions or insertions are allowed\n    \"\"\"\n    _check_arguments(subsequence, sequence, max_substitutions)\n\n    for match in _find_near_matches_substitutions_ngrams(subsequence, sequence,\n                                                         max_substitutions):\n        return True\n    return False", "response": "search for near - matches of subsequence in sequence"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch for near - matches of subsequence in sequence", "response": "def find_near_matches_generic(subsequence, sequence, search_params):\n    \"\"\"search for near-matches of subsequence in sequence\n\n    This searches for near-matches, where the nearly-matching parts of the\n    sequence must meet the following limitations (relative to the subsequence):\n\n    * the maximum allowed number of character substitutions\n    * the maximum allowed number of new characters inserted\n    * and the maximum allowed number of character deletions\n    * the total number of substitutions, insertions and deletions\n    \"\"\"\n    if not subsequence:\n        raise ValueError('Given subsequence is empty!')\n\n    # if the limitations are so strict that only exact matches are allowed,\n    # use search_exact()\n    if search_params.max_l_dist == 0:\n        return [\n            Match(start_index, start_index + len(subsequence), 0)\n            for start_index in search_exact(subsequence, sequence)\n        ]\n\n    # if the n-gram length would be at least 3, use the n-gram search method\n    elif len(subsequence) // (search_params.max_l_dist + 1) >= 3:\n        return find_near_matches_generic_ngrams(subsequence, sequence, search_params)\n\n    # use the linear programming search method\n    else:\n        matches = find_near_matches_generic_linear_programming(subsequence, sequence, search_params)\n\n        match_groups = group_matches(matches)\n        best_matches = [get_best_match_in_group(group) for group in match_groups]\n        return sorted(best_matches)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching for near - matches of subsequence in sequence", "response": "def _find_near_matches_generic_linear_programming(subsequence, sequence, search_params):\n    \"\"\"search for near-matches of subsequence in sequence\n\n    This searches for near-matches, where the nearly-matching parts of the\n    sequence must meet the following limitations (relative to the subsequence):\n\n    * the maximum allowed number of character substitutions\n    * the maximum allowed number of new characters inserted\n    * and the maximum allowed number of character deletions\n    * the total number of substitutions, insertions and deletions\n    \"\"\"\n    if not subsequence:\n        raise ValueError('Given subsequence is empty!')\n\n    max_substitutions, max_insertions, max_deletions, max_l_dist = search_params.unpacked\n\n    # optimization: prepare some often used things in advance\n    subseq_len = len(subsequence)\n\n    candidates = []\n    for index, char in enumerate(sequence):\n        candidates.append(GenericSearchCandidate(index, 0, 0, 0, 0, 0))\n        new_candidates = []\n\n        for cand in candidates:\n            # if this sequence char is the candidate's next expected char\n            if char == subsequence[cand.subseq_index]:\n                # if reached the end of the subsequence, return a match\n                if cand.subseq_index + 1 == subseq_len:\n                    yield Match(cand.start, index + 1, cand.l_dist)\n                # otherwise, update the candidate's subseq_index and keep it\n                else:\n                    new_candidates.append(cand._replace(\n                        subseq_index=cand.subseq_index + 1,\n                    ))\n\n            # if this sequence char is *not* the candidate's next expected char\n            else:\n                # we can try skipping a sequence or sub-sequence char (or both),\n                # unless this candidate has already skipped the maximum allowed\n                # number of characters\n                if cand.l_dist == max_l_dist:\n                    continue\n\n                if cand.n_ins < max_insertions:\n                    # add a candidate skipping a sequence char\n                    new_candidates.append(cand._replace(\n                        n_ins=cand.n_ins + 1,\n                        l_dist=cand.l_dist + 1,\n                    ))\n\n                if cand.subseq_index + 1 < subseq_len:\n                    if cand.n_subs < max_substitutions:\n                        # add a candidate skipping both a sequence char and a\n                        # subsequence char\n                        new_candidates.append(cand._replace(\n                            n_subs=cand.n_subs + 1,\n                            subseq_index=cand.subseq_index + 1,\n                            l_dist=cand.l_dist + 1,\n                        ))\n                    elif cand.n_dels < max_deletions and cand.n_ins < max_insertions:\n                        # add a candidate skipping both a sequence char and a\n                        # subsequence char\n                        new_candidates.append(cand._replace(\n                            n_ins=cand.n_ins + 1,\n                            n_dels=cand.n_dels + 1,\n                            subseq_index=cand.subseq_index + 1,\n                            l_dist=cand.l_dist + 1,\n                        ))\n                else:\n                    # cand.subseq_index == _subseq_len - 1\n                    if (\n                            cand.n_subs < max_substitutions or\n                            (\n                                cand.n_dels < max_deletions and\n                                cand.n_ins < max_insertions\n                            )\n                    ):\n                        yield Match(cand.start, index + 1, cand.l_dist + 1)\n\n                # try skipping subsequence chars\n                for n_skipped in xrange(1, min(max_deletions - cand.n_dels, max_l_dist - cand.l_dist) + 1):\n                    # if skipping n_dels sub-sequence chars reaches the end\n                    # of the sub-sequence, yield a match\n                    if cand.subseq_index + n_skipped == subseq_len:\n                        yield Match(cand.start, index + 1,\n                                    cand.l_dist + n_skipped)\n                        break\n                    # otherwise, if skipping n_skipped sub-sequence chars\n                    # reaches a sub-sequence char identical to this sequence\n                    # char ...\n                    elif subsequence[cand.subseq_index + n_skipped] == char:\n                        # if this is the last char of the sub-sequence, yield\n                        # a match\n                        if cand.subseq_index + n_skipped + 1 == subseq_len:\n                            yield Match(cand.start, index + 1,\n                                        cand.l_dist + n_skipped)\n                        # otherwise add a candidate skipping n_skipped\n                        # subsequence chars\n                        else:\n                            new_candidates.append(cand._replace(\n                                n_dels=cand.n_dels + n_skipped,\n                                subseq_index=cand.subseq_index + 1 + n_skipped,\n                                l_dist=cand.l_dist + n_skipped,\n                            ))\n                        break\n                # note: if the above loop ends without a break, that means that\n                # no candidate could be added / yielded by skipping sub-sequence\n                # chars\n\n        candidates = new_candidates\n\n    for cand in candidates:\n        # note: index + 1 == length(sequence)\n        n_skipped = subseq_len - cand.subseq_index\n        if cand.n_dels + n_skipped <= max_deletions and \\\n           cand.l_dist + n_skipped <= max_l_dist:\n            yield Match(cand.start, index + 1, cand.l_dist + n_skipped)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_near_matches_generic_ngrams(subsequence, sequence, search_params):\n    if not subsequence:\n        raise ValueError('Given subsequence is empty!')\n\n    matches = list(_find_near_matches_generic_ngrams(subsequence, sequence, search_params))\n\n    # don't return overlapping matches; instead, group overlapping matches\n    # together and return the best match from each group\n    match_groups = group_matches(matches)\n    best_matches = [get_best_match_in_group(group) for group in match_groups]\n    return sorted(best_matches)", "response": "search for near - matches of subsequence in sequence"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches for near - matches of subsequence in sequence", "response": "def has_near_match_generic_ngrams(subsequence, sequence, search_params):\n    \"\"\"search for near-matches of subsequence in sequence\n\n    This searches for near-matches, where the nearly-matching parts of the\n    sequence must meet the following limitations (relative to the subsequence):\n\n    * the maximum allowed number of character substitutions\n    * the maximum allowed number of new characters inserted\n    * and the maximum allowed number of character deletions\n    * the total number of substitutions, insertions and deletions\n    \"\"\"\n    if not subsequence:\n        raise ValueError('Given subsequence is empty!')\n\n    for match in _find_near_matches_generic_ngrams(subsequence, sequence, search_params):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexpanding a partial match of a Levenstein search.", "response": "def _expand(subsequence, sequence, max_l_dist):\n    \"\"\"Expand a partial match of a Levenstein search.\n\n    An expansion must begin at the beginning of the sequence, which makes\n    this much simpler than a full search, and allows for greater optimization.\n    \"\"\"\n    # If given a long sub-sequence and relatively small max distance,\n    # use a more complex algorithm better optimized for such cases.\n    if len(subsequence) > max(max_l_dist * 2, 10):\n        return _expand_long(subsequence, sequence, max_l_dist)\n    else:\n        return _expand_short(subsequence, sequence, max_l_dist)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _py_expand_short(subsequence, sequence, max_l_dist):\n    # The following diagram shows the score calculation step.\n    #\n    # Each new score is the minimum of:\n    #  * a OR a + 1 (substitution, if needed)\n    #  * b + 1 (deletion, i.e. skipping a sequence character)\n    #  * c + 1 (insertion, i.e. skipping a sub-sequence character)\n    #\n    # a -- +1 -> c\n    #\n    # |  \\       |\n    # |   \\      |\n    # +1  +1?    +1\n    # |      \\   |\n    # v       \u231f  v\n    #\n    # b -- +1 -> scores[subseq_index]\n\n    subseq_len = len(subsequence)\n    if subseq_len == 0:\n        return (0, 0)\n\n    # Initialize the scores array with values for just skipping sub-sequence\n    # chars.\n    scores = list(range(1, subseq_len + 1))\n\n    min_score = subseq_len\n    min_score_idx = -1\n\n    for seq_index, char in enumerate(sequence):\n        # calculate scores, one for each character in the sub-sequence\n        a = seq_index\n        c = a + 1\n        for subseq_index in range(subseq_len):\n            b = scores[subseq_index]\n            c = scores[subseq_index] = min(\n                a + (char != subsequence[subseq_index]),\n                b + 1,\n                c + 1,\n            )\n            a = b\n\n        # keep the minimum score found for matches of the entire sub-sequence\n        if c <= min_score:\n            min_score = c\n            min_score_idx = seq_index\n\n        # bail early when it is impossible to find a better expansion\n        elif min(scores) >= min_score:\n            break\n\n    return (min_score, min_score_idx + 1) if min_score <= max_l_dist else (None, None)", "response": "Straightforward implementation of partial match expansion."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_near_matches_levenshtein(subsequence, sequence, max_l_dist):\n    if not subsequence:\n        raise ValueError('Given subsequence is empty!')\n    if max_l_dist < 0:\n        raise ValueError('Maximum Levenshtein distance must be >= 0!')\n\n    if max_l_dist == 0:\n        return [\n            Match(start_index, start_index + len(subsequence), 0)\n            for start_index in search_exact(subsequence, sequence)\n        ]\n\n    elif len(subsequence) // (max_l_dist + 1) >= 3:\n        return find_near_matches_levenshtein_ngrams(subsequence,\n                                                    sequence,\n                                                    max_l_dist)\n\n    else:\n        matches = find_near_matches_levenshtein_linear_programming(subsequence,\n                                                                   sequence,\n                                                                   max_l_dist)\n        match_groups = group_matches(matches)\n        best_matches = [get_best_match_in_group(group) for group in match_groups]\n        return sorted(best_matches)", "response": "Find near - matches of the given subsequence in the given sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _randomized_hands():\n    '''\n    :return: 4 hands, obtained by shuffling the 28 dominoes used in\n             this variation of the game, and distributing them evenly\n    '''\n    all_dominoes = [dominoes.Domino(i, j) for i in range(7) for j in range(i, 7)]\n    random.shuffle(all_dominoes)\n    return [dominoes.Hand(all_dominoes[0:7]), dominoes.Hand(all_dominoes[7:14]),\n            dominoes.Hand(all_dominoes[14:21]), dominoes.Hand(all_dominoes[21:28])]", "response": "Randomized hands for the 28 dominoes used in\n            ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that a player is a valid node.", "response": "def _validate_player(player):\n    '''\n    Checks that a player is a valid player. Valid players are: 0, 1, 2, and 3.\n\n    :param int player: player to be validated\n    :return: None\n    :raises NoSuchPlayerException: if the player is invalid\n    '''\n    valid_players = range(4)\n    if player not in valid_players:\n        valid_players = ', '.join(str(p) for p in valid_players)\n        raise dominoes.NoSuchPlayerException('{} is not a valid player. Valid players'\n                                             ' are: {}'.format(player, valid_players))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _domino_hand(d, hands):\n    '''\n    :param Domino d: domino to find within the hands\n    :param list hands: hands to find domino in\n    :return: index of the hand that contains the specified domino\n    :raises NoSuchDominoException: if no hand contains the specified domino\n    '''\n    for i, hand in enumerate(hands):\n        if d in hand:\n            return i\n\n    raise dominoes.NoSuchDominoException('{} is not in any hand!'.format(d))", "response": "Returns the index of the domino that contains the specified domino"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _remaining_points(hands):\n    '''\n    :param list hands: hands for which to compute the remaining points\n    :return: a list indicating the amount of points\n             remaining in each of the input hands\n    '''\n    points = []\n    for hand in hands:\n        points.append(sum(d.first + d.second for d in hand))\n\n    return points", "response": "compute the remaining points in a list of hands"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate that the given list of hands is present in the dominoes.", "response": "def _validate_hands(hands, missing):\n    '''\n    Validates hands, based on values that\n    are supposed to be missing from them.\n\n    :param list hands: list of Hand objects to validate\n    :param list missing: list of sets that indicate the values\n                         that are supposed to be missing from\n                         the respective Hand objects\n    :return: True if no Hand objects contain values that they\n             are supposed to be missing; False otherwise\n    '''\n    for h, m in zip(hands, missing):\n        for value in m:\n            if dominoes.hand.contains_value(h, value):\n                return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield all possible partitionings of the elements in the set of elements and sizes of partitions.", "response": "def _all_possible_partitionings(elements, sizes):\n    '''\n    Helper function for Game.all_possible_hands(). Given a set of elements\n    and the sizes of partitions, yields all possible partitionings of the\n    elements into partitions of the provided sizes.\n\n    :param set elements: a set of elements to partition.\n    :param list sizes: a list of sizes for the partitions. The sum of the\n                       sizes should equal the length of the set of elements.\n    :yields: a tuple of tuples, each inner tuple corresponding to a partition.\n    '''\n    try:\n        # get the size of the current partition\n        size = sizes[0]\n    except IndexError:\n        # base case: no more sizes left\n        yield ()\n        return\n\n    # don't include the current size in the recursive calls\n    sizes = sizes[1:]\n\n    # iterate over all possible partitions of the current size\n    for partition in itertools.combinations(elements, size):\n        # recursive case: pass down the remaining elements and the remaining sizes\n        for other_partitions in _all_possible_partitionings(elements.difference(partition), sizes):\n            # put results together and yield up\n            yield (partition,) + other_partitions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new(cls, starting_domino=None, starting_player=0):\n        '''\n        :param Domino starting_domino: the domino that should be played\n                                       to start the game. The player\n                                       with this domino in their hand\n                                       will play first.\n        :param int starting_player: the player that should play first.\n                                    This value is ignored if a starting\n                                    domino is provided. Players are\n                                    referred to by their indexes: 0, 1,\n                                    2, and 3. 0 and 2 are on one team,\n                                    and 1 and 3 are on another team.\n        :return: a new game, initialized according to\n                 starting_domino and starting_player\n        :raises NoSuchDominoException: if starting_domino is invalid\n        :raises NoSuchPlayerException: if starting_player is invalid\n        '''\n        board = dominoes.Board()\n\n        hands = _randomized_hands()\n\n        moves = []\n\n        result = None\n\n        if starting_domino is None:\n            _validate_player(starting_player)\n            valid_moves = tuple((d, True) for d in hands[starting_player])\n            game = cls(board, hands, moves, starting_player,\n                       valid_moves, starting_player, result)\n        else:\n            starting_player = _domino_hand(starting_domino, hands)\n            valid_moves = ((starting_domino, True),)\n            game = cls(board, hands, moves, starting_player,\n                       valid_moves, starting_player, result)\n            game.make_move(*valid_moves[0])\n\n        return game", "response": "Creates a new game with random moves."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_valid_moves(self):\n        '''\n        Updates self.valid_moves according to the latest game state.\n        Assumes that the board and all hands are non-empty.\n        '''\n        left_end = self.board.left_end()\n        right_end = self.board.right_end()\n\n        moves = []\n        for d in self.hands[self.turn]:\n            if left_end in d:\n                moves.append((d, True))\n            # do not double count moves if both of the board's ends have\n            # the same value, and a domino can be placed on both of them\n            if right_end in d and left_end != right_end:\n                moves.append((d, False))\n\n        self.valid_moves = tuple(moves)", "response": "Updates self. valid_moves according to the latest game state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_move(self, d, left):\n        '''\n        Plays a domino from the hand of the player whose turn it is onto one\n        end of the game board. If the game does not end, the turn is advanced\n        to the next player who has a valid move.\n\n        Making a move is transactional - if the operation fails at any point,\n        the game will return to its state before the operation began.\n\n        :param Domino d: domino to be played\n        :param bool left: end of the board on which to play the\n                          domino (True for left, False for right)\n        :return: a Result object if the game ends; None otherwise\n        :raises GameOverException: if the game has already ended\n        :raises NoSuchDominoException: if the domino to be played is not in\n                                       the hand of the player whose turn it is\n        :raises EndsMismatchException: if the domino cannot be placed on\n                                       the specified position in the board\n        '''\n        if self.result is not None:\n            raise dominoes.GameOverException('Cannot make a move - the game is over!')\n\n        i = self.hands[self.turn].play(d)\n\n        try:\n            self.board.add(d, left)\n        except dominoes.EndsMismatchException as error:\n            # return the domino to the hand if it cannot be placed on the board\n            self.hands[self.turn].draw(d, i)\n\n            raise error\n\n        # record the move\n        self.moves.append((d, left))\n\n        # check if the game ended due to a player running out of dominoes\n        if not self.hands[self.turn]:\n            self.valid_moves = ()\n            self.result = dominoes.Result(\n                self.turn, True, pow(-1, self.turn) * sum(_remaining_points(self.hands))\n            )\n            return self.result\n\n        # advance the turn to the next player with a valid move.\n        # if no player has a valid move, the game is stuck. also,\n        # record all the passes.\n        passes = []\n        stuck = True\n        for _ in self.hands:\n            self.turn = next_player(self.turn)\n            self._update_valid_moves()\n            if self.valid_moves:\n                self.moves.extend(passes)\n                stuck = False\n                break\n            else:\n                passes.append(None)\n\n        if stuck:\n            player_points = _remaining_points(self.hands)\n            team_points = [player_points[0] + player_points[2],\n                           player_points[1] + player_points[3]]\n\n            if team_points[0] < team_points[1]:\n                self.result = dominoes.Result(self.turn, False, sum(team_points))\n            elif team_points[0] == team_points[1]:\n                self.result = dominoes.Result(self.turn, False, 0)\n            else:\n                self.result = dominoes.Result(self.turn, False, -sum(team_points))\n\n            return self.result", "response": "Plays a domino from the hand of the player whose turn it is on the one node and returns the result object if the game ends."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the set of values that must be missing from each corresponding player s hand.", "response": "def missing_values(self):\n        '''\n        Computes the values that must be missing from each\n        player's hand, based on when they have passed.\n\n        :return: a list of sets, each one containing the\n                 values that must be missing from the\n                 corresponding player's hand\n        '''\n        missing = [set() for _ in self.hands]\n\n        # replay the game from the beginning\n        board = dominoes.SkinnyBoard()\n        player = self.starting_player\n        for move in self.moves:\n            if move is None:\n                # pass - update the missing values\n                missing[player].update([board.left_end(), board.right_end()])\n            else:\n                # not a pass - update the board\n                board.add(*move)\n\n            # move on to the next player\n            player = next_player(player)\n\n        return missing"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of random possible hands for all players given the information known by every player whose turn it is.", "response": "def random_possible_hands(self):\n        '''\n        Returns random possible hands for all players, given the information\n        known by the player whose turn it is. This information includes the\n        current player's hand, the sizes of the other players' hands, and the\n        moves played by every player, including the passes.\n\n        :return: a list of possible Hand objects, corresponding to each player\n        '''\n        # compute values that must be missing from\n        # each hand, to rule out impossible hands\n        missing = self.missing_values()\n\n        # get the dominoes that are in all of the other hands. note that, even\n        # though we are 'looking' at the other hands to get these dominoes, we\n        # are not 'cheating' because these dominoes could also be computed by\n        # subtracting the dominoes that have been played (which are public\n        # knowledge) and the dominoes in the current player's hand from the\n        # initial set of dominoes\n        other_dominoes = [d for p, h in enumerate(self.hands) for d in h if p != self.turn]\n\n        while True:\n            # generator for a shuffled shallow copy of other_dominoes\n            shuffled_dominoes = (d for d in random.sample(other_dominoes, len(other_dominoes)))\n\n            # generate random hands by partitioning the shuffled dominoes according\n            # to how many dominoes need to be in each of the other hands. since we\n            # know the current player's hand, we just use a shallow copy of it\n            hands = []\n            for player, hand in enumerate(self.hands):\n                if player != self.turn:\n                    hand = [next(shuffled_dominoes) for _ in hand]\n                hands.append(dominoes.Hand(hand))\n\n            # only return the hands if they are possible, according to the values we\n            # know to be missing from each hand. if the hands are not possible, try\n            # generating random hands again\n            if _validate_hands(hands, missing):\n                return hands"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield all possible hands for all players given the information known by every player whose turn it is.", "response": "def all_possible_hands(self):\n        '''\n        Yields all possible hands for all players, given the information\n        known by the player whose turn it is. This information includes the\n        current player's hand, the sizes of the other players' hands, and the\n        moves played by every player, including the passes.\n\n        :yields: a list of possible Hand objects, corresponding to each player\n        '''\n        # compute values that must be missing from\n        # each hand, to rule out impossible hands\n        missing = self.missing_values()\n\n        # get the dominoes that are in all of the other hands. note that, even\n        # though we are 'looking' at the other hands to get these dominoes, we\n        # are not 'cheating' because these dominoes could also be computed by\n        # subtracting the dominoes that have been played (which are public\n        # knowledge) and the dominoes in the current player's hand from the\n        # initial set of dominoes\n        other_dominoes = {d for p, h in enumerate(self.hands) for d in h if p != self.turn}\n\n        # get the lengths of all the other hands, so\n        # that we know how many dominoes to place in each\n        other_hand_lengths = [len(h) for p, h in enumerate(self.hands) if p != self.turn]\n\n        # iterate over all possible hands that the other players might have\n        for possible_hands in _all_possible_partitionings(other_dominoes, other_hand_lengths):\n            # given possible hands for all players, this is a generator for\n            # tuples containing the dominoes that are in the other players' hands\n            possible_hands = (h for h in possible_hands)\n\n            # build a list containing possible hands for all players. since we\n            # know the current player's hand, we just use a shallow copy of it\n            hands = []\n            for player, hand in enumerate(self.hands):\n                if player != self.turn:\n                    hand = next(possible_hands)\n                hands.append(dominoes.Hand(hand))\n\n            # only yield the hands if they are possible, according\n            # to the values we know to be missing from each hand\n            if _validate_hands(hands, missing):\n                yield hands"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprefer moves randomly. :param Game game: game to play :return: None", "response": "def random(game):\n    '''\n    Prefers moves randomly.\n\n    :param Game game: game to play\n    :return: None\n    '''\n    game.valid_moves = tuple(sorted(game.valid_moves, key=lambda _: rand.random()))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bota_gorda(game):\n    '''\n    Prefers to play dominoes with higher point values.\n\n    :param Game game: game to play\n    :return: None\n    '''\n    game.valid_moves = tuple(sorted(game.valid_moves, key=lambda m: -(m[0].first + m[0].second)))", "response": "Bota gorda prefers to play dominoes with higher point values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields all valid moves for the given game.", "response": "def make_moves(game, player=dominoes.players.identity):\n    '''\n    For each of a Game object's valid moves, yields\n    a tuple containing the move and the Game object\n    obtained by playing the move on the original Game\n    object. The original Game object will be modified.\n\n    :param Game game: the game to make moves on\n    :param callable player: a player to call on the\n                            game before making any\n                            moves, to determine the\n                            order in which they get\n                            made. The identity\n                            player is the default.\n    '''\n    # game is over - do not yield anything\n    if game.result is not None:\n        return\n\n    # determine the order in which to make moves\n    player(game)\n\n    # copy the original game before making all\n    # but the last move\n    for move in game.valid_moves[:-1]:\n        new_game = copy.deepcopy(game)\n        new_game.make_move(*move)\n        yield move, new_game\n\n    # don't copy the original game before making\n    # the last move\n    move = game.valid_moves[-1]\n    game.make_move(*move)\n    yield move, game"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef alphabeta(game, alpha_beta=(-float('inf'), float('inf')),\n              player=dominoes.players.identity):\n    '''\n    Runs minimax search with alpha-beta pruning on the provided game.\n\n    :param Game game: game to search\n    :param tuple alpha_beta: a tuple of two floats that indicate\n                             the initial values of alpha and beta,\n                             respectively. The default is (-inf, inf).\n    :param callable player: player used to sort moves to be explored.\n                            Ordering better moves first may significantly\n                            reduce the amount of moves that need to be\n                            explored. The identity player is the default.\n    '''\n    # base case - game is over\n    if game.result is not None:\n        return [], game.result.points\n\n    if game.turn % 2:\n        # minimizing player\n        best_value = float('inf')\n        op = operator.lt\n        update = lambda ab, v: (ab[0], min(ab[1], v))\n    else:\n        # maximizing player\n        best_value = -float('inf')\n        op = operator.gt\n        update = lambda ab, v: (max(ab[0], v), ab[1])\n\n    # recursive case - game is not over\n    for move, new_game in make_moves(game, player):\n        moves, value = alphabeta(new_game, alpha_beta, player)\n        if op(value, best_value):\n            best_value = value\n            best_moves = moves\n            best_moves.insert(0, move)\n            alpha_beta = update(alpha_beta, best_value)\n            if alpha_beta[1] <= alpha_beta[0]:\n                # alpha-beta cutoff\n                break\n\n    return best_moves, best_value", "response": "Runs minimax search with alpha - beta pruning on the provided game."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef next_game(self):\n        '''\n        Advances the series to the next game, if possible. Also updates\n        each team's score with points from the most recently completed game.\n\n        :return: the next game, if the previous game did not end the series;\n                 None otherwise\n        :raises SeriesOverException: if the series has already ended\n        :raises GameInProgressException: if the last game has not yet finished\n        '''\n        if self.is_over():\n            raise dominoes.SeriesOverException(\n                'Cannot start a new game - series ended with a score of {} to {}'.format(*self.scores)\n            )\n\n        result = self.games[-1].result\n        if result is None:\n            raise dominoes.GameInProgressException(\n                'Cannot start a new game - the latest one has not finished!'\n            )\n\n        # update each team's score with the points from the previous game\n        if result.points >= 0:\n            self.scores[0] += result.points\n        else:\n            self.scores[1] -= result.points\n\n        # return None if the series is now over\n        if self.is_over():\n            return\n\n        # determine the starting player for the next game\n        if result.won or pow(-1, result.player) * result.points > 0:\n            starting_player = result.player\n        elif not result.points:\n            starting_player = self.games[-1].starting_player\n        else: # pow(-1, result.player) * result.points < 0\n            starting_player = dominoes.game.next_player(result.player)\n\n        # start the next game\n        self.games.append(dominoes.Game.new(starting_player=starting_player))\n\n        return self.games[-1]", "response": "Advances the series to the next game if possible. Returns None if the next game is over."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a SkinnyBoard from a given Board.", "response": "def from_board(cls, board):\n        '''\n        :param Board board: board to represent\n        :return: SkinnyBoard to represent the given Board\n        '''\n        if len(board):\n            left = board.left_end()\n            right = board.right_end()\n        else:\n            left = None\n            right = None\n\n        return cls(left, right, len(board))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_left(self, d):\n        '''\n        Adds the provided domino to the left end of the board.\n\n        :param Domino d: domino to add\n        :return: None\n        :raises EndsMismatchException: if the values do not match\n        '''\n        if not self:\n            self._left = d.first\n            self._right = d.second\n        elif d.second == self.left_end():\n            self._left = d.first\n        elif d.first == self.left_end():\n            self._left = d.second\n        else:\n            raise dominoes.EndsMismatchException(\n                '{} cannot be added to the left of'\n                ' the board - values do not match!'.format(d)\n            )\n\n        self._length += 1", "response": "Adds the provided domino to the left end of the board."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the provided domino to the right end of the board.", "response": "def _add_right(self, d):\n        '''\n        Adds the provided domino to the right end of the board.\n\n        :param Domino d: domino to add\n        :return: None\n        :raises EndsMismatchException: if the values do not match\n        '''\n        if not self:\n            self._left = d.first\n            self._right = d.second\n        elif d.first == self.right_end():\n            self._right = d.second\n        elif d.second == self.right_end():\n            self._right = d.first\n        else:\n            raise dominoes.EndsMismatchException(\n                '{} cannot be added to the right of'\n                ' the board - values do not match!'.format(d)\n            )\n\n        self._length += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, d, left):\n        '''\n        Adds the provided domino to the specifed end of the board.\n\n        :param Domino d: domino to add\n        :param bool left: end of the board to which to add the\n                          domino (True for left, False for right)\n        :return: None\n        :raises EndsMismatchException: if the values do not match\n        '''\n        if left:\n            self._add_left(d)\n        else:\n            self._add_right(d)", "response": "Adds the domino d to the specifed end of the board."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_left(self, d):\n        '''\n        Adds the provided domino to the left end of the board.\n\n        :param Domino d: domino to add\n        :return: None\n        :raises EndsMismatchException: if the values do not match\n        '''\n        if not self:\n            self.board.append(d)\n        elif d.first == self.left_end():\n            self.board.appendleft(d.inverted())\n        elif d.second == self.left_end():\n            self.board.appendleft(d)\n        else:\n            raise dominoes.EndsMismatchException(\n                '{} cannot be added to the left of'\n                ' the board - values do not match!'.format(d)\n            )", "response": "Adds the provided domino to the left end of the board."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_right(self, d):\n        '''\n        Adds the provided domino to the right end of the board.\n\n        :param Domino d: domino to add\n        :return: None\n        :raises EndsMismatchException: if the values do not match\n        '''\n        if not self:\n            self.board.append(d)\n        elif d.first == self.right_end():\n            self.board.append(d)\n        elif d.second == self.right_end():\n            self.board.append(d.inverted())\n        else:\n            raise dominoes.EndsMismatchException(\n                '{} cannot be added to the right of'\n                ' the board - values do not match!'.format(d)\n            )", "response": "Adds the provided domino to the right end of the board."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef play(self, d):\n        '''\n        Removes a domino from the hand.\n\n        :param Domino d: domino to remove from the hand\n        :return: the index within the hand of the played domino\n        :raises NoSuchDominoException: if the domino is not in the hand\n        '''\n        try:\n            i = self._dominoes.index(d)\n        except ValueError:\n            raise dominoes.NoSuchDominoException('Cannot make move -'\n                                                 ' {} is not in hand!'.format(d))\n\n        self._dominoes.pop(i)\n        return i", "response": "Removes a domino from the hand."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a domino to the hand.", "response": "def draw(self, d, i=None):\n        '''\n        Adds a domino to the hand.\n\n        :param Domino d: domino to add to the hand\n        :param int i: index at which to add the domino;\n                      by default adds to the end of the hand\n        :return: None\n        '''\n        if i is None:\n            self._dominoes.append(d)\n        else:\n            self._dominoes.insert(i, d)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of full paths to the exec_name in the PATH environment variable", "response": "def find_exec_in_path(exec_name):\n    \"\"\"\n    :param str exec_name:\n    :return: yields full paths\n    :rtype: list[str]\n    \"\"\"\n    if \"PATH\" not in os.environ:\n        return\n    for p in os.environ[\"PATH\"].split(\":\"):\n        pp = \"%s/%s\" % (p, exec_name)\n        if os.path.exists(pp):\n            yield pp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the list of packages from pkg - config.", "response": "def get_pkg_config(pkg_config_args, *packages):\n    \"\"\"\n    :param str|list[str] pkg_config_args: e.g. \"--cflags\"\n    :param str packages: e.g. \"python3\"\n    :rtype: list[str]|None\n    \"\"\"\n    if not isinstance(pkg_config_args, (tuple, list)):\n        pkg_config_args = [pkg_config_args]\n    # Maybe we have multiple pkg-config, and maybe some of them finds it.\n    for pp in find_exec_in_path(\"pkg-config\"):\n        try:\n            cmd = [pp] + list(pkg_config_args) + list(packages)\n            #print(\" \".join(cmd))\n            out = check_output(cmd, stderr=open(os.devnull, \"wb\"))\n            return out.strip().decode(\"utf8\").split()\n        except CalledProcessError:\n            pass\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns keyword arguments for pkg - config.", "response": "def pkgconfig(*packages, **kw):\n\t\"\"\"\n\t:param str packages: list like 'libavutil', 'libavformat', ...\n\t:rtype: dict[str]\n\t\"\"\"\n\tkw = kw.copy()\n\tflag_map = {'-I': 'include_dirs', '-L': 'library_dirs', '-l': 'libraries'}  # kwargs of :class:`Extension`\n\tfor token in check_output([\"pkg-config\", \"--libs\", \"--cflags\"] + list(packages)).split():\n\t\tif token[:2] in flag_map:\n\t\t\tkw.setdefault(flag_map[token[:2]], []).append(token[2:])\n\t\telse:  # throw others to extra_link_args\n\t\t\tkw.setdefault('extra_link_args', []).append(token)\n\treturn kw"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new set of centerlines from a source ESRI Shapefile.", "response": "def create_centerlines(src, dst, density=0.5):\n    \"\"\"\n    Create centerlines and save the to an ESRI Shapefile.\n\n    Reads polygons from the `src` ESRI Shapefile, creates Centerline\n    objects with the specified `density` parameter and writes them to\n    the `dst` ESRI Shapefile.\n\n    Only Polygon features are converted to centerlines. Features of\n    different types are skipped.\n\n    Args:\n        src (str): source ESRI Shapefile\n        dst (str): destination ESRI Shapefile\n        density (:obj:`float`, optional): the Centerline's density.\n            Defaults to 0.5 (meters)\n\n    Returns:\n        None\n\n    \"\"\"\n    try:\n        DST_DRIVER = get_ogr_driver(filepath=dst)\n    except ValueError:\n        raise\n\n    with fiona.Env():\n        with fiona.open(src, mode='r') as source:\n            SCHEMA = source.schema.copy()\n            SCHEMA.update({'geometry': 'MultiLineString'})\n            with fiona.open(\n                    dst,\n                    mode='w',\n                    driver=DST_DRIVER.GetName(),\n                    schema=SCHEMA,\n                    crs=source.crs,\n                    encoding=source.encoding) as destination:\n                for record in source:\n                    geom = record.get('geometry')\n                    input_geom = shape(geom)\n\n                    if not is_valid_geometry(geometry=input_geom):\n                        continue\n\n                    attributes = record.get('properties')\n                    try:\n                        centerline_obj = Centerline(\n                            input_geom=input_geom,\n                            interpolation_dist=density,\n                            **attributes\n                        )\n                    except RuntimeError as err:\n                        logging.warning(\n                            \"ignoring record that could not be processed: %s\",\n                            err\n                        )\n                        continue\n\n                    centerline_dict = {\n                        'geometry': mapping(centerline_obj),\n                        'properties': {\n                            k: v\n                            for k, v in centerline_obj.__dict__.items()\n                            if k in attributes.keys()\n                        }\n                    }\n\n                    destination.write(centerline_dict)\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_centerline(self):\n        border = array(self.__densify_border())\n\n        vor = Voronoi(border)\n        vertex = vor.vertices\n\n        lst_lines = []\n        for j, ridge in enumerate(vor.ridge_vertices):\n            if -1 not in ridge:\n                line = LineString([\n                    (vertex[ridge[0]][0] + self._minx,\n                     vertex[ridge[0]][1] + self._miny),\n                    (vertex[ridge[1]][0] + self._minx,\n                     vertex[ridge[1]][1] + self._miny)])\n\n                if line.within(self._input_geom) and len(line.coords[0]) > 1:\n                    lst_lines.append(line)\n\n        nr_lines = len(lst_lines)\n        if nr_lines < 2:\n            raise RuntimeError((\n                \"Number of produced ridges is too small: {}\"\n                \", this might be caused by too large interpolation distance.\"\n            ).format(nr_lines))\n\n        return unary_union(lst_lines)", "response": "Calculate the centerline of a polygon."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplaces additional points on the border at the specified distance. By default the distance is 0.5 (meters) which means that the first point will be placed 0.5 m from the starting point, the second point will be placed at the distance of 1.0 m from the first point, etc. The loop breaks when the summarized distance exceeds the length of the line. Args: line (shapely.geometry.LineString): object Returns: list: a list of points where each point is represented by a list of its reduced coordinates Example: [[X1, Y1], [X2, Y2], ..., [Xn, Yn]", "response": "def __fixed_interpolation(self, line):\n        \"\"\"\n        Place additional points on the border at the specified distance.\n\n        By default the distance is 0.5 (meters) which means that the first\n        point will be placed 0.5 m from the starting point, the second\n        point will be placed at the distance of 1.0 m from the first\n        point, etc. The loop breaks when the summarized distance exceeds\n        the length of the line.\n\n        Args:\n            line (shapely.geometry.LineString): object\n\n        Returns:\n            list: a list of points where each point is represented by\n                a list of its reduced coordinates\n\n        Example:\n            [[X1, Y1], [X2, Y2], ..., [Xn, Yn]\n\n        \"\"\"\n        STARTPOINT = [line.xy[0][0] - self._minx, line.xy[1][0] - self._miny]\n        ENDPOINT = [line.xy[0][-1] - self._minx, line.xy[1][-1] - self._miny]\n\n        count = self._interpolation_dist\n        newline = [STARTPOINT]\n\n        while count < line.length:\n            point = line.interpolate(count)\n            newline.append([point.x - self._minx, point.y - self._miny])\n            count += self._interpolation_dist\n\n        newline.append(ENDPOINT)\n\n        return newline"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that the geometry type is of type Polygon or MultiPolygon.", "response": "def is_valid_geometry(geometry):\n    \"\"\"\n    Confirm that the geometry type is of type Polygon or MultiPolygon.\n\n    Args:\n        geometry (BaseGeometry): BaseGeometry instance (e.g. Polygon)\n\n    Returns:\n        bool\n\n    \"\"\"\n    if isinstance(geometry, Polygon) or isinstance(geometry, MultiPolygon):\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ogr_driver(filepath):\n    filename, file_extension = os.path.splitext(filepath)\n    EXTENSION = file_extension[1:]\n\n    ogr_driver_count = ogr.GetDriverCount()\n    for idx in range(ogr_driver_count):\n        driver = ogr.GetDriver(idx)\n        driver_extension = driver.GetMetadataItem(str('DMD_EXTENSION')) or ''\n        driver_extensions = driver.GetMetadataItem(str('DMD_EXTENSIONS')) or ''\n\n        if EXTENSION == driver_extension or EXTENSION in driver_extensions:\n            return driver\n\n    else:\n        msg = 'No driver found for the following file extension: {}'.format(\n            EXTENSION)\n        raise ValueError(msg)", "response": "Get the OGR driver from the provided file extension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert number words to integers in a given text.", "response": "def get_numwords():\n    \"\"\"Convert number words to integers in a given text.\"\"\"\n    numwords = {'and': (1, 0), 'a': (1, 1), 'an': (1, 1)}\n\n    for idx, word in enumerate(UNITS):\n        numwords[word] = (1, idx)\n    for idx, word in enumerate(TENS):\n        numwords[word] = (1, idx * 10)\n    for idx, word in enumerate(SCALES):\n        numwords[word] = (10 ** (idx * 3 or 2), 0)\n\n    all_numbers = ur'|'.join(ur'\\b%s\\b' % i for i in numwords.keys() if i)\n\n    return all_numbers, numwords"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a compiled regex object for all units in the current language.", "response": "def get_units_regex():\n    \"\"\"Build a compiled regex object.\"\"\"\n    op_keys = sorted(OPERATORS.keys(), key=len, reverse=True)\n    unit_keys = sorted(l.UNITS.keys(), key=len, reverse=True)\n    symbol_keys = sorted(l.SYMBOLS.keys(), key=len, reverse=True)\n\n    exponent = ur'(?:(?:\\^?\\-?[0-9%s]*)(?:\\ cubed|\\ squared)?)(?![a-zA-Z])' % \\\n               SUPERSCRIPTS\n\n    all_ops = '|'.join([r'%s' % re.escape(i) for i in op_keys])\n    all_units = '|'.join([ur'%s' % re.escape(i) for i in unit_keys])\n    all_symbols = '|'.join([ur'%s' % re.escape(i) for i in symbol_keys])\n\n    pattern = ur'''\n\n        (?P<prefix>(?:%s)(?![a-zA-Z]))?         # Currencies, mainly\n        (?P<value>%s)-?                           # Number\n        (?:(?P<operator1>%s)?(?P<unit1>(?:%s)%s)?)    # Operator + Unit (1)\n        (?:(?P<operator2>%s)?(?P<unit2>(?:%s)%s)?)    # Operator + Unit (2)\n        (?:(?P<operator3>%s)?(?P<unit3>(?:%s)%s)?)    # Operator + Unit (3)\n        (?:(?P<operator4>%s)?(?P<unit4>(?:%s)%s)?)    # Operator + Unit (4)\n\n    ''' % tuple([all_symbols, RAN_PATTERN] + 4 * [all_ops, all_units,\n                                                  exponent])\n\n    regex = re.compile(pattern, re.VERBOSE | re.IGNORECASE)\n\n    return regex"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_dimension_permutations(entities, dimensions):\n    new_dimensions = defaultdict(int)\n    for item in dimensions:\n        new = entities[item['base']].dimensions\n        if new:\n            for new_item in new:\n                new_dimensions[new_item['base']] += new_item['power'] * \\\n                                                 item['power']\n        else:\n            new_dimensions[item['base']] += item['power']\n\n    final = [[{'base': i[0], 'power': i[1]} for i in new_dimensions.items()]]\n    final.append(dimensions)\n    final = [sorted(i, key=lambda x: x['base']) for i in final]\n\n    candidates = []\n    for item in final:\n        if item not in candidates:\n            candidates.append(item)\n\n    return candidates", "response": "Get all possible dimensional definitions for an entity."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_entities():\n    path = os.path.join(TOPDIR, 'entities.json')\n    entities = json.load(open(path))\n    names = [i['name'] for i in entities]\n\n    try:\n        assert len(set(names)) == len(entities)\n    except AssertionError:\n        raise Exception('Entities with same name: %s' % [i for i in names if\n                                                         names.count(i) > 1])\n\n    entities = dict((k['name'], c.Entity(name=k['name'],\n                                         dimensions=k['dimensions'],\n                                         uri=k['URI'])) for k in entities)\n\n    dimensions_ent = defaultdict(list)\n    for ent in entities:\n        if not entities[ent].dimensions:\n            continue\n        perms = get_dimension_permutations(entities, entities[ent].dimensions)\n        for perm in perms:\n            key = get_key_from_dimensions(perm)\n            dimensions_ent[key].append(entities[ent])\n\n    return entities, dimensions_ent", "response": "Load entities from JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating dictionary of unit dimensions.", "response": "def get_dimensions_units(names):\n    \"\"\"Create dictionary of unit dimensions.\"\"\"\n    dimensions_uni = {}\n\n    for name in names:\n\n        key = get_key_from_dimensions(names[name].dimensions)\n        dimensions_uni[key] = names[name]\n        plain_dimensions = [{'base': name, 'power': 1}]\n        key = get_key_from_dimensions(plain_dimensions)\n        dimensions_uni[key] = names[name]\n\n        if not names[name].dimensions:\n            names[name].dimensions = plain_dimensions\n\n        names[name].dimensions = [{'base': names[i['base']].name,\n                                   'power': i['power']} for i in\n                                  names[name].dimensions]\n\n    return dimensions_uni"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads units from JSON file.", "response": "def load_units():\n    \"\"\"Load units from JSON file.\"\"\"\n    names = {}\n    lowers = defaultdict(list)\n    symbols = defaultdict(list)\n    surfaces = defaultdict(list)\n    for unit in json.load(open(os.path.join(TOPDIR, 'units.json'))):\n\n        try:\n            assert unit['name'] not in names\n        except AssertionError:\n            msg = 'Two units with same name in units.json: %s' % unit['name']\n            raise Exception(msg)\n\n        obj = c.Unit(name=unit['name'], surfaces=unit['surfaces'],\n                     entity=ENTITIES[unit['entity']], uri=unit['URI'],\n                     symbols=unit['symbols'], dimensions=unit['dimensions'])\n\n        names[unit['name']] = obj\n\n        for symbol in unit['symbols']:\n            surfaces[symbol].append(obj)\n            lowers[symbol.lower()].append(obj)\n            if unit['entity'] == 'currency':\n                symbols[symbol].append(obj)\n\n        for surface in unit['surfaces']:\n            surfaces[surface].append(obj)\n            lowers[surface.lower()].append(obj)\n            split = surface.split()\n            index = None\n            if ' per ' in surface:\n                index = split.index('per') - 1\n            elif 'degree ' in surface:\n                index = split.index('degree')\n            if index is not None:\n                plural = ' '.join([i if num != index else\n                                   PLURALS.plural(split[index]) for num, i in\n                                   enumerate(split)])\n            else:\n                plural = PLURALS.plural(surface)\n            if plural != surface:\n                surfaces[plural].append(obj)\n                lowers[plural.lower()].append(obj)\n\n    dimensions_uni = get_dimensions_units(names)\n\n    return names, surfaces, lowers, symbols, dimensions_uni"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading WikiPedia pages of ambiguous units.", "response": "def download_wiki():\n    \"\"\"Download WikiPedia pages of ambiguous units.\"\"\"\n    ambiguous = [i for i in l.UNITS.items() if len(i[1]) > 1]\n    ambiguous += [i for i in l.DERIVED_ENT.items() if len(i[1]) > 1]\n    pages = set([(j.name, j.uri) for i in ambiguous for j in i[1]])\n\n    print\n    objs = []\n    for num, page in enumerate(pages):\n\n        obj = {'url': page[1]}\n        obj['_id'] = obj['url'].replace('https://en.wikipedia.org/wiki/', '')\n        obj['clean'] = obj['_id'].replace('_', ' ')\n\n        print '---> Downloading %s (%d of %d)' % \\\n              (obj['clean'], num + 1, len(pages))\n\n        obj['text'] = wikipedia.page(obj['clean']).content\n        obj['unit'] = page[0]\n        objs.append(obj)\n\n    path = os.path.join(l.TOPDIR, 'wiki.json')\n    os.remove(path)\n    json.dump(objs, open(path, 'w'), indent=4, sort_keys=True)\n\n    print '\\n---> All done.\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclean text for TFIDF.", "response": "def clean_text(text):\n    \"\"\"Clean text for TFIDF.\"\"\"\n    new_text = re.sub(ur'\\p{P}+', ' ', text)\n\n    new_text = [stem(i) for i in new_text.lower().split() if not\n                re.findall(r'[0-9]', i)]\n\n    new_text = ' '.join(new_text)\n\n    return new_text"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef train_classifier(download=True, parameters=None, ngram_range=(1, 1)):\n    if download:\n        download_wiki()\n\n    path = os.path.join(l.TOPDIR, 'train.json')\n    training_set = json.load(open(path))\n    path = os.path.join(l.TOPDIR, 'wiki.json')\n    wiki_set = json.load(open(path))\n\n    target_names = list(set([i['unit'] for i in training_set + wiki_set]))\n    train_data, train_target = [], []\n    for example in training_set + wiki_set:\n        train_data.append(clean_text(example['text']))\n        train_target.append(target_names.index(example['unit']))\n\n    tfidf_model = TfidfVectorizer(sublinear_tf=True,\n                                  ngram_range=ngram_range,\n                                  stop_words='english')\n\n    matrix = tfidf_model.fit_transform(train_data)\n\n    if parameters is None:\n        parameters = {'loss': 'log', 'penalty': 'l2', 'n_iter': 50,\n                      'alpha': 0.00001, 'fit_intercept': True}\n\n    clf = SGDClassifier(**parameters).fit(matrix, train_target)\n    obj = {'tfidf_model': tfidf_model,\n           'clf': clf,\n           'target_names': target_names}\n    path = os.path.join(l.TOPDIR, 'clf.pickle')\n    pickle.dump(obj, open(path, 'w'))", "response": "Train the intent classifier."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_classifier():\n    path = os.path.join(l.TOPDIR, 'clf.pickle')\n    obj = pickle.load(open(path, 'r'))\n\n    return obj['tfidf_model'], obj['clf'], obj['target_names']", "response": "Train the intent classifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves ambiguity between entities with same dimensionality.", "response": "def disambiguate_entity(key, text):\n    \"\"\"Resolve ambiguity between entities with same dimensionality.\"\"\"\n    new_ent = l.DERIVED_ENT[key][0]\n\n    if len(l.DERIVED_ENT[key]) > 1:\n        transformed = TFIDF_MODEL.transform([text])\n        scores = CLF.predict_proba(transformed).tolist()[0]\n        scores = sorted(zip(scores, TARGET_NAMES), key=lambda x: x[0],\n                        reverse=True)\n        names = [i.name for i in l.DERIVED_ENT[key]]\n        scores = [i for i in scores if i[1] in names]\n        try:\n            new_ent = l.ENTITIES[scores[0][1]]\n        except IndexError:\n            logging.debug('\\tAmbiguity not resolved for \"%s\"', str(key))\n\n    return new_ent"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef disambiguate_unit(unit, text):\n    new_unit = l.UNITS[unit]\n    if not new_unit:\n        new_unit = l.LOWER_UNITS[unit.lower()]\n        if not new_unit:\n            raise KeyError('Could not find unit \"%s\"' % unit)\n\n    if len(new_unit) > 1:\n        transformed = TFIDF_MODEL.transform([clean_text(text)])\n        scores = CLF.predict_proba(transformed).tolist()[0]\n        scores = sorted(zip(scores, TARGET_NAMES), key=lambda x: x[0],\n                        reverse=True)\n        names = [i.name for i in new_unit]\n        scores = [i for i in scores if i[1] in names]\n        try:\n            final = l.UNITS[scores[0][1]][0]\n            logging.debug('\\tAmbiguity resolved for \"%s\" (%s)', unit, scores)\n        except IndexError:\n            logging.debug('\\tAmbiguity not resolved for \"%s\"', unit)\n            final = new_unit[0]\n    else:\n        final = new_unit[0]\n\n    return final", "response": "Disambiguate a single unit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove spurious characters from a quantity s surface.", "response": "def clean_surface(surface, span):\n    \"\"\"Remove spurious characters from a quantity's surface.\"\"\"\n    surface = surface.replace('-', ' ')\n    no_start = ['and', ' ']\n    no_end = [' and', ' ']\n\n    found = True\n    while found:\n        found = False\n        for word in no_start:\n            if surface.lower().startswith(word):\n                surface = surface[len(word):]\n                span = (span[0] + len(word), span[1])\n                found = True\n        for word in no_end:\n            if surface.lower().endswith(word):\n                surface = surface[:-len(word)]\n                span = (span[0], span[1] - len(word))\n                found = True\n\n    if not surface:\n        return None, None\n\n    split = surface.lower().split()\n    if split[0] in ['one', 'a', 'an'] and len(split) > 1 and split[1] in \\\n            r.UNITS + r.TENS:\n        span = (span[0] + len(surface.split()[0]) + 1, span[1])\n        surface = ' '.join(surface.split()[1:])\n\n    return surface, span"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_spellout_values(text):\n    values = []\n    for item in r.REG_TXT.finditer(text):\n        surface, span = clean_surface(item.group(0), item.span())\n        if not surface or surface.lower() in r.SCALES:\n            continue\n        curr = result = 0.0\n        for word in surface.split():\n            try:\n                scale, increment = 1, float(word.lower())\n            except ValueError:\n                scale, increment = r.NUMWORDS[word.lower()]\n            curr = curr * scale + increment\n            if scale > 100:\n                result += curr\n                curr = 0.0\n        values.append({'old_surface': surface,\n                       'old_span': span,\n                       'new_surface': unicode(result + curr)})\n\n    for item in re.finditer(r'\\d+(,\\d{3})+', text):\n        values.append({'old_surface': item.group(0),\n                       'old_span': item.span(),\n                       'new_surface': unicode(item.group(0).replace(',', ''))})\n\n    return sorted(values, key=lambda x: x['old_span'][0])", "response": "Convert spelled out numbers in a given text to digits."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting spelled out numbers in a given text to digits.", "response": "def substitute_values(text, values):\n    \"\"\"Convert spelled out numbers in a given text to digits.\"\"\"\n    shift, final_text, shifts = 0, text, defaultdict(int)\n    for value in values:\n        first = value['old_span'][0] + shift\n        second = value['old_span'][1] + shift\n        new_s = value['new_surface']\n        final_text = final_text[0:first] + new_s + final_text[second:]\n        shift += len(new_s) - len(value['old_surface'])\n        for char in range(first + 1, len(final_text)):\n            shifts[char] = shift\n\n    logging.debug(u'Text after numeric conversion: \"%s\"', final_text)\n\n    return final_text, shifts"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_values(item):\n    fracs = r'|'.join(r.UNI_FRAC)\n\n    value = item.group(2)\n    value = re.sub(ur'(?<=\\d)(%s)10' % r.MULTIPLIERS, 'e', value)\n    value = re.sub(fracs, callback, value, re.IGNORECASE)\n    value = re.sub(' +', ' ', value)\n\n    range_separator = re.findall(ur'\\d+ ?(-|and|(?:- ?)?to) ?\\d', value)\n    uncer_separator = re.findall(ur'\\d+ ?(\\+/-|\u00b1) ?\\d', value)\n    fract_separator = re.findall(ur'\\d+/\\d+', value)\n\n    uncertainty = None\n    if range_separator:\n        values = value.split(range_separator[0])\n        values = [float(re.sub(r'-$', '', i)) for i in values]\n    elif uncer_separator:\n        values = [float(i) for i in value.split(uncer_separator[0])]\n        uncertainty = values[1]\n        values = [values[0]]\n    elif fract_separator:\n        values = value.split()\n        if len(values) > 1:\n            values = [float(values[0]) + float(Fraction(values[1]))]\n        else:\n            values = [float(Fraction(values[0]))]\n    else:\n        values = [float(re.sub(r'-$', '', value))]\n\n    logging.debug(u'\\tUncertainty: %s', uncertainty)\n    logging.debug(u'\\tValues: %s', values)\n\n    return uncertainty, values", "response": "Extract value from regex hit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_unit_name(dimensions):\n    name = ''\n\n    for unit in dimensions:\n        if unit['power'] < 0:\n            name += 'per '\n        power = abs(unit['power'])\n        if power == 1:\n            name += unit['base']\n        elif power == 2:\n            name += 'square ' + unit['base']\n        elif power == 3:\n            name += 'cubic ' + unit['base']\n        elif power > 3:\n            name += unit['base'] + ' to the %g' % power\n        name += ' '\n\n    name = name.strip()\n\n    logging.debug(u'\\tUnit inferred name: %s', name)\n\n    return name", "response": "Build the name of the unit from its dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreconciles a unit based on its dimensionality.", "response": "def get_unit_from_dimensions(dimensions, text):\n    \"\"\"Reconcile a unit based on its dimensionality.\"\"\"\n    key = l.get_key_from_dimensions(dimensions)\n\n    try:\n        unit = l.DERIVED_UNI[key]\n    except KeyError:\n        logging.debug(u'\\tCould not find unit for: %s', key)\n        unit = c.Unit(name=build_unit_name(dimensions),\n                      dimensions=dimensions,\n                      entity=get_entity_from_dimensions(dimensions, text))\n\n    return unit"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an entity from the given dimension.", "response": "def get_entity_from_dimensions(dimensions, text):\n    \"\"\"\n    Infer the underlying entity of a unit (e.g. \"volume\" for \"m^3\").\n\n    Just based on the unit's dimensionality if the classifier is disabled.\n    \"\"\"\n    new_dimensions = [{'base': l.NAMES[i['base']].entity.name,\n                       'power': i['power']} for i in dimensions]\n\n    final_dimensions = sorted(new_dimensions, key=lambda x: x['base'])\n    key = l.get_key_from_dimensions(final_dimensions)\n\n    try:\n        if clf.USE_CLF:\n            ent = clf.disambiguate_entity(key, text)\n        else:\n            ent = l.DERIVED_ENT[key][0]\n    except IndexError:\n        logging.debug(u'\\tCould not find entity for: %s', key)\n        ent = c.Entity(name='unknown', dimensions=new_dimensions)\n\n    return ent"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_unit(item, group, slash):\n    surface = item.group(group).replace('.', '')\n    power = re.findall(r'\\-?[0-9%s]+' % r.SUPERSCRIPTS, surface)\n\n    if power:\n        power = [r.UNI_SUPER[i] if i in r.UNI_SUPER else i for i\n                 in power]\n        power = ''.join(power)\n        new_power = (-1 * int(power) if slash else int(power))\n        surface = re.sub(r'\\^?\\-?[0-9%s]+' % r.SUPERSCRIPTS, '', surface)\n\n    elif re.findall(r'\\bcubed\\b', surface):\n        new_power = (-3 if slash else 3)\n        surface = re.sub(r'\\bcubed\\b', '', surface).strip()\n\n    elif re.findall(r'\\bsquared\\b', surface):\n        new_power = (-2 if slash else 2)\n        surface = re.sub(r'\\bsquared\\b', '', surface).strip()\n\n    else:\n        new_power = (-1 if slash else 1)\n\n    return surface, new_power", "response": "Parse the surface and power from unit text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_unit(item, text):\n    group_units = [1, 4, 6, 8, 10]\n    group_operators = [3, 5, 7, 9]\n\n    item_units = [item.group(i) for i in group_units if item.group(i)]\n\n    if len(item_units) == 0:\n        unit = l.NAMES['dimensionless']\n    else:\n        dimensions, slash = [], False\n        for group in sorted(group_units + group_operators):\n            if not item.group(group):\n                continue\n            if group in group_units:\n                surface, power = parse_unit(item, group, slash)\n                if clf.USE_CLF:\n                    base = clf.disambiguate_unit(surface, text).name\n                else:\n                    base = l.UNITS[surface][0].name\n                dimensions += [{'base': base, 'power': power}]\n            elif not slash:\n                slash = any(i in item.group(group) for i in [u'/', u' per '])\n\n        unit = get_unit_from_dimensions(dimensions, text)\n\n    logging.debug(u'\\tUnit: %s', unit)\n    logging.debug(u'\\tEntity: %s', unit.entity)\n\n    return unit", "response": "Extract unit from regex hit."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts a single segment from a regex hit.", "response": "def get_surface(shifts, orig_text, item, text):\n    \"\"\"Extract surface from regex hit.\"\"\"\n    span = item.span()\n    logging.debug(u'\\tInitial span: %s (\"%s\")', span, text[span[0]:span[1]])\n\n    real_span = (span[0] - shifts[span[0]], span[1] - shifts[span[1] - 1])\n    surface = orig_text[real_span[0]:real_span[1]]\n    logging.debug(u'\\tShifted span: %s (\"%s\")', real_span, surface)\n\n    while any(surface.endswith(i) for i in [' ', '-']):\n        surface = surface[:-1]\n        real_span = (real_span[0], real_span[1] - 1)\n\n    while surface.startswith(' '):\n        surface = surface[1:]\n        real_span = (real_span[0] + 1, real_span[1])\n\n    logging.debug(u'\\tFinal span: %s (\"%s\")', real_span, surface)\n    return surface, real_span"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_quote_artifact(orig_text, span):\n    res = False\n    cursor = re.finditer(r'(\"|\\')[^ .,:;?!()*+-].*?(\"|\\')', orig_text)\n\n    for item in cursor:\n        if item.span()[1] == span[1]:\n            res = True\n\n    return res", "response": "Distinguish between quotes and units."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_quantity(orig_text, text, item, values, unit, surface, span, uncert):\n    # Discard irrelevant txt2float extractions, cardinal numbers, codes etc.\n    if surface.lower() in ['a', 'an', 'one'] or \\\n            re.search(r'1st|2nd|3rd|[04-9]th', surface) or \\\n            re.search(r'\\d+[A-Z]+\\d+', surface) or \\\n            re.search(r'\\ba second\\b', surface, re.IGNORECASE):\n        logging.debug(u'\\tMeaningless quantity (\"%s\"), discard', surface)\n        return\n\n    # Usually \"$3T\" does not stand for \"dollar tesla\"\n    elif unit.entity.dimensions and \\\n            unit.entity.dimensions[0]['base'] == 'currency':\n        if len(unit.dimensions) > 1:\n            try:\n                suffix = re.findall(r'\\d(K|M|B|T)\\b(.*?)$', surface)[0]\n                values = [i * r.SUFFIXES[suffix[0]] for i in values]\n                unit = l.UNITS[unit.dimensions[0]['base']][0]\n                if suffix[1]:\n                    surface = surface[:surface.find(suffix[1])]\n                    span = (span[0], span[1] - len(suffix[1]))\n                logging.debug(u'\\tCorrect for \"$3T\" pattern')\n            except IndexError:\n                pass\n        else:\n            try:\n                suffix = re.findall(r'%s(K|M|B|T)\\b' % re.escape(surface),\n                                    orig_text)[0]\n                surface += suffix\n                span = (span[0], span[1] + 1)\n                values = [i * r.SUFFIXES[suffix] for i in values]\n                logging.debug(u'\\tCorrect for \"$3T\" pattern')\n            except IndexError:\n                pass\n\n    # Usually \"1990s\" stands for the decade, not the amount of seconds\n    elif re.match(r'[1-2]\\d\\d0s', surface):\n        unit = l.NAMES['dimensionless']\n        surface = surface[:-1]\n        span = (span[0], span[1] - 1)\n        logging.debug(u'\\tCorrect for decade pattern')\n\n    # Usually \"in\" stands for the preposition, not inches\n    elif unit.dimensions[-1]['base'] == 'inch' and \\\n            re.search(r' in$', surface) and '/' not in surface:\n        if len(unit.dimensions) > 1:\n            unit = get_unit_from_dimensions(unit.dimensions[:-1], orig_text)\n        else:\n            unit = l.NAMES['dimensionless']\n        surface = surface[:-3]\n        span = (span[0], span[1] - 3)\n        logging.debug(u'\\tCorrect for \"in\" pattern')\n\n    elif is_quote_artifact(text, item.span()):\n        if len(unit.dimensions) > 1:\n            unit = get_unit_from_dimensions(unit.dimensions[:-1], orig_text)\n        else:\n            unit = l.NAMES['dimensionless']\n        surface = surface[:-1]\n        span = (span[0], span[1] - 1)\n        logging.debug(u'\\tCorrect for quotes')\n\n    elif re.search(r' time$', surface) and len(unit.dimensions) > 1 and \\\n            unit.dimensions[-1]['base'] == 'count':\n        unit = get_unit_from_dimensions(unit.dimensions[:-1], orig_text)\n        surface = surface[:-5]\n        span = (span[0], span[1] - 5)\n        logging.debug(u'\\tCorrect for \"time\"')\n\n    objs = []\n    for value in values:\n        obj = c.Quantity(value=value,\n                         unit=unit,\n                         surface=surface,\n                         span=span,\n                         uncertainty=uncert)\n        objs.append(obj)\n\n    return objs", "response": "Build a Quantity object out of extracted information."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclean text before parsing.", "response": "def clean_text(text):\n    \"\"\"Clean text before parsing.\"\"\"\n    # Replace a few nasty unicode characters with their ASCII equivalent\n    maps = {u'\u00d7': u'x', u'\u2013': u'-', u'\u2212': '-'}\n    for element in maps:\n        text = text.replace(element, maps[element])\n\n    # Replace genitives\n    text = re.sub(r'(?<=\\w)\\'s\\b|(?<=\\w)s\\'(?!\\w)', '  ', text)\n\n    logging.debug(u'Clean text: \"%s\"', text)\n\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting all quantities from unstructured text.", "response": "def parse(text, verbose=False):\n    \"\"\"Extract all quantities from unstructured text.\"\"\"\n    log_format = ('%(asctime)s --- %(message)s')\n    logging.basicConfig(format=log_format)\n    root = logging.getLogger()\n\n    if verbose:\n        level = root.level\n        root.setLevel(logging.DEBUG)\n        logging.debug(u'Verbose mode')\n\n    if isinstance(text, str):\n        text = text.decode('utf-8')\n        logging.debug(u'Converted string to unicode (assume utf-8 encoding)')\n\n    orig_text = text\n    logging.debug(u'Original text: \"%s\"', orig_text)\n\n    text = clean_text(text)\n    values = extract_spellout_values(text)\n    text, shifts = substitute_values(text, values)\n\n    quantities = []\n    for item in r.REG_DIM.finditer(text):\n\n        groups = dict([i for i in item.groupdict().items() if i[1] and\n                       i[1].strip()])\n        logging.debug(u'Quantity found: %s', groups)\n\n        try:\n            uncert, values = get_values(item)\n        except ValueError as err:\n            logging.debug(u'Could not parse quantity: %s', err)\n\n        unit = get_unit(item, text)\n        surface, span = get_surface(shifts, orig_text, item, text)\n        objs = build_quantity(orig_text, text, item, values, unit, surface,\n                              span, uncert)\n        if objs is not None:\n            quantities += objs\n\n    if verbose:\n        root.level = level\n\n    return quantities"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef inline_parse(text, verbose=False):\n    if isinstance(text, str):\n        text = text.decode('utf-8')\n\n    parsed = parse(text, verbose=verbose)\n\n    shift = 0\n    for quantity in parsed:\n        index = quantity.span[1] + shift\n        to_add = u' {' + unicode(quantity) + u'}'\n        text = text[0:index] + to_add + text[index:]\n        shift += len(to_add)\n\n    return text", "response": "Extract all quantities from unstructured text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreconnect to the Meteor server.", "response": "def _reconnected(self):\n        \"\"\"Reconnect\n\n        Currently we get a new session every time so we have\n        to clear all the data an resubscribe\"\"\"\n\n        if self._login_data or self._login_token:\n\n            def reconnect_login_callback(error, result):\n                if error:\n                    if self._login_token:\n                        self._login_token = None\n                        self._login(self._login_data,\n                                    callback=reconnect_login_callback)\n                        return\n                    else:\n                        raise MeteorClientException(\n                            'Failed to re-authenticate during reconnect')\n\n                self.connected = True\n                self._resubscribe()\n\n            if self._login_token:\n                self._resume(self._login_token,\n                             callback=reconnect_login_callback)\n            else:\n                self._login(self._login_data,\n                            callback=reconnect_login_callback)\n        else:\n            self._resubscribe()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs-in with a username and password", "response": "def login(self, user, password, token=None, callback=None):\n        \"\"\"Login with a username and password\n\n        Arguments:\n        user - username or email address\n        password - the password for the account\n\n        Keyword Arguments:\n        token - meteor resume token\n        callback - callback function containing error as first argument and login data\"\"\"\n        # TODO: keep the tokenExpires around so we know the next time\n        #       we need to authenticate\n\n        # hash the password\n        hashed = hashlib.sha256(password).hexdigest()\n        # handle username or email address\n        if '@' in user:\n            user_object = {\n                'email': user\n            }\n        else:\n            user_object = {\n                'username': user\n            }\n        password_object = {\n            'algorithm': 'sha-256',\n            'digest': hashed\n        }\n\n        self._login_token = token\n        self._login_data = {'user': user_object, 'password': password_object}\n\n        if token:\n            self._resume(token, callback=callback)\n        else:\n            self._login(self._login_data, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef call(self, method, params, callback=None):\n        self._wait_for_connect()\n        self.ddp_client.call(method, params, callback=callback)", "response": "Call a remote method on the DDP server"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsubscribes to a collection of publication items.", "response": "def subscribe(self, name, params=[], callback=None):\n        \"\"\"Subscribe to a collection\n        Arguments:\n        name - the name of the publication\n        params - the subscription parameters\n\n        Keyword Arguments:\n        callback - a function callback that returns an error (if exists)\"\"\"\n        self._wait_for_connect()\n\n        def subscribed(error, sub_id):\n            if error:\n                self._remove_sub_by_id(sub_id)\n                if callback:\n                    callback(error.get('reason'))\n                return\n            if callback:\n                callback(None)\n            self.emit('subscribed', name)\n\n        if name in self.subscriptions:\n            raise MeteorClientException('Already subcribed to {}'.format(name))\n\n        sub_id = self.ddp_client.subscribe(name, params, subscribed)\n        self.subscriptions[name] = {\n            'id': sub_id,\n            'params': params\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find(self, collection, selector={}):\n        results = []\n        for _id, doc in self.collection_data.data.get(collection, {}).items():\n            doc.update({'_id': _id})\n            if selector == {}:\n                results.append(doc)\n            for key, value in selector.items():\n                if key in doc and doc[key] == value:\n                    results.append(doc)\n        return results", "response": "Find data in a collection"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_one(self, collection, selector={}):\n        for _id, doc in self.collection_data.data.get(collection, {}).items():\n            doc.update({'_id': _id})\n            if selector == {}:\n                return doc\n            for key, value in selector.items():\n                if key in doc and doc[key] == value:\n                    return doc\n        return None", "response": "Return one item from a collection"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert an item into a collection", "response": "def insert(self, collection, doc, callback=None):\n        \"\"\"Insert an item into a collection\n\n        Arguments:\n        collection - the collection to be modified\n        doc - The document to insert. May not yet have an _id attribute,\n        in which case Meteor will generate one for you.\n\n        Keyword Arguments:\n        callback - Optional. If present, called with an error object as the first argument and,\n        if no error, the _id as the second.\"\"\"\n        self.call(\"/\" + collection + \"/insert\", [doc], callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninserts an item into a collection", "response": "def update(self, collection, selector, modifier, callback=None):\n        \"\"\"Insert an item into a collection\n\n        Arguments:\n        collection - the collection to be modified\n        selector - specifies which documents to modify\n        modifier - Specifies how to modify the documents\n\n        Keyword Arguments:\n        callback - Optional. If present, called with an error object as the first argument and,\n        if no error, the number of affected documents as the second.\"\"\"\n        self.call(\"/\" + collection + \"/update\", [selector, modifier], callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove an item from a collection", "response": "def remove(self, collection, selector, callback=None):\n        \"\"\"Remove an item from a collection\n\n        Arguments:\n        collection - the collection to be modified\n        selector - Specifies which documents to remove\n\n        Keyword Arguments:\n        callback - Optional. If present, called with an error object as its argument.\"\"\"\n        self.call(\"/\" + collection + \"/remove\", [selector], callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self, status=1000, reason=u''):\n        try:\n            if self.closed is False:\n                close_msg = bytearray()\n                close_msg.extend(struct.pack(\"!H\", status))\n                if _check_unicode(reason):\n                    close_msg.extend(reason.encode('utf-8'))\n                else:\n                    close_msg.extend(reason)\n\n                self._send_message(False, CLOSE, close_msg)\n        finally:\n            self.closed = True", "response": "Send a Close frame to the underlying socket."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_fragment_start(self, data):\n        opcode = BINARY\n        if _check_unicode(data):\n            opcode = TEXT\n\n        self._send_message(True, opcode, data)", "response": "Send the start of a data fragment stream to a websocket client."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_message(self, data):\n        opcode = BINARY\n        if _check_unicode(data):\n            opcode = TEXT\n\n        self._send_message(False, opcode, data)", "response": "Send a message to the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deflate_and_encode(plantuml_text):\n    zlibbed_str = zlib.compress(plantuml_text.encode('utf-8'))\n    compressed_string = zlibbed_str[2:-4]\n    return encode(compressed_string.decode('latin-1'))", "response": "Deflate the plantuml text and encode it for the plantuml server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode(data):\n    res = \"\"\n    for i in range(0,len(data), 3):\n        if (i+2==len(data)):\n            res += _encode3bytes(ord(data[i]), ord(data[i+1]), 0)\n        elif (i+1==len(data)):\n            res += _encode3bytes(ord(data[i]), 0, 0)\n        else:\n            res += _encode3bytes(ord(data[i]), ord(data[i+1]), ord(data[i+2]))\n    return res", "response": "encode the plantuml data which may be compresses in the proper\n    encoding for the plantuml server"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef processes(self, plantuml_text):\n        url = self.get_url(plantuml_text)\n        try:\n            response, content = self.http.request(url, **self.request_opts)\n        except self.HttpLib2Error as e:\n            raise PlantUMLConnectionError(e)\n        if response.status != 200:\n            raise PlantUMLHTTPError(response, content)\n        return content", "response": "Processes the plantuml markup into the raw PNG image data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef processes_file(self, filename, outfile=None, errorfile=None):\n        if outfile is None:\n            outfile = os.path.splitext(filename)[0] + '.png'\n        if errorfile is None:\n            errorfile = os.path.splitext(filename)[0] + '_error.html'\n        data = open(filename, 'U').read()\n        try:\n            content = self.processes(data)\n        except PlantUMLHTTPError as e:\n            err = open(errorfile, 'w')\n            err.write(e.content)\n            err.close()\n            return False\n        out = open(outfile, 'wb')\n        out.write(content)\n        out.close()\n        return True", "response": "Processes a plantuml text file and writes the result to outfile."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef download_issuetypes(jira_connection, project_ids):\n    '''\n    For Jira next-gen projects, issue types can be scoped to projects.\n    For issue types that are scoped to projects, only extract the ones\n    in the extracted projects.\n    '''\n    print('downloading jira issue types... ', end='', flush=True)\n    result = []\n    for it in jira_connection.issue_types():\n        if 'scope' in it.raw and it.raw['scope']['type'] == 'PROJECT':\n            if it.raw['scope']['project']['id'] in project_ids:\n                result.append(it.raw)\n        else:\n            result.append(it.raw)\n    print('\u2713')\n    return result", "response": "Download all issue types from Jira"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a CertificateOptions from a collection of PEM objects.", "response": "def certificateOptionsFromPEMs(pemObjects, **kw):\n    # type: (List[AbstractPEMObject], **Any) -> ssl.CerticateOptions\n    \"\"\"\n    Load a CertificateOptions from the given collection of PEM objects\n    (already-loaded private keys and certificates).\n\n    In those PEM objects, identify one private key and its corresponding\n    certificate to use as the primary certificate.  Then use the rest of the\n    certificates found as chain certificates.  Raise a ValueError if no\n    certificate matching a private key is found.\n\n    :return: A TLS context factory using *pemObjects*\n    :rtype: `twisted.internet.ssl.CertificateOptions`_\n\n    .. _`twisted.internet.ssl.CertificateOptions`: \\\n        https://twistedmatrix.com/documents/current/api/\\\n        twisted.internet.ssl.CertificateOptions.html\n    \"\"\"\n    keys = [key for key in pemObjects if isinstance(key, Key)]\n    if not len(keys):\n        raise ValueError(\"Supplied PEM file(s) does *not* contain a key.\")\n    if len(keys) > 1:\n        raise ValueError(\"Supplied PEM file(s) contains *more* than one key.\")\n\n    privateKey = ssl.KeyPair.load(str(keys[0]), FILETYPE_PEM)\n\n    certs = [cert for cert in pemObjects if isinstance(cert, Certificate)]\n    if not len(certs):\n        raise ValueError(\"*At least one* certificate is required.\")\n    certificates = [ssl.Certificate.loadPEM(str(certPEM)) for certPEM in certs]\n\n    certificatesByFingerprint = dict(\n        [\n            (certificate.getPublicKey().keyHash(), certificate)\n            for certificate in certificates\n        ]\n    )\n\n    if privateKey.keyHash() not in certificatesByFingerprint:\n        raise ValueError(\n            \"No certificate matching {fingerprint} found.\".format(\n                fingerprint=privateKey.keyHash()\n            )\n        )\n\n    primaryCertificate = certificatesByFingerprint.pop(privateKey.keyHash())\n\n    if \"dhParameters\" in kw:\n        raise TypeError(\n            \"Passing DH parameters as a keyword argument instead of a \"\n            \"PEM object is not supported anymore.\"\n        )\n\n    dhparams = [o for o in pemObjects if isinstance(o, DHParameters)]\n    if len(dhparams) > 1:\n        raise ValueError(\n            \"Supplied PEM file(s) contain(s) *more* than one set of DH \"\n            \"parameters.\"\n        )\n    elif len(dhparams) == 1:\n        kw[\"dhParameters\"] = ssl.DiffieHellmanParameters(str(dhparams[0]))\n\n    ctxFactory = ssl.CertificateOptions(\n        privateKey=privateKey.original,\n        certificate=primaryCertificate.original,\n        extraCertChain=[\n            chain.original for chain in certificatesByFingerprint.values()\n        ],\n        **kw\n    )\n\n    return ctxFactory"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread all PEM files named by pemFiles and parse them using .", "response": "def certificateOptionsFromFiles(*pemFiles, **kw):\n    # type: (*str, **Any) -> ssl.CertificateOptions\n    \"\"\"\n    Read all files named by *pemFiles*, and parse them using\n    :func:`certificateOptionsFromPEMs`.\n    \"\"\"\n    pems = []  # type: List[AbstractPEMObject]\n    for pemFile in pemFiles:\n        pems += parse_file(pemFile)\n\n    return certificateOptionsFromPEMs(pems, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(pem_str):\n    # type: (bytes) -> List[AbstractPEMObject]\n    \"\"\"\n    Extract PEM objects from *pem_str*.\n\n    :param pem_str: String to parse.\n    :type pem_str: bytes\n    :return: list of :ref:`pem-objects`\n    \"\"\"\n    return [\n        _PEM_TO_CLASS[match.group(1)](match.group(0))\n        for match in _PEM_RE.finditer(pem_str)\n    ]", "response": "Extracts PEM objects from * pem_str*."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sha1_hexdigest(self):\n        # type: () -> str\n        \"\"\"\n        A SHA-1 digest of the whole object for easy differentiation.\n\n        .. versionadded:: 18.1.0\n        \"\"\"\n        if self._sha1_hexdigest is None:\n            self._sha1_hexdigest = hashlib.sha1(self._pem_bytes).hexdigest()\n\n        return self._sha1_hexdigest", "response": "A SHA - 1 hex digest of the whole object for easy differentiation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make(cls, **kwargs):\n    cls_attrs = {f.name: f for f in attr.fields(cls)}\n\n    unknown = {k: v for k, v in kwargs.items() if k not in cls_attrs}\n    if len(unknown) > 0:\n        _LOGGER.warning(\n            \"Got unknowns for %s: %s - please create an issue!\", cls.__name__, unknown\n        )\n\n    missing = [k for k in cls_attrs if k not in kwargs]\n\n    data = {k: v for k, v in kwargs.items() if k in cls_attrs}\n\n    # initialize missing values to avoid passing default=None\n    # for the attrs attribute definitions\n    for m in missing:\n        default = cls_attrs[m].default\n        if isinstance(default, attr.Factory):\n            if not default.takes_self:\n                data[m] = default.factory()\n            else:\n                raise NotImplementedError\n        else:\n            _LOGGER.debug(\"Missing key %s with no default for %s\", m, cls.__name__)\n            data[m] = None\n\n    # initialize and store raw data for debug purposes\n    inst = cls(**data)\n    setattr(inst, \"raw\", kwargs)\n\n    return inst", "response": "Create a new object of the specified class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a POST request to the API.", "response": "async def create_post_request(self, method: str, params: Dict = None):\n        \"\"\"Call the given method over POST.\n\n        :param method: Name of the method\n        :param params: dict of parameters\n        :return: JSON object\n        \"\"\"\n        if params is None:\n            params = {}\n        headers = {\"Content-Type\": \"application/json\"}\n        payload = {\n            \"method\": method,\n            \"params\": [params],\n            \"id\": next(self.idgen),\n            \"version\": \"1.0\",\n        }\n\n        if self.debug > 1:\n            _LOGGER.debug(\"> POST %s with body: %s\", self.guide_endpoint, payload)\n\n        async with aiohttp.ClientSession(headers=headers) as session:\n            res = await session.post(self.guide_endpoint, json=payload, headers=headers)\n            if self.debug > 1:\n                _LOGGER.debug(\"Received %s: %s\" % (res.status_code, res.text))\n            if res.status != 200:\n                raise SongpalException(\n                    \"Got a non-ok (status %s) response for %s\" % (res.status, method),\n                    error=await res.json()[\"error\"],\n                )\n\n            res = await res.json()\n\n        # TODO handle exceptions from POST? This used to raise SongpalException\n        #      on requests.RequestException (Unable to get APIs).\n\n        if \"error\" in res:\n            raise SongpalException(\"Got an error for %s\" % method, error=res[\"error\"])\n\n        if self.debug > 1:\n            _LOGGER.debug(\"Got %s: %s\", method, pf(res))\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets information about supported methods.", "response": "async def get_supported_methods(self):\n        \"\"\"Get information about supported methods.\n\n        Calling this as the first thing before doing anything else is\n        necessary to fill the available services table.\n        \"\"\"\n        response = await self.request_supported_methods()\n\n        if \"result\" in response:\n            services = response[\"result\"][0]\n            _LOGGER.debug(\"Got %s services!\" % len(services))\n\n            for x in services:\n                serv = await Service.from_payload(\n                    x, self.endpoint, self.idgen, self.debug, self.force_protocol\n                )\n                if serv is not None:\n                    self.services[x[\"service\"]] = serv\n                else:\n                    _LOGGER.warning(\"Unable to create service %s\", x[\"service\"])\n\n            for service in self.services.values():\n                if self.debug > 1:\n                    _LOGGER.debug(\"Service %s\", service)\n                for api in service.methods:\n                    # self.logger.debug(\"%s > %s\" % (service, api))\n                    if self.debug > 1:\n                        _LOGGER.debug(\"> %s\" % api)\n            return self.services\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntoggles the device on and off.", "response": "async def set_power(self, value: bool):\n        \"\"\"Toggle the device on and off.\"\"\"\n        if value:\n            status = \"active\"\n        else:\n            status = \"off\"\n        # TODO WoL works when quickboot is not enabled\n        return await self.services[\"system\"][\"setPowerStatus\"](status=status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the current play info.", "response": "async def get_play_info(self) -> PlayInfo:\n        \"\"\"Return  of the device.\"\"\"\n        info = await self.services[\"avContent\"][\"getPlayingContentInfo\"]({})\n        return PlayInfo.make(**info.pop())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_settings(self) -> List[SettingsEntry]:\n        settings = await self.request_settings_tree()\n        return [SettingsEntry.make(**x) for x in settings[\"settings\"]]", "response": "Get a list of available settings."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_misc_settings(self) -> List[Setting]:\n        misc = await self.services[\"system\"][\"getDeviceMiscSettings\"](target=\"\")\n        return [Setting.make(**x) for x in misc]", "response": "Return miscellaneous settings such as name and timezone."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_sleep_timer_settings(self) -> List[Setting]:\n        return [\n            Setting.make(**x)\n            for x in await self.services[\"system\"][\"getSleepTimerSettings\"]({})\n        ]", "response": "Get sleep timer settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn information about connected storage devices.", "response": "async def get_storage_list(self) -> List[Storage]:\n        \"\"\"Return information about connected storage devices.\"\"\"\n        return [\n            Storage.make(**x)\n            for x in await self.services[\"system\"][\"getStorageList\"]({})\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting information about updates.", "response": "async def get_update_info(self, from_network=True) -> SoftwareUpdateInfo:\n        \"\"\"Get information about updates.\"\"\"\n        if from_network:\n            from_network = \"true\"\n        else:\n            from_network = \"false\"\n        # from_network = \"\"\n        info = await self.services[\"system\"][\"getSWUpdateInfo\"](network=from_network)\n        return SoftwareUpdateInfo.make(**info)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn list of available outputs.", "response": "async def get_inputs(self) -> List[Input]:\n        \"\"\"Return list of available outputs.\"\"\"\n        res = await self.services[\"avContent\"][\"getCurrentExternalTerminalsStatus\"]()\n        return [Input.make(services=self.services, **x) for x in res if 'meta:zone:output' not in x['meta']]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_zones(self) -> List[Zone]:\n        res = await self.services[\"avContent\"][\"getCurrentExternalTerminalsStatus\"]()\n        zones = [Zone.make(services=self.services, **x) for x in res if 'meta:zone:output' in x['meta']]\n        if not zones:\n            raise SongpalException(\"Device has no zones\")\n        return zones", "response": "Return list of available zones."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a single setting for a given service.", "response": "async def get_setting(self, service: str, method: str, target: str):\n        \"\"\"Get a single setting for service.\n\n        :param service: Service to query.\n        :param method: Getter method for the setting, read from ApiMapping.\n        :param target: Setting to query.\n        :return: JSON response from the device.\n        \"\"\"\n        return await self.services[service][method](target=target)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def set_custom_eq(self, target: str, value: str) -> None:\n        params = {\"settings\": [{\"target\": target, \"value\": value}]}\n        return await self.services[\"audio\"][\"setCustomEqualizerSettings\"](params)", "response": "Set custom EQ settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of inputs and their supported functions.", "response": "async def get_supported_playback_functions(\n        self, uri=\"\"\n    ) -> List[SupportedFunctions]:\n        \"\"\"Return list of inputs and their supported functions.\"\"\"\n        return [\n            SupportedFunctions.make(**x)\n            for x in await self.services[\"avContent\"][\"getSupportedPlaybackFunction\"](\n                uri=uri\n            )\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget playback settings such as shuffle and repeat.", "response": "async def get_playback_settings(self) -> List[Setting]:\n        \"\"\"Get playback settings such as shuffle and repeat.\"\"\"\n        return [\n            Setting.make(**x)\n            for x in await self.services[\"avContent\"][\"getPlaybackModeSettings\"]({})\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset playback settings such a shuffle and repeat.", "response": "async def set_playback_settings(self, target, value) -> None:\n        \"\"\"Set playback settings such a shuffle and repeat.\"\"\"\n        params = {\"settings\": [{\"target\": target, \"value\": value}]}\n        return await self.services[\"avContent\"][\"setPlaybackModeSettings\"](params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning supported uri schemes.", "response": "async def get_schemes(self) -> List[Scheme]:\n        \"\"\"Return supported uri schemes.\"\"\"\n        return [\n            Scheme.make(**x)\n            for x in await self.services[\"avContent\"][\"getSchemeList\"]()\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def get_source_list(self, scheme: str = \"\") -> List[Source]:\n        res = await self.services[\"avContent\"][\"getSourceList\"](scheme=scheme)\n        return [Source.make(**x) for x in res]", "response": "Return available sources for playback."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns file listing for source.", "response": "async def get_content_count(self, source: str):\n        \"\"\"Return file listing for source.\"\"\"\n        params = {\"uri\": source, \"type\": None, \"target\": \"all\", \"view\": \"flat\"}\n        return ContentInfo.make(\n            **await self.services[\"avContent\"][\"getContentCount\"](params)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_contents(self, uri) -> List[Content]:\n        contents = [\n            Content.make(**x)\n            for x in await self.services[\"avContent\"][\"getContentList\"](uri=uri)\n        ]\n        contentlist = []\n\n        for content in contents:\n            if content.contentKind == \"directory\" and content.index >= 0:\n                # print(\"got directory %s\" % content.uri)\n                res = await self.get_contents(content.uri)\n                contentlist.extend(res)\n            else:\n                contentlist.append(content)\n                # print(\"%s%s\" % (' ' * depth, content))\n        return contentlist", "response": "Request content listing recursively for the given URI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def get_volume_information(self) -> List[Volume]:\n        res = await self.services[\"audio\"][\"getVolumeInformation\"]({})\n        volume_info = [Volume.make(services=self.services, **x) for x in res]\n        if len(volume_info) < 1:\n            logging.warning(\"Unable to get volume information\")\n        elif len(volume_info) > 1:\n            logging.debug(\"The device seems to have more than one volume setting.\")\n        return volume_info", "response": "Get the volume information."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def get_sound_settings(self, target=\"\") -> List[Setting]:\n        res = await self.services[\"audio\"][\"getSoundSettings\"]({\"target\": target})\n        return [Setting.make(**x) for x in res]", "response": "Get the current sound settings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the current sound field settings.", "response": "async def get_soundfield(self) -> List[Setting]:\n        \"\"\"Get the current sound field settings.\"\"\"\n        res = await self.services[\"audio\"][\"getSoundSettings\"]({\"target\": \"soundField\"})\n        return Setting.make(**res[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def set_sound_settings(self, target: str, value: str):\n        params = {\"settings\": [{\"target\": target, \"value\": value}]}\n        return await self.services[\"audio\"][\"setSoundSettings\"](params)", "response": "Change a sound setting."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def get_speaker_settings(self) -> List[Setting]:\n        speaker_settings = await self.services[\"audio\"][\"getSpeakerSettings\"]({})\n        return [Setting.make(**x) for x in speaker_settings]", "response": "Return the speaker settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlistens for notifications from the device forever.", "response": "async def listen_notifications(self, fallback_callback=None):\n        \"\"\"Listen for notifications from the device forever.\n\n        Use :func:on_notification: to register what notifications to listen to.\n        \"\"\"\n        tasks = []\n\n        async def handle_notification(notification):\n            if type(notification) not in self.callbacks:\n                if not fallback_callback:\n                    _LOGGER.debug(\"No callbacks for %s\", notification)\n                    # _LOGGER.debug(\"Existing callbacks for: %s\" % self.callbacks)\n                else:\n                    await fallback_callback(notification)\n                return\n            for cb in self.callbacks[type(notification)]:\n                await cb(notification)\n\n        for serv in self.services.values():\n            tasks.append(\n                asyncio.ensure_future(\n                    serv.listen_all_notifications(handle_notification)\n                )\n            )\n\n        try:\n            print(await asyncio.gather(*tasks))\n        except Exception as ex:\n            # TODO: do a slightly restricted exception handling?\n            # Notify about disconnect\n            await handle_notification(ConnectChange(connected=False, exception=ex))\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def stop_listen_notifications(self):\n        _LOGGER.debug(\"Stopping listening for notifications..\")\n        for serv in self.services.values():\n            await serv.stop_listen_notifications()\n\n        return True", "response": "Stop listening for notifications."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget available notifications which can then be subscribed to.", "response": "async def get_notifications(self) -> List[Notification]:\n        \"\"\"Get available notifications, which can then be subscribed to.\n\n        Call :func:activate: to enable notifications, and :func:listen_notifications:\n        to loop forever for notifications.\n\n        :return: List of Notification objects\n        \"\"\"\n        notifications = []\n        for serv in self.services:\n            for notification in self.services[serv].notifications:\n                notifications.append(notification)\n        return notifications"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall an arbitrary method with given parameters.", "response": "async def raw_command(self, service: str, method: str, params: Any):\n        \"\"\"Call an arbitrary method with given parameters.\n\n        This is useful for debugging and trying out commands before\n        implementing them properly.\n        :param service: Service, use list(self.services) to get a list of availables.\n        :param method: Method to call.\n        :param params: Parameters as a python object (e.g., dict, list)\n        :return: Raw JSON response from the device.\n        \"\"\"\n        _LOGGER.info(\"Calling %s.%s(%s)\", service, method, params)\n        return await self.services[service][method](params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconnecting to the group service.", "response": "async def connect(self):\n        requester = AiohttpRequester()\n        factory = UpnpFactory(requester)\n        device = await factory.async_create_device(self.url)\n\n        self.service = device.service('urn:schemas-sony-com:service:Group:1')\n        if not self.service:\n            _LOGGER.error(\"Unable to find group service!\")\n            return False\n\n        for act in self.service.actions.values():\n            _LOGGER.debug(\"Action: %s (%s)\", act, [arg.name for arg in act.in_arguments()])\n\n        return True\n\n        \"\"\"\n        Available actions\n\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_GetDeviceInfo)> ([])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_GetState)> ([])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_GetStateM)> ([])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_SetGroupName)> (['GroupName'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_ChangeGroupVolume)> (['GroupVolume'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_GetAllGroupMemory)> ([])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_DeleteGroupMemory)> (['MemoryID'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_UpdateGroupMemory)> (['MemoryID', 'GroupMode', 'GroupName', 'SlaveList', 'CodecType', 'CodecBitrate'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_Start)> (['GroupMode', 'GroupName', 'SlaveList', 'CodecType', 'CodecBitrate'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_Entry)> (['MasterSessionID', 'SlaveList'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_EntryM)> (['MasterSessionID', 'SlaveList'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_Leave)> (['MasterSessionID', 'SlaveList'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_LeaveM)> (['MasterSessionID', 'SlaveList'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_Abort)> (['MasterSessionID'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_SetGroupMute)> (['GroupMute'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_SetCodec)> (['CodecType', 'CodecBitrate'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_GetCodec)> ([])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_Invite)> (['GroupMode', 'GroupName', 'MasterUUID', 'MasterSessionID'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_Exit)> (['SlaveSessionID'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_Play)> (['MasterSessionID'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_Stop)> (['MasterSessionID'])\n        INFO:songpal.upnpctl:Action: <UpnpService.Action(X_Delegate)> (['GroupMode', 'SlaveList', 'DelegateURI', 'DelegateURIMetaData'])\n\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake an action call with given kwargs.", "response": "async def call(self, action, **kwargs):\n        \"\"\"Make an action call with given kwargs.\"\"\"\n        act = self.service.action(action)\n        _LOGGER.info(\"Calling %s with %s\", action, kwargs)\n        res = await act.async_call(**kwargs)\n\n        _LOGGER.info(\"  Result: %s\" % res)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def state(self) -> GroupState:\n        act = self.service.action(\"X_GetState\")\n        res = await act.async_call()\n        return GroupState.make(**res)", "response": "Return the current group state"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def abort(self):\n        state = await self.state()\n        res = await self.call(\"X_Abort\", MasterSessionID=state.MasterSessionID)\n        return res", "response": "Abort current group session."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def fetch_signatures(endpoint, protocol, idgen):\n        async with aiohttp.ClientSession() as session:\n            req = {\n                \"method\": \"getMethodTypes\",\n                \"params\": [''],\n                \"version\": \"1.0\",\n                \"id\": next(idgen),\n            }\n\n            if protocol == ProtocolType.WebSocket:\n                async with session.ws_connect(endpoint, timeout=2) as s:\n                    await s.send_json(req)\n                    res = await s.receive_json()\n                    return res\n            else:\n                res = await session.post(endpoint, json=req)\n                json = await res.json()\n\n                return json", "response": "Request available methods for the service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def from_payload(cls, payload, endpoint, idgen, debug, force_protocol=None):\n        service_name = payload[\"service\"]\n\n        if \"protocols\" not in payload:\n            raise SongpalException(\n                \"Unable to find protocols from payload: %s\" % payload\n            )\n\n        protocols = payload[\"protocols\"]\n        _LOGGER.debug(\"Available protocols for %s: %s\", service_name, protocols)\n        if force_protocol and force_protocol.value in protocols:\n            protocol = force_protocol\n        elif \"websocket:jsonizer\" in protocols:\n            protocol = ProtocolType.WebSocket\n        elif \"xhrpost:jsonizer\" in protocols:\n            protocol = ProtocolType.XHRPost\n        else:\n            raise SongpalException(\n                \"No known protocols for %s, got: %s\" % (service_name, protocols)\n            )\n        _LOGGER.debug(\"Using protocol: %s\" % protocol)\n\n        service_endpoint = \"%s/%s\" % (endpoint, service_name)\n\n        # creation here we want to pass the created service class to methods.\n        service = cls(service_name, service_endpoint, protocol, idgen, debug)\n\n        sigs = await cls.fetch_signatures(\n            service_endpoint, protocol, idgen\n        )\n\n        if debug > 1:\n            _LOGGER.debug(\"Signatures: %s\", sigs)\n        if \"error\" in sigs:\n            _LOGGER.error(\"Got error when fetching sigs: %s\", sigs[\"error\"])\n            return None\n\n        methods = {}\n\n        for sig in sigs[\"results\"]:\n            name = sig[0]\n            parsed_sig = MethodSignature.from_payload(*sig)\n            if name in methods:\n                _LOGGER.debug(\"Got duplicate signature for %s, existing was %s. Keeping the existing one\",\n                              parsed_sig, methods[name])\n            else:\n                methods[name] = Method(service, parsed_sig, debug)\n\n        service.methods = methods\n\n        if \"notifications\" in payload and \"switchNotifications\" in methods:\n            notifications = [\n                Notification(\n                    service_endpoint, methods[\"switchNotifications\"], notification\n                )\n                for notification in payload[\"notifications\"]\n            ]\n            service.notifications = notifications\n            _LOGGER.debug(\"Got notifications: %s\" % notifications)\n\n        return service", "response": "Create a Service object from a JSON - RPC payload."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling a method (internal). This is an internal implementation, which formats the parameters if necessary and chooses the preferred transport protocol. The return values are JSON objects. Use :func:__call__: provides external API leveraging this.", "response": "async def call_method(self, method, *args, **kwargs):\n        \"\"\"Call a method (internal).\n\n        This is an internal implementation, which formats the parameters if necessary\n         and chooses the preferred transport protocol.\n         The return values are JSON objects.\n        Use :func:__call__: provides external API leveraging this.\n        \"\"\"\n        _LOGGER.debug(\n            \"%s got called with args (%s) kwargs (%s)\" % (method.name, args, kwargs)\n        )\n\n        # Used for allowing keeping reading from the socket\n        _consumer = None\n        if \"_consumer\" in kwargs:\n            if self.active_protocol != ProtocolType.WebSocket:\n                raise SongpalException(\n                    \"Notifications are only supported over websockets\"\n                )\n            _consumer = kwargs[\"_consumer\"]\n            del kwargs[\"_consumer\"]\n\n        if len(kwargs) == 0 and len(args) == 0:\n            params = []  # params need to be empty array, if none is given\n        elif len(kwargs) > 0:\n            params = [kwargs]\n        elif len(args) == 1 and args[0] is not None:\n            params = [args[0]]\n        else:\n            params = []\n\n        # TODO check for type correctness\n        # TODO note parameters are not always necessary, see getPlaybackModeSettings\n        # which has 'target' and 'uri' but works just fine without anything (wildcard)\n        # if len(params) != len(self._inputs):\n        #    _LOGGER.error(\"args: %s signature: %s\" % (args,\n        #                                              self.signature.input))\n        #    raise Exception(\"Invalid number of inputs, wanted %s got %s / %s\" % (\n        #        len(self.signature.input), len(args), len(kwargs)))\n\n        async with aiohttp.ClientSession() as session:\n            req = {\n                \"method\": method.name,\n                \"params\": params,\n                \"version\": method.version,\n                \"id\": next(self.idgen),\n            }\n            if self.debug > 1:\n                _LOGGER.debug(\"sending request: %s (proto: %s)\", req, self.active_protocol)\n            if self.active_protocol == ProtocolType.WebSocket:\n                async with session.ws_connect(\n                    self.endpoint, timeout=self.timeout, heartbeat=self.timeout * 5\n                ) as s:\n                    await s.send_json(req)\n                    # If we have a consumer, we are going to loop forever while\n                    # emiting the incoming payloads to e.g. notification handler.\n                    if _consumer is not None:\n                        self.listening = True\n                        while self.listening:\n                            res_raw = await s.receive_json()\n                            res = self.wrap_notification(res_raw)\n                            _LOGGER.debug(\"Got notification: %s\", res)\n                            if self.debug > 1:\n                                _LOGGER.debug(\"Got notification raw: %s\", res_raw)\n\n                            await _consumer(res)\n\n                    res = await s.receive_json()\n                    return res\n            else:\n                res = await session.post(self.endpoint, json=req)\n                return await res.json()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a JSON notification to a notification class.", "response": "def wrap_notification(self, data):\n        \"\"\"Convert notification JSON to a notification class.\"\"\"\n        if \"method\" in data:\n            method = data[\"method\"]\n            params = data[\"params\"]\n            change = params[0]\n            if method == \"notifyPowerStatus\":\n                return PowerChange.make(**change)\n            elif method == \"notifyVolumeInformation\":\n                return VolumeChange.make(**change)\n            elif method == \"notifyPlayingContentInfo\":\n                return ContentChange.make(**change)\n            elif method == \"notifySettingsUpdate\":\n                return SettingChange.make(**change)\n            elif method == \"notifySWUpdateInfo\":\n                return SoftwareUpdateChange.make(**change)\n            else:\n                _LOGGER.warning(\"Got unknown notification type: %s\", method)\n        elif \"result\" in data:\n            result = data[\"result\"][0]\n            if \"enabled\" in result and \"enabled\" in result:\n                return NotificationChange(**result)\n        else:\n            _LOGGER.warning(\"Unknown notification, returning raw: %s\", data)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nenable all exposed notifications.", "response": "async def listen_all_notifications(self, callback):\n        \"\"\"Enable all exposed notifications.\n\n        :param callback: Callback to call when a notification is received.\n        \"\"\"\n        everything = [noti.asdict() for noti in self.notifications]\n        if len(everything) > 0:\n            await self._methods[\"switchNotifications\"](\n                {\"enabled\": everything}, _consumer=callback\n            )\n        else:\n            _LOGGER.debug(\"No notifications available for %s\", self.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asdict(self):\n        return {\n            \"methods\": {m.name: m.asdict() for m in self.methods},\n            \"protocols\": self.protocols,\n            \"notifications\": {n.name: n.asdict() for n in self.notifications},\n        }", "response": "Return dict presentation of this service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading CSV simulate write plot plot Taxonomy", "response": "def horizrad(infn: Path, outfn: Path, c1: dict) -> xarray.Dataset:\n    \"\"\"\n    read CSV, simulate, write, plot\n    \"\"\"\n    if infn is not None:\n        infn = Path(infn).expanduser()\n\n        if infn.suffix == '.h5':\n            TR = xarray.open_dataset(infn)\n            return TR\n\n    c1.update({'model': 0,  # 0: user meterological data\n               'itype': 1,  # 1: horizontal path\n               'iemsct': 1,  # 1: radiance model\n               'im': 1,    # 1: for horizontal path (see Lowtran manual p.42)\n               'ird1': 1,  # 1: use card 2C2)\n               })\n# %% read csv file\n    if not infn:  # demo mode\n        c1['p'] = [949., 959.]\n        c1['t'] = [283.8, 285.]\n        c1['wmol'] = [[93.96, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n                      [93.96, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]\n        c1['time'] = [parse('2017-04-05T12'),\n                      parse('2017-04-05T18')]\n    else:  # read csv, normal case\n        PTdata = read_csv(infn)\n        c1['p'] = PTdata['p']\n        c1['t'] = PTdata['Ta']\n        c1['wmol'] = np.zeros((PTdata.shape[0], 12))\n        c1['wmol'][:, 0] = PTdata['RH']\n        c1['time'] = [parse(t) for t in PTdata['time']]\n# %% TR is 3-D array with axes: time, wavelength, and [transmission,radiance]\n    TR = loopuserdef(c1)\n\n    return TR"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting wavelength in nm to cm^ - 1", "response": "def nm2lt7(short_nm: float, long_nm: float, step_cminv: float = 20) -> Tuple[float, float, float]:\n    \"\"\"converts wavelength in nm to cm^-1\n    minimum meaningful step is 20, but 5 is minimum before crashing lowtran\n\n    short: shortest wavelength e.g. 200 nm\n    long: longest wavelength e.g. 30000 nm\n    step: step size in cm^-1 e.g. 20\n\n    output in cm^-1\n    \"\"\"\n    short = 1e7 / short_nm\n    long = 1e7 / long_nm\n\n    N = int(np.ceil((short-long) / step_cminv)) + 1  # yes, ceil\n\n    return short, long, N"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loopuserdef(c1: Dict[str, Any]) -> xarray.DataArray:\n\n    wmol = np.atleast_2d(c1['wmol'])\n    P = np.atleast_1d(c1['p'])\n    T = np.atleast_1d(c1['t'])\n    time = np.atleast_1d(c1['time'])\n\n    assert wmol.shape[0] == len(P) == len(T) == len(time), 'WMOL, P, T,time must be vectors of equal length'\n\n    N = len(P)\n# %% 3-D array indexed by metadata\n    TR = xarray.Dataset(coords={'time': time, 'wavelength_nm': None, 'angle_deg': None})\n\n    for i in range(N):\n        c = c1.copy()\n        c['wmol'] = wmol[i, :]\n        c['p'] = P[i]\n        c['t'] = T[i]\n        c['time'] = time[i]\n\n        TR = TR.merge(golowtran(c))\n\n    #   TR = TR.sort_index(axis=0) # put times in order, sometimes CSV is not monotonic in time.\n\n    return TR", "response": "Loop user - defined parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef golowtran(c1: Dict[str, Any]) -> xarray.Dataset:\n# %% default parameters\n    c1.setdefault('time', None)\n\n    defp = ('h1', 'h2', 'angle', 'im', 'iseasn', 'ird1', 'range_km', 'zmdl', 'p', 't')\n    for p in defp:\n        c1.setdefault(p, 0)\n\n    c1.setdefault('wmol', [0]*12)\n# %% input check\n    assert len(c1['wmol']) == 12, 'see Lowtran user manual for 12 values of WMOL'\n    assert np.isfinite(c1['h1']), 'per Lowtran user manual Table 14, H1 must always be defined'\n# %% setup wavelength\n    c1.setdefault('wlstep', 20)\n    if c1['wlstep'] < 5:\n        logging.critical('minimum resolution 5 cm^-1, specified resolution 20 cm^-1')\n\n    wlshort, wllong, nwl = nm2lt7(c1['wlshort'], c1['wllong'], c1['wlstep'])\n\n    if not 0 < wlshort and wllong <= 50000:\n        logging.critical('specified model range 0 <= wavelength [cm^-1] <= 50000')\n# %% invoke lowtran\n    \"\"\"\n    Note we invoke case \"3a\" from table 14, only observer altitude and apparent\n    angle are specified\n    \"\"\"\n    Tx, V, Alam, trace, unif, suma, irrad, sumvv = lowtran7.lwtrn7(\n        True, nwl, wllong, wlshort, c1['wlstep'],\n        c1['model'], c1['itype'], c1['iemsct'], c1['im'],\n        c1['iseasn'], c1['ird1'],\n        c1['zmdl'], c1['p'], c1['t'], c1['wmol'],\n        c1['h1'], c1['h2'], c1['angle'], c1['range_km'])\n\n    dims = ('time', 'wavelength_nm', 'angle_deg')\n    TR = xarray.Dataset({'transmission': (dims, Tx[:, 9][None, :, None]),\n                         'radiance': (dims, sumvv[None, :, None]),\n                         'irradiance': (dims, irrad[:, 0][None, :, None]),\n                         'pathscatter': (dims, irrad[:, 2][None, :, None])},\n                        coords={'time': [c1['time']],\n                                'wavelength_nm': Alam*1e3,\n                                'angle_deg': [c1['angle']]})\n\n    return TR", "response": "directly run Fortran code"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes one plot per time for now.", "response": "def plotradtime(TR: xarray.Dataset, c1: Dict[str, Any], log: bool = False):\n    \"\"\"\n    make one plot per time for now.\n\n    TR: 3-D array: time, wavelength, [transmittance, radiance]\n\n    radiance is currently single-scatter solar\n    \"\"\"\n\n    for t in TR.time:  # for each time\n        plotirrad(TR.sel(time=t), c1, log)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary describing the method.", "response": "def asdict(self) -> Dict[str, Union[Dict, Union[str, Dict]]]:\n        \"\"\"Return a dictionary describing the method.\n\n        This can be used to dump the information into a JSON file.\n        \"\"\"\n        return {\n            \"service\": self.service.name,\n            **self.signature.serialize(),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn user - friendly error message.", "response": "def error(self):\n        \"\"\"Return user-friendly error message.\"\"\"\n        try:\n            errcode = DeviceErrorCode(self.error_code)\n            return \"%s (%s): %s\" % (errcode.name, errcode.value, self.error_message)\n        except:\n            return \"Error %s: %s\" % (self.error_code, self.error_message)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a coroutine and handle possible errors for the click cli. Source https://github.com/pallets/click/issues/85#issuecomment-43378930", "response": "def coro(f):\n    \"\"\"Run a coroutine and handle possible errors for the click cli.\n\n    Source https://github.com/pallets/click/issues/85#issuecomment-43378930\n    \"\"\"\n    f = asyncio.coroutine(f)\n\n    def wrapper(*args, **kwargs):\n        loop = asyncio.get_event_loop()\n        try:\n            return loop.run_until_complete(f(*args, **kwargs))\n        except KeyboardInterrupt:\n            click.echo(\"Got CTRL+C, quitting..\")\n            dev = args[0]\n            loop.run_until_complete(dev.stop_listen_notifications())\n        except SongpalException as ex:\n            err(\"Error: %s\" % ex)\n            if len(args) > 0 and hasattr(args[0], \"debug\"):\n                if args[0].debug > 0:\n                    raise ex\n\n    return update_wrapper(wrapper, f)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint all available settings.", "response": "async def traverse_settings(dev, module, settings, depth=0):\n    \"\"\"Print all available settings.\"\"\"\n    for setting in settings:\n        if setting.is_directory:\n            print(\"%s%s (%s)\" % (depth * \" \", setting.title, module))\n            return await traverse_settings(dev, module, setting.settings, depth + 2)\n        else:\n            try:\n                print_settings([await setting.get_value(dev)], depth=depth)\n            except SongpalException as ex:\n                err(\"Unable to read setting %s: %s\" % (setting, ex))\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_settings(settings, depth=0):\n    # handle the case where a single setting is passed\n    if isinstance(settings, Setting):\n        settings = [settings]\n    for setting in settings:\n        cur = setting.currentValue\n        print(\n            \"%s* %s (%s, value: %s, type: %s)\"\n            % (\n                \" \" * depth,\n                setting.title,\n                setting.target,\n                click.style(cur, bold=True),\n                setting.type,\n            )\n        )\n        for opt in setting.candidate:\n            if not opt.isAvailable:\n                logging.debug(\"Unavailable setting %s\", opt)\n                continue\n            click.echo(\n                click.style(\n                    \"%s  - %s (%s)\" % (\" \" * depth, opt.title, opt.value),\n                    bold=opt.value == cur,\n                )\n            )", "response": "Print all available settings of the device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nturn on and off control power settings.", "response": "async def power(dev: Device, cmd, target, value):\n    \"\"\"Turn on and off, control power settings.\n\n    Accepts commands 'on', 'off', and 'settings'.\n    \"\"\"\n    async def try_turn(cmd):\n        state = True if cmd == \"on\" else False\n        try:\n            return await dev.set_power(state)\n        except SongpalException as ex:\n            if ex.code == 3:\n                err(\"The device is already %s.\" % cmd)\n            else:\n                raise ex\n\n    if cmd == \"on\" or cmd == \"off\":\n        click.echo(await try_turn(cmd))\n    elif cmd == \"settings\":\n        settings = await dev.get_power_settings()\n        print_settings(settings)\n    elif cmd == \"set\" and target and value:\n        click.echo(await dev.set_power_settings(target, value))\n    else:\n        power = await dev.get_power()\n        click.echo(click.style(str(power), bold=power))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget and change outputs.", "response": "async def input(dev: Device, input, output):\n    \"\"\"Get and change outputs.\"\"\"\n    inputs = await dev.get_inputs()\n    if input:\n        click.echo(\"Activating %s\" % input)\n        try:\n            input = next((x for x in inputs if x.title == input))\n        except StopIteration:\n            click.echo(\"Unable to find input %s\" % input)\n            return\n        zone = None\n        if output:\n            zone = await dev.get_zone(output)\n            if zone.uri not in input.outputs:\n                click.echo(\"Input %s not valid for zone %s\" % (input.title, output))\n                return\n\n        await input.activate(zone)\n    else:\n        click.echo(\"Inputs:\")\n        for input in inputs:\n            act = False\n            if input.active:\n                act = True\n            click.echo(\"  * \" + click.style(str(input), bold=act))\n            for out in input.outputs:\n                click.echo(\"    - %s\" % out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def zone(dev: Device, zone, activate):\n    if zone:\n        zone = await dev.get_zone(zone)\n        click.echo(\"%s %s\" % (\"Activating\" if activate else \"Deactivating\", zone)) \n        await zone.activate(activate)\n    else:\n        click.echo(\"Zones:\")\n        for zone in await dev.get_zones():\n            act = False\n            if zone.active:\n                act = True\n            click.echo(\"  * \" + click.style(str(zone), bold=act))", "response": "Get and change outputs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def source(dev: Device, scheme):\n    if scheme is None:\n        schemes = await dev.get_schemes()\n        schemes = [scheme.scheme for scheme in schemes]  # noqa: T484\n    else:\n        schemes = [scheme]\n\n    for schema in schemes:\n        try:\n            sources = await dev.get_source_list(schema)\n        except SongpalException as ex:\n            click.echo(\"Unable to get sources for %s\" % schema)\n            continue\n        for src in sources:\n            click.echo(src)\n            if src.isBrowsable:\n                try:\n                    count = await dev.get_content_count(src.source)\n                    if count.count > 0:\n                        click.echo(\"  %s\" % count)\n                        for content in await dev.get_contents(src.source):\n                            click.echo(\"   %s\\n\\t%s\" % (content.title, content.uri))\n                    else:\n                        click.echo(\"  No content to list.\")\n                except SongpalException as ex:\n                    click.echo(\"  %s\" % ex)", "response": "List available sources for a given scheme."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def volume(dev: Device, volume, output):\n    vol = None\n    vol_controls = await dev.get_volume_information()\n    if output is not None:\n        click.echo(\"Using output: %s\" % output)\n        output_uri = (await dev.get_zone(output)).uri\n        for v in vol_controls:\n            if v.output == output_uri:\n                vol = v\n                break\n    else:\n        vol = vol_controls[0]\n\n    if vol is None:\n        err(\"Unable to find volume controller: %s\" % output)\n        return\n\n    if volume and volume == \"mute\":\n        click.echo(\"Muting\")\n        await vol.set_mute(True)\n    elif volume and volume == \"unmute\":\n        click.echo(\"Unmuting\")\n        await vol.set_mute(False)\n    elif volume:\n        click.echo(\"Setting volume to %s\" % volume)\n        await vol.set_volume(volume)\n\n    if output is not None:\n        click.echo(vol)\n    else:\n        [click.echo(x) for x in vol_controls]", "response": "Get and set the volume settings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def schemes(dev: Device):\n    schemes = await dev.get_schemes()\n    for scheme in schemes:\n        click.echo(scheme)", "response": "Print supported uri schemes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def check_update(dev: Device, internet: bool, update: bool):\n    if internet:\n        print(\"Checking updates from network\")\n    else:\n        print(\"Not checking updates from internet\")\n    update_info = await dev.get_update_info(from_network=internet)\n    if not update_info.isUpdatable:\n        click.echo(\"No updates available.\")\n        return\n    if not update:\n        click.echo(\"Update available: %s\" % update_info)\n        click.echo(\"Use --update to activate update!\")\n    else:\n        click.echo(\"Activating update, please be seated.\")\n        res = await dev.activate_system_update()\n        click.echo(\"Update result: %s\" % res)", "response": "Print out update information."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def bluetooth(dev: Device, target, value):\n    if target and value:\n        await dev.set_bluetooth_settings(target, value)\n\n    print_settings(await dev.get_bluetooth_settings())", "response": "Get or set bluetooth settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints out system information.", "response": "async def sysinfo(dev: Device):\n    \"\"\"Print out system information (version, MAC addrs).\"\"\"\n    click.echo(await dev.get_system_info())\n    click.echo(await dev.get_interface_information())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints out all possible settings.", "response": "async def settings(dev: Device):\n    \"\"\"Print out all possible settings.\"\"\"\n    settings_tree = await dev.get_settings()\n\n    for module in settings_tree:\n        await traverse_settings(dev, module.usage, module.settings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets or set sound settings.", "response": "async def sound(dev: Device, target, value):\n    \"\"\"Get or set sound settings.\"\"\"\n    if target and value:\n        click.echo(\"Setting %s to %s\" % (target, value))\n        click.echo(await dev.set_sound_settings(target, value))\n\n    print_settings(await dev.get_sound_settings())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def soundfield(dev: Device, soundfield: str):\n    if soundfield is not None:\n        await dev.set_sound_settings(\"soundField\", soundfield)\n    soundfields = await dev.get_sound_settings(\"soundField\")\n    print_settings(soundfields)", "response": "Get or set sound field."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def playback(dev: Device, cmd, target, value):\n    if target and value:\n        dev.set_playback_settings(target, value)\n    if cmd == \"support\":\n        click.echo(\"Supported playback functions:\")\n        supported = await dev.get_supported_playback_functions(\"storage:usb1\")\n        for i in supported:\n            print(i)\n    elif cmd == \"settings\":\n        print_settings(await dev.get_playback_settings())\n        # click.echo(\"Playback functions:\")\n        # funcs = await dev.get_available_playback_functions()\n        # print(funcs)\n    else:\n        click.echo(\"Currently playing: %s\" % await dev.get_play_info())", "response": "Get and set playback settings e. g. repeat and shuffle.."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting and set external speaker settings.", "response": "async def speaker(dev: Device, target, value):\n    \"\"\"Get and set external speaker settings.\"\"\"\n    if target and value:\n        click.echo(\"Setting %s to %s\" % (target, value))\n        await dev.set_speaker_settings(target, value)\n\n    print_settings(await dev.get_speaker_settings())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def notifications(dev: Device, notification: str, listen_all: bool):\n    notifications = await dev.get_notifications()\n\n    async def handle_notification(x):\n        click.echo(\"got notification: %s\" % x)\n\n    if listen_all:\n        if notification is not None:\n            await dev.services[notification].listen_all_notifications(\n                handle_notification\n            )\n        else:\n            click.echo(\"Listening to all possible notifications\")\n            await dev.listen_notifications(fallback_callback=handle_notification)\n\n    elif notification:\n        click.echo(\"Subscribing to notification %s\" % notification)\n        for notif in notifications:\n            if notif.name == notification:\n                await notif.activate(handle_notification)\n\n        click.echo(\"Unable to find notification %s\" % notification)\n\n    else:\n        click.echo(click.style(\"Available notifications\", bold=True))\n        for notification in notifications:\n            click.echo(\"* %s\" % notification)", "response": "List available notifications and listen to them."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_all(dev: Device):\n    for name, service in dev.services.items():\n        click.echo(click.style(\"\\nService %s\" % name, bold=True))\n        for method in service.methods:\n            click.echo(\"  %s\" % method.name)", "response": "List all available API calls."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns a raw command.", "response": "async def command(dev, service, method, parameters):\n    \"\"\"Run a raw command.\"\"\"\n    params = None\n    if parameters is not None:\n        params = ast.literal_eval(parameters)\n    click.echo(\"Calling %s.%s with params %s\" % (service, method, params))\n    res = await dev.raw_command(service, method, params)\n    click.echo(res)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping developer information. Pass `file` to write the results directly into a file.", "response": "async def dump_devinfo(dev: Device, file):\n    \"\"\"Dump developer information.\n\n    Pass `file` to write the results directly into a file.\n    \"\"\"\n    import attr\n\n    methods = await dev.get_supported_methods()\n    res = {\n        \"supported_methods\": {k: v.asdict() for k, v in methods.items()},\n        \"settings\": [attr.asdict(x) for x in await dev.get_settings()],\n        \"sysinfo\": attr.asdict(await dev.get_system_info()),\n        \"interface_info\": attr.asdict(await dev.get_interface_information()),\n    }\n    if file:\n        click.echo(\"Saving to file: %s\" % file.name)\n        json.dump(res, file, sort_keys=True, indent=4)\n    else:\n        click.echo(json.dumps(res, sort_keys=True, indent=4))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def create(gc: GroupControl, name, slaves):\n    click.echo(\"Creating group %s with slaves: %s\" % (name, slaves))\n    click.echo(await gc.create(name, slaves))", "response": "Create a new group"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding speakers to group.", "response": "async def add(gc: GroupControl, slaves):\n    \"\"\"Add speakers to group.\"\"\"\n    click.echo(\"Adding to existing group: %s\" % slaves)\n    click.echo(await gc.add(slaves))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving speakers from group.", "response": "async def remove(gc: GroupControl, slaves):\n    \"\"\"Remove speakers from group.\"\"\"\n    click.echo(\"Removing from existing group: %s\" % slaves)\n    click.echo(await gc.remove(slaves))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadjusts volume - 100", "response": "async def volume(gc: GroupControl, volume):\n    \"\"\"Adjust volume [-100, 100]\"\"\"\n    click.echo(\"Setting volume to %s\" % volume)\n    click.echo(await gc.set_group_volume(volume))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, method, **kwargs):\n        payload = {\n            'id': 1,\n            'jsonrpc': '2.0',\n            'method': method,\n            'params': kwargs\n        }\n\n        credentials = base64.b64encode('{}:{}'.format(self._username, self._password).encode())\n        auth_header_prefix = 'Basic ' if self._auth_header == DEFAULT_AUTH_HEADER else ''\n        headers = {\n            self._auth_header: auth_header_prefix + credentials.decode(),\n            'Content-Type': 'application/json',\n        }\n\n        return self._do_request(headers, payload)", "response": "Execute a remote API call."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tc(g):\n        ret = {}\n        for scc in tarjan(g):\n                ws = set()\n                ews = set()\n                for v in scc:\n                        ws.update(g[v])\n                for w in ws:\n                        assert w in ret or w in scc\n                        ews.add(w)\n                        ews.update(ret.get(w,()))\n                if len(scc) > 1:\n                        ews.update(scc)\n                ews = tuple(ews)\n                for v in scc:\n                        ret[v] = ews\n        return ret", "response": "Given a graph g returns the transitive closure of g."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noutput a list of all feed names", "response": "def list_feeds(self):\n        \"\"\"\n        Output a list of all feed names\n        \"\"\"\n        feeds = configparser.ConfigParser()\n        feeds.read(self.data_filename)\n        return feeds.sections()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef retrieve_data_directory(self):\n        args = self.args\n        try:\n            if args['datadirectory']:\n                aux.ensure_dir(args['datadirectory'])\n                return args['datadirectory']\n        except KeyError:\n            pass\n        config = configparser.ConfigParser()\n        config.read([config_filename_global, self.config_filename_user])\n        section = config.default_section\n        data_path = config.get(section, 'Data directory',\n                               fallback='~/.local/share/greg')\n        data_path_expanded = os.path.expanduser(data_path)\n        aux.ensure_dir(data_path_expanded)\n        return os.path.expanduser(data_path_expanded)", "response": "Retrieve the data directory of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrieve_config(self, value, default):\n        args = self.args\n        name = self.name\n        try:\n            if args[value]:\n                return args[value]\n        except KeyError:\n            pass\n        section = name if self.config.has_section(\n            name) else self.config.default_section\n        answer = self.config.get(section, value, fallback=default)\n        return answer", "response": "Retrieves a value from the config files\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the download path", "response": "def retrieve_download_path(self):\n        \"\"\"\n        Retrieves the download path (looks first into config_filename_global\n        then into the [DEFAULT], then the [feed], section of\n        config_filename_user. The latest takes preeminence)\n        \"\"\"\n        section = self.name if self.config.has_section(\n            self.name) else self.config.default_section\n        download_path = self.config.get(\n            section, 'Download directory', fallback='~/Podcasts')\n        subdirectory = self.config.get(\n            section, 'Create subdirectories', fallback='no')\n        return [os.path.expanduser(download_path), subdirectory]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck whether the feed should be tagged", "response": "def will_tag(self):\n        \"\"\"\n        Check whether the feed should be tagged\n        \"\"\"\n        wanttags = self.retrieve_config('Tag', 'no')\n        if wanttags == 'yes':\n            if aux.staggerexists:\n                willtag = True\n            else:\n                willtag = False\n                print((\"You want me to tag {0}, but you have not installed \"\n                       \"the Stagger module. I cannot honour your request.\").\n                      format(self.name), file=sys.stderr, flush=True)\n        else:\n            willtag = False\n        return willtag"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the current date and stop of the entry.", "response": "def how_many(self):\n        \"\"\"\n        Ascertain where to start downloading, and how many entries.\n        \"\"\"\n        if self.linkdates != []:\n            # What follows is a quick sanity check: if the entry date is in the\n            # future, this is probably a mistake, and we just count the entry\n            # date as right now.\n            if max(self.linkdates) <= list(time.localtime()):\n                currentdate = max(self.linkdates)\n            else:\n                currentdate = list(time.localtime())\n                print((\"This entry has its date set in the future. \"\n                       \"I will use your current local time as its date \"\n                       \"instead.\"),\n                      file=sys.stderr, flush=True)\n            stop = sys.maxsize\n        else:\n            currentdate = [1, 1, 1, 0, 0]\n            firstsync = self.retrieve_config('firstsync', '1')\n            if firstsync == 'all':\n                stop = sys.maxsize\n            else:\n                stop = int(firstsync)\n        return currentdate, stop"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the linkdate attribute of the entry based on the feed. sync_by_date flag.", "response": "def fix_linkdate(self, entry):\n        \"\"\"\n        Give a date for the entry, depending on feed.sync_by_date\n        Save it as feed.linkdate\n        \"\"\"\n        if self.sync_by_date:\n            try:\n                entry.linkdate = list(entry.published_parsed)\n                self.linkdate = list(entry.published_parsed)\n            except (AttributeError, TypeError):\n                try:\n                    entry.linkdate = list(entry.updated_parsed)\n                    self.linkdate = list(entry.updated_parsed)\n                except (AttributeError, TypeError):\n                    print((\"This entry doesn't seem to have a parseable date. \"\n                           \"I will use your local time instead.\"),\n                          file=sys.stderr, flush=True)\n                    entry.linkdate = list(time.localtime())\n                    self.linkdate = list(time.localtime())\n        else:\n            entry.linkdate = list(time.localtime())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrieve_mime(self):\n        mime = self.retrieve_config('mime', 'audio')\n        mimedict = {\"number\": mime}\n        # the input that parse_for_download expects\n        return aux.parse_for_download(mimedict)", "response": "Retrieve the mime - type of the audio file and parse it for download"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_entry(self, entry):\n        downloadlinks = {}\n        downloaded = False\n        ignoreenclosures = self.retrieve_config('ignoreenclosures', 'no')\n        notype = self.retrieve_config('notype', 'no')\n        if ignoreenclosures == 'no':\n            for enclosure in entry.enclosures:\n                if notype == 'yes':\n                    downloadlinks[urlparse(enclosure[\"href\"]).path.split(\n                        \"/\")[-1]] = enclosure[\"href\"]\n                    # preserve original name\n                else:\n                    try:\n                        # We will download all enclosures of the desired\n                        # mime-type\n                        if any([mimetype in enclosure[\"type\"] for mimetype in\n                                self.mime]):\n                            downloadlinks[urlparse(\n                                enclosure[\"href\"]).path.split(\n                                    \"/\")[-1]] = enclosure[\"href\"]\n                            # preserve original name\n                    except KeyError:\n                        print(\"This podcast carries no information about \"\n                              \"enclosure types. Try using the notype \"\n                              \"option in your greg.conf\", file=sys.stderr,\n                              flush=True)\n        else:\n            downloadlinks[urlparse(entry.link).query.split(\n                \"/\")[-1]] = entry.link\n        for podname in downloadlinks:\n            if (podname, entry.linkdate) not in zip(self.entrylinks,\n                                                    self.linkdates):\n                try:\n                    title = entry.title\n                except:\n                    title = podname\n                try:\n                    sanitizedsummary = aux.html_to_text(entry.summary)\n                    if sanitizedsummary == \"\":\n                        sanitizedsummary = \"No summary available\"\n                except:\n                    sanitizedsummary = \"No summary available\"\n                try:\n                    placeholders = Placeholders(\n                        self, entry, downloadlinks[podname], podname, title,\n                        sanitizedsummary)\n                    placeholders = aux.check_directory(placeholders)\n                    condition = aux.filtercond(placeholders)\n                    if condition:\n                        print(\"Downloading {} -- {}\".format(title, podname))\n                        aux.download_handler(self, placeholders)\n                        if self.willtag:\n                            aux.tag(placeholders)\n                        downloaded = True\n                    else:\n                        print(\"Skipping {} -- {}\".format(title, podname))\n                        downloaded = False\n                    if self.info:\n                        with open(self.info, 'a') as current:\n                            # We write to file this often to ensure that\n                            # downloaded entries count as downloaded.\n                            current.write(''.join([podname, ' ',\n                                          str(entry.linkdate), '\\n']))\n                except URLError:\n                    sys.exit((\"... something went wrong. \"\n                             \"Are you connected to the internet?\"))\n        return downloaded", "response": "Download an entry from the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    args = parser.parse_args()\n    try:\n        function = args.func\n    except AttributeError:\n        parser.print_usage()\n        parser.exit(1)\n    function(vars(args))", "response": "Parse the args and call the function selected\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new feed to the database.", "response": "def add(args):\n    \"\"\"\n    Add a new feed\n    \"\"\"\n    session = c.Session(args)\n    if args[\"name\"] in session.feeds.sections():\n        sys.exit(\"You already have a feed with that name.\")\n    if args[\"name\"] in [\"all\", \"DEFAULT\"]:\n        sys.exit(\n            (\"greg uses \"\"{}\"\" for a special purpose.\"\n             \"Please choose another name for your feed.\").format(args[\"name\"]))\n    entry = {}\n    for key, value in args.items():\n        if value is not None and key != \"func\" and key != \"name\":\n            entry[key] = value\n    session.feeds[args[\"name\"]] = entry\n    with open(session.data_filename, 'w') as configfile:\n        session.feeds.write(configfile)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving the feed given in args", "response": "def remove(args):\n    \"\"\"\n    Remove the feed given in <args>\n    \"\"\"\n    session = c.Session(args)\n    if not args[\"name\"] in session.feeds:\n        sys.exit(\"You don't have a feed with that name.\")\n    inputtext = (\"Are you sure you want to remove the {} \"\n                 \" feed? (y/N) \").format(args[\"name\"])\n    reply = input(inputtext)\n    if reply != \"y\" and reply != \"Y\":\n        return 0\n    else:\n        session.feeds.remove_section(args[\"name\"])\n        with open(session.data_filename, 'w') as configfile:\n            session.feeds.write(configfile)\n        try:\n            os.remove(os.path.join(session.data_dir, args[\"name\"]))\n        except FileNotFoundError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproviding information about a number of feeds", "response": "def info(args):\n    \"\"\"\n    Provide information of a number of feeds\n    \"\"\"\n    session = c.Session(args)\n    if \"all\" in args[\"names\"]:\n        feeds = session.list_feeds()\n    else:\n        feeds = args[\"names\"]\n    for feed in feeds:\n        aux.pretty_print(session, feed)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimplementing the ggreg sync command", "response": "def sync(args):\n    \"\"\"\n    Implement the 'greg sync' command\n    \"\"\"\n    import operator\n    session = c.Session(args)\n    if \"all\" in args[\"names\"]:\n        targetfeeds = session.list_feeds()\n    else:\n        targetfeeds = []\n        for name in args[\"names\"]:\n            if name not in session.feeds:\n                print(\"You don't have a feed called {}.\"\n                      .format(name), file=sys.stderr, flush=True)\n            else:\n                targetfeeds.append(name)\n    for target in targetfeeds:\n        feed = c.Feed(session, target, None)\n        if not feed.wentwrong:\n            try:\n                title = feed.podcast.target.title\n            except AttributeError:\n                title = target\n            print(\"Checking\", title, end=\"...\\n\")\n            currentdate, stop = feed.how_many()\n            entrycounter = 0\n            entries_to_download = feed.podcast.entries\n            for entry in entries_to_download:\n                feed.fix_linkdate(entry)\n            # Sort entries_to_download, but only if you want to download as\n            # many as there are\n            if stop >= len(entries_to_download):\n                entries_to_download.sort(key=operator.attrgetter(\"linkdate\"),\n                                         reverse=False)\n            for entry in entries_to_download:\n                if entry.linkdate > currentdate:\n                    downloaded = feed.download_entry(entry)\n                    entrycounter += downloaded\n                if entrycounter >= stop:\n                    break\n            print(\"Done\")\n        else:\n            msg = ''.join([\"I cannot sync \", feed,\n                           \" just now. Are you connected to the internet?\"])\n            print(msg, file=sys.stderr, flush=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check(args):\n    session = c.Session(args)\n    if str(args[\"url\"]) != 'None':\n        url = args[\"url\"]\n        name = \"DEFAULT\"\n    else:\n        try:\n            url = session.feeds[args[\"feed\"]][\"url\"]\n            name = args[\"feed\"]\n        except KeyError:\n            sys.exit(\"You don't appear to have a feed with that name.\")\n    podcast = aux.parse_podcast(url)\n    for entry in enumerate(podcast.entries):\n        listentry = list(entry)\n        print(listentry[0], end=\": \")\n        try:\n            print(listentry[1][\"title\"], end=\" (\")\n        except:\n            print(listentry[1][\"link\"], end=\" (\")\n        try:\n            print(listentry[1][\"updated\"], end=\")\")\n        except:\n            print(\"\", end=\")\")\n        print()\n    dumpfilename = os.path.join(session.data_dir, 'feeddump')\n    with open(dumpfilename, mode='wb') as dumpfile:\n        dump = [name, podcast]\n        pickle.dump(dump, dumpfile)", "response": "Implement thegreg check command\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimplement the greg download command", "response": "def download(args):\n    \"\"\"\n    Implement the 'greg download' command\n    \"\"\"\n    session = c.Session(args)\n    issues = aux.parse_for_download(args)\n    if issues == ['']:\n        sys.exit(\n            \"You need to give a list of issues, of the form \"\"a, b-c, d...\"\"\")\n    dumpfilename = os.path.join(session.data_dir, 'feeddump')\n    if not os.path.isfile(dumpfilename):\n        sys.exit(\n            (\"You need to run \"\"greg check\"\n             \"<feed>\"\" before using \"\"greg download\"\".\"))\n    with open(dumpfilename, mode='rb') as dumpfile:\n        dump = pickle.load(dumpfile)\n    try:\n        feed = c.Feed(session, dump[0], dump[1])\n    except Exception:\n        sys.exit((\n            \"... something went wrong.\"\n            \"Are you sure your last \"\"greg check\"\" went well?\"))\n    for number in issues:\n        entry = dump[1].entries[eval(number)]\n        feed.info = []\n        feed.entrylinks = []\n        feed.fix_linkdate(entry)\n        feed.download_entry(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_podcast(url):\n    try:\n        podcast = feedparser.parse(url)\n        wentwrong = \"urlopen\" in str(podcast[\"bozo_exception\"])\n    except KeyError:\n        wentwrong = False\n    if wentwrong:\n        print(\"Error: \", url, \": \", str(podcast[\"bozo_exception\"]))\n    return podcast", "response": "Try to parse podcast url and return a dict of the podcasts."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds out and create if needed and return the full path of the current directory.", "response": "def check_directory(placeholders):\n    \"\"\"\n    Find out, and create if needed,\n    the directory in which the feed will be downloaded\n    \"\"\"\n    feed = placeholders.feed\n    args = feed.args\n    placeholders.directory = \"This very directory\"  # wink, wink\n    placeholders.fullpath = os.path.join(\n        placeholders.directory, placeholders.filename)\n    try:\n        if args[\"downloaddirectory\"]:\n            ensure_dir(args[\"downloaddirectory\"])\n            placeholders.directory = args[\"downloaddirectory\"]\n    except KeyError:\n        pass\n    download_path = os.path.expanduser(\n        feed.retrieve_config(\"Download Directory\", \"~/Podcasts\"))\n    subdirectory = feed.retrieve_config(\n        \"Create subdirectory\", \"no\")\n    if \"no\" in subdirectory:\n        placeholders.directory = download_path\n    elif \"yes\" in subdirectory:\n        subdnametemplate = feed.retrieve_config(\n            \"subdirectory_name\", \"{podcasttitle}\")\n        subdname = substitute_placeholders(\n            subdnametemplate, placeholders)\n        placeholders.directory = os.path.join(download_path, subdname)\n    ensure_dir(placeholders.directory)\n    placeholders.fullpath = os.path.join(\n        placeholders.directory, placeholders.filename)\n    return placeholders"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nturns an argument such as 4 6 - 7 8 10 into a list such as [ 4 6 - 8 10 )", "response": "def parse_for_download(args):\n    \"\"\"\n    Turn an argument such as 4, 6-8, 10 into a list such as [4,6,7,8,10]\n    \"\"\"\n    single_arg = \"\"\n    # in the first bit we put all arguments\n    # together and take out any extra spaces\n    list_of_feeds = []\n    for arg in args[\"number\"]:\n        single_arg = ''.join([single_arg, \" \", arg])\n    single_arg = single_arg.translate({32: None})  # eliminates spaces\n    for group in single_arg.split(sep=\",\"):\n        if not(\"-\" in group):\n            list_of_feeds.append(group)\n        else:\n            extremes = group.split(sep=\"-\")\n            list_of_feeds = list_of_feeds + [str(x) for x in range(\n                eval(extremes[0]), eval(extremes[1])+1)]\n    return list_of_feeds"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntagging the file at podpath with the information in podcast and entry", "response": "def tag(placeholders):\n    \"\"\"\n    Tag the file at podpath with the information in podcast and entry\n    \"\"\"\n    # We first recover the name of the file to be tagged...\n    template = placeholders.feed.retrieve_config(\"file_to_tag\", \"{filename}\")\n    filename = substitute_placeholders(template, placeholders)\n    podpath = os.path.join(placeholders.directory, filename)\n    # ... and this is it\n\n    # now we create a dictionary of tags and values\n    tagdict = placeholders.feed.defaulttagdict  # these are the defaults\n    try:  # We do as if there was a section with potential tag info\n        feedoptions = placeholders.feed.config.options(placeholders.name)\n        # this monstruous concatenation of classes... surely a bad idea.\n        tags = [[option.replace(\"tag_\", \"\"), placeholders.feed.config[\n            placeholders.name][option]] for option in feedoptions if \"tag_\" in\n                option]  # these are the tags to be filled\n        if tags:\n            for tag in tags:\n                tagdict[tag[0]] = tag[1]\n    except configparser.NoSectionError:\n        pass\n    for tag in tagdict:\n        metadata = substitute_placeholders(\n            tagdict[tag], placeholders)\n        if metadata:\n            stagger.util.set_frames(podpath, {tag: metadata})\n        else:\n            stagger.util.remove_frames(podpath, tag)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download_handler(feed, placeholders):\n    import shlex\n    \"\"\"\n    Parse and execute the download handler\n    \"\"\"\n    value = feed.retrieve_config('downloadhandler', 'greg')\n    if value == 'greg':\n        while os.path.isfile(placeholders.fullpath):\n            placeholders.fullpath = placeholders.fullpath + '_'\n            placeholders.filename = placeholders.filename + '_'\n        urlretrieve(placeholders.link, placeholders.fullpath)\n    else:\n        value_list = shlex.split(value)\n        instruction_list = [substitute_placeholders(part, placeholders) for\n                            part in value_list]\n        returncode = subprocess.call(instruction_list)\n        if returncode:\n            raise URLError", "response": "Parse and execute the download handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a feed file in. local / share / gmt / data and return a list of links and linkdates", "response": "def parse_feed_info(infofile):\n    \"\"\"\n    Take a feed file in .local/share/greg/data and return a list of links and\n    of dates\n    \"\"\"\n    entrylinks = []\n    linkdates = []\n    try:\n        with open(infofile, 'r') as previous:\n            for line in previous:\n                entrylinks.append(line.split(sep=' ')[0])\n                # This is the list of already downloaded entry links\n                linkdates.append(eval(line.split(sep=' ', maxsplit=1)[1]))\n                # This is the list of already downloaded entry dates\n                # Note that entrydates are lists, converted from a\n                # time.struct_time() object\n    except FileNotFoundError:\n        pass\n    return entrylinks, linkdates"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the dictionary entry of a feed in a nice way.", "response": "def pretty_print(session, feed):\n    \"\"\"\n    Print the dictionary entry of a feed in a nice way.\n    \"\"\"\n    if feed in session.feeds:\n        print()\n        feed_info = os.path.join(session.data_dir, feed)\n        entrylinks, linkdates = parse_feed_info(feed_info)\n        print(feed)\n        print(\"-\"*len(feed))\n        print(''.join([\"    url: \", session.feeds[feed][\"url\"]]))\n        if linkdates != []:\n            print(''.join([\"    Next sync will download from: \", time.strftime(\n                \"%d %b %Y %H:%M:%S\", tuple(max(linkdates))), \".\"]))\n    else:\n        print(\"You don't have a feed called {}.\".format(feed), file=sys.stderr,\n              flush=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a string with placeholders and return the strings with substitutions.", "response": "def substitute_placeholders(inputstring, placeholders):\n    \"\"\"\n    Take a string with placeholders, and return the strings with substitutions.\n    \"\"\"\n    newst = inputstring.format(link=placeholders.link,\n                               filename=placeholders.filename,\n                               directory=placeholders.directory,\n                               fullpath=placeholders.fullpath,\n                               title=placeholders.title,\n                               filename_title=placeholders.filename_title,\n                               date=placeholders.date_string(),\n                               podcasttitle=placeholders.podcasttitle,\n                               filename_podcasttitle=\n                               placeholders.filename_podcasttitle,\n                               name=placeholders.name,\n                               subtitle=placeholders.sanitizedsubtitle,\n                               entrysummary=placeholders.entrysummary)\n    return newst"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing by Tarjan and Tarjan_iter. This is the head of the the main iteration.", "response": "def _tarjan_head(ctx, v):\n        \"\"\" Used by @tarjan and @tarjan_iter.  This is the head of the\n            main iteration \"\"\"\n        ctx.index[v] = len(ctx.index)\n        ctx.lowlink[v] = ctx.index[v]\n        ctx.S.append(v)\n        ctx.S_set.add(v)\n        it = iter(ctx.g.get(v, ()))\n        ctx.T.append((it,False,v,None))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses by Tarjan and Tarjan_iter. This is the body of the Tarjan iteration.", "response": "def _tarjan_body(ctx, it, v):\n        \"\"\" Used by @tarjan and @tarjan_iter.  This is the body of the\n            main iteration \"\"\"\n        for w in it:\n                if w not in ctx.index:\n                        ctx.T.append((it,True,v,w))\n                        _tarjan_head(ctx, w)\n                        return\n                if w in ctx.S_set:\n                        ctx.lowlink[v] = min(ctx.lowlink[v], ctx.index[w])\n        if ctx.lowlink[v] == ctx.index[v]:\n                scc = []\n                w = None\n                while v != w:\n                        w = ctx.S.pop()\n                        scc.append(w)\n                        ctx.S_set.remove(w)\n                ctx.ret.append(scc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an iterator over the strongly connected components of the graph g.", "response": "def tarjan_iter(g):\n        \"\"\" Returns the strongly connected components of the graph @g\n            in a topological order.\n\n                @g is the graph represented as a dictionary\n                        { <vertex> : <successors of vertex> }.\n\n            This function does not recurse.  It returns an iterator. \"\"\"\n        ctx = TarjanContext(\n                g = g,\n                S = [],\n                S_set = set(),\n                index = {},\n                lowlink = {},\n                T = [],\n                ret = [])\n        main_iter = iter(g)\n        while True:\n                try:\n                        v = next(main_iter)\n                except StopIteration:\n                        return\n                if v not in ctx.index:\n                        _tarjan_head(ctx, v)\n                while ctx.T:\n                        it, inside, v, w = ctx.T.pop()\n                        if inside:\n                                ctx.lowlink[v] = min(ctx.lowlink[w],\n                                                        ctx.lowlink[v])\n                        _tarjan_body(ctx, it, v)\n                        if ctx.ret:\n                                assert len(ctx.ret) == 1\n                                yield ctx.ret.pop()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the strongly connected components of the graph @g in a topological order. @g is the graph represented as a dictionary { <vertex> : <successors of vertex> }. This function recurses --- large graphs may cause a stack overflow.", "response": "def tarjan_recursive(g):\n        \"\"\" Returns the strongly connected components of the graph @g\n            in a topological order.\n\n                @g is the graph represented as a dictionary\n                        { <vertex> : <successors of vertex> }.\n                        \n            This function recurses --- large graphs may cause a stack\n            overflow. \"\"\"\n        S = []\n        S_set = set()\n        index = {}\n        lowlink = {}\n        ret = []\n\n        def visit(v):\n                index[v] = len(index)\n                lowlink[v] = index[v]\n                S.append(v)\n                S_set.add(v)\n                for w in g.get(v,()):\n                        if w not in index:\n                                visit(w)\n                                lowlink[v] = min(lowlink[w], lowlink[v])\n                        elif w in S_set:\n                                lowlink[v] = min(lowlink[v], index[w])\n                if lowlink[v] == index[v]:\n                        scc = []\n                        w = None\n                        while v != w:\n                                w = S.pop()\n                                scc.append(w)\n                                S_set.remove(w)\n                        ret.append(scc)\n\n        for v in g:\n                if not v in index:\n                        visit(v)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef symm_block_tridiag_matmul(H_diag, H_upper_diag, v):\n    T, D, _ = H_diag.shape\n    assert H_diag.ndim == 3 and H_diag.shape[2] == D\n    assert H_upper_diag.shape == (T-1, D, D)\n    assert v.shape == (T, D)\n\n    out = np.matmul(H_diag, v[:, :, None])[:, :, 0]\n    out[:-1] += np.matmul(H_upper_diag, v[1:][:, :, None])[:, :, 0]\n    out[1:] += np.matmul(np.swapaxes(H_upper_diag, -2, -1), v[:-1][:, :, None])[:, :, 0]\n    return out", "response": "Compute matrix - vector product with a symmetric block - diagonal matrix H and vector v."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_block_tridiag_to_banded(H_diag, H_upper_diag, lower=True):\n    T, D, _ = H_diag.shape\n    assert H_diag.ndim == 3 and H_diag.shape[2] == D\n    assert H_upper_diag.shape == (T - 1, D, D)\n    H_lower_diag = np.swapaxes(H_upper_diag, -2, -1)\n\n    ab = np.zeros((2 * D, T * D))\n\n    # Fill in blocks along the diagonal\n    for d in range(D):\n        # Get indices of (-d)-th diagonal of H_diag\n        i = np.arange(d, D)\n        j = np.arange(0, D - d)\n        h = np.column_stack((H_diag[:, i, j], np.zeros((T, d))))\n        ab[d] = h.ravel()\n\n    # Fill in lower left corner of blocks below the diagonal\n    for d in range(0, D):\n        # Get indices of (-d)-th diagonal of H_diag\n        i = np.arange(d, D)\n        j = np.arange(0, D - d)\n        h = np.column_stack((H_lower_diag[:, i, j], np.zeros((T - 1, d))))\n        ab[D + d, :D * (T - 1)] = h.ravel()\n\n    # Fill in upper corner of blocks below the diagonal\n    for d in range(1, D):\n        # Get indices of (+d)-th diagonal of H_lower_diag\n        i = np.arange(0, D - d)\n        j = np.arange(d, D)\n        h = np.column_stack((np.zeros((T - 1, d)), H_lower_diag[:, i, j]))\n        ab[D - d, :D * (T - 1)] += h.ravel()\n\n    return ab if lower else transpose_lower_banded_matrix(ab)", "response": "converts a tridiagonal matrix into a banded matrix representation required for scipy.\n    we are using the lower form."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsolves a symmetric block tridiagonal system", "response": "def scipy_solve_symm_block_tridiag(H_diag, H_upper_diag, v, ab=None):\n    \"\"\"\n    use scipy.linalg.solve_banded to solve a symmetric block tridiagonal system\n\n    see https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solveh_banded.html\n    \"\"\"\n    from scipy.linalg import solveh_banded\n    ab = convert_block_tridiag_to_banded(H_diag, H_upper_diag) \\\n        if ab is None else ab\n    x = solveh_banded(ab, v.ravel(), lower=True)\n    return x.reshape(v.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the log determinant of a positive definite symmetric block tridiagonal matrix.", "response": "def logdet_symm_block_tridiag(H_diag, H_upper_diag):\n    \"\"\"\n    compute the log determinant of a positive definite,\n    symmetric block tridiag matrix.  Use the Kalman\n    info filter to do so.  Specifically, the KF computes\n    the normalizer:\n\n        log Z = 1/2 h^T J^{-1} h -1/2 log |J| +n/2 log 2 \\pi\n\n    We set h=0 to get -1/2 log |J| + n/2 log 2 \\pi and from\n    this we solve for log |J|.\n    \"\"\"\n    T, D, _ = H_diag.shape\n    assert H_diag.ndim == 3 and H_diag.shape[2] == D\n    assert H_upper_diag.shape == (T - 1, D, D)\n\n    J_init = J_11 = J_22 = np.zeros((D, D))\n    h_init = h_1 = h_2 = np.zeros((D,))\n    log_Z_init = 0\n\n    J_21 = np.swapaxes(H_upper_diag, -1, -2)\n    log_Z_pair = 0\n\n    J_node = H_diag\n    h_node = np.zeros((T, D))\n    log_Z_node = 0\n\n    logZ, _, _ = kalman_info_filter(J_init, h_init, log_Z_init,\n                                    J_11, J_21, J_22, h_1, h_2, log_Z_pair,\n                                    J_node, h_node, log_Z_node)\n\n    # logZ = -1/2 log |J| + n/2 log 2 \\pi\n    logdetJ = -2 * (logZ - (T*D) / 2 * np.log(2 * np.pi))\n    return logdetJ"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the covariances for a symmetric block tridiagonal system.", "response": "def compute_symm_block_tridiag_covariances(H_diag, H_upper_diag):\n    \"\"\"\n    use the info smoother to solve a symmetric block tridiagonal system\n    \"\"\"\n    T, D, _ = H_diag.shape\n    assert H_diag.ndim == 3 and H_diag.shape[2] == D\n    assert H_upper_diag.shape == (T - 1, D, D)\n\n    J_init = J_11 = J_22 = np.zeros((D, D))\n    h_init = h_1 = h_2 = np.zeros((D,))\n\n    J_21 = np.swapaxes(H_upper_diag, -1, -2)\n    J_node = H_diag\n    h_node = np.zeros((T, D))\n\n    _, _, sigmas, E_xt_xtp1 = \\\n        info_E_step(J_init, h_init, 0,\n                    J_11, J_21, J_22, h_1, h_2, np.zeros((T-1)),\n                    J_node, h_node, np.zeros(T))\n    return sigmas, E_xt_xtp1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the expected log likelihood for a mean and covariance of x and an observed value of y.", "response": "def expected_log_likelihood(self, mus, sigmas, y):\n        \"\"\"\n        Compute the expected log likelihood for a mean and\n        covariance of x and an observed value of y.\n        \"\"\"\n\n        # Flatten the covariance\n        T = mus.shape[0]\n        D = self.D_in\n        sigs_vec = sigmas.reshape((T, D ** 2))\n\n        # Compute the log likelihood of each column\n        ll = np.zeros((T, self.D_out))\n        for n in range(self.D_out):\n\n            an = self.A[n]\n\n            E_loglmbda = np.dot(mus, an)\n            ll[:,n] += y[:,n] * E_loglmbda\n\n            # Vectorized log likelihood calculation\n            aa_vec = np.outer(an, an).reshape((D ** 2,))\n            ll[:,n] = -np.exp(E_loglmbda + 0.5 * np.dot(sigs_vec, aa_vec))\n\n        return ll"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef max_likelihood(self, data, weights=None, stats=None):\n        if isinstance(data, list):\n            x = np.vstack([d[0] for d in data])\n            y = np.vstack([d[1] for d in data])\n        elif isinstance(data, tuple):\n            assert len(data) == 2\n        elif isinstance(data, np.ndarray):\n            x, y = data[:,:self.D_in], data[:, self.D_in:]\n        else:\n            raise Exception(\"Invalid data type\")\n\n        from sklearn.linear_model import LogisticRegression\n        for n in progprint_xrange(self.D_out):\n            lr = LogisticRegression(fit_intercept=False)\n            lr.fit(x, y[:,n])\n            self.A[n] = lr.coef_", "response": "Maximize the likelihood for given data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef log_conditional_likelihood(self, x):\n        T, D = self.T, self.D_latent\n        assert x.shape == (T, D)\n\n        ll = 0\n        for t in range(self.T):\n            ll += self.local_log_likelihood(x[t], self.data[t], self.inputs[t])\n        return ll", "response": "Returns the log likelihood of a conditional log - likelihood of a set of data points."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grad_local_log_likelihood(self, x):\n        T, D = self.T, self.D_latent\n        assert x.shape == (T, D)\n        gfun = grad(self.local_log_likelihood)\n\n        g = np.zeros((T, D))\n        for t in range(T):\n            g[t] += gfun(x[t], self.data[t], self.inputs[t])\n        return g", "response": "gradients the local log likelihood of the local class"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hessian_local_log_likelihood(self, x):\n        T, D = self.T, self.D_latent\n        assert x.shape == (T, D)\n\n        hfun = hessian(self.local_log_likelihood)\n        H_diag = np.zeros((T, D, D))\n        for t in range(T):\n            H_diag[t] = hfun(x[t], self.data[t], self.inputs[t])\n        return H_diag", "response": "Returns the Hessian of the local log likelihood of each time bin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log_joint(self, x):\n        T, D = self.T, self.D_latent\n        assert x.shape == (T, D)\n\n        # prior log p(x) -- quadratic terms\n        J_diag, J_upper_diag = self.sparse_J_prior\n        lp = -0.5 * np.sum(x * symm_block_tridiag_matmul(J_diag, J_upper_diag, x))\n\n        # prior log p(x) -- linear terms\n        _, h_init, log_Z_init = self.info_init_params\n        _, _, _, h1, h2, log_Z_dyn = self.info_dynamics_params\n        lp += x[0].dot(h_init)\n        lp += np.sum(x[:-1] * h1)\n        lp += np.sum(x[1:] * h2)\n\n        # prior log p(x) -- normalization constants\n        lp += log_Z_init\n        lp += np.sum(log_Z_dyn)\n\n        # likelihood log p(y | x)\n        lp += self.log_conditional_likelihood(x)\n\n        return lp", "response": "Compute the log joint probability p x y"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the Hessian of the local log likelihood of the Gaussian LDS prior and the local log likelihood of the Gaussian LDS prior.", "response": "def sparse_hessian_log_joint(self, x):\n        \"\"\"\n        The Hessian includes the quadratic terms of the Gaussian LDS prior\n        as well as the Hessian of the local log likelihood.\n        \"\"\"\n        T, D = self.T, self.D_latent\n        assert x.shape == (T, D)\n\n        # Collect the Gaussian LDS prior terms\n        J_diag, J_upper_diag = self.sparse_J_prior\n        H_diag, H_upper_diag = -J_diag, -J_upper_diag\n\n        # Collect the likelihood terms\n        H_diag += self.hessian_local_log_likelihood(x)\n\n        # Subtract a little bit to ensure negative definiteness\n        H_diag -= 1e-8 * np.eye(D)\n\n        return H_diag, H_upper_diag"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the gradient of the log joint probability of the log joint.", "response": "def gradient_log_joint(self, x):\n        \"\"\"\n        The gradient of the log joint probability.\n\n        For the Gaussian terms, this is\n\n            d/dx [-1/2 x^T J x + h^T x] = -Jx + h.\n\n        For the likelihood terms, we have for each time t\n\n            d/dx log p(yt | xt)\n        \"\"\"\n        T, D = self.T, self.D_latent\n        assert x.shape == (T, D)\n\n        # Collect the Gaussian LDS prior terms\n        _, h_init, _ = self.info_init_params\n        _, _, _, h1, h2, _ = self.info_dynamics_params\n        H_diag, H_upper_diag = self.sparse_J_prior\n\n        # Compute the gradient from the prior\n        g = -1 * symm_block_tridiag_matmul(H_diag, H_upper_diag, x)\n        g[0] += h_init\n        g[:-1] += h1\n        g[1:] += h2\n\n        # Compute gradient from the likelihood terms\n        g += self.grad_local_log_likelihood(x)\n\n        return g"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsolve a Laplace approximation with Newton s method.", "response": "def _laplace_approximation_newton(self, tol=1e-6, stepsz=0.9, verbose=False):\n        \"\"\"\n        Solve a block tridiagonal system with message passing.\n        \"\"\"\n        from pylds.util import solve_symm_block_tridiag, scipy_solve_symm_block_tridiag\n        scale = self.T * self.D_emission\n\n        def newton_step(x, stepsz):\n            assert 0 <= stepsz <= 1\n            g = self.gradient_log_joint(x)\n            H_diag, H_upper_diag = self.sparse_hessian_log_joint(x)\n            Hinv_g = -scipy_solve_symm_block_tridiag(-H_diag / scale,\n                                               -H_upper_diag / scale,\n                                               g / scale)\n            return x - stepsz * Hinv_g\n\n        if verbose:\n            print(\"Fitting Laplace approximation\")\n\n        itr = [0]\n        def cbk(x):\n            print(\"Iteration: \", itr[0],\n                  \"\\tObjective: \", (self.log_joint(x) / scale).round(4),\n                  \"\\tAvg Grad: \", (self.gradient_log_joint(x).mean() / scale).round(4))\n            itr[0] += 1\n\n        # Solve for optimal x with Newton's method\n        x = self.gaussian_states\n        dx = np.inf\n        while dx >= tol:\n            xnew = newton_step(x, stepsz)\n            dx = np.mean(abs(xnew - x))\n            x = xnew\n\n            if verbose:\n                cbk(x)\n\n        assert np.all(np.isfinite(x))\n        if verbose:\n            print(\"Done\")\n\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef grad_local_log_likelihood(self, x):\n        # Observation likelihoods\n        lmbda = np.exp(np.dot(x, self.C.T) + np.dot(self.inputs, self.D.T))\n        return (self.data - lmbda).dot(self.C)", "response": "Gradient of the local log likelihood of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the Hessian of the local log likelihood of the class.", "response": "def hessian_local_log_likelihood(self, x):\n        \"\"\"\n        d/dx  (y - lmbda)^T C = d/dx -exp(Cx + d)^T C\n            = -C^T exp(Cx + d)^T C\n        \"\"\"\n        # Observation likelihoods\n        lmbda = np.exp(np.dot(x, self.C.T) + np.dot(self.inputs, self.D.T))\n        return np.einsum('tn, ni, nj ->tij', -lmbda, self.C, self.C)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hessian_local_log_likelihood(self, x):\n        C, D, u, y = self.C, self.D, self.inputs, self.data\n        psi = x.dot(C.T) + u.dot(D.T)\n        p = 1. / (1 + np.exp(-psi))\n        dp_dpsi = p * (1 - p)\n        return np.einsum('tn, ni, nj ->tij', -dp_dpsi, self.C, self.C)", "response": "Hessian of the local log likelihood of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resample_emission_distn(self):\n        masked_datas = [s.masked_data.tocsc() for s in self.states_list]\n        xs = [np.hstack((s.gaussian_states, s.inputs))for s in self.states_list]\n\n        for n in range(self.D_obs):\n            # Get the nonzero values of the nth column\n            rowns = [md.indices[md.indptr[n]:md.indptr[n+1]] for md in masked_datas]\n            xns = [x[r] for x,r in zip(xs, rowns)]\n            yns = [s.masked_data.getcol(n).data for s in self.states_list]\n            maskns = [np.ones_like(y, dtype=bool) for y in yns]\n            omegans = [s.omega.getcol(n).data for s in self.states_list]\n            self.emission_distn._resample_row_of_emission_matrix(n, xns, yns, maskns, omegans)", "response": "Resample the emission distribution matrix to fit the latent states."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef authenticate(self, username, password, service='login', encoding='utf-8', resetcreds=True):\n\n        @conv_func\n        def my_conv(n_messages, messages, p_response, app_data):\n            \"\"\"Simple conversation function that responds to any\n               prompt where the echo is off with the supplied password\"\"\"\n            # Create an array of n_messages response objects\n            addr = calloc(n_messages, sizeof(PamResponse))\n            response = cast(addr, POINTER(PamResponse))\n            p_response[0] = response\n            for i in range(n_messages):\n                if messages[i].contents.msg_style == PAM_PROMPT_ECHO_OFF:\n                    dst = calloc(len(password)+1, sizeof(c_char))\n                    memmove(dst, cpassword, len(password))\n                    response[i].resp = dst\n                    response[i].resp_retcode = 0\n            return 0\n\n        # python3 ctypes prefers bytes\n        if sys.version_info >= (3,):\n            if isinstance(username, str): username = username.encode(encoding)\n            if isinstance(password, str): password = password.encode(encoding)\n            if isinstance(service, str):  service  = service.encode(encoding)\n        else:\n            if isinstance(username, unicode):\n                username = username.encode(encoding)\n            if isinstance(password, unicode):\n                password = password.encode(encoding)\n            if isinstance(service, unicode):\n                service  = service.encode(encoding)\n\n        if b'\\x00' in username or b'\\x00' in password or b'\\x00' in service:\n            self.code = 4  # PAM_SYSTEM_ERR in Linux-PAM\n            self.reason = 'strings may not contain NUL'\n            return False\n\n        # do this up front so we can safely throw an exception if there's\n        # anything wrong with it\n        cpassword = c_char_p(password)\n\n        handle = PamHandle()\n        conv   = PamConv(my_conv, 0)\n        retval = pam_start(service, username, byref(conv), byref(handle))\n\n        if retval != 0:\n            # This is not an authentication error, something has gone wrong starting up PAM\n            self.code   = retval\n            self.reason = \"pam_start() failed\"\n            return False\n\n        retval = pam_authenticate(handle, 0)\n        auth_success = retval == 0\n\n        if auth_success and resetcreds:\n            retval = pam_setcred(handle, PAM_REINITIALIZE_CRED);\n\n        # store information to inform the caller why we failed\n        self.code   = retval\n        self.reason = pam_strerror(handle, retval)\n        if sys.version_info >= (3,):\n            self.reason = self.reason.decode(encoding)\n\n        if hasattr(libpam, 'pam_end'):\n            pam_end(handle, retval)\n\n        return auth_success", "response": "Authenticate with the given username and password."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self):\n        with open(self.filename) as f:\n            content = f.readlines()\n        content = [\" \".join(x.split()).strip('\\n').lstrip().split(' ', 1) for x in content]\n\n        # removes duplicated spaces, and splits in two fields, removes leading spaces\n        hosts = {}\n        host = \"NA\"\n        for line in content:\n            if line[0].startswith('#') or line[0] is '':\n                pass  # ignore line\n            else:\n                attribute = line[0]\n                value = line[1]\n                if attribute.lower().strip() in ['Host', 'host']:\n                    host = value\n                    hosts[host] = {'host': host}\n                else:\n                    # In case of special configuration lines, such as port\n                    # forwarding,\n                    # there would be no 'Host india' line.\n                    if host in hosts:\n                        hosts[host][attribute] = value\n                        # pass\n        self.hosts = hosts", "response": "load the hosts defined in the ssh config file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, name, command):\n        if name in [\"localhost\"]:\n            r = '\\n'.join(Shell.sh(\"-c\", command).split()[-1:])\n        else:\n            r = '\\n'.join(Shell.ssh(name, command).split()[-1:])\n        return r", "response": "execute the command on the named host"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(self,\n                 key=\"india\",\n                 host=\"india.futuresystems.org\",\n                 username=None,\n                 force=False,\n                 verbose=False):\n        \"\"\"\n        adds a host to the config file with given parameters.  #TODO: make sure this is better documented\n        :param key: the key\n        :param host: the host\n        :param username: the username\n        :param force: not used\n        :param verbose: prints debug messages\n        :return: \n        \"\"\"\n        data = {\n            \"host\": host,\n            \"key\": key,\n            \"username\": username\n        }\n        if verbose and key in self.names():\n            Console.error(\"{key} already in ~/.ssh/config\".format(**data), traceflag=False)\n            return \"\"\n        else:\n            entry = dedent(\"\"\"\n            Host {key}\n                Hostname {host}\n                User {username}\n            \"\"\".format(**data))\n        try:\n            with open(self.filename, \"a\") as config_ssh:\n                config_ssh.write(entry)\n            config_ssh.close()\n            self.load()\n            if verbose:\n                Console.ok(\"Added india to ~/.ssh/config\")\n        except Exception as e:\n            if verbose:\n                Console.error(e.message)", "response": "Generates a new config file with given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a logger with the given filename", "response": "def LOGGER(filename):\n    \"\"\"creates a logger with the given name.\n\n    You can use it as follows::\n\n       log = cloudmesh.common.LOGGER(__file__)\n       log.error(\"this is an error\")\n       log.info(\"this is an info\")\n       log.warning(\"this is a warning\")\n\n    \"\"\"\n    pwd = os.getcwd()\n    name = filename.replace(pwd, \"$PWD\")\n    try:\n        (first, name) = name.split(\"site-packages\")\n        name += \"... site\"\n    except:\n        pass\n\n    loglevel = logging.CRITICAL\n    try:\n        level = grep(\"loglevel:\", config_file(\n            \"/cloudmesh_debug.yaml\")).strip().split(\":\")[1].strip().lower()\n\n        if level.upper() == \"DEBUG\":\n            loglevel = logging.DEBUG\n        elif level.upper() == \"INFO\":\n            loglevel = logging.INFO\n        elif level.upper() == \"WARNING\":\n            loglevel = logging.WARNING\n        elif level.upper() == \"ERROR\":\n            loglevel = logging.ERROR\n        else:\n            level = logging.CRITICAL\n    except:\n        # print \"LOGLEVEL NOT FOUND\"\n        loglevel = logging.DEBUG\n\n    log = logging.getLogger(name)\n    log.setLevel(loglevel)\n\n    formatter = logging.Formatter(\n        'CM {0:>50}:%(lineno)s: %(levelname)6s - %(message)s'.format(name))\n\n    # formatter = logging.Formatter(\n    #    'CM {0:>50}: %(levelname)6s - %(module)s:%(lineno)s %funcName)s: %(message)s'.format(name))\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    log.addHandler(handler)\n    return log"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef key_prefix_replace(d, prefix, new_prefix=\"\"):\n    items = []\n    for k, v in d.items():\n        new_key = k\n        for p in prefix:\n            new_key = new_key.replace(p, new_prefix, 1)\n        items.append((new_key, v))\n    return dict(items)", "response": "Replaces the list of prefix in keys of a flattened dict with a new prefix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nflattening the dict into a one dimensional dictionary.", "response": "def flatten(d, parent_key='', sep='__'):\n    \"\"\"\n    flattens the dict into a one dimensional dictionary\n\n    :param d: multidimensional dict\n    :param parent_key: replaces from the parent key\n    :param sep: the separation character used when fattening. the default is __\n    :return: the flattened dict\n    \"\"\"\n    # http://stackoverflow.com/questions/6027558/flatten-nested-python-dictionaries-compressing-keys\n    if type(d) == list:\n        flat = []\n        for entry in d:\n            flat.append(flatten(entry, parent_key=parent_key, sep=sep))\n        return flat\n    else:\n        items = []\n        for k, v in d.items():\n            new_key = parent_key + sep + k if parent_key else k\n\n            if isinstance(v, collectionsAbc.MutableMapping):\n                items.extend(flatten(v, new_key, sep=sep).items())\n            else:\n                items.append((new_key, v))\n\n\n        return dict(items)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint the error message to stdout.", "response": "def msg(cls, error=None, debug=True, trace=True):\n        \"\"\"\n        prints the error message\n        :param error: the error message\n        :param debug: only prints it if debug is set to true\n        :param trace: if true prints the trace\n        :return: \n        \"\"\"\n        if debug and error is not None:\n            print(error)\n        # TODO: BUG: trace should only be printed if debug is true\n        if trace:\n            print(traceback.format_exc())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the traceback of the current exception.", "response": "def traceback(cls, error=None, debug=True, trace=True):\n        \"\"\"\n        prints the trace\n        :param error: a message preceding the trace\n        :param debug: prints it if debug is set to true\n        :param trace: \n        :return: \n        \"\"\"\n        # TODO: if debug:\n        Error.msg(error=error, debug=debug, trace=trace)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nindent the given text by the indent specified and wrapping to the given width", "response": "def indent(text, indent=2, width=128):\n    \"\"\"\n    indents the given text by the indent specified and wrapping to the given width\n    \n    :param text: the text to print\n    :param indent: indent characters\n    :param width: the width of the text\n    :return: \n    \"\"\"\n    return \"\\n\".join(\n        textwrap.wrap(text,\n                      width=width,\n                      initial_indent=\" \" * indent,\n                      subsequent_indent=\" \" * indent))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_theme(color=True):\n        if color:\n            Console.theme = Console.theme_color\n        else:\n            Console.theme = Console.theme_bw\n        Console.color = color", "response": "Define if the console messages are printed in color\n            Console. theme is set to color"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef error(cls, message, prefix=True, traceflag=False):\n        # print (message, prefix)\n        message = message or \"\"\n        if prefix:\n            text = \"ERROR: \"\n        else:\n            text = \"\"\n        if cls.color:\n            cls.cprint('FAIL', text, str(message))\n        else:\n            print(cls.txt_msg(text + str(message)))\n\n        if traceflag and cls.debug:\n            trace = traceback.format_exc().strip()\n            if trace:\n                print()\n                print(\"Trace:\")\n                print(\"\\n    \".join(str(trace).splitlines()))\n                print()", "response": "Prints an error message to the screen."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints an error message to stdout.", "response": "def TODO(message, prefix=True, traceflag=True):\n        \"\"\"\n        prints an TODO message\n        :param message: the message\n        :param prefix: if set to true it prints TODO: as prefix\n        :param traceflag: if true the stack trace is retrieved and printed\n        :return: \n        \"\"\"\n        message = message or \"\"\n        if prefix:\n            text = \"TODO: \"\n        else:\n            text = \"\"\n        if Console.color:\n            Console.cprint('FAIL', text, str(message))\n        else:\n            print(Console.msg(text + str(message)))\n\n        trace = traceback.format_exc().strip()\n\n        if traceflag and trace != \"None\":\n            print()\n            print(\"\\n\".join(str(trace).splitlines()))\n            print()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef debug_msg(message):\n        message = message or \"\"\n        if Console.color:\n            Console.cprint('RED', 'DEBUG: ', message)\n        else:\n            print(Console.msg('DEBUG: ' + message))", "response": "print a debug message"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints an informational message", "response": "def info(message):\n        \"\"\"\n        prints an informational message\n        :param message: the message\n        :return: \n        \"\"\"\n        message = message or \"\"\n        if Console.color:\n            Console.cprint('OKBLUE', \"INFO: \", message)\n        else:\n            print(Console.msg(\"INFO: \" + message))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a warning message", "response": "def warning(message):\n        \"\"\"\n        prints a warning\n        :param message: the message\n        :return: \n        \"\"\"\n        message = message or \"\"\n        if Console.color:\n            Console.cprint('WARNING', \"WARNING: \", message)\n        else:\n            print(Console.msg(\"WARNING: \" + message))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ok(message):\n        message = message or \"\"\n        if Console.color:\n            Console.cprint('OKGREEN', \"\", message)\n        else:\n            print(Console.msg(message))", "response": "Prints an ok message"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cprint(color, prefix, message):\n        message = message or \"\"\n        prefix = prefix or \"\"\n        print((Console.theme[color] +\n               prefix +\n               message +\n               Console.theme['ENDC']))", "response": "Print a message in a given color"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(cls, name):\n        if cls.debug:\n            print(\"Timer\", name, \"started ...\")\n        cls.timer_start[name] = time.time()", "response": "starts a timer with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstop the timer with a given name.", "response": "def stop(cls, name):\n        \"\"\"\n        stops the timer with a given name.\n\n        :param name: the name of the timer\n        :type name: string\n        \"\"\"\n        cls.timer_end[name] = time.time()\n        if cls.debug:\n            print(\"Timer\", name, \"stopped ...\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the time of the timer.", "response": "def get(cls, name):\n        \"\"\"\n        returns the time of the timer.\n\n        :param name: the name of the timer\n        :type name: string\n        :rtype: the elapsed time\n        \"\"\"\n        if name in cls.timer_end:\n            cls.timer_elapsed[name] = cls.timer_end[name] - \\\n                                      cls.timer_start[name]\n            return cls.timer_elapsed[name]\n        else:\n            return \"undefined\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a timer. The first argument is the label if it exists, the last is the timer :param args: label, name :return:", "response": "def print(cls, *args):\n        \"\"\"\n        prints a timer. The first argument is the label if it exists, the last is the timer\n        :param args: label, name \n        :return: \n        \"\"\"\n        if cls.verbose:\n            if len(args) == 2:\n                print(args[0], str(\"{0:.2f}\".format(cls.get(args[1]))), \"s\")\n            else:\n                raise Exception(\"StopWatch: wrong number of arguments\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint out all timers in a convenient benchmark tabble", "response": "def benchmark(cls, sysinfo=True):\n        \"\"\"\n        prints out all timers in a convenient benchmark tabble\n        :return:\n        :rtype:\n        \"\"\"\n\n        #\n        # PRINT PLATFORM\n        #\n        if sysinfo:\n            data_platform = systeminfo()\n            print(Printer.attribute(data_platform,\n                                    [\"Machine Arribute\", \"Time/s\"]))\n\n        #\n        # PRINT TIMERS\n        #\n        timers = StopWatch.keys()\n\n        data_timers = {}\n        for timer in timers:\n            data_timers[timer] = {\n                'time': round(StopWatch.get(timer), 2),\n                'timer': timer\n            }\n            for attribute in [\"node\", \"system\", \"machine\", \"mac_version\",\n                              \"win_version\"]:\n                data_timers[timer][attribute] = data_platform[attribute]\n\n        # print(Printer.attribute(data_timers, header=[\"Command\", \"Time/s\"]))\n        print(Printer.write(\n            data_timers,\n            order=[\"timer\", \"time\", \"node\", \"system\", \"mac_version\",\n                   \"win_version\"]\n        ))\n\n        print()\n        print(Printer.write(\n            data_timers,\n            order=[\"timer\", \"time\", \"node\", \"system\", \"mac_version\",\n                   \"win_version\"],\n            output=\"csv\"\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dprint(OD, mode='dict', s=\"\", indent=' ' * 4, level=0):\n\n    def is_number(s):\n        \"\"\"\n        checks if the type of s is a float\n        :param s: \n        :return: \n        \"\"\"\n        try:\n            float(s)\n            return True\n        except ValueError:\n            return False\n\n    def fstr(s):\n        \"\"\"\n        return a string or number\n        :param s: teh string or number\n        :return: \n        \"\"\"\n        return s if is_number(s) else '\"%s\"' % s\n\n    if mode != 'dict':\n        kv_tpl = '(\"%s\", %s)'\n        ST = 'OrderedDict([\\n'\n        END = '])'\n    else:\n        kv_tpl = '\"%s\": %s'\n        ST = '{\\n'\n        END = '}'\n    for i, k in enumerate(OD.keys()):\n        if type(OD[k]) in [dict, OrderedDict]:\n            level += 1\n            s += (level - 1) * indent + kv_tpl % (\n                k, ST + dprint(OD[k], mode=mode,\n                               indent=indent, level=level) + (\n                        level - 1) * indent + END)\n            level -= 1\n        else:\n            s += level * indent + kv_tpl % (k, fstr(OD[k]))\n        if i != len(OD) - 1:\n            s += \",\"\n        s += \"\\n\"\n    return s", "response": "recursive dict printer method that adds indentations to the string s"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the file contains tabs and returns False if it does not contain tabs", "response": "def check_file_for_tabs(cls, filename, verbose=True):\n        \"\"\"identifies if the file contains tabs and returns True if it\n        does. It also prints the location of the lines and columns. If\n        verbose is set to False, the location is not printed.\n\n        :param verbose: if true prints issues\n        :param filename: the filename\n        :type filename: str\n        :rtype: True if there are tabs in the file\n        \"\"\"\n        filename = path_expand(filename)\n        file_contains_tabs = False\n\n        with open(filename, 'r') as f:\n            lines = f.read().split(\"\\n\")\n\n        line_no = 1\n        for line in lines:\n            if \"\\t\" in line:\n                file_contains_tabs = True\n                location = [\n                    i for i in range(len(line)) if line.startswith('\\t', i)]\n                if verbose:\n                    print(\"Tab found in line\", line_no, \"and column(s)\",\n                          location)\n            line_no += 1\n        return file_contains_tabs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path_expand(cls, path):\n        current_dir = \".\" + os.path.sep\n        if path.startswith(current_dir):\n            cwd = str(os.getcwd())\n            path = path.replace(current_dir, cwd, 1)\n        location = os.path.expandvars(os.path.expanduser(path))\n        return location", "response": "expands the path while replacing environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_file(cls, filename, load_order=None, verbose=False):\n        if load_order is None:\n            load_order = [\".\", os.path.join(\"~\", \".cloudmesh\")]\n        for path in load_order:\n            name = Config.path_expand(path + os.path.sep + filename)\n            if verbose:\n                print(\"try finding file\", name)\n            if os.path.isfile(name):\n                if verbose:\n                    print(\"Found File\", name)\n                return name\n        return None", "response": "find the specified file in the list of directories that are given in the load_order"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self, filename):\n        # print (\"LOAD CONFIGDICT\", filename)\n\n        self.data = BaseConfigDict(filename=Config.path_expand(filename))\n        try:\n            version = str(self.data[\"meta\"][\"version\"])\n            if version not in self.versions:\n                Console.error(\"The yaml file version must be {}\".format(\n                    ', '.join(self.versions)))\n                sys.exit(1)\n        except Exception as e:\n            Console.error(\n                \"Your yaml file ~/.cloudmesh/cloudmesh.yaml is not up to date.\",\n                traceflag=False)\n            Console.error(e.message, traceflag=False)\n            sys.exit(1)", "response": "Loads the configuration from the yaml file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a backup of the file specified in the location.", "response": "def make_a_copy(self, location=None):\n        \"\"\"\n        Creates a backup of the file specified in the location. The backup\n        filename  appends a .bak.NO where number is a number that is not yet\n        used in the backup directory.\n        TODO: This function should be moved to another file maybe XShell\n        :param location: the location of the file to be backed up\n        \"\"\"\n        import shutil\n        destination = backup_name(location)\n        shutil.copyfile(location, destination)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the configuration in the given file.", "response": "def save(self, filename=None):\n        \"\"\"\n        saves the configuration in the given filename,\n        if it is none the filename at load time is used.\n        :param filename: the file name\n        :type filename: string\n        :return:\n        \"\"\"\n        content = self.data.yaml()\n        with open(Config.path_expand(ConfigDict.filename), 'w') as f:\n            f.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef json(self, start=None):\n        if start is not None:\n            data = self.data[start]\n        return json.dumps(self.data, indent=4)", "response": "returns the dict in json format"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the username for a specified cloud. TODO: works currently only for opensatck. :param cloud: the name of the cloud :return:", "response": "def getUser(cls, cloud):\n        \"\"\"\n        gets the username for a specified cloud.\n        TODO: works currently only for opensatck.\n        :param cloud: the name of the cloud\n        :return: \n        \"\"\"\n        try:\n            config = d = ConfigDict(\"cloudmesh.yaml\")\n\n            d = ConfigDict(\"cloudmesh.yaml\")\n\n            #\n            # bug: cloud is none when adding a group\n            #\n\n            config = d[\"cloudmesh\"][\"clouds\"][cloud]\n            credentials = config[\"credentials\"]\n            cloud_type = config[\"cm_type\"]\n\n            if cloud_type == \"openstack\":\n                return credentials[\"OS_USERNAME\"]\n            else:\n                raise ValueError(\"getUser for this cloud type not yet \"\n                                 \"supported: {}\".format(cloud))\n        except Exception as ex:\n            Console.error(\"problem getting user\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the config file and makes sure the directory exists if it doesn t already exist.", "response": "def config_dir_setup(filename):\n    \"\"\"\n    sets the config file and makes sure the directory exists if it has not yet been created.\n    :param filename: \n    :return: \n    \"\"\"\n    path = os.path.dirname(filename)\n    if not os.path.isdir(path):\n        Shell.mkdir(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_python(cls):\n        python_version = sys.version_info[:3]\n        v_string = [str(i) for i in python_version]\n        python_version_s = '.'.join(v_string)\n\n        # pip_version = pip.__version__\n        pip_version = Shell.pip(\"--version\").split()[1]\n        return python_version_s, pip_version", "response": "returns the python version and pip version"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_python(cls):\n        python_version = sys.version_info[:3]\n\n        v_string = [str(i) for i in python_version]\n\n        if python_version[0] == 2:\n\n            python_version_s = '.'.join(v_string)\n            if (python_version[0] == 2) and (python_version[1] >= 7) and (\n                    python_version[2] >= 9):\n\n                print(\n                    \"You are running a supported version of python: {:}\".format(\n                        python_version_s))\n            else:\n                print(\n                    \"WARNING: You are running an unsupported version of python: {:}\".format(\n                        python_version_s))\n                print(\"         We recommend you update your python\")\n\n        elif python_version[0] == 3:\n\n            python_version_s = '.'.join(v_string)\n            if (python_version[0] == 3) and (python_version[1] >= 7) and (\n                    python_version[2] >= 0):\n\n                print(\n                    \"You are running a supported version of python: {:}\".format(\n                        python_version_s))\n            else:\n                print(\n                    \"WARNING: You are running an unsupported version of python: {:}\".format(\n                        python_version_s))\n                print(\"         We recommend you update your python\")\n\n        # pip_version = pip.__version__\n        python_version, pip_version = cls.get_python()\n\n        if int(pip_version.split(\".\")[0]) >= 18:\n            print(\"You are running a supported version of pip: \" + str(\n                pip_version))\n        else:\n            print(\"WARNING: You are running an old version of pip: \" + str(\n                pip_version))\n            print(\"         We recommend you update your pip  with \\n\")\n            print(\"             pip install -U pip\\n\")", "response": "Checks if the python version is supported by pip"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef VBoxManage(cls, *args):\n\n        if platform.system().lower() == \"darwin\":\n            command = \"/Applications/VirtualBox.app/Contents/MacOS/VBoxManage\"\n        else:\n            command = 'VBoxManage'\n        return cls.execute(command, args)", "response": "Executes the VBoxManage command with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting ping on a set of available cache entries", "response": "def ping(cls, host=None, count=1):\n        \"\"\"\n        execute ping\n        :param host: the host to ping \n        :param count: the number of pings\n        :return: \n        \"\"\"\n        option = '-n' if platform.system().lower() == 'windows' else '-c'\n        return cls.execute('ping',\n                           \"{option} {count} {host}\".format(option=option,\n                                                            count=count,\n                                                            host=host))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_line_with(cls, lines, what):\n        result = []\n        for line in lines:\n            if what not in line:\n                result = result + [line]\n        return result", "response": "returns all lines that do not contain what"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_lines_with(cls, lines, what):\n        result = []\n        for line in lines:\n            if what in line:\n                result = result + [line]\n        return result", "response": "returns all lines that contain what"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the executables in cygwin", "response": "def find_cygwin_executables(cls):\n        \"\"\"\n        find the executables in cygwin\n        \"\"\"\n        exe_paths = glob.glob(cls.cygwin_path + r'\\*.exe')\n        # print cls.cygwin_path\n        # list all *.exe in  cygwin path, use glob\n        for c in exe_paths:\n            exe = c.split('\\\\')\n            name = exe[1].split('.')[0]\n            # command['windows'][name] = \"{:}\\{:}.exe\".format(cygwin_path, c)\n            cls.command['windows'][name] = c"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the type of terminal that this system is running on.", "response": "def terminal_type(cls):\n        \"\"\"\n        returns  darwin, cygwin, cmd, or linux\n        \"\"\"\n        what = sys.platform\n\n        kind = 'UNDEFINED_TERMINAL_TYPE'\n        if 'linux' in what:\n            kind = 'linux'\n        elif 'darwin' in what:\n            kind = 'darwin'\n        elif 'cygwin' in what:\n            kind = 'cygwin'\n        elif 'windows' in what:\n            kind = 'windows'\n\n        return kind"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(cls,\n                cmd,\n                arguments=\"\",\n                shell=False,\n                cwd=None,\n                traceflag=True,\n                witherror=True):\n        \"\"\"Run Shell command\n\n        :param witherror: if set to False the error will not be printed\n        :param traceflag: if set to true the trace is printed in case of an error\n        :param cwd: the current working directory in whcih the command is supposed to be executed.\n        :param shell: if set to true the subprocess is called as part of a shell\n        :param cmd: command to run\n        :param arguments: we do not know yet\n        :return:\n        \"\"\"\n        # print \"--------------\"\n        result = None\n        terminal = cls.terminal_type()\n        # print cls.command\n        os_command = [cmd]\n        if terminal in ['linux', 'windows']:\n            os_command = [cmd]\n        elif 'cygwin' in terminal:\n            if not cls.command_exists(cmd):\n                print(\"ERROR: the command could not be found\", cmd)\n                return\n            else:\n                os_command = [cls.command[cls.operating_system()][cmd]]\n\n        if isinstance(arguments, list):\n            os_command = os_command + arguments\n        elif isinstance(arguments, tuple):\n            os_command = os_command + list(arguments)\n        elif isinstance(arguments, str):\n            os_command = os_command + arguments.split()\n        else:\n            print(\"ERROR: Wrong parameter type\", type(arguments))\n\n        if cwd is None:\n            cwd = os.getcwd()\n        try:\n            if shell:\n                result = subprocess.check_output(\n                    os_command,\n                    stderr=subprocess.STDOUT,\n                    shell=True,\n                    cwd=cwd)\n            else:\n                result = subprocess.check_output(\n                    os_command,\n                    # shell=True,\n                    stderr=subprocess.STDOUT,\n                    cwd=cwd)\n        except:\n            if witherror:\n                Console.error(\"problem executing subprocess\",\n                              traceflag=traceflag)\n        if result is not None:\n            result = result.strip().decode()\n        return result", "response": "Execute a command in the specified shell and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mkdir(cls, directory):\n        directory = path_expand(directory)\n        try:\n            os.makedirs(directory)\n        except OSError as e:\n\n            # EEXIST (errno 17) occurs under two conditions when the path exists:\n            # - it is a file\n            # - it is a directory\n            #\n            # if it is a file, this is a valid error, otherwise, all\n            # is fine.\n            if e.errno == errno.EEXIST and os.path.isdir(directory):\n                pass\n            else:\n                raise", "response": "Creates a directory with all its parents in ots name\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts the headers from the log file.", "response": "def _get_headers(self):\n        \"\"\"\n        assumes comment have been stripped with extract\n        :return:\n        \"\"\"\n\n        header = self.lines[0]\n        self.lines = self.lines[1:]\n\n        self.headers = \\\n            [self.clean(h) for h in header.split(self.seperator)]\n        if self.is_strip:\n            self.headers = self.headers[1:-1]\n        return self.headers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tempdir(*args, **kwargs):\n\n    d = tempfile.mkdtemp(*args, **kwargs)\n    try:\n        yield d\n    finally:\n        shutil.rmtree(d)", "response": "A contextmanager that creates a temporary directory and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exponential_backoff(fn, sleeptime_s_max=30 * 60):\n\n    sleeptime_ms = 500\n    while True:\n        if fn():\n            return True\n        else:\n            print('Sleeping {} ms'.format(sleeptime_ms))\n            time.sleep(sleeptime_ms / 1000.0)\n            sleeptime_ms *= 2\n\n        if sleeptime_ms / 1000.0 > sleeptime_s_max:\n            return False", "response": "Calls fn until it returns True with an exponential increasing wait time between calls"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search(lines, pattern):\n    p = pattern.replace(\"*\", \".*\")\n    test = re.compile(p)\n    result = []\n    for l in lines:\n        if test.search(l):\n            result.append(l)\n    return result", "response": "searches the lines in the sequence that match the pattern"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef grep(pattern, filename):\n    try:\n        # for line in file\n        # if line matches pattern:\n        #    return line\n        return next((L for L in open(filename) if L.find(pattern) >= 0))\n    except StopIteration:\n        return ''", "response": "Very simple grep that returns the first matching line in a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a string with expanded variable.", "response": "def path_expand(text):\n    \"\"\" returns a string with expanded variable.\n\n    :param text: the path to be expanded, which can include ~ and environment $ variables\n    :param text: string\n\n    \"\"\"\n    result = os.path.expandvars(os.path.expanduser(text))\n\n    # template = Template(text)\n    # result = template.substitute(os.environ)\n\n    if result.startswith(\".\"):\n        result = result.replace(\".\", os.getcwd(), 1)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_from_unicode(data):\n    # if isinstance(data, basestring):\n\n    if isinstance(data, str):\n        return str(data)\n    elif isinstance(data, collectionsAbc.Mapping):\n        return dict(map(convert_from_unicode, data.items()))\n    elif isinstance(data, collectionsAbc.Iterable):\n        return type(data)(map(convert_from_unicode, data))\n    else:\n        return data", "response": "converts unicode data to a string\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nasks for a yes or no question.", "response": "def yn_choice(message, default='y', tries=None):\n    \"\"\"asks for a yes/no question.\n\n    :param tries: the number of tries\n    :param message: the message containing the question\n    :param default: the default answer\n    \"\"\"\n    # http://stackoverflow.com/questions/3041986/python-command-line-yes-no-input\"\"\"\n    choices = 'Y/n' if default.lower() in ('y', 'yes') else 'y/N'\n    if tries is None:\n        choice = input(\"%s (%s) \" % (message, choices))\n        values = ('y', 'yes', '') if default == 'y' else ('y', 'yes')\n        return True if choice.strip().lower() in values else False\n    else:\n        while tries > 0:\n            choice = input(\n                \"%s (%s) (%s)\" % (message, choices, \"'q' to discard\"))\n            choice = choice.strip().lower()\n            if choice in ['y', 'yes']:\n                return True\n            elif choice in ['n', 'no', 'q']:\n                return False\n            else:\n                print(\"Invalid input...\")\n                tries -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef str_banner(txt=None, c=\"#\", debug=True):\n    line = \"\"\n    if debug:\n        line += \"\\n\"\n        line += \"# \" + str(70 * c)\n        if txt is not None:\n            line += \"# \" + txt\n            line += \"# \" + str(70 * c)\n    return line", "response": "returns a string that is a line of the text that is printed by the text_banner function"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef HEADING(txt=None, c=\"#\"):\n    frame = inspect.getouterframes(inspect.currentframe())\n\n    filename = frame[1][1].replace(os.getcwd(), \"\")\n    line = frame[1][2] - 1\n    method = frame[1][3]\n    msg = \"{}\\n# {} {} {}\".format(txt, method, filename, line)\n\n    print()\n    banner(msg, c=c)", "response": "Prints a message to stdout with a given header."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef backup_name(filename):\n    location = path_expand(filename)\n    n = 0\n    found = True\n    backup = None\n    while found:\n        n += 1\n        backup = \"{0}.bak.{1}\".format(location, n)\n        found = os.path.isfile(backup)\n    return backup", "response": "returns a backup name for the given filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a version number in the __init__.py file. it can be accessed with __version__ :param class_name: :param version: :param filename: :return:", "response": "def auto_create_version(class_name, version, filename=\"__init__.py\"):\n    \"\"\"\n    creates a version number in the __init__.py file.\n    it can be accessed with __version__\n    :param class_name: \n    :param version: \n    :param filename: \n    :return: \n    \"\"\"\n    version_filename = Path(\n        \"{classname}/{filename}\".format(classname=class_name,\n                                        filename=filename))\n    with open(version_filename, \"r\") as f:\n        content = f.read()\n\n    if content != '__version__ = \"{0}\"'.format(version):\n        banner(\"Updating version to {0}\".format(version))\n        with open(version_filename, \"w\") as text_file:\n            text_file.write('__version__ = \"{0:s}\"'.format(version))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the content of a file", "response": "def readfile(filename):\n    \"\"\"\n    returns the content of a file\n    :param filename: the filename\n    :return: \n    \"\"\"\n    with open(path_expand(filename), 'r') as f:\n        content = f.read()\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef writefile(filename, content):\n    with open(path_expand(filename), 'w') as outfile:\n        outfile.write(content)", "response": "writes the content into the file filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a password from a sequence of characters.", "response": "def generate_password(length=8, lower=True, upper=True, number=True):\n    \"\"\"\n    generates a simple password. We should not really use this in production.\n    :param length: the length of the password\n    :param lower: True of lower case characters are allowed\n    :param upper: True if upper case characters are allowed\n    :param number: True if numbers are allowed\n    :return: \n    \"\"\"\n    lletters = \"abcdefghijklmnopqrstuvwxyz\"\n    uletters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n    # This doesn't guarantee both lower and upper cases will show up\n    alphabet = lletters + uletters\n    digit = \"0123456789\"\n    mypw = \"\"\n\n    def _random_character(texts):\n        return texts[random.randrange(len(texts))]\n\n    if not lower:\n        alphabet = uletters\n    elif not upper:\n        alphabet = lletters\n\n    for i in range(length):\n        # last half length will be filled with numbers\n        if number and i >= int(length / 2):\n            mypw = mypw + _random_character(digit)\n        else:\n            mypw = mypw + _random_character(alphabet)\n    return mypw"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nidentifying if the file contains tabs and returns True if it contains tabs.", "response": "def check_file_for_tabs(filename, verbose=True):\n    \"\"\"identifies if the file contains tabs and returns True if it\n    does. It also prints the location of the lines and columns. If\n    verbose is set to False, the location is not printed.\n\n    :param verbose: if true prints information about issues\n    :param filename: the filename\n    :rtype: True if there are tabs in the file\n    \"\"\"\n    file_contains_tabs = False\n    with open(filename) as f:\n        lines = f.read().split(\"\\n\")\n\n    line_no = 1\n    for line in lines:\n        if \"\\t\" in line:\n            file_contains_tabs = True\n            location = [\n                i for i in range(len(line)) if line.startswith('\\t', i)]\n            if verbose:\n                Console.error(\"Tab found in line {} and column(s) {}\"\n                              .format(line_no,\n                                      str(location).replace(\"[\", \"\").replace(\n                                          \"]\", \"\")),\n                              traceflag=False)\n        line_no += 1\n    return file_contains_tabs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload an ordered dict into a yaml file preserving the order", "response": "def ordered_load(stream, Loader=yaml.Loader, object_pairs_hook=OrderedDict):\n    \"\"\"\n    Loads an ordered dict into a yaml while preserving the order\n\n    :param stream: the name of the stream\n    :param Loader: the yam loader (such as yaml.SafeLoader)\n    :param object_pairs_hook: the ordered dict\n    \"\"\"\n\n    # noinspection PyClassHasNoInit\n    class OrderedLoader(Loader):\n        \"\"\"\n        A helper class to define an Ordered Loader\n        \"\"\"\n        pass\n\n    def construct_mapping(loader, node):\n        \"\"\"\n        construct a flattened node mapping\n        :param loader: the loader\n        :param node: the node dict\n        :return: \n        \"\"\"\n        loader.flatten_mapping(node)\n        return object_pairs_hook(loader.construct_pairs(node))\n\n    OrderedLoader.add_constructor(\n        yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG,\n        construct_mapping)\n    return yaml.load(stream, OrderedLoader)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_yaml_config(filename, check=True, osreplace=True, exit=True):\n    location = filename\n    if location is not None:\n        location = path_expand(location)\n\n    if not os.path.exists(location) and not check:\n        return None\n\n    if check and os.path.exists(location):\n\n        # test for tab in yaml file\n        if check_file_for_tabs(location):\n            log.error(\"The file {0} contains tabs. yaml \"\n                      \"Files are not allowed to contain tabs\".format(location))\n            sys.exit()\n        result = None\n        try:\n\n            if osreplace:\n                result = open(location, 'r').read()\n                t = Template(result)\n                result = t.substitute(os.environ)\n\n                # data = yaml.safe_load(result)\n                data = ordered_load(result, yaml.SafeLoader)\n            else:\n                f = open(location, \"r\")\n\n                # data = yaml.safe_load(f)\n\n                data = ordered_load(result, yaml.SafeLoader)\n                f.close()\n\n            return data\n        except Exception as e:\n            log.error(\n                \"The file {0} fails with a yaml read error\".format(filename))\n            Error.traceback(e)\n            sys.exit()\n\n    else:\n        log.error(\"The file {0} does not exist.\".format(filename))\n        if exit:\n            sys.exit()\n\n    return None", "response": "Reads in a yaml file from the specified filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a given data structure such as a dict or ordered dict at a given indentation level", "response": "def custom_print(data_structure, indent):\n    \"\"\"\n    prints a given data structure such as a dict or ordered dict at a given indentation level\n    :param data_structure: \n    :param indent: \n    :return: \n    \"\"\"\n    for key, value in data_structure.items():\n        print(\"\\n%s%s:\" % (' ' * attribute_indent * indent, str(key)), end=' ')\n        if isinstance(value, OrderedDict):\n            custom_print(value, indent + 1)\n        elif isinstance(value, dict):\n            custom_print(value, indent + 1)\n        else:\n            print(\"%s\" % (str(value)), end=' ')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes the json object at given depth", "response": "def encode(self, o, depth=0):\n        \"\"\"\n        encode the json object at given depth\n        :param o: the object\n        :param depth: the depth\n        :return: the json encoding\n        \"\"\"\n        if isinstance(o, OrderedDict):\n            return \"{\" + \",\\n \".join([self.encode(k) + \":\" +\n                                      self.encode(v, depth + 1)\n                                      for (k, v) in o.items()]) + \"}\\n\"\n        else:\n            return simplejson.JSONEncoder.encode(self, o)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_meta(self):\n        for v in [\"filename\", \"location\", \"prefix\"]:\n            if \"meta\" not in self:\n                self[\"meta\"] = {}\n            self[\"meta\"][v] = self[v]\n            del self[v]", "response": "internal function to update the metadata of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the yaml file with the given filename.", "response": "def load(self, filename):\n        \"\"\"\n        Loads the yaml file with the given filename.\n\n        :param filename: the name of the yaml file\n        \"\"\"\n\n        self._set_filename(filename)\n\n        if os.path.isfile(self['location']):\n            # d = OrderedDict(read_yaml_config(self['location'], check=True))\n            d = read_yaml_config(self['location'], check=True)\n            with open(self['location']) as myfile:\n                document = myfile.read()\n            x = yaml.load(document, Loader=yaml.FullLoader)\n            try:\n                self.update(d)\n            except:\n                print(\"ERROR: can not find\", self[\"location\"])\n                sys.exit()\n        else:\n            print(\n                \"Error while reading and updating the configuration file {:}\".format(\n                    filename))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef error_keys_not_found(self, keys):\n        try:\n            log.error(\"Filename: {0}\".format(self['meta']['location']))\n        except:\n            log.error(\"Filename: {0}\".format(self['location']))\n        log.error(\"Key '{0}' does not exist\".format('.'.join(keys)))\n        indent = \"\"\n        last_index = len(keys) - 1\n        for i, k in enumerate(keys):\n            if i == last_index:\n                log.error(indent + k + \": <- this value is missing\")\n            else:\n                log.error(indent + k + \":\")\n            indent += \"    \"", "response": "Check if the requested keys are found in the dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef yaml(self):\n        return ordered_dump(OrderedDict(self),\n                            Dumper=yaml.SafeDumper,\n                            default_flow_style=False)", "response": "Returns the yaml output of the dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the value of the specified keys from the config file.", "response": "def get(self, *keys):\n        \"\"\"\n        returns the dict of the information as read from the yaml file. To\n        access the file safely, you can use the keys in the order of the\n        access.\n        Example: get(\"provisioner\",\"policy\") will return the value of\n        config[\"provisioner\"][\"policy\"] from the yaml file if it does not exists\n        an error will be printing that the value does not exists. Alternatively\n        you can use the . notation e.g. get(\"provisioner.policy\")\n        \"\"\"\n        if keys is None:\n            return self\n\n        if \".\" in keys[0]:\n            keys = keys[0].split('.')\n        element = self\n        for v in keys:\n            try:\n                element = element[v]\n            except KeyError:\n                self.error_keys_not_found(keys)\n                # sys.exit()\n        return element"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value of the key - value pairs in the dictionary.", "response": "def set(self, value, *keys):\n        \"\"\"\n        Sets the dict of the information as read from the yaml file. To access\n        the file safely, you can use the keys in the order of the access.\n        Example: set(\"{'project':{'fg82':[i0-i10]}}\", \"provisioner\",\"policy\")\n        will set the value of config[\"provisioner\"][\"policy\"] in the yaml file if\n        it does not exists an error will be printing that the value does not\n        exists.  Alternatively you can use the . notation e.g.\n        set(\"{'project':{'fg82':[i0-i10]}}\", \"provisioner.policy\")\n        \"\"\"\n        element = self\n\n        if keys is None:\n            return self\n\n        if '.' in keys[0]:\n            keys = keys[0].split(\".\")\n\n        nested_str = ''.join([\"['{0}']\".format(x) for x in keys])\n        # Safely evaluate an expression to see if it is one of the Python\n        # literal structures: strings, numbers, tuples, lists, dicts, booleans,\n        # and None. Quoted string will be used if it is none of these types.\n        try:\n            ast.literal_eval(str(value))\n            converted = str(value)\n        except ValueError:\n            converted = \"'\" + str(value) + \"'\"\n        exec(\"self\" + nested_str + \"=\" + converted)\n        return element"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attribute(self, keys):\n        if self['meta']['prefix'] is None:\n            k = keys\n        else:\n            k = self['meta']['prefix'] + \".\" + keys\n        return self.get(k)", "response": "get the attribute of the object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flatwrite(cls, table,\n                  order=None,\n                  header=None,\n                  output=\"table\",\n                  sort_keys=True,\n                  show_none=\"\",\n                  sep=\".\"\n                  ):\n        \"\"\"\n        writes the information given in the table\n        :param table: the table of values\n        :param order: the order of the columns\n        :param header: the header for the columns\n        :param output: the format (default is table, values are raw, csv, json, yaml, dict\n        :param sort_keys: if true the table is sorted\n        :param show_none: passed along to the list or dict printer\n        :param sep: uses sep as the separator for csv printer\n        :return:\n        \"\"\"\n\n        flat = flatten(table, sep=sep)\n\n        return Printer.write(flat,\n                             sort_keys=sort_keys,\n                             order=order,\n                             header=header,\n                             output=output)", "response": "Writes the information given in the table to the output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the information given in the table to the specified output", "response": "def write(cls, table,\n              order=None,\n              header=None,\n              output=\"table\",\n              sort_keys=True,\n              show_none=\"\"\n              ):\n        \"\"\"\n        writes the information given in the table\n        :param table: the table of values\n        :param order: the order of the columns\n        :param header: the header for the columns\n        :param output: the format (default is table, values are raw, csv, json, yaml, dict\n        :param sort_keys: if true the table is sorted\n        :param show_none: passed along to the list or dict printer\n        :return: \n        \"\"\"\n        if output == \"raw\":\n            return table\n        elif table is None:\n            return None\n        elif type(table) in [dict, dotdict]:\n            return cls.dict(table,\n                            order=order,\n                            header=header,\n                            output=output,\n                            sort_keys=sort_keys,\n                            show_none=show_none)\n\n        elif type(table) == list:\n\n            return cls.list(table,\n                            order=order, header=header, output=output,\n                            sort_keys=sort_keys, show_none=show_none)\n        else:\n            Console.error(\"unkown type {0}\".format(type(table)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(cls,\n             l,\n             order=None,\n             header=None,\n             output=\"table\",\n             sort_keys=True,\n             show_none=\"\"\n             ):\n        \"\"\"\n        :param l: l is a list not a dict\n        :param order:\n        :param header:\n        :param output:\n        :param sort_keys:\n        :param show_none:\n        :return:\n        \"\"\"\n        d = {}\n        count = 0\n        for entry in l:\n            name = str(count)\n            d[name] = entry\n            count += 1\n        return cls.dict(d,\n                        order=order,\n                        header=header,\n                        sort_keys=sort_keys,\n                        output=output,\n                        show_none=show_none)", "response": "list - returns a list of all the nacms related entries in a dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dict(cls,\n             d,\n             order=None,\n             header=None,\n             output=\"table\",\n             sort_keys=True,\n             show_none=\"\"):\n        \"\"\"\n        TODO\n        :param d: A a dict with dicts of the same type.\n        :type d: dict\n        :param order:The order in which the columns are printed.\n                    The order is specified by the key names of the dict.\n        :type order:\n        :param header: The Header of each of the columns\n        :type header: list or tuple of field names\n        :param output: type of output (table, csv, json, yaml or dict)\n        :type output: string\n        :param sort_keys:\n        :type sort_keys: bool\n        :param show_none: prints None if True for None values otherwise \"\"\n        :type show_none: bool\n        :return:\n        \"\"\"\n        if output == \"table\":\n            if d == {}:\n                return None\n            else:\n                return cls.dict_table(d,\n                                      order=order,\n                                      header=header,\n                                      sort_keys=sort_keys)\n        elif output == \"csv\":\n            return cls.csv(d,\n                           order=order,\n                           header=header,\n                           sort_keys=sort_keys)\n        elif output == \"json\":\n            return json.dumps(d, sort_keys=sort_keys, indent=4)\n        elif output == \"yaml\":\n            return yaml.dump(convert_from_unicode(d), default_flow_style=False)\n        elif output == \"dict\":\n            return d\n        else:\n            return \"UNKOWN FORMAT. Please use table, csv, json, yaml, dict.\"", "response": "Returns a dict representation of the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef csv(cls,\n            d,\n            order=None,\n            header=None,\n            sort_keys=True):\n        \"\"\"\n        prints a table in csv format\n\n        :param d: A a dict with dicts of the same type.\n        :type d: dict\n        :param order:The order in which the columns are printed.\n                    The order is specified by the key names of the dict.\n        :type order:\n        :param header: The Header of each of the columns\n        :type header: list or tuple of field names\n        :param sort_keys: TODO: not yet implemented\n        :type sort_keys: bool\n        :return: a string representing the table in csv format\n        \"\"\"\n        first_element = list(d)[0]\n\n        def _keys():\n            return list(d[first_element])\n\n        # noinspection PyBroadException\n        def _get(element, key):\n            try:\n                tmp = str(d[element][key])\n            except:\n                tmp = ' '\n            return tmp\n\n        if d is None or d == {}:\n            return None\n\n        if order is None:\n            order = _keys()\n\n        if header is None and order is not None:\n            header = order\n        elif header is None:\n            header = _keys()\n\n        table = \"\"\n        content = []\n        for attribute in order:\n            content.append(attribute)\n        table = table + \",\".join([str(e) for e in content]) + \"\\n\"\n\n        for job in d:\n            content = []\n            for attribute in order:\n                try:\n                    content.append(d[job][attribute])\n                except:\n                    content.append(\"None\")\n            table = table + \",\".join([str(e) for e in content]) + \"\\n\"\n        return table", "response": "Prints a table in csv format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting a pretty table from a dict of dicts", "response": "def dict_table(cls,\n                   d,\n                   order=None,\n                   header=None,\n                   sort_keys=True,\n                   show_none=\"\",\n                   max_width=40):\n        \"\"\"prints a pretty table from an dict of dicts\n        :param d: A a dict with dicts of the same type.\n                      Each key will be a column\n        :param order: The order in which the columns are printed.\n                      The order is specified by the key names of the dict.\n        :param header:  The Header of each of the columns\n        :type header:   A list of string\n        :param sort_keys:   Key(s) of the dict to be used for sorting.\n                            This specify the column(s) in the table for sorting.\n        :type sort_keys:    string or a tuple of string (for sorting with multiple columns)\n        :param show_none: prints None if True for None values otherwise \"\"\n        :type show_none: bool\n        :param max_width: maximum width for a cell\n        :type max_width: int\n        \"\"\"\n\n        def _keys():\n            all_keys = []\n            for e in d:\n                keys = d[e].keys()\n                all_keys.extend(keys)\n            return list(set(all_keys))\n\n        # noinspection PyBroadException\n        def _get(item, key):\n            try:\n                tmp = str(d[item][key])\n                if tmp == \"None\":\n                    tmp = show_none\n            except:\n                tmp = ' '\n            return tmp\n\n        if d is None or d == {}:\n            return None\n\n        if order is None:\n            order = _keys()\n\n        if header is None and order is not None:\n            header = order\n        elif header is None:\n            header = _keys()\n\n        x = PrettyTable(header)\n        x.max_width = max_width\n\n        if sort_keys:\n            if type(sort_keys) is str:\n                sorted_list = sorted(d, key=lambda x: d[x][sort_keys])\n            elif type(sort_keys) == tuple:\n                sorted_list = sorted(d, key=lambda x: tuple(\n                    [d[x][sort_key] for sort_key in sort_keys]))\n            else:\n                sorted_list = d\n        else:\n            sorted_list = d\n\n        for element in sorted_list:\n            values = []\n            for key in order:\n                values.append(_get(element, key))\n            x.add_row(values)\n        x.align = \"l\"\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints a list of attribute values", "response": "def attribute(cls,\n                  d,\n                  header=None,\n                  order=None,\n                  sort_keys=True,\n                  output=\"table\"):\n        \"\"\"prints a attribute/key value table \n         :param d: A a dict with dicts of the same type.\n                       Each key will be a column\n         :param order: The order in which the columns are printed.\n                       The order is specified by the key names of the dict.\n         :param header:  The Header of each of the columns\n         :type header:   A list of string\n         :param sort_keys:   Key(s) of the dict to be used for sorting.\n                             This specify the column(s) in the table for sorting.\n         :type sort_keys:    string or a tuple of string (for sorting with multiple columns)\n         :param output: the output format table, csv, dict, json\n         \"\"\"\n\n        if header is None:\n            header = [\"Attribute\", \"Value\"]\n        if output == \"table\":\n            x = PrettyTable(header)\n            if order is not None:\n                sorted_list = order\n            else:\n                sorted_list = list(d)\n            if sort_keys:\n                sorted_list = sorted(d)\n\n            for key in sorted_list:\n                if type(d[key]) == dict:\n                    values = d[key]\n                    x.add_row([key, \"+\"])\n                    for e in values:\n                        x.add_row([\"  -\", \"{}: {}\".format(e, values[e])])\n                elif type(d[key]) == list:\n                    values = list(d[key])\n                    x.add_row([key, \"+\"])\n                    for e in values:\n                        x.add_row([\"  -\", e])\n                else:\n                    x.add_row([key, d[key] or \"\"])\n\n            x.align = \"l\"\n            return x\n        else:\n            return cls.dict({output: d}, output=output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a list of n - items", "response": "def print_list(cls, l, output='table'):\n        \"\"\"\n        prints a list\n        :param l: the list\n        :param output: the output, default is a table\n        :return: \n        \"\"\"\n\n        def dict_from_list(l):\n            \"\"\"\n            returns a dict from a list for printing\n            :param l: the list\n            :return: \n            \"\"\"\n            d = dict([(idx, item) for idx, item in enumerate(l)])\n            return d\n\n        if output == 'table':\n            x = PrettyTable([\"Index\", \"Host\"])\n            for (idx, item) in enumerate(l):\n                x.add_row([idx, item])\n            x.align = \"l\"\n            x.align[\"Index\"] = \"r\"\n            return x\n        elif output == 'csv':\n            return \",\".join(l)\n        elif output == 'dict':\n            d = dict_from_list(l)\n            return d\n        elif output == 'json':\n            d = dict_from_list(l)\n            result = json.dumps(d, indent=4)\n            return result\n        elif output == 'yaml':\n            d = dict_from_list(l)\n            result = yaml.dump(d, default_flow_style=False)\n            return result\n        elif output == 'txt':\n            return \"\\n\".join(l)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints a pretty table from a dict", "response": "def row_table(cls, d, order=None, labels=None):\n        \"\"\"prints a pretty table from data in the dict.\n        :param d: A dict to be printed\n        :param order: The order in which the columns are printed.\n                      The order is specified by the key names of the dict.\n        :param labels: The array of labels for the column\n        \"\"\"\n        # header\n        header = list(d)\n        x = PrettyTable(labels)\n        if order is None:\n            order = header\n        for key in order:\n            value = d[key]\n            if type(value) == list:\n                x.add_row([key, value[0]])\n                for element in value[1:]:\n                    x.add_row([\"\", element])\n            elif type(value) == dict:\n                value_keys = list(value)\n                first_key = value_keys[0]\n                rest_keys = value_keys[1:]\n                x.add_row(\n                    [key, \"{0} : {1}\".format(first_key, value[first_key])])\n                for element in rest_keys:\n                    x.add_row([\"\", \"{0} : {1}\".format(element, value[element])])\n            else:\n                x.add_row([key, value])\n\n        x.align = \"l\"\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_fingerprint_from_public_key(pubkey):\n\n    # TODO: why is there a tmpdir?\n    with tempdir() as workdir:\n        key = os.path.join(workdir, 'key.pub')\n        with open(key, 'w') as fd:\n            fd.write(pubkey)\n\n        cmd = [\n            'ssh-keygen',\n            '-l',\n            '-f', key,\n        ]\n\n        p = Subprocess(cmd)\n        output = p.stdout.strip()\n        bits, fingerprint, _ = output.split(' ', 2)\n        return fingerprint", "response": "Generate the fingerprint of a public key"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(cls, path):\n        auth = cls()\n        with open(path) as fd:\n            for pubkey in itertools.imap(str.strip, fd):\n                # skip empty lines\n                if not pubkey:\n                    continue\n                auth.add(pubkey)\n        return auth", "response": "load the keys from a file path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a public key to the list", "response": "def add(self, pubkey):\n        \"\"\"\n        add a public key.\n        :param pubkey: the filename to the public key\n        :return: \n        \"\"\"\n        f = get_fingerprint_from_public_key(pubkey)\n        if f not in self._keys:\n            self._order[len(self._keys)] = f\n            self._keys[f] = pubkey"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating html and thumbnails for admin site.", "response": "def thumb(self, obj):\n        \"\"\"\n        Generates html and thumbnails for admin site.\n        \"\"\"\n        format, created = Format.objects.get_or_create(name='newman_thumb',\n                                                       defaults={\n            'max_width': 100,\n            'max_height': 100,\n            'flexible_height': False,\n            'stretch': False,\n            'nocrop': True,\n        })\n\n        if created:\n            format.sites = Site.objects.all()\n\n        info = obj.get_formated_photo(format)\n\n        return '<a href=\"%(href)s\"><img src=\"%(src)s\"></a>' % {\n            'href': '%s/' % obj.pk,\n            'src': info['url']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_pdb(pdbfile, outpath, as_string=False, outputprefix='report'):\n    if not as_string:\n        startmessage = '\\nStarting analysis of %s\\n' % pdbfile.split('/')[-1]\n    else:\n        startmessage = \"Starting analysis from stdin.\\n\"\n    write_message(startmessage)\n    write_message('='*len(startmessage)+'\\n')\n    mol = PDBComplex()\n    mol.output_path = outpath\n    mol.load_pdb(pdbfile, as_string=as_string)\n    # #@todo Offers possibility for filter function from command line (by ligand chain, position, hetid)\n    for ligand in mol.ligands:\n        mol.characterize_complex(ligand)\n\n    create_folder_if_not_exists(outpath)\n\n    # Generate the report files\n    streport = StructureReport(mol, outputprefix=outputprefix)\n\n    config.MAXTHREADS = min(config.MAXTHREADS, len(mol.interaction_sets))\n\n    ######################################\n    # PyMOL Visualization (parallelized) #\n    ######################################\n\n    if config.PYMOL or config.PICS:\n        try:\n            from plip.modules.visualize import visualize_in_pymol\n        except ImportError:\n            from modules.visualize import visualize_in_pymol\n        complexes = [VisualizerData(mol, site) for site in sorted(mol.interaction_sets)\n                     if not len(mol.interaction_sets[site].interacting_res) == 0]\n        if config.MAXTHREADS > 1:\n            write_message('\\nGenerating visualizations in parallel on %i cores ...' % config.MAXTHREADS)\n            parfn = parallel_fn(visualize_in_pymol)\n            parfn(complexes, processes=config.MAXTHREADS)\n        else:\n            [visualize_in_pymol(plcomplex) for plcomplex in complexes]\n\n    if config.XML:  # Generate report in xml format\n        streport.write_xml(as_string=config.STDOUT)\n\n    if config.TXT:  # Generate report in txt (rst) format\n        streport.write_txt(as_string=config.STDOUT)", "response": "This function will process a single PDB file and generate a textual report XML PyMOL session files and images as output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a PDB ID downloads the corresponding PDB structure. Returns the path of the downloaded file.", "response": "def download_structure(inputpdbid):\n    \"\"\"Given a PDB ID, downloads the corresponding PDB structure.\n    Checks for validity of ID and handles error while downloading.\n    Returns the path of the downloaded file.\"\"\"\n    try:\n        if len(inputpdbid) != 4 or extract_pdbid(inputpdbid.lower()) == 'UnknownProtein':\n            sysexit(3, 'Invalid PDB ID (Wrong format)\\n')\n        pdbfile, pdbid = fetch_pdb(inputpdbid.lower())\n        pdbpath = tilde_expansion('%s/%s.pdb' % (config.BASEPATH.rstrip('/'), pdbid))\n        create_folder_if_not_exists(config.BASEPATH)\n        with open(pdbpath, 'w') as g:\n            g.write(pdbfile)\n        write_message('file downloaded as %s\\n\\n' % pdbpath)\n        return pdbpath, pdbid\n\n    except ValueError:  # Invalid PDB ID, cannot fetch from RCBS server\n        sysexit(3, 'Invalid PDB ID (Entry does not exist)\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck input lists for duplicates and returns a list with unique entries", "response": "def remove_duplicates(slist):\n    \"\"\"Checks input lists for duplicates and returns\n    a list with unique entries\"\"\"\n    unique = list(set(slist))\n    difference = len(slist) - len(unique)\n    if difference == 1:\n        write_message(\"Removed one duplicate entry from input list.\\n\")\n    if difference > 1:\n        write_message(\"Removed %i duplicate entries from input list.\\n\" % difference)\n    return unique"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses command line arguments and start main script for analysis.", "response": "def main_init():\n    \"\"\"Parse command line arguments and start main script for analysis.\"\"\"\n    parser = ArgumentParser(prog=\"PLIP\", description=descript)\n    pdbstructure = parser.add_mutually_exclusive_group(required=True)  # Needs either PDB ID or file\n    # '-' as file name reads from stdin\n    pdbstructure.add_argument(\"-f\", \"--file\", dest=\"input\", nargs=\"+\", help=\"Set input file, '-' reads from stdin\")\n    pdbstructure.add_argument(\"-i\", \"--input\", dest=\"pdbid\", nargs=\"+\")\n    outputgroup = parser.add_mutually_exclusive_group(required=False)  # Needs either outpath or stdout\n    outputgroup.add_argument(\"-o\", \"--out\", dest=\"outpath\", default=\"./\")\n    outputgroup.add_argument(\"-O\", \"--stdout\", dest=\"stdout\", action=\"store_true\", default=False, help=\"Write to stdout instead of file\")\n    parser.add_argument(\"--rawstring\", dest=\"use_raw_string\", default=False, action=\"store_true\", help=\"Use Python raw strings for stdout and stdin\")\n    parser.add_argument(\"-v\", \"--verbose\", dest=\"verbose\", default=False, help=\"Set verbose mode\", action=\"store_true\")\n    parser.add_argument(\"-p\", \"--pics\", dest=\"pics\", default=False, help=\"Additional pictures\", action=\"store_true\")\n    parser.add_argument(\"-x\", \"--xml\", dest=\"xml\", default=False, help=\"Generate report file in XML format\",\n                        action=\"store_true\")\n    parser.add_argument(\"-t\", \"--txt\", dest=\"txt\", default=False, help=\"Generate report file in TXT (RST) format\",\n                        action=\"store_true\")\n    parser.add_argument(\"-y\", \"--pymol\", dest=\"pymol\", default=False, help=\"Additional PyMOL session files\",\n                        action=\"store_true\")\n    parser.add_argument(\"--maxthreads\", dest=\"maxthreads\", default=multiprocessing.cpu_count(),\n                        help=\"Set maximum number of main threads (number of binding sites processed simultaneously).\"\n                             \"If not set, PLIP uses all available CPUs if possible.\",\n                        type=int)\n    parser.add_argument(\"--breakcomposite\", dest=\"breakcomposite\", default=False,\n                        help=\"Don't combine ligand fragments with covalent bonds but treat them as single ligands for the analysis.\",\n                        action=\"store_true\")\n    parser.add_argument(\"--altlocation\", dest=\"altlocation\", default=False,\n                        help=\"Also consider alternate locations for atoms (e.g. alternate conformations).\",\n                        action=\"store_true\")\n    parser.add_argument(\"--debug\", dest=\"debug\", default=False,\n                        help=\"Turn on DEBUG mode with extended log.\",\n                        action=\"store_true\")\n    parser.add_argument(\"--nofix\", dest=\"nofix\", default=False,\n                        help=\"Turns off fixing of PDB files.\",\n                        action=\"store_true\")\n    parser.add_argument(\"--nofixfile\", dest=\"nofixfile\", default=False,\n                        help=\"Turns off writing files for fixed PDB files.\",\n                        action=\"store_true\")\n    parser.add_argument(\"--nopdbcanmap\", dest=\"nopdbcanmap\", default=False,\n                        help=\"Turns off calculation of mapping between canonical and PDB atom order for ligands.\",\n                        action=\"store_true\")\n    parser.add_argument(\"--dnareceptor\", dest=\"dnareceptor\", default=False,\n                        help=\"Uses the DNA instead of the protein as a receptor for interactions.\",\n                        action=\"store_true\")\n    parser.add_argument(\"--name\", dest=\"outputfilename\", default=\"report\",\n                        help=\"Set a filename for the report TXT and XML files. Will only work when processing single structures.\")\n    ligandtype = parser.add_mutually_exclusive_group()  # Either peptide/inter or intra mode\n    ligandtype.add_argument(\"--peptides\", \"--inter\", dest=\"peptides\", default=[],\n                        help=\"Allows to define one or multiple chains as peptide ligands or to detect inter-chain contacts\",\n                        nargs=\"+\")\n    ligandtype.add_argument(\"--intra\", dest=\"intra\", help=\"Allows to define one chain to analyze intra-chain contacts.\")\n    parser.add_argument(\"--keepmod\", dest=\"keepmod\", default=False,\n                        help=\"Keep modified residues as ligands\",\n                        action=\"store_true\")\n    # Optional threshold arguments, not shown in help\n    thr = namedtuple('threshold', 'name type')\n    thresholds = [thr(name='aromatic_planarity', type='angle'),\n                  thr(name='hydroph_dist_max', type='distance'), thr(name='hbond_dist_max', type='distance'),\n                  thr(name='hbond_don_angle_min', type='angle'), thr(name='pistack_dist_max', type='distance'),\n                  thr(name='pistack_ang_dev', type='other'), thr(name='pistack_offset_max', type='distance'),\n                  thr(name='pication_dist_max', type='distance'), thr(name='saltbridge_dist_max', type='distance'),\n                  thr(name='halogen_dist_max', type='distance'), thr(name='halogen_acc_angle', type='angle'),\n                  thr(name='halogen_don_angle', type='angle'), thr(name='halogen_angle_dev', type='other'),\n                  thr(name='water_bridge_mindist', type='distance'), thr(name='water_bridge_maxdist', type='distance'),\n                  thr(name='water_bridge_omega_min', type='angle'), thr(name='water_bridge_omega_max', type='angle'),\n                  thr(name='water_bridge_theta_min', type='angle')]\n    for t in thresholds:\n        parser.add_argument('--%s' % t.name, dest=t.name, type=lambda val: threshold_limiter(parser, val),\n                            help=argparse.SUPPRESS)\n\n    arguments = parser.parse_args()\n    config.VERBOSE = True if (arguments.verbose or arguments.debug) else False\n    config.DEBUG = True if arguments.debug else False\n    config.MAXTHREADS = arguments.maxthreads\n    config.XML = arguments.xml\n    config.TXT = arguments.txt\n    config.PICS = arguments.pics\n    config.PYMOL = arguments.pymol\n    config.STDOUT = arguments.stdout\n    config.RAWSTRING = arguments.use_raw_string\n    config.OUTPATH = arguments.outpath\n    config.OUTPATH = tilde_expansion(\"\".join([config.OUTPATH, '/'])\n                                     if not config.OUTPATH.endswith('/') else config.OUTPATH)\n    config.BASEPATH = config.OUTPATH  # Used for batch processing\n    config.BREAKCOMPOSITE = arguments.breakcomposite\n    config.ALTLOC = arguments.altlocation\n    config.PEPTIDES = arguments.peptides\n    config.INTRA = arguments.intra\n    config.NOFIX = arguments.nofix\n    config.NOFIXFILE = arguments.nofixfile\n    config.NOPDBCANMAP = arguments.nopdbcanmap\n    config.KEEPMOD = arguments.keepmod\n    config.DNARECEPTOR = arguments.dnareceptor\n    config.OUTPUTFILENAME = arguments.outputfilename\n    # Make sure we have pymol with --pics and --pymol\n    if config.PICS or config.PYMOL:\n        try:\n            import pymol\n        except ImportError:\n            write_message(\"PyMOL is required for --pics and --pymol.\\n\", mtype='error')\n            raise\n    # Assign values to global thresholds\n    for t in thresholds:\n        tvalue = getattr(arguments, t.name)\n        if tvalue is not None:\n            if t.type == 'angle' and not 0 < tvalue < 180:  # Check value for angle thresholds\n                parser.error(\"Threshold for angles need to have values within 0 and 180.\")\n            if t.type == 'distance':\n                if tvalue > 10:  # Check value for angle thresholds\n                    parser.error(\"Threshold for distances must not be larger than 10 Angstrom.\")\n                elif tvalue > config.BS_DIST + 1:  # Dynamically adapt the search space for binding site residues\n                    config.BS_DIST = tvalue + 1\n            setattr(config, t.name.upper(), tvalue)\n    # Check additional conditions for interdependent thresholds\n    if not config.HALOGEN_ACC_ANGLE > config.HALOGEN_ANGLE_DEV:\n        parser.error(\"The halogen acceptor angle has to be larger than the halogen angle deviation.\")\n    if not config.HALOGEN_DON_ANGLE > config.HALOGEN_ANGLE_DEV:\n        parser.error(\"The halogen donor angle has to be larger than the halogen angle deviation.\")\n    if not config.WATER_BRIDGE_MINDIST < config.WATER_BRIDGE_MAXDIST:\n        parser.error(\"The water bridge minimum distance has to be smaller than the water bridge maximum distance.\")\n    if not config.WATER_BRIDGE_OMEGA_MIN < config.WATER_BRIDGE_OMEGA_MAX:\n        parser.error(\"The water bridge omega minimum angle has to be smaller than the water bridge omega maximum angle\")\n    expanded_path = tilde_expansion(arguments.input) if arguments.input is not None else None\n    main(expanded_path, arguments.pdbid)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate that the crop coordinates fit into the source photo and the format.", "response": "def clean(self):\n        \"\"\"\n        Validation function that checks the dimensions of the crop whether it fits into the original and the format.\n        \"\"\"\n        data = self.cleaned_data\n        photo = data['photo']\n        if (\n            (data['crop_left'] > photo.width) or\n            (data['crop_top'] > photo.height) or\n            ((data['crop_left'] + data['crop_width']) > photo.width) or\n            ((data['crop_top'] + data['crop_height']) > photo.height)\n        ):\n            # raise forms.ValidationError, ugettext(\"The specified crop coordinates do not fit into the source photo.\")\n            raise ValidationError(ugettext(\"The specified crop coordinates do not fit into the source photo.\"))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clean(self):\n\n        data = self.cleaned_data\n        formats = Format.objects.filter(name=data['name'])\n        if self.instance:\n            formats = formats.exclude(pk=self.instance.pk)\n\n        exists_sites = []\n        for f in formats:\n            for s in f.sites.all():\n                if s in data['sites']:\n                    exists_sites.append(s.__unicode__())\n\n        if len(exists_sites):\n            raise ValidationError(ugettext(\"Format with this name exists for site(s): %s\" % \", \".join(exists_sites)))\n\n        return data", "response": "Check format name uniqueness for sites\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses in admin image crop tool.", "response": "def format_photo_json(self, request, photo, format):\n        \"Used in admin image 'crop tool'.\"\n        try:\n            photo = get_cached_object(Photo, pk=photo)\n            format = get_cached_object(Format, pk=format)\n            content = {\n                'error': False,\n                'image':settings.MEDIA_URL + photo.image,\n                'width':photo.width,\n                'height': photo.height,\n                'format_width':format.max_width,\n                'format_height':format.max_height\n            }\n        except (Photo.DoesNotExist, Format.DoesNotExist):\n            content = {'error':True}\n        return HttpResponse(simplejson.dumps(content))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_initial_representations(self):\n        self.update_model_dict()\n        self.rc(\"background solid white\")\n        self.rc(\"setattr g display 0\")  # Hide all pseudobonds\n        self.rc(\"~display #%i & :/isHet & ~:%s\" % (self.model_dict[self.plipname], self.hetid))", "response": "Set the initial representations of the hierarchy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the model dictionary with the current set of open models.", "response": "def update_model_dict(self):\n        \"\"\"Updates the model dictionary\"\"\"\n        dct = {}\n        models = self.chimera.openModels\n        for md in models.list():\n            dct[md.name] = md.id\n        self.model_dict = dct"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprovide a dictionary mapping serial numbers to their atom objects.", "response": "def atom_by_serialnumber(self):\n        \"\"\"Provides a dictionary mapping serial numbers to their atom objects.\"\"\"\n        atm_by_snum = {}\n        for atom in self.model.atoms:\n            atm_by_snum[atom.serialNumber] = atom\n        return atm_by_snum"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvisualizes pi - stacking interactions.", "response": "def show_stacking(self):\n        \"\"\"Visualizes pi-stacking interactions.\"\"\"\n        grp = self.getPseudoBondGroup(\"pi-Stacking-%i\" % self.tid, associateWith=[self.model])\n        grp.lineWidth = 3\n        grp.lineType = self.chimera.Dash\n        for i, stack in enumerate(self.plcomplex.pistacking):\n\n            m = self.model\n            r = m.newResidue(\"pseudoatoms\", \" \", 1, \" \")\n            centroid_prot = m.newAtom(\"CENTROID\", self.chimera.Element(\"CENTROID\"))\n            x, y, z = stack.proteinring_center\n            centroid_prot.setCoord(self.chimera.Coord(x, y, z))\n            r.addAtom(centroid_prot)\n\n            centroid_lig = m.newAtom(\"CENTROID\", self.chimera.Element(\"CENTROID\"))\n            x, y, z = stack.ligandring_center\n            centroid_lig.setCoord(self.chimera.Coord(x, y, z))\n            r.addAtom(centroid_lig)\n\n            b = grp.newPseudoBond(centroid_lig, centroid_prot)\n            b.color = self.colorbyname('forest green')\n\n            self.bs_res_ids += stack.proteinring_atoms"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_cationpi(self):\n        grp = self.getPseudoBondGroup(\"Cation-Pi-%i\" % self.tid, associateWith=[self.model])\n        grp.lineWidth = 3\n        grp.lineType = self.chimera.Dash\n        for i, cat in enumerate(self.plcomplex.pication):\n\n            m = self.model\n            r = m.newResidue(\"pseudoatoms\", \" \", 1, \" \")\n            chargecenter = m.newAtom(\"CHARGE\", self.chimera.Element(\"CHARGE\"))\n            x, y, z = cat.charge_center\n            chargecenter.setCoord(self.chimera.Coord(x, y, z))\n            r.addAtom(chargecenter)\n\n            centroid = m.newAtom(\"CENTROID\", self.chimera.Element(\"CENTROID\"))\n            x, y, z = cat.ring_center\n            centroid.setCoord(self.chimera.Coord(x, y, z))\n            r.addAtom(centroid)\n\n            b = grp.newPseudoBond(centroid, chargecenter)\n            b.color = self.colorbyname('orange')\n\n            if cat.protcharged:\n                self.bs_res_ids += cat.charge_atoms\n            else:\n                self.bs_res_ids += cat.ring_atoms", "response": "Visualizes cation - pi interactions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncleaning up the visualization.", "response": "def cleanup(self):\n        \"\"\"Clean up the visualization.\"\"\"\n\n        if not len(self.water_ids) == 0:\n            # Hide all non-interacting water molecules\n            water_selection = []\n            for wid in self.water_ids:\n                water_selection.append('serialNumber=%i' % wid)\n            self.rc(\"~display :HOH\")\n            self.rc(\"display :@/%s\" % \" or \".join(water_selection))\n\n        # Show all interacting binding site residues\n        self.rc(\"~display #%i & ~:/isHet\" % self.model_dict[self.plipname])\n        self.rc(\"display :%s\" % \",\".join([str(self.atoms[bsid].residue.id) for bsid in self.bs_res_ids]))\n        self.rc(\"color lightblue :HOH\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zoom_to_ligand(self):\n        self.rc(\"center #%i & :%s\" % (self.model_dict[self.plipname], self.hetid))", "response": "Centers the view on the ligand and its binding site residues."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetail for the visualization.", "response": "def refinements(self):\n        \"\"\"Details for the visualization.\"\"\"\n        self.rc(\"setattr a color gray @CENTROID\")\n        self.rc(\"setattr a radius 0.3 @CENTROID\")\n        self.rc(\"represent sphere @CENTROID\")\n        self.rc(\"setattr a color orange @CHARGE\")\n        self.rc(\"setattr a radius 0.4 @CHARGE\")\n        self.rc(\"represent sphere @CHARGE\")\n        self.rc(\"display :pseudoatoms\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef forwards(self, orm):\n        \"Write your forwards methods here.\"\n        if not db.dry_run:\n            for pl in orm['core.Placement'].objects.all():\n                pl.listing_set.update(publishable=pl.publishable)\n                publishable = pl.publishable\n                publishable.publish_from = pl.publish_from\n                publishable.static = pl.static\n                publishable.publish_to = pl.publish_to\n                publishable.save(force_update=True)", "response": "Write your forwards methods here."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format(self):\n        if hasattr(self.image, '_getexif'):\n            self.rotate_exif()\n        crop_box = self.crop_to_ratio()\n        self.resize()\n        return self.image, crop_box", "response": "Return the image and crop_box used."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_format(self):\n        f = self.fmt\n\n        if f.flexible_height and f.flexible_max_height:\n            flexw, flexh = self.fw, f.flexible_max_height\n            flex_ratio = float(flexw) / flexh\n\n            if abs(flex_ratio - self.image_ratio) < abs(self.format_ratio - self.image_ratio):\n                self.fh = flexh\n                self.format_ratio = flex_ratio", "response": "Set the format of the image."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets coordinates of the rectangle defining the new image boundaries.", "response": "def get_crop_box(self):\n        \"\"\"\n        Get coordinates of the rectangle defining the new image boundaries. It\n        takes into acount any specific wishes from the model (explicitely\n        passed in crop_box), the desired format and it's options\n        (flexible_height, nocrop) and mainly it's ratio. After dimensions of\n        the format were specified (see set_format), crop the image to the same\n        ratio.\n        \"\"\"\n\n        # check if the flexible height option is active and applies\n        self.set_format()\n\n\n        if self.fmt.nocrop:\n            # cropping not allowed\n            return\n\n        if self.crop_box:\n            # crop coordinates passed in explicitely\n            return self.crop_box\n\n        iw, ih = self.image.size\n\n        if iw <= self.fw and ih <= self.fh:\n            # image fits in the target format, no need to crop\n            return\n\n        if self.image_ratio < self.format_ratio:\n            # image taller than format\n            diff = ih - (iw * self.fh / self.fw)\n            return (0, diff // 2 , iw, ih - diff // 2)\n\n        elif self.image_ratio > self.format_ratio:\n            # image wider than format\n            diff = iw - (ih * self.fw / self.fh)\n            return (diff // 2, 0, iw - diff // 2, ih)\n\n        else:\n            # same ratio as format\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef center_important_part(self, crop_box):\n        if not self.important_box:\n            return crop_box\n\n        # shortcuts\n        ib = self.important_box\n        cl, ct, cr, cb = crop_box\n        iw, ih = self.image.size\n\n        # compute the move of crop center onto important center\n        move_horiz = (ib[0] + ib[2]) // 2 - (cl + cr) // 2\n        move_verti = (ib[1] + ib[3]) // 2 - (ct + cb) // 2\n\n        # make sure we don't get out of the image\n        # ... horizontaly\n        if move_horiz > 0:\n            move_horiz = min(iw - cr, move_horiz)\n        else:\n            move_horiz = max(-cl, move_horiz)\n\n        # .. and verticaly\n        if move_verti > 0:\n            move_verti = min(ih - cb, move_verti)\n        else:\n            move_verti = max(-ct, move_verti)\n\n        # move the crop_box\n        return (cl + move_horiz, ct + move_verti, cr + move_horiz, cb + move_verti)", "response": "Return the center of the important part of the image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting crop coordinates and perform the crop if we get any.", "response": "def crop_to_ratio(self):\n        \" Get crop coordinates and perform the crop if we get any. \"\n        crop_box = self.get_crop_box()\n\n        if not crop_box:\n            return\n\n        crop_box = self.center_important_part(crop_box)\n\n        iw, ih = self.image.size\n        # see if we want to crop something from outside of the image\n        out_of_photo = min(crop_box[0], crop_box[1]) < 0 or crop_box[2] > iw or crop_box[3] > ih\n        # check whether there's transparent information in the image\n        transparent = self.image.mode in ('RGBA', 'LA')\n\n        if photos_settings.DEFAULT_BG_COLOR != 'black' and out_of_photo and not transparent:\n            # if we do, just crop the image to the portion that will be visible\n            updated_crop_box = (\n                max(0, crop_box[0]), max(0, crop_box[1]), min(iw, crop_box[2]), min(ih, crop_box[3]),\n            )\n            cropped = self.image.crop(updated_crop_box)\n\n            # create new image of the proper size and color\n            self.image = Image.new('RGB', (crop_box[2] - crop_box[0], crop_box[3] - crop_box[1]), photos_settings.DEFAULT_BG_COLOR)\n            # and paste the cropped part into it's proper position\n            self.image.paste(cropped, (abs(min(crop_box[0], 0)), abs(min(crop_box[1], 0))))\n        else:\n            # crop normally if not the case\n            self.image = self.image.crop(crop_box)\n        return crop_box"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget target size for a cropped image and do the resizing if we got anything usable.", "response": "def resize(self):\n        \"\"\"\n        Get target size for a cropped image and do the resizing if we got\n        anything usable.\n        \"\"\"\n        resized_size = self.get_resized_size()\n        if not resized_size:\n            return\n\n        self.image = self.image.resize(resized_size, Image.ANTIALIAS)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrotating image via exif information.", "response": "def rotate_exif(self):\n        \"\"\"\n        Rotate image via exif information.\n        Only 90, 180 and 270 rotations are supported.\n        \"\"\"\n        exif = self.image._getexif() or {}\n        rotation = exif.get(TAGS['Orientation'], 1)\n\n        rotations = {\n            6: -90,\n            3: -180,\n            8: -270,\n        }\n        if rotation not in rotations:\n            return\n\n        self.image = self.image.rotate(rotations[rotation])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvisualizing the protein - ligand pliprofiler at one site in PyMOL.", "response": "def visualize_in_pymol(plcomplex):\n    \"\"\"Visualizes the protein-ligand pliprofiler at one site in PyMOL.\"\"\"\n\n    vis = PyMOLVisualizer(plcomplex)\n\n    #####################\n    # Set everything up #\n    #####################\n\n    pdbid = plcomplex.pdbid\n    lig_members = plcomplex.lig_members\n    chain = plcomplex.chain\n    if config.PEPTIDES != []:\n        vis.ligname = 'PeptideChain%s' % plcomplex.chain\n    if config.INTRA is not None:\n        vis.ligname = 'Intra%s' % plcomplex.chain\n\n    ligname = vis.ligname\n    hetid = plcomplex.hetid\n\n    metal_ids = plcomplex.metal_ids\n    metal_ids_str = '+'.join([str(i) for i in metal_ids])\n\n    ########################\n    # Basic visualizations #\n    ########################\n\n    start_pymol(run=True, options='-pcq', quiet=not config.DEBUG)\n    vis.set_initial_representations()\n\n    cmd.load(plcomplex.sourcefile)\n    current_name = cmd.get_object_list(selection='(all)')[0]\n    write_message('Setting current_name to \"%s\" and pdbid to \"%s\\n\"' % (current_name, pdbid), mtype='debug')\n    cmd.set_name(current_name, pdbid)\n    cmd.hide('everything', 'all')\n    if config.PEPTIDES != []:\n        cmd.select(ligname, 'chain %s and not resn HOH' % plcomplex.chain)\n    else:\n        cmd.select(ligname, 'resn %s and chain %s and resi %s*' % (hetid, chain, plcomplex.position))\n    write_message(\"Selecting ligand for PDBID %s and ligand name %s with: \" % (pdbid, ligname), mtype='debug')\n    write_message('resn %s and chain %s and resi %s*' % (hetid, chain, plcomplex.position), mtype='debug')\n\n    # Visualize and color metal ions if there are any\n    if not len(metal_ids) == 0:\n        vis.select_by_ids(ligname, metal_ids, selection_exists=True)\n        cmd.show('spheres', 'id %s and %s' % (metal_ids_str, pdbid))\n\n    # Additionally, select all members of composite ligands\n    if len(lig_members) > 1:\n        for member in lig_members:\n           resid, chain, resnr = member[0], member[1], str(member[2])\n           cmd.select(ligname, '%s or (resn %s and chain %s and resi %s)' % (ligname, resid, chain, resnr))\n\n    cmd.show('sticks', ligname)\n    cmd.color('myblue')\n    cmd.color('myorange', ligname)\n    cmd.util.cnc('all')\n    if not len(metal_ids) == 0:\n        cmd.color('hotpink', 'id %s' % metal_ids_str)\n        cmd.hide('sticks', 'id %s' % metal_ids_str)\n        cmd.set('sphere_scale', 0.3, ligname)\n    cmd.deselect()\n\n    vis.make_initial_selections()\n\n    vis.show_hydrophobic()  # Hydrophobic Contacts\n    vis.show_hbonds()  # Hydrogen Bonds\n    vis.show_halogen()  # Halogen Bonds\n    vis.show_stacking()  # pi-Stacking Interactions\n    vis.show_cationpi()  # pi-Cation Interactions\n    vis.show_sbridges()  # Salt Bridges\n    vis.show_wbridges()  # Water Bridges\n    vis.show_metal()  # Metal Coordination\n\n    vis.refinements()\n\n    vis.zoom_to_ligand()\n\n    vis.selections_cleanup()\n\n    vis.selections_group()\n    vis.additional_cleanup()\n    if config.DNARECEPTOR:\n        # Rename Cartoon selection to Line selection and change repr.\n        cmd.set_name('%sCartoon' % plcomplex.pdbid, '%sLines' % plcomplex.pdbid)\n        cmd.hide('cartoon', '%sLines' % plcomplex.pdbid)\n        cmd.show('lines', '%sLines' % plcomplex.pdbid)\n\n    if config.PEPTIDES != []:\n        filename = \"%s_PeptideChain%s\" % (pdbid.upper(), plcomplex.chain)\n        if config.PYMOL:\n            vis.save_session(config.OUTPATH, override=filename)\n    elif config.INTRA is not None:\n        filename = \"%s_IntraChain%s\" % (pdbid.upper(), plcomplex.chain)\n        if config.PYMOL:\n            vis.save_session(config.OUTPATH, override=filename)\n    else:\n        filename = '%s_%s' % (pdbid.upper(), \"_\".join([hetid, plcomplex.chain, plcomplex.position]))\n        if config.PYMOL:\n            vis.save_session(config.OUTPATH)\n    if config.PICS:\n        vis.save_picture(config.OUTPATH, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a ContentType object based on its slugified verbose_name_plural.", "response": "def get_content_type(ct_name):\n    \"\"\"\n    A helper function that returns ContentType object based on its slugified verbose_name_plural.\n\n    Results of this function is cached to improve performance.\n\n    :Parameters:\n        - `ct_name`:  Slugified verbose_name_plural of the target model.\n\n    :Exceptions:\n        - `Http404`: if no matching ContentType is found\n    \"\"\"\n    try:\n        ct = CONTENT_TYPE_MAPPING[ct_name]\n    except KeyError:\n        for model in models.get_models():\n            if ct_name == slugify(model._meta.verbose_name_plural):\n                ct = ContentType.objects.get_for_model(model)\n                CONTENT_TYPE_MAPPING[ct_name] = ct\n                break\n        else:\n            raise Http404\n    return ct"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of templates for a given content type and slug.", "response": "def get_templates(name, slug=None, category=None, app_label=None, model_label=None):\n    \"\"\"\n    Returns templates in following format and order:\n\n    * ``'page/category/%s/content_type/%s.%s/%s/%s' % (<CATEGORY_PART>, app_label, model_label, slug, name)``\n    * ``'page/category/%s/content_type/%s.%s/%s' % (<CATEGORY_PART>, app_label, model_label, name)``\n    * ``'page/category/%s/%s' % (<CATEGORY_PART>, name)``\n    * ``'page/content_type/%s.%s/%s' % (app_label, model_label, name)``\n    * ``'page/%s' % name``\n\n    Where ``<CATEGORY_PART>`` is derived from ``path`` attribute by these rules:\n\n    * When **no** parent exists (this is therfore root category) ``<CATEGORY_PART> = path``\n    * When exactly **one** parent exists: ``<CATEGORY_PART> = path``\n    * When multiple parent exist (category nestedN is deep in the tree)::\n\n          <CATEGORY_PART> = (\n              'nested1/nested2/../nestedN/',\n              'nested1/nested2/../nestedN-1/',\n              ...\n              'nested1'\n          )\n\n    Examples. Three categories exist having slugs **ROOT**, **NESTED1**,\n    **NESTED2** where **NESTED2**'s parent is **NESTED1**.::\n\n        ROOT\n           \\\n         NESTED1\n             \\\n            NESTED2\n\n    * For **ROOT**, ``<CATEGORY_PART>`` is only one - \"ROOT\".\n    * For **NESTED1**, ``<CATEGORY_PART>`` is only one - \"NESTED1\".\n    * For **NESTED2**, ``<CATEGORY_PART>`` has two elements: \"NESTED1/NESTED2\" and \"NESTED1\".\n    \"\"\"\n    def category_templates(category, incomplete_template, params):\n        paths = []\n        parts = category.path.split('/')\n        for i in reversed(range(1, len(parts) + 1)):\n            params.update({'pth': '/'.join(parts[:i])})\n            paths.append(incomplete_template % params)\n        return paths\n\n    FULL = 'page/category/%(pth)s/content_type/%(app_label)s.%(model_label)s/%(slug)s/%(name)s'\n    FULL_NO_SLUG = 'page/category/%(pth)s/content_type/%(app_label)s.%(model_label)s/%(name)s'\n    BY_CATEGORY = 'page/category/%(pth)s/%(name)s'\n    BY_CONTENT_TYPE = 'page/content_type/%(app_label)s.%(model_label)s/%(name)s'\n\n    templates = []\n    params = {'name': name}\n\n    if app_label and model_label:\n        params.update({'app_label': app_label, 'model_label': model_label})\n\n    if slug:\n        params.update({'slug': slug})\n\n    if category:\n        if app_label and model_label:\n            if slug:\n                templates += category_templates(category, FULL, params)\n            templates += category_templates(category, FULL_NO_SLUG, params)\n        templates += category_templates(category, BY_CATEGORY, params)\n\n    if app_label and model_label:\n        templates.append(BY_CONTENT_TYPE % params)\n\n    templates.append('page/%(name)s' % params)\n    return templates"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_templates_from_publishable(name, publishable):\n    slug = publishable.slug\n    category = publishable.category\n    app_label = publishable.content_type.app_label\n    model_label = publishable.content_type.model\n    return get_templates(name, slug, category, app_label, model_label)", "response": "Returns a list of templates from a Publishable instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexports a list of objects in the tree.", "response": "def export(request, count, name='', content_type=None):\n    \"\"\"\n    Export banners.\n\n    :Parameters:\n        - `count`: number of objects to pass into the template\n        - `name`: name of the template ( page/export/banner.html is default )\n        - `models`: list of Model classes to include\n    \"\"\"\n    t_list = []\n    if name:\n        t_list.append('page/export/%s.html' % name)\n    t_list.append('page/export/banner.html')\n\n    try:\n        cat = Category.objects.get_by_tree_path('')\n    except Category.DoesNotExist:\n        raise Http404()\n    listing = Listing.objects.get_listing(count=count, category=cat)\n    return render(\n            request,\n            t_list,\n            { 'category' : cat, 'listing' : listing },\n            content_type=content_type\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_templates(self, context, template_name=None):\n        \" Extract parameters for `get_templates` from the context. \"\n        if not template_name:\n            template_name = self.template_name\n\n        kw = {}\n        if 'object' in context:\n            o = context['object']\n            kw['slug'] = o.slug\n\n        if context.get('content_type', False):\n            ct = context['content_type']\n            kw['app_label'] = ct.app_label\n            kw['model_label'] = ct.model\n\n        return get_templates(template_name, category=context['category'], **kw)", "response": "Extract parameters for get_templates from the context."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning ARCHIVE_ENTRY_YEAR from settings ( if exists ) or year of the newest object in category", "response": "def _archive_entry_year(self, category):\n        \" Return ARCHIVE_ENTRY_YEAR from settings (if exists) or year of the newest object in category \"\n        year = getattr(settings, 'ARCHIVE_ENTRY_YEAR', None)\n        if not year:\n            n = now()\n            try:\n                year = Listing.objects.filter(\n                        category__site__id=settings.SITE_ID,\n                        category__tree_path__startswith=category.tree_path,\n                        publish_from__lte=n\n                    ).values('publish_from')[0]['publish_from'].year\n            except:\n                year = n.year\n        return year"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride models. Model. save.", "response": "def save(self, **kwargs):\n        \"\"\"Overrides models.Model.save.\n\n        - Generates slug.\n        - Saves image file.\n        \"\"\"\n        if not self.width or not self.height:\n            self.width, self.height = self.image.width, self.image.height\n\n        # prefill the slug with the ID, it requires double save\n        if not self.id:\n            img = self.image\n\n            # store dummy values first...\n            w, h = self.width, self.height\n            self.image = ''\n            self.width, self.height = w, h\n            self.slug = ''\n\n            super(Photo, self).save(force_insert=True)\n\n            # ... so that we can generate the slug\n            self.slug = str(self.id) + '-' + slugify(self.title)\n            # truncate slug in order to fit in an ImageField and/or paths in Redirects\n            self.slug = self.slug[:64]\n            # .. tha will be used in the image's upload_to function\n            self.image = img\n            # and the image will be saved properly\n            super(Photo, self).save(force_update=True)\n        else:\n            try:\n                old = Photo.objects.get(pk=self.pk)\n\n                force_update = True\n                # delete formatedphotos if new image was uploaded\n                if old.image != self.image:\n                    for f_photo in self.formatedphoto_set.all():\n                        f_photo.delete()\n            except Photo.DoesNotExist:\n                # somebody is just trying to create new model with given PK\n                force_update = False\n\n            super(Photo, self).save(force_update=force_update)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns fake FormatedPhoto object to be used in templates when an error occurs in image generation.", "response": "def get_blank_img(self):\n        \"\"\"\n        Return fake ``FormatedPhoto`` object to be used in templates when an error\n        occurs in image generation.\n        \"\"\"\n        if photos_settings.DEBUG:\n            return self.get_placeholder_img()\n\n        out = {\n            'blank': True,\n            'width': self.max_width,\n            'height': self.max_height,\n            'url': photos_settings.EMPTY_IMAGE_SITE_PREFIX + 'img/empty/%s.png' % (self.name),\n        }\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn fake photo object grabbed from image placeholder generator service for the purpose of debugging when images are not available but we still want to see something.", "response": "def get_placeholder_img(self):\n        \"\"\"\n        Returns fake ``FormatedPhoto`` object grabbed from image placeholder\n        generator service for the purpose of debugging when images\n        are not available but we still want to see something.\n        \"\"\"\n        pars = {\n            'width': self.max_width,\n            'height': self.max_height\n        }\n        out = {\n            'placeholder': True,\n            'width': self.max_width,\n            'height': self.max_height,\n            'url': photos_settings.DEBUG_PLACEHOLDER_PROVIDER_TEMPLATE % pars\n        }\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, **kwargs):\n\n        if self.id:\n            for f_photo in self.formatedphoto_set.all():\n                f_photo.delete()\n\n        super(Format, self).save(**kwargs)", "response": "Overrides models. Model. save. save."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(self, save=True):\n        stretched_photo, crop_box = self._generate_img()\n\n        # set crop_box to (0,0,0,0) if photo not cropped\n        if not crop_box:\n            crop_box = 0, 0, 0, 0\n\n        self.crop_left, self.crop_top, right, bottom = crop_box\n        self.crop_width = right - self.crop_left\n        self.crop_height = bottom - self.crop_top\n\n        self.width, self.height = stretched_photo.size\n\n        f = StringIO()\n        imgf = (self.photo._get_image().format or\n                Image.EXTENSION[path.splitext(self.photo.image.name)[1]])\n\n        stretched_photo.save(f, format=imgf, quality=self.format.resample_quality)\n        f.seek(0)\n\n        self.image.save(self.file(), ContentFile(f.read()), save)", "response": "Generates photo file in current format."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noverrides models. Model. save - Removes old file from the FS - Generates new file.", "response": "def save(self, **kwargs):\n        \"\"\"Overrides models.Model.save\n\n        - Removes old file from the FS\n        - Generates new file.\n        \"\"\"\n        self.remove_file()\n        if not self.image:\n            self.generate(save=False)\n        else:\n            self.image.name = self.file()\n        super(FormatedPhoto, self).save(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file(self):\n        if photos_settings.FORMATED_PHOTO_FILENAME is not None:\n            return photos_settings.FORMATED_PHOTO_FILENAME(self)\n        source_file = path.split(self.photo.image.name)\n        return path.join(source_file[0], str(self.format.id) + '-' + source_file[1])", "response": "Method returns formated photo path derived from format. id and source photo filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_category_from_pars_var(template_var, context):\n    '''\n    get category from template variable or from tree_path\n    '''\n    cat = template_var.resolve(context)\n    if isinstance(cat, basestring):\n        cat = Category.objects.get_by_tree_path(cat)\n    return cat", "response": "get category from template variable or from tree_path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef position(parser, token):\n    bits = token.split_contents()\n    nodelist = parser.parse(('end' + bits[0],))\n    parser.delete_first_token()\n    return _parse_position_tag(bits, nodelist)", "response": "Render a given position for category."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ifposition(parser, token):\n    bits = list(token.split_contents())\n    end_tag = 'end' + bits[0]\n\n    nofallback = False\n    if bits[-1] == 'nofallback':\n        nofallback = True\n        bits.pop()\n\n    if len(bits) >= 4 and bits[-2] == 'for':\n        category = template.Variable(bits.pop())\n        pos_names = bits[1:-1]\n    else:\n        raise TemplateSyntaxError('Invalid syntax: {% ifposition POSITION_NAME ... for CATEGORY [nofallback] %}')\n\n    nodelist_true = parser.parse(('else', end_tag))\n    token = parser.next_token()\n\n    if token.contents == 'else':\n        nodelist_false = parser.parse((end_tag,))\n        parser.delete_first_token()\n    else:\n        nodelist_false = template.NodeList()\n\n    return IfPositionNode(category, pos_names, nofallback, nodelist_true, nodelist_false)", "response": "Returns a node for the if - position of the given tag."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_contacts(pairings):\n    if not config.INTRA:\n        return pairings\n    filtered1_pairings = [p for p in pairings if (p.resnr, p.reschain) != (p.resnr_l, p.reschain_l)]\n    already_considered = []\n    filtered2_pairings = []\n    for contact in filtered1_pairings:\n        try:\n            dist = 'D{}'.format(round(contact.distance, 2))\n        except AttributeError:\n            try:\n                dist = 'D{}'.format(round(contact.distance_ah, 2))\n            except AttributeError:\n                dist = 'D{}'.format(round(contact.distance_aw, 2))\n        res1, res2 = ''.join([str(contact.resnr), contact.reschain]), ''.join(\n            [str(contact.resnr_l), contact.reschain_l])\n        data = {res1, res2, dist}\n        if data not in already_considered:\n            filtered2_pairings.append(contact)\n            already_considered.append(data)\n    return filtered2_pairings", "response": "Filter interactions by two criteria."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of hydrophobic interaction objects between two sets of atoms.", "response": "def hydrophobic_interactions(atom_set_a, atom_set_b):\n    \"\"\"Detection of hydrophobic pliprofiler between atom_set_a (binding site) and atom_set_b (ligand).\n    Definition: All pairs of qualified carbon atoms within a distance of HYDROPH_DIST_MAX\n    \"\"\"\n    data = namedtuple('hydroph_interaction', 'bsatom bsatom_orig_idx ligatom ligatom_orig_idx '\n                                             'distance restype resnr reschain restype_l, resnr_l, reschain_l')\n    pairings = []\n    for a, b in itertools.product(atom_set_a, atom_set_b):\n        if a.orig_idx == b.orig_idx:\n            continue\n        e = euclidean3d(a.atom.coords, b.atom.coords)\n        if not config.MIN_DIST < e < config.HYDROPH_DIST_MAX:\n            continue\n        restype, resnr, reschain = whichrestype(a.atom), whichresnumber(a.atom), whichchain(a.atom)\n        restype_l, resnr_l, reschain_l = whichrestype(b.orig_atom), whichresnumber(b.orig_atom), whichchain(b.orig_atom)\n        contact = data(bsatom=a.atom, bsatom_orig_idx=a.orig_idx, ligatom=b.atom, ligatom_orig_idx=b.orig_idx,\n                       distance=e, restype=restype, resnr=resnr,\n                       reschain=reschain, restype_l=restype_l,\n                       resnr_l=resnr_l, reschain_l=reschain_l)\n        pairings.append(contact)\n    return filter_contacts(pairings)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of tuples containing the names of hydrogen bonds between acceptors and donor pairs.", "response": "def hbonds(acceptors, donor_pairs, protisdon, typ):\n    \"\"\"Detection of hydrogen bonds between sets of acceptors and donor pairs.\n    Definition: All pairs of hydrogen bond acceptor and donors with\n    donor hydrogens and acceptor showing a distance within HBOND DIST MIN and HBOND DIST MAX\n    and donor angles above HBOND_DON_ANGLE_MIN\n    \"\"\"\n    data = namedtuple('hbond', 'a a_orig_idx d d_orig_idx h distance_ah distance_ad angle type protisdon resnr '\n                               'restype reschain resnr_l restype_l reschain_l sidechain atype dtype')\n    pairings = []\n    for acc, don in itertools.product(acceptors, donor_pairs):\n        if not typ == 'strong':\n            continue\n        # Regular (strong) hydrogen bonds\n        dist_ah = euclidean3d(acc.a.coords, don.h.coords)\n        dist_ad = euclidean3d(acc.a.coords, don.d.coords)\n        if not config.MIN_DIST < dist_ad < config.HBOND_DIST_MAX:\n            continue\n        vec1, vec2 = vector(don.h.coords, don.d.coords), vector(don.h.coords, acc.a.coords)\n        v = vecangle(vec1, vec2)\n        if not v > config.HBOND_DON_ANGLE_MIN:\n            continue\n        protatom = don.d.OBAtom if protisdon else acc.a.OBAtom\n        ligatom = don.d.OBAtom if not protisdon else acc.a.OBAtom\n        is_sidechain_hbond = protatom.GetResidue().GetAtomProperty(protatom, 8)  # Check if sidechain atom\n        resnr = whichresnumber(don.d) if protisdon else whichresnumber(acc.a)\n        resnr_l = whichresnumber(acc.a_orig_atom) if protisdon else whichresnumber(don.d_orig_atom)\n        restype = whichrestype(don.d) if protisdon else whichrestype(acc.a)\n        restype_l = whichrestype(acc.a_orig_atom) if protisdon else whichrestype(don.d_orig_atom)\n        reschain = whichchain(don.d) if protisdon else whichchain(acc.a)\n        rechain_l = whichchain(acc.a_orig_atom) if protisdon else whichchain(don.d_orig_atom)\n        # Next line prevents H-Bonds within amino acids in intermolecular interactions\n        if config.INTRA is not None and whichresnumber(don.d) == whichresnumber(acc.a):\n            continue\n        # Next line prevents backbone-backbone H-Bonds\n        if config.INTRA is not None and protatom.GetResidue().GetAtomProperty(protatom, 8) and ligatom.GetResidue().GetAtomProperty(ligatom, 8):\n            continue\n        contact = data(a=acc.a, a_orig_idx=acc.a_orig_idx, d=don.d, d_orig_idx=don.d_orig_idx, h=don.h,\n                       distance_ah=dist_ah, distance_ad=dist_ad, angle=v, type=typ, protisdon=protisdon,\n                       resnr=resnr, restype=restype, reschain=reschain, resnr_l=resnr_l,\n                       restype_l=restype_l, reschain_l=rechain_l, sidechain=is_sidechain_hbond,\n                       atype=acc.a.type, dtype=don.d.type)\n        pairings.append(contact)\n    return filter_contacts(pairings)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pistacking(rings_bs, rings_lig):\n    data = namedtuple(\n        'pistack', 'proteinring ligandring distance angle offset type restype resnr reschain restype_l resnr_l reschain_l')\n    pairings = []\n    for r, l in itertools.product(rings_bs, rings_lig):\n        # DISTANCE AND RING ANGLE CALCULATION\n        d = euclidean3d(r.center, l.center)\n        b = vecangle(r.normal, l.normal)\n        a = min(b, 180 - b if not 180 - b < 0 else b)  # Smallest of two angles, depending on direction of normal\n\n        # RING CENTER OFFSET CALCULATION (project each ring center into the other ring)\n        proj1 = projection(l.normal, l.center, r.center)\n        proj2 = projection(r.normal, r.center, l.center)\n        offset = min(euclidean3d(proj1, l.center), euclidean3d(proj2, r.center))\n\n        # RECEPTOR DATA\n        resnr, restype, reschain = whichresnumber(r.atoms[0]), whichrestype(r.atoms[0]), whichchain(r.atoms[0])\n        resnr_l, restype_l, reschain_l = whichresnumber(l.orig_atoms[0]), whichrestype(\n            l.orig_atoms[0]), whichchain(l.orig_atoms[0])\n\n        # SELECTION BY DISTANCE, ANGLE AND OFFSET\n        passed = False\n        if not config.MIN_DIST < d < config.PISTACK_DIST_MAX:\n            continue\n        if 0 < a < config.PISTACK_ANG_DEV and offset < config.PISTACK_OFFSET_MAX:\n            ptype = 'P'\n            passed = True\n        if 90 - config.PISTACK_ANG_DEV < a < 90 + config.PISTACK_ANG_DEV and offset < config.PISTACK_OFFSET_MAX:\n            ptype = 'T'\n            passed = True\n        if passed:\n            contact = data(proteinring=r, ligandring=l, distance=d, angle=a, offset=offset,\n                           type=ptype, resnr=resnr, restype=restype, reschain=reschain,\n                           resnr_l=resnr_l, restype_l=restype_l, reschain_l=reschain_l)\n            pairings.append(contact)\n    return filter_contacts(pairings)", "response": "Return all pi - stackings between the given aromatic ring systems in receptor and ligand."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pication(rings, pos_charged, protcharged):\n    data = namedtuple(\n        'pication', 'ring charge distance offset type restype resnr reschain restype_l resnr_l reschain_l protcharged')\n    pairings = []\n    if len(rings) == 0 or len(pos_charged) == 0:\n        return pairings\n    for ring in rings:\n        c = ring.center\n        for p in pos_charged:\n            d = euclidean3d(c, p.center)\n            # Project the center of charge into the ring and measure distance to ring center\n            proj = projection(ring.normal, ring.center, p.center)\n            offset = euclidean3d(proj, ring.center)\n            if not config.MIN_DIST < d < config.PICATION_DIST_MAX or not offset < config.PISTACK_OFFSET_MAX:\n                continue\n            if type(p).__name__ == 'lcharge' and p.fgroup == 'tertamine':\n                # Special case here if the ligand has a tertiary amine, check an additional angle\n                # Otherwise, we might have have a pi-cation interaction 'through' the ligand\n                n_atoms = [a_neighbor for a_neighbor in OBAtomAtomIter(p.atoms[0].OBAtom)]\n                n_atoms_coords = [(a.x(), a.y(), a.z()) for a in n_atoms]\n                amine_normal = np.cross(vector(n_atoms_coords[0], n_atoms_coords[1]),\n                                        vector(n_atoms_coords[2], n_atoms_coords[0]))\n                b = vecangle(ring.normal, amine_normal)\n                # Smallest of two angles, depending on direction of normal\n                a = min(b, 180 - b if not 180 - b < 0 else b)\n                if not a > 30.0:\n                    resnr, restype = whichresnumber(ring.atoms[0]), whichrestype(ring.atoms[0])\n                    reschain = whichchain(ring.atoms[0])\n                    resnr_l, restype_l = whichresnumber(p.orig_atoms[0]), whichrestype(p.orig_atoms[0])\n                    reschain_l = whichchain(p.orig_atoms[0])\n                    contact = data(ring=ring, charge=p, distance=d, offset=offset, type='regular',\n                                   restype=restype, resnr=resnr, reschain=reschain,\n                                   restype_l=restype_l, resnr_l=resnr_l, reschain_l=reschain_l,\n                                   protcharged=protcharged)\n                    pairings.append(contact)\n                break\n            resnr = whichresnumber(p.atoms[0]) if protcharged else whichresnumber(ring.atoms[0])\n            resnr_l = whichresnumber(ring.orig_atoms[0]) if protcharged else whichresnumber(p.orig_atoms[0])\n            restype = whichrestype(p.atoms[0]) if protcharged else whichrestype(ring.atoms[0])\n            restype_l = whichrestype(ring.orig_atoms[0]) if protcharged else whichrestype(p.orig_atoms[0])\n            reschain = whichchain(p.atoms[0]) if protcharged else whichchain(ring.atoms[0])\n            reschain_l = whichchain(ring.orig_atoms[0]) if protcharged else whichchain(p.orig_atoms[0])\n            contact = data(ring=ring, charge=p, distance=d, offset=offset, type='regular', restype=restype,\n                           resnr=resnr, reschain=reschain, restype_l=restype_l, resnr_l=resnr_l,\n                           reschain_l=reschain_l, protcharged=protcharged)\n            pairings.append(contact)\n    return filter_contacts(pairings)", "response": "Return all pi - Cation interaction between aromatic rings and positively charged groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef saltbridge(poscenter, negcenter, protispos):\n    data = namedtuple(\n        'saltbridge', 'positive negative distance protispos resnr restype reschain resnr_l restype_l reschain_l')\n    pairings = []\n    for pc, nc in itertools.product(poscenter, negcenter):\n        if not config.MIN_DIST < euclidean3d(pc.center, nc.center) < config.SALTBRIDGE_DIST_MAX:\n            continue\n        resnr = pc.resnr if protispos else nc.resnr\n        resnr_l = whichresnumber(nc.orig_atoms[0]) if protispos else whichresnumber(pc.orig_atoms[0])\n        restype = pc.restype if protispos else nc.restype\n        restype_l = whichrestype(nc.orig_atoms[0]) if protispos else whichrestype(pc.orig_atoms[0])\n        reschain = pc.reschain if protispos else nc.reschain\n        reschain_l = whichchain(nc.orig_atoms[0]) if protispos else whichchain(pc.orig_atoms[0])\n        contact = data(positive=pc, negative=nc, distance=euclidean3d(pc.center, nc.center), protispos=protispos,\n                       resnr=resnr, restype=restype, reschain=reschain, resnr_l=resnr_l, restype_l=restype_l,\n                       reschain_l=reschain_l)\n        pairings.append(contact)\n    return filter_contacts(pairings)", "response": "Detect all salt bridges between centers of positive and negative charge"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetect all halogen bonds of the type Y - O... X - C", "response": "def halogen(acceptor, donor):\n    \"\"\"Detect all halogen bonds of the type Y-O...X-C\"\"\"\n    data = namedtuple('halogenbond', 'acc acc_orig_idx don don_orig_idx distance don_angle acc_angle restype '\n                                     'resnr reschain restype_l resnr_l reschain_l donortype acctype sidechain')\n    pairings = []\n    for acc, don in itertools.product(acceptor, donor):\n        dist = euclidean3d(acc.o.coords, don.x.coords)\n        if not config.MIN_DIST < dist < config.HALOGEN_DIST_MAX:\n            continue\n        vec1, vec2 = vector(acc.o.coords, acc.y.coords), vector(acc.o.coords, don.x.coords)\n        vec3, vec4 = vector(don.x.coords, acc.o.coords), vector(don.x.coords, don.c.coords)\n        acc_angle, don_angle = vecangle(vec1, vec2), vecangle(vec3, vec4)\n        is_sidechain_hal = acc.o.OBAtom.GetResidue().GetAtomProperty(acc.o.OBAtom, 8)  # Check if sidechain atom\n        if not config.HALOGEN_ACC_ANGLE - config.HALOGEN_ANGLE_DEV < acc_angle \\\n                < config.HALOGEN_ACC_ANGLE + config.HALOGEN_ANGLE_DEV:\n            continue\n        if not config.HALOGEN_DON_ANGLE - config.HALOGEN_ANGLE_DEV < don_angle \\\n                < config.HALOGEN_DON_ANGLE + config.HALOGEN_ANGLE_DEV:\n            continue\n        restype, reschain, resnr = whichrestype(acc.o), whichchain(acc.o), whichresnumber(acc.o)\n        restype_l, reschain_l, resnr_l = whichrestype(don.orig_x), whichchain(don.orig_x), whichresnumber(don.orig_x)\n        contact = data(acc=acc, acc_orig_idx=acc.o_orig_idx, don=don, don_orig_idx=don.x_orig_idx,\n                       distance=dist, don_angle=don_angle, acc_angle=acc_angle,\n                       restype=restype, resnr=resnr,\n                       reschain=reschain, restype_l=restype_l,\n                       reschain_l=reschain_l, resnr_l=resnr_l, donortype=don.x.OBAtom.GetType(), acctype=acc.o.type,\n                       sidechain=is_sidechain_hal)\n        pairings.append(contact)\n    return filter_contacts(pairings)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding all metal complexes between metals and appropriate groups in both protein and ligand as well as water", "response": "def metal_complexation(metals, metal_binding_lig, metal_binding_bs):\n    \"\"\"Find all metal complexes between metals and appropriate groups in both protein and ligand, as well as water\"\"\"\n    data = namedtuple('metal_complex', 'metal metal_orig_idx metal_type target target_orig_idx target_type '\n                                       'coordination_num distance resnr restype '\n                                       'reschain  restype_l reschain_l resnr_l location rms, geometry num_partners complexnum')\n    pairings_dict = {}\n    pairings = []\n    # #@todo Refactor\n    metal_to_id = {}\n    metal_to_orig_atom = {}\n    for metal, target in itertools.product(metals, metal_binding_lig + metal_binding_bs):\n        distance = euclidean3d(metal.m.coords, target.atom.coords)\n        if not distance < config.METAL_DIST_MAX:\n            continue\n        if metal.m not in pairings_dict:\n            pairings_dict[metal.m] = [(target, distance), ]\n            metal_to_id[metal.m] = metal.m_orig_idx\n            metal_to_orig_atom[metal.m] = metal.orig_m\n        else:\n            pairings_dict[metal.m].append((target, distance))\n    for cnum, metal in enumerate(pairings_dict):\n        rms = 0.0\n        excluded = []\n        # cnum +1 being the complex number\n        contact_pairs = pairings_dict[metal]\n        num_targets = len(contact_pairs)\n        vectors_dict = defaultdict(list)\n        for contact_pair in contact_pairs:\n            target, distance = contact_pair\n            vectors_dict[target.atom.idx].append(vector(metal.coords, target.atom.coords))\n\n        # Listing of coordination numbers and their geometries\n        configs = {2: ['linear', ],\n                   3: ['trigonal.planar', 'trigonal.pyramidal'],\n                   4: ['tetrahedral', 'square.planar'],\n                   5: ['trigonal.bipyramidal', 'square.pyramidal'],\n                   6: ['octahedral', ]}\n\n        # Angle signatures for each geometry (as seen from each target atom)\n        ideal_angles = {'linear': [[180.0]] * 2,\n                        'trigonal.planar': [[120.0, 120.0]] * 3,\n                        'trigonal.pyramidal': [[109.5, 109.5]] * 3,\n                        'tetrahedral': [[109.5, 109.5, 109.5, 109.5]] * 4,\n                        'square.planar': [[90.0, 90.0, 90.0, 90.0]] * 4,\n                        'trigonal.bipyramidal': [[120.0, 120.0, 90.0, 90.0]] * 3 + [[90.0, 90.0, 90.0, 180.0]] * 2,\n                        'square.pyramidal': [[90.0, 90.0, 90.0, 180.0]] * 4 + [[90.0, 90.0, 90.0, 90.0]],\n                        'octahedral': [[90.0, 90.0, 90.0, 90.0, 180.0]] * 6}\n        angles_dict = {}\n\n        for target in vectors_dict:\n            cur_vector = vectors_dict[target]\n            other_vectors = []\n            for t in vectors_dict:\n                if not t == target:\n                    [other_vectors.append(x) for x in vectors_dict[t]]\n            angles = [vecangle(pair[0], pair[1]) for pair in itertools.product(cur_vector, other_vectors)]\n            angles_dict[target] = angles\n\n        all_total = []  # Record fit information for each geometry tested\n        gdata = namedtuple('gdata', 'geometry rms coordination excluded diff_targets')  # Geometry Data\n        # Can't specify geometry with only one target\n        if num_targets == 1:\n            final_geom = 'NA'\n            final_coo = 1\n            excluded = []\n            rms = 0.0\n        else:\n            for coo in sorted(configs, reverse=True):  # Start with highest coordination number\n                geometries = configs[coo]\n                for geometry in geometries:\n                    signature = ideal_angles[geometry]  # Set of ideal angles for geometry, from each perspective\n                    geometry_total = 0\n                    geometry_scores = []  # All scores for one geometry (from all subsignatures)\n                    used_up_targets = []  # Use each target just once for a subsignature\n                    not_used = []\n                    coo_diff = num_targets - coo  # How many more observed targets are there?\n\n                    # Find best match for each subsignature\n                    for subsignature in signature:  # Ideal angles from one perspective\n                        best_target = None  # There's one best-matching target for each subsignature\n                        best_target_score = 999\n\n                        for k, target in enumerate(angles_dict):\n                            if target not in used_up_targets:\n                                observed_angles = angles_dict[target]  # Observed angles from perspective of one target\n                                single_target_scores = []\n                                used_up_observed_angles = []\n                                for i, ideal_angle in enumerate(subsignature):\n                                    # For each angle in the signature, find the best-matching observed angle\n                                    best_match = None\n                                    best_match_diff = 999\n                                    for j, observed_angle in enumerate(observed_angles):\n                                        if j not in used_up_observed_angles:\n                                            diff = abs(ideal_angle - observed_angle)\n                                            if diff < best_match_diff:\n                                                best_match_diff = diff\n                                                best_match = j\n                                    if best_match is not None:\n                                        used_up_observed_angles.append(best_match)\n                                        single_target_scores.append(best_match_diff)\n                                # Calculate RMS for target angles\n                                target_total = sum([x ** 2 for x in single_target_scores]) ** 0.5  # Tot. score targ/sig\n                                if target_total < best_target_score:\n                                    best_target_score = target_total\n                                    best_target = target\n\n                        used_up_targets.append(best_target)\n                        geometry_scores.append(best_target_score)\n                        # Total score is mean of RMS values\n                        geometry_total = np.mean(geometry_scores)\n                    # Record the targets not used for excluding them when deciding for a final geometry\n                    [not_used.append(target) for target in angles_dict if target not in used_up_targets]\n                    all_total.append(gdata(geometry=geometry, rms=geometry_total, coordination=coo,\n                                           excluded=not_used, diff_targets=coo_diff))\n\n        # Make a decision here. Starting with the geometry with lowest difference in ideal and observed partners ...\n        # Check if the difference between the RMS to the next best solution is not larger than 0.5\n        if not num_targets == 1:  # Can't decide for any geoemtry in that case\n            all_total = sorted(all_total, key=lambda x: abs(x.diff_targets))\n            for i, total in enumerate(all_total):\n                next_total = all_total[i + 1]\n                this_rms, next_rms = total.rms, next_total.rms\n                diff_to_next = next_rms - this_rms\n                if diff_to_next > 0.5:\n                    final_geom, final_coo, rms, excluded = total.geometry, total.coordination, total.rms, total.excluded\n                    break\n                elif next_total.rms < 3.5:\n                    final_geom, final_coo, = next_total.geometry, next_total.coordination\n                    rms, excluded = next_total.rms, next_total.excluded\n                    break\n                elif i == len(all_total) - 2:\n                    final_geom, final_coo, rms, excluded = \"NA\", \"NA\", float('nan'), []\n                    break\n\n        # Record all contact pairing, excluding those with targets superfluous for chosen geometry\n        only_water = set([x[0].location for x in contact_pairs]) == {'water'}\n        if not only_water:  # No complex if just with water as targets\n            write_message(\"Metal ion %s complexed with %s geometry (coo. number %r/ %i observed).\\n\"\n                          % (metal.type, final_geom, final_coo, num_targets), indent=True)\n            for contact_pair in contact_pairs:\n                target, distance = contact_pair\n                if target.atom.idx not in excluded:\n                    metal_orig_atom = metal_to_orig_atom[metal]\n                    restype_l, reschain_l, resnr_l = whichrestype(metal_orig_atom), whichchain(\n                        metal_orig_atom), whichresnumber(metal_orig_atom)\n                    contact = data(metal=metal, metal_orig_idx=metal_to_id[metal], metal_type=metal.type,\n                                   target=target, target_orig_idx=target.atom_orig_idx, target_type=target.type,\n                                   coordination_num=final_coo, distance=distance, resnr=target.resnr,\n                                   restype=target.restype, reschain=target.reschain, location=target.location,\n                                   rms=rms, geometry=final_geom, num_partners=num_targets, complexnum=cnum + 1,\n                                   resnr_l=resnr_l, restype_l=restype_l, reschain_l=reschain_l)\n                    pairings.append(contact)\n    return filter_contacts(pairings)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getdata(self, tree, location, force_string=False):\n        found = tree.xpath('%s/text()' % location)\n        if not found:\n            return None\n        else:\n            data = found[0]\n        if force_string:\n            return data\n        if data == 'True':\n            return True\n        elif data == 'False':\n            return False\n        else:\n            try:\n                return int(data)\n            except ValueError:\n                try:\n                    return float(data)\n                except ValueError:\n                    # It's a string\n                    return data", "response": "Gets XML data from a specific element and handles types."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget coordinates from a specific element in PLIP XML", "response": "def getcoordinates(self, tree, location):\n        \"\"\"Gets coordinates from a specific element in PLIP XML\"\"\"\n        return tuple(float(x) for x in tree.xpath('.//%s/*/text()' % location))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_atom_mapping(self):\n        # Atom mappings\n        smiles_to_pdb_mapping = self.bindingsite.xpath('mappings/smiles_to_pdb/text()')\n        if smiles_to_pdb_mapping == []:\n            self.mappings = {'smiles_to_pdb': None, 'pdb_to_smiles': None}\n        else:\n            smiles_to_pdb_mapping = {int(y[0]): int(y[1]) for y in [x.split(':')\n                                                                    for x in smiles_to_pdb_mapping[0].split(',')]}\n            self.mappings = {'smiles_to_pdb': smiles_to_pdb_mapping}\n            self.mappings['pdb_to_smiles'] = {v: k for k, v in self.mappings['smiles_to_pdb'].items()}", "response": "Parses the ligand atom mapping."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncounting the interaction types and backbone hydrogen bonding in a binding site", "response": "def get_counts(self):\n        \"\"\"counts the interaction types and backbone hydrogen bonding in a binding site\"\"\"\n\n        hbondsback = len([hb for hb in self.hbonds if not hb.sidechain])\n        counts = {'hydrophobics': len(self.hydrophobics), 'hbonds': len(self.hbonds),\n                  'wbridges': len(self.wbridges), 'sbridges': len(self.sbridges), 'pistacks': len(self.pi_stacks),\n                  'pications': len(self.pi_cations), 'halogens': len(self.halogens), 'metal': len(self.metal_complexes),\n                  'hbond_back': hbondsback, 'hbond_nonback': (len(self.hbonds) - hbondsback)}\n        counts['total'] = counts['hydrophobics'] + counts['hbonds'] + counts['wbridges'] + \\\n            counts['sbridges'] + counts['pistacks'] + counts['pications'] + counts['halogens'] + counts['metal']\n        return counts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload and parses an XML resource and saves it as a tree if successful", "response": "def load_data(self, pdbid):\n        \"\"\"Loads and parses an XML resource and saves it as a tree if successful\"\"\"\n        f = urlopen(\"http://projects.biotec.tu-dresden.de/plip-rest/pdb/%s?format=xml\" % pdbid.lower())\n        self.doc = etree.parse(f)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite your forwards methods here.", "response": "def forwards(self, orm):\n        \"Write your forwards methods here.\"\n        for a in orm.Article.objects.all():\n            if a.updated:\n                a.last_updated = a.updated\n                a.save(force_update=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_pdb_status(pdbid):\n    url = 'http://www.rcsb.org/pdb/rest/idStatus?structureId=%s' % pdbid\n    xmlf = urlopen(url)\n    xml = et.parse(xmlf)\n    xmlf.close()\n    status = None\n    current_pdbid = pdbid\n    for df in xml.xpath('//record'):\n        status = df.attrib['status']  # Status of an entry can be either 'UNKWOWN', 'OBSOLETE', or 'CURRENT'\n        if status == 'OBSOLETE':\n            current_pdbid = df.attrib['replacedBy']  # Contains the up-to-date PDB ID for obsolete entries\n    return [status, current_pdbid.lower()]", "response": "Returns the status and up - to - date entry in the PDB for a given PDB ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the newest entry from the RCSB server for the given PDB ID. Exits with 1 if the given PDB ID is invalid.", "response": "def fetch_pdb(pdbid):\n    \"\"\"Get the newest entry from the RCSB server for the given PDB ID. Exits with '1' if PDB ID is invalid.\"\"\"\n    pdbid = pdbid.lower()\n    write_message('\\nChecking status of PDB ID %s ... ' % pdbid)\n    state, current_entry = check_pdb_status(pdbid)  # Get state and current PDB ID\n\n    if state == 'OBSOLETE':\n        write_message('entry is obsolete, getting %s instead.\\n' % current_entry)\n    elif state == 'CURRENT':\n        write_message('entry is up to date.\\n')\n    elif state == 'UNKNOWN':\n        sysexit(3, 'Invalid PDB ID (Entry does not exist on PDB server)\\n')\n    write_message('Downloading file from PDB ... ')\n    pdburl = 'http://www.rcsb.org/pdb/files/%s.pdb' % current_entry  # Get URL for current entry\n    try:\n        pdbfile = urlopen(pdburl).read().decode()\n        # If no PDB file is available, a text is now shown with \"We're sorry, but ...\"\n        # Could previously be distinguished by an HTTP error\n        if 'sorry' in pdbfile:\n            sysexit(5, \"No file in PDB format available from wwPDB for the given PDB ID.\\n\")\n    except HTTPError:\n        sysexit(5, \"No file in PDB format available from wwPDB for the given PDB ID.\\n\")\n    return [pdbfile, current_entry]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the active position for given position name.", "response": "def get_active_position(self, category, name, nofallback=False):\n        \"\"\"\n        Get active position for given position name.\n\n        params:\n            category - Category model to look for\n            name - name of the position\n            nofallback - if True than do not fall back to parent\n                        category if active position is not found for category\n        \"\"\"\n        now = timezone.now()\n        lookup = (Q(active_from__isnull=True) | Q(active_from__lte=now)) & \\\n                 (Q(active_till__isnull=True) | Q(active_till__gt=now))\n\n        while True:\n            try:\n                return self.get(lookup, category=category, name=name,\n                    disabled=False)\n            except Position.DoesNotExist:\n                # if nofallback was specified, do not look into parent categories\n                if nofallback:\n                    return False\n\n                # traverse the category tree to the top otherwise\n                category = category.tree_parent\n\n                # we reached the top and still haven't found the position - return\n                if category is None:\n                    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_initial_representations(self):\n        self.standard_settings()\n        cmd.set('dash_gap', 0)  # Show not dashes, but lines for the pliprofiler\n        cmd.set('ray_shadow', 0)  # Turn on ray shadows for clearer ray-traced images\n        cmd.set('cartoon_color', 'mylightblue')\n\n        # Set clipping planes for full view\n        cmd.clip('far', -1000)\n        cmd.clip('near', 1000)", "response": "Set initial representations for the current system"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef standard_settings(self):\n        cmd.set('bg_rgb', [1.0, 1.0, 1.0])  # White background\n        cmd.set('depth_cue', 0)  # Turn off depth cueing (no fog)\n        cmd.set('cartoon_side_chain_helper', 1)  # Improve combined visualization of sticks and cartoon\n        cmd.set('cartoon_fancy_helices', 1)  # Nicer visualization of helices (using tapered ends)\n        cmd.set('transparency_mode', 1)  # Turn on multilayer transparency\n        cmd.set('dash_radius', 0.05)\n        self.set_custom_colorset()", "response": "Sets up standard settings for a nice visualization."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefining a colorset with matching colors. Provided by Joachim.", "response": "def set_custom_colorset(self):\n        \"\"\"Defines a colorset with matching colors. Provided by Joachim.\"\"\"\n        cmd.set_color('myorange', '[253, 174, 97]')\n        cmd.set_color('mygreen', '[171, 221, 164]')\n        cmd.set_color('myred', '[215, 25, 28]')\n        cmd.set_color('myblue', '[43, 131, 186]')\n        cmd.set_color('mylightblue', '[158, 202, 225]')\n        cmd.set_color('mylightgreen', '[229, 245, 224]')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvisualize pi - stacking interactions.", "response": "def show_stacking(self):\n        \"\"\"Visualize pi-stacking interactions.\"\"\"\n        stacks = self.plcomplex.pistacking\n        for i, stack in enumerate(stacks):\n            pires_ids = '+'.join(map(str, stack.proteinring_atoms))\n            pilig_ids = '+'.join(map(str, stack.ligandring_atoms))\n            cmd.select('StackRings-P', 'StackRings-P or (id %s & %s)' % (pires_ids, self.protname))\n            cmd.select('StackRings-L', 'StackRings-L or (id %s & %s)' % (pilig_ids, self.ligname))\n            cmd.select('StackRings-P', 'byres StackRings-P')\n            cmd.show('sticks', 'StackRings-P')\n\n            cmd.pseudoatom('ps-pistack-1-%i' % i, pos=stack.proteinring_center)\n            cmd.pseudoatom('ps-pistack-2-%i' % i, pos=stack.ligandring_center)\n            cmd.pseudoatom('Centroids-P', pos=stack.proteinring_center)\n            cmd.pseudoatom('Centroids-L', pos=stack.ligandring_center)\n\n            if stack.type == 'P':\n                cmd.distance('PiStackingP', 'ps-pistack-1-%i' % i, 'ps-pistack-2-%i' % i)\n            if stack.type == 'T':\n                cmd.distance('PiStackingT', 'ps-pistack-1-%i' % i, 'ps-pistack-2-%i' % i)\n        if self.object_exists('PiStackingP'):\n            cmd.set('dash_color', 'green', 'PiStackingP')\n            cmd.set('dash_gap', 0.3, 'PiStackingP')\n            cmd.set('dash_length', 0.6, 'PiStackingP')\n        if self.object_exists('PiStackingT'):\n            cmd.set('dash_color', 'smudge', 'PiStackingT')\n            cmd.set('dash_gap', 0.3, 'PiStackingT')\n            cmd.set('dash_length', 0.6, 'PiStackingT')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvisualize cation - pi interactions.", "response": "def show_cationpi(self):\n        \"\"\"Visualize cation-pi interactions.\"\"\"\n        for i, p in enumerate(self.plcomplex.pication):\n            cmd.pseudoatom('ps-picat-1-%i' % i, pos=p.ring_center)\n            cmd.pseudoatom('ps-picat-2-%i' % i, pos=p.charge_center)\n            if p.protcharged:\n                cmd.pseudoatom('Chargecenter-P', pos=p.charge_center)\n                cmd.pseudoatom('Centroids-L', pos=p.ring_center)\n                pilig_ids = '+'.join(map(str, p.ring_atoms))\n                cmd.select('PiCatRing-L', 'PiCatRing-L or (id %s & %s)' % (pilig_ids, self.ligname))\n                for a in p.charge_atoms:\n                    cmd.select('PosCharge-P', 'PosCharge-P or (id %i & %s)' % (a, self.protname))\n            else:\n                cmd.pseudoatom('Chargecenter-L', pos=p.charge_center)\n                cmd.pseudoatom('Centroids-P', pos=p.ring_center)\n                pires_ids = '+'.join(map(str, p.ring_atoms))\n                cmd.select('PiCatRing-P', 'PiCatRing-P or (id %s & %s)' % (pires_ids, self.protname))\n                for a in p.charge_atoms:\n                    cmd.select('PosCharge-L', 'PosCharge-L or (id %i & %s)' % (a, self.ligname))\n            cmd.distance('PiCation', 'ps-picat-1-%i' % i, 'ps-picat-2-%i' % i)\n        if self.object_exists('PiCation'):\n            cmd.set('dash_color', 'orange', 'PiCation')\n            cmd.set('dash_gap', 0.3, 'PiCation')\n            cmd.set('dash_length', 0.6, 'PiCation')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef selections_cleanup(self):\n\n        if not len(self.plcomplex.unpaired_hba_idx) == 0:\n            self.select_by_ids('Unpaired-HBA', self.plcomplex.unpaired_hba_idx, selection_exists=True)\n        if not len(self.plcomplex.unpaired_hbd_idx) == 0:\n            self.select_by_ids('Unpaired-HBD', self.plcomplex.unpaired_hbd_idx, selection_exists=True)\n        if not len(self.plcomplex.unpaired_hal_idx) == 0:\n            self.select_by_ids('Unpaired-HAL', self.plcomplex.unpaired_hal_idx, selection_exists=True)\n\n        selections = cmd.get_names(\"selections\")\n        for selection in selections:\n            try:\n                empty = len(cmd.get_model(selection).atom) == 0\n            except:\n                empty = True\n            if empty:\n                cmd.delete(selection)\n        cmd.deselect()\n        cmd.delete('tmp*')\n        cmd.delete('ps-*')", "response": "Cleans up non - used selections"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef additional_cleanup(self):\n\n        cmd.remove('not alt \"\"+A')  # Remove alternate conformations\n        cmd.hide('labels', 'Interactions')  # Hide labels of lines\n        cmd.disable('%sCartoon' % self.protname)\n        cmd.hide('everything', 'hydrogens')", "response": "Cleanup of various representations"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef zoom_to_ligand(self):\n        cmd.center(self.ligname)\n        cmd.orient(self.ligname)\n        cmd.turn('x', 110)  # If the ligand is aligned with the longest axis, aromatic rings are hidden\n        if 'AllBSRes' in cmd.get_names(\"selections\"):\n            cmd.zoom('%s or AllBSRes' % self.ligname, 3)\n        else:\n            if self.object_exists(self.ligname):\n                cmd.zoom(self.ligname, 3)\n        cmd.origin(self.ligname)", "response": "Zoom in too ligand and its interactions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving a PyMOL session file.", "response": "def save_session(self, outfolder, override=None):\n        \"\"\"Saves a PyMOL session file.\"\"\"\n        filename = '%s_%s' % (self.protname.upper(), \"_\".join(\n            [self.hetid, self.plcomplex.chain, self.plcomplex.position]))\n        if override is not None:\n            filename = override\n        cmd.save(\"/\".join([outfolder, \"%s.pse\" % filename]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_picture(self, outfolder, filename):\n        self.set_fancy_ray()\n        self.png_workaround(\"/\".join([outfolder, filename]))", "response": "Saves a picture of the current object to the given folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives the molecules a flat modern look.", "response": "def set_fancy_ray(self):\n        \"\"\"Give the molecule a flat, modern look.\"\"\"\n        cmd.set('light_count', 6)\n        cmd.set('spec_count', 1.5)\n        cmd.set('shininess', 4)\n        cmd.set('specular', 0.3)\n        cmd.set('reflect', 1.6)\n        cmd.set('ambient', 0)\n        cmd.set('direct', 0)\n        cmd.set('ray_shadow', 0)  # Gives the molecules a flat, modern look\n        cmd.set('ambient_occlusion_mode', 1)\n        cmd.set('ray_opaque_background', 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadapt visualization for peptide ligands and interchain contacts", "response": "def adapt_for_peptides(self):\n        \"\"\"Adapt visualization for peptide ligands and interchain contacts\"\"\"\n        cmd.hide('sticks', self.ligname)\n        cmd.set('cartoon_color', 'lightorange', self.ligname)\n        cmd.show('cartoon', self.ligname)\n        cmd.show('sticks', \"byres *-L\")\n        cmd.util.cnc(self.ligname)\n        cmd.remove('%sCartoon and chain %s' % (self.protname, self.plcomplex.chain))\n        cmd.set('cartoon_side_chain_helper', 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing refinements for the visualization", "response": "def refinements(self):\n        \"\"\"Refinements for the visualization\"\"\"\n\n        # Show sticks for all residues interacing with the ligand\n        cmd.select('AllBSRes', 'byres (Hydrophobic-P or HBondDonor-P or HBondAccept-P or PosCharge-P or NegCharge-P or '\n                               'StackRings-P or PiCatRing-P or HalogenAcc or Metal-P)')\n        cmd.show('sticks', 'AllBSRes')\n        # Show spheres for the ring centroids\n        cmd.hide('everything', 'centroids*')\n        cmd.show('nb_spheres', 'centroids*')\n        # Show spheres for centers of charge\n        if self.object_exists('Chargecenter-P') or self.object_exists('Chargecenter-L'):\n            cmd.hide('nonbonded', 'chargecenter*')\n            cmd.show('spheres', 'chargecenter*')\n            cmd.set('sphere_scale', 0.4, 'chargecenter*')\n            cmd.color('yellow', 'chargecenter*')\n\n        cmd.set('valence', 1)  # Show bond valency (e.g. double bonds)\n        # Optional cartoon representation of the protein\n        cmd.copy('%sCartoon' % self.protname, self.protname)\n        cmd.show('cartoon', '%sCartoon' % self.protname)\n        cmd.show('sticks', '%sCartoon' % self.protname)\n        cmd.set('stick_transparency', 1, '%sCartoon' % self.protname)\n\n        # Resize water molecules. Sometimes they are not heteroatoms HOH, but part of the protein\n        cmd.set('sphere_scale', 0.2, 'resn HOH or Water')  # Needs to be done here because of the copy made\n        cmd.set('sphere_transparency', 0.4, '!(resn HOH or Water)')\n\n        if 'Centroids*' in cmd.get_names(\"selections\"):\n            cmd.color('grey80', 'Centroids*')\n        cmd.hide('spheres', '%sCartoon' % self.protname)\n        cmd.hide('cartoon', '%sCartoon and resn DA+DG+DC+DU+DT+A+G+C+U+T' % self.protname)  # Hide DNA/RNA Cartoon\n        if self.ligname == 'SF4':  # Special case for iron-sulfur clusters, can't be visualized with sticks\n            cmd.show('spheres', '%s' % self.ligname)\n\n        cmd.hide('everything', 'resn HOH &!Water')  # Hide all non-interacting water molecules\n        cmd.hide('sticks', '%s and !%s and !AllBSRes' %\n                 (self.protname, self.ligname))  # Hide all non-interacting residues\n\n        if self.ligandtype in ['PEPTIDE', 'INTRA']:\n            self.adapt_for_peptides()\n\n        if self.ligandtype == 'INTRA':\n            self.adapt_for_intra()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a cached object for the given model. If the object does not exist in the cache create it.", "response": "def get_cached_object(model, timeout=CACHE_TIMEOUT, **kwargs):\n    \"\"\"\n    Return a cached object. If the object does not exist in the cache, create it.\n\n    Params:\n        model - ContentType instance representing the model's class or the model class itself\n        timeout - TTL for the item in cache, defaults to CACHE_TIMEOUT\n        **kwargs - lookup parameters for content_type.get_object_for_this_type and for key creation\n\n    Throws:\n        model.DoesNotExist is propagated from content_type.get_object_for_this_type\n    \"\"\"\n    if not isinstance(model, ContentType):\n        model_ct = ContentType.objects.get_for_model(model)\n    else:\n        model_ct = model\n\n    key = _get_key(KEY_PREFIX, model_ct, **kwargs)\n\n    obj = cache.get(key)\n    if obj is None:\n        # if we are looking for a publishable, fetch just the actual content\n        # type and then fetch the actual object\n        if model_ct.app_label == 'core' and model_ct.model == 'publishable':\n            actual_ct_id = model_ct.model_class()._default_manager.values('content_type_id').get(**kwargs)['content_type_id']\n            model_ct = ContentType.objects.get_for_id(actual_ct_id)\n\n        # fetch the actual object we want\n        obj = model_ct.model_class()._default_manager.get(**kwargs)\n\n        # since 99% of lookups are done via PK make sure we set the cache for\n        # that lookup even if we retrieved it using a different one.\n        if 'pk' in kwargs:\n            cache.set(key, obj, timeout)\n        elif not isinstance(cache, DummyCache):\n            cache.set_many({key: obj, _get_key(KEY_PREFIX, model_ct, pk=obj.pk): obj}, timeout=timeout)\n\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of objects with given PKs using cache.", "response": "def get_cached_objects(pks, model=None, timeout=CACHE_TIMEOUT, missing=RAISE):\n    \"\"\"\n    Return a list of objects with given PKs using cache.\n\n    Params:\n        pks - list of Primary Key values to look up or list of content_type_id, pk tuples\n        model - ContentType instance representing the model's class or the model class itself\n        timeout - TTL for the items in cache, defaults to CACHE_TIMEOUT\n\n    Throws:\n        model.DoesNotExist is propagated from content_type.get_object_for_this_type\n    \"\"\"\n    if model is not None:\n        if not isinstance(model, ContentType):\n            model = ContentType.objects.get_for_model(model)\n        pks = [(model, pk) for pk in pks]\n    else:\n        pks = [(ContentType.objects.get_for_id(ct_id), pk) for (ct_id, pk) in pks]\n\n    keys = [_get_key(KEY_PREFIX, model, pk=pk) for (model, pk) in pks]\n\n    cached = cache.get_many(keys)\n\n    # keys not in cache\n    keys_to_set = set(keys) - set(cached.keys())\n    if keys_to_set:\n        # build lookup to get model and pks from the key\n        lookup = dict(zip(keys, pks))\n\n        to_get = {}\n        # group lookups by CT so we can do in_bulk\n        for k in keys_to_set:\n            ct, pk = lookup[k]\n            to_get.setdefault(ct, {})[int(pk)] = k\n\n        # take out all the publishables\n        publishable_ct = ContentType.objects.get_for_model(get_model('core', 'publishable'))\n        if publishable_ct in to_get:\n            publishable_keys = to_get.pop(publishable_ct)\n            models = publishable_ct.model_class()._default_manager.values('content_type_id', 'id').filter(id__in=publishable_keys.keys())\n            for m in models:\n                ct = ContentType.objects.get_for_id(m['content_type_id'])\n                pk = m['id']\n                # and put them back as their native content_type\n                to_get.setdefault(ct, {})[pk] = publishable_keys[pk]\n\n        to_set = {}\n        # retrieve all the models from DB\n        for ct, vals in to_get.items():\n            models = ct.model_class()._default_manager.in_bulk(vals.keys())\n            for pk, m in models.items():\n                k = vals[pk]\n                cached[k] = to_set[k] = m\n\n        if not isinstance(cache, DummyCache):\n            # write them into cache\n            cache.set_many(to_set, timeout=timeout)\n\n    out = []\n    for k in keys:\n        try:\n            out.append(cached[k])\n        except KeyError:\n            if missing == NONE:\n                out.append(None)\n            elif missing == SKIP:\n                pass\n            elif missing == RAISE:\n                ct = ContentType.objects.get_for_id(int(k.split(':')[1]))\n                raise ct.model_class().DoesNotExist(\n                    '%s matching query does not exist.' % ct.model_class()._meta.object_name)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the object from the cache or raise Http404", "response": "def get_cached_object_or_404(model, timeout=CACHE_TIMEOUT, **kwargs):\n    \"\"\"\n    Shortcut that will raise Http404 if there is no object matching the query\n\n    see get_cached_object for params description\n    \"\"\"\n    try:\n        return get_cached_object(model, timeout=timeout, **kwargs)\n    except ObjectDoesNotExist, e:\n        raise Http404('Reason: %s' % str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tmpfile(prefix, direc):\n    return tempfile.mktemp(prefix=prefix, suffix='.pdb', dir=direc)", "response": "Returns the path to a newly created temporary file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_pdbid(string):\n    p = re.compile(\"[0-9][0-9a-z]{3}\")\n    m = p.search(string.lower())\n    try:\n        return m.group()\n    except AttributeError:\n        return \"UnknownProtein\"", "response": "Use regular expressions to get a PDB ID from a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef whichrestype(atom):\n    atom = atom if not isinstance(atom, Atom) else atom.OBAtom  # Convert to OpenBabel Atom\n    return atom.GetResidue().GetName() if atom.GetResidue() is not None else None", "response": "Returns the residue name of an Pybel or OpenBabel atom."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the residue number of an Pybel or OpenBabel atom.", "response": "def whichresnumber(atom):\n    \"\"\"Returns the residue number of an Pybel or OpenBabel atom (numbering as in original PDB file).\"\"\"\n    atom = atom if not isinstance(atom, Atom) else atom.OBAtom  # Convert to OpenBabel Atom\n    return atom.GetResidue().GetNum() if atom.GetResidue() is not None else None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the residue number of an PyBel or OpenBabel atom.", "response": "def whichchain(atom):\n    \"\"\"Returns the residue number of an PyBel or OpenBabel atom.\"\"\"\n    atom = atom if not isinstance(atom, Atom) else atom.OBAtom  # Convert to OpenBabel Atom\n    return atom.GetResidue().GetChain() if atom.GetResidue() is not None else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef euclidean3d(v1, v2):\n    if not len(v1) == 3 and len(v2) == 3:\n        print(\"Vectors are not in 3D space. Returning None.\")\n        return None\n    return np.sqrt((v1[0] - v2[0]) ** 2 + (v1[1] - v2[1]) ** 2 + (v1[2] - v2[2]) ** 2)", "response": "Faster implementation of euclidean distance for the 3D case."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvector from p1 to p2.", "response": "def vector(p1, p2):\n    \"\"\"Vector from p1 to p2.\n    :param p1: coordinates of point p1\n    :param p2: coordinates of point p2\n    :returns : numpy array with vector coordinates\n    \"\"\"\n    return None if len(p1) != len(p2) else np.array([p2[i] - p1[i] for i in range(len(p1))])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vecangle(v1, v2, deg=True):\n    if np.array_equal(v1, v2):\n        return 0.0\n    dm = np.dot(v1, v2)\n    cm = np.linalg.norm(v1) * np.linalg.norm(v2)\n    angle = np.arccos(round(dm / cm, 10))  # Round here to prevent floating point errors\n    return np.degrees([angle, ])[0] if deg else angle", "response": "Calculate the angle between two vectors"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef normalize_vector(v):\n    norm = np.linalg.norm(v)\n    return v/norm if not norm == 0 else v", "response": "Take a vector and return the normalized vector"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef centroid(coo):\n    return list(map(np.mean, (([c[0] for c in coo]), ([c[1] for c in coo]), ([c[2] for c in coo]))))", "response": "Calculates the centroid from a 3D point cloud and returns the coordinates\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a list of doubles this function returns a list of tuples that are clusters of the elements in the list if they share one element .", "response": "def cluster_doubles(double_list):\n    \"\"\"Given a list of doubles, they are clustered if they share one element\n    :param double_list: list of doubles\n    :returns : list of clusters (tuples)\n    \"\"\"\n    location = {}  # hashtable of which cluster each element is in\n    clusters = []\n    # Go through each double\n    for t in double_list:\n        a, b = t[0], t[1]\n        # If they both are already in different clusters, merge the clusters\n        if a in location and b in location:\n            if location[a] != location[b]:\n                if location[a] < location[b]:\n                    clusters[location[a]] = clusters[location[a]].union(clusters[location[b]])  # Merge clusters\n                    clusters = clusters[:location[b]] + clusters[location[b]+1:]\n                else:\n                    clusters[location[b]] = clusters[location[b]].union(clusters[location[a]])  # Merge clusters\n                    clusters = clusters[:location[a]] + clusters[location[a]+1:]\n                # Rebuild index of locations for each element as they have changed now\n                location = {}\n                for i, cluster in enumerate(clusters):\n                    for c in cluster:\n                        location[c] = i\n        else:\n            # If a is already in a cluster, add b to that cluster\n            if a in location:\n                clusters[location[a]].add(b)\n                location[b] = location[a]\n            # If b is already in a cluster, add a to that cluster\n            if b in location:\n                clusters[location[b]].add(a)\n                location[a] = location[b]\n            # If neither a nor b is in any cluster, create a new one with a and b\n            if not (b in location and a in location):\n                clusters.append(set(t))\n                location[a] = len(clusters) - 1\n                location[b] = len(clusters) - 1\n    return map(tuple, clusters)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a folder if it does not exists.", "response": "def create_folder_if_not_exists(folder_path):\n    \"\"\"Creates a folder if it does not exists.\"\"\"\n    folder_path = tilde_expansion(folder_path)\n    folder_path = \"\".join([folder_path, '/']) if not folder_path[-1] == '/' else folder_path\n    direc = os.path.dirname(folder_path)\n    if not folder_exists(direc):\n        os.makedirs(direc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing PyMOL with the given options.", "response": "def initialize_pymol(options):\n    \"\"\"Initializes PyMOL\"\"\"\n    import pymol\n    # Pass standard arguments of function to prevent PyMOL from printing out PDB headers (workaround)\n    pymol.finish_launching(args=['pymol', options, '-K'])\n    pymol.cmd.reinitialize()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart up PyMOL and sets general options. Quiet mode suppresses all PyMOL output.", "response": "def start_pymol(quiet=False, options='-p', run=False):\n    \"\"\"Starts up PyMOL and sets general options. Quiet mode suppresses all PyMOL output.\n    Command line options can be passed as the second argument.\"\"\"\n    import pymol\n    pymol.pymol_argv = ['pymol', '%s' % options] + sys.argv[1:]\n    if run:\n        initialize_pymol(options)\n    if quiet:\n        pymol.cmd.feedback('disable', 'all', 'everything')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsupports for DNA and RNA ligands by finding missing covalent linkages to stitch DNA / RNA together.", "response": "def nucleotide_linkage(residues):\n    \"\"\"Support for DNA/RNA ligands by finding missing covalent linkages to stitch DNA/RNA together.\"\"\"\n\n    nuc_covalent = []\n    #######################################\n    # Basic support for RNA/DNA as ligand #\n    #######################################\n    nucleotides = ['A', 'C', 'T', 'G', 'U', 'DA', 'DC', 'DT', 'DG', 'DU']\n    dna_rna = {}  # Dictionary of DNA/RNA residues by chain\n    covlinkage = namedtuple(\"covlinkage\", \"id1 chain1 pos1 conf1 id2 chain2 pos2 conf2\")\n    # Create missing covlinkage entries for DNA/RNA\n    for ligand in residues:\n        resname, chain, pos = ligand\n        if resname in nucleotides:\n            if chain not in dna_rna:\n                dna_rna[chain] = [(resname, pos), ]\n            else:\n                dna_rna[chain].append((resname, pos))\n    for chain in dna_rna:\n        nuc_list = dna_rna[chain]\n        for i, nucleotide in enumerate(nuc_list):\n            if not i == len(nuc_list) - 1:\n                name, pos = nucleotide\n                nextnucleotide = nuc_list[i + 1]\n                nextname, nextpos = nextnucleotide\n                newlink = covlinkage(id1=name, chain1=chain, pos1=pos, conf1='',\n                                     id2=nextname, chain2=chain, pos2=nextpos, conf2='')\n                nuc_covalent.append(newlink)\n\n    return nuc_covalent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the ring is sufficiently planar", "response": "def ring_is_planar(ring, r_atoms):\n    \"\"\"Given a set of ring atoms, check if the ring is sufficiently planar\n    to be considered aromatic\"\"\"\n    normals = []\n    for a in r_atoms:\n        adj = pybel.ob.OBAtomAtomIter(a.OBAtom)\n        # Check for neighboring atoms in the ring\n        n_coords = [pybel.Atom(neigh).coords for neigh in adj if ring.IsMember(neigh)]\n        vec1, vec2 = vector(a.coords, n_coords[0]), vector(a.coords, n_coords[1])\n        normals.append(np.cross(vec1, vec2))\n    # Given all normals of ring atoms and their neighbors, the angle between any has to be 5.0 deg or less\n    for n1, n2 in itertools.product(normals, repeat=2):\n        arom_angle = vecangle(n1, n2)\n        if all([arom_angle > config.AROMATIC_PLANARITY, arom_angle < 180.0 - config.AROMATIC_PLANARITY]):\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef classify_by_name(names):\n    if len(names) > 3:  # Polymer\n        if len(set(config.RNA).intersection(set(names))) != 0:\n            ligtype = 'RNA'\n        elif len(set(config.DNA).intersection(set(names))) != 0:\n            ligtype = 'DNA'\n        else:\n            ligtype = \"POLYMER\"\n    else:\n        ligtype = 'SMALLMOLECULE'\n\n    for name in names:\n        if name in config.METAL_IONS:\n            if len(names) == 1:\n                ligtype = 'ION'\n            else:\n                if \"ION\" not in ligtype:\n                    ligtype += '+ION'\n    return ligtype", "response": "Classify a composite ligand by the HETID s."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sort_members_by_importance(members):\n    main = [x for x in members if x[0] not in config.METAL_IONS]\n    ion = [x for x in members if x[0] in config.METAL_IONS]\n    sorted_main = sorted(main, key=lambda x: (x[1], x[2]))\n    sorted_main = sorted(main, key=lambda x: (x[1], x[2]))\n    sorted_ion = sorted(ion, key=lambda x: (x[1], x[2]))\n    return sorted_main + sorted_ion", "response": "Sort the members of a composite ligand according to two criteria."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_isomorphisms(reference, lig):\n    query = pybel.ob.CompileMoleculeQuery(reference.OBMol)\n    mappr = pybel.ob.OBIsomorphismMapper.GetInstance(query)\n    if all:\n        isomorphs = pybel.ob.vvpairUIntUInt()\n        mappr.MapAll(lig.OBMol, isomorphs)\n    else:\n        isomorphs = pybel.ob.vpairUIntUInt()\n        mappr.MapFirst(lig.OBMol, isomorphs)\n        isomorphs = [isomorphs]\n    write_message(\"Number of isomorphisms: %i\\n\" % len(isomorphs), mtype='debug')\n    # #@todo Check which isomorphism to take\n    return isomorphs", "response": "Get all isomorphisms of the ligand."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef canonicalize(lig, preserve_bond_order=False):\n    atomorder = None\n    # Get canonical atom order\n\n    lig = pybel.ob.OBMol(lig.OBMol)\n    if not preserve_bond_order:\n        for bond in pybel.ob.OBMolBondIter(lig):\n            if bond.GetBondOrder() != 1:\n                bond.SetBondOrder(1)\n    lig.DeleteData(pybel.ob.StereoData)\n    lig = pybel.Molecule(lig)\n    testcan = lig.write(format='can')\n    try:\n        pybel.readstring('can', testcan)\n        reference = pybel.readstring('can', testcan)\n    except IOError:\n        testcan, reference = '', ''\n    if testcan != '':\n        reference.removeh()\n        isomorphs = get_isomorphisms(reference, lig)  # isomorphs now holds all isomorphisms within the molecule\n        if not len(isomorphs) == 0:\n            smi_dict = {}\n            smi_to_can = isomorphs[0]\n            for x in smi_to_can:\n                smi_dict[int(x[1]) + 1] = int(x[0]) + 1\n            atomorder = [smi_dict[x + 1] for x in range(len(lig.atoms))]\n        else:\n            atomorder = None\n    return atomorder", "response": "Get the canonical atom order for the ligand."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a suspicious number represented as a 32 bit integer returns the actual number.", "response": "def int32_to_negative(int32):\n    \"\"\"Checks if a suspicious number (e.g. ligand position) is in fact a negative number represented as a\n    32 bit integer and returns the actual number.\n    \"\"\"\n    dct = {}\n    if int32 == 4294967295:  # Special case in some structures (note, this is just a workaround)\n        return -1\n    for i in range(-1000, -1):\n        dct[np.uint32(i)] = i\n    if int32 in dct:\n        return dct[int32]\n    else:\n        return int32"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_pdb(pdbfname, as_string=False):\n    pybel.ob.obErrorLog.StopLogging()  # Suppress all OpenBabel warnings\n    if os.name != 'nt':  # Resource module not available for Windows\n        maxsize = resource.getrlimit(resource.RLIMIT_STACK)[-1]\n        resource.setrlimit(resource.RLIMIT_STACK, (min(2 ** 28, maxsize), maxsize))\n    sys.setrecursionlimit(10 ** 5)  # increase Python recoursion limit\n    return readmol(pdbfname, as_string=as_string)", "response": "Reads a given PDB file and returns a Pybel Molecule."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a file handler and detects gzipped files.", "response": "def read(fil):\n    \"\"\"Returns a file handler and detects gzipped files.\"\"\"\n    if os.path.splitext(fil)[-1] == '.gz':\n        return gzip.open(fil, 'rb')\n    elif os.path.splitext(fil)[-1] == '.zip':\n        zf = zipfile.ZipFile(fil, 'r')\n        return zf.open(zf.infolist()[0].filename)\n    else:\n        return open(fil, 'r')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the given file and returns the corresponding Pybel molecule as well as the input file type.", "response": "def readmol(path, as_string=False):\n    \"\"\"Reads the given molecule file and returns the corresponding Pybel molecule as well as the input file type.\n    In contrast to the standard Pybel implementation, the file is closed properly.\"\"\"\n    supported_formats = ['pdb']\n    # Fix for Windows-generated files: Remove carriage return characters\n    if \"\\r\" in path and as_string:\n        path = path.replace('\\r', '')\n\n    for sformat in supported_formats:\n        obc = pybel.ob.OBConversion()\n        obc.SetInFormat(sformat)\n        write_message(\"Detected {} as format. Trying to read file with OpenBabel...\\n\".format(sformat), mtype='debug')\n\n        # Read molecules with single bond information\n        if as_string:\n            try:\n                mymol = pybel.readstring(sformat, path)\n            except IOError:\n                sysexit(4, 'No valid file format provided.')\n        else:\n            read_file = pybel.readfile(format=sformat, filename=path, opt={\"s\": None})\n            try:\n                mymol = next(read_file)\n            except StopIteration:\n                sysexit(4, 'File contains no valid molecules.\\n')\n\n        write_message(\"Molecule successfully read.\\n\", mtype='debug')\n\n        # Assign multiple bonds\n        mymol.OBMol.PerceiveBondOrders()\n        return mymol, sformat\n\n    sysexit(4, 'No valid file format provided.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef colorlog(msg, color, bold=False, blink=False):\n\n    # ANSI Escape Codes\n    PINK_COL = '\\x1b[35m'\n    GREEN_COL = '\\x1b[32m'\n    RED_COL = '\\x1b[31m'\n    YELLOW_COL = '\\x1b[33m'\n    BLINK = '\\x1b[5m'\n    RESET = '\\x1b[0m'\n\n    if platform.system() != 'Windows':\n        if blink:\n            msg = BLINK + msg + RESET\n        if color == 'yellow':\n            msg = YELLOW_COL + msg + RESET\n        if color == 'red':\n            msg = RED_COL + msg + RESET\n        if color == 'green':\n            msg = GREEN_COL + msg + RESET\n        if color == 'pink':\n            msg = PINK_COL + msg + RESET\n    return msg", "response": "Colors messages on non-Windows systems supporting ANSI escape."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_message(msg, indent=False, mtype='standard', caption=False):\n    if (mtype == 'debug' and config.DEBUG) or (mtype != 'debug' and config.VERBOSE) or mtype == 'error':\n        message(msg, indent=indent, mtype=mtype, caption=caption)", "response": "Writes a message to the log file if verbose mode is set."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a message to the log", "response": "def message(msg, indent=False, mtype='standard', caption=False):\n    \"\"\"Writes messages in verbose mode\"\"\"\n    if caption:\n        msg = '\\n' + msg + '\\n' + '-'*len(msg) + '\\n'\n    if mtype == 'warning':\n        msg = colorlog('Warning:  ' + msg, 'yellow')\n    if mtype == 'error':\n        msg = colorlog('Error:  ' + msg, 'red')\n    if mtype == 'debug':\n        msg = colorlog('Debug:  ' + msg, 'pink')\n    if mtype == 'info':\n        msg = colorlog('Info:  ' + msg, 'green')\n    if indent:\n        msg = '  ' + msg\n    sys.stderr.write(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_related(parser, token):\n    bits = token.split_contents()\n    obj_var, count, var_name, mods, finder = parse_related_tag(bits)\n    return RelatedNode(obj_var, count, var_name, mods, finder)", "response": "Parse related tag into a context variable optionally specifying related finder."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding some content type info of self. target", "response": "def PublishableBox(publishable, box_type, nodelist, model=None):\n    \"add some content type info of self.target\"\n    if not model:\n        model = publishable.content_type.model_class()\n    box_class = model.box_class\n\n    if box_class == PublishableBox:\n        box_class = Box\n    return box_class(publishable, box_type, nodelist, model=model)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelegate the boxing to the target s Box class.", "response": "def ListingBox(listing, *args, **kwargs):\n    \" Delegate the boxing to the target's Box class. \"\n    obj = listing.publishable\n    return obj.box_class(obj, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_absolute_url(self, domain=False):\n        \" Get object's URL. \"\n        category = self.category\n\n        kwargs = {\n            'slug': self.slug,\n        }\n\n        if self.static:\n            kwargs['id'] = self.pk\n            if category.tree_parent_id:\n                kwargs['category'] = category.tree_path\n                url = reverse('static_detail', kwargs=kwargs)\n            else:\n                url = reverse('home_static_detail', kwargs=kwargs)\n        else:\n            publish_from = localize(self.publish_from)\n            kwargs.update({\n                    'year': publish_from.year,\n                    'month': publish_from.month,\n                    'day': publish_from.day,\n                })\n            if category.tree_parent_id:\n                kwargs['category'] = category.tree_path\n                url = reverse('object_detail', kwargs=kwargs)\n            else:\n                url = reverse('home_object_detail', kwargs=kwargs)\n\n        if category.site_id != settings.SITE_ID or domain:\n            return 'http://' + category.site.domain + url\n        return url", "response": "Get object s URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_published(self):\n        \"Return True if the Publishable is currently active.\"\n        cur_time = now()\n        return self.published and cur_time > self.publish_from and \\\n            (self.publish_to is None or cur_time < self.publish_to)", "response": "Return True if the Publishable is currently active."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_params(self, text):\n        \" Parse the parameters into a dict. \"\n        params = MultiValueDict()\n        for line in text.split('\\n'):\n            pair = line.split(':', 1)\n            if len(pair) == 2:\n                params.appendlist(pair[0].strip(), pair[1].strip())\n        return params", "response": "Parse the parameters into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the object for the next processing.", "response": "def prepare(self, context):\n        \"\"\"\n        Do the pre-processing - render and parse the parameters and\n        store them for further use in self.params.\n        \"\"\"\n        self.params = {}\n\n        # no params, not even a newline\n        if not self.nodelist:\n            return\n\n        # just static text, no vars, assume one TextNode\n        if not self.nodelist.contains_nontext:\n            text = self.nodelist[0].s.strip()\n\n        # vars in params, we have to render\n        else:\n            context.push()\n            context['object'] = self.obj\n            text = self.nodelist.render(context)\n            context.pop()\n\n        if text:\n            self.params = self.resolve_params(text)\n\n        # override the default template from the parameters\n        if 'template_name' in self.params:\n            self.template_name = self.params['template_name']"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets context to render the template.", "response": "def get_context(self):\n        \" Get context to render the template. \"\n        return {\n                'content_type_name' : str(self.name),\n                'content_type_verbose_name' : self.verbose_name,\n                'content_type_verbose_name_plural' : self.verbose_name_plural,\n                'object' : self.obj,\n                'box' : self,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render(self, context):\n        self.prepare(context)\n        \" Cached wrapper around self._render(). \"\n        if getattr(settings, 'DOUBLE_RENDER', False) and self.can_double_render:\n            if 'SECOND_RENDER' not in context:\n                return self.double_render()\n        key = self.get_cache_key()\n        if key:\n            rend = cache.get(key)\n            if rend is None:\n                rend = self._render(context)\n                cache.set(key, rend, core_settings.CACHE_TIMEOUT)\n        else:\n            rend = self._render(context)\n        return rend", "response": "Cached wrapper around self. _render."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_template_list(self):\n        \" Get the hierarchy of templates belonging to the object/box_type given. \"\n        t_list = []\n        if hasattr(self.obj, 'category_id') and self.obj.category_id:\n            cat = self.obj.category\n            base_path = 'box/category/%s/content_type/%s/' % (cat.path, self.name)\n            if hasattr(self.obj, 'slug'):\n                t_list.append(base_path + '%s/%s.html' % (self.obj.slug, self.box_type,))\n            t_list.append(base_path + '%s.html' % (self.box_type,))\n            t_list.append(base_path + 'box.html')\n\n        base_path = 'box/content_type/%s/' % self.name\n        if hasattr(self.obj, 'slug'):\n            t_list.append(base_path + '%s/%s.html' % (self.obj.slug, self.box_type,))\n        t_list.append(base_path + '%s.html' % (self.box_type,))\n        t_list.append(base_path + 'box.html')\n\n        t_list.append('box/%s.html' % self.box_type)\n        t_list.append('box/box.html')\n\n        return t_list", "response": "Get the hierarchy of templates belonging to the object / box_type given."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_cache_key(self):\n        \" Return a cache key constructed from the box's parameters. \"\n        if not self.is_model:\n            return None\n\n        pars = ''\n        if self.params:\n            pars = ','.join(':'.join((smart_str(key), smart_str(self.params[key]))) for key in sorted(self.params.keys()))\n\n        return normalize_key('%s:box:%d:%s:%s' % (\n                _get_key(KEY_PREFIX, self.ct, pk=self.obj.pk), settings.SITE_ID, str(self.box_type), pars\n            ))", "response": "Return a cache key constructed from the box s parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, **kwargs):\n        \"Override save() to construct tree_path based on the category's parent.\"\n        old_tree_path = self.tree_path\n        if self.tree_parent:\n            if self.tree_parent.tree_path:\n                self.tree_path = '%s/%s' % (self.tree_parent.tree_path, self.slug)\n            else:\n                self.tree_path = self.slug\n        else:\n            self.tree_path = ''\n        Category.objects.clear_cache()\n        super(Category, self).save(**kwargs)\n        if old_tree_path != self.tree_path:\n            # the tree_path has changed, update children\n            children = Category.objects.filter(tree_parent=self)\n            for child in children:\n                child.save(force_update=True)", "response": "Override save () to construct tree_path based on the category s parent."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_absolute_url(self):\n        if not self.tree_parent_id:\n            url = reverse('root_homepage')\n        else:\n            url = reverse('category_detail', kwargs={'category' : self.tree_path})\n        if self.site_id != settings.SITE_ID:\n            # prepend the domain if it doesn't match current Site\n            return 'http://' + self.site.domain + url\n        return url", "response": "Returns the absolute URL for the category."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef listing(parser, token):\n    var_name, parameters = listing_parse(token.split_contents())\n    return ListingNode(var_name, parameters)", "response": "Return a list of top objects for a given category and store them in context under given name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntagging Node representing our idea of a reusable box. It can handle multiple parameters in its body which will then be accessible via ``{{ box.params }}`` in the template being rendered. .. note:: The inside of the box will be rendered only when redering the box in current context and the ``object`` template variable will be present and set to the target of the box. Author of any ``Model`` can specify it's own ``box_class`` which enables custom handling of some content types (boxes for polls for example need some extra information to render properly). Boxes, same as :ref:`core-views`, look for most specific template for a given object an only fall back to more generic template if the more specific one doesn't exist. The list of templates it looks for: * ``box/category/<tree_path>/content_type/<app>.<model>/<slug>/<box_name>.html`` * ``box/category/<tree_path>/content_type/<app>.<model>/<box_name>.html`` * ``box/category/<tree_path>/content_type/<app>.<model>/box.html`` * ``box/content_type/<app>.<model>/<slug>/<box_name>.html`` * ``box/content_type/<app>.<model>/<box_name>.html`` * ``box/content_type/<app>.<model>/box.html`` * ``box/<box_name>.html`` * ``box/box.html`` .. note:: Since boxes work for all models (and not just ``Publishable`` subclasses), some template names don't exist for some model classes, for example ``Photo`` model doesn't have a link to ``Category`` so that cannot be used. Boxes are always rendered in current context with added variables: * ``object`` - object being represented * ``box`` - instance of ``ella.core.box.Box`` Usage:: {% box <boxtype> for <app.model> with <field> <value> %} param_name: value param_name_2: {{ some_var }} {% endbox %} {% box <boxtype> for <var_name> %} ... {% endbox %} Parameters: ================================== ================================================ Option Description ================================== ================================================ ``boxtype`` Name of the box to use ``app.model`` Model class to use ``field`` Field on which to do DB lookup ``value`` Value for DB lookup ``var_name`` Template variable to get the instance from ================================== ================================================ Examples:: {% box home_listing for articles.article with slug \"some-slug\" %}{% endbox %} {% box home_listing for articles.article with pk object_id %} template_name : {{object.get_box_template}} {% endbox %} {% box home_listing for article %}{% endbox %}", "response": "def do_box(parser, token):\n    \"\"\"\n    Tag Node representing our idea of a reusable box. It can handle multiple\n    parameters in its body which will then be accessible via ``{{ box.params\n    }}`` in the template being rendered.\n\n    .. note::\n        The inside of the box will be rendered only when redering the box in\n        current context and the ``object`` template variable will be present\n        and set to the target of the box.\n\n    Author of any ``Model`` can specify it's own ``box_class`` which enables\n    custom handling of some content types (boxes for polls for example need\n    some extra information to render properly).\n\n    Boxes, same as :ref:`core-views`, look for most specific template for a given\n    object an only fall back to more generic template if the more specific one\n    doesn't exist. The list of templates it looks for:\n\n    * ``box/category/<tree_path>/content_type/<app>.<model>/<slug>/<box_name>.html``\n    * ``box/category/<tree_path>/content_type/<app>.<model>/<box_name>.html``\n    * ``box/category/<tree_path>/content_type/<app>.<model>/box.html``\n    * ``box/content_type/<app>.<model>/<slug>/<box_name>.html``\n    * ``box/content_type/<app>.<model>/<box_name>.html``\n    * ``box/content_type/<app>.<model>/box.html``\n    * ``box/<box_name>.html``\n    * ``box/box.html``\n\n    .. note::\n        Since boxes work for all models (and not just ``Publishable`` subclasses),\n        some template names don't exist for some model classes, for example\n        ``Photo`` model doesn't have a link to ``Category`` so that cannot be used.\n\n    Boxes are always rendered in current context with added variables:\n\n    * ``object`` - object being represented\n    * ``box`` - instance of ``ella.core.box.Box``\n\n    Usage::\n\n        {% box <boxtype> for <app.model> with <field> <value> %}\n            param_name: value\n            param_name_2: {{ some_var }}\n        {% endbox %}\n\n        {% box <boxtype> for <var_name> %}\n            ...\n        {% endbox %}\n\n    Parameters:\n\n        ==================================  ================================================\n        Option                              Description\n        ==================================  ================================================\n        ``boxtype``                         Name of the box to use\n        ``app.model``                       Model class to use\n        ``field``                           Field on which to do DB lookup\n        ``value``                           Value for DB lookup\n        ``var_name``                        Template variable to get the instance from\n        ==================================  ================================================\n\n    Examples::\n\n        {% box home_listing for articles.article with slug \"some-slug\" %}{% endbox %}\n\n        {% box home_listing for articles.article with pk object_id %}\n            template_name : {{object.get_box_template}}\n        {% endbox %}\n\n        {% box home_listing for article %}{% endbox %}\n    \"\"\"\n    bits = token.split_contents()\n\n    nodelist = parser.parse(('end' + bits[0],))\n    parser.delete_first_token()\n    return _parse_box(nodelist, bits)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_render(parser, token):\n    bits = token.split_contents()\n\n    if len(bits) != 2:\n        raise template.TemplateSyntaxError()\n\n    return RenderNode(bits[1])", "response": "Renders a rich - text field using defined markup."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister modules for later usage", "response": "def register(app_name, modules):\n    \"\"\"\n    simple module registering for later usage\n    we don't want to import admin.py in models.py\n    \"\"\"\n    global INSTALLED_APPS_REGISTER\n    mod_list = INSTALLED_APPS_REGISTER.get(app_name, [])\n\n    if isinstance(modules, basestring):\n        mod_list.append(modules)\n    elif is_iterable(modules):\n        mod_list.extend(modules)\n\n    INSTALLED_APPS_REGISTER[app_name] = mod_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef call_modules(auto_discover=()):\n    for app in settings.INSTALLED_APPS:\n        modules = set(auto_discover)\n        if app in INSTALLED_APPS_REGISTER:\n            modules.update(INSTALLED_APPS_REGISTER[app])\n        for module in modules:\n            mod = import_module(app)\n            try:\n                import_module('%s.%s' % (app, module))\n                inst = getattr(mod, '__install__', lambda: None)\n                inst()\n            except:\n                if module_has_submodule(mod, module):\n                    raise\n    app_modules_loaded.send(sender=None)", "response": "Call modules in the current project"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef related_by_category(obj, count, collected_so_far, mods=[], only_from_same_site=True):\n    related = []\n    # top objects in given category\n    if count > 0:\n        from ella.core.models import Listing\n        cat = obj.category\n        listings = Listing.objects.get_queryset_wrapper(\n            category=cat,\n            content_types=[ContentType.objects.get_for_model(m) for m in mods]\n        )\n        for l in listings[0:count + len(related)]:\n            t = l.publishable\n            if t != obj and t not in collected_so_far and t not in related:\n                related.append(t)\n                count -= 1\n\n            if count <= 0:\n                return related\n    return related", "response": "Returns related Publishable objects related to obj by using the same\n    category principle. Returns up to count objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning objects related to obj up to count by searching related objects by searching related_ct and related_id.", "response": "def directly_related(obj, count, collected_so_far, mods=[], only_from_same_site=True):\n    \"\"\"\n    Returns objects related to ``obj`` up to ``count`` by searching\n    ``Related`` instances for the ``obj``.\n    \"\"\"\n    # manually entered dependencies\n    qset = Related.objects.filter(publishable=obj)\n\n    if mods:\n        qset = qset.filter(related_ct__in=[\n            ContentType.objects.get_for_model(m).pk for m in mods])\n\n    return get_cached_objects(qset.values_list('related_ct', 'related_id')[:count], missing=SKIP)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef construct_xml_tree(self):\n        report = et.Element('report')\n        plipversion = et.SubElement(report, 'plipversion')\n        plipversion.text = __version__\n        date_of_creation = et.SubElement(report, 'date_of_creation')\n        date_of_creation.text = time.strftime(\"%Y/%m/%d\")\n        citation_information = et.SubElement(report, 'citation_information')\n        citation_information.text = \"Salentin,S. et al. PLIP: fully automated protein-ligand interaction profiler. \" \\\n            \"Nucl. Acids Res. (1 July 2015) 43 (W1): W443-W447. doi: 10.1093/nar/gkv315\"\n        mode = et.SubElement(report, 'mode')\n        if config.DNARECEPTOR:\n            mode.text = 'dna_receptor'\n        else:\n            mode.text = 'default'\n        pdbid = et.SubElement(report, 'pdbid')\n        pdbid.text = self.mol.pymol_name.upper()\n        filetype = et.SubElement(report, 'filetype')\n        filetype.text = self.mol.filetype.upper()\n        pdbfile = et.SubElement(report, 'pdbfile')\n        pdbfile.text = self.mol.sourcefiles['pdbcomplex']\n        pdbfixes = et.SubElement(report, 'pdbfixes')\n        pdbfixes.text = str(self.mol.information['pdbfixes'])\n        filename = et.SubElement(report, 'filename')\n        filename.text = str(self.mol.sourcefiles.get('filename') or None)\n        exligs = et.SubElement(report, 'excluded_ligands')\n        for i, exlig in enumerate(self.excluded):\n            e = et.SubElement(exligs, 'excluded_ligand', id=str(i + 1))\n            e.text = exlig\n        covalent = et.SubElement(report, 'covlinkages')\n        for i, covlinkage in enumerate(self.mol.covalent):\n            e = et.SubElement(covalent, 'covlinkage', id=str(i + 1))\n            f1 = et.SubElement(e, 'res1')\n            f2 = et.SubElement(e, 'res2')\n            f1.text = \":\".join([covlinkage.id1, covlinkage.chain1, str(covlinkage.pos1)])\n            f2.text = \":\".join([covlinkage.id2, covlinkage.chain2, str(covlinkage.pos2)])\n        return report", "response": "Construct the basic XML tree for the protein - ligand interaction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing the header of the txt file", "response": "def construct_txt_file(self):\n        \"\"\"Construct the header of the txt file\"\"\"\n        textlines = ['Prediction of noncovalent interactions for PDB structure %s' % self.mol.pymol_name.upper(), ]\n        textlines.append(\"=\" * len(textlines[0]))\n        textlines.append('Created on %s using PLIP v%s\\n' % (time.strftime(\"%Y/%m/%d\"), __version__))\n        textlines.append('If you are using PLIP in your work, please cite:')\n        textlines.append('Salentin,S. et al. PLIP: fully automated protein-ligand interaction profiler.')\n        textlines.append('Nucl. Acids Res. (1 July 2015) 43 (W1): W443-W447. doi: 10.1093/nar/gkv315\\n')\n        if len(self.excluded) != 0:\n            textlines.append('Excluded molecules as ligands: %s\\n' % ','.join([lig for lig in self.excluded]))\n        if config.DNARECEPTOR:\n            textlines.append('DNA/RNA in structure was chosen as the receptor part.\\n')\n        return textlines"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the additional data for the binding sites", "response": "def get_bindingsite_data(self):\n        \"\"\"Get the additional data for the binding sites\"\"\"\n        for i, site in enumerate(sorted(self.mol.interaction_sets)):\n            s = self.mol.interaction_sets[site]\n            bindingsite = BindingSiteReport(s).generate_xml()\n            bindingsite.set('id', str(i + 1))\n            bindingsite.set('has_interactions', 'False')\n            self.xmlreport.insert(i + 1, bindingsite)\n            for itype in BindingSiteReport(s).generate_txt():\n                self.txtreport.append(itype)\n            if not s.no_interactions:\n                bindingsite.set('has_interactions', 'True')\n            else:\n                self.txtreport.append('No interactions detected.')\n            sys.stdout = sys.__stdout__"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_xml(self, as_string=False):\n        if not as_string:\n            et.ElementTree(self.xmlreport).write('{}/{}.xml'.format(self.outpath, self.outputprefix), pretty_print=True, xml_declaration=True)\n        else:\n            output = et.tostring(self.xmlreport, pretty_print=True)\n            if config.RAWSTRING:\n                output = repr(output)\n            print(output)", "response": "Write the XML report"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_txt(self, as_string=False):\n        if not as_string:\n            with open('{}/{}.txt'.format(self.outpath, self.outputprefix), 'w') as f:\n                [f.write(textline + '\\n') for textline in self.txtreport]\n        else:\n            output = '\\n'.join(self.txtreport)\n            if config.RAWSTRING:\n                output = repr(output)\n            print(output)", "response": "Write the TXT report"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a section of the info to f.", "response": "def write_section(self, name, features, info, f):\n        \"\"\"Provides formatting for one section (e.g. hydrogen bonds)\"\"\"\n        if not len(info) == 0:\n            f.write('\\n\\n### %s ###\\n' % name)\n            f.write('%s\\n' % '\\t'.join(features))\n            for line in info:\n                f.write('%s\\n' % '\\t'.join(map(str, line)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive an array of strings returns and table in rST format.", "response": "def rst_table(self, array):\n        \"\"\"Given an array, the function formats and returns and table in rST format.\"\"\"\n        # Determine cell width for each column\n        cell_dict = {}\n        for i, row in enumerate(array):\n            for j, val in enumerate(row):\n                if j not in cell_dict:\n                    cell_dict[j] = []\n                cell_dict[j].append(val)\n        for item in cell_dict:\n            cell_dict[item] = max([len(x) for x in cell_dict[item]]) + 1  # Contains adapted width for each column\n\n        # Format top line\n        num_cols = len(array[0])\n        form = '+'\n        for col in range(num_cols):\n            form += (cell_dict[col] + 1) * '-'\n            form += '+'\n        form += '\\n'\n\n        # Format values\n        for i, row in enumerate(array):\n            form += '| '\n            for j, val in enumerate(row):\n                cell_width = cell_dict[j]\n                form += str(val) + (cell_width - len(val)) * ' ' + '| '\n            form.rstrip()\n            form += '\\n'\n\n            # Seperation lines\n            form += '+'\n            if i == 0:\n                sign = '='\n            else:\n                sign = '-'\n            for col in range(num_cols):\n                form += (cell_dict[col] + 1) * sign\n                form += '+'\n            form += '\\n'\n        return form"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_txt(self):\n\n        txt = []\n        titletext = '%s (%s) - %s' % (self.bsid, self.longname, self.ligtype)\n        txt.append(titletext)\n        for i, member in enumerate(self.lig_members[1:]):\n            txt.append('  + %s' % \":\".join(str(element) for element in member))\n        txt.append(\"-\" * len(titletext))\n        txt.append(\"Interacting chain(s): %s\\n\" % ','.join([chain for chain in self.interacting_chains]))\n        for section in [['Hydrophobic Interactions', self.hydrophobic_features, self.hydrophobic_info],\n                        ['Hydrogen Bonds', self.hbond_features, self.hbond_info],\n                        ['Water Bridges', self.waterbridge_features, self.waterbridge_info],\n                        ['Salt Bridges', self.saltbridge_features, self.saltbridge_info],\n                        ['pi-Stacking', self.pistacking_features, self.pistacking_info],\n                        ['pi-Cation Interactions', self.pication_features, self.pication_info],\n                        ['Halogen Bonds', self.halogen_features, self.halogen_info],\n                        ['Metal Complexes', self.metal_features, self.metal_info]]:\n            iname, features, interaction_information = section\n            # Sort results first by res number, then by distance and finally ligand coordinates to get a unique order\n            interaction_information = sorted(interaction_information, key=itemgetter(0, 2, -2))\n            if not len(interaction_information) == 0:\n\n                txt.append('\\n**%s**' % iname)\n                table = [features, ]\n                for single_contact in interaction_information:\n                    values = []\n                    for x in single_contact:\n                        if type(x) == str:\n                            values.append(x)\n                        elif type(x) == tuple and len(x) == 3:  # Coordinates\n                            values.append(\"%.3f, %.3f, %.3f\" % x)\n                        else:\n                            values.append(str(x))\n                    table.append(values)\n                txt.append(self.rst_table(table))\n        txt.append('\\n')\n        return txt", "response": "Generates a flat text report for a single binding site."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating an XML - formatted report for a single binding site.", "response": "def generate_xml(self):\n        \"\"\"Generates an XML-formatted report for a single binding site\"\"\"\n        report = et.Element('bindingsite')\n        identifiers = et.SubElement(report, 'identifiers')\n        longname = et.SubElement(identifiers, 'longname')\n        ligtype = et.SubElement(identifiers, 'ligtype')\n        hetid = et.SubElement(identifiers, 'hetid')\n        chain = et.SubElement(identifiers, 'chain')\n        position = et.SubElement(identifiers, 'position')\n        composite = et.SubElement(identifiers, 'composite')\n        members = et.SubElement(identifiers, 'members')\n        smiles = et.SubElement(identifiers, 'smiles')\n        inchikey = et.SubElement(identifiers, 'inchikey')\n\n        # Ligand properties. Number of (unpaired) functional atoms and rings.\n        lig_properties = et.SubElement(report, 'lig_properties')\n        num_heavy_atoms = et.SubElement(lig_properties, 'num_heavy_atoms')\n        num_hbd = et.SubElement(lig_properties, 'num_hbd')\n        num_hbd.text = str(self.ligand.num_hbd)\n        num_unpaired_hbd = et.SubElement(lig_properties, 'num_unpaired_hbd')\n        num_unpaired_hbd.text = str(self.complex.num_unpaired_hbd)\n        num_hba = et.SubElement(lig_properties, 'num_hba')\n        num_hba.text = str(self.ligand.num_hba)\n        num_unpaired_hba = et.SubElement(lig_properties, 'num_unpaired_hba')\n        num_unpaired_hba.text = str(self.complex.num_unpaired_hba)\n        num_hal = et.SubElement(lig_properties, 'num_hal')\n        num_hal.text = str(self.ligand.num_hal)\n        num_unpaired_hal = et.SubElement(lig_properties, 'num_unpaired_hal')\n        num_unpaired_hal.text = str(self.complex.num_unpaired_hal)\n        num_aromatic_rings = et.SubElement(lig_properties, 'num_aromatic_rings')\n        num_aromatic_rings.text = str(self.ligand.num_rings)\n        num_rot_bonds = et.SubElement(lig_properties, 'num_rotatable_bonds')\n        num_rot_bonds.text = str(self.ligand.num_rot_bonds)\n        molweight = et.SubElement(lig_properties, 'molweight')\n        molweight.text = str(self.ligand.molweight)\n        logp = et.SubElement(lig_properties, 'logp')\n        logp.text = str(self.ligand.logp)\n\n        ichains = et.SubElement(report, 'interacting_chains')\n        bsresidues = et.SubElement(report, 'bs_residues')\n        for i, ichain in enumerate(self.interacting_chains):\n            c = et.SubElement(ichains, 'interacting_chain', id=str(i + 1))\n            c.text = ichain\n        for i, bsres in enumerate(self.bs_res):\n            contact = 'True' if bsres in self.bs_res_interacting else 'False'\n            distance = '%.1f' % self.min_dist[bsres][0]\n            aatype = self.min_dist[bsres][1]\n            c = et.SubElement(bsresidues, 'bs_residue', id=str(i + 1), contact=contact, min_dist=distance, aa=aatype)\n            c.text = bsres\n        hetid.text, chain.text, position.text = self.ligand.hetid, self.ligand.chain, str(self.ligand.position)\n        composite.text = 'True' if len(self.lig_members) > 1 else 'False'\n        longname.text = self.longname\n        ligtype.text = self.ligtype\n        smiles.text = self.ligand.smiles\n        inchikey.text = self.ligand.inchikey\n        num_heavy_atoms.text = str(self.ligand.heavy_atoms)  # Number of heavy atoms in ligand\n        for i, member in enumerate(self.lig_members):\n            bsid = \":\".join(str(element) for element in member)\n            m = et.SubElement(members, 'member', id=str(i + 1))\n            m.text = bsid\n        interactions = et.SubElement(report, 'interactions')\n\n        def format_interactions(element_name, features, interaction_information):\n            \"\"\"Returns a formatted element with interaction information.\"\"\"\n            interaction = et.Element(element_name)\n            # Sort results first by res number, then by distance and finally ligand coordinates to get a unique order\n            interaction_information = sorted(interaction_information, key=itemgetter(0, 2, -2))\n            for j, single_contact in enumerate(interaction_information):\n                if not element_name == 'metal_complexes':\n                    new_contact = et.SubElement(interaction, element_name[:-1], id=str(j + 1))\n                else:  # Metal Complex[es]\n                    new_contact = et.SubElement(interaction, element_name[:-2], id=str(j + 1))\n                for i, feature in enumerate(single_contact):\n                    # Just assign the value unless it's an atom list, use subelements in this case\n                    if features[i] == 'LIG_IDX_LIST':\n                        feat = et.SubElement(new_contact, features[i].lower())\n                        for k, atm_idx in enumerate(feature.split(',')):\n                            idx = et.SubElement(feat, 'idx', id=str(k + 1))\n                            idx.text = str(atm_idx)\n                    elif features[i].endswith('COO'):\n                        feat = et.SubElement(new_contact, features[i].lower())\n                        xc, yc, zc = feature\n                        xcoo = et.SubElement(feat, 'x')\n                        xcoo.text = '%.3f' % xc\n                        ycoo = et.SubElement(feat, 'y')\n                        ycoo.text = '%.3f' % yc\n                        zcoo = et.SubElement(feat, 'z')\n                        zcoo.text = '%.3f' % zc\n                    else:\n                        feat = et.SubElement(new_contact, features[i].lower())\n                        feat.text = str(feature)\n            return interaction\n\n        interactions.append(format_interactions('hydrophobic_interactions', self.hydrophobic_features,\n                                                self.hydrophobic_info))\n        interactions.append(format_interactions('hydrogen_bonds', self.hbond_features, self.hbond_info))\n        interactions.append(format_interactions('water_bridges', self.waterbridge_features, self.waterbridge_info))\n        interactions.append(format_interactions('salt_bridges', self.saltbridge_features, self.saltbridge_info))\n        interactions.append(format_interactions('pi_stacks', self.pistacking_features, self.pistacking_info))\n        interactions.append(format_interactions('pi_cation_interactions', self.pication_features, self.pication_info))\n        interactions.append(format_interactions('halogen_bonds', self.halogen_features, self.halogen_info))\n        interactions.append(format_interactions('metal_complexes', self.metal_features, self.metal_info))\n\n        # Mappings\n        mappings = et.SubElement(report, 'mappings')\n        smiles_to_pdb = et.SubElement(mappings, 'smiles_to_pdb')  # SMILES numbering to PDB file numbering (atoms)\n        bsid = ':'.join([self.ligand.hetid, self.ligand.chain, str(self.ligand.position)])\n        if self.ligand.atomorder is not None:\n            smiles_to_pdb_map = [(key, self.ligand.Mapper.mapid(self.ligand.can_to_pdb[key],\n                                                                mtype='protein', bsid=bsid)) for key in self.ligand.can_to_pdb]\n            smiles_to_pdb.text = ','.join([str(mapping[0])+':'+str(mapping[1]) for mapping in smiles_to_pdb_map])\n        else:\n            smiles_to_pdb.text = ''\n\n        return report"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a single iterator of n elements of lists of length 3 given a sequence of len n.", "response": "def pool_args(function, sequence, kwargs):\n    \"\"\"Return a single iterator of n elements of lists of length 3, given a sequence of len n.\"\"\"\n    return zip(itertools.repeat(function), sequence, itertools.repeat(kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_pdb(self):\n        if self.as_string:\n            fil = self.pdbpath.rstrip('\\n').split('\\n')  # Removing trailing newline character\n        else:\n            f = read(self.pdbpath)\n            fil = f.readlines()\n            f.close()\n        corrected_lines = []\n        i, j = 0, 0  # idx and PDB numbering\n        d = {}\n        modres = set()\n        covalent = []\n        alt = []\n        previous_ter = False\n\n        # Standard without fixing\n        if not config.NOFIX:\n            if not config.PLUGIN_MODE:\n                lastnum = 0  # Atom numbering (has to be consecutive)\n                other_models = False\n                for line in fil:\n                    if not other_models:  # Only consider the first model in an NRM structure\n                        corrected_line, newnum = self.fix_pdbline(line, lastnum)\n                        if corrected_line is not None:\n                            if corrected_line.startswith('MODEL'):\n                                try:  # Get number of MODEL (1,2,3)\n                                    model_num = int(corrected_line[10:14])\n                                    if model_num > 1:  # MODEL 2,3,4 etc.\n                                        other_models = True\n                                except ValueError:\n                                    write_message(\"Ignoring invalid MODEL entry: %s\\n\" % corrected_line, mtype='debug')\n                            corrected_lines.append(corrected_line)\n                            lastnum = newnum\n                corrected_pdb = ''.join(corrected_lines)\n            else:\n                corrected_pdb = self.pdbpath\n                corrected_lines = fil\n        else:\n            corrected_pdb = self.pdbpath\n            corrected_lines = fil\n\n        for line in corrected_lines:\n            if line.startswith((\"ATOM\", \"HETATM\")):\n                # Retrieve alternate conformations\n                atomid, location = int(line[6:11]), line[16]\n                location = 'A' if location == ' ' else location\n                if location != 'A':\n                    alt.append(atomid)\n\n                if not previous_ter:\n                    i += 1\n                    j += 1\n                else:\n                    i += 1\n                    j += 2\n                d[i] = j\n                previous_ter = False\n            # Numbering Changes at TER records\n            if line.startswith(\"TER\"):\n                previous_ter = True\n            # Get modified residues\n            if line.startswith(\"MODRES\"):\n                modres.add(line[12:15].strip())\n            # Get covalent linkages between ligands\n            if line.startswith(\"LINK\"):\n                covalent.append(self.get_linkage(line))\n        return d, modres, covalent, alt, corrected_pdb", "response": "Parses the NRM structure and returns a list of modified residue IDs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fix_pdbline(self, pdbline, lastnum):\n        pdbqt_conversion = {\n            \"HD\": \"H\", \"HS\": \"H\", \"NA\": \"N\",\n            \"NS\": \"N\", \"OA\": \"O\", \"OS\": \"O\", \"SA\": \"S\"}\n        fixed = False\n        newnum = 0\n        forbidden_characters = \"[^a-zA-Z0-9_]\"\n        pdbline = pdbline.strip('\\n')\n        # Some MD / Docking tools produce empty lines, leading to segfaults\n        if len(pdbline.strip()) == 0:\n            self.num_fixed_lines += 1\n            return None, lastnum\n        if len(pdbline) > 100:  # Should be 80 long\n            self.num_fixed_lines += 1\n            return None, lastnum\n        # TER Entries also have continuing numbering, consider them as well\n        if pdbline.startswith('TER'):\n            newnum = lastnum + 1\n        if pdbline.startswith('ATOM'):\n            newnum = lastnum + 1\n            currentnum = int(pdbline[6:11])\n            resnum = pdbline[22:27].strip()\n            resname = pdbline[17:21].strip()\n            # Invalid residue number\n            try:\n                int(resnum)\n            except ValueError:\n                pdbline = pdbline[:22] + '   0 ' + pdbline[27:]\n                fixed = True\n            # Invalid characters in residue name\n            if re.match(forbidden_characters, resname.strip()):\n                pdbline = pdbline[:17] + 'UNK ' + pdbline[21:]\n                fixed = True\n            if lastnum + 1 != currentnum:\n                pdbline = pdbline[:6] + (5 - len(str(newnum))) * ' ' + str(newnum) + ' ' + pdbline[12:]\n                fixed = True\n            # No chain assigned\n            if pdbline[21] == ' ':\n                pdbline = pdbline[:21] + 'A' + pdbline[22:]\n                fixed = True\n            if pdbline.endswith('H'):\n                self.num_fixed_lines += 1\n                return None, lastnum\n            # Sometimes, converted PDB structures contain PDBQT atom types. Fix that.\n            for pdbqttype in pdbqt_conversion:\n                if pdbline.strip().endswith(pdbqttype):\n                    pdbline = pdbline.strip()[:-2] + ' ' + pdbqt_conversion[pdbqttype] + '\\n'\n                    self.num_fixed_lines += 1\n        if pdbline.startswith('HETATM'):\n            newnum = lastnum + 1\n            try:\n                currentnum = int(pdbline[6:11])\n            except ValueError:\n                currentnum = None\n                write_message(\"Invalid HETATM entry: %s\\n\" % pdbline, mtype='debug')\n            if lastnum + 1 != currentnum:\n                pdbline = pdbline[:6] + (5 - len(str(newnum))) * ' ' + str(newnum) + ' ' + pdbline[12:]\n                fixed = True\n            # No chain assigned or number assigned as chain\n            if pdbline[21] == ' ':\n                pdbline = pdbline[:21] + 'Z' + pdbline[22:]\n                fixed = True\n            # No residue number assigned\n            if pdbline[23:26] == '   ':\n                pdbline = pdbline[:23] + '999' + pdbline[26:]\n                fixed = True\n            # Non-standard Ligand Names\n            ligname = pdbline[17:21].strip()\n            if len(ligname) > 3:\n                pdbline = pdbline[:17] + ligname[:3] + ' ' + pdbline[21:]\n                fixed = True\n            if re.match(forbidden_characters, ligname.strip()):\n                pdbline = pdbline[:17] + 'LIG ' + pdbline[21:]\n                fixed = True\n            if len(ligname.strip()) == 0:\n                pdbline = pdbline[:17] + 'LIG ' + pdbline[21:]\n                fixed = True\n            if pdbline.endswith('H'):\n                self.num_fixed_lines += 1\n                return None, lastnum\n            # Sometimes, converted PDB structures contain PDBQT atom types. Fix that.\n            for pdbqttype in pdbqt_conversion:\n                if pdbline.strip().endswith(pdbqttype):\n                    pdbline = pdbline.strip()[:-2] + ' ' + pdbqt_conversion[pdbqttype] + ' '\n                    self.num_fixed_lines += 1\n        self.num_fixed_lines += 1 if fixed else 0\n        return pdbline + '\\n', max(newnum, lastnum)", "response": "Fix a PDB line if information is missing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_linkage(self, line):\n        conf1, id1, chain1, pos1 = line[16].strip(), line[17:20].strip(), line[21].strip(), int(line[22:26])\n        conf2, id2, chain2, pos2 = line[46].strip(), line[47:50].strip(), line[51].strip(), int(line[52:56])\n        return self.covlinkage(id1=id1, chain1=chain1, pos1=pos1, conf1=conf1,\n                               id2=id2, chain2=chain2, pos2=pos2, conf2=conf2)", "response": "Get the linkage information from a LINK entry PDB line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to extract the underlying ligand formed by all residues in the given chain. If the chain is not defined via the command line options the underlying ligand is returned. Otherwise None is returned.", "response": "def getpeptides(self, chain):\n        \"\"\"If peptide ligand chains are defined via the command line options,\n        try to extract the underlying ligand formed by all residues in the\n        given chain without water\n        \"\"\"\n        all_from_chain = [o for o in pybel.ob.OBResidueIter(\n            self.proteincomplex.OBMol) if o.GetChain() == chain]  # All residues from chain\n        if len(all_from_chain) == 0:\n            return None\n        else:\n            non_water = [o for o in all_from_chain if not o.GetResidueProperty(9)]\n            ligand = self.extract_ligand(non_water)\n            return ligand"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget all ligands from a PDB file and prepare them for analysis.", "response": "def getligs(self):\n        \"\"\"Get all ligands from a PDB file and prepare them for analysis.\n        Returns all non-empty ligands.\n        \"\"\"\n\n        if config.PEPTIDES == [] and config.INTRA is None:\n            # Extract small molecule ligands (default)\n            ligands = []\n\n            # Filter for ligands using lists\n            ligand_residues, self.lignames_all, self.water = self.filter_for_ligands()\n\n            all_res_dict = {(a.GetName(), a.GetChain(), a.GetNum()): a for a in ligand_residues}\n            self.lignames_kept = list(set([a.GetName() for a in ligand_residues]))\n\n            if not config.BREAKCOMPOSITE:\n                #  Update register of covalent links with those between DNA/RNA subunits\n                self.covalent += nucleotide_linkage(all_res_dict)\n                #  Find fragment linked by covalent bonds\n                res_kmers = self.identify_kmers(all_res_dict)\n            else:\n                res_kmers = [[a, ] for a in ligand_residues]\n            write_message(\"{} ligand kmer(s) detected for closer inspection.\\n\".format(len(res_kmers)), mtype='debug')\n            for kmer in res_kmers:  # iterate over all ligands and extract molecules + information\n                if len(kmer) > config.MAX_COMPOSITE_LENGTH:\n                    write_message(\"Ligand kmer(s) filtered out with a length of {} fragments ({} allowed).\\n\".format(\n                        len(kmer), config.MAX_COMPOSITE_LENGTH), mtype='debug')\n                else:\n                    ligands.append(self.extract_ligand(kmer))\n\n        else:\n            # Extract peptides from given chains\n            self.water = [o for o in pybel.ob.OBResidueIter(self.proteincomplex.OBMol) if o.GetResidueProperty(9)]\n            if config.PEPTIDES != []:\n                peptide_ligands = [self.getpeptides(chain) for chain in config.PEPTIDES]\n            elif config.INTRA is not None:\n                peptide_ligands = [self.getpeptides(config.INTRA), ]\n\n            ligands = [p for p in peptide_ligands if p is not None]\n            self.covalent, self.lignames_kept, self.lignames_all = [], [], set()\n\n        return [lig for lig in ligands if len(lig.mol.atoms) != 0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_ligand(self, kmer):\n        data = namedtuple('ligand', 'mol hetid chain position water members longname type atomorder can_to_pdb')\n        members = [(res.GetName(), res.GetChain(), int32_to_negative(res.GetNum())) for res in kmer]\n        members = sort_members_by_importance(members)\n        rname, rchain, rnum = members[0]\n        write_message(\"Finalizing extraction for ligand %s:%s:%s with %i elements\\n\" %\n                      (rname, rchain, rnum, len(kmer)), mtype='debug')\n        names = [x[0] for x in members]\n        longname = '-'.join([x[0] for x in members])\n\n        if config.PEPTIDES != []:\n            ligtype = 'PEPTIDE'\n        elif config.INTRA is not None:\n            ligtype = 'INTRA'\n        else:\n            # Classify a ligand by its HETID(s)\n            ligtype = classify_by_name(names)\n        write_message(\"Ligand classified as {}\\n\".format(ligtype), mtype='debug')\n\n        hetatoms = set()\n        for obresidue in kmer:\n            hetatoms_res = set([(obatom.GetIdx(), obatom) for obatom in pybel.ob.OBResidueAtomIter(obresidue)\n                                if obatom.GetAtomicNum() != 1])\n\n            if not config.ALTLOC:\n                # Remove alternative conformations (standard -> True)\n                hetatoms_res = set([atm for atm in hetatoms_res\n                                    if not self.mapper.mapid(atm[0], mtype='protein',\n                                                             to='internal') in self.altconformations])\n            hetatoms.update(hetatoms_res)\n        write_message(\"Hetero atoms determined (n={})\\n\".format(len(hetatoms)), mtype='debug')\n\n        hetatoms = dict(hetatoms)  # make it a dict with idx as key and OBAtom as value\n        lig = pybel.ob.OBMol()  # new ligand mol\n        neighbours = dict()\n        for obatom in hetatoms.values():  # iterate over atom objects\n            idx = obatom.GetIdx()\n            lig.AddAtom(obatom)\n            # ids of all neighbours of obatom\n            neighbours[idx] = set([neighbour_atom.GetIdx() for neighbour_atom\n                                   in pybel.ob.OBAtomAtomIter(obatom)]) & set(hetatoms.keys())\n        write_message(\"Atom neighbours mapped\\n\", mtype='debug')\n\n        ##############################################################\n        # map the old atom idx of OBMol to the new idx of the ligand #\n        ##############################################################\n\n        newidx = dict(zip(hetatoms.keys(), [obatom.GetIdx() for obatom in pybel.ob.OBMolAtomIter(lig)]))\n        mapold = dict(zip(newidx.values(), newidx))\n        # copy the bonds\n        for obatom in hetatoms:\n            for neighbour_atom in neighbours[obatom]:\n                bond = hetatoms[obatom].GetBond(hetatoms[neighbour_atom])\n                lig.AddBond(newidx[obatom], newidx[neighbour_atom], bond.GetBondOrder())\n        lig = pybel.Molecule(lig)\n\n        # For kmers, the representative ids are chosen (first residue of kmer)\n        lig.data.update({'Name': rname, 'Chain': rchain, 'ResNr': rnum})\n\n        # Check if a negative residue number is represented as a 32 bit integer\n        if rnum > 10 ** 5:\n            rnum = int32_to_negative(rnum)\n\n        lig.title = ':'.join((rname, rchain, str(rnum)))\n        self.mapper.ligandmaps[lig.title] = mapold\n\n        write_message(\"Renumerated molecule generated\\n\", mtype='debug')\n\n        if not config.NOPDBCANMAP:\n            atomorder = canonicalize(lig)\n        else:\n            atomorder = None\n\n        can_to_pdb = {}\n        if atomorder is not None:\n            can_to_pdb = {atomorder[key-1]: mapold[key] for key in mapold}\n\n        ligand = data(mol=lig, hetid=rname, chain=rchain, position=rnum, water=self.water,\n                      members=members, longname=longname, type=ligtype, atomorder=atomorder,\n                      can_to_pdb=can_to_pdb)\n        return ligand", "response": "Extract the ligand by copying atoms and bonds and assign all information necessary for later steps."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_het_residue(self, obres):\n        if not obres.GetResidueProperty(0):\n            # If the residue is NOT amino (0)\n            # It can be amino_nucleo, coenzme, ion, nucleo, protein, purine, pyrimidine, solvent\n            # In these cases, it is a ligand candidate\n            return True\n        else:\n            # Here, the residue is classified as amino\n            # Amino acids can still be ligands, so we check for HETATM entries\n            # Only residues with at least one HETATM entry are processed as ligands\n            het_atoms = []\n            for atm in pybel.ob.OBResidueAtomIter(obres):\n                het_atoms.append(obres.IsHetAtom(atm))\n            if True in het_atoms:\n                return True\n        return False", "response": "Determines if the given OBResidue is a possible ligand candidate\n            in the PDB file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_for_ligands(self):\n\n        candidates1 = [o for o in pybel.ob.OBResidueIter(\n            self.proteincomplex.OBMol) if not o.GetResidueProperty(9) and self.is_het_residue(o)]\n\n        if config.DNARECEPTOR:  # If DNA is the receptor, don't consider DNA as a ligand\n            candidates1 = [res for res in candidates1 if res.GetName() not in config.DNA+config.RNA]\n        all_lignames = set([a.GetName() for a in candidates1])\n\n        water = [o for o in pybel.ob.OBResidueIter(self.proteincomplex.OBMol) if o.GetResidueProperty(9)]\n        # Filter out non-ligands\n        if not config.KEEPMOD:  # Keep modified residues as ligands\n            candidates2 = [a for a in candidates1 if is_lig(a.GetName()) and a.GetName() not in self.modresidues]\n        else:\n            candidates2 = [a for a in candidates1 if is_lig(a.GetName())]\n        write_message(\"%i ligand(s) after first filtering step.\\n\" % len(candidates2), mtype='debug')\n\n        ############################################\n        # Filtering by counting and artifacts list #\n        ############################################\n        artifacts = []\n        unique_ligs = set(a.GetName() for a in candidates2)\n        for ulig in unique_ligs:\n            # Discard if appearing 15 times or more and is possible artifact\n            if ulig in config.biolip_list and [a.GetName() for a in candidates2].count(ulig) >= 15:\n                artifacts.append(ulig)\n\n        selected_ligands = [a for a in candidates2 if a.GetName() not in artifacts]\n\n        return selected_ligands, all_lignames, water", "response": "Given an OpenBabel Molecule get all ligands their names and water"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef identify_kmers(self, residues):\n\n        # Remove all those not considered by ligands and pairings including alternate conformations\n        ligdoubles = [[(link.id1, link.chain1, link.pos1),\n                       (link.id2, link.chain2, link.pos2)] for link in\n                      [c for c in self.covalent if c.id1 in self.lignames_kept and c.id2 in self.lignames_kept\n                       and c.conf1 in ['A', ''] and c.conf2 in ['A', '']\n                       and (c.id1, c.chain1, c.pos1) in residues\n                       and (c.id2, c.chain2, c.pos2) in residues]]\n        kmers = cluster_doubles(ligdoubles)\n        if not kmers:  # No ligand kmers, just normal independent ligands\n            return [[residues[res]] for res in residues]\n\n        else:\n            # res_kmers contains clusters of covalently bound ligand residues (kmer ligands)\n            res_kmers = [[residues[res] for res in kmer] for kmer in kmers]\n\n            # In this case, add other ligands which are not part of a kmer\n            in_kmer = []\n            for res_kmer in res_kmers:\n                for res in res_kmer:\n                    in_kmer.append((res.GetName(), res.GetChain(), res.GetNum()))\n            for res in residues:\n                if res not in in_kmer:\n                    newres = [residues[res], ]\n                    res_kmers.append(newres)\n            return res_kmers", "response": "Identify all residues in a ligand and return a list of residues that are part of a kmer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the atom for a given ligand ID.", "response": "def id_to_atom(self, idx):\n        \"\"\"Returns the atom for a given original ligand ID.\n        To do this, the ID is mapped to the protein first and then the atom returned.\n        \"\"\"\n        mapped_idx = self.mapid(idx, 'reversed')\n        return pybel.Atom(self.original_structure.GetAtom(mapped_idx))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nselect all carbon atoms which have only carbons and or hydrogens as direct neighbors.", "response": "def hydrophobic_atoms(self, all_atoms):\n        \"\"\"Select all carbon atoms which have only carbons and/or hydrogens as direct neighbors.\"\"\"\n        atom_set = []\n        data = namedtuple('hydrophobic', 'atom orig_atom orig_idx')\n        atm = [a for a in all_atoms if a.atomicnum == 6 and set([natom.GetAtomicNum() for natom\n                                                                 in pybel.ob.OBAtomAtomIter(a.OBAtom)]).issubset(\n            {1, 6})]\n        for atom in atm:\n            orig_idx = self.Mapper.mapid(atom.idx, mtype=self.mtype, bsid=self.bsid)\n            orig_atom = self.Mapper.id_to_atom(orig_idx)\n            if atom.idx not in self.altconf:\n                atom_set.append(data(atom=atom, orig_atom=orig_atom, orig_idx=orig_idx))\n        return atom_set"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_hba(self, all_atoms):\n        data = namedtuple('hbondacceptor', 'a a_orig_atom a_orig_idx type')\n        a_set = []\n        for atom in filter(lambda at: at.OBAtom.IsHbondAcceptor(), all_atoms):\n            if atom.atomicnum not in [9, 17, 35, 53] and atom.idx not in self.altconf:  # Exclude halogen atoms\n                a_orig_idx = self.Mapper.mapid(atom.idx, mtype=self.mtype, bsid=self.bsid)\n                a_orig_atom = self.Mapper.id_to_atom(a_orig_idx)\n                a_set.append(data(a=atom, a_orig_atom=a_orig_atom, a_orig_idx=a_orig_idx, type='regular'))\n        return a_set", "response": "Find all possible hydrogen bond acceptors"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_hbd(self, all_atoms, hydroph_atoms):\n        donor_pairs = []\n        data = namedtuple('hbonddonor', 'd d_orig_atom d_orig_idx h type')\n        for donor in [a for a in all_atoms if a.OBAtom.IsHbondDonor() and a.idx not in self.altconf]:\n            in_ring = False\n            if not in_ring:\n                for adj_atom in [a for a in pybel.ob.OBAtomAtomIter(donor.OBAtom) if a.IsHbondDonorH()]:\n                    d_orig_idx = self.Mapper.mapid(donor.idx, mtype=self.mtype, bsid=self.bsid)\n                    d_orig_atom = self.Mapper.id_to_atom(d_orig_idx)\n                    donor_pairs.append(data(d=donor, d_orig_atom=d_orig_atom, d_orig_idx=d_orig_idx,\n                                            h=pybel.Atom(adj_atom), type='regular'))\n        for carbon in hydroph_atoms:\n            for adj_atom in [a for a in pybel.ob.OBAtomAtomIter(carbon.atom.OBAtom) if a.GetAtomicNum() == 1]:\n                d_orig_idx = self.Mapper.mapid(carbon.atom.idx, mtype=self.mtype, bsid=self.bsid)\n                d_orig_atom = self.Mapper.id_to_atom(d_orig_idx)\n                donor_pairs.append(data(d=carbon, d_orig_atom=d_orig_atom,\n                                        d_orig_idx=d_orig_idx, h=pybel.Atom(adj_atom), type='weak'))\n        return donor_pairs", "response": "Find all possible strong and weak hydrogen bonds donors."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_rings(self, mol, all_atoms):\n        data = namedtuple('aromatic_ring', 'atoms orig_atoms atoms_orig_idx normal obj center type')\n        rings = []\n        aromatic_amino = ['TYR', 'TRP', 'HIS', 'PHE']\n        ring_candidates = mol.OBMol.GetSSSR()\n        write_message(\"Number of aromatic ring candidates: %i\\n\" % len(ring_candidates), mtype=\"debug\")\n        # Check here first for ligand rings not being detected as aromatic by Babel and check for planarity\n        for ring in ring_candidates:\n            r_atoms = [a for a in all_atoms if ring.IsMember(a.OBAtom)]\n            if 4 < len(r_atoms) <= 6:\n                res = list(set([whichrestype(a) for a in r_atoms]))\n                if ring.IsAromatic() or res[0] in aromatic_amino or ring_is_planar(ring, r_atoms):\n                    # Causes segfault with OpenBabel 2.3.2, so deactivated\n                    # typ = ring.GetType() if not ring.GetType() == '' else 'unknown'\n                    # Alternative typing\n                    typ = '%s-membered' % len(r_atoms)\n                    ring_atms = [r_atoms[a].coords for a in [0, 2, 4]]  # Probe atoms for normals, assuming planarity\n                    ringv1 = vector(ring_atms[0], ring_atms[1])\n                    ringv2 = vector(ring_atms[2], ring_atms[0])\n                    atoms_orig_idx = [self.Mapper.mapid(r_atom.idx, mtype=self.mtype,\n                                                        bsid=self.bsid) for r_atom in r_atoms]\n                    orig_atoms = [self.Mapper.id_to_atom(idx) for idx in atoms_orig_idx]\n                    rings.append(data(atoms=r_atoms,\n                                      orig_atoms=orig_atoms,\n                                      atoms_orig_idx=atoms_orig_idx,\n                                      normal=normalize_vector(np.cross(ringv1, ringv2)),\n                                      obj=ring,\n                                      center=centroid([ra.coords for ra in r_atoms]),\n                                      type=typ))\n        return rings", "response": "Find rings and return only aromatic. aromatic."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_unpaired_ligand(self):\n        unpaired_hba, unpaired_hbd, unpaired_hal = [], [], []\n        # Unpaired hydrogen bond acceptors/donors in ligand (not used for hydrogen bonds/water, salt bridges/mcomplex)\n        involved_atoms = [hbond.a.idx for hbond in self.hbonds_pdon] + [hbond.d.idx for hbond in self.hbonds_ldon]\n        [[involved_atoms.append(atom.idx) for atom in sb.negative.atoms] for sb in self.saltbridge_lneg]\n        [[involved_atoms.append(atom.idx) for atom in sb.positive.atoms] for sb in self.saltbridge_pneg]\n        [involved_atoms.append(wb.a.idx) for wb in self.water_bridges if wb.protisdon]\n        [involved_atoms.append(wb.d.idx) for wb in self.water_bridges if not wb.protisdon]\n        [involved_atoms.append(mcomplex.target.atom.idx) for mcomplex in self.metal_complexes\n         if mcomplex.location == 'ligand']\n        for atom in [hba.a for hba in self.ligand.get_hba()]:\n            if atom.idx not in involved_atoms:\n                unpaired_hba.append(atom)\n        for atom in [hbd.d for hbd in self.ligand.get_hbd()]:\n            if atom.idx not in involved_atoms:\n                unpaired_hbd.append(atom)\n\n        # unpaired halogen bond donors in ligand (not used for the previous + halogen bonds)\n        [involved_atoms.append(atom.don.x.idx) for atom in self.halogen_bonds]\n        for atom in [haldon.x for haldon in self.ligand.halogenbond_don]:\n            if atom.idx not in involved_atoms:\n                unpaired_hal.append(atom)\n\n        return unpaired_hba, unpaired_hbd, unpaired_hal", "response": "Identify unpaired functional in groups in ligands involving H - bond acceptors and halogen bond donors."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refine_hydrophobic(self, all_h, pistacks):\n        sel = {}\n        #  1. Rings interacting via stacking can't have additional hydrophobic contacts between each other.\n        for pistack, h in itertools.product(pistacks, all_h):\n            h1, h2 = h.bsatom.idx, h.ligatom.idx\n            brs, lrs = [p1.idx for p1 in pistack.proteinring.atoms], [p2.idx for p2 in pistack.ligandring.atoms]\n            if h1 in brs and h2 in lrs:\n                sel[(h1, h2)] = \"EXCLUDE\"\n        hydroph = [h for h in all_h if not (h.bsatom.idx, h.ligatom.idx) in sel]\n        sel2 = {}\n        #  2. If a ligand atom interacts with several binding site atoms in the same residue,\n        #  keep only the one with the closest distance\n        for h in hydroph:\n            if not (h.ligatom.idx, h.resnr) in sel2:\n                sel2[(h.ligatom.idx, h.resnr)] = h\n            else:\n                if sel2[(h.ligatom.idx, h.resnr)].distance > h.distance:\n                    sel2[(h.ligatom.idx, h.resnr)] = h\n        hydroph = [h for h in sel2.values()]\n        hydroph_final = []\n        bsclust = {}\n        #  3. If a protein atom interacts with several neighboring ligand atoms, just keep the one with the closest dist\n        for h in hydroph:\n            if h.bsatom.idx not in bsclust:\n                bsclust[h.bsatom.idx] = [h, ]\n            else:\n                bsclust[h.bsatom.idx].append(h)\n\n        idx_to_h = {}\n        for bs in [a for a in bsclust if len(bsclust[a]) == 1]:\n            hydroph_final.append(bsclust[bs][0])\n\n        # A list of tuples with the idx of an atom and one of its neighbours is created\n        for bs in [a for a in bsclust if not len(bsclust[a]) == 1]:\n            tuples = []\n            all_idx = [i.ligatom.idx for i in bsclust[bs]]\n            for b in bsclust[bs]:\n                idx = b.ligatom.idx\n                neigh = [na for na in pybel.ob.OBAtomAtomIter(b.ligatom.OBAtom)]\n                for n in neigh:\n                    n_idx = n.GetIdx()\n                    if n_idx in all_idx:\n                        if n_idx < idx:\n                            tuples.append((n_idx, idx))\n                        else:\n                            tuples.append((idx, n_idx))\n                        idx_to_h[idx] = b\n\n            tuples = list(set(tuples))\n            tuples = sorted(tuples, key=itemgetter(1))\n            clusters = cluster_doubles(tuples)  # Cluster connected atoms (i.e. find hydrophobic patches)\n\n            for cluster in clusters:\n                min_dist = float('inf')\n                min_h = None\n                for atm_idx in cluster:\n                    h = idx_to_h[atm_idx]\n                    if h.distance < min_dist:\n                        min_dist = h.distance\n                        min_h = h\n                hydroph_final.append(min_h)\n        before, reduced = len(all_h), len(hydroph_final)\n        if not before == 0 and not before == reduced:\n            write_message('Reduced number of hydrophobic contacts from %i to %i.\\n' % (before, reduced), indent=True)\n        return hydroph_final", "response": "Apply several rules to reduce the number of hydrophobic interactions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refine_pi_cation_laro(self, all_picat, stacks):\n        i_set = []\n        for picat in all_picat:\n            exclude = False\n            for stack in stacks:\n                if whichrestype(stack.proteinring.atoms[0]) == 'HIS' and picat.ring.obj == stack.ligandring.obj:\n                    exclude = True\n            if not exclude:\n                i_set.append(picat)\n        return i_set", "response": "This function is used to refine pi - cation interaction with ligand - specific ligand."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlooks for Halogen bond acceptors.", "response": "def find_hal(self, atoms):\n        \"\"\"Look for halogen bond acceptors (Y-{O|P|N|S}, with Y=C,P,S)\"\"\"\n        data = namedtuple('hal_acceptor', 'o o_orig_idx y y_orig_idx')\n        a_set = []\n        # All oxygens, nitrogen, sulfurs with neighboring carbon, phosphor, nitrogen or sulfur\n        for a in [at for at in atoms if at.atomicnum in [8, 7, 16]]:\n            n_atoms = [na for na in pybel.ob.OBAtomAtomIter(a.OBAtom) if na.GetAtomicNum() in [6, 7, 15, 16]]\n            if len(n_atoms) == 1:  # Proximal atom\n                o_orig_idx = self.Mapper.mapid(a.idx, mtype=self.mtype, bsid=self.bsid)\n                y_orig_idx = self.Mapper.mapid(n_atoms[0].GetIdx(), mtype=self.mtype, bsid=self.bsid)\n                a_set.append(data(o=a, o_orig_idx=o_orig_idx, y=pybel.Atom(n_atoms[0]), y_orig_idx=y_orig_idx))\n        return a_set"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlook for positive charges in arginine histidine or lysine and glutamic acid.", "response": "def find_charged(self, mol):\n        \"\"\"Looks for positive charges in arginine, histidine or lysine, for negative in aspartic and glutamic acid.\"\"\"\n        data = namedtuple('pcharge', 'atoms atoms_orig_idx type center restype resnr reschain')\n        a_set = []\n        # Iterate through all residue, exclude those in chains defined as peptides\n        for res in [r for r in pybel.ob.OBResidueIter(mol.OBMol) if not r.GetChain() in config.PEPTIDES]:\n            if config.INTRA is not None:\n                if res.GetChain() != config.INTRA:\n                    continue\n            a_contributing = []\n            a_contributing_orig_idx = []\n            if res.GetName() in ('ARG', 'HIS', 'LYS'):  # Arginine, Histidine or Lysine have charged sidechains\n                for a in pybel.ob.OBResidueAtomIter(res):\n                    if a.GetType().startswith('N') and res.GetAtomProperty(a, 8) \\\n                            and not self.Mapper.mapid(a.GetIdx(), mtype='protein') in self.altconf:\n                        a_contributing.append(pybel.Atom(a))\n                        a_contributing_orig_idx.append(self.Mapper.mapid(a.GetIdx(), mtype='protein'))\n                if not len(a_contributing) == 0:\n                    a_set.append(data(atoms=a_contributing,\n                                      atoms_orig_idx=a_contributing_orig_idx,\n                                      type='positive',\n                                      center=centroid([ac.coords for ac in a_contributing]),\n                                      restype=res.GetName(),\n                                      resnr=res.GetNum(),\n                                      reschain=res.GetChain()))\n            if res.GetName() in ('GLU', 'ASP'):  # Aspartic or Glutamic Acid\n                for a in pybel.ob.OBResidueAtomIter(res):\n                    if a.GetType().startswith('O') and res.GetAtomProperty(a, 8) \\\n                            and not self.Mapper.mapid(a.GetIdx(), mtype='protein') in self.altconf:\n                        a_contributing.append(pybel.Atom(a))\n                        a_contributing_orig_idx.append(self.Mapper.mapid(a.GetIdx(), mtype='protein'))\n                if not len(a_contributing) == 0:\n                    a_set.append(data(atoms=a_contributing,\n                                      atoms_orig_idx=a_contributing_orig_idx,\n                                      type='negative',\n                                      center=centroid([ac.coords for ac in a_contributing]),\n                                      restype=res.GetName(),\n                                      resnr=res.GetNum(),\n                                      reschain=res.GetChain()))\n        return a_set"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_metal_binding(self, mol):\n        data = namedtuple('metal_binding', 'atom atom_orig_idx type restype resnr reschain location')\n        a_set = []\n        for res in pybel.ob.OBResidueIter(mol.OBMol):\n            restype, reschain, resnr = res.GetName().upper(), res.GetChain(), res.GetNum()\n            if restype in ['ASP', 'GLU', 'SER', 'THR', 'TYR']:  # Look for oxygens here\n                for a in pybel.ob.OBResidueAtomIter(res):\n                    if a.GetType().startswith('O') and res.GetAtomProperty(a, 8) \\\n                            and not self.Mapper.mapid(a.GetIdx(), mtype='protein') in self.altconf:\n                        atom_orig_idx = self.Mapper.mapid(a.GetIdx(), mtype=self.mtype, bsid=self.bsid)\n                        a_set.append(data(atom=pybel.Atom(a), atom_orig_idx=atom_orig_idx, type='O', restype=restype,\n                                          resnr=resnr, reschain=reschain,\n                                          location='protein.sidechain'))\n            if restype == 'HIS':  # Look for nitrogen here\n                for a in pybel.ob.OBResidueAtomIter(res):\n                    if a.GetType().startswith('N') and res.GetAtomProperty(a, 8) \\\n                            and not self.Mapper.mapid(a.GetIdx(), mtype='protein') in self.altconf:\n                        atom_orig_idx = self.Mapper.mapid(a.GetIdx(), mtype=self.mtype, bsid=self.bsid)\n                        a_set.append(data(atom=pybel.Atom(a), atom_orig_idx=atom_orig_idx, type='N', restype=restype,\n                                          resnr=resnr, reschain=reschain,\n                                          location='protein.sidechain'))\n            if restype == 'CYS':  # Look for sulfur here\n                for a in pybel.ob.OBResidueAtomIter(res):\n                    if a.GetType().startswith('S') and res.GetAtomProperty(a, 8) \\\n                            and not self.Mapper.mapid(a.GetIdx(), mtype='protein') in self.altconf:\n                        atom_orig_idx = self.Mapper.mapid(a.GetIdx(), mtype=self.mtype, bsid=self.bsid)\n                        a_set.append(data(atom=pybel.Atom(a), atom_orig_idx=atom_orig_idx, type='S', restype=restype,\n                                          resnr=resnr, reschain=reschain,\n                                          location='protein.sidechain'))\n            for a in pybel.ob.OBResidueAtomIter(res):  # All main chain oxygens\n                if a.GetType().startswith('O') and res.GetAtomProperty(a, 2) \\\n                        and not self.Mapper.mapid(a.GetIdx(), mtype='protein') in self.altconf and restype != 'HOH':\n                    atom_orig_idx = self.Mapper.mapid(a.GetIdx(), mtype=self.mtype, bsid=self.bsid)\n                    a_set.append(data(atom=pybel.Atom(a), atom_orig_idx=atom_orig_idx, type='O', restype=res.GetName(),\n                                      resnr=res.GetNum(), reschain=res.GetChain(),\n                                      location='protein.mainchain'))\n        return a_set", "response": "Looks for atoms that could possibly be involved in chelating a metal ion."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a pybel atom look up if it belongs to a function group", "response": "def is_functional_group(self, atom, group):\n        \"\"\"Given a pybel atom, look up if it belongs to a function group\"\"\"\n        n_atoms = [a_neighbor.GetAtomicNum() for a_neighbor in pybel.ob.OBAtomAtomIter(atom.OBAtom)]\n\n        if group in ['quartamine', 'tertamine'] and atom.atomicnum == 7:  # Nitrogen\n            # It's a nitrogen, so could be a protonated amine or quaternary ammonium\n            if '1' not in n_atoms and len(n_atoms) == 4:\n                return True if group == 'quartamine' else False  # It's a quat. ammonium (N with 4 residues != H)\n            elif atom.OBAtom.GetHyb() == 3 and len(n_atoms) >= 3:\n                return True if group == 'tertamine' else False  # It's sp3-hybridized, so could pick up an hydrogen\n            else:\n                return False\n\n        if group in ['sulfonium', 'sulfonicacid', 'sulfate'] and atom.atomicnum == 16:  # Sulfur\n            if '1' not in n_atoms and len(n_atoms) == 3:  # It's a sulfonium (S with 3 residues != H)\n                return True if group == 'sulfonium' else False\n            elif n_atoms.count(8) == 3:  # It's a sulfonate or sulfonic acid\n                return True if group == 'sulfonicacid' else False\n            elif n_atoms.count(8) == 4:  # It's a sulfate\n                return True if group == 'sulfate' else False\n\n        if group == 'phosphate' and atom.atomicnum == 15:  # Phosphor\n            if set(n_atoms) == {8}:  # It's a phosphate\n                return True\n\n        if group in ['carboxylate', 'guanidine'] and atom.atomicnum == 6:  # It's a carbon atom\n            if n_atoms.count(8) == 2 and n_atoms.count(6) == 1:  # It's a carboxylate group\n                return True if group == 'carboxylate' else False\n            elif n_atoms.count(7) == 3 and len(n_atoms) == 3:  # It's a guanidine group\n                nitro_partners = []\n                for nitro in pybel.ob.OBAtomAtomIter(atom.OBAtom):\n                    nitro_partners.append(len([b_neighbor for b_neighbor in pybel.ob.OBAtomAtomIter(nitro)]))\n                if min(nitro_partners) == 1:  # One nitrogen is only connected to the carbon, can pick up a H\n                    return True if group == 'guanidine' else False\n\n        if group == 'halocarbon' and atom.atomicnum in [9, 17, 35, 53]:  # Halogen atoms\n            n_atoms = [na for na in pybel.ob.OBAtomAtomIter(atom.OBAtom) if na.GetAtomicNum() == 6]\n            if len(n_atoms) == 1:  # Halocarbon\n                return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind all halogen bond donors in the ligand.", "response": "def find_hal(self, atoms):\n        \"\"\"Look for halogen bond donors (X-C, with X=F, Cl, Br, I)\"\"\"\n        data = namedtuple('hal_donor', 'x orig_x x_orig_idx c c_orig_idx')\n        a_set = []\n        for a in atoms:\n            if self.is_functional_group(a, 'halocarbon'):\n                n_atoms = [na for na in pybel.ob.OBAtomAtomIter(a.OBAtom) if na.GetAtomicNum() == 6]\n                x_orig_idx = self.Mapper.mapid(a.idx, mtype=self.mtype, bsid=self.bsid)\n                orig_x = self.Mapper.id_to_atom(x_orig_idx)\n                c_orig_idx = [self.Mapper.mapid(na.GetIdx(), mtype=self.mtype, bsid=self.bsid) for na in n_atoms]\n                a_set.append(data(x=a, orig_x=orig_x, x_orig_idx=x_orig_idx,\n                                  c=pybel.Atom(n_atoms[0]), c_orig_idx=c_orig_idx))\n        if len(a_set) != 0:\n            write_message('Ligand contains %i halogen atom(s).\\n' % len(a_set), indent=True)\n        return a_set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nidentify all positively charged groups in a ligand.", "response": "def find_charged(self, all_atoms):\n        \"\"\"Identify all positively charged groups in a ligand. This search is not exhaustive, as the cases can be quite\n        diverse. The typical cases seem to be protonated amines, quaternary ammoinium and sulfonium\n        as mentioned in 'Cation-pi interactions in ligand recognition and catalysis' (Zacharias et al., 2002)).\n        Identify negatively charged groups in the ligand.\n        \"\"\"\n        data = namedtuple('lcharge', 'atoms orig_atoms atoms_orig_idx type center fgroup')\n        a_set = []\n        for a in all_atoms:\n            a_orig_idx = self.Mapper.mapid(a.idx, mtype=self.mtype, bsid=self.bsid)\n            a_orig = self.Mapper.id_to_atom(a_orig_idx)\n            if self.is_functional_group(a, 'quartamine'):\n                a_set.append(data(atoms=[a, ], orig_atoms=[a_orig, ], atoms_orig_idx=[a_orig_idx, ], type='positive',\n                                  center=list(a.coords), fgroup='quartamine'))\n            elif self.is_functional_group(a, 'tertamine'):\n                a_set.append(data(atoms=[a, ], orig_atoms=[a_orig, ], atoms_orig_idx=[a_orig_idx, ], type='positive', center=list(a.coords),\n                                  fgroup='tertamine'))\n            if self.is_functional_group(a, 'sulfonium'):\n                a_set.append(data(atoms=[a, ], orig_atoms=[a_orig, ], atoms_orig_idx=[a_orig_idx, ], type='positive', center=list(a.coords),\n                                  fgroup='sulfonium'))\n            if self.is_functional_group(a, 'phosphate'):\n                a_contributing = [a, ]\n                a_contributing_orig_idx = [a_orig_idx, ]\n                [a_contributing.append(pybel.Atom(neighbor)) for neighbor in pybel.ob.OBAtomAtomIter(a.OBAtom)]\n                [a_contributing_orig_idx.append(self.Mapper.mapid(neighbor.idx, mtype=self.mtype, bsid=self.bsid))\n                 for neighbor in a_contributing]\n                orig_contributing = [self.Mapper.id_to_atom(idx) for idx in a_contributing_orig_idx]\n                a_set.append(data(atoms=a_contributing, orig_atoms=orig_contributing, atoms_orig_idx=a_contributing_orig_idx, type='negative',\n                                  center=a.coords, fgroup='phosphate'))\n            if self.is_functional_group(a, 'sulfonicacid'):\n                a_contributing = [a, ]\n                a_contributing_orig_idx = [a_orig_idx, ]\n                [a_contributing.append(pybel.Atom(neighbor)) for neighbor in pybel.ob.OBAtomAtomIter(a.OBAtom) if\n                 neighbor.GetAtomicNum() == 8]\n                [a_contributing_orig_idx.append(self.Mapper.mapid(neighbor.idx, mtype=self.mtype, bsid=self.bsid))\n                 for neighbor in a_contributing]\n                orig_contributing = [self.Mapper.id_to_atom(idx) for idx in a_contributing_orig_idx]\n                a_set.append(data(atoms=a_contributing, orig_atoms=orig_contributing, atoms_orig_idx=a_contributing_orig_idx, type='negative',\n                                  center=a.coords, fgroup='sulfonicacid'))\n            elif self.is_functional_group(a, 'sulfate'):\n                a_contributing = [a, ]\n                a_contributing_orig_idx = [a_orig_idx, ]\n                [a_contributing_orig_idx.append(self.Mapper.mapid(neighbor.idx, mtype=self.mtype, bsid=self.bsid))\n                 for neighbor in a_contributing]\n                [a_contributing.append(pybel.Atom(neighbor)) for neighbor in pybel.ob.OBAtomAtomIter(a.OBAtom)]\n                orig_contributing = [self.Mapper.id_to_atom(idx) for idx in a_contributing_orig_idx]\n                a_set.append(data(atoms=a_contributing, orig_atoms=orig_contributing, atoms_orig_idx=a_contributing_orig_idx, type='negative',\n                                  center=a.coords, fgroup='sulfate'))\n            if self.is_functional_group(a, 'carboxylate'):\n                a_contributing = [pybel.Atom(neighbor) for neighbor in pybel.ob.OBAtomAtomIter(a.OBAtom)\n                                  if neighbor.GetAtomicNum() == 8]\n                a_contributing_orig_idx = [self.Mapper.mapid(neighbor.idx, mtype=self.mtype, bsid=self.bsid)\n                                           for neighbor in a_contributing]\n                orig_contributing = [self.Mapper.id_to_atom(idx) for idx in a_contributing_orig_idx]\n                a_set.append(data(atoms=a_contributing, orig_atoms=orig_contributing, atoms_orig_idx=a_contributing_orig_idx, type='negative',\n                                  center=centroid([a.coords for a in a_contributing]), fgroup='carboxylate'))\n            elif self.is_functional_group(a, 'guanidine'):\n                a_contributing = [pybel.Atom(neighbor) for neighbor in pybel.ob.OBAtomAtomIter(a.OBAtom)\n                                  if neighbor.GetAtomicNum() == 7]\n                a_contributing_orig_idx = [self.Mapper.mapid(neighbor.idx, mtype=self.mtype, bsid=self.bsid)\n                                           for neighbor in a_contributing]\n                orig_contributing = [self.Mapper.id_to_atom(idx) for idx in a_contributing_orig_idx]\n                a_set.append(data(atoms=a_contributing, orig_atoms=orig_contributing, atoms_orig_idx=a_contributing_orig_idx, type='positive',\n                                  center=a.coords, fgroup='guanidine'))\n        return a_set"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlooks for atoms that could possibly be involved in binding a metal ion.", "response": "def find_metal_binding(self, lig_atoms, water_oxygens):\n        \"\"\"Looks for atoms that could possibly be involved in binding a metal ion.\n        This can be any water oxygen, as well as oxygen from carboxylate, phophoryl, phenolate, alcohol;\n        nitrogen from imidazole; sulfur from thiolate.\n        \"\"\"\n        a_set = []\n        data = namedtuple('metal_binding', 'atom orig_atom atom_orig_idx type fgroup restype resnr reschain location')\n        for oxygen in water_oxygens:\n            a_set.append(data(atom=oxygen.oxy, atom_orig_idx=oxygen.oxy_orig_idx, type='O', fgroup='water',\n                              restype=whichrestype(oxygen.oxy), resnr=whichresnumber(oxygen.oxy),\n                              reschain=whichchain(oxygen.oxy), location='water', orig_atom=self.Mapper.id_to_atom(oxygen.oxy_orig_idx)))\n        # #@todo Refactor code\n        for a in lig_atoms:\n            a_orig_idx = self.Mapper.mapid(a.idx, mtype='ligand', bsid=self.bsid)\n            n_atoms = pybel.ob.OBAtomAtomIter(a.OBAtom)  # Neighboring atoms\n            # All atomic numbers of neighboring atoms\n            n_atoms_atomicnum = [n.GetAtomicNum() for n in pybel.ob.OBAtomAtomIter(a.OBAtom)]\n            if a.atomicnum == 8:  # Oxygen\n                if n_atoms_atomicnum.count('1') == 1 and len(n_atoms_atomicnum) == 2:  # Oxygen in alcohol (R-[O]-H)\n                    a_set.append(data(atom=a, atom_orig_idx=a_orig_idx, type='O', fgroup='alcohol',\n                                      restype=self.hetid, resnr=self.position, reschain=self.chain,\n                                      location='ligand', orig_atom=self.Mapper.id_to_atom(a_orig_idx)))\n                if True in [n.IsAromatic() for n in n_atoms] and not a.OBAtom.IsAromatic():  # Phenolate oxygen\n                    a_set.append(data(atom=a, atom_orig_idx=a_orig_idx, type='O', fgroup='phenolate',\n                                      restype=self.hetid, resnr=self.position, reschain=self.chain,\n                                      location='ligand', orig_atom=self.Mapper.id_to_atom(a_orig_idx)))\n            if a.atomicnum == 6:  # It's a carbon atom\n                if n_atoms_atomicnum.count(8) == 2 and n_atoms_atomicnum.count(6) == 1:  # It's a carboxylate group\n                    for neighbor in [n for n in n_atoms if n.GetAtomicNum() == 8]:\n                        neighbor_orig_idx = self.Mapper.mapid(neighbor.GetIdx(), mtype='ligand', bsid=self.bsid)\n                        a_set.append(data(atom=pybel.Atom(neighbor), atom_orig_idx=neighbor_orig_idx, type='O',\n                                          fgroup='carboxylate',\n                                          restype=self.hetid,\n                                          resnr=self.position, reschain=self.chain,\n                                          location='ligand', orig_atom=self.Mapper.id_to_atom(a_orig_idx)))\n            if a.atomicnum == 15:  # It's a phosphor atom\n                if n_atoms_atomicnum.count(8) >= 3:  # It's a phosphoryl\n                    for neighbor in [n for n in n_atoms if n.GetAtomicNum() == 8]:\n                        neighbor_orig_idx = self.Mapper.mapid(neighbor.GetIdx(), mtype='ligand', bsid=self.bsid)\n                        a_set.append(data(atom=pybel.Atom(neighbor), atom_orig_idx=neighbor_orig_idx, type='O',\n                                          fgroup='phosphoryl',\n                                          restype=self.hetid,\n                                          resnr=self.position, reschain=self.chain,\n                                          location='ligand', orig_atom=self.Mapper.id_to_atom(a_orig_idx)))\n                if n_atoms_atomicnum.count(8) == 2:  # It's another phosphor-containing group #@todo (correct name?)\n                    for neighbor in [n for n in n_atoms if n.GetAtomicNum() == 8]:\n                        neighbor_orig_idx = self.Mapper.mapid(neighbor.GetIdx(), mtype='ligand', bsid=self.bsid)\n                        a_set.append(data(atom=pybel.Atom(neighbor), atom_orig_idx=neighbor_orig_idx, type='O',\n                                          fgroup='phosphor.other', restype=self.hetid,\n                                          resnr=self.position,\n                                          reschain=self.chain, location='ligand', orig_atom=self.Mapper.id_to_atom(a_orig_idx)))\n            if a.atomicnum == 7:  # It's a nitrogen atom\n                if n_atoms_atomicnum.count(6) == 2:  # It's imidazole/pyrrole or similar\n                    a_set.append(data(atom=a, atom_orig_idx=a_orig_idx, type='N', fgroup='imidazole/pyrrole',\n                                      restype=self.hetid, resnr=self.position, reschain=self.chain,\n                                      location='ligand', orig_atom=self.Mapper.id_to_atom(a_orig_idx)))\n            if a.atomicnum == 16:  # It's a sulfur atom\n                if True in [n.IsAromatic() for n in n_atoms] and not a.OBAtom.IsAromatic():  # Thiolate\n                    a_set.append(data(atom=a, atom_orig_idx=a_orig_idx, type='S', fgroup='thiolate',\n                                      restype=self.hetid, resnr=self.position, reschain=self.chain,\n                                      location='ligand', orig_atom=self.Mapper.id_to_atom(a_orig_idx)))\n                if set(n_atoms_atomicnum) == {26}:  # Sulfur in Iron sulfur cluster\n                    a_set.append(data(atom=a, atom_orig_idx=a_orig_idx, type='S', fgroup='iron-sulfur.cluster',\n                                      restype=self.hetid, resnr=self.position, reschain=self.chain,\n                                      location='ligand', orig_atom=self.Mapper.id_to_atom(a_orig_idx)))\n\n        return a_set"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a PDB file with protein AND ligand and separates and prepares them.", "response": "def load_pdb(self, pdbpath, as_string=False):\n        \"\"\"Loads a pdb file with protein AND ligand(s), separates and prepares them.\n        If specified 'as_string', the input is a PDB string instead of a path.\"\"\"\n        if as_string:\n            self.sourcefiles['pdbcomplex.original'] = None\n            self.sourcefiles['pdbcomplex'] = None\n            self.sourcefiles['pdbstring'] = pdbpath\n        else:\n            self.sourcefiles['pdbcomplex.original'] = pdbpath\n            self.sourcefiles['pdbcomplex'] = pdbpath\n        self.information['pdbfixes'] = False\n        pdbparser = PDBParser(pdbpath, as_string=as_string)  # Parse PDB file to find errors and get additonal data\n        # #@todo Refactor and rename here\n        self.Mapper.proteinmap = pdbparser.proteinmap\n        self.Mapper.reversed_proteinmap = {v: k for k, v in self.Mapper.proteinmap.items()}\n        self.modres = pdbparser.modres\n        self.covalent = pdbparser.covalent\n        self.altconf = pdbparser.altconformations\n        self.corrected_pdb = pdbparser.corrected_pdb\n\n        if not config.PLUGIN_MODE:\n            if pdbparser.num_fixed_lines > 0:\n                write_message('%i lines automatically fixed in PDB input file.\\n' % pdbparser.num_fixed_lines)\n                # Save modified PDB file\n                if not as_string:\n                    basename = os.path.basename(pdbpath).split('.')[0]\n                else:\n                    basename = \"from_stdin\"\n                pdbpath_fixed = tmpfile(prefix='plipfixed.' + basename + '_', direc=self.output_path)\n                create_folder_if_not_exists(self.output_path)\n                self.sourcefiles['pdbcomplex'] = pdbpath_fixed\n                self.corrected_pdb = re.sub(r'[^\\x00-\\x7F]+', ' ', self.corrected_pdb)  # Strip non-unicode chars\n                if not config.NOFIXFILE:  # Only write to file if this option is not activated\n                    with open(pdbpath_fixed, 'w') as f:\n                        f.write(self.corrected_pdb)\n                self.information['pdbfixes'] = True\n\n        if not as_string:\n            self.sourcefiles['filename'] = os.path.basename(self.sourcefiles['pdbcomplex'])\n        self.protcomplex, self.filetype = read_pdb(self.corrected_pdb, as_string=True)\n\n        # Update the model in the Mapper class instance\n        self.Mapper.original_structure = self.protcomplex.OBMol\n        write_message('PDB structure successfully read.\\n')\n\n        # Determine (temporary) PyMOL Name from Filename\n        self.pymol_name = pdbpath.split('/')[-1].split('.')[0] + '-Protein'\n        # Replace characters causing problems in PyMOL\n        self.pymol_name = self.pymol_name.replace(' ', '').replace('(', '').replace(')', '').replace('-', '_')\n        # But if possible, name it after PDBID in Header\n        if 'HEADER' in self.protcomplex.data:  # If the PDB file has a proper header\n            potential_name = self.protcomplex.data['HEADER'][56:60].lower()\n            if extract_pdbid(potential_name) != 'UnknownProtein':\n                self.pymol_name = potential_name\n        write_message(\"Pymol Name set as: '%s'\\n\" % self.pymol_name, mtype='debug')\n\n        # Extract and prepare ligands\n        ligandfinder = LigandFinder(self.protcomplex, self.altconf, self.modres, self.covalent, self.Mapper)\n        self.ligands = ligandfinder.ligands\n        self.excluded = ligandfinder.excluded\n\n        # Add polar hydrogens\n        self.protcomplex.OBMol.AddPolarHydrogens()\n        for atm in self.protcomplex:\n            self.atoms[atm.idx] = atm\n        write_message(\"Assigned polar hydrogens\\n\", mtype='debug')\n\n        if len(self.excluded) != 0:\n            write_message(\"Excluded molecules as ligands: %s\\n\" % ','.join([lig for lig in self.excluded]))\n\n        if config.DNARECEPTOR:\n            self.resis = [obres for obres in pybel.ob.OBResidueIter(\n                self.protcomplex.OBMol) if obres.GetName() in config.DNA+config.RNA]\n        else:\n            self.resis = [obres for obres in pybel.ob.OBResidueIter(\n                self.protcomplex.OBMol) if obres.GetResidueProperty(0)]\n\n        num_ligs = len(self.ligands)\n        if num_ligs == 1:\n            write_message(\"Analyzing one ligand...\\n\")\n        elif num_ligs > 1:\n            write_message(\"Analyzing %i ligands...\\n\" % num_ligs)\n        else:\n            write_message(\"Structure contains no ligands.\\n\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle all basic functions for characterizing the interactions for one ligand", "response": "def characterize_complex(self, ligand):\n        \"\"\"Handles all basic functions for characterizing the interactions for one ligand\"\"\"\n\n        single_sites = []\n        for member in ligand.members:\n            single_sites.append(':'.join([str(x) for x in member]))\n        site = ' + '.join(single_sites)\n        site = site if not len(site) > 20 else site[:20] + '...'\n        longname = ligand.longname if not len(ligand.longname) > 20 else ligand.longname[:20] + '...'\n        ligtype = 'Unspecified type' if ligand.type == 'UNSPECIFIED' else ligand.type\n        ligtext = \"\\n%s [%s] -- %s\" % (longname, ligtype, site)\n        if ligtype == 'PEPTIDE':\n            ligtext = '\\n Chain %s [PEPTIDE / INTER-CHAIN]' % ligand.chain\n        if ligtype == 'INTRA':\n            ligtext = \"\\n Chain %s [INTRA-CHAIN]\" % ligand.chain\n        any_in_biolip = len(set([x[0] for x in ligand.members]).intersection(config.biolip_list)) != 0\n        write_message(ligtext)\n        write_message('\\n' + '-' * len(ligtext) + '\\n')\n\n        if ligtype not in ['POLYMER', 'DNA', 'ION', 'DNA+ION', 'RNA+ION', 'SMALLMOLECULE+ION'] and any_in_biolip:\n            write_message('may be biologically irrelevant\\n', mtype='info', indent=True)\n\n        lig_obj = Ligand(self, ligand)\n        cutoff = lig_obj.max_dist_to_center + config.BS_DIST\n        bs_res = self.extract_bs(cutoff, lig_obj.centroid, self.resis)\n        # Get a list of all atoms belonging to the binding site, search by idx\n        bs_atoms = [self.atoms[idx] for idx in [i for i in self.atoms.keys()\n                                                if self.atoms[i].OBAtom.GetResidue().GetIdx() in bs_res]\n                    if idx in self.Mapper.proteinmap and self.Mapper.mapid(idx, mtype='protein') not in self.altconf]\n        if ligand.type == 'PEPTIDE':\n            # If peptide, don't consider the peptide chain as part of the protein binding site\n            bs_atoms = [a for a in bs_atoms if a.OBAtom.GetResidue().GetChain() != lig_obj.chain]\n        if ligand.type == 'INTRA':\n            # Interactions within the chain\n            bs_atoms = [a for a in bs_atoms if a.OBAtom.GetResidue().GetChain() == lig_obj.chain]\n        bs_atoms_refined = []\n\n        # Create hash with BSRES -> (MINDIST_TO_LIG, AA_TYPE)\n        # and refine binding site atom selection with exact threshold\n        min_dist = {}\n        for r in bs_atoms:\n            bs_res_id = ''.join([str(whichresnumber(r)), whichchain(r)])\n            for l in ligand.mol.atoms:\n                distance = euclidean3d(r.coords, l.coords)\n                if bs_res_id not in min_dist:\n                    min_dist[bs_res_id] = (distance, whichrestype(r))\n                elif min_dist[bs_res_id][0] > distance:\n                    min_dist[bs_res_id] = (distance, whichrestype(r))\n                if distance <= config.BS_DIST and r not in bs_atoms_refined:\n                    bs_atoms_refined.append(r)\n        num_bs_atoms = len(bs_atoms_refined)\n        write_message('Binding site atoms in vicinity (%.1f A max. dist: %i).\\n' % (config.BS_DIST, num_bs_atoms),\n                      indent=True)\n\n        bs_obj = BindingSite(bs_atoms_refined, self.protcomplex, self, self.altconf, min_dist, self.Mapper)\n        pli_obj = PLInteraction(lig_obj, bs_obj, self)\n        self.interaction_sets[ligand.mol.title] = pli_obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the residues belonging to the binding site", "response": "def extract_bs(self, cutoff, ligcentroid, resis):\n        \"\"\"Return list of ids from residues belonging to the binding site\"\"\"\n        return [obres.GetIdx() for obres in resis if self.res_belongs_to_bs(obres, cutoff, ligcentroid)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef res_belongs_to_bs(self, res, cutoff, ligcentroid):\n        rescentroid = centroid([(atm.x(), atm.y(), atm.z()) for atm in pybel.ob.OBResidueAtomIter(res)])\n        # Check geometry\n        near_enough = True if euclidean3d(rescentroid, ligcentroid) < cutoff else False\n        # Check chain membership\n        restricted_chain = True if res.GetChain() in config.PEPTIDES else False\n        return (near_enough and not restricted_chain)", "response": "Checks if a residue is near enough to a given ligand centroid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef url_info(request):\n\n    return {\n        'MEDIA_URL' : core_settings.MEDIA_URL,\n        'STATIC_URL': core_settings.STATIC_URL,\n        'VERSION' : core_settings.VERSION,\n        'SERVER_INFO' : core_settings.SERVER_INFO,\n        'SITE_NAME' : current_site_name,\n        'CURRENT_SITE': current_site,\n    }", "response": "Return a dictionary of all the URL info for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the cache if needed.", "response": "def process_response(self, request, response):\n        \"\"\"Sets the cache, if needed.\"\"\"\n\n        # never cache headers + ETag\n        add_never_cache_headers(response)\n\n        if not hasattr(request, '_cache_update_cache') or not request._cache_update_cache:\n            # We don't need to update the cache, just return.\n            return response\n        if request.method != 'GET':\n            # This is a stronger requirement than above. It is needed\n            # because of interactions between this middleware and the\n            # HTTPMiddleware, which throws the body of a HEAD-request\n            # away before this middleware gets a chance to cache it.\n            return response\n        if not response.status_code == 200:\n            return response\n\n        # use the precomputed cache_key\n        if request._cache_middleware_key:\n            cache_key = request._cache_middleware_key\n        else:\n            cache_key = learn_cache_key(request, response, self.cache_timeout, self.key_prefix)\n\n        # include the orig_time information within the cache\n        cache.set(cache_key, (time.time(), response), self.cache_timeout)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether the page is already cached and returns the cached version if available.", "response": "def process_request(self, request):\n        \"\"\"\n        Checks whether the page is already cached and returns the cached\n        version if available.\n        \"\"\"\n        if self.cache_anonymous_only:\n            assert hasattr(request, 'user'), \"The Django cache middleware with CACHE_MIDDLEWARE_ANONYMOUS_ONLY=True requires authentication middleware to be installed. Edit your MIDDLEWARE_CLASSES setting to insert 'django.contrib.auth.middleware.AuthenticationMiddleware' before the CacheMiddleware.\"\n\n        if not request.method in ('GET', 'HEAD') or request.GET:\n            request._cache_update_cache = False\n            return None # Don't bother checking the cache.\n\n        if self.cache_anonymous_only and request.user.is_authenticated():\n            request._cache_update_cache = False\n            return None # Don't cache requests from authenticated users.\n\n        cache_key = get_cache_key(request, self.key_prefix)\n        request._cache_middleware_key = cache_key\n\n        if cache_key is None:\n            request._cache_update_cache = True\n            return None # No cache information available, need to rebuild.\n\n        response = cache.get(cache_key, None)\n        if response is None:\n            request._cache_update_cache = True\n            return None # No cache information available, need to rebuild.\n\n        orig_time, response = response\n        # time to refresh the cache\n        if orig_time and  ((time.time() - orig_time) > self.cache_refresh_timeout):\n            request._cache_update_cache = True\n            # keep the response in the cache for just self.timeout seconds and mark it for update\n            # other requests will continue werving this response from cache while I alone work on refreshing it\n            cache.set(cache_key, (None, response), self.timeout)\n            return None\n\n        request._cache_update_cache = False\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef collect_related(self, finder_funcs, obj, count, *args, **kwargs):\n        collected = []\n        for func in finder_funcs:\n            gathered = func(obj, count, collected, *args, **kwargs)\n            if gathered:\n                collected += gathered\n            if len(collected) >= count:\n                return collected[:count]\n\n        return collected", "response": "Collect related objects using a list of finder functions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn at most count publishable objects related to obj using the given related finder.", "response": "def get_related_for_object(self, obj, count, finder=None, mods=[], only_from_same_site=True):\n        \"\"\"\n        Returns at most ``count`` publishable objects related to ``obj`` using\n        named related finder ``finder``.\n\n        If only specific type of publishable is prefered, use ``mods`` attribute\n        to list required classes.\n\n        Finally, use ``only_from_same_site`` if you don't want cross-site\n        content.\n\n        ``finder`` atribute uses ``RELATED_FINDERS`` settings to find out\n        what finder function to use. If none is specified, ``default``\n        is used to perform the query.\n        \"\"\"\n        return self.collect_related(self._get_finders(finder), obj, count, mods, only_from_same_site)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_listing(self, category=None, children=ListingHandler.NONE, count=10, offset=0, content_types=[], date_range=(), exclude=None, **kwargs):\n        assert offset >= 0, \"Offset must be a positive integer\"\n        assert count >= 0, \"Count must be a positive integer\"\n\n        if not count:\n            return []\n\n        limit = offset + count\n\n        qset = self.get_listing_queryset(category, children, content_types, date_range, exclude, **kwargs)\n\n        # direct listings, we don't need to check for duplicates\n        if children == ListingHandler.NONE:\n            return qset[offset:limit]\n\n        seen = set()\n        out = []\n        while len(out) < count:\n            skip = 0\n            # 2 i a reasonable value for padding, wouldn't you say dear Watson?\n            for l in qset[offset:limit + 2]:\n                if l.publishable_id not in seen:\n                    seen.add(l.publishable_id)\n                    out.append(l)\n                    if len(out) == count:\n                        break\n                else:\n                    skip += 1\n\n            # no enough skipped, or not enough listings to work with, no need for another try\n            if skip <= 2 or (len(out) + skip) < (count + 2):\n                break\n\n            # get another page to fill in the gaps\n            offset += count\n            limit += count\n\n        return out", "response": "Returns a list of objects for the given category and children."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string representation of a base - level pagination template.", "response": "def paginator(context, adjacent_pages=2, template_name=None):\n    \"\"\"\n    Renders a ``inclusion_tags/paginator.html`` or ``inc/paginator.html``\n    template with additional pagination context. To be used in conjunction\n    with the ``object_list`` generic\n    view.\n\n    If ``TEMPLATE_NAME`` parameter is given,\n    ``inclusion_tags/paginator_TEMPLATE_NAME.html`` or \n    ``inc/paginator_TEMPLATE_NAME.html`` will be used instead.\n\n    Adds pagination context variables for use in displaying first, adjacent pages and\n    last page links in addition to those created by the ``object_list`` generic\n    view.\n\n    Taken from http://www.djangosnippets.org/snippets/73/\n\n    Syntax::\n\n        {% paginator [NUMBER_OF_ADJACENT_PAGES] [TEMPLATE_NAME] %}\n\n    Examples::\n\n        {% paginator %}\n        {% paginator 5 %}\n        {% paginator 5 \"special\" %}\n        # with Django 1.4 and above you can also do:\n        {% paginator template_name=\"special\" %}\n    \"\"\"\n    tname, context = _do_paginator(context, adjacent_pages, template_name)\n    return render_to_string(tname, context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of objects that were published by given author recently and optionally with publishable objects in results.", "response": "def do_author_listing(parser, token):\n    \"\"\"\n    Get N listing objects that were published by given author recently and optionally\n    omit a publishable object in results.\n\n    **Usage**::\n\n        {% author_listing <author> <limit> as <result> [omit <obj>] %}\n\n    **Parameters**::\n        ==================================  ================================================\n        Option                              Description\n        ==================================  ================================================\n        ``author``                          Author to load objects for.\n        ``limit``                           Maximum number of objects to store,\n        ``result``                          Store the resulting list in context under given\n                                            name.\n        ==================================  ================================================\n\n    **Examples**::\n\n        {% author_listing object.authors.all.0 10 as article_listing %}\n    \"\"\"\n    contents = token.split_contents()\n\n    if len(contents) not in [5, 7]:\n        raise template.TemplateSyntaxError('%r tag requires 4 or 6 arguments.' % contents[0])\n    elif len(contents) == 5:\n        tag, obj_var, count, fill, var_name = contents\n        return AuthorListingNode(obj_var, count, var_name)\n    else:\n        tag, obj_var, count, fill, var_name, filll, omit_var = contents\n        return AuthorListingNode(obj_var, count, var_name, omit_var)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _Triple(S):\n    def f(parr):\n        T, P = parr\n        pw = _Region1(T, P)\n        gw = pw[\"h\"]-T*pw[\"s\"]\n\n        pv = _Region2(T, P)\n        gv = pv[\"h\"]-T*pv[\"s\"]\n\n        gih = _Ice(T, P)[\"g\"]\n        ps = SeaWater._saline(T, P, S)\n\n        return -ps[\"g\"]+S*ps[\"gs\"]-gw+gih, -ps[\"g\"]+S*ps[\"gs\"]-gw+gv\n\n    Tt, Pt = fsolve(f, [273, 6e-4])\n\n    prop = {}\n    prop[\"Tt\"] = Tt\n    prop[\"Pt\"] = Pt\n    return prop", "response": "Procedure to calculate the triple point pressure and temperature for a Seawater Seawater"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _OsmoticPressure(T, P, S):\n    pw = _Region1(T, P)\n    gw = pw[\"h\"]-T*pw[\"s\"]\n\n    def f(Posm):\n        pw2 = _Region1(T, P+Posm)\n        gw2 = pw2[\"h\"]-T*pw2[\"s\"]\n        ps = SeaWater._saline(T, P+Posm, S)\n        return -ps[\"g\"]+S*ps[\"gs\"]-gw+gw2\n\n    Posm = fsolve(f, 0)[0]\n    return Posm", "response": "Procedure to calculate the osmotic pressure of seawater\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _solNa2SO4(T, mH2SO4, mNaCl):\n    # Check input parameters\n    if T < 523.15 or T > 623.15 or mH2SO4 < 0 or mH2SO4 > 0.75 or \\\n            mNaCl < 0 or mNaCl > 2.25:\n        raise NotImplementedError(\"Incoming out of bound\")\n\n    A00 = -0.8085987*T+81.4613752+0.10537803*T*log(T)\n    A10 = 3.4636364*T-281.63322-0.46779874*T*log(T)\n    A20 = -6.0029634*T+480.60108+0.81382854*T*log(T)\n    A30 = 4.4540258*T-359.36872-0.60306734*T*log(T)\n    A01 = 0.4909061*T-46.556271-0.064612393*T*log(T)\n    A02 = -0.002781314*T+1.722695+0.0000013319698*T*log(T)\n    A03 = -0.014074108*T+0.99020227+0.0019397832*T*log(T)\n    A11 = -0.87146573*T+71.808756+0.11749585*T*log(T)\n\n    S = A00 + A10*mH2SO4 + A20*mH2SO4**2 + A30*mH2SO4**3 + A01*mNaCl + \\\n        A02*mNaCl**2 + A03*mNaCl**3 + A11*mH2SO4*mNaCl\n\n    return S", "response": "Equation for the solubility of sodium sulfate in aqueous mixture of sodium chloride and sulfuric acid from Water to Concentrated solutions of sodium chloride and sodium chloride."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calculo(self):\n        T = self.kwargs[\"T\"]\n        P = self.kwargs[\"P\"]\n        S = self.kwargs[\"S\"]\n\n        self.m = S/(1-S)/Ms\n        if self.kwargs[\"fast\"] and T <= 313.15:\n            pw = self._waterSupp(T, P)\n        elif self.kwargs[\"IF97\"]:\n            pw = self._waterIF97(T, P)\n        else:\n            pw = self._water(T, P)\n        ps = self._saline(T, P, S)\n\n        prop = {}\n        for key in ps:\n            prop[key] = pw[key]+ps[key]\n            self.__setattr__(key, prop[key])\n\n        self.T = T\n        self.P = P\n        self.rho = 1./prop[\"gp\"]\n        self.v = prop[\"gp\"]\n        self.s = -prop[\"gt\"]\n        self.cp = -T*prop[\"gtt\"]\n        self.cv = T*(prop[\"gtp\"]**2/prop[\"gpp\"]-prop[\"gtt\"])\n        self.h = prop[\"g\"]-T*prop[\"gt\"]\n        self.u = prop[\"g\"]-T*prop[\"gt\"]-P*1000*prop[\"gp\"]\n        self.a = prop[\"g\"]-P*1000*prop[\"gp\"]\n        self.alfav = prop[\"gtp\"]/prop[\"gp\"]\n        self.betas = -prop[\"gtp\"]/prop[\"gtt\"]\n        self.xkappa = -prop[\"gpp\"]/prop[\"gp\"]\n        self.ks = (prop[\"gtp\"]**2-prop[\"gtt\"]*prop[\"gpp\"])/prop[\"gp\"] / \\\n            prop[\"gtt\"]\n        self.w = prop[\"gp\"]*(prop[\"gtt\"]*1000/(prop[\"gtp\"]**2 -\n                             prop[\"gtt\"]*1000*prop[\"gpp\"]*1e-6))**0.5\n\n        if \"thcond\" in pw:\n            kw = pw[\"thcond\"]\n        else:\n            kw = _ThCond(1/pw[\"gp\"], T)\n        try:\n            self.k = _ThCond_SeaWater(T, P, S)+kw\n        except NotImplementedError:\n            self.k = None\n\n        if S:\n            self.mu = prop[\"gs\"]\n            self.muw = prop[\"g\"]-S*prop[\"gs\"]\n            self.mus = prop[\"g\"]+(1-S)*prop[\"gs\"]\n            self.osm = -(ps[\"g\"]-S*prop[\"gs\"])/self.m/Rm/T\n            self.haline = -prop[\"gsp\"]/prop[\"gp\"]\n        else:\n            self.mu = None\n            self.muw = None\n            self.mus = None\n            self.osm = None\n            self.haline = None", "response": "Calculate the values of the internal structure of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _water(cls, T, P):\n        water = IAPWS95(P=P, T=T)\n        prop = {}\n        prop[\"g\"] = water.h-T*water.s\n        prop[\"gt\"] = -water.s\n        prop[\"gp\"] = 1./water.rho\n        prop[\"gtt\"] = -water.cp/T\n        prop[\"gtp\"] = water.betas*water.cp/T\n        prop[\"gpp\"] = -1e6/(water.rho*water.w)**2-water.betas**2*1e3*water.cp/T\n        prop[\"gs\"] = 0\n        prop[\"gsp\"] = 0\n        prop[\"thcond\"] = water.k\n        return prop", "response": "Get properties of pure water Table4 pag 8"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets properties of pure water using the supplementary release SR7 - 09 Section 6.", "response": "def _waterSupp(cls, T, P):\n        \"\"\"Get properties of pure water using the supplementary release SR7-09,\n        Table4 pag 6\"\"\"\n        tau = (T-273.15)/40\n        pi = (P-0.101325)/100\n\n        J = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n             3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7]\n        K = [0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2,\n             3, 4, 5, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 0, 1]\n        G = [0.101342743139674e3, 0.100015695367145e6, -0.254457654203630e4,\n             0.284517778446287e3, -0.333146754253611e2, 0.420263108803084e1,\n             -0.546428511471039, 0.590578347909402e1, -0.270983805184062e3,\n             0.776153611613101e3, -0.196512550881220e3, 0.289796526294175e2,\n             -0.213290083518327e1, -0.123577859330390e5, 0.145503645404680e4,\n             -0.756558385769359e3, 0.273479662323528e3, -0.555604063817218e2,\n             0.434420671917197e1, 0.736741204151612e3, -0.672507783145070e3,\n             0.499360390819152e3, -0.239545330654412e3, 0.488012518593872e2,\n             -0.166307106208905e1, -0.148185936433658e3, 0.397968445406972e3,\n             -0.301815380621876e3, 0.152196371733841e3, -0.263748377232802e2,\n             0.580259125842571e2, -0.194618310617595e3, 0.120520654902025e3,\n             -0.552723052340152e2, 0.648190668077221e1, -0.189843846514172e2,\n             0.635113936641785e2, -0.222897317140459e2, 0.817060541818112e1,\n             0.305081646487967e1, -0.963108119393062e1]\n\n        g, gt, gp, gtt, gtp, gpp = 0, 0, 0, 0, 0, 0\n        for j, k, gi in zip(J, K, G):\n            g += gi*tau**j*pi**k\n            if j >= 1:\n                gt += gi*j*tau**(j-1)*pi**k\n            if k >= 1:\n                gp += k*gi*tau**j*pi**(k-1)\n            if j >= 2:\n                gtt += j*(j-1)*gi*tau**(j-2)*pi**k\n            if j >= 1 and k >= 1:\n                gtp += j*k*gi*tau**(j-1)*pi**(k-1)\n            if k >= 2:\n                gpp += k*(k-1)*gi*tau**j*pi**(k-2)\n\n        prop = {}\n        prop[\"g\"] = g*1e-3\n        prop[\"gt\"] = gt/40*1e-3\n        prop[\"gp\"] = gp/100*1e-6\n        prop[\"gtt\"] = gtt/40**2*1e-3\n        prop[\"gtp\"] = gtp/40/100*1e-6\n        prop[\"gpp\"] = gpp/100**2*1e-6\n        prop[\"gs\"] = 0\n        prop[\"gsp\"] = 0\n        return prop"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _saline(cls, T, P, S):\n\n        # Check input in range of validity\n        if T <= 261 or T > 353 or P <= 0 or P > 100 or S < 0 or S > 0.12:\n            warnings.warn(\"Incoming out of bound\")\n\n        S_ = 0.03516504*40/35\n        X = (S/S_)**0.5\n        tau = (T-273.15)/40\n        pi = (P-0.101325)/100\n\n        I = [1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 2, 3, 4, 2, 3, 4, 2, 3, 4,\n             2, 4, 2, 2, 3, 4, 5, 2, 3, 4, 2, 3, 2, 3, 2, 3, 2, 3, 4, 2, 3, 2,\n             3, 2, 2, 2, 3, 4, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2]\n        J = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n             5, 5, 6, 0, 0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 0, 0, 0, 1, 1, 2,\n             2, 3, 4, 0, 0, 0, 1, 1, 2, 2, 3, 4, 0, 0, 1, 2, 3, 0, 1, 2]\n        K = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n             0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n             2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5]\n        G = [0.581281456626732e4, 0.141627648484197e4, -0.243214662381794e4,\n             0.202580115603697e4, -0.109166841042967e4, 0.374601237877840e3,\n             -0.485891069025409e2, 0.851226734946706e3, 0.168072408311545e3,\n             -0.493407510141682e3, 0.543835333000098e3, -0.196028306689776e3,\n             0.367571622995805e2, 0.880031352997204e3, -0.430664675978042e2,\n             -0.685572509204491e2, -0.225267649263401e3, -0.100227370861875e2,\n             0.493667694856254e2, 0.914260447751259e2, 0.875600661808945,\n             -0.171397577419788e2, -0.216603240875311e2, 0.249697009569508e1,\n             0.213016970847183e1, -0.331049154044839e4, 0.199459603073901e3,\n             -0.547919133532887e2, 0.360284195611086e2, 0.729116529735046e3,\n             -0.175292041186547e3, -0.226683558512829e2, -0.860764303783977e3,\n             0.383058066002476e3, 0.694244814133268e3, -0.460319931801257e3,\n             -0.297728741987187e3, 0.234565187611355e3, 0.384794152978599e3,\n             -0.522940909281335e2, -0.408193978912261e1, -0.343956902961561e3,\n             0.831923927801819e2, 0.337409530269367e3, -0.541917262517112e2,\n             -0.204889641964903e3, 0.747261411387560e2, -0.965324320107458e2,\n             0.680444942726459e2, -0.301755111971161e2, 0.124687671116248e3,\n             -0.294830643494290e2, -0.178314556207638e3, 0.256398487389914e2,\n             0.113561697840594e3, -0.364872919001588e2, 0.158408172766824e2,\n             -0.341251932441282e1, -0.316569643860730e2, 0.442040358308000e2,\n             -0.111282734326413e2, -0.262480156590992e1, 0.704658803315449e1,\n             -0.792001547211682e1]\n\n        g, gt, gp, gtt, gtp, gpp, gs, gsp = 0, 0, 0, 0, 0, 0, 0, 0\n\n        # Calculate only for some salinity\n        if S != 0:\n            for i, j, k, gi in zip(I, J, K, G):\n                if i == 1:\n                    g += gi*X**2*log(X)*tau**j*pi**k\n                    gs += gi*(2*log(X)+1)*tau**j*pi**k\n                else:\n                    g += gi*X**i*tau**j*pi**k\n                    gs += i*gi*X**(i-2)*tau**j*pi**k\n                if j >= 1:\n                    if i == 1:\n                        gt += gi*X**2*log(X)*j*tau**(j-1)*pi**k\n                    else:\n                        gt += gi*X**i*j*tau**(j-1)*pi**k\n                if k >= 1:\n                    gp += k*gi*X**i*tau**j*pi**(k-1)\n                    gsp += i*k*gi*X**(i-2)*tau**j*pi**(k-1)\n                if j >= 2:\n                    gtt += j*(j-1)*gi*X**i*tau**(j-2)*pi**k\n                if j >= 1 and k >= 1:\n                    gtp += j*k*gi*X**i*tau**(j-1)*pi**(k-1)\n                if k >= 2:\n                    gpp += k*(k-1)*gi*X**i*tau**j*pi**(k-2)\n\n        prop = {}\n        prop[\"g\"] = g*1e-3\n        prop[\"gt\"] = gt/40*1e-3\n        prop[\"gp\"] = gp/100*1e-6\n        prop[\"gtt\"] = gtt/40**2*1e-3\n        prop[\"gtp\"] = gtp/40/100*1e-6\n        prop[\"gpp\"] = gpp/100**2*1e-6\n        prop[\"gs\"] = gs/S_/2*1e-3\n        prop[\"gsp\"] = gsp/S_/2/100*1e-6\n        return prop", "response": "Saline the base of the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _phir(tau, delta, coef):\n    fir = 0\n\n    # Polinomial terms\n    nr1 = coef.get(\"nr1\", [])\n    d1 = coef.get(\"d1\", [])\n    t1 = coef.get(\"t1\", [])\n    for n, d, t in zip(nr1, d1, t1):\n        fir += n*delta**d*tau**t\n\n    # Exponential terms\n    nr2 = coef.get(\"nr2\", [])\n    d2 = coef.get(\"d2\", [])\n    g2 = coef.get(\"gamma2\", [])\n    t2 = coef.get(\"t2\", [])\n    c2 = coef.get(\"c2\", [])\n    for n, d, g, t, c in zip(nr2, d2, g2, t2, c2):\n        fir += n*delta**d*tau**t*exp(-g*delta**c)\n\n    # Gaussian terms\n    nr3 = coef.get(\"nr3\", [])\n    d3 = coef.get(\"d3\", [])\n    t3 = coef.get(\"t3\", [])\n    a3 = coef.get(\"alfa3\", [])\n    e3 = coef.get(\"epsilon3\", [])\n    b3 = coef.get(\"beta3\", [])\n    g3 = coef.get(\"gamma3\", [])\n    for n, d, t, a, e, b, g in zip(nr3, d3, t3, a3, e3, b3, g3):\n        fir += n*delta**d*tau**t*exp(-a*(delta-e)**2-b*(tau-g)**2)\n\n    # Non analitic terms\n    nr4 = coef.get(\"nr4\", [])\n    a4 = coef.get(\"a4\", [])\n    b4 = coef.get(\"b4\", [])\n    Ai = coef.get(\"A\", [])\n    Bi = coef.get(\"B\", [])\n    Ci = coef.get(\"C\", [])\n    Di = coef.get(\"D\", [])\n    bt4 = coef.get(\"beta4\", [])\n    for n, a, b, A, B, C, D, bt in zip(nr4, a4, b4, Ai, Bi, Ci, Di, bt4):\n        Tita = (1-tau)+A*((delta-1)**2)**(0.5/bt)\n        F = exp(-C*(delta-1)**2-D*(tau-1)**2)\n        Delta = Tita**2+B*((delta-1)**2)**a\n        fir += n*Delta**b*delta*F\n\n    return fir", "response": "Residual contribution to the adimensional free Helmholtz energy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning decorator used to automatic adiction of base class MEoS in subclass __doc__", "response": "def mainClassDoc():\n    \"\"\"Function decorator used to automatic adiction of base class MEoS in\n    subclass __doc__\"\"\"\n    def decorator(f):\n        # __doc__ is only writable in python3.\n        # The doc build must be done with python3 so this snnippet do the work\n        py_version = platform.python_version()\n        if py_version[0] == \"3\":\n            doc = f.__doc__.split(os.linesep)\n            try:\n                ind = doc.index(\"\")\n            except ValueError:\n                ind = 1\n\n            doc1 = os.linesep.join(doc[:ind])\n            doc3 = os.linesep.join(doc[ind:])\n            doc2 = os.linesep.join(MEoS.__doc__.split(os.linesep)[3:])\n\n            f.__doc__ = doc1 + os.linesep + os.linesep + \\\n                doc2 + os.linesep + os.linesep + doc3\n        return f\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if inputs are enough to define state", "response": "def calculable(self):\n        \"\"\"Check if inputs are enough to define state\"\"\"\n        self._mode = \"\"\n        if self.kwargs[\"T\"] and self.kwargs[\"P\"]:\n            self._mode = \"TP\"\n        elif self.kwargs[\"T\"] and self.kwargs[\"rho\"]:\n            self._mode = \"Trho\"\n        elif self.kwargs[\"T\"] and self.kwargs[\"h\"] is not None:\n            self._mode = \"Th\"\n        elif self.kwargs[\"T\"] and self.kwargs[\"s\"] is not None:\n            self._mode = \"Ts\"\n        elif self.kwargs[\"T\"] and self.kwargs[\"u\"] is not None:\n            self._mode = \"Tu\"\n        elif self.kwargs[\"P\"] and self.kwargs[\"rho\"]:\n            self._mode = \"Prho\"\n        elif self.kwargs[\"P\"] and self.kwargs[\"h\"] is not None:\n            self._mode = \"Ph\"\n        elif self.kwargs[\"P\"] and self.kwargs[\"s\"] is not None:\n            self._mode = \"Ps\"\n        elif self.kwargs[\"P\"] and self.kwargs[\"u\"] is not None:\n            self._mode = \"Pu\"\n        elif self.kwargs[\"rho\"] and self.kwargs[\"h\"] is not None:\n            self._mode = \"rhoh\"\n        elif self.kwargs[\"rho\"] and self.kwargs[\"s\"] is not None:\n            self._mode = \"rhos\"\n        elif self.kwargs[\"rho\"] and self.kwargs[\"u\"] is not None:\n            self._mode = \"rhou\"\n        elif self.kwargs[\"h\"] is not None and self.kwargs[\"s\"] is not None:\n            self._mode = \"hs\"\n        elif self.kwargs[\"h\"] is not None and self.kwargs[\"u\"] is not None:\n            self._mode = \"hu\"\n        elif self.kwargs[\"s\"] is not None and self.kwargs[\"u\"] is not None:\n            self._mode = \"su\"\n        elif self.kwargs[\"T\"] and self.kwargs[\"x\"] is not None:\n            self._mode = \"Tx\"\n        elif self.kwargs[\"P\"] and self.kwargs[\"x\"] is not None:\n            self._mode = \"Px\"\n        return bool(self._mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the current state of the object.", "response": "def calculo(self):\n        \"\"\"Calculate procedure\"\"\"\n        T = self.kwargs[\"T\"]\n        rho = self.kwargs[\"rho\"]\n        P = self.kwargs[\"P\"]\n        s = self.kwargs[\"s\"]\n        h = self.kwargs[\"h\"]\n        u = self.kwargs[\"u\"]\n        x = self.kwargs[\"x\"]\n\n        # Initial values\n        T0 = self.kwargs[\"T0\"]\n        rho0 = self.kwargs[\"rho0\"]\n\n        if T0 or rho0:\n            To = T0\n            rhoo = rho0\n        elif self.name == \"air\":\n            To = 300\n            rhoo = 1e-3\n        else:\n            try:\n                st0 = IAPWS97(**self.kwargs)\n            except NotImplementedError:\n                To = 300\n                rhoo = 900\n            else:\n                if st0.status:\n                    To = st0.T\n                    rhoo = st0.rho\n                else:\n                    To = 300\n                    rhoo = 900\n\n        self.R = self._constants[\"R\"]/self._constants.get(\"M\", self.M)\n        rhoc = self._constants.get(\"rhoref\", self.rhoc)\n        Tc = self._constants.get(\"Tref\", self.Tc)\n\n        propiedades = None\n\n        if self._mode not in (\"Tx\", \"Px\"):\n            # Method with iteration necessary to get x\n            if self._mode == \"TP\":\n                try:\n                    if self.name == \"air\":\n                        raise ValueError\n                    st0 = IAPWS97(**self.kwargs)\n                    rhoo = st0.rho\n                except NotImplementedError:\n                    if rho0:\n                        rhoo = rho0\n                    elif T < self.Tc and P < self.Pc and \\\n                            self._Vapor_Pressure(T) < P:\n                        rhoo = self._Liquid_Density(T)\n                    elif T < self.Tc and P < self.Pc:\n                        rhoo = self._Vapor_Density(T)\n                    else:\n                        rhoo = self.rhoc*3\n                except ValueError:\n                    rhoo = 1e-3\n\n                def f(rho):\n                    delta = rho/rhoc\n                    tau = Tc/T\n\n                    fird = _phird(tau, delta, self._constants)\n                    Po = (1+delta*fird)*self.R*T*rho\n                    return Po-P*1000\n\n                rho = fsolve(f, rhoo)[0]\n\n                # Calculate quality\n                if T > self.Tc:\n                    x = 1\n                else:\n                    Ps = self._Vapor_Pressure(T)\n                    if Ps*0.95 < P < Ps*1.05:\n                        rhol, rhov, Ps = self._saturation(T)\n                        Ps *= 1e-3\n\n                    if Ps > P:\n                        x = 1\n                    else:\n                        x = 0\n\n            elif self._mode == \"Th\":\n                tau = Tc/T\n                ideal = self._phi0(tau, 1)\n                fiot = ideal[\"fiot\"]\n\n                def f(rho):\n                    delta = rho/rhoc\n                    fird = _phird(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    ho = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n                    return ho-h\n\n                if T >= self.Tc:\n                    rhoo = self.rhoc\n                    rho = fsolve(f, rhoo)[0]\n                else:\n                    x0 = self.kwargs[\"x0\"]\n                    rhov = self._Vapor_Density(T)\n                    rhol = self._Liquid_Density(T)\n                    deltaL = rhol/rhoc\n                    deltaG = rhov/rhoc\n\n                    firdL = _phird(tau, deltaL, self._constants)\n                    firtL = _phirt(tau, deltaL, self._constants)\n                    firdG = _phird(tau, deltaG, self._constants)\n                    firtG = _phirt(tau, deltaG, self._constants)\n                    hl = self.R*T*(1+tau*(fiot+firtL)+deltaL*firdL)\n                    hv = self.R*T*(1+tau*(fiot+firtG)+deltaG*firdG)\n                    if x0 not in (0, 1) and hl <= h <= hv:\n                        rhol, rhov, Ps = self._saturation(T)\n                        vapor = self._Helmholtz(rhov, T)\n                        liquido = self._Helmholtz(rhol, T)\n                        hv = vapor[\"h\"]\n                        hl = liquido[\"h\"]\n                        x = (h-hl)/(hv-hl)\n                        rho = 1/(x/rhov+(1-x)/rhol)\n                        P = Ps/1000\n                    else:\n                        if h > hv:\n                            rhoo = rhov\n                        else:\n                            rhoo = rhol\n                        rho = fsolve(f, rhoo)[0]\n\n            elif self._mode == \"Ts\":\n                tau = Tc/T\n\n                def f(rho):\n                    if rho < 0:\n                        rho = 1e-20\n                    delta = rho/rhoc\n\n                    ideal = self._phi0(tau, delta)\n                    fio = ideal[\"fio\"]\n                    fiot = ideal[\"fiot\"]\n                    fir = _phir(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    so = self.R*(tau*(fiot+firt)-fio-fir)\n                    return so-s\n\n                if T >= self.Tc:\n                    rhoo = self.rhoc\n                    rho = fsolve(f, rhoo)[0]\n                else:\n                    rhov = self._Vapor_Density(T)\n                    rhol = self._Liquid_Density(T)\n                    deltaL = rhol/rhoc\n                    deltaG = rhov/rhoc\n\n                    idealL = self._phi0(tau, deltaL)\n                    idealG = self._phi0(tau, deltaG)\n                    fioL = idealL[\"fio\"]\n                    fioG = idealG[\"fio\"]\n                    fiot = idealL[\"fiot\"]\n                    firL = _phir(tau, deltaL, self._constants)\n                    firtL = _phirt(tau, deltaL, self._constants)\n                    sl = self.R*(tau*(fiot+firtL)-fioL-firL)\n                    firG = _phir(tau, deltaG, self._constants)\n                    firtG = _phirt(tau, deltaG, self._constants)\n                    sv = self.R*(tau*(fiot+firtG)-fioG-firG)\n\n                    if sl <= s <= sv:\n                        rhol, rhov, Ps = self._saturation(T)\n                        vapor = self._Helmholtz(rhov, T)\n                        liquido = self._Helmholtz(rhol, T)\n                        sv = vapor[\"s\"]\n                        sl = liquido[\"s\"]\n                        x = (s-sl)/(sv-sl)\n                        rho = 1/(x/rhov+(1-x)/rhol)\n                        P = Ps/1000\n                    else:\n                        if s > sv:\n                            rhoo = rhov\n                        else:\n                            rhoo = rhol\n                        rho = fsolve(f, rhoo)[0]\n\n            elif self._mode == \"Tu\":\n                tau = Tc/T\n                ideal = self._phi0(tau, 1)\n                fiot = ideal[\"fiot\"]\n\n                def f(rho):\n                    delta = rho/rhoc\n\n                    fird = _phird(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    Po = (1+delta*fird)*self.R*T*rho\n                    ho = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n\n                    return ho-Po/rho-u\n\n                if T >= self.Tc:\n                    rhoo = self.rhoc\n                    rho = fsolve(f, rhoo)[0]\n                else:\n                    rhov = self._Vapor_Density(T)\n                    rhol = self._Liquid_Density(T)\n                    deltaL = rhol/rhoc\n                    deltaG = rhov/rhoc\n\n                    firdL = _phird(tau, deltaL, self._constants)\n                    firtL = _phirt(tau, deltaL, self._constants)\n                    firdG = _phird(tau, deltaG, self._constants)\n                    firtG = _phirt(tau, deltaG, self._constants)\n                    PoL = (1+deltaL*firdL)*self.R*T*rhol\n                    PoG = (1+deltaG*firdG)*self.R*T*rhov\n                    hoL = self.R*T*(1+tau*(fiot+firtL)+deltaL*firdL)\n                    hoG = self.R*T*(1+tau*(fiot+firtG)+deltaG*firdG)\n\n                    uv = hoG-PoG/rhov\n                    ul = hoL-PoL/rhol\n                    if ul <= u <= uv:\n                        rhol, rhov, Ps = self._saturation(T)\n                        vapor = self._Helmholtz(rhov, T)\n                        liquido = self._Helmholtz(rhol, T)\n                        uv = vapor[\"h\"]-vapor[\"P\"]/rhov\n                        ul = liquido[\"h\"]-liquido[\"P\"]/rhol\n                        x = (u-ul)/(uv-ul)\n                        rho = 1/(x/rhov-(1-x)/rhol)\n                        P = Ps/1000\n                    else:\n                        if u > uv:\n                            rhoo = rhov\n                        else:\n                            rhoo = rhol\n                        rho = fsolve(f, rhoo)[0]\n\n            elif self._mode == \"Prho\":\n                delta = rho/rhoc\n\n                def f(T):\n                    tau = Tc/T\n\n                    fird = _phird(tau, delta, self._constants)\n                    Po = (1+delta*fird)*self.R*T*rho\n                    return Po-P*1000\n\n                T = fsolve(f, To)[0]\n                rhol = self._Liquid_Density(T)\n                rhov = self._Vapor_Density(T)\n                if T == To or rhov <= rho <= rhol:\n\n                    def f(parr):\n                        T, rhol, rhog = parr\n                        tau = Tc/T\n                        deltaL = rhol/self.rhoc\n                        deltaG = rhog/self.rhoc\n\n                        firL = _phir(tau, deltaL, self._constants)\n                        firdL = _phird(tau, deltaL, self._constants)\n                        firG = _phir(tau, deltaG, self._constants)\n                        firdG = _phird(tau, deltaG, self._constants)\n\n                        Jl = rhol*(1+deltaL*firdL)\n                        Jv = rhog*(1+deltaG*firdG)\n                        K = firL-firG\n                        Ps = self.R*T*rhol*rhog/(rhol-rhog)*(K+log(rhol/rhog))\n                        return (Jl-Jv,\n                                Jl*(1/rhog-1/rhol)-log(rhol/rhog)-K,\n                                Ps - P*1000)\n\n                    for to in [To, 300, 400, 500, 600]:\n                        rhoLo = self._Liquid_Density(to)\n                        rhoGo = self._Vapor_Density(to)\n                        sol = fsolve(f, [to, rhoLo, rhoGo], full_output=True)\n                        T, rhoL, rhoG = sol[0]\n                        x = (1./rho-1/rhoL)/(1/rhoG-1/rhoL)\n                        if sol[2] == 1 and 0 <= x <= 1 and \\\n                                sum(abs(sol[1][\"fvec\"])) < 1e-5:\n                            break\n\n                    if sum(abs(sol[1][\"fvec\"])) > 1e-5:\n                        raise(RuntimeError(sol[3]))\n\n                    liquido = self._Helmholtz(rhoL, T)\n                    vapor = self._Helmholtz(rhoG, T)\n                    P = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(\n                        liquido[\"fir\"]-vapor[\"fir\"]+log(rhoL/rhoG))/1000\n\n            elif self._mode == \"Ph\":\n                def funcion(parr):\n                    rho, T = parr\n                    delta = rho/rhoc\n                    tau = Tc/T\n\n                    ideal = self._phi0(tau, delta)\n                    fiot = ideal[\"fiot\"]\n                    fird = _phird(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    Po = (1+delta*fird)*self.R*T*rho\n                    ho = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n                    return Po-P*1000, ho-h\n\n                rho, T = fsolve(funcion, [rhoo, To])\n                rhol = self._Liquid_Density(T)\n                rhov = self._Vapor_Density(T)\n                if rho == rhoo or rhov <= rho <= rhol:\n\n                    def f(parr):\n                        T, rhol, rhog, x = parr\n                        tau = Tc/T\n                        deltaL = rhol/self.rhoc\n                        deltaG = rhog/self.rhoc\n\n                        ideal = self._phi0(tau, deltaL)\n                        fiot = ideal[\"fiot\"]\n\n                        firL = _phir(tau, deltaL, self._constants)\n                        firdL = _phird(tau, deltaL, self._constants)\n                        firtL = _phirt(tau, deltaL, self._constants)\n                        hoL = self.R*T*(1+tau*(fiot+firtL)+deltaL*firdL)\n                        firG = _phir(tau, deltaG, self._constants)\n                        firdG = _phird(tau, deltaG, self._constants)\n                        firtG = _phirt(tau, deltaG, self._constants)\n                        hoG = self.R*T*(1+tau*(fiot+firtG)+deltaG*firdG)\n\n                        Jl = rhol*(1+deltaL*firdL)\n                        Jv = rhog*(1+deltaG*firdG)\n                        K = firL-firG\n                        Ps = self.R*T*rhol*rhog/(rhol-rhog)*(K+log(rhol/rhog))\n\n                        return (Jl-Jv,\n                                Jl*(1/rhog-1/rhol)-log(rhol/rhog)-K,\n                                hoL*(1-x)+hoG*x - h,\n                                Ps - P*1000)\n\n                    for to in [To, 300, 400, 500, 600]:\n                        rLo = self._Liquid_Density(to)\n                        rGo = self._Vapor_Density(to)\n                        sol = fsolve(f, [to, rLo, rGo, 0.5], full_output=True)\n                        T, rhoL, rhoG, x = sol[0]\n                        if sol[2] == 1 and 0 <= x <= 1 and \\\n                                sum(abs(sol[1][\"fvec\"])) < 1e-5:\n                            break\n\n                    if sum(abs(sol[1][\"fvec\"])) > 1e-5:\n                        raise(RuntimeError(sol[3]))\n\n                    liquido = self._Helmholtz(rhoL, T)\n                    vapor = self._Helmholtz(rhoG, T)\n                    P = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(\n                        liquido[\"fir\"]-vapor[\"fir\"]+log(rhoL/rhoG))/1000\n\n            elif self._mode == \"Ps\":\n                try:\n                    x0 = st0.x\n                except NameError:\n                    x0 = None\n\n                if x0 is None or x0 == 0 or x0 == 1:\n                    def f(parr):\n                        rho, T = parr\n                        delta = rho/rhoc\n                        tau = Tc/T\n\n                        ideal = self._phi0(tau, delta)\n                        fio = ideal[\"fio\"]\n                        fiot = ideal[\"fiot\"]\n                        fird = _phird(tau, delta, self._constants)\n                        fir = _phir(tau, delta, self._constants)\n                        firt = _phirt(tau, delta, self._constants)\n                        Po = (1+delta*fird)*self.R*T*rho\n                        so = self.R*(tau*(fiot+firt)-fio-fir)\n                        return Po-P*1000, so-s\n\n                    rho, T = fsolve(f, [rhoo, To])\n\n                else:\n                    def funcion(parr):\n                        rho, T = parr\n                        rhol, rhov, Ps = self._saturation(T)\n                        vapor = self._Helmholtz(rhov, T)\n                        liquido = self._Helmholtz(rhol, T)\n                        x = (1./rho-1/rhol)/(1/rhov-1/rhol)\n                        return Ps-P*1000, vapor[\"s\"]*x+liquido[\"s\"]*(1-x)-s\n                    rho, T = fsolve(funcion, [2., 500.])\n                    rhol, rhov, Ps = self._saturation(T)\n                    vapor = self._Helmholtz(rhov, T)\n                    liquido = self._Helmholtz(rhol, T)\n                    sv = vapor[\"s\"]\n                    sl = liquido[\"s\"]\n                    x = (s-sl)/(sv-sl)\n\n            elif self._mode == \"Pu\":\n                def f(parr):\n                    rho, T = parr\n                    delta = rho/rhoc\n                    tau = Tc/T\n\n                    ideal = self._phi0(tau, delta)\n                    fiot = ideal[\"fiot\"]\n                    fird = _phird(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    Po = (1+delta*fird)*self.R*T*rho\n                    ho = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n                    return ho-Po/rho-u, Po-P*1000\n\n                sol = fsolve(f, [rhoo, To], full_output=True)\n                rho, T = sol[0]\n                rhol = self._Liquid_Density(T)\n                rhov = self._Vapor_Density(T)\n                if rho == rhoo or sol[2] != 1:\n\n                    def f(parr):\n                        T, rhol, rhog, x = parr\n                        tau = Tc/T\n                        deltaL = rhol/self.rhoc\n                        deltaG = rhog/self.rhoc\n\n                        ideal = self._phi0(tau, deltaL)\n                        fiot = ideal[\"fiot\"]\n\n                        firL = _phir(tau, deltaL, self._constants)\n                        firdL = _phird(tau, deltaL, self._constants)\n                        firtL = _phirt(tau, deltaL, self._constants)\n                        hoL = self.R*T*(1+tau*(fiot+firtL)+deltaL*firdL)\n                        firG = _phir(tau, deltaG, self._constants)\n                        firdG = _phird(tau, deltaG, self._constants)\n                        firtG = _phirt(tau, deltaG, self._constants)\n                        hoG = self.R*T*(1+tau*(fiot+firtG)+deltaG*firdG)\n\n                        Jl = rhol*(1+deltaL*firdL)\n                        Jv = rhog*(1+deltaG*firdG)\n                        K = firL-firG\n                        Ps = self.R*T*rhol*rhog/(rhol-rhog)*(K+log(rhol/rhog))\n                        vu = hoG-Ps/rhog\n                        lu = hoL-Ps/rhol\n                        return (Jl-Jv,\n                                Jl*(1/rhog-1/rhol)-log(rhol/rhog)-K,\n                                lu*(1-x)+vu*x - u,\n                                Ps - P*1000)\n\n                    for to in [To, 300, 400, 500, 600]:\n                        rLo = self._Liquid_Density(to)\n                        rGo = self._Vapor_Density(to)\n                        sol = fsolve(f, [to, rLo, rGo, 0.5], full_output=True)\n                        T, rhoL, rhoG, x = sol[0]\n                        if sol[2] == 1 and 0 <= x <= 1 and \\\n                                sum(abs(sol[1][\"fvec\"])) < 1e-5:\n                            break\n\n                    if sum(abs(sol[1][\"fvec\"])) > 1e-5:\n                        raise(RuntimeError(sol[3]))\n\n                    liquido = self._Helmholtz(rhoL, T)\n                    vapor = self._Helmholtz(rhoG, T)\n                    P = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(\n                        liquido[\"fir\"]-vapor[\"fir\"]+log(rhoL/rhoG))/1000\n\n            elif self._mode == \"rhoh\":\n                delta = rho/rhoc\n\n                def f(T):\n                    tau = Tc/T\n\n                    ideal = self._phi0(tau, delta)\n                    fiot = ideal[\"fiot\"]\n                    fird = _phird(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    ho = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n                    return ho-h\n\n                T = fsolve(f, To)[0]\n                rhol = self._Liquid_Density(T)\n                rhov = self._Vapor_Density(T)\n                if T == To or rhov <= rho <= rhol:\n                    def f(parr):\n                        T, rhol, rhog = parr\n                        tau = Tc/T\n                        deltaL = rhol/self.rhoc\n                        deltaG = rhog/self.rhoc\n\n                        ideal = self._phi0(tau, deltaL)\n                        fiot = ideal[\"fiot\"]\n                        firL = _phir(tau, deltaL, self._constants)\n                        firdL = _phird(tau, deltaL, self._constants)\n                        firtL = _phirt(tau, deltaL, self._constants)\n                        hoL = self.R*T*(1+tau*(fiot+firtL)+deltaL*firdL)\n                        firG = _phir(tau, deltaG, self._constants)\n                        firdG = _phird(tau, deltaG, self._constants)\n                        firtG = _phirt(tau, deltaG, self._constants)\n                        hoG = self.R*T*(1+tau*(fiot+firtG)+deltaG*firdG)\n\n                        Jl = rhol*(1+deltaL*firdL)\n                        Jv = rhog*(1+deltaG*firdG)\n                        K = firL-firG\n                        x = (1./rho-1/rhol)/(1/rhog-1/rhol)\n                        return (Jl-Jv,\n                                Jl*(1/rhog-1/rhol)-log(rhol/rhog)-K,\n                                hoL*(1-x)+hoG*x - h)\n\n                    for to in [To, 300, 400, 500, 600]:\n                        rhoLo = self._Liquid_Density(to)\n                        rhoGo = self._Vapor_Density(to)\n                        sol = fsolve(f, [to, rhoLo, rhoGo], full_output=True)\n                        T, rhoL, rhoG = sol[0]\n                        x = (1./rho-1/rhoL)/(1/rhoG-1/rhoL)\n                        if sol[2] == 1 and 0 <= x <= 1 and \\\n                                sum(abs(sol[1][\"fvec\"])) < 1e-5:\n                            break\n\n                    if sum(abs(sol[1][\"fvec\"])) > 1e-5:\n                        raise(RuntimeError(sol[3]))\n\n                    liquido = self._Helmholtz(rhoL, T)\n                    vapor = self._Helmholtz(rhoG, T)\n                    P = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(\n                        liquido[\"fir\"]-vapor[\"fir\"]+log(rhoL/rhoG))/1000\n\n            elif self._mode == \"rhos\":\n                delta = rho/rhoc\n\n                def f(T):\n                    tau = Tc/T\n                    ideal = self._phi0(tau, delta)\n                    fio = ideal[\"fio\"]\n                    fiot = ideal[\"fiot\"]\n                    fir = _phir(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    so = self.R*(tau*(fiot+firt)-fio-fir)\n                    return so-s\n\n                T = fsolve(f, To)[0]\n                rhol = self._Liquid_Density(T)\n                rhov = self._Vapor_Density(T)\n                if T == To or rhov <= rho <= rhol:\n\n                    def f(parr):\n                        T, rhol, rhog = parr\n                        tau = Tc/T\n                        deltaL = rhol/self.rhoc\n                        deltaG = rhog/self.rhoc\n\n                        idealL = self._phi0(tau, deltaL)\n                        fioL = idealL[\"fio\"]\n                        fiot = idealL[\"fiot\"]\n                        idealG = self._phi0(tau, deltaG)\n                        fioG = idealG[\"fio\"]\n\n                        firL = _phir(tau, deltaL, self._constants)\n                        firdL = _phird(tau, deltaL, self._constants)\n                        firtL = _phirt(tau, deltaL, self._constants)\n                        soL = self.R*(tau*(fiot+firtL)-fioL-firL)\n                        firG = _phir(tau, deltaG, self._constants)\n                        firdG = _phird(tau, deltaG, self._constants)\n                        firtG = _phirt(tau, deltaG, self._constants)\n                        soG = self.R*(tau*(fiot+firtG)-fioG-firG)\n\n                        Jl = rhol*(1+deltaL*firdL)\n                        Jv = rhog*(1+deltaG*firdG)\n                        K = firL-firG\n                        x = (1./rho-1/rhol)/(1/rhog-1/rhol)\n                        return (Jl-Jv,\n                                Jl*(1/rhog-1/rhol)-log(rhol/rhog)-K,\n                                soL*(1-x)+soG*x - s)\n\n                    for to in [To, 300, 400, 500, 600]:\n                        rhoLo = self._Liquid_Density(to)\n                        rhoGo = self._Vapor_Density(to)\n                        sol = fsolve(f, [to, rhoLo, rhoGo], full_output=True)\n                        T, rhoL, rhoG = sol[0]\n                        x = (1./rho-1/rhoL)/(1/rhoG-1/rhoL)\n                        if sol[2] == 1 and 0 <= x <= 1 and \\\n                                sum(abs(sol[1][\"fvec\"])) < 1e-5:\n                            break\n\n                    if sum(abs(sol[1][\"fvec\"])) > 1e-5:\n                        raise(RuntimeError(sol[3]))\n\n                    liquido = self._Helmholtz(rhoL, T)\n                    vapor = self._Helmholtz(rhoG, T)\n                    P = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(\n                        liquido[\"fir\"]-vapor[\"fir\"]+log(rhoL/rhoG))/1000\n\n            elif self._mode == \"rhou\":\n                delta = rho/rhoc\n\n                def f(T):\n                    tau = Tc/T\n\n                    ideal = self._phi0(tau, delta)\n                    fiot = ideal[\"fiot\"]\n                    fird = _phird(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    Po = (1+delta*fird)*self.R*T*rho\n                    ho = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n                    return ho-Po/rho-u\n\n                T = fsolve(f, To)[0]\n                rhol = self._Liquid_Density(T)\n                rhov = self._Vapor_Density(T)\n                if T == To or rhov <= rho <= rhol:\n                    def f(parr):\n                        T, rhol, rhog = parr\n                        tau = Tc/T\n                        deltaL = rhol/self.rhoc\n                        deltaG = rhog/self.rhoc\n\n                        ideal = self._phi0(tau, deltaL)\n                        fiot = ideal[\"fiot\"]\n                        firL = _phir(tau, deltaL, self._constants)\n                        firdL = _phird(tau, deltaL, self._constants)\n                        firtL = _phirt(tau, deltaL, self._constants)\n                        hoL = self.R*T*(1+tau*(fiot+firtL)+deltaL*firdL)\n                        firG = _phir(tau, deltaG, self._constants)\n                        firdG = _phird(tau, deltaG, self._constants)\n                        firtG = _phirt(tau, deltaG, self._constants)\n                        hoG = self.R*T*(1+tau*(fiot+firtG)+deltaG*firdG)\n\n                        Jl = rhol*(1+deltaL*firdL)\n                        Jv = rhog*(1+deltaG*firdG)\n                        K = firL-firG\n                        x = (1./rho-1/rhol)/(1/rhog-1/rhol)\n                        Ps = self.R*T*rhol*rhog/(rhol-rhog)*(K+log(rhol/rhog))\n                        vu = hoG-Ps/rhog\n                        lu = hoL-Ps/rhol\n                        return (Jl-Jv,\n                                Jl*(1/rhog-1/rhol)-log(rhol/rhog)-K,\n                                lu*(1-x)+vu*x - u)\n\n                    for to in [To, 300, 400, 500, 600]:\n                        rhoLo = self._Liquid_Density(to)\n                        rhoGo = self._Vapor_Density(to)\n                        sol = fsolve(f, [to, rhoLo, rhoGo], full_output=True)\n                        T, rhoL, rhoG = sol[0]\n                        x = (1./rho-1/rhoL)/(1/rhoG-1/rhoL)\n                        if sol[2] == 1 and 0 <= x <= 1 and \\\n                                sum(abs(sol[1][\"fvec\"])) < 1e-5:\n                            break\n\n                    if sum(abs(sol[1][\"fvec\"])) > 1e-5:\n                        raise(RuntimeError(sol[3]))\n\n                    liquido = self._Helmholtz(rhoL, T)\n                    vapor = self._Helmholtz(rhoG, T)\n                    P = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(\n                        liquido[\"fir\"]-vapor[\"fir\"]+log(rhoL/rhoG))/1000\n\n            elif self._mode == \"hs\":\n                def f(parr):\n                    rho, T = parr\n                    delta = rho/rhoc\n                    tau = Tc/T\n\n                    ideal = self._phi0(tau, delta)\n                    fio = ideal[\"fio\"]\n                    fiot = ideal[\"fiot\"]\n                    fird = _phird(tau, delta, self._constants)\n                    fir = _phir(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    ho = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n                    so = self.R*(tau*(fiot+firt)-fio-fir)\n                    return ho-h, so-s\n\n                rho, T = fsolve(f, [rhoo, To])\n                rhol = self._Liquid_Density(T)\n                rhov = self._Vapor_Density(T)\n                if rhov <= rho <= rhol:\n\n                    def f(parr):\n                        T, rhol, rhog, x = parr\n                        tau = Tc/T\n                        deltaL = rhol/self.rhoc\n                        deltaG = rhog/self.rhoc\n\n                        idealL = self._phi0(tau, deltaL)\n                        fiot = idealL[\"fiot\"]\n                        fioL = idealL[\"fio\"]\n                        idealG = self._phi0(tau, deltaG)\n                        fioG = idealG[\"fio\"]\n\n                        firL = _phir(tau, deltaL, self._constants)\n                        firdL = _phird(tau, deltaL, self._constants)\n                        firtL = _phirt(tau, deltaL, self._constants)\n                        hoL = self.R*T*(1+tau*(fiot+firtL)+deltaL*firdL)\n                        soL = self.R*(tau*(fiot+firtL)-fioL-firL)\n                        firG = _phir(tau, deltaG, self._constants)\n                        firdG = _phird(tau, deltaG, self._constants)\n                        firtG = _phirt(tau, deltaG, self._constants)\n                        hoG = self.R*T*(1+tau*(fiot+firtG)+deltaG*firdG)\n                        soG = self.R*(tau*(fiot+firtG)-fioG-firG)\n\n                        Jl = rhol*(1+deltaL*firdL)\n                        Jv = rhog*(1+deltaG*firdG)\n                        K = firL-firG\n                        return (Jl-Jv,\n                                Jl*(1/rhog-1/rhol)-log(rhol/rhog)-K,\n                                hoL*(1-x)+hoG*x - h,\n                                soL*(1-x)+soG*x - s)\n\n                    for to in [To, 300, 400, 500, 600]:\n                        rLo = self._Liquid_Density(to)\n                        rGo = self._Vapor_Density(to)\n                        sol = fsolve(f, [to, rLo, rGo, 0.5], full_output=True)\n                        T, rhoL, rhoG, x = sol[0]\n                        if sol[2] == 1 and 0 <= x <= 1 and \\\n                                sum(abs(sol[1][\"fvec\"])) < 1e-5:\n                            break\n\n                    if sum(abs(sol[1][\"fvec\"])) > 1e-5:\n                        raise(RuntimeError(sol[3]))\n\n                    liquido = self._Helmholtz(rhoL, T)\n                    vapor = self._Helmholtz(rhoG, T)\n                    P = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(\n                        liquido[\"fir\"]-vapor[\"fir\"]+log(rhoL/rhoG))/1000\n\n            elif self._mode == \"hu\":\n                def f(parr):\n                    rho, T = parr\n                    delta = rho/rhoc\n                    tau = Tc/T\n\n                    ideal = self._phi0(tau, delta)\n                    fiot = ideal[\"fiot\"]\n                    fird = _phird(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    Po = (1+delta*fird)*self.R*T*rho\n                    ho = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n\n                    return ho-Po/rho-u, ho-h\n\n                sol = fsolve(f, [rhoo, To], full_output=True)\n                rho, T = sol[0]\n                rhol = self._Liquid_Density(T)\n                rhov = self._Vapor_Density(T)\n                if sol[2] != 1 or rhov <= rho <= rhol:\n\n                    def f(parr):\n                        T, rhol, rhog, x = parr\n                        tau = Tc/T\n                        deltaL = rhol/self.rhoc\n                        deltaG = rhog/self.rhoc\n\n                        ideal = self._phi0(tau, deltaL)\n                        fiot = ideal[\"fiot\"]\n\n                        firL = _phir(tau, deltaL, self._constants)\n                        firdL = _phird(tau, deltaL, self._constants)\n                        firtL = _phirt(tau, deltaL, self._constants)\n                        hoL = self.R*T*(1+tau*(fiot+firtL)+deltaL*firdL)\n                        firG = _phir(tau, deltaG, self._constants)\n                        firdG = _phird(tau, deltaG, self._constants)\n                        firtG = _phirt(tau, deltaG, self._constants)\n                        hoG = self.R*T*(1+tau*(fiot+firtG)+deltaG*firdG)\n\n                        Jl = rhol*(1+deltaL*firdL)\n                        Jv = rhog*(1+deltaG*firdG)\n                        K = firL-firG\n\n                        Ps = self.R*T*rhol*rhog/(rhol-rhog)*(K+log(rhol/rhog))\n                        vu = hoG-Ps/rhog\n                        lu = hoL-Ps/rhol\n\n                        return (Jl-Jv,\n                                Jl*(1/rhog-1/rhol)-log(rhol/rhog)-K,\n                                hoL*(1-x)+hoG*x - h,\n                                lu*(1-x)+vu*x - u)\n\n                    for to in [To, 300, 400, 500, 600]:\n                        rLo = self._Liquid_Density(to)\n                        rGo = self._Vapor_Density(to)\n                        sol = fsolve(f, [to, rLo, rGo, 0.5], full_output=True)\n                        T, rhoL, rhoG, x = sol[0]\n                        if sol[2] == 1 and 0 <= x <= 1 and \\\n                                sum(abs(sol[1][\"fvec\"])) < 1e-5:\n                            break\n\n                    if sum(abs(sol[1][\"fvec\"])) > 1e-5:\n                        raise(RuntimeError(sol[3]))\n\n                    liquido = self._Helmholtz(rhoL, T)\n                    vapor = self._Helmholtz(rhoG, T)\n                    P = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(\n                        liquido[\"fir\"]-vapor[\"fir\"]+log(rhoL/rhoG))/1000\n\n            elif self._mode == \"su\":\n                def f(parr):\n                    rho, T = parr\n                    delta = rho/rhoc\n                    tau = Tc/T\n\n                    ideal = self._phi0(tau, delta)\n                    fio = ideal[\"fio\"]\n                    fiot = ideal[\"fiot\"]\n                    fird = _phird(tau, delta, self._constants)\n                    fir = _phir(tau, delta, self._constants)\n                    firt = _phirt(tau, delta, self._constants)\n                    ho = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n                    so = self.R*(tau*(fiot+firt)-fio-fir)\n                    Po = (1+delta*fird)*self.R*T*rho\n                    return ho-Po/rho-u, so-s\n\n                sol = fsolve(f, [rhoo, To], full_output=True)\n                rho, T = sol[0]\n                rhol = self._Liquid_Density(T)\n                rhov = self._Vapor_Density(T)\n                if sol[2] != 1 or rhov <= rho <= rhol:\n\n                    def f(parr):\n                        T, rhol, rhog, x = parr\n                        tau = Tc/T\n                        deltaL = rhol/self.rhoc\n                        deltaG = rhog/self.rhoc\n\n                        idealL = self._phi0(tau, deltaL)\n                        fiot = idealL[\"fiot\"]\n                        fioL = idealL[\"fio\"]\n                        idealG = self._phi0(tau, deltaG)\n                        fioG = idealG[\"fio\"]\n\n                        firL = _phir(tau, deltaL, self._constants)\n                        firdL = _phird(tau, deltaL, self._constants)\n                        firtL = _phirt(tau, deltaL, self._constants)\n                        hoL = self.R*T*(1+tau*(fiot+firtL)+deltaL*firdL)\n                        soL = self.R*(tau*(fiot+firtL)-fioL-firL)\n                        firG = _phir(tau, deltaG, self._constants)\n                        firdG = _phird(tau, deltaG, self._constants)\n                        firtG = _phirt(tau, deltaG, self._constants)\n                        hoG = self.R*T*(1+tau*(fiot+firtG)+deltaG*firdG)\n                        soG = self.R*(tau*(fiot+firtG)-fioG-firG)\n\n                        Jl = rhol*(1+deltaL*firdL)\n                        Jv = rhog*(1+deltaG*firdG)\n                        K = firL-firG\n\n                        Ps = self.R*T*rhol*rhog/(rhol-rhog)*(K+log(rhol/rhog))\n                        vu = hoG-Ps/rhog\n                        lu = hoL-Ps/rhol\n\n                        return (Jl-Jv,\n                                Jl*(1/rhog-1/rhol)-log(rhol/rhog)-K,\n                                soL*(1-x)+soG*x - s,\n                                lu*(1-x)+vu*x - u)\n\n                    for to in [To, 300, 400, 500, 600]:\n                        rLo = self._Liquid_Density(to)\n                        rGo = self._Vapor_Density(to)\n                        sol = fsolve(f, [to, rLo, rGo, 0.5], full_output=True)\n                        T, rhoL, rhoG, x = sol[0]\n                        if sol[2] == 1 and 0 <= x <= 1 and \\\n                                sum(abs(sol[1][\"fvec\"])) < 1e-5:\n                            break\n\n                    if sum(abs(sol[1][\"fvec\"])) > 1e-5:\n                        raise(RuntimeError(sol[3]))\n\n                    liquido = self._Helmholtz(rhoL, T)\n                    vapor = self._Helmholtz(rhoG, T)\n                    P = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(\n                        liquido[\"fir\"]-vapor[\"fir\"]+log(rhoL/rhoG))/1000\n\n            elif self._mode == \"Trho\":\n                if T < self.Tc:\n                    rhov = self._Vapor_Density(T)\n                    rhol = self._Liquid_Density(T)\n                    if rhol > rho > rhov:\n                        rhol, rhov, Ps = self._saturation(T)\n                        if rhol > rho > rhov:\n                            vapor = self._Helmholtz(rhov, T)\n                            liquido = self._Helmholtz(rhol, T)\n                            x = (1/rho-1/rhol)/(1/rhov-1/rhol)\n                            P = Ps/1000\n\n            rho = float(rho)\n            T = float(T)\n            propiedades = self._Helmholtz(rho, T)\n\n            if T > self.Tc:\n                x = 1\n            elif x is None:\n                x = 0\n\n            if not P:\n                P = propiedades[\"P\"]/1000.\n\n        elif self._mode == \"Tx\":\n            # Check input T in saturation range\n            if self.Tt > T or self.Tc < T or x > 1 or x < 0:\n                raise NotImplementedError(\"Incoming out of bound\")\n\n            rhol, rhov, Ps = self._saturation(T)\n            vapor = self._Helmholtz(rhov, T)\n            liquido = self._Helmholtz(rhol, T)\n            if x == 0:\n                propiedades = liquido\n            elif x == 1:\n                propiedades = vapor\n            P = Ps/1000.\n\n        elif self._mode == \"Px\":\n            # Check input P in saturation range\n            if self.Pc < P or x > 1 or x < 0:\n                raise NotImplementedError(\"Incoming out of bound\")\n\n            # Iterate over saturation routine to get T\n            def f(T):\n                rhol = self._Liquid_Density(T)\n                rhog = self._Vapor_Density(T)\n\n                deltaL = rhol/self.rhoc\n                deltaG = rhog/self.rhoc\n\n                tau = Tc/T\n\n                firL = _phir(tau, deltaL, self._constants)\n                firG = _phir(tau, deltaG, self._constants)\n                Ps = self.R*T*rhol*rhog/(rhol-rhog)*(\n                    firL-firG+log(deltaL/deltaG))\n                return Ps/1000-P\n\n            if T0:\n                To = T0\n            elif self.name == \"water\":\n                To = _TSat_P(P)\n            else:\n                To = (self.Tc+self.Tt)/2\n            T = fsolve(f, To)[0]\n            rhol, rhov, Ps = self._saturation(T)\n            vapor = self._Helmholtz(rhov, T)\n            liquido = self._Helmholtz(rhol, T)\n            if x == 0:\n                propiedades = liquido\n            elif x == 1:\n                propiedades = vapor\n\n        self.T = T\n        self.Tr = T/self.Tc\n        self.P = P\n        self.Pr = self.P/self.Pc\n        self.x = x\n        if self._mode in [\"Tx\", \"Px\"] or 0 < x < 1:\n            region = 4\n        else:\n            region = 0\n        self.phase = getphase(self.Tc, self.Pc, self.T, self.P, self.x, region)\n\n        self.Liquid = _fase()\n        self.Gas = _fase()\n        if x == 0:\n            # liquid phase\n            self.fill(self.Liquid, propiedades)\n            self.fill(self, propiedades)\n        elif x == 1:\n            # vapor phase\n            self.fill(self.Gas, propiedades)\n            self.fill(self, propiedades)\n        else:\n            self.fill(self.Liquid, liquido)\n            self.fill(self.Gas, vapor)\n\n            self.v = x*self.Gas.v+(1-x)*self.Liquid.v\n            self.rho = 1./self.v\n\n            self.h = x*self.Gas.h+(1-x)*self.Liquid.h\n            self.s = x*self.Gas.s+(1-x)*self.Liquid.s\n            self.u = x*self.Gas.u+(1-x)*self.Liquid.u\n            self.a = x*self.Gas.a+(1-x)*self.Liquid.a\n            self.g = x*self.Gas.g+(1-x)*self.Liquid.g\n\n            self.Z = x*self.Gas.Z+(1-x)*self.Liquid.Z\n            self.f = x*self.Gas.f+(1-x)*self.Liquid.f\n\n            self.Z_rho = x*self.Gas.Z_rho+(1-x)*self.Liquid.Z_rho\n            self.IntP = x*self.Gas.IntP+(1-x)*self.Liquid.IntP\n\n        # Calculate special properties useful only for one phase\n        if self._mode in (\"Px\", \"Tx\") or (x < 1 and self.Tt <= T <= self.Tc):\n            self.sigma = self._surface(T)\n        else:\n            self.sigma = None\n\n        vir = self._virial(T)\n        self.virialB = vir[\"B\"]/self.rhoc\n        self.virialC = vir[\"C\"]/self.rhoc**2\n\n        if 0 < x < 1:\n            self.Hvap = vapor[\"h\"]-liquido[\"h\"]\n            self.Svap = vapor[\"s\"]-liquido[\"s\"]\n        else:\n            self.Hvap = None\n            self.Svap = None\n\n        self.invT = -1/self.T\n\n        # Ideal properties\n        cp0 = self._prop0(self.rho, self.T)\n        self.v0 = self.R*self.T/self.P/1000\n        self.rho0 = 1./self.v0\n        self.h0 = cp0.h\n        self.u0 = self.h0-self.P*self.v0\n        self.s0 = cp0.s\n        self.a0 = self.u0-self.T*self.s0\n        self.g0 = self.h0-self.T*self.s0\n        self.cp0 = cp0.cp\n        self.cv0 = cp0.cv\n        self.cp0_cv = self.cp0/self.cv0\n        cp0.v = self.v0\n        self.gamma0 = -self.v0/self.P/1000*self.derivative(\"P\", \"v\", \"s\", cp0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fill(self, fase, estado):\n        fase.rho = estado[\"rho\"]\n        fase.v = 1/fase.rho\n\n        fase.h = estado[\"h\"]\n        fase.s = estado[\"s\"]\n        fase.u = fase.h-self.P*1000*fase.v\n        fase.a = fase.u-self.T*fase.s\n        fase.g = fase.h-self.T*fase.s\n\n        fase.Z = self.P*fase.v/self.T/self.R*1e3\n        fase.fi = exp(estado[\"fir\"]+estado[\"delta\"]*estado[\"fird\"] -\n                      log(1+estado[\"delta\"]*estado[\"fird\"]))\n        fase.f = fase.fi*self.P\n        fase.cv = estado[\"cv\"]\n\n        fase.rhoM = fase.rho/self.M\n        fase.hM = fase.h*self.M\n        fase.sM = fase.s*self.M\n        fase.uM = fase.u*self.M\n        fase.aM = fase.a*self.M\n        fase.gM = fase.g*self.M\n\n        fase.alfap = estado[\"alfap\"]\n        fase.betap = estado[\"betap\"]\n\n        fase.cp = self.derivative(\"h\", \"T\", \"P\", fase)\n        fase.cp_cv = fase.cp/fase.cv\n        fase.w = (self.derivative(\"P\", \"rho\", \"s\", fase)*1000)**0.5\n        fase.cvM = fase.cv*self.M\n        fase.cpM = fase.cp*self.M\n\n        fase.joule = self.derivative(\"T\", \"P\", \"h\", fase)*1e3\n        fase.Gruneisen = fase.v/fase.cv*self.derivative(\"P\", \"T\", \"v\", fase)\n        fase.alfav = self.derivative(\"v\", \"T\", \"P\", fase)/fase.v\n        fase.kappa = -self.derivative(\"v\", \"P\", \"T\", fase)/fase.v*1e3\n        fase.betas = self.derivative(\"T\", \"P\", \"s\", fase)\n\n        fase.gamma = -fase.v/self.P*self.derivative(\"P\", \"v\", \"s\", fase)*1e-3\n        fase.kt = -fase.v/self.P*self.derivative(\"P\", \"v\", \"T\", fase)*1e-3\n        fase.ks = -self.derivative(\"v\", \"P\", \"s\", fase)/fase.v*1e3\n        fase.Kt = -fase.v*self.derivative(\"P\", \"v\", \"s\", fase)*1e-3\n        fase.Ks = -fase.v*self.derivative(\"P\", \"v\", \"T\", fase)*1e-3\n        fase.dhdT_rho = self.derivative(\"h\", \"T\", \"rho\", fase)\n        fase.dhdT_P = self.derivative(\"h\", \"T\", \"P\", fase)\n        fase.dhdP_T = self.derivative(\"h\", \"P\", \"T\", fase)*1e3\n        fase.dhdP_rho = self.derivative(\"h\", \"P\", \"rho\", fase)*1e3\n        fase.dhdrho_T = self.derivative(\"h\", \"rho\", \"T\", fase)\n        fase.dhdrho_P = self.derivative(\"h\", \"rho\", \"P\", fase)\n        fase.dpdT_rho = self.derivative(\"P\", \"T\", \"rho\", fase)*1e-3\n        fase.dpdrho_T = self.derivative(\"P\", \"rho\", \"T\", fase)*1e-3\n        fase.drhodP_T = self.derivative(\"rho\", \"P\", \"T\", fase)*1e3\n        fase.drhodT_P = self.derivative(\"rho\", \"T\", \"P\", fase)\n\n        fase.Z_rho = (fase.Z-1)/fase.rho\n        fase.IntP = self.T*self.derivative(\"P\", \"T\", \"rho\", fase)*1e-3-self.P\n        fase.hInput = fase.v*self.derivative(\"h\", \"v\", \"P\", fase)\n\n        fase.mu = self._visco(fase.rho, self.T, fase)\n        fase.k = self._thermo(fase.rho, self.T, fase)\n        fase.nu = fase.mu/fase.rho\n        fase.alfa = fase.k/1000/fase.rho/fase.cp\n        fase.Prandt = fase.mu*fase.cp*1000/fase.k\n        if self.name == \"water\":\n            try:\n                fase.epsilon = _Dielectric(fase.rho, self.T)\n            except NotImplementedError:\n                fase.epsilon = None\n\n            try:\n                fase.n = _Refractive(fase.rho, self.T, self.kwargs[\"l\"])\n            except NotImplementedError:\n                fase.n = None\n        else:\n            fase.epsilon = None\n            fase.n = None", "response": "Fill the internal state of the object with the properties of the object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef derivative(self, z, x, y, fase):\n        return deriv_H(self, z, x, y, fase)", "response": "Wrapper for derivative for custom derived properties\n        where x y z can be P T v rho u h s g a"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _saturation(self, T):\n        rhoc = self._constants.get(\"rhoref\", self.rhoc)\n        Tc = self._constants.get(\"Tref\", self.Tc)\n\n        if T > Tc:\n            T = Tc\n        tau = Tc/T\n\n        rhoLo = self._Liquid_Density(T)\n        rhoGo = self._Vapor_Density(T)\n\n        def f(parr):\n            rhol, rhog = parr\n            deltaL = rhol/rhoc\n            deltaG = rhog/rhoc\n            phirL = _phir(tau, deltaL, self._constants)\n            phirG = _phir(tau, deltaG, self._constants)\n            phirdL = _phird(tau, deltaL, self._constants)\n            phirdG = _phird(tau, deltaG, self._constants)\n            Jl = deltaL*(1+deltaL*phirdL)\n            Jv = deltaG*(1+deltaG*phirdG)\n            Kl = deltaL*phirdL+phirL+log(deltaL)\n            Kv = deltaG*phirdG+phirG+log(deltaG)\n            return Kv-Kl, Jv-Jl\n\n        rhoL, rhoG = fsolve(f, [rhoLo, rhoGo])\n        if rhoL == rhoG:\n            Ps = self.Pc\n        else:\n            deltaL = rhoL/self.rhoc\n            deltaG = rhoG/self.rhoc\n            firL = _phir(tau, deltaL, self._constants)\n            firG = _phir(tau, deltaG, self._constants)\n\n            Ps = self.R*T*rhoL*rhoG/(rhoL-rhoG)*(firL-firG+log(deltaL/deltaG))\n        return rhoL, rhoG, Ps", "response": "Saturation calculation for two phase search for two - phase search."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the properties of the object based on the helmholtz free energy and derivatives.", "response": "def _Helmholtz(self, rho, T):\n        \"\"\"Calculated properties from helmholtz free energy and derivatives\n\n        Parameters\n        ----------\n        rho : float\n            Density, [kg/m\u00b3]\n        T : float\n            Temperature, [K]\n\n        Returns\n        -------\n        prop : dict\n            Dictionary with calculated properties:\n                * fir: [-]\n                * fird: \u2202fir/\u2202\u03b4|\u03c4\n                * firdd: \u2202\u00b2fir/\u2202\u03b4\u00b2|\u03c4\n                * delta: Reducen density rho/rhoc, [-]\n                * P: Pressure, [kPa]\n                * h: Enthalpy, [kJ/kg]\n                * s: Entropy, [kJ/kgK]\n                * cv: Isochoric specific heat, [kJ/kgK]\n                * alfav: Thermal expansion coefficient, [1/K]\n                * betap: Isothermal compressibility, [1/kPa]\n\n        References\n        ----------\n        IAPWS, Revised Release on the IAPWS Formulation 1995 for the\n        Thermodynamic Properties of Ordinary Water Substance for General and\n        Scientific Use, September 2016, Table 3\n        http://www.iapws.org/relguide/IAPWS-95.html\n        \"\"\"\n        if isinstance(rho, ndarray):\n            rho = rho[0]\n        if isinstance(T, ndarray):\n            T = T[0]\n        if rho < 0:\n            rho = 1e-20\n        if T < 50:\n            T = 50\n        rhoc = self._constants.get(\"rhoref\", self.rhoc)\n        Tc = self._constants.get(\"Tref\", self.Tc)\n        delta = rho/rhoc\n        tau = Tc/T\n        ideal = self._phi0(tau, delta)\n        fio = ideal[\"fio\"]\n        fiot = ideal[\"fiot\"]\n        fiott = ideal[\"fiott\"]\n\n        res = self._phir(tau, delta)\n        fir = res[\"fir\"]\n        firt = res[\"firt\"]\n        firtt = res[\"firtt\"]\n        fird = res[\"fird\"]\n        firdd = res[\"firdd\"]\n        firdt = res[\"firdt\"]\n\n        propiedades = {}\n        propiedades[\"fir\"] = fir\n        propiedades[\"fird\"] = fird\n        propiedades[\"firdd\"] = firdd\n        propiedades[\"delta\"] = delta\n\n        propiedades[\"rho\"] = rho\n        propiedades[\"P\"] = (1+delta*fird)*self.R*T*rho\n        propiedades[\"h\"] = self.R*T*(1+tau*(fiot+firt)+delta*fird)\n        propiedades[\"s\"] = self.R*(tau*(fiot+firt)-fio-fir)\n        propiedades[\"cv\"] = -self.R*tau**2*(fiott+firtt)\n        propiedades[\"alfap\"] = (1-delta*tau*firdt/(1+delta*fird))/T\n        propiedades[\"betap\"] = rho*(\n            1+(delta*fird+delta**2*firdd)/(1+delta*fird))\n        return propiedades"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the dimensional form of the free energy derivatives of a given resource.", "response": "def _derivDimensional(self, rho, T):\n        \"\"\"Calcule the dimensional form or Helmholtz free energy derivatives\n\n        Parameters\n        ----------\n        rho : float\n            Density, [kg/m\u00b3]\n        T : float\n            Temperature, [K]\n\n        Returns\n        -------\n        prop : dict\n            Dictionary with residual helmholtz energy and derivatives:\n\n                * fir, [kJ/kg]\n                * firt: \u2202fir/\u2202T|\u03c1, [kJ/kgK]\n                * fird: \u2202fir/\u2202\u03c1|T, [kJ/m\u00b3kg\u00b2]\n                * firtt: \u2202\u00b2fir/\u2202T\u00b2|\u03c1, [kJ/kgK\u00b2]\n                * firdt: \u2202\u00b2fir/\u2202T\u2202\u03c1, [kJ/m\u00b3kg\u00b2K]\n                * firdd: \u2202\u00b2fir/\u2202\u03c1\u00b2|T, [kJ/m\u2076kg]\n\n        References\n        ----------\n        IAPWS, Guideline on an Equation of State for Humid Air in Contact with\n        Seawater and Ice, Consistent with the IAPWS Formulation 2008 for the\n        Thermodynamic Properties of Seawater, Table 7,\n        http://www.iapws.org/relguide/SeaAir.html\n        \"\"\"\n        if not rho:\n            prop = {}\n            prop[\"fir\"] = 0\n            prop[\"firt\"] = 0\n            prop[\"fird\"] = 0\n            prop[\"firtt\"] = 0\n            prop[\"firdt\"] = 0\n            prop[\"firdd\"] = 0\n            return prop\n\n        R = self._constants.get(\"R\")/self._constants.get(\"M\", self.M)\n        rhoc = self._constants.get(\"rhoref\", self.rhoc)\n        Tc = self._constants.get(\"Tref\", self.Tc)\n        delta = rho/rhoc\n        tau = Tc/T\n\n        ideal = self._phi0(tau, delta)\n        fio = ideal[\"fio\"]\n        fiot = ideal[\"fiot\"]\n        fiott = ideal[\"fiott\"]\n        fiod = ideal[\"fiod\"]\n        fiodd = ideal[\"fiodd\"]\n\n        res = self._phir(tau, delta)\n        fir = res[\"fir\"]\n        firt = res[\"firt\"]\n        firtt = res[\"firtt\"]\n        fird = res[\"fird\"]\n        firdd = res[\"firdd\"]\n        firdt = res[\"firdt\"]\n\n        prop = {}\n        prop[\"fir\"] = R*T*(fio+fir)\n        prop[\"firt\"] = R*(fio+fir-(fiot+firt)*tau)\n        prop[\"fird\"] = R*T/rhoc*(fiod+fird)\n        prop[\"firtt\"] = R*tau**2/T*(fiott+firtt)\n        prop[\"firdt\"] = R/rhoc*(fiod+fird-firdt*tau)\n        prop[\"firdd\"] = R*T/rhoc**2*(fiodd+firdd)\n        return prop"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _Vapor_Pressure(cls, T):\n        Tita = 1-T/cls.Tc\n        suma = 0\n        for n, x in zip(cls._Pv[\"ao\"], cls._Pv[\"exp\"]):\n            suma += n*Tita**x\n        Pr = exp(cls.Tc/T*suma)\n        Pv = Pr*cls.Pc\n        return Pv", "response": "Auxiliary equation for the vapour pressure."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Liquid_Density(cls, T):\n        eq = cls._rhoL[\"eq\"]\n        Tita = 1-T/cls.Tc\n        if eq == 2:\n            Tita = Tita**(1./3)\n        suma = 0\n        for n, x in zip(cls._rhoL[\"ao\"], cls._rhoL[\"exp\"]):\n            suma += n*Tita**x\n        Pr = suma+1\n        rho = Pr*cls.rhoc\n        return rho", "response": "Auxiliary equation for the density of saturated liquid at a given temperature."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fugacity(T, P, x):\n    # Check input parameters\n    if T < 193 or T > 473 or P < 0 or P > 5 or x < 0 or x > 1:\n        raise(NotImplementedError(\"Input not in range of validity\"))\n\n    R = 8.314462  # J/molK\n\n    # Virial coefficients\n    vir = _virial(T)\n\n    # Eq 3\n    beta = x*(2-x)*vir[\"Bww\"]+(1-x)**2*(2*vir[\"Baw\"]-vir[\"Baa\"])\n\n    # Eq 4\n    gamma = x**2*(3-2*x)*vir[\"Cwww\"] + \\\n        (1-x)**2*(6*x*vir[\"Caww\"]+3*(1-2*x)*vir[\"Caaw\"]-2*(1-x)*vir[\"Caaa\"]) +\\\n        (x**2*vir[\"Bww\"]+2*x*(1-x)*vir[\"Baw\"]+(1-x)**2*vir[\"Baa\"]) * \\\n        (x*(3*x-4)*vir[\"Bww\"]+2*(1-x)*(3*x-2)*vir[\"Baw\"]+3*(1-x)**2*vir[\"Baa\"])\n\n    # Eq 2\n    fv = x*P*exp(beta*P*1e6/R/T+0.5*gamma*(P*1e6/R/T)**2)\n    return fv", "response": "Fugacity equation for humid air"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _bubbleP(cls, T):\n        c = cls._blend[\"bubble\"]\n        Tj = cls._blend[\"Tj\"]\n        Pj = cls._blend[\"Pj\"]\n        Tita = 1-T/Tj\n\n        suma = 0\n        for i, n in zip(c[\"i\"], c[\"n\"]):\n            suma += n*Tita**(i/2.)\n        P = Pj*exp(Tj/T*suma)\n        return P", "response": "Using ancillary equation return the pressure of bubble point"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if inputs are enough to define state", "response": "def calculable(self):\n        \"\"\"Check if inputs are enough to define state\"\"\"\n        self._mode = \"\"\n        if self.kwargs[\"T\"] and self.kwargs[\"P\"]:\n            self._mode = \"TP\"\n        elif self.kwargs[\"T\"] and self.kwargs[\"rho\"]:\n            self._mode = \"Trho\"\n        elif self.kwargs[\"P\"] and self.kwargs[\"rho\"]:\n            self._mode = \"Prho\"\n\n        # Composition definition\n        self._composition = \"\"\n        if self.kwargs[\"A\"] is not None:\n            self._composition = \"A\"\n        elif self.kwargs[\"xa\"] is not None:\n            self._composition = \"xa\"\n\n        return bool(self._mode) and bool(self._composition)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculo(self):\n        T = self.kwargs[\"T\"]\n        rho = self.kwargs[\"rho\"]\n        P = self.kwargs[\"P\"]\n\n        # Composition alternate definition\n        if self._composition == \"A\":\n            A = self.kwargs[\"A\"]\n        elif self._composition == \"xa\":\n            xa = self.kwargs[\"xa\"]\n            A = xa/(1-(1-xa)*(1-Mw/Ma))\n\n        # Thermodynamic definition\n        if self._mode == \"TP\":\n            def f(rho):\n                fav = self._fav(T, rho, A)\n                return rho**2*fav[\"fird\"]/1000-P\n            rho = fsolve(f, 1)[0]\n        elif self._mode == \"Prho\":\n            def f(T):\n                fav = self._fav(T, rho, A)\n                return rho**2*fav[\"fird\"]/1000-P\n            T = fsolve(f, 300)[0]\n\n        # General calculation procedure\n        fav = self._fav(T, rho, A)\n\n        # Common thermodynamic properties\n        prop = self._prop(T, rho, fav)\n        self.T = T\n        self.rho = rho\n        self.v = 1/rho\n        self.P = prop[\"P\"]\n        self.s = prop[\"s\"]\n        self.cp = prop[\"cp\"]\n        self.h = prop[\"h\"]\n        self.g = prop[\"g\"]\n        self.u = self.h-self.P*1000*self.v\n        self.alfav = prop[\"alfav\"]\n        self.betas = prop[\"betas\"]\n        self.xkappa = prop[\"xkappa\"]\n        self.ks = prop[\"ks\"]\n        self.w = prop[\"w\"]\n\n        # Coligative properties\n        coligative = self._coligative(rho, A, fav)\n        self.A = A\n        self.W = 1-A\n        self.mu = coligative[\"mu\"]\n        self.muw = coligative[\"muw\"]\n        self.M = coligative[\"M\"]\n        self.HR = coligative[\"HR\"]\n        self.xa = coligative[\"xa\"]\n        self.xw = coligative[\"xw\"]\n        self.Pv = (1-self.xa)*self.P\n\n        # Saturation related properties\n        A_sat = self._eq(self.T, self.P)\n        self.xa_sat = A_sat*Mw/Ma/(1-A_sat*(1-Mw/Ma))\n        self.RH = (1-self.xa)/(1-self.xa_sat)", "response": "Calculate the structure of the current object based on the parameters of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _eq(self, T, P):\n        if T <= 273.16:\n            ice = _Ice(T, P)\n            gw = ice[\"g\"]\n        else:\n            water = IAPWS95(T=T, P=P)\n            gw = water.g\n\n        def f(parr):\n            rho, a = parr\n            if a > 1:\n                a = 1\n            fa = self._fav(T, rho, a)\n            muw = fa[\"fir\"]+rho*fa[\"fird\"]-a*fa[\"fira\"]\n            return gw-muw, rho**2*fa[\"fird\"]/1000-P\n\n        rinput = fsolve(f, [1, 0.95], full_output=True)\n        Asat = rinput[0][1]\n        return Asat", "response": "Procedure for calculate the composition in saturation state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _prop(self, T, rho, fav):\n        prop = {}\n        prop[\"P\"] = rho**2*fav[\"fird\"]/1000                             # Eq T1\n        prop[\"s\"] = -fav[\"firt\"]                                        # Eq T2\n        prop[\"cp\"] = -T*fav[\"firtt\"]+T*rho*fav[\"firdt\"]**2/(            # Eq T3\n            2*fav[\"fird\"]+rho*fav[\"firdd\"])\n        prop[\"h\"] = fav[\"fir\"]-T*fav[\"firt\"]+rho*fav[\"fird\"]            # Eq T4\n        prop[\"g\"] = fav[\"fir\"]+rho*fav[\"fird\"]                          # Eq T5\n        prop[\"alfav\"] = fav[\"firdt\"]/(2*fav[\"fird\"]+rho*fav[\"firdd\"])   # Eq T6\n        prop[\"betas\"] = 1000*fav[\"firdt\"]/rho/(                         # Eq T7\n            rho*fav[\"firdt\"]**2-fav[\"firtt\"]*(2*fav[\"fird\"]+rho*fav[\"firdd\"]))\n        prop[\"xkappa\"] = 1e3/(rho**2*(2*fav[\"fird\"]+rho*fav[\"firdd\"]))  # Eq T8\n        prop[\"ks\"] = 1000*fav[\"firtt\"]/rho**2/(                         # Eq T9\n            fav[\"firtt\"]*(2*fav[\"fird\"]+rho*fav[\"firdd\"])-rho*fav[\"firdt\"]**2)\n        prop[\"w\"] = (rho**2*1000*(fav[\"firtt\"]*fav[\"firdd\"]-fav[\"firdt\"]**2) /\n                     fav[\"firtt\"]+2*rho*fav[\"fird\"]*1000)**0.5         # Eq T10\n        return prop", "response": "This function returns the properties of the object that is used to set the thermodynamic properties of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _coligative(self, rho, A, fav):\n        prop = {}\n        prop[\"mu\"] = fav[\"fira\"]\n        prop[\"muw\"] = fav[\"fir\"]+rho*fav[\"fird\"]-A*fav[\"fira\"]\n        prop[\"M\"] = 1/((1-A)/Mw+A/Ma)\n        prop[\"HR\"] = 1/A-1\n        prop[\"xa\"] = A*Mw/Ma/(1-A*(1-Mw/Ma))\n        prop[\"xw\"] = 1-prop[\"xa\"]\n        return prop", "response": "Coligative version of the get_dict_of_keys_from_dict_of_keys_from_dicts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _Ice(T, P):\n    # Check input in range of validity\n    if T > 273.16:\n        # No Ice Ih stable\n        warnings.warn(\"Metastable ice\")\n    elif P > 208.566:\n        # Ice Ih limit upper pressure\n        raise NotImplementedError(\"Incoming out of bound\")\n    elif P < Pt:\n        Psub = _Sublimation_Pressure(T)\n        if Psub > P:\n            # Zone Gas\n            warnings.warn(\"Metastable ice in vapor region\")\n    elif 251.165 < T:\n        Pmel = _Melting_Pressure(T)\n        if Pmel < P:\n            # Zone Liquid\n            warnings.warn(\"Metastable ice in liquid region\")\n\n    Tr = T/Tt\n    Pr = P/Pt\n    P0 = 101325e-6/Pt\n    s0 = -0.332733756492168e4*1e-3  # Express in kJ/kgK\n\n    gok = [-0.632020233335886e6, 0.655022213658955, -0.189369929326131e-7,\n           0.339746123271053e-14, -0.556464869058991e-21]\n    r2k = [complex(-0.725974574329220e2, -0.781008427112870e2)*1e-3,\n           complex(-0.557107698030123e-4, 0.464578634580806e-4)*1e-3,\n           complex(0.234801409215913e-10, -0.285651142904972e-10)*1e-3]\n    t1 = complex(0.368017112855051e-1, 0.510878114959572e-1)\n    t2 = complex(0.337315741065416, 0.335449415919309)\n    r1 = complex(0.447050716285388e2, 0.656876847463481e2)*1e-3\n\n    go = gop = gopp = 0\n    for k in range(5):\n        go += gok[k]*1e-3*(Pr-P0)**k\n    for k in range(1, 5):\n        gop += gok[k]*1e-3*k/Pt*(Pr-P0)**(k-1)\n    for k in range(2, 5):\n        gopp += gok[k]*1e-3*k*(k-1)/Pt**2*(Pr-P0)**(k-2)\n    r2 = r2p = 0\n    for k in range(3):\n        r2 += r2k[k]*(Pr-P0)**k\n    for k in range(1, 3):\n        r2p += r2k[k]*k/Pt*(Pr-P0)**(k-1)\n    r2pp = r2k[2]*2/Pt**2\n\n    c = r1*((t1-Tr)*log_c(t1-Tr)+(t1+Tr)*log_c(t1+Tr)-2*t1*log_c(\n        t1)-Tr**2/t1)+r2*((t2-Tr)*log_c(t2-Tr)+(t2+Tr)*log_c(\n            t2+Tr)-2*t2*log_c(t2)-Tr**2/t2)\n    ct = r1*(-log_c(t1-Tr)+log_c(t1+Tr)-2*Tr/t1)+r2*(\n        -log_c(t2-Tr)+log_c(t2+Tr)-2*Tr/t2)\n    ctt = r1*(1/(t1-Tr)+1/(t1+Tr)-2/t1) + r2*(1/(t2-Tr)+1/(t2+Tr)-2/t2)\n    cp = r2p*((t2-Tr)*log_c(t2-Tr)+(t2+Tr)*log_c(\n        t2+Tr)-2*t2*log_c(t2)-Tr**2/t2)\n    ctp = r2p*(-log_c(t2-Tr)+log_c(t2+Tr)-2*Tr/t2)\n    cpp = r2pp*((t2-Tr)*log_c(t2-Tr)+(t2+Tr)*log_c(\n        t2+Tr)-2*t2*log_c(t2)-Tr**2/t2)\n\n    g = go-s0*Tt*Tr+Tt*c.real\n    gt = -s0+ct.real\n    gp = gop+Tt*cp.real\n    gtt = ctt.real/Tt\n    gtp = ctp.real\n    gpp = gopp+Tt*cpp.real\n\n    propiedades = {}\n    propiedades[\"gt\"] = gt\n    propiedades[\"gp\"] = gp\n    propiedades[\"gtt\"] = gtt\n    propiedades[\"gpp\"] = gpp\n    propiedades[\"gtp\"] = gtp\n    propiedades[\"T\"] = T\n    propiedades[\"P\"] = P\n    propiedades[\"v\"] = gp/1000\n    propiedades[\"rho\"] = 1000./gp\n    propiedades[\"h\"] = g-T*gt\n    propiedades[\"s\"] = -gt\n    propiedades[\"cp\"] = -T*gtt\n    propiedades[\"u\"] = g-T*gt-P*gp\n    propiedades[\"g\"] = g\n    propiedades[\"a\"] = g-P*gp\n    propiedades[\"alfav\"] = gtp/gp\n    propiedades[\"beta\"] = -gtp/gpp\n    propiedades[\"xkappa\"] = -gpp/gp\n    propiedades[\"ks\"] = (gtp**2-gtt*gpp)/gp/gtt\n    return propiedades", "response": "Basic state equation for Ice Ih\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Liquid(T, P=0.1):\n    # Check input in range of validity\n    if T <= 253.15 or T >= 383.15 or P < 0.1 or P > 0.3:\n        raise NotImplementedError(\"Incoming out of bound\")\n    elif P != 0.1:\n        # Raise a warning if the P value is extrapolated\n        warnings.warn(\"Using extrapolated values\")\n\n    R = 0.46151805   # kJ/kgK\n    Po = 0.1\n    Tr = 10\n    tau = T/Tr\n    alfa = Tr/(593-T)\n    beta = Tr/(T-232)\n\n    a = [None, -1.661470539e5, 2.708781640e6, -1.557191544e8, None,\n         1.93763157e-2, 6.74458446e3, -2.22521604e5, 1.00231247e8,\n         -1.63552118e9, 8.32299658e9, -7.5245878e-6, -1.3767418e-2,\n         1.0627293e1, -2.0457795e2, 1.2037414e3]\n    b = [None, -8.237426256e-1, 1.908956353, -2.017597384, 8.546361348e-1,\n         5.78545292e-3, -1.53195665E-2, 3.11337859e-2, -4.23546241e-2,\n         3.38713507e-2, -1.19946761e-2, -3.1091470e-6, 2.8964919e-5,\n         -1.3112763e-4, 3.0410453e-4, -3.9034594e-4, 2.3403117e-4,\n         -4.8510101e-5]\n    c = [None, -2.452093414e2, 3.869269598e1, -8.983025854]\n    n = [None, 4, 5, 7, None, None, 4, 5, 7, 8, 9, 1, 3, 5, 6, 7]\n    m = [None, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 6, 7, 9]\n\n    suma1 = sum([a[i]*alfa**n[i] for i in range(1, 4)])\n    suma2 = sum([b[i]*beta**m[i] for i in range(1, 5)])\n    go = R*Tr*(c[1]+c[2]*tau+c[3]*tau*log(tau)+suma1+suma2)\n\n    suma1 = sum([a[i]*alfa**n[i] for i in range(6, 11)])\n    suma2 = sum([b[i]*beta**m[i] for i in range(5, 11)])\n    vo = R*Tr/Po/1000*(a[5]+suma1+suma2)\n\n    suma1 = sum([a[i]*alfa**n[i] for i in range(11, 16)])\n    suma2 = sum([b[i]*beta**m[i] for i in range(11, 18)])\n    vpo = R*Tr/Po**2/1000*(suma1+suma2)\n\n    suma1 = sum([n[i]*a[i]*alfa**(n[i]+1) for i in range(1, 4)])\n    suma2 = sum([m[i]*b[i]*beta**(m[i]+1) for i in range(1, 5)])\n    so = -R*(c[2]+c[3]*(1+log(tau))+suma1-suma2)\n\n    suma1 = sum([n[i]*(n[i]+1)*a[i]*alfa**(n[i]+2) for i in range(1, 4)])\n    suma2 = sum([m[i]*(m[i]+1)*b[i]*beta**(m[i]+2) for i in range(1, 5)])\n    cpo = -R*(c[3]+tau*suma1+tau*suma2)\n\n    suma1 = sum([n[i]*a[i]*alfa**(n[i]+1) for i in range(6, 11)])\n    suma2 = sum([m[i]*b[i]*beta**(m[i]+1) for i in range(5, 11)])\n    vto = R/Po/1000*(suma1-suma2)\n\n    # This properties are only neccessary for computing thermodynamic\n    # properties at pressures different from 0.1 MPa\n    suma1 = sum([n[i]*(n[i]+1)*a[i]*alfa**(n[i]+2) for i in range(6, 11)])\n    suma2 = sum([m[i]*(m[i]+1)*b[i]*beta**(m[i]+2) for i in range(5, 11)])\n    vtto = R/Tr/Po/1000*(suma1+suma2)\n\n    suma1 = sum([n[i]*a[i]*alfa**(n[i]+1) for i in range(11, 16)])\n    suma2 = sum([m[i]*b[i]*beta**(m[i]+1) for i in range(11, 18)])\n    vpto = R/Po**2/1000*(suma1-suma2)\n\n    if P != 0.1:\n        go += vo*(P-0.1)\n        so -= vto*(P-0.1)\n        cpo -= T*vtto*(P-0.1)\n        vo -= vpo*(P-0.1)\n        vto += vpto*(P-0.1)\n        vppo = 3.24e-10*R*Tr/0.1**3\n        vpo += vppo*(P-0.1)\n\n    h = go+T*so\n    u = h-P*vo\n    a = go-P*vo\n    cv = cpo+T*vto**2/vpo\n    xkappa = -vpo/vo\n    alfa = vto/vo\n    ks = -(T*vto**2/cpo+vpo)/vo\n    w = (-vo**2*1e9/(vpo*1e3+T*vto**2*1e6/cpo))**0.5\n\n    propiedades = {}\n    propiedades[\"g\"] = go\n    propiedades[\"T\"] = T\n    propiedades[\"P\"] = P\n    propiedades[\"v\"] = vo\n    propiedades[\"vt\"] = vto\n    propiedades[\"vp\"] = vpo\n    propiedades[\"vpt\"] = vpto\n    propiedades[\"vtt\"] = vtto\n    propiedades[\"rho\"] = 1/vo\n    propiedades[\"h\"] = h\n    propiedades[\"s\"] = so\n    propiedades[\"cp\"] = cpo\n    propiedades[\"cv\"] = cv\n    propiedades[\"u\"] = u\n    propiedades[\"a\"] = a\n    propiedades[\"xkappa\"] = xkappa\n    propiedades[\"alfav\"] = vto/vo\n    propiedades[\"ks\"] = ks\n    propiedades[\"w\"] = w\n\n    # Viscosity correlation, Eq 7\n    a = [None, 280.68, 511.45, 61.131, 0.45903]\n    b = [None, -1.9, -7.7, -19.6, -40]\n    T_ = T/300\n    mu = sum([a[i]*T_**b[i] for i in range(1, 5)])/1e6\n    propiedades[\"mu\"] = mu\n\n    # Thermal conductivity correlation, Eq 8\n    c = [None, 1.6630, -1.7781, 1.1567, -0.432115]\n    d = [None, -1.15, -3.4, -6.0, -7.6]\n    k = sum([c[i]*T_**d[i] for i in range(1, 5)])\n    propiedades[\"k\"] = k\n\n    # Dielectric constant correlation, Eq 9\n    e = [None, -43.7527, 299.504, -399.364, 221.327]\n    f = [None, -0.05, -1.47, -2.11, -2.31]\n    epsilon = sum([e[i]*T_**f[i] for i in range(1, 5)])\n    propiedades[\"epsilon\"] = epsilon\n\n    return propiedades", "response": "Supplementary release on properties of liquid water at 0. 1 MPa."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict with calculated properties of the supercooled water.", "response": "def _Supercooled(T, P):\n    \"\"\"Guideline on thermodynamic properties of supercooled water\n\n    Parameters\n    ----------\n    T : float\n        Temperature, [K]\n    P : float\n        Pressure, [MPa]\n\n    Returns\n    -------\n    prop : dict\n        Dict with calculated properties of water. The available properties are:\n\n            * L: Ordering field, [-]\n            * x: Mole fraction of low-density structure, [-]\n            * rho: Density, [kg/m\u00b3]\n            * s: Specific entropy, [kJ/kgK]\n            * h: Specific enthalpy, [kJ/kg]\n            * u: Specific internal energy, [kJ/kg]\n            * a: Specific Helmholtz energy, [kJ/kg]\n            * g: Specific Gibbs energy, [kJ/kg]\n            * alfap: Thermal expansion coefficient, [1/K]\n            * xkappa : Isothermal compressibility, [1/MPa]\n            * cp: Specific isobaric heat capacity, [kJ/kgK]\n            * cv: Specific isochoric heat capacity, [kJ/kgK]\n            * w: Speed of sound, [m/s\u00b2]\n\n    Notes\n    ------\n    Raise :class:`NotImplementedError` if input isn't in limit:\n\n        * Tm \u2264 T \u2264 300\n        * 0 < P \u2264 1000\n\n    The minimum temperature in range of validity is the melting temperature, it\n    depend of pressure\n\n    Examples\n    --------\n    >>> liq = _Supercooled(235.15, 0.101325)\n    >>> liq[\"rho\"], liq[\"cp\"], liq[\"w\"]\n    968.09999 5.997563 1134.5855\n\n    References\n    ----------\n    IAPWS, Guideline on Thermodynamic Properties of Supercooled Water,\n    http://iapws.org/relguide/Supercooled.html\n    \"\"\"\n\n    # Check input in range of validity\n    if P < 198.9:\n        Tita = T/235.15\n        Ph = 0.1+228.27*(1-Tita**6.243)+15.724*(1-Tita**79.81)\n        if P < Ph or T > 300:\n            raise NotImplementedError(\"Incoming out of bound\")\n    else:\n        Th = 172.82+0.03718*P+3.403e-5*P**2-1.573e-8*P**3\n        if T < Th or T > 300 or P > 1000:\n            raise NotImplementedError(\"Incoming out of bound\")\n\n    # Parameters, Table 1\n    Tll = 228.2\n    rho0 = 1081.6482\n    R = 0.461523087\n    pi0 = 300e3/rho0/R/Tll\n    omega0 = 0.5212269\n    L0 = 0.76317954\n    k0 = 0.072158686\n    k1 = -0.31569232\n    k2 = 5.2992608\n\n    # Reducing parameters, Eq 2\n    tau = T/Tll-1\n    p = P*1000/rho0/R/Tll\n    tau_ = tau+1\n    p_ = p+pi0\n\n    # Eq 3\n    ci = [-8.1570681381655, 1.2875032, 7.0901673598012, -3.2779161e-2,\n          7.3703949e-1, -2.1628622e-1, -5.1782479, 4.2293517e-4, 2.3592109e-2,\n          4.3773754, -2.9967770e-3, -9.6558018e-1, 3.7595286, 1.2632441,\n          2.8542697e-1, -8.5994947e-1, -3.2916153e-1, 9.0019616e-2,\n          8.1149726e-2, -3.2788213]\n    ai = [0, 0, 1, -0.2555, 1.5762, 1.6400, 3.6385, -0.3828, 1.6219, 4.3287,\n          3.4763, 5.1556, -0.3593, 5.0361, 2.9786, 6.2373, 4.0460, 5.3558,\n          9.0157, 1.2194]\n    bi = [0, 1, 0, 2.1051, 1.1422, 0.9510, 0, 3.6402, 2.0760, -0.0016, 2.2769,\n          0.0008, 0.3706, -0.3975, 2.9730, -0.3180, 2.9805, 2.9265, 0.4456,\n          0.1298]\n    di = [0, 0, 0, -0.0016, 0.6894, 0.0130, 0.0002, 0.0435, 0.0500, 0.0004,\n          0.0528, 0.0147, 0.8584, 0.9924, 1.0041, 1.0961, 1.0228, 1.0303,\n          1.6180, 0.5213]\n    phir = phirt = phirp = phirtt = phirtp = phirpp = 0\n    for c, a, b, d in zip(ci, ai, bi, di):\n        phir += c*tau_**a*p_**b*exp(-d*p_)\n        phirt += c*a*tau_**(a-1)*p_**b*exp(-d*p_)\n        phirp += c*tau_**a*p_**(b-1)*(b-d*p_)*exp(-d*p_)\n        phirtt += c*a*(a-1)*tau_**(a-2)*p_**b*exp(-d*p_)\n        phirtp += c*a*tau_**(a-1)*p_**(b-1)*(b-d*p_)*exp(-d*p_)\n        phirpp += c*tau_**a*p_**(b-2)*((d*p_-b)**2-b)*exp(-d*p_)\n\n    # Eq 5\n    K1 = ((1+k0*k2+k1*(p-k2*tau))**2-4*k0*k1*k2*(p-k2*tau))**0.5\n    K2 = (1+k2**2)**0.5\n\n    # Eq 6\n    omega = 2+omega0*p\n\n    # Eq 4\n    L = L0*K2/2/k1/k2*(1+k0*k2+k1*(p+k2*tau)-K1)\n\n    # Define interval of solution, Table 4\n    if omega < 10/9*(log(19)-L):\n        xmin = 0.049\n        xmax = 0.5\n    elif 10/9*(log(19)-L) <= omega < 50/49*(log(99)-L):\n        xmin = 0.0099\n        xmax = 0.051\n    else:\n        xmin = 0.99*exp(-50/49*L-omega)\n        xmax = min(1.1*exp(-L-omega), 0.0101)\n\n    def f(x):\n        return abs(L+log(x/(1-x))+omega*(1-2*x))\n\n    x = minimize(f, ((xmin+xmax)/2,), bounds=((xmin, xmax),))[\"x\"][0]\n\n    # Eq 12\n    fi = 2*x-1\n    Xi = 1/(2/(1-fi**2)-omega)\n\n    # Derivatives, Table 3\n    Lt = L0*K2/2*(1+(1-k0*k2+k1*(p-k2*tau))/K1)\n    Lp = L0*K2*(K1+k0*k2-k1*p+k1*k2*tau-1)/2/k2/K1\n    Ltt = -2*L0*K2*k0*k1*k2**2/K1**3\n    Ltp = 2*L0*K2*k0*k1*k2/K1**3\n    Lpp = -2*L0*K2*k0*k1/K1**3\n\n    prop = {}\n    prop[\"L\"] = L\n    prop[\"x\"] = x\n\n    # Eq 13\n    prop[\"rho\"] = rho0/((tau+1)/2*(omega0/2*(1-fi**2)+Lp*(fi+1))+phirp)\n\n    # Eq 1\n    prop[\"g\"] = phir+(tau+1)*(x*L+x*log(x)+(1-x)*log(1-x)+omega*x*(1-x))\n\n    # Eq 14\n    prop[\"s\"] = -R*((tau+1)/2*Lt*(fi+1) +\n                    (x*L+x*log(x)+(1-x)*log(1-x)+omega*x*(1-x))+phirt)\n\n    # Basic derived state properties\n    prop[\"h\"] = prop[\"g\"]+T*prop[\"s\"]\n    prop[\"u\"] = prop[\"h\"]+P/prop[\"rho\"]\n    prop[\"a\"] = prop[\"u\"]-T*prop[\"s\"]\n\n    # Eq 15\n    prop[\"xkappa\"] = prop[\"rho\"]/rho0**2/R*1000/Tll*(\n        (tau+1)/2*(Xi*(Lp-omega0*fi)**2-(fi+1)*Lpp)-phirpp)\n    prop[\"alfap\"] = prop[\"rho\"]/rho0/Tll*(\n        Ltp/2*(tau+1)*(fi+1) + (omega0*(1-fi**2)/2+Lp*(fi+1))/2 -\n        (tau+1)*Lt/2*Xi*(Lp-omega0*fi) + phirtp)\n    prop[\"cp\"] = -R*(tau+1)*(Lt*(fi+1)+(tau+1)/2*(Ltt*(fi+1)-Lt**2*Xi)+phirtt)\n\n    # Eq 16\n    prop[\"cv\"] = prop[\"cp\"]-T*prop[\"alfap\"]**2/prop[\"rho\"]/prop[\"xkappa\"]*1e3\n\n    # Eq 17\n    prop[\"w\"] = (prop[\"rho\"]*prop[\"xkappa\"]*1e-6*prop[\"cv\"]/prop[\"cp\"])**-0.5\n    return prop"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _Melting_Pressure(T, ice=\"Ih\"):\n    if ice == \"Ih\" and 251.165 <= T <= 273.16:\n        # Ice Ih\n        Tref = Tt\n        Pref = Pt\n        Tita = T/Tref\n        a = [0.119539337e7, 0.808183159e5, 0.33382686e4]\n        expo = [3., 0.2575e2, 0.10375e3]\n        suma = 1\n        for ai, expi in zip(a, expo):\n            suma += ai*(1-Tita**expi)\n        P = suma*Pref\n    elif ice == \"III\" and 251.165 < T <= 256.164:\n        # Ice III\n        Tref = 251.165\n        Pref = 208.566\n        Tita = T/Tref\n        P = Pref*(1-0.299948*(1-Tita**60.))\n    elif (ice == \"V\" and 256.164 < T <= 273.15) or 273.15 < T <= 273.31:\n        # Ice V\n        Tref = 256.164\n        Pref = 350.100\n        Tita = T/Tref\n        P = Pref*(1-1.18721*(1-Tita**8.))\n    elif 273.31 < T <= 355:\n        # Ice VI\n        Tref = 273.31\n        Pref = 632.400\n        Tita = T/Tref\n        P = Pref*(1-1.07476*(1-Tita**4.6))\n    elif 355. < T <= 715:\n        # Ice VII\n        Tref = 355\n        Pref = 2216.000\n        Tita = T/Tref\n        P = Pref*exp(1.73683*(1-1./Tita)-0.544606e-1*(1-Tita**5) +\n                     0.806106e-7*(1-Tita**22))\n    else:\n        raise NotImplementedError(\"Incoming out of bound\")\n    return P", "response": "Melting Pressure correlation for a given temperature and type of ice."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _Viscosity(rho, T, fase=None, drho=None):\n    Tr = T/Tc\n    Dr = rho/rhoc\n\n    # Eq 11\n    H = [1.67752, 2.20462, 0.6366564, -0.241605]\n    mu0 = 100*Tr**0.5/sum([Hi/Tr**i for i, Hi in enumerate(H)])\n\n    # Eq 12\n    I = [0, 1, 2, 3, 0, 1, 2, 3, 5, 0, 1, 2, 3, 4, 0, 1, 0, 3, 4, 3, 5]\n    J = [0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 4, 4, 5, 6, 6]\n    Hij = [0.520094, 0.850895e-1, -0.108374e1, -0.289555, 0.222531, 0.999115,\n           0.188797e1, 0.126613e1, 0.120573, -0.281378, -0.906851, -0.772479,\n           -0.489837, -0.257040, 0.161913, 0.257399, -0.325372e-1, 0.698452e-1,\n           0.872102e-2, -0.435673e-2, -0.593264e-3]\n    mu1 = exp(Dr*sum([(1/Tr-1)**i*h*(Dr-1)**j for i, j, h in zip(I, J, Hij)]))\n\n    # Critical enhancement\n    if fase and drho:\n        qc = 1/1.9\n        qd = 1/1.1\n\n        # Eq 21\n        DeltaX = Pc*Dr**2*(fase.drhodP_T/rho-drho/rho*1.5/Tr)\n        if DeltaX < 0:\n            DeltaX = 0\n\n        # Eq 20\n        X = 0.13*(DeltaX/0.06)**(0.63/1.239)\n\n        if X <= 0.3817016416:\n            # Eq 15\n            Y = qc/5*X*(qd*X)**5*(1-qc*X+(qc*X)**2-765./504*(qd*X)**2)\n\n        else:\n            Fid = acos((1+qd**2*X**2)**-0.5)                            # Eq 17\n            w = abs((qc*X-1)/(qc*X+1))**0.5*tan(Fid/2)                  # Eq 19\n\n            # Eq 18\n            if qc*X > 1:\n                Lw = log((1+w)/(1-w))\n            else:\n                Lw = 2*atan(abs(w))\n\n            # Eq 16\n            Y = sin(3*Fid)/12-sin(2*Fid)/4/qc/X+(1-5/4*(qc*X)**2)/(\n                qc*X)**2*sin(Fid)-((1-3/2*(qc*X)**2)*Fid-abs((\n                    qc*X)**2-1)**1.5*Lw)/(qc*X)**3\n\n        # Eq 14\n        mu2 = exp(0.068*Y)\n    else:\n        mu2 = 1\n\n    # Eq 10\n    mu = mu0*mu1*mu2\n    return mu*1e-6", "response": "Equation for the Viscosity of Ordinary taxonomy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _Tension(T):\n    if 248.15 <= T <= Tc:\n        Tr = T/Tc\n        return 1e-3*(235.8*(1-Tr)**1.256*(1-0.625*(1-Tr)))\n    else:\n        raise NotImplementedError(\"Incoming out of bound\")", "response": "Equation for the surface tension of the liquid metastable state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Refractive(rho, T, l=0.5893):\n    # Check input parameters\n    if rho < 0 or rho > 1060 or T < 261.15 or T > 773.15 or l < 0.2 or l > 1.1:\n        raise NotImplementedError(\"Incoming out of bound\")\n\n    Lir = 5.432937\n    Luv = 0.229202\n    d = rho/1000.\n    Tr = T/273.15\n    L = l/0.589\n    a = [0.244257733, 0.974634476e-2, -0.373234996e-2, 0.268678472e-3,\n         0.158920570e-2, 0.245934259e-2, 0.900704920, -0.166626219e-1]\n    A = d*(a[0]+a[1]*d+a[2]*Tr+a[3]*L**2*Tr+a[4]/L**2+a[5]/(L**2-Luv**2)+a[6]/(\n        L**2-Lir**2)+a[7]*d**2)\n    return ((2*A+1)/(1-A))**0.5", "response": "Equation for the refractive index of the given resource class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _Conductivity(rho, T):\n    # FIXME: Dont work\n    rho_ = rho/1000\n    kw = 10**-_Kw(rho, T)\n\n    A = [1850., 1410., 2.16417e-6, 1.81609e-7, -1.75297e-9, 7.20708e-12]\n    B = [16., 11.6, 3.26e-4, -2.3e-6, 1.1e-8]\n    t = T-273.15\n\n    Loo = A[0]-1/(1/A[1]+sum([A[i+2]*t**(i+1) for i in range(4)]))      # Eq 5\n    rho_h = B[0]-1/(1/B[1]+sum([B[i+2]*t**(i+1) for i in range(3)]))    # Eq 6\n\n    # Eq 4\n    L_o = (rho_h-rho_)*Loo/rho_h\n\n    # Eq 1\n    k = 100*1e-3*L_o*kw**0.5*rho_\n    return k", "response": "Equation for the electrolytic conductivity of liquid and dense base class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _D2O_Melting_Pressure(T, ice=\"Ih\"):\n    if ice == \"Ih\" and 254.415 <= T <= 276.969:\n        # Ice Ih, Eq 9\n        Tita = T/276.969\n        ai = [-0.30153e5, 0.692503e6]\n        ti = [5.5, 8.2]\n        suma = 1\n        for a, t in zip(ai, ti):\n            suma += a*(1-Tita**t)\n        P = suma*0.00066159\n    elif ice == \"III\" and 254.415 < T <= 258.661:\n        # Ice III, Eq 10\n        Tita = T/254.415\n        P = 222.41*(1-0.802871*(1-Tita**33))\n    elif ice == \"V\" and 258.661 < T <= 275.748:\n        # Ice V, Eq 11\n        Tita = T/258.661\n        P = 352.19*(1-1.280388*(1-Tita**7.6))\n    elif (ice == \"VI\" and 275.748 < T <= 276.969) or 276.969 < T <= 315:\n        # Ice VI\n        Tita = T/275.748\n        P = 634.53*(1-1.276026*(1-Tita**4))\n    else:\n        raise NotImplementedError(\"Incoming out of bound\")\n    return P", "response": "Melting Pressure correlation for heavy water."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _Henry(T, gas, liquid=\"H2O\"):\n    if liquid == \"D2O\":\n        gas += \"(D2O)\"\n\n    limit = {\n        \"He\": (273.21, 553.18),\n        \"Ne\": (273.20, 543.36),\n        \"Ar\": (273.19, 568.36),\n        \"Kr\": (273.19, 525.56),\n        \"Xe\": (273.22, 574.85),\n        \"H2\": (273.15, 636.09),\n        \"N2\": (278.12, 636.46),\n        \"O2\": (274.15, 616.52),\n        \"CO\": (278.15, 588.67),\n        \"CO2\": (274.19, 642.66),\n        \"H2S\": (273.15, 533.09),\n        \"CH4\": (275.46, 633.11),\n        \"C2H6\": (275.44, 473.46),\n        \"SF6\": (283.14, 505.55),\n        \"He(D2O)\": (288.15, 553.18),\n        \"Ne(D2O)\": (288.18, 549.96),\n        \"Ar(D2O)\": (288.30, 583.76),\n        \"Kr(D2O)\": (288.19, 523.06),\n        \"Xe(D2O)\": (295.39, 574.85),\n        \"D2(D2O)\": (288.17, 581.00),\n        \"CH4(D2O)\": (288.16, 517.46)}\n\n    # Check input parameters\n    if liquid != \"D2O\" and liquid != \"H2O\":\n        raise NotImplementedError(\"Solvent liquid unsupported\")\n    if gas not in limit:\n        raise NotImplementedError(\"Gas unsupported\")\n\n    Tmin, Tmax = limit[gas]\n    if T < Tmin or T > Tmax:\n        warnings.warn(\"Temperature out of data of correlation\")\n\n    if liquid == \"D2O\":\n        Tc = 643.847\n        Pc = 21.671\n    else:\n        Tc = 647.096\n        Pc = 22.064\n\n    Tr = T/Tc\n    tau = 1-Tr\n\n    # Eq 4\n    if liquid == \"H2O\":\n        ai = [-7.85951783, 1.84408259, -11.7866497, 22.6807411, -15.9618719,\n              1.80122502]\n        bi = [1, 1.5, 3, 3.5, 4, 7.5]\n    else:\n        ai = [-7.896657, 24.73308, -27.81128, 9.355913, -9.220083]\n        bi = [1, 1.89, 2, 3, 3.6]\n    ps = Pc*exp(1/Tr*sum([a*tau**b for a, b in zip(ai, bi)]))\n\n    # Select values from Table 2\n    par = {\n        \"He\": (-3.52839, 7.12983, 4.47770),\n        \"Ne\": (-3.18301, 5.31448, 5.43774),\n        \"Ar\": (-8.40954, 4.29587, 10.52779),\n        \"Kr\": (-8.97358, 3.61508, 11.29963),\n        \"Xe\": (-14.21635, 4.00041, 15.60999),\n        \"H2\": (-4.73284, 6.08954, 6.06066),\n        \"N2\": (-9.67578, 4.72162, 11.70585),\n        \"O2\": (-9.44833, 4.43822, 11.42005),\n        \"CO\": (-10.52862, 5.13259, 12.01421),\n        \"CO2\": (-8.55445, 4.01195, 9.52345),\n        \"H2S\": (-4.51499, 5.23538, 4.42126),\n        \"CH4\": (-10.44708, 4.66491, 12.12986),\n        \"C2H6\": (-19.67563, 4.51222, 20.62567),\n        \"SF6\": (-16.56118, 2.15289, 20.35440),\n        \"He(D2O)\": (-0.72643, 7.02134, 2.04433),\n        \"Ne(D2O)\": (-0.91999, 5.65327, 3.17247),\n        \"Ar(D2O)\": (-7.17725, 4.48177, 9.31509),\n        \"Kr(D2O)\": (-8.47059, 3.91580, 10.69433),\n        \"Xe(D2O)\": (-14.46485, 4.42330, 15.60919),\n        \"D2(D2O)\": (-5.33843, 6.15723, 6.53046),\n        \"CH4(D2O)\": (-10.01915, 4.73368, 11.75711)}\n    A, B, C = par[gas]\n\n    # Eq 3\n    kh = ps*exp(A/Tr+B*tau**0.355/Tr+C*Tr**-0.41*exp(tau))\n    return kh", "response": "Equation for the calculation of Henry s constant"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getphase(Tc, Pc, T, P, x, region):\n    # Avoid round problem\n    P = round(P, 8)\n    T = round(T, 8)\n    if P > Pc and T > Tc:\n        phase = \"Supercritical fluid\"\n    elif T > Tc:\n        phase = \"Gas\"\n    elif P > Pc:\n        phase = \"Compressible liquid\"\n    elif P == Pc and T == Tc:\n        phase = \"Critical point\"\n    elif region == 4 and x == 1:\n        phase = \"Saturated vapor\"\n    elif region == 4 and x == 0:\n        phase = \"Saturated liquid\"\n    elif region == 4:\n        phase = \"Two phases\"\n    elif x == 1:\n        phase = \"Vapour\"\n    elif x == 0:\n        phase = \"Liquid\"\n    return phase", "response": "Returns the name of the current phase of the current language"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deriv_H(state, z, x, y, fase):\n    # We use the relation between rho and v and his partial derivative\n    # \u2202v/\u2202b|c = -1/\u03c1\u00b2 \u2202\u03c1/\u2202b|c\n    # \u2202a/\u2202v|c = -\u03c1\u00b2 \u2202a/\u2202\u03c1|c\n    mul = 1\n    if z == \"rho\":\n        mul = -fase.rho**2\n        z = \"v\"\n    if x == \"rho\":\n        mul = -1/fase.rho**2\n        x = \"v\"\n    if y == \"rho\":\n        y = \"v\"\n\n    dT = {\"P\": state.P*1000*fase.alfap,\n          \"T\": 1,\n          \"v\": 0,\n          \"u\": fase.cv,\n          \"h\": fase.cv+state.P*1000*fase.v*fase.alfap,\n          \"s\": fase.cv/state.T,\n          \"g\": state.P*1000*fase.v*fase.alfap-fase.s,\n          \"a\": -fase.s}\n    dv = {\"P\": -state.P*1000*fase.betap,\n          \"T\": 0,\n          \"v\": 1,\n          \"u\": state.P*1000*(state.T*fase.alfap-1),\n          \"h\": state.P*1000*(state.T*fase.alfap-fase.v*fase.betap),\n          \"s\": state.P*1000*fase.alfap,\n          \"g\": -state.P*1000*fase.v*fase.betap,\n          \"a\": -state.P*1000}\n    deriv = (dv[z]*dT[y]-dT[z]*dv[y])/(dv[x]*dT[y]-dT[x]*dv[y])\n    return mul*deriv", "response": "r Calculates generic partial derivative of a state from a fundamental Helmholtz free energy equation of state z x y fase."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deriv_G(state, z, x, y, fase):\n    mul = 1\n    if z == \"rho\":\n        mul = -fase.rho**2\n        z = \"v\"\n    if x == \"rho\":\n        mul = -1/fase.rho**2\n        x = \"v\"\n\n    dT = {\"P\": 0,\n          \"T\": 1,\n          \"v\": fase.v*fase.alfav,\n          \"u\": fase.cp-state.P*1000*fase.v*fase.alfav,\n          \"h\": fase.cp,\n          \"s\": fase.cp/state.T,\n          \"g\": -fase.s,\n          \"a\": -state.P*1000*fase.v*fase.alfav-fase.s}\n    dP = {\"P\": 1,\n          \"T\": 0,\n          \"v\": -fase.v*fase.xkappa,\n          \"u\": fase.v*(state.P*1000*fase.xkappa-state.T*fase.alfav),\n          \"h\": fase.v*(1-state.T*fase.alfav),\n          \"s\": -fase.v*fase.alfav,\n          \"g\": fase.v,\n          \"a\": state.P*1000*fase.v*fase.xkappa}\n    deriv = (dP[z]*dT[y]-dT[z]*dP[y])/(dP[x]*dT[y]-dT[x]*dP[y])\n    return mul*deriv", "response": "r Calculates generic partial derivative of a state object from a fundamental state object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _h13_s(s):\n    # Check input parameters\n    if s < 3.397782955 or s > 3.77828134:\n        raise NotImplementedError(\"Incoming out of bound\")\n\n    sigma = s/3.8\n    I = [0, 1, 1, 3, 5, 6]\n    J = [0, -2, 2, -12, -4, -3]\n    n = [0.913965547600543, -0.430944856041991e-4, 0.603235694765419e2,\n         0.117518273082168e-17, 0.220000904781292, -0.690815545851641e2]\n\n    suma = 0\n    for i, j, ni in zip(I, J, n):\n        suma += ni * (sigma-0.884)**i * (sigma-0.864)**j\n    return 1700 * suma", "response": "Define the boundary between Region 1 and 3 and h = f ( s )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _PSat_T(T):\n    # Check input parameters\n    if T < 273.15 or T > Tc:\n        raise NotImplementedError(\"Incoming out of bound\")\n\n    n = [0, 0.11670521452767E+04, -0.72421316703206E+06, -0.17073846940092E+02,\n         0.12020824702470E+05, -0.32325550322333E+07, 0.14915108613530E+02,\n         -0.48232657361591E+04, 0.40511340542057E+06, -0.23855557567849E+00,\n         0.65017534844798E+03]\n    tita = T+n[9]/(T-n[10])\n    A = tita**2+n[1]*tita+n[2]\n    B = n[3]*tita**2+n[4]*tita+n[5]\n    C = n[6]*tita**2+n[7]*tita+n[8]\n    return (2*C/(-B+(B**2-4*A*C)**0.5))**4", "response": "Define the saturated line P = f ( T )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndefine the saturated line T = f P", "response": "def _TSat_P(P):\n    \"\"\"Define the saturated line, T=f(P)\n\n    Parameters\n    ----------\n    P : float\n        Pressure, [MPa]\n\n    Returns\n    -------\n    T : float\n        Temperature, [K]\n\n    Notes\n    ------\n    Raise :class:`NotImplementedError` if input isn't in limit:\n\n        * 0.00061121 \u2264 P \u2264 22.064\n\n    References\n    ----------\n    IAPWS, Revised Release on the IAPWS Industrial Formulation 1997 for the\n    Thermodynamic Properties of Water and Steam August 2007,\n    http://www.iapws.org/relguide/IF97-Rev.html, Eq 31\n\n    Examples\n    --------\n    >>> _TSat_P(10)\n    584.149488\n    \"\"\"\n    # Check input parameters\n    if P < 611.212677/1e6 or P > 22.064:\n        raise NotImplementedError(\"Incoming out of bound\")\n\n    n = [0, 0.11670521452767E+04, -0.72421316703206E+06, -0.17073846940092E+02,\n         0.12020824702470E+05, -0.32325550322333E+07, 0.14915108613530E+02,\n         -0.48232657361591E+04, 0.40511340542057E+06, -0.23855557567849E+00,\n         0.65017534844798E+03]\n    beta = P**0.25\n    E = beta**2+n[3]*beta+n[6]\n    F = n[1]*beta**2+n[4]*beta+n[7]\n    G = n[2]*beta**2+n[5]*beta+n[8]\n    D = 2*G/(-F-(F**2-4*E*G)**0.5)\n    return (n[10]+D-((n[10]+D)**2-4*(n[9]+n[10]*D))**0.5)/2"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _PSat_h(h):\n    # Check input parameters\n    hmin_Ps3 = _Region1(623.15, Ps_623)[\"h\"]\n    hmax_Ps3 = _Region2(623.15, Ps_623)[\"h\"]\n    if h < hmin_Ps3 or h > hmax_Ps3:\n        raise NotImplementedError(\"Incoming out of bound\")\n\n    nu = h/2600\n    I = [0, 1, 1, 1, 1, 5, 7, 8, 14, 20, 22, 24, 28, 36]\n    J = [0, 1, 3, 4, 36, 3, 0, 24, 16, 16, 3, 18, 8, 24]\n    n = [0.600073641753024, -0.936203654849857e1, 0.246590798594147e2,\n         -0.107014222858224e3, -0.915821315805768e14, -0.862332011700662e4,\n         -0.235837344740032e2, 0.252304969384128e18, -0.389718771997719e19,\n         -0.333775713645296e23, 0.356499469636328e11, -0.148547544720641e27,\n         0.330611514838798e19, 0.813641294467829e38]\n\n    suma = 0\n    for i, j, ni in zip(I, J, n):\n        suma += ni * (nu-1.02)**i * (nu-0.608)**j\n    return 22*suma", "response": "Define the saturated line P for region 3"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _PSat_s(s):\n    # Check input parameters\n    smin_Ps3 = _Region1(623.15, Ps_623)[\"s\"]\n    smax_Ps3 = _Region2(623.15, Ps_623)[\"s\"]\n    if s < smin_Ps3 or s > smax_Ps3:\n        raise NotImplementedError(\"Incoming out of bound\")\n\n    sigma = s/5.2\n    I = [0, 1, 1, 4, 12, 12, 16, 24, 28, 32]\n    J = [0, 1, 32, 7, 4, 14, 36, 10, 0, 18]\n    n = [0.639767553612785, -0.129727445396014e2, -0.224595125848403e16,\n         0.177466741801846e7, 0.717079349571538e10, -0.378829107169011e18,\n         -0.955586736431328e35, 0.187269814676188e24, 0.119254746466473e12,\n         0.110649277244882e37]\n\n    suma = 0\n    for i, j, ni in zip(I, J, n):\n        suma += ni * (sigma-1.03)**i * (sigma-0.699)**j\n    return 22*suma", "response": "Define the saturated line P = f ( s ) for region 3"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _h2ab_s(s):\n    # Check input parameters\n    if s < 5.85 or s > 9.155759395:\n        raise NotImplementedError(\"Incoming out of bound\")\n\n    sigma1 = s/5.21\n    sigma2 = s/9.2\n    I = [1, 1, 2, 2, 4, 4, 7, 8, 8, 10, 12, 12, 18, 20, 24, 28, 28, 28, 28, 28,\n         32, 32, 32, 32, 32, 36, 36, 36, 36, 36]\n    J = [8, 24, 4, 32, 1, 2, 7, 5, 12, 1, 0, 7, 10, 12, 32, 8, 12, 20, 22, 24,\n         2, 7, 12, 14, 24, 10, 12, 20, 22, 28]\n    n = [-0.524581170928788e3, -0.926947218142218e7, -0.237385107491666e3,\n         0.210770155812776e11, -0.239494562010986e2, 0.221802480294197e3,\n         -0.510472533393438e7, 0.124981396109147e7, 0.200008436996201e10,\n         -0.815158509791035e3, -0.157612685637523e3, -0.114200422332791e11,\n         0.662364680776872e16, -0.227622818296144e19, -0.171048081348406e32,\n         0.660788766938091e16, 0.166320055886021e23, -0.218003784381501e30,\n         -0.787276140295618e30, 0.151062329700346e32, 0.795732170300541e7,\n         0.131957647355347e16, -0.325097068299140e24, -0.418600611419248e26,\n         0.297478906557467e35, -0.953588761745473e20, 0.166957699620939e25,\n         -0.175407764869978e33, 0.347581490626396e35, -0.710971318427851e39]\n\n    suma = 0\n    for i, j, ni in zip(I, J, n):\n        suma += ni * (1/sigma1-0.513)**i * (sigma2-0.524)**j\n    return 2800*exp(suma)", "response": "Define the saturated line boundary between Region 4 and 2a - 2b"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _Region1(T, P):\n    if P < 0:\n        P = Pmin\n\n    I = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4,\n         4, 4, 5, 8, 8, 21, 23, 29, 30, 31, 32]\n    J = [-2, -1, 0, 1, 2, 3, 4, 5, -9, -7, -1, 0, 1, 3, -3, 0, 1, 3, 17, -4, 0,\n         6, -5, -2, 10, -8, -11, -6, -29, -31, -38, -39, -40, -41]\n    n = [0.14632971213167, -0.84548187169114, -0.37563603672040e1,\n         0.33855169168385e1, -0.95791963387872, 0.15772038513228,\n         -0.16616417199501e-1, 0.81214629983568e-3, 0.28319080123804e-3,\n         -0.60706301565874e-3, -0.18990068218419e-1, -0.32529748770505e-1,\n         -0.21841717175414e-1, -0.52838357969930e-4, -0.47184321073267e-3,\n         -0.30001780793026e-3, 0.47661393906987e-4, -0.44141845330846e-5,\n         -0.72694996297594e-15, -0.31679644845054e-4, -0.28270797985312e-5,\n         -0.85205128120103e-9, -0.22425281908000e-5, -0.65171222895601e-6,\n         -0.14341729937924e-12, -0.40516996860117e-6, -0.12734301741641e-8,\n         -0.17424871230634e-9, -0.68762131295531e-18, 0.14478307828521e-19,\n         0.26335781662795e-22, -0.11947622640071e-22, 0.18228094581404e-23,\n         -0.93537087292458e-25]\n    Tr = 1386/T\n    Pr = P/16.53\n    g = gp = gpp = gt = gtt = gpt = 0\n    for i, j, ni in zip(I, J, n):\n        g += ni * (7.1-Pr)**i * (Tr-1.222)**j\n        gp -= ni*i * (7.1-Pr)**(i-1) * (Tr-1.222)**j\n        gpp += ni*i*(i-1) * (7.1-Pr)**(i-2) * (Tr-1.222)**j\n        gt += ni*j * (7.1-Pr)**i * (Tr-1.222)**(j-1)\n        gtt += ni*j*(j-1) * (7.1-Pr)**i * (Tr-1.222)**(j-2)\n        gpt -= ni*i*j * (7.1-Pr)**(i-1) * (Tr-1.222)**(j-1)\n\n    propiedades = {}\n    propiedades[\"T\"] = T\n    propiedades[\"P\"] = P\n    propiedades[\"v\"] = Pr*gp*R*T/P/1000\n    propiedades[\"h\"] = Tr*gt*R*T\n    propiedades[\"s\"] = R*(Tr*gt-g)\n    propiedades[\"cp\"] = -R*Tr**2*gtt\n    propiedades[\"cv\"] = R*(-Tr**2*gtt+(gp-Tr*gpt)**2/gpp)\n    propiedades[\"w\"] = sqrt(R*T*1000*gp**2/((gp-Tr*gpt)**2/(Tr**2*gtt)-gpp))\n    propiedades[\"alfav\"] = (1-Tr*gpt/gp)/T\n    propiedades[\"kt\"] = -Pr*gpp/gp/P\n    propiedades[\"region\"] = 1\n    propiedades[\"x\"] = 0\n    return propiedades", "response": "Basic equation for region 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Region2_cp0(Tr, Pr):\n    Jo = [0, 1, -5, -4, -3, -2, -1, 2, 3]\n    no = [-0.96927686500217E+01, 0.10086655968018E+02, -0.56087911283020E-02,\n          0.71452738081455E-01, -0.40710498223928E+00, 0.14240819171444E+01,\n          -0.43839511319450E+01, -0.28408632460772E+00, 0.21268463753307E-01]\n    go = log(Pr)\n    gop = Pr**-1\n    gopp = -Pr**-2\n    got = gott = gopt = 0\n    for j, ni in zip(Jo, no):\n        go += ni * Tr**j\n        got += ni*j * Tr**(j-1)\n        gott += ni*j*(j-1) * Tr**(j-2)\n    return go, gop, gopp, got, gott, gopt", "response": "Ideal properties for region 2"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndefine the boundary between Region 2a and 2b h = f ( s", "response": "def _hab_s(s):\n    \"\"\"Define the boundary between Region 2a and 2b, h=f(s)\n\n    Parameters\n    ----------\n    s : float\n        Specific entropy, [kJ/kgK]\n\n    Returns\n    -------\n    h : float\n        Specific enthalpy, [kJ/kg]\n\n    References\n    ----------\n    IAPWS, Revised Supplementary Release on Backward Equations for Pressure\n    as a Function of Enthalpy and Entropy p(h,s) for Regions 1 and 2 of the\n    IAPWS Industrial Formulation 1997 for the Thermodynamic Properties of\n    Water and Steam, http://www.iapws.org/relguide/Supp-PHS12-2014.pdf, Eq 2\n\n    Examples\n    --------\n    >>> _hab_s(7)\n    3376.437884\n    \"\"\"\n    smin = _Region2(_TSat_P(4), 4)[\"s\"]\n    smax = _Region2(1073.15, 4)[\"s\"]\n    if s < smin:\n        h = 0\n    elif s > smax:\n        h = 5000\n    else:\n        h = -0.349898083432139e4 + 0.257560716905876e4*s - \\\n            0.421073558227969e3*s**2+0.276349063799944e2*s**3\n    return h"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _Backward2_T_Ph(P, h):\n    if P <= 4:\n        T = _Backward2a_T_Ph(P, h)\n    elif 4 < P <= 6.546699678:\n        T = _Backward2b_T_Ph(P, h)\n    else:\n        hf = _hbc_P(P)\n        if h >= hf:\n            T = _Backward2b_T_Ph(P, h)\n        else:\n            T = _Backward2c_T_Ph(P, h)\n\n    if P <= 22.064:\n        Tsat = _TSat_P(P)\n        T = max(Tsat, T)\n    return T", "response": "Backward equation for region 2 T = f P h"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Backward2_T_Ps(P, s):\n    if P <= 4:\n        T = _Backward2a_T_Ps(P, s)\n    elif s >= 5.85:\n        T = _Backward2b_T_Ps(P, s)\n    else:\n        T = _Backward2c_T_Ps(P, s)\n\n    if P <= 22.064:\n        Tsat = _TSat_P(P)\n        T = max(Tsat, T)\n    return T", "response": "Backward equation for region 2 T = f P s"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndefine the boundary between Region 3a - 3b T = f ( P )", "response": "def _tab_P(P):\n    \"\"\"Define the boundary between Region 3a-3b, T=f(P)\n\n    Parameters\n    ----------\n    P : float\n        Pressure, [MPa]\n\n    Returns\n    -------\n    T : float\n        Temperature, [K]\n\n    References\n    ----------\n    IAPWS, Revised Supplementary Release on Backward Equations for Specific\n    Volume as a Function of Pressure and Temperature v(p,T) for Region 3 of the\n    IAPWS Industrial Formulation 1997 for the Thermodynamic Properties of Water\n    and Steam, http://www.iapws.org/relguide/Supp-VPT3-2016.pdf, Eq. 2\n\n    Examples\n    --------\n    >>> _tab_P(40)\n    693.0341408\n    \"\"\"\n    I = [0, 1, 2, -1, -2]\n    n = [0.154793642129415e4, -0.187661219490113e3, 0.213144632222113e2,\n         -0.191887498864292e4, 0.918419702359447e3]\n\n    Pr = P/1\n    T = 0\n    for i, ni in zip(I, n):\n        T += ni * log(Pr)**i\n    return T"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _txx_P(P, xy):\n    ng = {\n        \"cd\": [0.585276966696349e3, 0.278233532206915e1, -0.127283549295878e-1,\n               0.159090746562729e-3],\n        \"gh\": [-0.249284240900418e5, 0.428143584791546e4, -0.269029173140130e3,\n               0.751608051114157e1, -0.787105249910383e-1],\n        \"ij\": [0.584814781649163e3, -0.616179320924617, 0.260763050899562,\n               -0.587071076864459e-2, 0.515308185433082e-4],\n        \"jk\": [0.617229772068439e3, -0.770600270141675e1, 0.697072596851896,\n               -0.157391839848015e-1, 0.137897492684194e-3],\n        \"mn\": [0.535339483742384e3, 0.761978122720128e1, -0.158365725441648,\n               0.192871054508108e-2],\n        \"qu\": [0.565603648239126e3, 0.529062258221222e1, -0.102020639611016,\n               0.122240301070145e-2],\n        \"rx\": [0.584561202520006e3, -0.102961025163669e1, 0.243293362700452,\n               -0.294905044740799e-2],\n        \"uv\": [0.528199646263062e3, 0.890579602135307e1, -0.222814134903755,\n               0.286791682263697e-2]}\n\n    n = ng[xy]\n    Pr = P/1\n    T = 0\n    for i, ni in enumerate(n):\n        T += ni * Pr**i\n    return T", "response": "Define the boundary between 3x - 3y T = f ( P xy )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _Backward3a_v_Ph(P, h):\n    I = [-12, -12, -12, -12, -10, -10, -10, -8, -8, -6, -6, -6, -4, -4, -3, -2,\n         -2, -1, -1, -1, -1, 0, 0, 1, 1, 1, 2, 2, 3, 4, 5, 8]\n    J = [6, 8, 12, 18, 4, 7, 10, 5, 12, 3, 4, 22, 2, 3, 7, 3, 16, 0, 1, 2, 3,\n         0, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2]\n    n = [0.529944062966028e-2, -0.170099690234461, 0.111323814312927e2,\n         -0.217898123145125e4, -0.506061827980875e-3, 0.556495239685324,\n         -0.943672726094016e1, -0.297856807561527, 0.939353943717186e2,\n         0.192944939465981e-1, 0.421740664704763, -0.368914126282330e7,\n         -0.737566847600639e-2, -0.354753242424366, -0.199768169338727e1,\n         0.115456297059049e1, 0.568366875815960e4, 0.808169540124668e-2,\n         0.172416341519307, 0.104270175292927e1, -0.297691372792847,\n         0.560394465163593, 0.275234661176914, -0.148347894866012,\n         -0.651142513478515e-1, -0.292468715386302e1, 0.664876096952665e-1,\n         0.352335014263844e1, -0.146340792313332e-1, -0.224503486668184e1,\n         0.110533464706142e1, -0.408757344495612e-1]\n\n    Pr = P/100\n    nu = h/2100\n    suma = 0\n    for i, j, ni in zip(I, J, n):\n        suma += ni * (Pr+0.128)**i * (nu-0.727)**j\n    return 0.0028*suma", "response": "Backward equation for region 3a v = f ( P h )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Backward3_v_Ph(P, h):\n    hf = _h_3ab(P)\n    if h <= hf:\n        return _Backward3a_v_Ph(P, h)\n    else:\n        return _Backward3b_v_Ph(P, h)", "response": "Backward equation for region 3 v = f ( P h )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _Backward3_P_hs(h, s):\n    sc = 4.41202148223476\n    if s <= sc:\n        return _Backward3a_P_hs(h, s)\n    else:\n        return _Backward3b_P_hs(h, s)", "response": "Backward equation for region 3 P = f h s"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _Backward3x_v_PT(T, P, x):\n    par = {\n        \"a\": [0.0024, 100, 760, 0.085, 0.817, 1, 1, 1],\n        \"b\": [0.0041, 100, 860, 0.280, 0.779, 1, 1, 1],\n        \"c\": [0.0022, 40, 690, 0.259, 0.903, 1, 1, 1],\n        \"d\": [0.0029, 40, 690, 0.559, 0.939, 1, 1, 4],\n        \"e\": [0.0032, 40, 710, 0.587, 0.918, 1, 1, 1],\n        \"f\": [0.0064, 40, 730, 0.587, 0.891, 0.5, 1, 4],\n        \"g\": [0.0027, 25, 660, 0.872, 0.971, 1, 1, 4],\n        \"h\": [0.0032, 25, 660, 0.898, 0.983, 1, 1, 4],\n        \"i\": [0.0041, 25, 660, 0.910, 0.984, 0.5, 1, 4],\n        \"j\": [0.0054, 25, 670, 0.875, 0.964, 0.5, 1, 4],\n        \"k\": [0.0077, 25, 680, 0.802, 0.935, 1, 1, 1],\n        \"l\": [0.0026, 24, 650, 0.908, 0.989, 1, 1, 4],\n        \"m\": [0.0028, 23, 650, 1.000, 0.997, 1, 0.25, 1],\n        \"n\": [0.0031, 23, 650, 0.976, 0.997, None, None, None],\n        \"o\": [0.0034, 23, 650, 0.974, 0.996, 0.5, 1, 1],\n        \"p\": [0.0041, 23, 650, 0.972, 0.997, 0.5, 1, 1],\n        \"q\": [0.0022, 23, 650, 0.848, 0.983, 1, 1, 4],\n        \"r\": [0.0054, 23, 650, 0.874, 0.982, 1, 1, 1],\n        \"s\": [0.0022, 21, 640, 0.886, 0.990, 1, 1, 4],\n        \"t\": [0.0088, 20, 650, 0.803, 1.020, 1, 1, 1],\n        \"u\": [0.0026, 23, 650, 0.902, 0.988, 1, 1, 1],\n        \"v\": [0.0031, 23, 650, 0.960, 0.995, 1, 1, 1],\n        \"w\": [0.0039, 23, 650, 0.959, 0.995, 1, 1, 4],\n        \"x\": [0.0049, 23, 650, 0.910, 0.988, 1, 1, 1],\n        \"y\": [0.0031, 22, 650, 0.996, 0.994, 1, 1, 4],\n        \"z\": [0.0038, 22, 650, 0.993, 0.994, 1, 1, 4],\n        }\n\n    I = {\n        \"a\": [-12, -12, -12, -10, -10, -10, -8, -8, -8, -6, -5, -5, -5, -4, -3,\n              -3, -3, -3, -2, -2, -2, -1, -1, -1, 0, 0, 1, 1, 2, 2],\n        \"b\": [-12, -12, -10, -10, -8, -6, -6, -6, -5, -5, -5, -4, -4, -4, -3,\n              -3, -3, -3, -3, -2, -2, -2, -1, -1, 0, 0, 1, 1, 2, 3, 4, 4],\n        \"c\": [-12, -12, -12, -10, -10, -10, -8, -8, -8, -6, -5, -5, -5, -4, -4,\n              -3, -3, -2, -2, -2, -1, -1, -1, 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, 3,\n              8],\n        \"d\": [-12, -12, -12, -12, -12, -12, -10, -10, -10, -10, -10, -10, -10,\n              -8, -8, -8, -8, -6, -6, -5, -5, -5, -5, -4, -4, -4, -3, -3, -2,\n              -2, -1, -1, -1, 0, 0, 1, 1, 3],\n        \"e\": [-12, -12, -10, -10, -10, -10, -10, -8, -8, -8, -6, -5, -4, -4,\n              -3, -3, -3, -2, -2, -2, -2, -1, 0, 0, 1, 1, 1, 2, 2],\n        \"f\": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 6, 7, 7,\n              10, 12, 12, 12, 14, 14, 14, 14, 14, 16, 16, 18, 18, 20, 20, 20,\n              22, 24, 24, 28, 32],\n        \"g\": [-12, -12, -12, -12, -12, -12, -10, -10, -10, -8, -8, -8, -8, -6,\n              -6, -5, -5, -4, -3, -2, -2, -2, -2, -1, -1, -1, 0, 0, 0, 1, 1, 1,\n              3, 5, 6, 8, 10, 10],\n        \"h\": [-12, -12, -10, -10, -10, -10, -10, -10, -8, -8, -8, -8, -8, -6,\n              -6, -6, -5, -5, -5, -4, -4, -3, -3, -2, -1, -1, 0, 1, 1],\n        \"i\": [0, 0, 0, 1, 1, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 5, 7, 7, 8, 8, 10,\n              12, 12, 12, 14, 14, 14, 14, 18, 18, 18, 18, 18, 20, 20, 22, 24,\n              24, 32, 32, 36, 36],\n        \"j\": [0, 0, 0, 1, 1, 1, 2, 2, 3, 4, 4, 5, 5, 5, 6, 10, 12, 12, 14, 14,\n              14, 16, 18, 20, 20, 24, 24, 28, 28],\n        \"k\": [-2, -2, -1, -1, 0, -0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2,\n              2, 2, 2, 2, 5, 5, 5, 6, 6, 6, 6, 8, 10, 12],\n        \"l\": [-12, -12, -12, -12, -12, -10, -10, -8, -8, -8, -8, -8, -8, -8,\n              -6, -5, -5, -4, -4, -3, -3, -3, -3, -2, -2, -2, -1, -1, -1, 0, 0,\n              0, 0, 1, 1, 2, 4, 5, 5, 6, 10, 10, 14],\n        \"m\": [0, 3, 8, 20, 1, 3, 4, 5, 1, 6, 2, 4, 14, 2, 5, 3, 0, 1, 1, 1, 28,\n              2, 16, 0, 5, 0, 3, 4, 12, 16, 1, 8, 14, 0, 2, 3, 4, 8, 14, 24],\n        \"n\": [0, 3, 4, 6, 7, 10, 12, 14, 18, 0, 3, 5, 6, 8, 12, 0, 3, 7, 12,\n              2, 3, 4, 2, 4, 7, 4, 3, 5, 6, 0, 0, 3, 1, 0, 1, 0, 1, 0, 1],\n        \"o\": [0, 0, 0, 2, 3, 4, 4, 4, 4, 4, 5, 5, 6, 7, 8, 8, 8, 10, 10, 14,\n              14, 20, 20, 24],\n        \"p\": [0, 0, 0, 0, 1, 2, 3, 3, 4, 6, 7, 7, 8, 10, 12, 12, 12, 14, 14,\n              14, 16, 18, 20, 22, 24, 24, 36],\n        \"q\": [-12, -12, -10, -10, -10, -10, -8, -6, -5, -5, -4, -4, -3, -2,\n              -2, -2, -2, -1, -1, -1, 0, 1, 1, 1],\n        \"r\": [-8, -8, -3, -3, -3, -3, -3, 0, 0, 0, 0, 3, 3, 8, 8, 8, 8, 10,\n              10, 10, 10, 10, 10, 10, 10, 12, 14],\n        \"s\": [-12, -12, -10, -8, -6, -5, -5, -4, -4, -3, -3, -2, -1, -1, -1, 0,\n              0, 0, 0, 1, 1, 3, 3, 3, 4, 4, 4, 5, 14],\n        \"t\": [0, 0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 4, 4, 7, 7, 7, 7, 7, 10, 10, 10,\n              10, 10, 18, 20, 22, 22, 24, 28, 32, 32, 32, 36],\n        \"u\": [-12, -10, -10, -10, -8, -8, -8, -6, -6, -5, -5, -5, -3, -1, -1,\n              -1, -1, 0, 0, 1, 2, 2, 3, 5, 5, 5, 6, 6, 8, 8, 10, 12, 12, 12,\n              14, 14, 14, 14],\n        \"v\": [-10, -8, -6, -6, -6, -6, -6, -6, -5, -5, -5, -5, -5, -5, -4, -4,\n              -4, -4, -3, -3, -3, -2, -2, -1, -1, 0, 0, 0, 1, 1, 3, 4, 4, 4, 5,\n              8, 10, 12, 14],\n        \"w\": [-12, -12, -10, -10, -8, -8, -8, -6, -6, -6, -6, -5, -4, -4, -3,\n              -3, -2, -2, -1, -1, -1, 0, 0, 1, 2, 2, 3, 3, 5, 5, 5, 8, 8, 10,\n              10],\n        \"x\": [-8, -6, -5, -4, -4, -4, -3, -3, -1, 0, 0, 0, 1, 1, 2, 3, 3, 3, 4,\n              5, 5, 5, 6, 8, 8, 8, 8, 10, 12, 12, 12, 12, 14, 14, 14, 14],\n        \"y\": [0, 0, 0, 0, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 8, 8, 10, 12],\n        \"z\": [-8, -6, -5, -5, -4, -4, -4, -3, -3, -3, -2, -1, 0, 1, 2, 3, 3, 6,\n              6, 6, 6, 8, 8]}\n\n    J = {\n        \"a\": [5, 10, 12, 5, 10, 12, 5, 8, 10, 1, 1, 5, 10, 8, 0, 1, 3, 6, 0,\n              2, 3, 0, 1, 2, 0, 1, 0, 2, 0, 2],\n        \"b\": [10, 12, 8, 14, 8, 5, 6, 8, 5, 8, 10, 2, 4, 5, 0, 1, 2, 3, 5, 0,\n              2, 5, 0, 2, 0, 1, 0, 2, 0, 2, 0, 1],\n        \"c\": [6, 8, 10, 6, 8, 10, 5, 6, 7, 8, 1, 4, 7, 2, 8, 0, 3, 0, 4, 5, 0,\n              1, 2, 0, 1, 2, 0, 2, 0, 1, 3, 7, 0, 7, 1],\n        \"d\": [4, 6, 7, 10, 12, 16, 0, 2, 4, 6, 8, 10, 14, 3, 7, 8, 10, 6, 8, 1,\n              2, 5, 7, 0, 1, 7, 2, 4, 0, 1, 0, 1, 5, 0, 2, 0, 6, 0],\n        \"e\": [14, 16, 3, 6, 10, 14, 16, 7, 8, 10, 6, 6, 2, 4, 2, 6, 7, 0, 1,\n              3, 4, 0, 0, 1, 0, 4, 6, 0, 2],\n        \"f\": [-3, -2, -1, 0, 1, 2, -1, 1, 2, 3, 0, 1, -5, -2, 0, -3, -8, 1, -6,\n              -4, 1, -6, -10, -8, -4, -12, -10, -8, -6, -4, -10, -8, -12, -10,\n              -12, -10, -6, -12, -12, -4, -12, -12],\n        \"g\": [7, 12, 14, 18, 22, 24, 14, 20, 24, 7, 8, 10, 12, 8, 22, 7, 20,\n              22, 7, 3, 5, 14, 24, 2, 8, 18, 0, 1, 2, 0, 1, 3, 24, 22, 12, 3,\n              0, 6],\n        \"h\": [8, 12, 4, 6, 8, 10, 14, 16, 0, 1, 6, 7, 8, 4, 6, 8, 2, 3, 4, 2,\n              4, 1, 2, 0, 0, 2, 0, 0, 2],\n        \"i\": [0, 1, 10, -4, -2, -1, 0, 0, -5, 0, -3, -2, -1, -6, -1, 12, -4,\n              -3, -6, 10, -8, -12, -6, -4, -10, -8, -4, 5, -12, -10, -8, -6,\n              2, -12, -10, -12, -12, -8, -10, -5, -10, -8],\n        \"j\": [-1, 0, 1, -2, -1, 1, -1, 1, -2, -2, 2, -3, -2, 0, 3, -6, -8, -3,\n              -10, -8, -5, -10, -12, -12, -10, -12, -6, -12, -5],\n        \"k\": [10, 12, -5, 6, -12, -6, -2, -1, 0, 1, 2, 3, 14, -3, -2, 0, 1, 2,\n              -8, -6, -3, -2, 0, 4, -12, -6, -3, -12, -10, -8, -5, -12, -12,\n              -10],\n        \"l\": [14, 16, 18, 20, 22, 14, 24, 6, 10, 12, 14, 18, 24, 36, 8, 4, 5,\n              7, 16, 1, 3, 18, 20, 2, 3, 10, 0, 1, 3, 0, 1, 2, 12, 0, 16, 1, 0,\n              0, 1, 14, 4, 12, 10],\n        \"m\": [0, 0, 0, 2, 5, 5, 5, 5, 6, 6, 7, 8, 8, 10, 10, 12, 14, 14, 18,\n              20, 20, 22, 22, 24, 24, 28, 28, 28, 28, 28, 32, 32, 32, 36, 36,\n              36, 36, 36, 36, 36],\n        \"n\": [-12, -12, -12, -12, -12, -12, -12, -12, -12, -10, -10, -10, -10,\n              -10, -10, -8, -8, -8, -8, -6, -6, -6, -5, -5, -5, -4, -3, -3,\n              -3, -2, -1, -1, 0, 1, 1, 2, 4, 5, 6],\n        \"o\": [-12, -4, -1, -1, -10, -12, -8, -5, -4, -1, -4, -3, -8, -12, -10,\n              -8, -4, -12, -8, -12, -8, -12, -10, -12],\n        \"p\": [-1, 0, 1, 2, 1, -1, -3, 0, -2, -2, -5, -4, -2, -3, -12, -6, -5,\n              -10, -8, -3, -8, -8, -10, -10, -12, -8, -12],\n        \"q\": [10, 12, 6, 7, 8, 10, 8, 6, 2, 5, 3, 4, 3, 0, 1, 2, 4, 0, 1, 2,\n              0, 0, 1, 3],\n        \"r\": [6, 14, -3, 3, 4, 5, 8, -1, 0, 1, 5, -6, -2, -12, -10, -8, -5,\n              -12, -10, -8, -6, -5, -4, -3, -2, -12, -12],\n        \"s\": [20, 24, 22, 14, 36, 8, 16, 6, 32, 3, 8, 4, 1, 2, 3, 0, 1, 4, 28,\n              0, 32, 0, 1, 2, 3, 18, 24, 4, 24],\n        \"t\": [0, 1, 4, 12, 0, 10, 0, 6, 14, 3, 8, 0, 10, 3, 4, 7, 20, 36, 10,\n              12, 14, 16, 22, 18, 32, 22, 36, 24, 28, 22, 32, 36, 36],\n        \"u\": [14, 10, 12, 14, 10, 12, 14, 8, 12, 4, 8, 12, 2, -1, 1, 12, 14,\n              -3, 1, -2, 5, 10, -5, -4, 2, 3, -5, 2, -8, 8, -4, -12, -4, 4,\n              -12, -10, -6, 6],\n        \"v\": [-8, -12, -12, -3, 5, 6, 8, 10, 1, 2, 6, 8, 10, 14, -12, -10, -6,\n              10, -3, 10, 12, 2, 4, -2, 0, -2, 6, 10, -12, -10, 3, -6, 3, 10,\n              2, -12, -2, -3, 1],\n        \"w\": [8, 14, -1, 8, 6, 8, 14, -4, -3, 2, 8, -10, -1, 3, -10, 3, 1, 2,\n              -8, -4, 1, -12, 1, -1, -1, 2, -12, -5, -10, -8, -6, -12, -10,\n              -12, -8],\n        \"x\": [14, 10, 10, 1, 2, 14, -2, 12, 5, 0, 4, 10, -10, -1, 6, -12, 0,\n              8, 3, -6, -2, 1, 1, -6, -3, 1, 8, -8, -10, -8, -5, -4, -12, -10,\n              -8, -6],\n        \"y\": [-3, 1, 5, 8, 8, -4, -1, 4, 5, -8, 4, 8, -6, 6, -2, 1, -8, -2,\n              -5, -8],\n        \"z\": [3, 6, 6, 8, 5, 6, 8, -2, 5, 6, 2, -6, 3, 1, 6, -6, -2, -6, -5,\n              -4, -1, -8, -4]}\n\n    n = {\n        \"a\": [0.110879558823853e-2, 0.572616740810616e3, -0.767051948380852e5,\n              -0.253321069529674e-1, 0.628008049345689e4, 0.234105654131876e6,\n              0.216867826045856, -0.156237904341963e3, -0.269893956176613e5,\n              -0.180407100085505e-3, 0.116732227668261e-2, 0.266987040856040e2,\n              0.282776617243286e5, -0.242431520029523e4, 0.435217323022733e-3,\n              -0.122494831387441e-1, 0.179357604019989e1, 0.442729521058314e2,\n              -0.593223489018342e-2, 0.453186261685774, 0.135825703129140e1,\n              0.408748415856745e-1, 0.474686397863312, 0.118646814997915e1,\n              0.546987265727549, 0.195266770452643, -0.502268790869663e-1,\n              -0.369645308193377, 0.633828037528420e-2, 0.797441793901017e-1],\n        \"b\": [-0.827670470003621e-1, 0.416887126010565e2, 0.483651982197059e-1,\n              -0.291032084950276e5, -0.111422582236948e3, -.202300083904014e-1,\n              0.294002509338515e3, 0.140244997609658e3, -0.344384158811459e3,\n              0.361182452612149e3, -0.140699677420738e4, -0.202023902676481e-2,\n              0.171346792457471e3, -0.425597804058632e1, 0.691346085000334e-5,\n              0.151140509678925e-2, -0.416375290166236e-1, -.413754957011042e2,\n              -0.506673295721637e2, -0.572212965569023e-3, 0.608817368401785e1,\n              0.239600660256161e2, 0.122261479925384e-1, 0.216356057692938e1,\n              0.398198903368642, -0.116892827834085, -0.102845919373532,\n              -0.492676637589284, 0.655540456406790e-1, -0.240462535078530,\n              -0.269798180310075e-1, 0.128369435967012],\n        \"c\": [0.311967788763030e1, 0.276713458847564e5, 0.322583103403269e8,\n              -0.342416065095363e3, -0.899732529907377e6, -0.793892049821251e8,\n              0.953193003217388e2, 0.229784742345072e4, 0.175336675322499e6,\n              0.791214365222792e7, 0.319933345844209e-4, -0.659508863555767e2,\n              -0.833426563212851e6, 0.645734680583292e-1, -0.382031020570813e7,\n              0.406398848470079e-4, 0.310327498492008e2, -0.892996718483724e-3,\n              0.234604891591616e3, 0.377515668966951e4, 0.158646812591361e-1,\n              0.707906336241843, 0.126016225146570e2, 0.736143655772152,\n              0.676544268999101, -0.178100588189137e2, -0.156531975531713,\n              0.117707430048158e2, 0.840143653860447e-1, -0.186442467471949,\n              -0.440170203949645e2, 0.123290423502494e7, -0.240650039730845e-1,\n              -0.107077716660869e7, 0.438319858566475e-1],\n        \"d\": [-0.452484847171645e-9, .315210389538801e-4, -.214991352047545e-2,\n              0.508058874808345e3, -0.127123036845932e8, 0.115371133120497e13,\n              -.197805728776273e-15, .241554806033972e-10,\n              -.156481703640525e-5, 0.277211346836625e-2, -0.203578994462286e2,\n              0.144369489909053e7, -0.411254217946539e11, 0.623449786243773e-5,\n              -.221774281146038e2, -0.689315087933158e5, -0.195419525060713e8,\n              0.316373510564015e4, 0.224040754426988e7, -0.436701347922356e-5,\n              -.404213852833996e-3, -0.348153203414663e3, -0.385294213555289e6,\n              0.135203700099403e-6, 0.134648383271089e-3, 0.125031835351736e6,\n              0.968123678455841e-1, 0.225660517512438e3, -0.190102435341872e-3,\n              -.299628410819229e-1, 0.500833915372121e-2, 0.387842482998411,\n              -0.138535367777182e4, 0.870745245971773, 0.171946252068742e1,\n              -.326650121426383e-1, 0.498044171727877e4, 0.551478022765087e-2],\n        \"e\": [0.715815808404721e9, -0.114328360753449e12, .376531002015720e-11,\n              -0.903983668691157e-4, 0.665695908836252e6, 0.535364174960127e10,\n              0.794977402335603e11, 0.922230563421437e2, -0.142586073991215e6,\n              -0.111796381424162e7, 0.896121629640760e4, -0.669989239070491e4,\n              0.451242538486834e-2, -0.339731325977713e2, -0.120523111552278e1,\n              0.475992667717124e5, -0.266627750390341e6, -0.153314954386524e-3,\n              0.305638404828265, 0.123654999499486e3, -0.104390794213011e4,\n              -0.157496516174308e-1, 0.685331118940253, 0.178373462873903e1,\n              -0.544674124878910, 0.204529931318843e4, -0.228342359328752e5,\n              0.413197481515899, -0.341931835910405e2],\n        \"f\": [-0.251756547792325e-7, .601307193668763e-5, -.100615977450049e-2,\n              0.999969140252192, 0.214107759236486e1, -0.165175571959086e2,\n              -0.141987303638727e-2, 0.269251915156554e1, 0.349741815858722e2,\n              -0.300208695771783e2, -0.131546288252539e1, -0.839091277286169e1,\n              0.181545608337015e-9, -0.591099206478909e-3, 0.152115067087106e1,\n              0.252956470663225e-4, 0.100726265203786e-14, -0.14977453386065e1,\n              -0.793940970562969e-9, -0.150290891264717e-3, .151205531275133e1,\n              0.470942606221652e-5, .195049710391712e-12, -.911627886266077e-8,\n              .604374640201265e-3, -.225132933900136e-15, .610916973582981e-11,\n              -.303063908043404e-6, -.137796070798409e-4, -.919296736666106e-3,\n              .639288223132545e-9, .753259479898699e-6, -0.400321478682929e-12,\n              .756140294351614e-8, -.912082054034891e-11, -.237612381140539e-7,\n              0.269586010591874e-4, -.732828135157839e-10, .241995578306660e-9,\n              -.405735532730322e-3, .189424143498011e-9, -.486632965074563e-9],\n        \"g\": [0.412209020652996e-4, -0.114987238280587e7, 0.948180885032080e10,\n              -0.195788865718971e18, 0.4962507048713e25, -0.105549884548496e29,\n              -0.758642165988278e12, -.922172769596101e23, .725379072059348e30,\n              -0.617718249205859e2, 0.107555033344858e5, -0.379545802336487e8,\n              0.228646846221831e12, -0.499741093010619e7, -.280214310054101e31,\n              0.104915406769586e7, 0.613754229168619e28, 0.802056715528378e32,\n              -0.298617819828065e8, -0.910782540134681e2, 0.135033227281565e6,\n              -0.712949383408211e19, -0.104578785289542e37, .304331584444093e2,\n              0.593250797959445e10, -0.364174062110798e28, 0.921791403532461,\n              -0.337693609657471, -0.724644143758508e2, -0.110480239272601,\n              0.536516031875059e1, -0.291441872156205e4, 0.616338176535305e40,\n              -0.120889175861180e39, 0.818396024524612e23, 0.940781944835829e9,\n              -0.367279669545448e5, -0.837513931798655e16],\n        \"h\": [0.561379678887577e-1, 0.774135421587083e10, 0.111482975877938e-8,\n              -0.143987128208183e-2, 0.193696558764920e4, -0.605971823585005e9,\n              0.171951568124337e14, -.185461154985145e17, 0.38785116807801e-16,\n              -.395464327846105e-13, -0.170875935679023e3, -0.21201062070122e4,\n              0.177683337348191e8, 0.110177443629575e2, -0.234396091693313e6,\n              -0.656174421999594e7, 0.156362212977396e-4, -0.212946257021400e1,\n              0.135249306374858e2, 0.177189164145813, 0.139499167345464e4,\n              -0.703670932036388e-2, -0.152011044389648, 0.981916922991113e-4,\n              0.147199658618076e-2, 0.202618487025578e2, 0.899345518944240,\n              -0.211346402240858, 0.249971752957491e2],\n        \"i\": [0.106905684359136e1, -0.148620857922333e1, 0.259862256980408e15,\n              -.446352055678749e-11, -.566620757170032e-6,\n              -.235302885736849e-2, -0.269226321968839, 0.922024992944392e1,\n              0.357633505503772e-11, -.173942565562222e2, 0.700681785556229e-5,\n              -.267050351075768e-3, -.231779669675624e1, -.753533046979752e-12,\n              .481337131452891e1, -0.223286270422356e22, -.118746004987383e-4,\n              .646412934136496e-2, -0.410588536330937e-9, .422739537057241e20,\n              .313698180473812e-12, 0.16439533434504e-23, -.339823323754373e-5,\n              -.135268639905021e-1, -.723252514211625e-14, .184386437538366e-8,\n              -.463959533752385e-1, -.99226310037675e14, .688169154439335e-16,\n              -.222620998452197e-10, -.540843018624083e-7, .345570606200257e-2,\n              .422275800304086e11, -.126974478770487e-14, .927237985153679e-9,\n              .612670812016489e-13, -.722693924063497e-11,\n              -.383669502636822e-3, .374684572410204e-3, -0.931976897511086e5,\n              -0.247690616026922e-1, .658110546759474e2],\n        \"j\": [-0.111371317395540e-3, 0.100342892423685e1, 0.530615581928979e1,\n              0.179058760078792e-5, -0.728541958464774e-3, -.187576133371704e2,\n              0.199060874071849e-2, 0.243574755377290e2, -0.177040785499444e-3,\n              -0.25968038522713e-2, -0.198704578406823e3, 0.738627790224287e-4,\n              -0.236264692844138e-2, -0.161023121314333e1, 0.622322971786473e4,\n              -.960754116701669e-8, -.510572269720488e-10, .767373781404211e-2,\n              .663855469485254e-14, -.717590735526745e-9, 0.146564542926508e-4,\n              .309029474277013e-11, -.464216300971708e-15,\n              -.390499637961161e-13, -.236716126781431e-9,\n              .454652854268717e-11, -.422271787482497e-2,\n              0.283911742354706e-10, 0.270929002720228e1],\n        \"k\": [-0.401215699576099e9, 0.484501478318406e11, .394721471363678e-14,\n              .372629967374147e5, -.369794374168666e-29, -.380436407012452e-14,\n              0.475361629970233e-6, -0.879148916140706e-3, 0.844317863844331,\n              0.122433162656600e2, -0.104529634830279e3, 0.589702771277429e3,\n              -.291026851164444e14, .170343072841850e-5, -0.277617606975748e-3,\n              -0.344709605486686e1, 0.221333862447095e2, -0.194646110037079e3,\n              .808354639772825e-15, -.18084520914547e-10, -.696664158132412e-5,\n              -0.181057560300994e-2, 0.255830298579027e1, 0.328913873658481e4,\n              -.173270241249904e-18, -.661876792558034e-6, -.39568892342125e-2,\n              .604203299819132e-17, -.400879935920517e-13, .160751107464958e-8,\n              .383719409025556e-4, -.649565446702457e-14, -.149095328506e-11,\n              0.541449377329581e-8],\n        \"l\": [0.260702058647537e10, -.188277213604704e15, 0.554923870289667e19,\n              -.758966946387758e23, .413865186848908e27, -.81503800073806e12,\n              -.381458260489955e33, -.123239564600519e-1, 0.226095631437174e8,\n              -.49501780950672e12, 0.529482996422863e16, -0.444359478746295e23,\n              .521635864527315e35, -0.487095672740742e55, -0.714430209937547e6,\n              0.127868634615495, -0.100752127917598e2, 0.777451437960990e7,\n              -.108105480796471e25, -.357578581169659e-5, -0.212857169423484e1,\n              0.270706111085238e30, -0.695953622348829e33, 0.110609027472280,\n              0.721559163361354e2, -0.306367307532219e15, 0.265839618885530e-4,\n              0.253392392889754e-1, -0.214443041836579e3, 0.937846601489667,\n              0.223184043101700e1, 0.338401222509191e2, 0.494237237179718e21,\n              -0.198068404154428, -0.141415349881140e31, -0.993862421613651e2,\n              0.125070534142731e3, -0.996473529004439e3, 0.473137909872765e5,\n              0.116662121219322e33, -0.315874976271533e16,\n              -0.445703369196945e33, 0.642794932373694e33],\n        \"m\": [0.811384363481847, -0.568199310990094e4, -0.178657198172556e11,\n              0.795537657613427e32, -0.814568209346872e5, -0.659774567602874e8,\n              -.152861148659302e11, -0.560165667510446e12, 0.458384828593949e6,\n              -0.385754000383848e14, 0.453735800004273e8, 0.939454935735563e12,\n              .266572856432938e28, -0.547578313899097e10, 0.200725701112386e15,\n              0.185007245563239e13, 0.185135446828337e9, -0.170451090076385e12,\n              0.157890366037614e15, -0.202530509748774e16, 0.36819392618357e60,\n              0.170215539458936e18, 0.639234909918741e42, -.821698160721956e15,\n              -.795260241872306e24, 0.23341586947851e18, -0.600079934586803e23,\n              0.594584382273384e25, 0.189461279349492e40, -.810093428842645e46,\n              0.188813911076809e22, 0.111052244098768e36, 0.291133958602503e46,\n              -.329421923951460e22, -.137570282536696e26, 0.181508996303902e28,\n              -.346865122768353e30, -.21196114877426e38, -0.128617899887675e49,\n              0.479817895699239e65],\n        \"n\": [.280967799943151e-38, .614869006573609e-30, .582238667048942e-27,\n              .390628369238462e-22, .821445758255119e-20, .402137961842776e-14,\n              .651718171878301e-12, -.211773355803058e-7, 0.264953354380072e-2,\n              -.135031446451331e-31, -.607246643970893e-23,\n              -.402352115234494e-18, -.744938506925544e-16,\n              .189917206526237e-12, .364975183508473e-5, .177274872361946e-25,\n              -.334952758812999e-18, -.421537726098389e-8,\n              -.391048167929649e-1, .541276911564176e-13, .705412100773699e-11,\n              .258585887897486e-8, -.493111362030162e-10, -.158649699894543e-5,\n              -0.525037427886100, 0.220019901729615e-2, -0.643064132636925e-2,\n              0.629154149015048e2, 0.135147318617061e3, 0.240560808321713e-6,\n              -.890763306701305e-3, -0.440209599407714e4, -0.302807107747776e3,\n              0.159158748314599e4, 0.232534272709876e6, -0.792681207132600e6,\n              -.869871364662769e11, .354542769185671e12, 0.400849240129329e15],\n        \"o\": [.128746023979718e-34, -.735234770382342e-11, .28907869214915e-2,\n              0.244482731907223, 0.141733492030985e-23, -0.354533853059476e-28,\n              -.594539202901431e-17, -.585188401782779e-8, .201377325411803e-5,\n              0.138647388209306e1, -0.173959365084772e-4, 0.137680878349369e-2,\n              .814897605805513e-14, .425596631351839e-25,\n              -.387449113787755e-17, .13981474793024e-12, -.171849638951521e-2,\n              0.641890529513296e-21, .118960578072018e-10,\n              -.155282762571611e-17, .233907907347507e-7,\n              -.174093247766213e-12, .377682649089149e-8,\n              -.516720236575302e-10],\n        \"p\": [-0.982825342010366e-4, 0.105145700850612e1, 0.116033094095084e3,\n              0.324664750281543e4, -0.123592348610137e4, -0.561403450013495e-1,\n              0.856677401640869e-7, 0.236313425393924e3, 0.972503292350109e-2,\n              -.103001994531927e1, -0.149653706199162e-8, -.215743778861592e-4,\n              -0.834452198291445e1, 0.586602660564988, 0.343480022104968e-25,\n              .816256095947021e-5, .294985697916798e-2, 0.711730466276584e-16,\n              0.400954763806941e-9, 0.107766027032853e2, -0.409449599138182e-6,\n              -.729121307758902e-5, 0.677107970938909e-8, 0.602745973022975e-7,\n              -.382323011855257e-10, .179946628317437e-2,\n              -.345042834640005e-3],\n        \"q\": [-0.820433843259950e5, 0.473271518461586e11, -.805950021005413e-1,\n              0.328600025435980e2, -0.35661702998249e4, -0.172985781433335e10,\n              0.351769232729192e8, -0.775489259985144e6, 0.710346691966018e-4,\n              0.993499883820274e5, -0.642094171904570, -0.612842816820083e4,\n              .232808472983776e3, -0.142808220416837e-4, -0.643596060678456e-2,\n              -0.428577227475614e1, 0.225689939161918e4, 0.100355651721510e-2,\n              0.333491455143516, 0.109697576888873e1, 0.961917379376452,\n              -0.838165632204598e-1, 0.247795908411492e1, -.319114969006533e4],\n        \"r\": [.144165955660863e-2, -.701438599628258e13, -.830946716459219e-16,\n              0.261975135368109, 0.393097214706245e3, -0.104334030654021e5,\n              0.490112654154211e9, -0.147104222772069e-3, 0.103602748043408e1,\n              0.305308890065089e1, -0.399745276971264e7, 0.569233719593750e-11,\n              -.464923504407778e-1, -.535400396512906e-17,\n              .399988795693162e-12, -.536479560201811e-6, .159536722411202e-1,\n              .270303248860217e-14, .244247453858506e-7, -0.983430636716454e-5,\n              0.663513144224454e-1, -0.993456957845006e1, 0.546491323528491e3,\n              -0.143365406393758e5, 0.150764974125511e6, -.337209709340105e-9,\n              0.377501980025469e-8],\n        \"s\": [-0.532466612140254e23, .100415480000824e32, -.191540001821367e30,\n              0.105618377808847e17, 0.202281884477061e59, 0.884585472596134e8,\n              0.166540181638363e23, -0.313563197669111e6, -.185662327545324e54,\n              -.624942093918942e-1, -0.50416072413259e10, 0.187514491833092e5,\n              0.121399979993217e-2, 0.188317043049455e1, -0.167073503962060e4,\n              0.965961650599775, 0.294885696802488e1, -0.653915627346115e5,\n              0.604012200163444e50, -0.198339358557937, -0.175984090163501e58,\n              0.356314881403987e1, -0.575991255144384e3, 0.456213415338071e5,\n              -.109174044987829e8, 0.437796099975134e34, -0.616552611135792e46,\n              0.193568768917797e10, 0.950898170425042e54],\n        \"t\": [0.155287249586268e1, 0.664235115009031e1, -0.289366236727210e4,\n              -0.385923202309848e13, -.291002915783761e1, -.829088246858083e12,\n              0.176814899675218e1, -0.534686695713469e9, 0.160464608687834e18,\n              0.196435366560186e6, 0.156637427541729e13, -0.178154560260006e1,\n              -0.229746237623692e16, 0.385659001648006e8, 0.110554446790543e10,\n              -.677073830687349e14, -.327910592086523e31, -.341552040860644e51,\n              -.527251339709047e21, .245375640937055e24, -0.168776617209269e27,\n              .358958955867578e29, -0.656475280339411e36, 0.355286045512301e39,\n              .569021454413270e58, -.700584546433113e48, -0.705772623326374e65,\n              0.166861176200148e53, -.300475129680486e61, -.668481295196808e51,\n              .428432338620678e69, -.444227367758304e72, -.281396013562745e77],\n        \"u\": [0.122088349258355e18, 0.104216468608488e10, -.882666931564652e16,\n              .259929510849499e20, 0.222612779142211e15, -0.878473585050085e18,\n              -0.314432577551552e22, -.216934916996285e13, .159079648196849e21,\n              -.339567617303423e3, 0.884387651337836e13, -0.843405926846418e21,\n              0.114178193518022e2, -0.122708229235641e-3, -0.106201671767107e3,\n              .903443213959313e25, -0.693996270370852e28, 0.648916718965575e-8,\n              0.718957567127851e4, 0.105581745346187e-2, -0.651903203602581e15,\n              -0.160116813274676e25, -0.510254294237837e-8, -0.152355388953402,\n              0.677143292290144e12, 0.276378438378930e15, 0.116862983141686e-1,\n              -.301426947980171e14, 0.169719813884840e-7, 0.104674840020929e27,\n              -0.10801690456014e5, -0.990623601934295e-12, 0.536116483602738e7,\n              .226145963747881e22, -0.488731565776210e-9, 0.151001548880670e-4,\n              -0.227700464643920e5, -0.781754507698846e28],\n        \"v\": [-.415652812061591e-54, .177441742924043e-60,\n              -.357078668203377e-54, 0.359252213604114e-25,\n              -0.259123736380269e2, 0.594619766193460e5, -0.624184007103158e11,\n              0.313080299915944e17, .105006446192036e-8, -0.192824336984852e-5,\n              0.654144373749937e6, 0.513117462865044e13, -.697595750347391e19,\n              -.103977184454767e29, .119563135540666e-47,\n              -.436677034051655e-41, .926990036530639e-29, .587793105620748e21,\n              .280375725094731e-17, -0.192359972440634e23, .742705723302738e27,\n              -0.517429682450605e2, 0.820612048645469e7, -0.188214882341448e-8,\n              .184587261114837e-1, -0.135830407782663e-5, -.723681885626348e17,\n              -.223449194054124e27, -.111526741826431e-34,\n              .276032601145151e-28, 0.134856491567853e15, 0.652440293345860e-9,\n              0.510655119774360e17, -.468138358908732e32, -.760667491183279e16,\n              -.417247986986821e-18, 0.312545677756104e14,\n              -.100375333864186e15, .247761392329058e27],\n        \"w\": [-.586219133817016e-7, -.894460355005526e11, .531168037519774e-30,\n              0.109892402329239, -0.575368389425212e-1, 0.228276853990249e5,\n              -.158548609655002e19, .329865748576503e-27,\n              -.634987981190669e-24, 0.615762068640611e-8, -.961109240985747e8,\n              -.406274286652625e-44, -0.471103725498077e-12, 0.725937724828145,\n              .187768525763682e-38, -.103308436323771e4, -0.662552816342168e-1,\n              0.579514041765710e3, .237416732616644e-26, .271700235739893e-14,\n              -0.9078862134836e2, -0.171242509570207e-36, 0.156792067854621e3,\n              0.923261357901470, -0.597865988422577e1, 0.321988767636389e7,\n              -.399441390042203e-29, .493429086046981e-7, .812036983370565e-19,\n              -.207610284654137e-11, -.340821291419719e-6,\n              .542000573372233e-17, -.856711586510214e-12,\n              0.266170454405981e-13, 0.858133791857099e-5],\n        \"x\": [.377373741298151e19, -.507100883722913e13, -0.10336322559886e16,\n              .184790814320773e-5, -.924729378390945e-3, -0.425999562292738e24,\n              -.462307771873973e-12, .107319065855767e22, 0.648662492280682e11,\n              0.244200600688281e1, -0.851535733484258e10, 0.169894481433592e22,\n              0.215780222509020e-26, -0.320850551367334, -0.382642448458610e17,\n              -.275386077674421e-28, -.563199253391666e6, -.326068646279314e21,\n              0.397949001553184e14, 0.100824008584757e-6, 0.162234569738433e5,\n              -0.432355225319745e11, -.59287424559861e12, 0.133061647281106e1,\n              0.157338197797544e7, 0.258189614270853e14, 0.262413209706358e25,\n              -.920011937431142e-1, 0.220213765905426e-2, -0.110433759109547e2,\n              0.847004870612087e7, -0.592910695762536e9, -0.183027173269660e-4,\n              0.181339603516302, -0.119228759669889e4, 0.430867658061468e7],\n        \"y\": [-0.525597995024633e-9, 0.583441305228407e4, -.134778968457925e17,\n              .118973500934212e26, -0.159096490904708e27, -.315839902302021e-6,\n              0.496212197158239e3, 0.327777227273171e19, -0.527114657850696e22,\n              .210017506281863e-16, 0.705106224399834e21, -.266713136106469e31,\n              -0.145370512554562e-7, 0.149333917053130e28, -.149795620287641e8,\n              -.3818819062711e16, 0.724660165585797e-4, -0.937808169550193e14,\n              0.514411468376383e10, -0.828198594040141e5],\n        \"z\": [0.24400789229065e-10, -0.463057430331242e7, 0.728803274777712e10,\n              .327776302858856e16, -.110598170118409e10, -0.323899915729957e13,\n              .923814007023245e16, 0.842250080413712e-12, 0.663221436245506e12,\n              -.167170186672139e15, .253749358701391e4, -0.819731559610523e-20,\n              0.328380587890663e12, -0.625004791171543e8, 0.803197957462023e21,\n              -.204397011338353e-10, -.378391047055938e4, 0.97287654593862e-2,\n              0.154355721681459e2, -0.373962862928643e4, -0.682859011374572e11,\n              -0.248488015614543e-3, 0.394536049497068e7]}\n\n    I = I[x]\n    J = J[x]\n    n = n[x]\n    v_, P_, T_, a, b, c, d, e = par[x]\n\n    Pr = P/P_\n    Tr = T/T_\n    suma = 0\n    if x == \"n\":\n        for i, j, ni in zip(I, J, n):\n            suma += ni * (Pr-a)**i * (Tr-b)**j\n        return v_*exp(suma)\n    else:\n        for i, j, ni in zip(I, J, n):\n            suma += ni * (Pr-a)**(c*i) * (Tr-b)**(j*d)\n        return v_*suma**e", "response": "Backward equation for region 3x v = f P x"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the region definition for input T and P.", "response": "def _Bound_TP(T, P):\n    \"\"\"Region definition for input T and P\n\n    Parameters\n    ----------\n    T : float\n        Temperature, [K]\n    P : float\n        Pressure, [MPa]\n\n    Returns\n    -------\n    region : float\n        IAPWS-97 region code\n\n    References\n    ----------\n    Wagner, W; Kretzschmar, H-J: International Steam Tables: Properties of\n    Water and Steam Based on the Industrial Formulation IAPWS-IF97; Springer,\n    2008; doi: 10.1007/978-3-540-74234-0. Fig. 2.3\n    \"\"\"\n    region = None\n    if 1073.15 < T <= 2273.15 and Pmin <= P <= 50:\n        region = 5\n    elif Pmin <= P <= Ps_623:\n        Tsat = _TSat_P(P)\n        if 273.15 <= T <= Tsat:\n            region = 1\n        elif Tsat < T <= 1073.15:\n            region = 2\n    elif Ps_623 < P <= 100:\n        T_b23 = _t_P(P)\n        if 273.15 <= T <= 623.15:\n            region = 1\n        elif 623.15 < T < T_b23:\n            region = 3\n        elif T_b23 <= T <= 1073.15:\n            region = 2\n    return region"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prop0(T, P):\n    if T <= 1073.15:\n        Tr = 540/T\n        Pr = P/1.\n        go, gop, gopp, got, gott, gopt = Region2_cp0(Tr, Pr)\n    else:\n        Tr = 1000/T\n        Pr = P/1.\n        go, gop, gopp, got, gott, gopt = Region5_cp0(Tr, Pr)\n\n    prop0 = {}\n    prop0[\"v\"] = Pr*gop*R*T/P/1000\n    prop0[\"h\"] = Tr*got*R*T\n    prop0[\"s\"] = R*(Tr*got-go)\n    prop0[\"cp\"] = -R*Tr**2*gott\n    prop0[\"cv\"] = R*(-Tr**2*gott-1)\n\n    prop0[\"w\"] = (R*T*1000/(1+1/Tr**2/gott))**0.5\n    prop0[\"alfav\"] = 1/T\n    prop0[\"xkappa\"] = 1/P\n    return prop0", "response": "Ideal gas properties of a single resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the class is calculable by its kwargs", "response": "def calculable(self):\n        \"\"\"Check if class is calculable by its kwargs\"\"\"\n        self._thermo = \"\"\n        if self.kwargs[\"T\"] and self.kwargs[\"P\"]:\n            self._thermo = \"TP\"\n        elif self.kwargs[\"P\"] and self.kwargs[\"h\"] is not None:\n            self._thermo = \"Ph\"\n        elif self.kwargs[\"P\"] and self.kwargs[\"s\"] is not None:\n            self._thermo = \"Ps\"\n        # TODO: Add other pairs definitions options\n        # elif self.kwargs[\"P\"] and self.kwargs[\"v\"]:\n            # self._thermo = \"Pv\"\n        # elif self.kwargs[\"T\"] and self.kwargs[\"s\"] is not None:\n            # self._thermo = \"Ts\"\n        elif self.kwargs[\"h\"] is not None and self.kwargs[\"s\"] is not None:\n            self._thermo = \"hs\"\n        elif self.kwargs[\"T\"] and self.kwargs[\"x\"] is not None:\n            self._thermo = \"Tx\"\n        elif self.kwargs[\"P\"] and self.kwargs[\"x\"] is not None:\n            self._thermo = \"Px\"\n        return self._thermo"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef derivative(self, z, x, y, fase):\n        return deriv_G(self, z, x, y, fase)", "response": "Wrapper for derivative for custom derived properties\n        where x y z can be P T v u h s g a"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Ttr(x):\n    if 0 <= x <= 0.33367:\n        Ttr = 273.16*(1-0.3439823*x-1.3274271*x**2-274.973*x**3)\n    elif 0.33367 < x <= 0.58396:\n        Ttr = 193.549*(1-4.987368*(x-0.5)**2)\n    elif 0.58396 < x <= 0.81473:\n        Ttr = 194.38*(1-4.886151*(x-2/3)**2+10.37298*(x-2/3)**3)\n    elif 0.81473 < x <= 1:\n        Ttr = 195.495*(1-0.323998*(1-x)-15.87560*(1-x)**4)\n    else:\n        raise NotImplementedError(\"Incoming out of bound\")\n    return Ttr", "response": "Equation for the triple point of ammonia - water mixture."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _prop(self, rho, T, x):\n        # FIXME: The values are good, bad difer by 1%, a error I can find\n        # In Pressure happen and only use fird\n\n        M = (1-x)*IAPWS95.M + x*NH3.M\n        R = 8.314471/M\n\n        phio = self._phi0(rho, T, x)\n        fio = phio[\"fio\"]\n        tau0 = phio[\"tau\"]\n        fiot = phio[\"fiot\"]\n        fiott = phio[\"fiott\"]\n\n        phir = self._phir(rho, T, x)\n        fir = phir[\"fir\"]\n        tau = phir[\"tau\"]\n        delta = phir[\"delta\"]\n        firt = phir[\"firt\"]\n        firtt = phir[\"firtt\"]\n        fird = phir[\"fird\"]\n        firdd = phir[\"firdd\"]\n        firdt = phir[\"firdt\"]\n        F = phir[\"F\"]\n\n        prop = {}\n        Z = 1 + delta*fird\n        prop[\"M\"] = M\n        prop[\"P\"] = Z*R*T*rho/1000\n        prop[\"u\"] = R*T*(tau0*fiot + tau*firt)\n        prop[\"s\"] = R*(tau0*fiot + tau*firt - fio - fir)\n        prop[\"h\"] = R*T*(1+delta*fird+tau0*fiot+tau*firt)\n        prop[\"g\"] = prop[\"h\"]-T*prop[\"s\"]\n        prop[\"a\"] = prop[\"u\"]-T*prop[\"s\"]\n        cvR = -tau0**2*fiott - tau**2*firtt\n        prop[\"cv\"] = R*cvR\n        prop[\"cp\"] = R*(cvR+(1+delta*fird-delta*tau*firdt)**2 /\n                        (1+2*delta*fird+delta**2*firdd))\n        prop[\"w\"] = (R*T*1000*(1+2*delta*fird+delta**2*firdd +\n                               (1+delta*fird-delta*tau*firdt)**2 / cvR))**0.5\n        prop[\"fugH2O\"] = Z*exp(fir+delta*fird-x*F)\n        prop[\"fugNH3\"] = Z*exp(fir+delta*fird+(1-x)*F)\n        return prop", "response": "Returns a dict containing the properties of the thermodynamic properties of the ammonia - water mixture with the given temperature rho and Mole fraction x."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _phi0(self, rho, T, x):\n        # Define reducing parameters for mixture model\n        M = (1-x)*IAPWS95.M + x*NH3.M\n        tau = 500/T\n        delta = rho/15/M\n\n        # Table 2\n        Fi0 = {\n            \"log_water\": 3.006320,\n            \"ao_water\": [-7.720435, 8.649358],\n            \"pow_water\": [0, 1],\n            \"ao_exp\": [0.012436, 0.97315, 1.279500, 0.969560, 0.248730],\n            \"titao\": [1.666, 4.578, 10.018, 11.964, 35.600],\n            \"log_nh3\": -1.0,\n            \"ao_nh3\": [-16.444285, 4.036946, 10.69955, -1.775436, 0.82374034],\n            \"pow_nh3\": [0, 1, 1/3, -3/2, -7/4]}\n\n        fiod = 1/delta\n        fiodd = -1/delta**2\n        fiodt = 0\n        fiow = fiotw = fiottw = 0\n        fioa = fiota = fiotta = 0\n\n        # Water section\n        if x < 1:\n            fiow = Fi0[\"log_water\"]*log(tau) + log(1-x)\n            fiotw = Fi0[\"log_water\"]/tau\n            fiottw = -Fi0[\"log_water\"]/tau**2\n            for n, t in zip(Fi0[\"ao_water\"], Fi0[\"pow_water\"]):\n                fiow += n*tau**t\n                if t != 0:\n                    fiotw += t*n*tau**(t-1)\n                if t not in [0, 1]:\n                    fiottw += n*t*(t-1)*tau**(t-2)\n            for n, t in zip(Fi0[\"ao_exp\"], Fi0[\"titao\"]):\n                fiow += n*log(1-exp(-tau*t))\n                fiotw += n*t*((1-exp(-t*tau))**-1-1)\n                fiottw -= n*t**2*exp(-t*tau)*(1-exp(-t*tau))**-2\n\n        # ammonia section\n        if x > 0:\n            fioa = Fi0[\"log_nh3\"]*log(tau) + log(x)\n            fiota = Fi0[\"log_nh3\"]/tau\n            fiotta = -Fi0[\"log_nh3\"]/tau**2\n            for n, t in zip(Fi0[\"ao_nh3\"], Fi0[\"pow_nh3\"]):\n                fioa += n*tau**t\n                if t != 0:\n                    fiota += t*n*tau**(t-1)\n                if t not in [0, 1]:\n                    fiotta += n*t*(t-1)*tau**(t-2)\n\n        prop = {}\n        prop[\"tau\"] = tau\n        prop[\"delta\"] = delta\n        prop[\"fio\"] = log(delta) + (1-x)*fiow + x*fioa\n        prop[\"fiot\"] = (1-x)*fiotw + x*fiota\n        prop[\"fiott\"] = (1-x)*fiottw + x*fiotta\n        prop[\"fiod\"] = fiod\n        prop[\"fiodd\"] = fiodd\n        prop[\"fiodt\"] = fiodt\n        return prop", "response": "This function is used to calculate the phi0 of the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls a custom preprocessing method first then rename grid attrs. This wrapper is needed to generate a single function to pass to the ``preprocesss`` of xr.open_mfdataset. It makes sure that the user-specified preprocess function is called on the loaded Dataset before aospy's is applied. An example for why this might be needed is output from the WRF model; one needs to add a CF-compliant units attribute to the time coordinate of all input files, because it is not present by default. Parameters ---------- func : function An arbitrary function to call before calling ``grid_attrs_to_aospy_names`` in ``_load_data_from_disk``. Must take an xr.Dataset as an argument as well as ``**kwargs``. grid_attrs : dict (optional) Overriding dictionary of grid attributes mapping aospy internal names to names of grid attributes used in a particular model. Returns ------- function A function that calls the provided function ``func`` on the Dataset before calling ``grid_attrs_to_aospy_names``; this is meant to be passed as a ``preprocess`` argument to ``xr.open_mfdataset``.", "response": "def _preprocess_and_rename_grid_attrs(func, grid_attrs=None, **kwargs):\n    \"\"\"Call a custom preprocessing method first then rename grid attrs.\n\n    This wrapper is needed to generate a single function to pass to the\n    ``preprocesss`` of xr.open_mfdataset.  It makes sure that the\n    user-specified preprocess function is called on the loaded Dataset before\n    aospy's is applied.  An example for why this might be needed is output from\n    the WRF model; one needs to add a CF-compliant units attribute to the time\n    coordinate of all input files, because it is not present by default.\n\n    Parameters\n    ----------\n    func : function\n       An arbitrary function to call before calling\n       ``grid_attrs_to_aospy_names`` in ``_load_data_from_disk``.  Must take\n       an xr.Dataset as an argument as well as ``**kwargs``.\n    grid_attrs : dict (optional)\n        Overriding dictionary of grid attributes mapping aospy internal\n        names to names of grid attributes used in a particular model.\n\n    Returns\n    -------\n    function\n        A function that calls the provided function ``func`` on the Dataset\n        before calling ``grid_attrs_to_aospy_names``; this is meant to be\n        passed as a ``preprocess`` argument to ``xr.open_mfdataset``.\n    \"\"\"\n\n    def func_wrapper(ds):\n        return grid_attrs_to_aospy_names(func(ds, **kwargs), grid_attrs)\n    return func_wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef grid_attrs_to_aospy_names(data, grid_attrs=None):\n    if grid_attrs is None:\n        grid_attrs = {}\n\n    # Override GRID_ATTRS with entries in grid_attrs\n    attrs = GRID_ATTRS.copy()\n    for k, v in grid_attrs.items():\n        if k not in attrs:\n            raise ValueError(\n                'Unrecognized internal name, {!r}, specified for a custom '\n                'grid attribute name.  See the full list of valid internal '\n                'names below:\\n\\n{}'.format(k, list(GRID_ATTRS.keys())))\n        attrs[k] = (v, )\n\n    dims_and_vars = set(data.variables).union(set(data.dims))\n    for name_int, names_ext in attrs.items():\n        data_coord_name = set(names_ext).intersection(dims_and_vars)\n        if data_coord_name:\n            data = data.rename({data_coord_name.pop(): name_int})\n    return set_grid_attrs_as_coords(data)", "response": "Rename grid attributes to be consistent with aospy internal names."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets available grid attributes as coordinates in a given Dataset.", "response": "def set_grid_attrs_as_coords(ds):\n    \"\"\"Set available grid attributes as coordinates in a given Dataset.\n\n    Grid attributes are assumed to have their internal aospy names. Grid\n    attributes are set as coordinates, such that they are carried by all\n    selected DataArrays with overlapping index dimensions.\n\n    Parameters\n    ----------\n    ds : Dataset\n        Input data\n\n    Returns\n    -------\n    Dataset\n        Dataset with grid attributes set as coordinates\n    \"\"\"\n    grid_attrs_in_ds = set(GRID_ATTRS.keys()).intersection(\n        set(ds.coords) | set(ds.data_vars))\n    ds = ds.set_coords(grid_attrs_in_ds)\n    return ds"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncast DataArrays to np. float64 if they are of type np. float32.", "response": "def _maybe_cast_to_float64(da):\n    \"\"\"Cast DataArrays to np.float64 if they are of type np.float32.\n\n    Parameters\n    ----------\n    da : xr.DataArray\n        Input DataArray\n\n    Returns\n    -------\n    DataArray\n    \"\"\"\n    if da.dtype == np.float32:\n        logging.warning('Datapoints were stored using the np.float32 datatype.'\n                        'For accurate reduction operations using bottleneck, '\n                        'datapoints are being cast to the np.float64 datatype.'\n                        ' For more information see: https://github.com/pydata/'\n                        'xarray/issues/1346')\n        return da.astype(np.float64)\n    else:\n        return da"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _sel_var(ds, var, upcast_float32=True):\n    for name in var.names:\n        try:\n            da = ds[name].rename(var.name)\n            if upcast_float32:\n                return _maybe_cast_to_float64(da)\n            else:\n                return da\n        except KeyError:\n            pass\n    msg = '{0} not found among names: {1} in\\n{2}'.format(var, var.names, ds)\n    raise LookupError(msg)", "response": "Select the specified variable by trying all possible alternative names."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares time coordinate information in Dataset for use in aospy.", "response": "def _prep_time_data(ds):\n    \"\"\"Prepare time coordinate information in Dataset for use in aospy.\n\n    1. If the Dataset contains a time bounds coordinate, add attributes\n       representing the true beginning and end dates of the time interval used\n       to construct the Dataset\n    2. If the Dataset contains a time bounds coordinate, overwrite the time\n       coordinate values with the averages of the time bounds at each timestep\n    3. Decode the times into np.datetime64 objects for time indexing\n\n    Parameters\n    ----------\n    ds : Dataset\n        Pre-processed Dataset with time coordinate renamed to\n        internal_names.TIME_STR\n\n    Returns\n    -------\n    Dataset\n        The processed Dataset\n    \"\"\"\n    ds = times.ensure_time_as_index(ds)\n    if TIME_BOUNDS_STR in ds:\n        ds = times.ensure_time_avg_has_cf_metadata(ds)\n        ds[TIME_STR] = times.average_time_bounds(ds)\n    else:\n        logging.warning(\"dt array not found.  Assuming equally spaced \"\n                        \"values in time, even though this may not be \"\n                        \"the case\")\n        ds = times.add_uniform_time_weights(ds)\n    # Suppress enable_cftimeindex is a no-op warning; we'll keep setting it for\n    # now to maintain backwards compatibility for older xarray versions.\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore')\n        with xr.set_options(enable_cftimeindex=True):\n            ds = xr.decode_cf(ds, decode_times=True, decode_coords=False,\n                              mask_and_scale=True)\n    return ds"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a Dataset from a list or glob - string of files.", "response": "def _load_data_from_disk(file_set, preprocess_func=lambda ds: ds,\n                         data_vars='minimal', coords='minimal',\n                         grid_attrs=None, **kwargs):\n    \"\"\"Load a Dataset from a list or glob-string of files.\n\n    Datasets from files are concatenated along time,\n    and all grid attributes are renamed to their aospy internal names.\n\n    Parameters\n    ----------\n    file_set : list or str\n        List of paths to files or glob-string\n    preprocess_func : function (optional)\n        Custom function to call before applying any aospy logic\n        to the loaded dataset\n    data_vars : str (default 'minimal')\n        Mode for concatenating data variables in call to ``xr.open_mfdataset``\n    coords : str (default 'minimal')\n        Mode for concatenating coordinate variables in call to\n        ``xr.open_mfdataset``.\n    grid_attrs : dict\n        Overriding dictionary of grid attributes mapping aospy internal\n        names to names of grid attributes used in a particular model.\n\n    Returns\n    -------\n    Dataset\n    \"\"\"\n    apply_preload_user_commands(file_set)\n    func = _preprocess_and_rename_grid_attrs(preprocess_func, grid_attrs,\n                                             **kwargs)\n    return xr.open_mfdataset(file_set, preprocess=func, concat_dim=TIME_STR,\n                             decode_times=False, decode_coords=False,\n                             mask_and_scale=True, data_vars=data_vars,\n                             coords=coords)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _setattr_default(obj, attr, value, default):\n    if value is None:\n        setattr(obj, attr, default)\n    else:\n        setattr(obj, attr, value)", "response": "Set an attribute of an object to a value or default value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a DataArray for the specified variable and time range.", "response": "def load_variable(self, var=None, start_date=None, end_date=None,\n                      time_offset=None, grid_attrs=None, **DataAttrs):\n        \"\"\"Load a DataArray for requested variable and time range.\n\n        Automatically renames all grid attributes to match aospy conventions.\n\n        Parameters\n        ----------\n        var : Var\n            aospy Var object\n        start_date : datetime.datetime\n            start date for interval\n        end_date : datetime.datetime\n            end date for interval\n        time_offset : dict\n            Option to add a time offset to the time coordinate to correct for\n            incorrect metadata.\n        grid_attrs : dict (optional)\n            Overriding dictionary of grid attributes mapping aospy internal\n            names to names of grid attributes used in a particular model.\n        **DataAttrs\n            Attributes needed to identify a unique set of files to load from\n\n        Returns\n        -------\n        da : DataArray\n             DataArray for the specified variable, date range, and interval in\n        \"\"\"\n        file_set = self._generate_file_set(var=var, start_date=start_date,\n                                           end_date=end_date, **DataAttrs)\n        ds = _load_data_from_disk(\n            file_set, self.preprocess_func, data_vars=self.data_vars,\n            coords=self.coords, start_date=start_date, end_date=end_date,\n            time_offset=time_offset, grid_attrs=grid_attrs, **DataAttrs\n        )\n        if var.def_time:\n            ds = _prep_time_data(ds)\n            start_date = times.maybe_convert_to_index_date_type(\n                ds.indexes[TIME_STR], start_date)\n            end_date = times.maybe_convert_to_index_date_type(\n                ds.indexes[TIME_STR], end_date)\n        ds = set_grid_attrs_as_coords(ds)\n        da = _sel_var(ds, var, self.upcast_float32)\n        if var.def_time:\n            da = self._maybe_apply_time_shift(da, time_offset, **DataAttrs)\n            return times.sel_time(da, start_date, end_date).load()\n        else:\n            return da.load()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a DataArray for the requested variable and time range using the provided Model object.", "response": "def _load_or_get_from_model(self, var, start_date=None, end_date=None,\n                                time_offset=None, model=None, **DataAttrs):\n        \"\"\"Load a DataArray for the requested variable and time range\n\n        Supports both access of grid attributes either through the DataLoader\n        or through an optionally-provided Model object.  Defaults to using\n        the version found in the DataLoader first.\n        \"\"\"\n        grid_attrs = None if model is None else model.grid_attrs\n\n        try:\n            return self.load_variable(\n                var, start_date=start_date, end_date=end_date,\n                time_offset=time_offset, grid_attrs=grid_attrs, **DataAttrs)\n        except (KeyError, IOError) as e:\n            if var.name not in GRID_ATTRS or model is None:\n                raise e\n            else:\n                try:\n                    return getattr(model, var.name)\n                except AttributeError:\n                    raise AttributeError(\n                        'Grid attribute {} could not be located either '\n                        'through this DataLoader or in the provided Model '\n                        'object: {}.'.format(var, model))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute a variable recursively loading data where needed.", "response": "def recursively_compute_variable(self, var, start_date=None, end_date=None,\n                                     time_offset=None, model=None,\n                                     **DataAttrs):\n        \"\"\"Compute a variable recursively, loading data where needed.\n\n        An obvious requirement here is that the variable must eventually be\n        able to be expressed in terms of model-native quantities; otherwise the\n        recursion will never stop.\n\n        Parameters\n        ----------\n        var : Var\n            aospy Var object\n        start_date : datetime.datetime\n            start date for interval\n        end_date : datetime.datetime\n            end date for interval\n        time_offset : dict\n            Option to add a time offset to the time coordinate to correct for\n            incorrect metadata.\n        model : Model\n            aospy Model object (optional)\n        **DataAttrs\n            Attributes needed to identify a unique set of files to load from\n\n        Returns\n        -------\n        da : DataArray\n             DataArray for the specified variable, date range, and interval in\n        \"\"\"\n        if var.variables is None:\n            return self._load_or_get_from_model(\n                var, start_date, end_date, time_offset, model, **DataAttrs)\n        else:\n            data = [self.recursively_compute_variable(\n                v, start_date, end_date, time_offset, model, **DataAttrs)\n                    for v in var.variables]\n            return var.func(*data).rename(var.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _maybe_apply_time_shift(da, time_offset=None, **DataAttrs):\n        if time_offset is not None:\n            time = times.apply_time_offset(da[TIME_STR], **time_offset)\n            da[TIME_STR] = time\n        return da", "response": "Apply specified time shift to DataArray"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generate_file_set(self, var=None, start_date=None, end_date=None,\n                           domain=None, intvl_in=None, dtype_in_vert=None,\n                           dtype_in_time=None, intvl_out=None):\n        \"\"\"Returns the file_set for the given interval in.\"\"\"\n        try:\n            return self.file_map[intvl_in]\n        except KeyError:\n            raise KeyError('File set does not exist for the specified'\n                           ' intvl_in {0}'.format(intvl_in))", "response": "Returns the file_set for the given interval in."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _maybe_apply_time_shift(da, time_offset=None, **DataAttrs):\n        if time_offset is not None:\n            time = times.apply_time_offset(da[TIME_STR], **time_offset)\n            da[TIME_STR] = time\n        else:\n            if DataAttrs['dtype_in_time'] == 'inst':\n                if DataAttrs['intvl_in'].endswith('hr'):\n                    offset = -1 * int(DataAttrs['intvl_in'][0])\n                else:\n                    offset = 0\n                time = times.apply_time_offset(da[TIME_STR], hours=offset)\n                da[TIME_STR] = time\n        return da", "response": "Apply time shift to the data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the given data to plotting units.", "response": "def to_plot_units(self, data, dtype_vert=False):\n        \"\"\"Convert the given data to plotting units.\"\"\"\n        if dtype_vert == 'vert_av' or not dtype_vert:\n            conv_factor = self.units.plot_units_conv\n        elif dtype_vert == ('vert_int'):\n            conv_factor = self.units.vert_int_plot_units_conv\n        else:\n            raise ValueError(\"dtype_vert value `{0}` not recognized.  Only \"\n                             \"bool(dtype_vert) = False, 'vert_av', and \"\n                             \"'vert_int' supported.\".format(dtype_vert))\n        if isinstance(data, dict):\n            return {key: val*conv_factor for key, val in data.items()}\n        return data*conv_factor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmask data array where values are outside physically valid range.", "response": "def mask_unphysical(self, data):\n        \"\"\"Mask data array where values are outside physically valid range.\"\"\"\n        if not self.valid_range:\n            return data\n        else:\n            return np.ma.masked_outside(data, np.min(self.valid_range),\n                                        np.max(self.valid_range))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nforcing data with units either degrees or radians to be radians.", "response": "def to_radians(arr, is_delta=False):\n    \"\"\"Force data with units either degrees or radians to be radians.\"\"\"\n    # Infer the units from embedded metadata, if it's there.\n    try:\n        units = arr.units\n    except AttributeError:\n        pass\n    else:\n        if units.lower().startswith('degrees'):\n            warn_msg = (\"Conversion applied: degrees -> radians to array: \"\n                        \"{}\".format(arr))\n            logging.debug(warn_msg)\n            return np.deg2rad(arr)\n    # Otherwise, assume degrees if the values are sufficiently large.\n    threshold = 0.1*np.pi if is_delta else 4*np.pi\n    if np.max(np.abs(arr)) > threshold:\n        warn_msg = (\"Conversion applied: degrees -> radians to array: \"\n                    \"{}\".format(arr))\n        logging.debug(warn_msg)\n        return np.deg2rad(arr)\n    return arr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_pascal(arr, is_dp=False):\n    threshold = 400 if is_dp else 1200\n    if np.max(np.abs(arr)) < threshold:\n        warn_msg = \"Conversion applied: hPa -> Pa to array: {}\".format(arr)\n        logging.debug(warn_msg)\n        return arr*100.\n    return arr", "response": "Convert array to Pa in hPa or Pa."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_hpa(arr):\n    if np.max(np.abs(arr)) > 1200.:\n        warn_msg = \"Conversion applied: Pa -> hPa to array: {}\".format(arr)\n        logging.debug(warn_msg)\n        return arr / 100.\n    return arr", "response": "Convert pressure array from Pa to hPa."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_coord(arr, old_dim, new_dim, new_coord):\n    new_arr = arr.rename({old_dim: new_dim})\n    new_arr[new_dim] = new_coord\n    return new_arr", "response": "Replace a coordinate with new one ; old must have same shape."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute data at full pressure levels from values at half levels.", "response": "def to_pfull_from_phalf(arr, pfull_coord):\n    \"\"\"Compute data at full pressure levels from values at half levels.\"\"\"\n    phalf_top = arr.isel(**{internal_names.PHALF_STR: slice(1, None)})\n    phalf_top = replace_coord(phalf_top, internal_names.PHALF_STR,\n                              internal_names.PFULL_STR, pfull_coord)\n\n    phalf_bot = arr.isel(**{internal_names.PHALF_STR: slice(None, -1)})\n    phalf_bot = replace_coord(phalf_bot, internal_names.PHALF_STR,\n                              internal_names.PFULL_STR, pfull_coord)\n    return 0.5*(phalf_bot + phalf_top)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_phalf_from_pfull(arr, val_toa=0, val_sfc=0):\n    phalf = np.zeros((arr.shape[0] + 1, arr.shape[1], arr.shape[2]))\n    phalf[0] = val_toa\n    phalf[-1] = val_sfc\n    phalf[1:-1] = 0.5*(arr[:-1] + arr[1:])\n    return phalf", "response": "Compute data at half pressure levels from values at full levels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pfull_from_ps(bk, pk, ps, pfull_coord):\n    return to_pfull_from_phalf(phalf_from_ps(bk, pk, ps), pfull_coord)", "response": "Compute pressure at full levels from surface pressure."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef d_deta_from_phalf(arr, pfull_coord):\n    d_deta = arr.diff(dim=internal_names.PHALF_STR, n=1)\n    return replace_coord(d_deta, internal_names.PHALF_STR,\n                         internal_names.PFULL_STR, pfull_coord)", "response": "Compute pressure level thickness from half level pressures."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef d_deta_from_pfull(arr):\n    right = arr[{internal_names.PFULL_STR: slice(2, None, None)}].values\n    left = arr[{internal_names.PFULL_STR: slice(0, -2, 1)}].values\n    deriv = xr.DataArray(np.zeros(arr.shape), dims=arr.dims,\n                         coords=arr.coords)\n    deriv[{internal_names.PFULL_STR: slice(1, -1, 1)}] = (right - left) / 2.\n    deriv[{internal_names.PFULL_STR: 0}] = (\n        arr[{internal_names.PFULL_STR: 1}].values -\n        arr[{internal_names.PFULL_STR: 0}].values)\n    deriv[{internal_names.PFULL_STR: -1}] = (\n        arr[{internal_names.PFULL_STR: -1}].values -\n        arr[{internal_names.PFULL_STR: -2}].values)\n    return deriv", "response": "Compute the derivative of the array on full hybrid levels."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dp_from_ps(bk, pk, ps, pfull_coord):\n    return d_deta_from_phalf(phalf_from_ps(bk, pk, ps), pfull_coord)", "response": "Compute pressure level thickness from surface pressure"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef integrate(arr, ddim, dim=False, is_pressure=False):\n    if is_pressure:\n        dim = vert_coord_name(ddim)\n    return (arr*ddim).sum(dim=dim)", "response": "Integrate along the given dimension."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dim_name(arr, names):\n    for name in names:\n        # TODO: raise warning/exception when multiple names arr attrs.\n        if hasattr(arr, name):\n            return name\n    raise AttributeError(\"No attributes of the object `{0}` match the \"\n                         \"specified names of `{1}`\".format(arr, names))", "response": "Determine if an object has an attribute name matching a given list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets level thickness of pressure data incorporating surface pressure.", "response": "def dp_from_p(p, ps, p_top=0., p_bot=1.1e5):\n    \"\"\"Get level thickness of pressure data, incorporating surface pressure.\n\n    Level edges are defined as halfway between the levels, as well as the user-\n    specified uppermost and lowermost values.  The dp of levels whose bottom\n    pressure is less than the surface pressure is not changed by ps, since they\n    don't intersect the surface.  If ps is in between a level's top and bottom\n    pressures, then its dp becomes the pressure difference between its top and\n    ps.  If ps is less than a level's top and bottom pressures, then that level\n    is underground and its values are masked.\n\n    Note that postprocessing routines (e.g. at GFDL) typically mask out data\n    wherever the surface pressure is less than the level's given value, not the\n    level's upper edge.  This masks out more levels than the\n\n    \"\"\"\n    p_str = get_dim_name(p, (internal_names.PLEVEL_STR, 'plev'))\n    p_vals = to_pascal(p.values.copy())\n\n    # Layer edges are halfway between the given pressure levels.\n    p_edges_interior = 0.5*(p_vals[:-1] + p_vals[1:])\n    p_edges = np.concatenate(([p_bot], p_edges_interior, [p_top]))\n    p_edge_above = p_edges[1:]\n    p_edge_below = p_edges[:-1]\n    dp = p_edge_below - p_edge_above\n    if not all(np.sign(dp)):\n        raise ValueError(\"dp array not all > 0 : {}\".format(dp))\n    # Pressure difference between ps and the upper edge of each pressure level.\n    p_edge_above_xr = xr.DataArray(p_edge_above, dims=p.dims, coords=p.coords)\n    dp_to_sfc = ps - p_edge_above_xr\n    # Find the level adjacent to the masked, under-ground levels.\n    change = xr.DataArray(np.zeros(dp_to_sfc.shape), dims=dp_to_sfc.dims,\n                          coords=dp_to_sfc.coords)\n    change[{p_str: slice(1, None)}] = np.diff(\n        np.sign(ps - to_pascal(p.copy()))\n    )\n    dp_combined = xr.DataArray(np.where(change, dp_to_sfc, dp),\n                               dims=dp_to_sfc.dims, coords=dp_to_sfc.coords)\n    # Mask levels that are under ground.\n    above_ground = ps > to_pascal(p.copy())\n    above_ground[p_str] = p[p_str]\n    dp_with_ps = dp_combined.where(above_ground)\n    # Revert to original dim order.\n    possible_dim_orders = [\n        (internal_names.TIME_STR, p_str, internal_names.LAT_STR,\n         internal_names.LON_STR),\n        (internal_names.TIME_STR, p_str, internal_names.LAT_STR),\n        (internal_names.TIME_STR, p_str, internal_names.LON_STR),\n        (internal_names.TIME_STR, p_str),\n        (p_str, internal_names.LAT_STR, internal_names.LON_STR),\n        (p_str, internal_names.LAT_STR),\n        (p_str, internal_names.LON_STR),\n        (p_str,),\n    ]\n    for dim_order in possible_dim_orders:\n        try:\n            return dp_with_ps.transpose(*dim_order)\n        except ValueError:\n            logging.debug(\"Failed transpose to dims: {}\".format(dim_order))\n    else:\n        logging.debug(\"No transpose was successful.\")\n        return dp_with_ps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the thickness of a single pressure level.", "response": "def level_thickness(p, p_top=0., p_bot=1.01325e5):\n    \"\"\"\n    Calculates the thickness, in Pa, of each pressure level.\n\n    Assumes that the pressure values given are at the center of that model\n    level, except for the lowest value (typically 1000 hPa), which is the\n    bottom boundary. The uppermost level extends to 0 hPa.\n\n    Unlike `dp_from_p`, this does not incorporate the surface pressure.\n\n    \"\"\"\n    p_vals = to_pascal(p.values.copy())\n    dp_vals = np.empty_like(p_vals)\n    # Bottom level extends from p[0] to halfway betwen p[0] and p[1].\n    dp_vals[0] = p_bot - 0.5*(p_vals[0] + p_vals[1])\n    # Middle levels extend from halfway between [k-1], [k] and [k], [k+1].\n    dp_vals[1:-1] = 0.5*(p_vals[0:-2] - p_vals[2:])\n    # Top level extends from halfway between top two levels to 0 hPa.\n    dp_vals[-1] = 0.5*(p_vals[-2] + p_vals[-1]) - p_top\n    dp = p.copy()\n    dp.values = dp_vals\n    return dp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef does_coord_increase_w_index(arr):\n    diff = np.diff(arr)\n    if not np.all(np.abs(np.sign(diff))):\n        raise ValueError(\"Array is not monotonic: {}\".format(arr))\n    # Since we know its monotonic, just test the first value.\n    return bool(diff[0])", "response": "Determine if the array values increase with the index."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_time_offset(time, years=0, months=0, days=0, hours=0):\n    return (pd.to_datetime(time.values) +\n            pd.DateOffset(years=years, months=months, days=days, hours=hours))", "response": "Apply a specified offset to the given time array."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the average of each set of time bounds in the Dataset.", "response": "def average_time_bounds(ds):\n    \"\"\"Return the average of each set of time bounds in the Dataset.\n\n    Useful for creating a new time array to replace the Dataset's native time\n    array, in the case that the latter matches either the start or end bounds.\n    This can cause errors in grouping (akin to an off-by-one error) if the\n    timesteps span e.g. one full month each.  Note that the Dataset's times\n    must not have already undergone \"CF decoding\", wherein they are converted\n    from floats using the 'units' attribute into datetime objects.\n\n    Parameters\n    ----------\n    ds : xarray.Dataset\n        A Dataset containing a time bounds array with name matching\n        internal_names.TIME_BOUNDS_STR.  This time bounds array must have two\n        dimensions, one of which's coordinates is the Dataset's time array, and\n        the other is length-2.\n\n    Returns\n    -------\n    xarray.DataArray\n        The mean of the start and end times of each timestep in the original\n        Dataset.\n\n    Raises\n    ------\n    ValueError\n        If the time bounds array doesn't match the shape specified above.\n\n    \"\"\"\n    bounds = ds[TIME_BOUNDS_STR]\n    new_times = bounds.mean(dim=BOUNDS_STR, keep_attrs=True)\n    new_times = new_times.drop(TIME_STR).rename(TIME_STR)\n    new_times[TIME_STR] = new_times\n    return new_times"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying monthly mean over each time index in that month.", "response": "def monthly_mean_at_each_ind(monthly_means, sub_monthly_timeseries):\n    \"\"\"Copy monthly mean over each time index in that month.\n\n    Parameters\n    ----------\n    monthly_means : xarray.DataArray\n        array of monthly means\n    sub_monthly_timeseries : xarray.DataArray\n        array of a timeseries at sub-monthly time resolution\n\n    Returns\n    -------\n    xarray.DataArray with eath monthly mean value from `monthly_means` repeated\n    at each time within that month from `sub_monthly_timeseries`\n\n    See Also\n    --------\n    monthly_mean_ts : Create timeseries of monthly mean values\n    \"\"\"\n    time = monthly_means[TIME_STR]\n    start = time.indexes[TIME_STR][0].replace(day=1, hour=0)\n    end = time.indexes[TIME_STR][-1]\n    new_indices = pd.DatetimeIndex(start=start, end=end, freq='MS')\n    arr_new = monthly_means.reindex(time=new_indices, method='backfill')\n    return arr_new.reindex_like(sub_monthly_timeseries, method='pad')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naverages a sub - yearly time - series over each year.", "response": "def yearly_average(arr, dt):\n    \"\"\"Average a sub-yearly time-series over each year.\n\n    Resulting timeseries comprises one value for each year in which the\n    original array had valid data.  Accounts for (i.e. ignores) masked values\n    in original data when computing the annual averages.\n\n    Parameters\n    ----------\n    arr : xarray.DataArray\n        The array to be averaged\n    dt : xarray.DataArray\n        Array of the duration of each timestep\n\n    Returns\n    -------\n    xarray.DataArray\n        Has the same shape and mask as the original ``arr``, except for the\n        time dimension, which is truncated to one value for each year that\n        ``arr`` spanned\n\n    \"\"\"\n    assert_matching_time_coord(arr, dt)\n    yr_str = TIME_STR + '.year'\n    # Retain original data's mask.\n    dt = dt.where(np.isfinite(arr))\n    return ((arr*dt).groupby(yr_str).sum(TIME_STR) /\n            dt.groupby(yr_str).sum(TIME_STR))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ensure_datetime(obj):\n    _VALID_TYPES = (str, datetime.datetime, cftime.datetime,\n                    np.datetime64)\n    if isinstance(obj, _VALID_TYPES):\n        return obj\n    raise TypeError(\"datetime-like object required.  \"\n                    \"Type given: {}\".format(type(obj)))", "response": "Return the original object if it is a datetime - like object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts string labels for months to integer indices.", "response": "def month_indices(months):\n    \"\"\"Convert string labels for months to integer indices.\n\n    Parameters\n    ----------\n     months : str, int\n         If int, number of the desired month, where January=1, February=2,\n         etc.  If str, must match either 'ann' or some subset of\n         'jfmamjjasond'.  If 'ann', use all months.  Otherwise, use the\n         specified months.\n\n    Returns\n    -------\n    np.ndarray of integers corresponding to desired month indices\n\n    Raises\n    ------\n    TypeError : If `months` is not an int or str\n\n    See also\n    --------\n    _month_conditional\n    \"\"\"\n    if not isinstance(months, (int, str)):\n        raise TypeError(\"`months` must be of type int or str: \"\n                        \"type(months) == {}\".format(type(months)))\n    if isinstance(months, int):\n        return [months]\n    if months.lower() == 'ann':\n        return np.arange(1, 13)\n    first_letter = 'jfmamjjasond' * 2\n    # Python indexing starts at 0; month indices start at 1 for January.\n    count = first_letter.count(months)\n    if (count == 0) or (count > 2):\n        message = (\"The user must provide a unique pattern of consecutive \"\n                   \"first letters of months within '{}'. The provided \"\n                   \"string '{}' does not comply.\"\n                   \"  For individual months use integers.\"\n                   \"\".format(first_letter, months))\n        raise ValueError(message)\n    st_ind = first_letter.find(months.lower())\n    return np.arange(st_ind, st_ind + len(months)) % 12 + 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _month_conditional(time, months):\n    if isinstance(months, (int, str)):\n        months_array = month_indices(months)\n    else:\n        months_array = months\n    cond = False\n    for month in months_array:\n        cond |= (time['{}.month'.format(TIME_STR)] == month)\n    return cond", "response": "Create a conditional statement for selecting data in a DataArray for specific months."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_months(time, months):\n    inds = _month_conditional(time, months)\n    return time.sel(time=inds)", "response": "Extract times within specified months of the year."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nenforce that the time average data is present in the Dataset or DataArray and adds CF metadata attributes to the dataset.", "response": "def ensure_time_avg_has_cf_metadata(ds):\n    \"\"\"Add time interval length and bounds coordinates for time avg data.\n\n    If the Dataset or DataArray contains time average data, enforce\n    that there are coordinates that track the lower and upper bounds of\n    the time intervals, and that there is a coordinate that tracks the\n    amount of time per time average interval.\n\n    CF conventions require that a quantity stored as time averages\n    over time intervals must have time and time_bounds coordinates [1]_.\n    aospy further requires AVERAGE_DT for time average data, for accurate\n    time-weighted averages, which can be inferred from the CF-required\n    time_bounds coordinate if needed.  This step should be done\n    prior to decoding CF metadata with xarray to ensure proper\n    computed timedeltas for different calendar types.\n\n    .. [1] http://cfconventions.org/cf-conventions/v1.6.0/cf-conventions.html#_data_representative_of_cells\n\n    Parameters\n    ----------\n    ds : Dataset or DataArray\n        Input data\n\n    Returns\n    -------\n    Dataset or DataArray\n        Time average metadata attributes added if needed.\n    \"\"\"  # noqa: E501\n    if TIME_WEIGHTS_STR not in ds:\n        time_weights = ds[TIME_BOUNDS_STR].diff(BOUNDS_STR)\n        time_weights = time_weights.rename(TIME_WEIGHTS_STR).squeeze()\n        if BOUNDS_STR in time_weights.coords:\n            time_weights = time_weights.drop(BOUNDS_STR)\n        ds[TIME_WEIGHTS_STR] = time_weights\n\n    raw_start_date = ds[TIME_BOUNDS_STR].isel(**{TIME_STR: 0, BOUNDS_STR: 0})\n    ds[RAW_START_DATE_STR] = raw_start_date.reset_coords(drop=True)\n    raw_end_date = ds[TIME_BOUNDS_STR].isel(**{TIME_STR: -1, BOUNDS_STR: 1})\n    ds[RAW_END_DATE_STR] = raw_end_date.reset_coords(drop=True)\n\n    for coord in [TIME_BOUNDS_STR, RAW_START_DATE_STR, RAW_END_DATE_STR]:\n        ds[coord].attrs['units'] = ds[TIME_STR].attrs['units']\n        if 'calendar' in ds[TIME_STR].attrs:\n            ds[coord].attrs['calendar'] = ds[TIME_STR].attrs['calendar']\n\n    unit_interval = ds[TIME_STR].attrs['units'].split('since')[0].strip()\n    ds[TIME_WEIGHTS_STR].attrs['units'] = unit_interval\n    return ds"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends uniform time weights to a Dataset.", "response": "def add_uniform_time_weights(ds):\n    \"\"\"Append uniform time weights to a Dataset.\n\n    All DataArrays with a time coordinate require a time weights coordinate.\n    For Datasets read in without a time bounds coordinate or explicit\n    time weights built in, aospy adds uniform time weights at each point\n    in the time coordinate.\n\n    Parameters\n    ----------\n    ds : Dataset\n        Input data\n\n    Returns\n    -------\n    Dataset\n    \"\"\"\n    time = ds[TIME_STR]\n    unit_interval = time.attrs['units'].split('since')[0].strip()\n    time_weights = xr.ones_like(time)\n    time_weights.attrs['units'] = unit_interval\n    del time_weights.attrs['calendar']\n    ds[TIME_WEIGHTS_STR] = time_weights\n    return ds"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck to make sure that data exists for the given time range.", "response": "def _assert_has_data_for_time(da, start_date, end_date):\n    \"\"\"Check to make sure data is in Dataset for the given time range.\n\n    Parameters\n    ----------\n    da : DataArray\n         DataArray with a time variable\n    start_date : datetime-like object or str\n         start date\n    end_date : datetime-like object or str\n         end date\n\n    Raises\n    ------\n    AssertionError\n         If the time range is not within the time range of the DataArray\n\n    \"\"\"\n    if isinstance(start_date, str) and isinstance(end_date, str):\n        logging.warning(\n            'When using strings to specify start and end dates, the check '\n            'to determine if data exists for the full extent of the desired '\n            'interval is not implemented.  Therefore it is possible that '\n            'you are doing a calculation for a lesser interval than you '\n            'specified.  If you would like this check to occur, use explicit '\n            'datetime-like objects for bounds instead.')\n        return\n\n    if RAW_START_DATE_STR in da.coords:\n        with warnings.catch_warnings(record=True):\n            da_start = da[RAW_START_DATE_STR].values\n            da_end = da[RAW_END_DATE_STR].values\n    else:\n        times = da.time.isel(**{TIME_STR: [0, -1]})\n        da_start, da_end = times.values\n\n    message = ('Data does not exist for requested time range: {0} to {1};'\n               ' found data from time range: {2} to {3}.')\n    # Add tolerance of one second, due to precision of cftime.datetimes\n    tol = datetime.timedelta(seconds=1)\n    if isinstance(da_start, np.datetime64):\n        tol = np.timedelta64(tol, 'ns')\n    range_exists = ((da_start - tol) <= start_date and\n                    (da_end + tol) >= end_date)\n    assert (range_exists), message.format(start_date, end_date,\n                                          da_start, da_end)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sel_time(da, start_date, end_date):\n    _assert_has_data_for_time(da, start_date, end_date)\n    da[SUBSET_START_DATE_STR] = xr.DataArray(start_date)\n    da[SUBSET_END_DATE_STR] = xr.DataArray(end_date)\n    return da.sel(**{TIME_STR: slice(start_date, end_date)})", "response": "Subset a DataArray or Dataset for a given date range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking to see if two DataArrays have the same time coordinate.", "response": "def assert_matching_time_coord(arr1, arr2):\n    \"\"\"Check to see if two DataArrays have the same time coordinate.\n\n    Parameters\n    ----------\n    arr1 : DataArray or Dataset\n        First DataArray or Dataset\n    arr2 : DataArray or Dataset\n        Second DataArray or Dataset\n\n    Raises\n    ------\n    ValueError\n        If the time coordinates are not identical between the two Datasets\n    \"\"\"\n    message = ('Time weights not indexed by the same time coordinate as'\n               ' computed data.  This will lead to an improperly computed'\n               ' time weighted average.  Exiting.\\n'\n               'arr1: {}\\narr2: {}')\n    if not (arr1[TIME_STR].identical(arr2[TIME_STR])):\n        raise ValueError(message.format(arr1[TIME_STR], arr2[TIME_STR]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ensure_time_as_index(ds):\n    time_indexed_coords = {TIME_WEIGHTS_STR, TIME_BOUNDS_STR}\n    time_indexed_vars = set(ds.data_vars).union(time_indexed_coords)\n    time_indexed_vars = time_indexed_vars.intersection(ds.variables)\n    variables_to_replace = {}\n    for name in time_indexed_vars:\n        if TIME_STR not in ds[name].indexes:\n            da = ds[name]\n            if TIME_STR not in da.dims:\n                da = ds[name].expand_dims(TIME_STR)\n            da = da.assign_coords(**{TIME_STR: ds[TIME_STR]})\n            variables_to_replace[name] = da\n    return ds.assign(**variables_to_replace)", "response": "Ensures that time is an indexed coordinate on relevant quantities."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a datetime - like object or string infer the year.", "response": "def infer_year(date):\n    \"\"\"Given a datetime-like object or string infer the year.\n\n    Parameters\n    ----------\n    date : datetime-like object or str\n        Input date\n\n    Returns\n    -------\n    int\n\n    Examples\n    --------\n    >>> infer_year('2000')\n    2000\n    >>> infer_year('2000-01')\n    2000\n    >>> infer_year('2000-01-31')\n    2000\n    >>> infer_year(datetime.datetime(2000, 1, 1))\n    2000\n    >>> infer_year(np.datetime64('2000-01-01'))\n    2000\n    >>> infer_year(DatetimeNoLeap(2000, 1, 1))\n    2000\n    >>>\n    \"\"\"\n    if isinstance(date, str):\n        # Look for a string that begins with four numbers; the first four\n        # numbers found are the year.\n        pattern = r'(?P<year>\\d{4})'\n        result = re.match(pattern, date)\n        if result:\n            return int(result.groupdict()['year'])\n        else:\n            raise ValueError('Invalid date string provided: {}'.format(date))\n    elif isinstance(date, np.datetime64):\n        return date.item().year\n    else:\n        return date.year"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a datetime - like object to the index s date type.", "response": "def maybe_convert_to_index_date_type(index, date):\n    \"\"\"Convert a datetime-like object to the index's date type.\n\n    Datetime indexing in xarray can be done using either a pandas\n    DatetimeIndex or a CFTimeIndex.  Both support partial-datetime string\n    indexing regardless of the calendar type of the underlying data;\n    therefore if a string is passed as a date, we return it unchanged.  If a\n    datetime-like object is provided, it will be converted to the underlying\n    date type of the index.  For a DatetimeIndex that is np.datetime64; for a\n    CFTimeIndex that is an object of type cftime.datetime specific to the\n    calendar used.\n\n    Parameters\n    ----------\n    index : pd.Index\n        Input time index\n    date : datetime-like object or str\n        Input datetime\n\n    Returns\n    -------\n    date of the type appropriate for the time index of the Dataset\n    \"\"\"\n    if isinstance(date, str):\n        return date\n\n    if isinstance(index, pd.DatetimeIndex):\n        if isinstance(date, np.datetime64):\n            return date\n        else:\n            return np.datetime64(str(date))\n    else:\n        date_type = index.date_type\n        if isinstance(date, date_type):\n            return date\n        else:\n            if isinstance(date, np.datetime64):\n                # Convert to datetime.date or datetime.datetime object\n                date = date.item()\n\n            if isinstance(date, datetime.date):\n                # Convert to a datetime.datetime object\n                date = datetime.datetime.combine(\n                    date, datetime.datetime.min.time())\n\n            return date_type(date.year, date.month, date.day, date.hour,\n                             date.minute, date.second, date.microsecond)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct the mask that defines a region on a given data s grid.", "response": "def _make_mask(self, data, lon_str=LON_STR, lat_str=LAT_STR):\n        \"\"\"Construct the mask that defines a region on a given data's grid.\"\"\"\n        mask = False\n        for west, east, south, north in self.mask_bounds:\n            if west < east:\n                mask_lon = (data[lon_str] > west) & (data[lon_str] < east)\n            else:\n                mask_lon = (data[lon_str] < west) | (data[lon_str] > east)\n            mask_lat = (data[lat_str] > south) & (data[lat_str] < north)\n            mask |= mask_lon & mask_lat\n        return mask"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmasking the given array of data outside this region.", "response": "def mask_var(self, data, lon_cyclic=True, lon_str=LON_STR,\n                 lat_str=LAT_STR):\n        \"\"\"Mask the given data outside this region.\n\n        Parameters\n        ----------\n        data : xarray.DataArray\n            The array to be regionally masked.\n        lon_cyclic : bool, optional (default True)\n            Whether or not the longitudes of ``data`` span the whole globe,\n            meaning that they should be wrapped around as necessary to cover\n            the Region's full width.\n        lon_str, lat_str : str, optional\n            The names of the longitude and latitude dimensions, respectively,\n            in the data to be masked.  Defaults are\n            ``aospy.internal_names.LON_STR`` and\n            ``aospy.internal_names.LON_STR``, respectively.\n\n        Returns\n        -------\n        xarray.DataArray\n            The original array with points outside of the region masked.\n\n        \"\"\"\n        # TODO: is this still necessary?\n        if not lon_cyclic:\n            if self.west_bound > self.east_bound:\n                raise ValueError(\"Longitudes of data to be masked are \"\n                                 \"specified as non-cyclic, but Region's \"\n                                 \"definition requires wraparound longitudes.\")\n        masked = data.where(self._make_mask(data, lon_str=lon_str,\n                                            lat_str=lat_str))\n        return masked"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a yearly time - series of values averaged within a region.", "response": "def ts(self, data, lon_cyclic=True, lon_str=LON_STR, lat_str=LAT_STR,\n           land_mask_str=LAND_MASK_STR, sfc_area_str=SFC_AREA_STR):\n        \"\"\"Create yearly time-series of region-averaged data.\n\n        Parameters\n        ----------\n        data : xarray.DataArray\n            The array to create the regional timeseries of\n        lon_cyclic : { None, True, False }, optional (default True)\n            Whether or not the longitudes of ``data`` span the whole globe,\n            meaning that they should be wrapped around as necessary to cover\n            the Region's full width.\n        lat_str, lon_str, land_mask_str, sfc_area_str : str, optional\n            The name of the latitude, longitude, land mask, and surface area\n            coordinates, respectively, in ``data``.  Defaults are the\n            corresponding values in ``aospy.internal_names``.\n\n        Returns\n        -------\n        xarray.DataArray\n            The timeseries of values averaged within the region and within each\n            year, one value per year.\n\n        \"\"\"\n        data_masked = self.mask_var(data, lon_cyclic=lon_cyclic,\n                                    lon_str=lon_str, lat_str=lat_str)\n        sfc_area = data[sfc_area_str]\n        sfc_area_masked = self.mask_var(sfc_area, lon_cyclic=lon_cyclic,\n                                        lon_str=lon_str, lat_str=lat_str)\n        land_mask = _get_land_mask(data, self.do_land_mask,\n                                   land_mask_str=land_mask_str)\n        weights = sfc_area_masked * land_mask\n        # Mask weights where data values are initially invalid in addition\n        # to applying the region mask.\n        weights = weights.where(np.isfinite(data))\n        weights_reg_sum = weights.sum(lon_str).sum(lat_str)\n        data_reg_sum = (data_masked * sfc_area_masked *\n                        land_mask).sum(lat_str).sum(lon_str)\n        return data_reg_sum / weights_reg_sum"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef av(self, data, lon_str=LON_STR, lat_str=LAT_STR,\n           land_mask_str=LAND_MASK_STR, sfc_area_str=SFC_AREA_STR):\n        \"\"\"Time-average of region-averaged data.\n\n        Parameters\n        ----------\n        data : xarray.DataArray\n            The array to compute the regional time-average of\n        lat_str, lon_str, land_mask_str, sfc_area_str : str, optional\n            The name of the latitude, longitude, land mask, and surface area\n            coordinates, respectively, in ``data``.  Defaults are the\n            corresponding values in ``aospy.internal_names``.\n\n        Returns\n        -------\n        xarray.DataArray\n            The region-averaged and time-averaged data.\n\n        \"\"\"\n        ts = self.ts(data, lon_str=lon_str, lat_str=lat_str,\n                     land_mask_str=land_mask_str, sfc_area_str=sfc_area_str)\n        if YEAR_STR not in ts.coords:\n            return ts\n        else:\n            return ts.mean(YEAR_STR)", "response": "Compute the time - average of the regional and time - averaged data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _rename_coords(ds, attrs):\n    for name_int, names_ext in attrs.items():\n        # Check if coord is in dataset already.\n        ds_coord_name = set(names_ext).intersection(set(ds.coords))\n        if ds_coord_name:\n            # Rename to the aospy internal name.\n            try:\n                ds = ds.rename({list(ds_coord_name)[0]: name_int})\n                logging.debug(\"Rename coord from `{0}` to `{1}` for \"\n                              \"Dataset `{2}`\".format(ds_coord_name,\n                                                     name_int, ds))\n            # xarray throws a ValueError if the name already exists\n            except ValueError:\n                ds = ds\n    return ds", "response": "Rename coordinates to aospy s internal names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _bounds_from_array(arr, dim_name, bounds_name):\n    # TODO: don't assume needed dimension is in axis=0\n    # TODO: refactor to get rid of repetitive code\n    spacing = arr.diff(dim_name).values\n    lower = xr.DataArray(np.empty_like(arr), dims=arr.dims,\n                         coords=arr.coords)\n    lower.values[:-1] = arr.values[:-1] - 0.5*spacing\n    lower.values[-1] = arr.values[-1] - 0.5*spacing[-1]\n    upper = xr.DataArray(np.empty_like(arr), dims=arr.dims,\n                         coords=arr.coords)\n    upper.values[:-1] = arr.values[:-1] + 0.5*spacing\n    upper.values[-1] = arr.values[-1] + 0.5*spacing[-1]\n    bounds = xr.concat([lower, upper], dim='bounds')\n    return bounds.T", "response": "Get the bounds of an array given its center values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget grid spacing by subtracting upper and lower bounds.", "response": "def _diff_bounds(bounds, coord):\n    \"\"\"Get grid spacing by subtracting upper and lower bounds.\"\"\"\n    try:\n        return bounds[:, 1] - bounds[:, 0]\n    except IndexError:\n        diff = np.diff(bounds, axis=0)\n        return xr.DataArray(diff, dims=coord.dims, coords=coord.coords)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the surface area of each grid cell in a lon - lat grid.", "response": "def _grid_sfc_area(lon, lat, lon_bounds=None, lat_bounds=None):\n    \"\"\"Calculate surface area of each grid cell in a lon-lat grid.\"\"\"\n    # Compute the bounds if not given.\n    if lon_bounds is None:\n        lon_bounds = _bounds_from_array(\n            lon, internal_names.LON_STR, internal_names.LON_BOUNDS_STR)\n    if lat_bounds is None:\n        lat_bounds = _bounds_from_array(\n            lat, internal_names.LAT_STR, internal_names.LAT_BOUNDS_STR)\n    # Compute the surface area.\n    dlon = _diff_bounds(utils.vertcoord.to_radians(lon_bounds, is_delta=True),\n                        lon)\n    sinlat_bounds = np.sin(utils.vertcoord.to_radians(lat_bounds,\n                                                      is_delta=True))\n    dsinlat = np.abs(_diff_bounds(sinlat_bounds, lat))\n    sfc_area = dlon*dsinlat*(RADIUS_EARTH**2)\n    # Rename the coordinates such that they match the actual lat / lon.\n    try:\n        sfc_area = sfc_area.rename(\n            {internal_names.LAT_BOUNDS_STR: internal_names.LAT_STR,\n             internal_names.LON_BOUNDS_STR: internal_names.LON_STR})\n    except ValueError:\n        pass\n    # Clean up: correct names and dimension order.\n    sfc_area = sfc_area.rename(internal_names.SFC_AREA_STR)\n    sfc_area[internal_names.LAT_STR] = lat\n    sfc_area[internal_names.LON_STR] = lon\n    return sfc_area.transpose()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_grid_files(self):\n        grid_file_paths = self.grid_file_paths\n        datasets = []\n        if isinstance(grid_file_paths, str):\n            grid_file_paths = [grid_file_paths]\n        for path in grid_file_paths:\n            try:\n                ds = xr.open_dataset(path, decode_times=False)\n            except (TypeError, AttributeError):\n                ds = xr.open_mfdataset(path, decode_times=False).load()\n            except (RuntimeError, OSError) as e:\n                msg = str(e) + ': {}'.format(path)\n                raise RuntimeError(msg)\n            datasets.append(ds)\n        return tuple(datasets)", "response": "Get the files holding grid data for an aospy object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_mult_grid_attr(self):\n        grid_objs = self._get_grid_files()\n\n        if self.grid_attrs is None:\n            self.grid_attrs = {}\n\n        # Override GRID_ATTRS with entries in grid_attrs\n        attrs = internal_names.GRID_ATTRS.copy()\n        for k, v in self.grid_attrs.items():\n            if k not in attrs:\n                raise ValueError(\n                    'Unrecognized internal name, {!r}, specified for a '\n                    'custom grid attribute name.  See the full list of '\n                    'valid internal names below:\\n\\n{}'.format(\n                        k, list(internal_names.GRID_ATTRS.keys())))\n            attrs[k] = (v, )\n\n        for name_int, names_ext in attrs.items():\n            for name in names_ext:\n                grid_attr = _get_grid_attr(grid_objs, name)\n                if grid_attr is not None:\n                    TIME_STR = internal_names.TIME_STR\n                    renamed_attr = _rename_coords(grid_attr, attrs)\n                    if ((TIME_STR not in renamed_attr.dims) and\n                       (TIME_STR in renamed_attr.coords)):\n                        renamed_attr = renamed_attr.drop(TIME_STR)\n                    setattr(self, name_int, renamed_attr)\n                    break", "response": "Set multiple attributes from grid file given their names in the grid file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_grid_data(self):\n        if self._grid_data_is_set:\n            return\n        self._set_mult_grid_attr()\n        if not np.any(getattr(self, 'sfc_area', None)):\n            try:\n                sfc_area = _grid_sfc_area(self.lon, self.lat, self.lon_bounds,\n                                          self.lat_bounds)\n            except AttributeError:\n                sfc_area = _grid_sfc_area(self.lon, self.lat)\n            self.sfc_area = sfc_area\n        try:\n            self.levs_thick = utils.vertcoord.level_thickness(self.level)\n        except AttributeError:\n            self.level = None\n            self.levs_thick = None\n        self._grid_data_is_set = True", "response": "Populate the attrs that hold grid data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _other_to_lon(func):\n    def func_other_to_lon(obj, other):\n        return func(obj, _maybe_cast_to_lon(other))\n    return func_other_to_lon", "response": "Wrapper for casting Longitude operator arguments to Longitude"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an attribute from an object via a string tag.", "response": "def _get_attr_by_tag(obj, tag, attr_name):\n    \"\"\"Get attribute from an object via a string tag.\n\n    Parameters\n    ----------\n    obj : object from which to get the attribute\n    attr_name : str\n        Unmodified name of the attribute to be found.  The actual attribute\n        that is returned may be modified be 'tag'.\n    tag : str\n        Tag specifying how to modify 'attr_name' by pre-pending it with 'tag'.\n        Must be a key of the _TAG_ATTR_MODIFIERS dict.\n\n    Returns\n    -------\n    the specified attribute of obj\n    \"\"\"\n    attr_name = _TAG_ATTR_MODIFIERS[tag] + attr_name\n    return getattr(obj, attr_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a list of dicts that can be passed to Calc. Calc_permute_dicts_of_specs", "response": "def _permuted_dicts_of_specs(specs):\n    \"\"\"Create {name: value} dict, one each for every permutation.\n\n    Each permutation becomes a dictionary, with the keys being the attr names\n    and the values being the corresponding value for that permutation.  These\n    dicts can then be directly passed to the Calc constructor.\n\n    \"\"\"\n    permuter = itertools.product(*specs.values())\n    return [dict(zip(specs.keys(), perm)) for perm in permuter]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_all_objs_of_type(type_, parent):\n    return set([obj for obj in parent.__dict__.values()\n                if isinstance(obj, type_)])", "response": "Get all attributes of the given type from the given object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _prune_invalid_time_reductions(spec):\n    valid_reductions = []\n    if not spec['var'].def_time and spec['dtype_out_time'] is not None:\n        for reduction in spec['dtype_out_time']:\n            if reduction not in _TIME_DEFINED_REDUCTIONS:\n                valid_reductions.append(reduction)\n            else:\n                msg = (\"Var {0} has no time dimension \"\n                       \"for the given time reduction \"\n                       \"{1} so this calculation will \"\n                       \"be skipped\".format(spec['var'].name, reduction))\n                logging.info(msg)\n    else:\n        valid_reductions = spec['dtype_out_time']\n    return valid_reductions", "response": "Prune time reductions of spec with no time dimension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting the Calc and log exceptions and return the result.", "response": "def _compute_or_skip_on_error(calc, compute_kwargs):\n    \"\"\"Execute the Calc, catching and logging exceptions, but don't re-raise.\n\n    Prevents one failed calculation from stopping a larger requested set\n    of calculations.\n    \"\"\"\n    try:\n        return calc.compute(**compute_kwargs)\n    except Exception:\n        msg = (\"Skipping aospy calculation `{0}` due to error with the \"\n               \"following traceback: \\n{1}\")\n        logging.warning(msg.format(calc, traceback.format_exc()))\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _submit_calcs_on_client(calcs, client, func):\n    logging.info('Connected to client: {}'.format(client))\n    if LooseVersion(dask.__version__) < '0.18':\n        dask_option_setter = dask.set_options\n    else:\n        dask_option_setter = dask.config.set\n    with dask_option_setter(get=client.get):\n        return db.from_sequence(calcs).map(func).compute()", "response": "Submit calculations via dask. bag and a distributed client"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _exec_calcs(calcs, parallelize=False, client=None, **compute_kwargs):\n    if parallelize:\n        def func(calc):\n            \"\"\"Wrap _compute_or_skip_on_error to require only the calc\n            argument\"\"\"\n            if 'write_to_tar' in compute_kwargs:\n                compute_kwargs['write_to_tar'] = False\n            return _compute_or_skip_on_error(calc, compute_kwargs)\n\n        if client is None:\n            n_workers = _n_workers_for_local_cluster(calcs)\n            with distributed.LocalCluster(n_workers=n_workers) as cluster:\n                with distributed.Client(cluster) as client:\n                    result = _submit_calcs_on_client(calcs, client, func)\n        else:\n            result = _submit_calcs_on_client(calcs, client, func)\n        if compute_kwargs['write_to_tar']:\n            _serial_write_to_tar(calcs)\n        return result\n    else:\n        return [_compute_or_skip_on_error(calc, compute_kwargs)\n                for calc in calcs]", "response": "Execute the given calculations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef submit_mult_calcs(calc_suite_specs, exec_options=None):\n    if exec_options is None:\n        exec_options = dict()\n    if exec_options.pop('prompt_verify', False):\n        print(_print_suite_summary(calc_suite_specs))\n        _user_verify()\n    calc_suite = CalcSuite(calc_suite_specs)\n    calcs = calc_suite.create_calcs()\n    if not calcs:\n        raise AospyException(\n            \"The specified combination of parameters yielded zero \"\n            \"calculations.  Most likely, one of the parameters is \"\n            \"inadvertently empty.\"\n        )\n    return _exec_calcs(calcs, **exec_options)", "response": "Submit multiple computations for a single base element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_requested_spec(self, obj, spec_name):\n        requested = self._specs_in[spec_name]\n        if isinstance(requested, str):\n            return _get_attr_by_tag(obj, requested, spec_name)\n        else:\n            return requested", "response": "Helper to translate user specifications to needed objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _permute_core_specs(self):\n        obj_trees = []\n        projects = self._get_requested_spec(self._obj_lib, _PROJECTS_STR)\n        for project in projects:\n            models = self._get_requested_spec(project, _MODELS_STR)\n            for model in models:\n                runs = self._get_requested_spec(model, _RUNS_STR)\n                for run in runs:\n                    obj_trees.append({\n                        self._NAMES_SUITE_TO_CALC[_PROJECTS_STR]: project,\n                        self._NAMES_SUITE_TO_CALC[_MODELS_STR]: model,\n                        self._NAMES_SUITE_TO_CALC[_RUNS_STR]: run,\n                    })\n        return obj_trees", "response": "Generate all requested combinations of the core objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_regions(self):\n        if self._specs_in[_REGIONS_STR] == 'all':\n            return [_get_all_objs_of_type(\n                Region, getattr(self._obj_lib, 'regions', self._obj_lib)\n            )]\n        else:\n            return [set(self._specs_in[_REGIONS_STR])]", "response": "Get the requested regions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the requested variables.", "response": "def _get_variables(self):\n        \"\"\"Get the requested variables.\"\"\"\n        if self._specs_in[_VARIABLES_STR] == 'all':\n            return _get_all_objs_of_type(\n                Var, getattr(self._obj_lib, 'variables', self._obj_lib)\n            )\n        else:\n            return set(self._specs_in[_VARIABLES_STR])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_aux_specs(self):\n        # Drop the \"core\" specifications, which are handled separately.\n        specs = self._specs_in.copy()\n        [specs.pop(core) for core in self._CORE_SPEC_NAMES]\n\n        specs[_REGIONS_STR] = self._get_regions()\n        specs[_VARIABLES_STR] = self._get_variables()\n        specs['date_ranges'] = self._get_date_ranges()\n        specs['output_time_regional_reductions'] = self._get_time_reg_reducts()\n\n        return specs", "response": "Get and pre - process all of the non - core specifications."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates all permutations of the non - core specifications.", "response": "def _permute_aux_specs(self):\n        \"\"\"Generate all permutations of the non-core specifications.\"\"\"\n        # Convert to attr names that Calc is expecting.\n        calc_aux_mapping = self._NAMES_SUITE_TO_CALC.copy()\n        # Special case: manually add 'library' to mapping\n        calc_aux_mapping[_OBJ_LIB_STR] = None\n        [calc_aux_mapping.pop(core) for core in self._CORE_SPEC_NAMES]\n\n        specs = self._get_aux_specs()\n        for suite_name, calc_name in calc_aux_mapping.items():\n            specs[calc_name] = specs.pop(suite_name)\n        return _permuted_dicts_of_specs(specs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncombines permutations over core and auxilliary Calc specs.", "response": "def _combine_core_aux_specs(self):\n        \"\"\"Combine permutations over core and auxilliary Calc specs.\"\"\"\n        all_specs = []\n        for core_dict in self._permute_core_specs():\n            for aux_dict in self._permute_aux_specs():\n                all_specs.append(_merge_dicts(core_dict, aux_dict))\n        return all_specs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_calcs(self):\n        specs = self._combine_core_aux_specs()\n        for spec in specs:\n            spec['dtype_out_time'] = _prune_invalid_time_reductions(spec)\n        return [Calc(**sp) for sp in specs]", "response": "Generate a Calc object for each requested parameter combination."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data_in_label(intvl_in, dtype_in_time, dtype_in_vert=False):\n    intvl_lbl = intvl_in\n    time_lbl = dtype_in_time\n    lbl = '_'.join(['from', intvl_lbl, time_lbl]).replace('__', '_')\n    vert_lbl = dtype_in_vert if dtype_in_vert else False\n    if vert_lbl:\n        lbl = '_'.join([lbl, vert_lbl]).replace('__', '_')\n    return lbl", "response": "Create string label specifying the input data of a calculation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef time_label(intvl, return_val=True):\n    # Monthly labels are 2 digit integers: '01' for jan, '02' for feb, etc.\n    if type(intvl) in [list, tuple, np.ndarray] and len(intvl) == 1:\n        label = '{:02}'.format(intvl[0])\n        value = np.array(intvl)\n    elif type(intvl) == int and intvl in range(1, 13):\n        label = '{:02}'.format(intvl)\n        value = np.array([intvl])\n    # Seasonal and annual time labels are short strings.\n    else:\n        labels = {'jfm': (1, 2, 3),\n                  'fma': (2, 3, 4),\n                  'mam': (3, 4, 5),\n                  'amj': (4, 5, 6),\n                  'mjj': (5, 6, 7),\n                  'jja': (6,  7,  8),\n                  'jas': (7, 8, 9),\n                  'aso': (8, 9, 10),\n                  'son': (9, 10, 11),\n                  'ond': (10, 11, 12),\n                  'ndj': (11, 12, 1),\n                  'djf': (1, 2, 12),\n                  'jjas': (6, 7, 8, 9),\n                  'djfm': (12, 1, 2, 3),\n                  'ann': range(1, 13)}\n        for lbl, vals in labels.items():\n            if intvl == lbl or set(intvl) == set(vals):\n                label = lbl\n                value = np.array(vals)\n                break\n    if return_val:\n        return label, value\n    else:\n        return label", "response": "Create time interval label for aospy data I/O."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines the filename of GFDL model data output.", "response": "def data_name_gfdl(name, domain, data_type, intvl_type, data_yr,\n                   intvl, data_in_start_yr, data_in_dur):\n    \"\"\"Determine the filename of GFDL model data output.\"\"\"\n    # Determine starting year of netCDF file to be accessed.\n    extra_yrs = (data_yr - data_in_start_yr) % data_in_dur\n    data_in_yr = data_yr - extra_yrs\n    # Determine file name. Two cases: time series (ts) or time-averaged (av).\n    if data_type in ('ts', 'inst'):\n        if intvl_type == 'annual':\n            if data_in_dur == 1:\n                filename = '.'.join([domain, '{:04d}'.format(data_in_yr),\n                                     name, 'nc'])\n            else:\n                filename = '.'.join([domain, '{:04d}-{:04d}'.format(\n                    data_in_yr, data_in_yr + data_in_dur - 1\n                ), name, 'nc'])\n        elif intvl_type == 'monthly':\n            filename = (domain + '.{:04d}'.format(data_in_yr) + '01-' +\n                        '{:04d}'.format(int(data_in_yr+data_in_dur-1)) +\n                        '12.' + name + '.nc')\n        elif intvl_type == 'daily':\n            filename = (domain + '.{:04d}'.format(data_in_yr) + '0101-' +\n                        '{:04d}'.format(int(data_in_yr+data_in_dur-1)) +\n                        '1231.' + name + '.nc')\n        elif 'hr' in intvl_type:\n            filename = '.'.join(\n                [domain, '{:04d}010100-{:04d}123123'.format(\n                    data_in_yr, data_in_yr + data_in_dur - 1), name, 'nc']\n            )\n    elif data_type == 'av':\n        if intvl_type in ['annual', 'ann']:\n            label = 'ann'\n        elif intvl_type in ['seasonal', 'seas']:\n            label = intvl.upper()\n        elif intvl_type in ['monthly', 'mon']:\n            label, val = time_label(intvl)\n        if data_in_dur == 1:\n            filename = (domain + '.{:04d}'.format(data_in_yr) +\n                        '.' + label + '.nc')\n        else:\n            filename = (domain + '.{:04d}'.format(data_in_yr) + '-' +\n                        '{:04d}'.format(int(data_in_yr+data_in_dur-1)) +\n                        '.' + label + '.nc')\n    elif data_type == 'av_ts':\n        filename = (domain + '.{:04d}'.format(data_in_yr) + '-' +\n                    '{:04d}'.format(int(data_in_yr+data_in_dur-1)) +\n                    '.01-12.nc')\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall GFDL command dmget to access archived files.", "response": "def dmget(files_list):\n    \"\"\"Call GFDL command 'dmget' to access archived files.\"\"\"\n    if isinstance(files_list, str):\n        files_list = [files_list]\n\n    archive_files = []\n    for f in files_list:\n        if f.startswith('/archive'):\n            archive_files.append(f)\n    try:\n        subprocess.call(['dmget'] + archive_files)\n    except OSError:\n        logging.debug('dmget command not found in this machine')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace p and dp Vars with appropriate Var objects specific to the dtype_in_vert.", "response": "def _replace_pressure(arguments, dtype_in_vert):\n    \"\"\"Replace p and dp Vars with appropriate Var objects specific to\n    the dtype_in_vert.\"\"\"\n    arguments_out = []\n    for arg in arguments:\n        if isinstance(arg, Var):\n            if arg.name == 'p':\n                arguments_out.append(_P_VARS[dtype_in_vert])\n            elif arg.name == 'dp':\n                arguments_out.append(_DP_VARS[dtype_in_vert])\n            else:\n                arguments_out.append(arg)\n        else:\n            arguments_out.append(arg)\n    return arguments_out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd metadata attributes to Dataset or DataArray", "response": "def _add_metadata_as_attrs(data, units, description, dtype_out_vert):\n    \"\"\"Add metadata attributes to Dataset or DataArray\"\"\"\n    if isinstance(data, xr.DataArray):\n        return _add_metadata_as_attrs_da(data, units, description,\n                                         dtype_out_vert)\n    else:\n        for name, arr in data.data_vars.items():\n            _add_metadata_as_attrs_da(arr, units, description,\n                                      dtype_out_vert)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding metadata attributes to DataArray", "response": "def _add_metadata_as_attrs_da(data, units, description, dtype_out_vert):\n    \"\"\"Add metadata attributes to DataArray\"\"\"\n    if dtype_out_vert == 'vert_int':\n        if units != '':\n            units = '(vertical integral of {0}): {0} kg m^-2)'.format(units)\n        else:\n            units = '(vertical integral of quantity with unspecified units)'\n    data.attrs['units'] = units\n    data.attrs['description'] = description\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _dir_out(self):\n        return os.path.join(self.proj.direc_out, self.proj.name,\n                            self.model.name, self.run.name, self.name)", "response": "Create string of the data directory to save individual. nc files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _dir_tar_out(self):\n        return os.path.join(self.proj.tar_direc_out, self.proj.name,\n                            self.model.name, self.run.name)", "response": "Create string of the data directory to store a tar file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _file_name(self, dtype_out_time, extension='nc'):\n        if dtype_out_time is None:\n            dtype_out_time = ''\n        out_lbl = utils.io.data_out_label(self.intvl_out, dtype_out_time,\n                                          dtype_vert=self.dtype_out_vert)\n        in_lbl = utils.io.data_in_label(self.intvl_in, self.dtype_in_time,\n                                        self.dtype_in_vert)\n        start_year = utils.times.infer_year(self.start_date)\n        end_year = utils.times.infer_year(self.end_date)\n        yr_lbl = utils.io.yr_label((start_year, end_year))\n        return '.'.join(\n            [self.name, out_lbl, in_lbl, self.model.name,\n             self.run.name, yr_lbl, extension]\n        ).replace('..', '.')", "response": "Create the name of the aospy file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrestricts the xarray DataArray or Dataset to the desired months.", "response": "def _to_desired_dates(self, arr):\n        \"\"\"Restrict the xarray DataArray or Dataset to the desired months.\"\"\"\n        times = utils.times.extract_months(\n            arr[internal_names.TIME_STR], self.months\n        )\n        return arr.sel(time=times)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_grid_attributes(self, ds):\n        for name_int, names_ext in self._grid_attrs.items():\n            ds_coord_name = set(names_ext).intersection(set(ds.coords) |\n                                                        set(ds.data_vars))\n            model_attr = getattr(self.model, name_int, None)\n            if ds_coord_name and (model_attr is not None):\n                # Force coords to have desired name.\n                ds = ds.rename({list(ds_coord_name)[0]: name_int})\n                ds = ds.set_coords(name_int)\n                if not np.array_equal(ds[name_int], model_attr):\n                    if np.allclose(ds[name_int], model_attr):\n                        msg = (\"Values for '{0}' are nearly (but not exactly) \"\n                               \"the same in the Run {1} and the Model {2}.  \"\n                               \"Therefore replacing Run's values with the \"\n                               \"model's.\".format(name_int, self.run,\n                                                 self.model))\n                        logging.info(msg)\n                        ds[name_int].values = model_attr.values\n                    else:\n                        msg = (\"Model coordinates for '{0}' do not match those\"\n                               \" in Run: {1} vs. {2}\"\n                               \"\".format(name_int, ds[name_int], model_attr))\n                        logging.info(msg)\n\n            else:\n                # Bring in coord from model object if it exists.\n                ds = ds.load()\n                if model_attr is not None:\n                    ds[name_int] = model_attr\n                    ds = ds.set_coords(name_int)\n            if (self.dtype_in_vert == 'pressure' and\n                    internal_names.PLEVEL_STR in ds.coords):\n                self.pressure = ds.level\n        return ds", "response": "Add model grid attributes to a dataset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_input_data(self, var, start_date, end_date):\n        logging.info(self._print_verbose(\"Getting input data:\", var))\n\n        if isinstance(var, (float, int)):\n            return var\n        else:\n            cond_pfull = ((not hasattr(self, internal_names.PFULL_STR))\n                          and var.def_vert and\n                          self.dtype_in_vert == internal_names.ETA_STR)\n            data = self.data_loader.recursively_compute_variable(\n                var, start_date, end_date, self.time_offset, self.model,\n                **self.data_loader_attrs)\n            name = data.name\n            data = self._add_grid_attributes(data.to_dataset(name=data.name))\n            data = data[name]\n            if cond_pfull:\n                try:\n                    self.pfull_coord = data[internal_names.PFULL_STR]\n                except KeyError:\n                    pass\n            # Force all data to be at full pressure levels, not half levels.\n            bool_to_pfull = (self.dtype_in_vert == internal_names.ETA_STR and\n                             var.def_vert == internal_names.PHALF_STR)\n            if bool_to_pfull:\n                data = utils.vertcoord.to_pfull_from_phalf(data,\n                                                           self.pfull_coord)\n        if var.def_time:\n            # Restrict to the desired dates within each year.\n            if self.dtype_in_time != 'av':\n                return self._to_desired_dates(data)\n        else:\n            return data", "response": "Get the data for a single variable over the desired date range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the needed data from all of the vars in the calculation.", "response": "def _get_all_data(self, start_date, end_date):\n        \"\"\"Get the needed data from all of the vars in the calculation.\"\"\"\n        return [self._get_input_data(var, start_date, end_date)\n                for var in _replace_pressure(self.variables,\n                                             self.dtype_in_vert)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _compute_full_ts(self, data):\n        # Get results at each desired timestep and spatial point.\n        full_ts, dt = self._compute(data)\n        # Vertically integrate.\n        vert_types = ('vert_int', 'vert_av')\n        if self.dtype_out_vert in vert_types and self.var.def_vert:\n            dp = self._get_input_data(_DP_VARS[self.dtype_in_vert],\n                                      self.start_date, self.end_date)\n            full_ts = utils.vertcoord.int_dp_g(full_ts, dp)\n            if self.dtype_out_vert == 'vert_av':\n                ps = self._get_input_data(utils.vertcoord.ps,\n                                          self.start_date, self.end_date)\n                full_ts *= (GRAV_EARTH / ps)\n        return full_ts, dt", "response": "Perform calculation and create yearly timeseries at each point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _full_to_yearly_ts(self, arr, dt):\n        time_defined = self.def_time and not ('av' in self.dtype_in_time)\n        if time_defined:\n            arr = utils.times.yearly_average(arr, dt)\n        return arr", "response": "Average the full timeseries within each year."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _time_reduce(self, arr, reduction):\n        if self.dtype_in_time == 'av' or not self.def_time:\n            return arr\n        reductions = {\n            'ts': lambda xarr: xarr,\n            'av': lambda xarr: xarr.mean(internal_names.YEAR_STR),\n            'std': lambda xarr: xarr.std(internal_names.YEAR_STR),\n            }\n        try:\n            return reductions[reduction](arr)\n        except KeyError:\n            raise ValueError(\"Specified time-reduction method '{}' is not \"\n                             \"supported\".format(reduction))", "response": "Perform the specified time reduction on a local time - series."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a calculation for all regions.", "response": "def region_calcs(self, arr, func):\n        \"\"\"Perform a calculation for all regions.\"\"\"\n        # Get pressure values for data output on hybrid vertical coordinates.\n        bool_pfull = (self.def_vert and self.dtype_in_vert ==\n                      internal_names.ETA_STR and self.dtype_out_vert is False)\n        if bool_pfull:\n            pfull_data = self._get_input_data(_P_VARS[self.dtype_in_vert],\n                                              self.start_date,\n                                              self.end_date)\n            pfull = self._full_to_yearly_ts(\n                pfull_data, arr[internal_names.TIME_WEIGHTS_STR]\n            ).rename('pressure')\n        # Loop over the regions, performing the calculation.\n        reg_dat = {}\n        for reg in self.region:\n            # Just pass along the data if averaged already.\n            if 'av' in self.dtype_in_time:\n                data_out = reg.ts(arr)\n            # Otherwise perform the calculation.\n            else:\n                method = getattr(reg, func)\n                data_out = method(arr)\n                if bool_pfull:\n                    # Don't apply e.g. standard deviation to coordinates.\n                    if func not in ['av', 'ts']:\n                        method = reg.ts\n                    # Convert Pa to hPa\n                    coord = method(pfull) * 1e-2\n                    data_out = data_out.assign_coords(\n                        **{reg.name + '_pressure': coord}\n                    )\n            reg_dat.update(**{reg.name: data_out})\n        return xr.Dataset(reg_dat)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _apply_all_time_reductions(self, data):\n        logging.info(self._print_verbose(\"Applying desired time-\"\n                                         \"reduction methods.\"))\n        reduc_specs = [r.split('.') for r in self.dtype_out_time]\n        reduced = {}\n        for reduc, specs in zip(self.dtype_out_time, reduc_specs):\n            func = specs[-1]\n            if 'reg' in specs:\n                reduced.update({reduc: self.region_calcs(data, func)})\n            else:\n                reduced.update({reduc: self._time_reduce(data, func)})\n        return OrderedDict(sorted(reduced.items(), key=lambda t: t[0]))", "response": "Apply all requested time reductions to the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute(self, write_to_tar=True):\n        data = self._get_all_data(self.start_date, self.end_date)\n        logging.info('Computing timeseries for {0} -- '\n                     '{1}.'.format(self.start_date, self.end_date))\n        full, full_dt = self._compute_full_ts(data)\n        full_out = self._full_to_yearly_ts(full, full_dt)\n        reduced = self._apply_all_time_reductions(full_out)\n        logging.info(\"Writing desired gridded outputs to disk.\")\n        for dtype_time, data in reduced.items():\n            data = _add_metadata_as_attrs(data, self.var.units,\n                                          self.var.description,\n                                          self.dtype_out_vert)\n            self.save(data, dtype_time, dtype_out_vert=self.dtype_out_vert,\n                      save_files=True, write_to_tar=write_to_tar)\n        return self", "response": "Perform all desired calculations on the data and save externally."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the data to netcdf files in direc_out.", "response": "def _save_files(self, data, dtype_out_time):\n        \"\"\"Save the data to netcdf files in direc_out.\"\"\"\n        path = self.path_out[dtype_out_time]\n        if not os.path.isdir(self.dir_out):\n            os.makedirs(self.dir_out)\n        if 'reg' in dtype_out_time:\n            try:\n                reg_data = xr.open_dataset(path)\n            except (EOFError, RuntimeError, IOError):\n                reg_data = xr.Dataset()\n            reg_data.update(data)\n            data_out = reg_data\n        else:\n            data_out = data\n        if isinstance(data_out, xr.DataArray):\n            data_out = xr.Dataset({self.name: data_out})\n        data_out.to_netcdf(path, engine='netcdf4', format='NETCDF3_64BIT')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _write_to_tar(self, dtype_out_time):\n        # When submitted in parallel and the directory does not exist yet\n        # multiple processes may try to create a new directory; this leads\n        # to an OSError for all processes that tried to make the\n        # directory, but were later than the first.\n        try:\n            os.makedirs(self.dir_tar_out)\n        except OSError:\n            pass\n        # tarfile 'append' mode won't overwrite the old file, which we want.\n        # So open in 'read' mode, extract the file, and then delete it.\n        # But 'read' mode throws OSError if file doesn't exist: make it first.\n        utils.io.dmget([self.path_tar_out])\n        with tarfile.open(self.path_tar_out, 'a') as tar:\n            pass\n        with tarfile.open(self.path_tar_out, 'r') as tar:\n            old_data_path = os.path.join(self.dir_tar_out,\n                                         self.file_name[dtype_out_time])\n            try:\n                tar.extract(self.file_name[dtype_out_time],\n                            path=old_data_path)\n            except KeyError:\n                pass\n            else:\n                # The os module treats files on archive as non-empty\n                # directories, so can't use os.remove or os.rmdir.\n                shutil.rmtree(old_data_path)\n                retcode = subprocess.call([\n                    \"tar\", \"--delete\", \"--file={}\".format(self.path_tar_out),\n                    self.file_name[dtype_out_time]\n                ])\n                if retcode:\n                    msg = (\"The 'tar' command to save your aospy output \"\n                           \"exited with an error.  Most likely, this is due \"\n                           \"to using an old version of 'tar' (especially if \"\n                           \"you are on a Mac).  Consider installing a newer \"\n                           \"version of 'tar' or disabling tar output by \"\n                           \"setting `write_to_tar=False` in the \"\n                           \"`calc_exec_options` argument of \"\n                           \"`submit_mult_calcs`.\")\n                    logging.warn(msg)\n        with tarfile.open(self.path_tar_out, 'a') as tar:\n            tar.add(self.path_out[dtype_out_time],\n                    arcname=self.file_name[dtype_out_time])", "response": "Add the data to the tar file in tar_out_direc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _update_data_out(self, data, dtype):\n        try:\n            self.data_out.update({dtype: data})\n        except AttributeError:\n            self.data_out = {dtype: data}", "response": "Append the data of the given dtype_out to the data_out attr."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave data to data_out attr and to an external file.", "response": "def save(self, data, dtype_out_time, dtype_out_vert=False,\n             save_files=True, write_to_tar=False):\n        \"\"\"Save aospy data to data_out attr and to an external file.\"\"\"\n        self._update_data_out(data, dtype_out_time)\n        if save_files:\n            self._save_files(data, dtype_out_time)\n        if write_to_tar and self.proj.tar_direc_out:\n            self._write_to_tar(dtype_out_time)\n        logging.info('\\t{}'.format(self.path_out[dtype_out_time]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading aospy data saved as netcdf files on the file system.", "response": "def _load_from_disk(self, dtype_out_time, dtype_out_vert=False,\n                        region=False):\n        \"\"\"Load aospy data saved as netcdf files on the file system.\"\"\"\n        ds = xr.open_dataset(self.path_out[dtype_out_time])\n        if region:\n            arr = ds[region.name]\n            # Use region-specific pressure values if available.\n            if (self.dtype_in_vert == internal_names.ETA_STR\n                    and not dtype_out_vert):\n                reg_pfull_str = region.name + '_pressure'\n                arr = arr.drop([r for r in arr.coords.iterkeys()\n                                if r not in (internal_names.PFULL_STR,\n                                             reg_pfull_str)])\n                # Rename pfull to pfull_ref always.\n                arr = arr.rename({internal_names.PFULL_STR:\n                                  internal_names.PFULL_STR + '_ref'})\n                # Rename region_pfull to pfull if its there.\n                if hasattr(arr, reg_pfull_str):\n                    return arr.rename({reg_pfull_str:\n                                       internal_names.PFULL_STR})\n                return arr\n            return arr\n        return ds[self.name]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_from_tar(self, dtype_out_time, dtype_out_vert=False):\n        path = os.path.join(self.dir_tar_out, 'data.tar')\n        utils.io.dmget([path])\n        with tarfile.open(path, 'r') as data_tar:\n            ds = xr.open_dataset(\n                data_tar.extractfile(self.file_name[dtype_out_time])\n            )\n            return ds[self.name]", "response": "Load data from tarball form on the file system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the data from the object if possible or from disk.", "response": "def load(self, dtype_out_time, dtype_out_vert=False, region=False,\n             plot_units=False, mask_unphysical=False):\n        \"\"\"Load the data from the object if possible or from disk.\"\"\"\n        msg = (\"Loading data from disk for object={0}, dtype_out_time={1}, \"\n               \"dtype_out_vert={2}, and region=\"\n               \"{3}\".format(self, dtype_out_time, dtype_out_vert, region))\n        logging.info(msg + ' ({})'.format(ctime()))\n        # Grab from the object if its there.\n        try:\n            data = self.data_out[dtype_out_time]\n        except (AttributeError, KeyError):\n            # Otherwise get from disk.  Try scratch first, then archive.\n            try:\n                data = self._load_from_disk(dtype_out_time, dtype_out_vert,\n                                            region=region)\n            except IOError:\n                data = self._load_from_tar(dtype_out_time, dtype_out_vert)\n        # Copy the array to self.data_out for ease of future access.\n        self._update_data_out(data, dtype_out_time)\n        # Apply desired plotting/cleanup methods.\n        if mask_unphysical:\n            data = self.var.mask_unphysical(data)\n        if plot_units:\n            data = self.var.to_plot_units(data, dtype_vert=dtype_out_vert)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef conv_precip_frac(precip_largescale, precip_convective):\n    total = total_precip(precip_largescale, precip_convective)\n    # Mask using xarray's `where` method to prevent divide-by-zero.\n    return precip_convective / total.where(total)", "response": "Returns the fraction of total precip that is from convection parameterization."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping data structure to str.", "response": "def dumps(x, float_bits=DEFAULT_FLOAT_BITS):\n    \"\"\"\n    Dump data structure to str.\n\n    Here float_bits is either 32 or 64.\n    \"\"\"\n    with lock:\n        if float_bits == 32:\n            encode_func[float] = encode_float32\n        elif float_bits == 64:\n            encode_func[float] = encode_float64\n        else:\n            raise ValueError('Float bits (%d) is not 32 or 64' % float_bits)\n        r = []\n        encode_func[type(x)](x, r)\n    return b''.join(r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef join(self, words):\n        chars = list(u\"\".join(words))\n        start = True\n\n        for i in xrange(len(chars)):\n            char = chars[i]\n            if char.isalpha():\n                if start:\n                    chars[i] = char.upper()\n                else:\n                    chars[i] = char.lower()\n\n                start = False\n            else:\n                if i > 2 and chars[i - 1] in \".?!\" and char.isspace():\n                    start = True\n\n        return u\"\".join(chars)", "response": "Capitalize the first alpha character in the reply and the\n        first alpha character that follows one of [.?! and a\n        space."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start_batch_learning(self):\n        self._learning = True\n\n        self.graph.cursor().execute(\"PRAGMA journal_mode=memory\")\n        self.graph.drop_reply_indexes()", "response": "Begin a series of batch learn operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop_batch_learning(self):\n        self._learning = False\n\n        self.graph.commit()\n        self.graph.cursor().execute(\"PRAGMA journal_mode=truncate\")\n        self.graph.ensure_indexes()", "response": "Finish a series of batch learn operations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlearn a string of text.", "response": "def learn(self, text):\n        \"\"\"Learn a string of text. If the input is not already\n        Unicode, it will be decoded as utf-8.\"\"\"\n        if type(text) != types.UnicodeType:\n            # Assume that non-Unicode text is encoded as utf-8, which\n            # should be somewhat safe in the modern world.\n            text = text.decode(\"utf-8\", \"ignore\")\n\n        tokens = self.tokenizer.split(text)\n        trace(\"Brain.learn_input_token_count\", len(tokens))\n\n        self._learn_tokens(tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreply to a string of text.", "response": "def reply(self, text, loop_ms=500, max_len=None):\n        \"\"\"Reply to a string of text. If the input is not already\n        Unicode, it will be decoded as utf-8.\"\"\"\n        if type(text) != types.UnicodeType:\n            # Assume that non-Unicode text is encoded as utf-8, which\n            # should be somewhat safe in the modern world.\n            text = text.decode(\"utf-8\", \"ignore\")\n\n        tokens = self.tokenizer.split(text)\n        input_ids = map(self.graph.get_token_by_text, tokens)\n\n        # filter out unknown words and non-words from the potential pivots\n        pivot_set = self._filter_pivots(input_ids)\n\n        # Conflate the known ids with the stems of their words\n        if self.stemmer is not None:\n            self._conflate_stems(pivot_set, tokens)\n\n        # If we didn't recognize any word tokens in the input, pick\n        # something random from the database and babble.\n        if len(pivot_set) == 0:\n            pivot_set = self._babble()\n\n        score_cache = {}\n\n        best_score = -1.0\n        best_reply = None\n\n        # Loop for approximately loop_ms milliseconds. This can either\n        # take more (if the first reply takes a long time to generate)\n        # or less (if the _generate_replies search ends early) time,\n        # but it should stay roughly accurate.\n        start = time.time()\n        end = start + loop_ms * 0.001\n        count = 0\n\n        all_replies = []\n\n        _start = time.time()\n        for edges, pivot_node in self._generate_replies(pivot_set):\n            reply = Reply(self.graph, tokens, input_ids, pivot_node, edges)\n\n            if max_len and self._too_long(max_len, reply):\n                continue\n\n            key = reply.edge_ids\n            if key not in score_cache:\n                with trace_us(\"Brain.evaluate_reply_us\"):\n                    score = self.scorer.score(reply)\n                    score_cache[key] = score\n            else:\n                # skip scoring, we've already seen this reply\n                score = -1\n\n            if score > best_score:\n                best_reply = reply\n                best_score = score\n\n            # dump all replies to the console if debugging is enabled\n            if log.isEnabledFor(logging.DEBUG):\n                all_replies.append((score, reply))\n\n            count += 1\n            if time.time() > end:\n                break\n\n        if best_reply is None:\n            # we couldn't find any pivot words in _babble(), so we're\n            # working with an essentially empty brain. Use the classic\n            # MegaHAL reply:\n            return \"I don't know enough to answer you yet!\"\n\n        _time = time.time() - _start\n\n        self.scorer.end(best_reply)\n\n        if log.isEnabledFor(logging.DEBUG):\n            replies = [(score, reply.to_text())\n                       for score, reply in all_replies]\n            replies.sort()\n\n            for score, text in replies:\n                log.debug(\"%f %s\", score, text)\n\n        trace(\"Brain.reply_input_token_count\", len(tokens))\n        trace(\"Brain.known_word_token_count\", len(pivot_set))\n\n        trace(\"Brain.reply_us\", _time)\n        trace(\"Brain.reply_count\", count, _time)\n        trace(\"Brain.best_reply_score\", int(best_score * 1000))\n        trace(\"Brain.best_reply_length\", len(best_reply.edge_ids))\n\n        log.debug(\"made %d replies (%d unique) in %f seconds\"\n                  % (count, len(score_cache), _time))\n\n        if len(text) > 60:\n            msg = text[0:60] + \"...\"\n        else:\n            msg = text\n\n        log.info(\"[%s] %d %f\", msg, count, best_score)\n\n        # look up the words for these tokens\n        with trace_us(\"Brain.reply_words_lookup_us\"):\n            text = best_reply.to_text()\n\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes a brain. This function creates a graph and initializes it with the given filename.", "response": "def init(filename, order=3, tokenizer=None):\n        \"\"\"Initialize a brain. This brain's file must not already exist.\n\nKeyword arguments:\norder -- Order of the forward/reverse Markov chains (integer)\ntokenizer -- One of Cobe, MegaHAL (default Cobe). See documentation\n             for cobe.tokenizers for details. (string)\"\"\"\n        log.info(\"Initializing a cobe brain: %s\" % filename)\n\n        if tokenizer is None:\n            tokenizer = \"Cobe\"\n\n        if tokenizer not in (\"Cobe\", \"MegaHAL\"):\n            log.info(\"Unknown tokenizer: %s. Using CobeTokenizer\", tokenizer)\n            tokenizer = \"Cobe\"\n\n        graph = Graph(sqlite3.connect(filename))\n\n        with trace_us(\"Brain.init_time_us\"):\n            graph.init(order, tokenizer)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect_to_cli(server=None, as_file=True, socket_timeout=1.0, attempts=5, retry_delay=0.3):\n\t'''Returns connected CLI interface socket (as file object, unless as_file=False),\n\t\t\twhere one can send same commands (as lines) as to \"pacmd\" tool\n\t\t\tor pulseaudio startup files (e.g. \"default.pa\").\n\t\t\"server\" option can be specified to use non-standard unix socket path\n\t\t\t(when passed absolute path string) or remote tcp socket,\n\t\t\twhen passed remote host address (to use default port) or (host, port) tuple.\n\t\tBe sure to adjust \"socket_timeout\" option for tcp sockets over laggy internet.\n\t\tReturned file object has line-buffered output,\n\t\t\tso there should be no need to use flush() after every command.\n\t\tBe sure to read from the socket line-by-line until\n\t\t\t\"### EOF\" or timeout for commands that have output (e.g. \"dump\\\\n\").\n\t\tIf default server socket is used (i.e. not specified),\n\t\t\tserver pid will be signaled to load module-cli between connection attempts.\n\t\tCompletely separate protocol from the regular API, as wrapped by libpulse.\n\t\tPulseError is raised on any failure.'''\n\timport socket, errno, signal, time\n\ts, n = None, attempts if attempts > 0 else None\n\ttry:\n\t\tpid_path, sock_af, sock_t = None, socket.AF_UNIX, socket.SOCK_STREAM\n\t\tif not server: server, pid_path = map(c.pa.runtime_path, ['cli', 'pid'])\n\t\telse:\n\t\t\tif not is_list(server):\n\t\t\t\tserver = c.force_str(server)\n\t\t\t\tif not server.startswith('/'): server = server, 4712 # default port\n\t\t\tif is_list(server):\n\t\t\t\ttry:\n\t\t\t\t\taddrinfo = socket.getaddrinfo(\n\t\t\t\t\t\tserver[0], server[1], 0, sock_t, socket.IPPROTO_TCP )\n\t\t\t\t\tif not addrinfo: raise socket.gaierror('No addrinfo for socket: {}'.format(server))\n\t\t\t\texcept (socket.gaierror, socket.error) as err:\n\t\t\t\t\traise PulseError( 'Failed to resolve socket parameters'\n\t\t\t\t\t\t' (address, family) via getaddrinfo: {!r} - {} {}'.format(server, type(err), err) )\n\t\t\t\tsock_af, sock_t, _, _, server = addrinfo[0]\n\n\t\ts = socket.socket(sock_af, sock_t)\n\t\ts.settimeout(socket_timeout)\n\t\twhile True:\n\t\t\tts = c.mono_time()\n\t\t\ttry: s.connect(server)\n\t\t\texcept socket.error as err:\n\t\t\t\tif err.errno not in [errno.ECONNREFUSED, errno.ENOENT, errno.ECONNABORTED]: raise\n\t\t\telse: break\n\t\t\tif n:\n\t\t\t\tn -= 1\n\t\t\t\tif n <= 0: raise PulseError('Number of connection attempts ({}) exceeded'.format(attempts))\n\t\t\tif pid_path:\n\t\t\t\twith open(pid_path) as src: os.kill(int(src.read().strip()), signal.SIGUSR2)\n\t\t\ttime.sleep(max(0, retry_delay - (c.mono_time() - ts)))\n\n\t\tif as_file: res = s.makefile('rw', 1)\n\t\telse: res, s = s, None # to avoid closing this socket\n\t\treturn res\n\n\texcept Exception as err: # CallError, socket.error, IOError (pidfile), OSError (os.kill)\n\t\traise PulseError( 'Failed to connect to pulse'\n\t\t\t' cli socket {!r}: {} {}'.format(server, type(err), err) )\n\n\tfinally:\n\t\tif s: s.close()", "response": "Connect to a CLI interface socket."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef struct_from_value( cls, name, volume,\n\t\t\tchannel_list=None, mute=False, device=None ):\n\t\t'Same arguments as with class instance init.'\n\t\tchan_map = c.PA_CHANNEL_MAP()\n\t\tif not channel_list: c.pa.channel_map_init_mono(chan_map)\n\t\telse:\n\t\t\tif not is_str(channel_list):\n\t\t\t\tchannel_list = b','.join(map(c.force_bytes, channel_list))\n\t\t\tc.pa.channel_map_parse(chan_map, channel_list)\n\t\tif not isinstance(volume, PulseVolumeInfo):\n\t\t\tvolume = PulseVolumeInfo(volume, chan_map.channels)\n\t\tstruct = c.PA_EXT_STREAM_RESTORE_INFO(\n\t\t\tname=c.force_bytes(name),\n\t\t\tmute=int(bool(mute)), device=c.force_bytes(device),\n\t\t\tchannel_map=chan_map, volume=volume.to_struct() )\n\t\treturn struct", "response": "Same arguments as with class instance init."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect(self, autospawn=False, wait=False):\n\t\t'''Connect to pulseaudio server.\n\t\t\t\"autospawn\" option will start new pulse daemon, if necessary.\n\t\t\tSpecifying \"wait\" option will make function block until pulseaudio server appears.'''\n\t\tif self._loop_closed:\n\t\t\traise PulseError('Eventloop object was already'\n\t\t\t\t' destroyed and cannot be reused from this instance.')\n\t\tif self.connected is not None: self._ctx_init()\n\t\tflags, self.connected = 0, None\n\t\tif not autospawn: flags |= c.PA_CONTEXT_NOAUTOSPAWN\n\t\tif wait: flags |= c.PA_CONTEXT_NOFAIL\n\t\ttry: c.pa.context_connect(self._ctx, self.server, flags, None)\n\t\texcept c.pa.CallError: self.connected = False\n\t\twhile self.connected is None: self._pulse_iterate()\n\t\tif self.connected is False: raise PulseError('Failed to connect to pulseaudio server')", "response": "Connect to pulseaudio server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npulse the mainloop loop until timeout is reached.", "response": "def _pulse_poll(self, timeout=None):\n\t\t'''timeout should be in seconds (float),\n\t\t\t0 for non-blocking poll and None (default) for no timeout.'''\n\t\twith self._pulse_loop() as loop:\n\t\t\tts = c.mono_time()\n\t\t\tts_deadline = timeout and (ts + timeout)\n\t\t\twhile True:\n\t\t\t\tdelay = max(0, int((ts_deadline - ts) * 1000000)) if ts_deadline else -1\n\t\t\t\tc.pa.mainloop_prepare(loop, delay) # usec\n\t\t\t\tc.pa.mainloop_poll(loop)\n\t\t\t\tif self._loop_closed: break # interrupted by close() or such\n\t\t\t\tc.pa.mainloop_dispatch(loop)\n\t\t\t\tif self._loop_stop: break\n\t\t\t\tts = c.mono_time()\n\t\t\t\tif ts_deadline and ts >= ts_deadline: break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pulse_method_call(pulse_op, func=None, index_arg=True):\n\t\t'''Creates following synchronous wrapper for async pa_operation callable:\n\t\t\twrapper(index, ...) -> pulse_op(index, [*]args_func(...))\n\t\t\tindex_arg=False: wrapper(...) -> pulse_op([*]args_func(...))'''\n\t\tdef _wrapper(self, *args, **kws):\n\t\t\tif index_arg:\n\t\t\t\tif 'index' in kws: index = kws.pop('index')\n\t\t\t\telse: index, args = args[0], args[1:]\n\t\t\tpulse_args = func(*args, **kws) if func else list()\n\t\t\tif not is_list(pulse_args): pulse_args = [pulse_args]\n\t\t\tif index_arg: pulse_args = [index] + list(pulse_args)\n\t\t\twith self._pulse_op_cb() as cb:\n\t\t\t\ttry: pulse_op(self._ctx, *(list(pulse_args) + [cb, None]))\n\t\t\t\texcept c.ArgumentError as err: raise TypeError(err.args)\n\t\t\t\texcept c.pa.CallError as err: raise PulseOperationInvalid(err.args[-1])\n\t\tfunc_args = list(inspect.getargspec(func or (lambda: None)))\n\t\tfunc_args[0] = list(func_args[0])\n\t\tif index_arg: func_args[0] = ['index'] + func_args[0]\n\t\t_wrapper.__name__ = '...'\n\t\t_wrapper.__doc__ = 'Signature: func' + inspect.formatargspec(*func_args)\n\t\tif func.__doc__: _wrapper.__doc__ += '\\n\\n' + func.__doc__\n\t\treturn _wrapper", "response": "A function that returns a function that will be called when the pulse method is called."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stream_restore_write( obj_name_or_list,\n\t\t\tmode='merge', apply_immediately=False, **obj_kws ):\n\t\t'''Update module-stream-restore db entry for specified name.\n\t\t\tCan be passed PulseExtStreamRestoreInfo object or list of them as argument,\n\t\t\t\tor name string there and object init keywords (e.g. volume, mute, channel_list, etc).\n\t\t\t\"mode\" is PulseUpdateEnum value of\n\t\t\t\t'merge' (default), 'replace' or 'set' (replaces ALL entries!!!).'''\n\t\tmode = PulseUpdateEnum[mode]._c_val\n\t\tif is_str(obj_name_or_list):\n\t\t\tobj_name_or_list = PulseExtStreamRestoreInfo(obj_name_or_list, **obj_kws)\n\t\tif isinstance(obj_name_or_list, PulseExtStreamRestoreInfo):\n\t\t\tobj_name_or_list = [obj_name_or_list]\n\t\t# obj_array is an array of structs, laid out contiguously in memory, not pointers\n\t\tobj_array = (c.PA_EXT_STREAM_RESTORE_INFO * len(obj_name_or_list))()\n\t\tfor n, obj in enumerate(obj_name_or_list):\n\t\t\tobj_struct, dst_struct = obj.to_struct(), obj_array[n]\n\t\t\tfor k,t in obj_struct._fields_: setattr(dst_struct, k, getattr(obj_struct, k))\n\t\treturn mode, obj_array, len(obj_array), int(bool(apply_immediately))", "response": "Update module - stream - restore db entry for specified name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default_set(self, obj):\n\t\t'Set passed sink or source to be used as default one by pulseaudio server.'\n\t\tassert_pulse_object(obj)\n\t\tmethod = {\n\t\t\tPulseSinkInfo: self.sink_default_set,\n\t\t\tPulseSourceInfo: self.source_default_set }.get(type(obj))\n\t\tif not method: raise NotImplementedError(type(obj))\n\t\tmethod(obj)", "response": "Set passed sink or source to be used as default one by pulseaudio server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoing not return until the event callback or timeout passes.", "response": "def event_listen(self, timeout=None, raise_on_disconnect=True):\n\t\t'''Does not return until PulseLoopStop\n\t\t\t\tgets raised in event callback or timeout passes.\n\t\t\ttimeout should be in seconds (float),\n\t\t\t\t0 for non-blocking poll and None (default) for no timeout.\n\t\t\traise_on_disconnect causes PulseDisconnected exceptions by default.\n\t\t\tDo not run any pulse operations from these callbacks.'''\n\t\tassert self.event_callback\n\t\ttry: self._pulse_poll(timeout)\n\t\texcept c.pa.CallError: pass # e.g. from mainloop_dispatch() on disconnect\n\t\tif raise_on_disconnect and not self.connected: raise PulseDisconnected()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef event_listen_stop(self):\n\t\t'''Stop event_listen() loop from e.g. another thread.\n\t\t\tDoes nothing if libpulse poll is not running yet, so might be racey with\n\t\t\t\tevent_listen() - be sure to call it in a loop until event_listen returns or something.'''\n\t\tself._loop_stop = True\n\t\tc.pa.mainloop_wakeup(self._loop)", "response": "Stop event_listen loop from e. g. another thread."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_poll_func(self, func, func_err_handler=None):\n\t\t'''Can be used to integrate pulse client into existing eventloop.\n\t\t\tFunction will be passed a list of pollfd structs and timeout value (seconds, float),\n\t\t\t\twhich it is responsible to use and modify (set poll flags) accordingly,\n\t\t\t\treturning int value >= 0 with number of fds that had any new events within timeout.\n\t\t\tfunc_err_handler defaults to traceback.print_exception(),\n\t\t\t\tand will be called on any exceptions from callback (to e.g. log these),\n\t\t\t\treturning poll error code (-1) to libpulse after that.'''\n\t\tif not func_err_handler: func_err_handler = traceback.print_exception\n\t\tself._pa_poll_cb = c.PA_POLL_FUNC_T(ft.partial(self._pulse_poll_cb, func, func_err_handler))\n\t\tc.pa.mainloop_set_poll_func(self._loop, self._pa_poll_cb, None)", "response": "Sets a function to be called when a new event is received from the pulse client."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pulse_obj_lookup(pulse, obj_lookup, prop_default=None):\n\t'''Return set of pulse object(s) with proplist values matching lookup-string.\n\n\t\tPattern syntax:\n\t\t\t[ { 'sink' | 'source' | 'sink-input' | 'source-output' } [ / ... ] ':' ]\n\t\t\t[ proplist-key-name (non-empty) [ / ... ] ':' ] [ ':' (for regexp match) ]\n\t\t\t[ proplist-key-value ]\n\n\t\tExamples:\n\t\t\t- sink:alsa.driver_name:snd_hda_intel\n\t\t\t\tMatch sink(s) with alsa.driver_name=snd_hda_intel (exact match!).\n\t\t\t- sink/source:device.bus:pci\n\t\t\t\tMatch all sinks and sources with device.bus=pci.\n\t\t\t- myprop:somevalue\n\t\t\t\tMatch any object (of all 4 supported types) that has myprop=somevalue.\n\t\t\t- mpv\n\t\t\t\tMatch any object with any of the \"default lookup props\" (!!!) being equal to \"mpv\".\n\t\t\t\t\"default lookup props\" are specified per-type in lookup_key_defaults above.\n\t\t\t\tFor example, sink input will be looked-up by media.name, application.name, etc.\n\t\t\t- sink-input/source-output:mpv\n\t\t\t\tSame as above, but lookup streams only (not sinks/sources).\n\t\t\t\tNote that \"sink-input/source-output\" matches type spec, and parsed as such, not as key.\n\t\t\t- si/so:mpv\n\t\t\t\tSame as above - see aliases for types in lookup_types.\n\t\t\t- application.binary/application.icon:mpv\n\t\t\t\tLookup by multiple keys with \"any match\" logic, same as with multiple object types.\n\t\t\t- key\\/with\\/slashes\\:and\\:colons:somevalue\n\t\t\t\tLookup by key that has slashes and colons in it.\n\t\t\t\t\"/\" and \":\" must only be escaped in the proplist key part, used as-is in values.\n\t\t\t\tBackslash itself can be escaped as well, i.e. as \"\\\\\".\n\t\t\t- module-stream-restore.id:sink-input-by-media-role:music\n\t\t\t\tValue has \":\" in it, but there's no need to escape it in any way.\n\t\t\t- device.description::Analog\n\t\t\t\tValue lookup starting with : is interpreted as a regexp,\n\t\t\t\t\ti.e. any object with device.description *containing* \"Analog\" in this case.\n\t\t\t- si/so:application.name::^mpv\\b\n\t\t\t\tReturn all sink-inputs/source-outputs (\"si/so\") where\n\t\t\t\t\t\"application.name\" proplist value matches regexp \"^mpv\\b\".\n\t\t\t- :^mpv\\b\n\t\t\t\tRegexp lookup (stuff starting with \"mpv\" word) without type or key specification.\n\n\t\tFor python2, lookup string should be unicode type.\n\t\t\"prop_default\" keyword arg can be used to specify\n\t\t\tdefault proplist value for when key is not found there.'''\n\n\t# \\ue000-\\uf8ff - private use area, never assigned to symbols\n\tobj_lookup = obj_lookup.replace('\\\\\\\\', '\\ue000').replace('\\\\:', '\\ue001')\n\tobj_types_re = '({0})(/({0}))*'.format('|'.join(lookup_types))\n\tm = re.search(\n\t\t( r'^((?P<t>{}):)?'.format(obj_types_re) +\n\t\t\tr'((?P<k>.+?):)?' r'(?P<v>.*)$' ), obj_lookup, re.IGNORECASE )\n\tif not m: raise ValueError(obj_lookup)\n\tlookup_type, lookup_keys, lookup_re = op.itemgetter('t', 'k', 'v')(m.groupdict())\n\tif lookup_keys:\n\t\tlookup_keys = list(\n\t\t\tv.replace('\\ue000', '\\\\\\\\').replace('\\ue001', ':').replace('\\ue002', '/')\n\t\t\tfor v in lookup_keys.replace('\\\\/', '\\ue002').split('/') )\n\tlookup_re = lookup_re.replace('\\ue000', '\\\\\\\\').replace('\\ue001', '\\\\:')\n\tobj_list_res, lookup_re = list(), re.compile( lookup_re[1:]\n\t\tif lookup_re.startswith(':') else '^{}$'.format(re.escape(lookup_re)) )\n\tfor k in set( lookup_types[k] for k in\n\t\t\t(lookup_type.split('/') if lookup_type else lookup_types.keys()) ):\n\t\tif not lookup_keys: lookup_keys = lookup_key_defaults.get(k)\n\t\tif not lookup_keys: continue\n\t\tobj_list = getattr(pulse, k)()\n\t\tif not obj_list: continue\n\t\tfor obj, k in it.product(obj_list, lookup_keys):\n\t\t\tv = obj.proplist.get(k, prop_default)\n\t\t\tif v is None: continue\n\t\t\tif lookup_re.search(v): obj_list_res.append(obj)\n\treturn set(obj_list_res)", "response": "Return set of pulse object with proplist values matching lookup - string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_link(id_link, post_data):\n        '''\n        Add record in link.\n        '''\n        if MLink.get_by_uid(id_link):\n            return False\n        try:\n            the_order = int(post_data['order'])\n        except:\n            the_order = 999\n        TabLink.create(name=post_data['name'],\n                       link=post_data['link'],\n                       order=the_order,\n                       logo=post_data['logo'] if 'logo' in post_data else '',\n                       uid=id_link)\n        return id_link", "response": "Create a link record in MLink."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh(self):\n        '''\n        List the wikis of dated.\n        '''\n        kwd = {\n            'pager': '',\n            'title': '\u6700\u8fd1\u6587\u6863',\n        }\n        self.render('wiki_page/wiki_list.html',\n                    view=MWiki.query_dated(16),\n                    format_date=tools.format_date,\n                    kwd=kwd,\n                    userinfo=self.userinfo)", "response": "Refresh the wiki page with the wikis of dated."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef view_or_add(self, title):\n        '''\n        To judge if there is a post of the title.\n        Then, to show, or to add.\n        '''\n        postinfo = MWiki.get_by_wiki(title)\n        if postinfo:\n            if postinfo.kind == self.kind:\n                self.view(postinfo)\n            else:\n                return False\n        else:\n            self.to_add(title)", "response": "View or add a post."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, title=''):\n        '''\n        Add wiki\n        '''\n\n        post_data = self.get_post_data()\n\n        if title == '':\n            pass\n        else:\n            post_data['title'] = title\n        post_data['user_name'] = self.get_current_user()\n        if MWiki.get_by_wiki(post_data['title']):\n            pass\n        else:\n            MWiki.create_wiki(post_data)\n\n        tornado.ioloop.IOLoop.instance().add_callback(self.cele_gen_whoosh)\n        # cele_gen_whoosh.delay()\n\n        self.redirect('/wiki/{0}'.format(tornado.escape.url_escape(post_data['title'])))", "response": "Add wiki to the page"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef echo_html_fenye_str(rec_num, fenye_num):\n    '''\n    \u751f\u6210\u5206\u9875\u7684\u5bfc\u822a\n    '''\n\n    pagination_num = int(math.ceil(rec_num * 1.0 / 10))\n\n    if pagination_num == 1 or pagination_num == 0:\n        fenye_str = ''\n\n    elif pagination_num > 1:\n        pager_mid, pager_pre, pager_next, pager_last, pager_home = '', '', '', '', ''\n\n        fenye_str = '<ul class=\"pagination\">'\n\n        if fenye_num > 1:\n            pager_home = '''<li class=\"{0}\" name='fenye' onclick='change(this);'\n              value='{1}'><a>First Page</a></li>'''.format('', 1)\n\n            pager_pre = ''' <li class=\"{0}\" name='fenye' onclick='change(this);'\n              value='{1}'><a>Previous Page</a></li>'''.format('', fenye_num - 1)\n        if fenye_num > 5:\n            cur_num = fenye_num - 4\n        else:\n            cur_num = 1\n\n        if pagination_num > 10 and cur_num < pagination_num - 10:\n            show_num = cur_num + 10\n\n        else:\n            show_num = pagination_num + 1\n\n        for num in range(cur_num, show_num):\n            if num == fenye_num:\n                checkstr = 'active'\n            else:\n                checkstr = ''\n\n            tmp_str_df = '''<li class=\"{0}\" name='fenye' onclick='change(this);'\n              value='{1}'><a>{1}</a></li>'''.format(checkstr, num)\n\n            pager_mid += tmp_str_df\n        if fenye_num < pagination_num:\n            pager_next = '''<li class=\"{0}\" name='fenye' onclick='change(this);'\n              value='{1}'><a>Next Page</a></li>'''.format('', fenye_num + 1)\n            pager_last = '''<li class=\"{0}\" name='fenye' onclick='change(this);'\n              value='{1}'><a>End Page</a></li>'''.format('', pagination_num)\n\n        fenye_str += pager_home + pager_pre + pager_mid + pager_next + pager_last\n        fenye_str += '</ul>'\n\n    else:\n        return ''\n    return fenye_str", "response": "echo html for a single fenye"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef echo_html(self, url_str):\n        '''\n        Show the HTML\n        '''\n\n        logger.info('info echo html: {0}'.format(url_str))\n\n        condition = self.gen_redis_kw()\n\n        url_arr = self.parse_url(url_str)\n        sig = url_arr[0]\n\n        num = (len(url_arr) - 2) // 2\n\n        catinfo = MCategory.get_by_uid(sig)\n\n        if catinfo.pid == '0000':\n            condition['def_cat_pid'] = sig\n        else:\n            condition['def_cat_uid'] = sig\n\n        fenye_num = 1\n        for idx in range(num):\n            ckey = url_arr[idx * 2 + 2]\n            tval = url_arr[idx * 2 + 3]\n\n            if tval == '0':\n                continue\n            if ckey == 'fenye':\n                # \u5206\u9875\u53c2\u6570\u3002\u5355\u72ec\u5904\u7406\u3002\n                fenye_num = int(tval)\n                continue\n            else:\n                cval = tval\n            ckey = 'tag_' + ckey\n            condition[ckey] = cval\n\n        if url_arr[1] == 'con':\n            infos = MPost.query_list_pager(condition, fenye_num, kind=catinfo.kind)\n            self.echo_html_list_str(sig, infos)\n        elif url_arr[1] == 'num':\n            allinfos = MPost.query_under_condition(condition, kind=catinfo.kind)\n            self.write(\n                tornado.escape.xhtml_unescape(\n                    echo_html_fenye_str(\n                        allinfos.count(),\n                        fenye_num\n                    )\n                )\n            )", "response": "Show the HTML for the given URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists \u67e5\u8be2 \u6253\u5f00\u540e\u7684\u6e32\u67d3\u65b9\u6cd5\uff0c\u4e0d\u5305\u542b list \u7684 \u67e5\u8be2\u7ed3\u679c\u4e0e\u5206\u9875\u5bfc\u822a", "response": "def list(self, catid):\n        '''\n        \u9875\u9762\u6253\u5f00\u540e\u7684\u6e32\u67d3\u65b9\u6cd5\uff0c\u4e0d\u5305\u542b list \u7684\u67e5\u8be2\u7ed3\u679c\u4e0e\u5206\u9875\u5bfc\u822a\n        '''\n        logger.info('Infocat input: {0}'.format(catid))\n        condition = self.gen_redis_kw()\n        sig = catid\n        bread_title = ''\n        bread_crumb_nav_str = '<li>\u5f53\u524d\u4f4d\u7f6e\uff1a<a href=\"/\">\u4fe1\u606f</a></li>'\n\n        _catinfo = MCategory.get_by_uid(catid)\n        logger.info('Infocat input: {0}'.format(_catinfo))\n        if _catinfo.pid == '0000':\n            pcatinfo = _catinfo\n            catinfo = None\n            parent_id = catid\n            parent_catname = MCategory.get_by_uid(parent_id).name\n            condition['parentid'] = [parent_id]\n            catname = MCategory.get_by_uid(sig).name\n            bread_crumb_nav_str += '<li><a href=\"/list/{0}\">{1}</a></li>'.format(sig, catname)\n            bread_title = '{0}'.format(catname)\n\n        else:\n            catinfo = _catinfo\n            pcatinfo = MCategory.get_by_uid(_catinfo.pid)\n            condition['def_cat_uid'] = [sig]\n            parent_id = _catinfo.uid\n            parent_catname = MCategory.get_by_uid(parent_id).name\n            catname = MCategory.get_by_uid(sig).name\n            bread_crumb_nav_str += '<li><a href=\"/list/{0}\">{1}</a></li>'.format(\n                parent_id,\n                parent_catname\n            )\n\n            bread_crumb_nav_str += '<li><a href=\"/list/{0}\">{1}</a></li>'.format(sig, catname)\n            bread_title += '{0} - '.format(parent_catname)\n            bread_title += '{0}'.format(catname)\n\n        num = MPost.get_num_condition(condition)\n\n        kwd = {'catid': catid,\n               'daohangstr': bread_crumb_nav_str,\n               'breadtilte': bread_title,\n               'parentid': parent_id,\n               'parentlist': MCategory.get_parent_list(),\n               'condition': condition,\n               'catname': catname,\n               'rec_num': num}\n\n        # cat_rec = MCategory.get_by_uid(catid)\n        if self.get_current_user() and self.userinfo:\n            redis_kw = redisvr.smembers(CMS_CFG['redis_kw'] + self.userinfo.user_name)\n        else:\n            redis_kw = []\n        kw_condition_arr = []\n        for the_key in redis_kw:\n            kw_condition_arr.append(the_key.decode('utf-8'))\n        self.render('autogen/list/list_{0}.html'.format(catid),\n                    userinfo=self.userinfo,\n                    kwd=kwd,\n                    widget_info=kwd,\n                    condition_arr=kw_condition_arr,\n                    cat_enum=MCategory.get_qian2(parent_id[:2]),\n                    pcatinfo=pcatinfo,\n                    catinfo=catinfo)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating HTML Dic for filter.", "response": "def gen_html_dic():\n    '''\n    \u751f\u6210 Filter .\n    '''\n\n    if WORK_BOOK:\n        pass\n    else:\n        return False\n\n    html_dics = {}\n    for wk_sheet in WORK_BOOK:\n        for column in FILTER_COLUMNS:\n            kkey, kval = __write_filter_dic(wk_sheet, column)\n            if kkey:\n                html_dics[kkey] = kval\n\n    return html_dics"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the array of the switcher form XLXS file.", "response": "def gen_array_crud():\n    '''\n    Return the dictionay of the switcher form XLXS file.\n    if valud of the column of the row is `1`,  it will be added to the array.\n    '''\n    if WORK_BOOK:\n        pass\n    else:\n        return False\n\n    papa_id = 0\n\n    switch_dics = {}\n    kind_dics = {}\n\n    for work_sheet in WORK_BOOK:\n        kind_sig = str(work_sheet['A1'].value).strip()\n        # the number of the categories in a website won't greater than 1000.\n        for row_num in range(3, 1000):\n            # \u7236\u7c7b, column A\n            a_cell_value = work_sheet['A{0}'.format(row_num)].value\n            # \u5b50\u7c7b, column B\n            b_cell_val = work_sheet['B{0}'.format(row_num)].value\n\n            if a_cell_value or b_cell_val:\n                pass\n            else:\n                break\n            if a_cell_value and a_cell_value != '':\n                papa_id = a_cell_value.strip()[1:]\n                u_dic = __get_switch_arr(work_sheet, row_num)\n                switch_dics['dic_{0}00'.format(papa_id)] = u_dic\n                kind_dics['kind_{0}00'.format(papa_id)] = kind_sig\n            if b_cell_val and b_cell_val != '':\n                sun_id = b_cell_val.strip()[1:]\n                if len(sun_id) == 4:\n                    app_uid = sun_id\n                else:\n                    app_uid = '{0}{1}'.format(papa_id, sun_id)\n                u_dic = __get_switch_arr(work_sheet, row_num)\n                switch_dics['dic_{0}'.format(app_uid)] = u_dic\n                kind_dics['kind_{0}'.format(app_uid)] = kind_sig\n\n    return (switch_dics, kind_dics)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the array of switcher entries.", "response": "def __get_switch_arr(work_sheet, row_num):\n    '''\n    if valud of the column of the row is `1`,  it will be added to the array.\n    '''\n\n    u_dic = []\n    for col_idx in FILTER_COLUMNS:\n        cell_val = work_sheet['{0}{1}'.format(col_idx, row_num)].value\n        if cell_val in [1, '1']:\n            # Appending the slug name of the switcher.\n            u_dic.append(work_sheet['{0}1'.format(col_idx)].value.strip().split(',')[0])\n    return u_dic"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd or update the record if new else update it.", "response": "def add_or_update(user_id, post_id, kind):\n        '''\n        Create the record if new, else update it.\n        '''\n\n        rec = MUsage.query_by_signature(user_id, post_id)\n        cate_rec = MInfor2Catalog.get_first_category(post_id)\n        if cate_rec:\n            cat_id = cate_rec.tag_id\n        else:\n            return False\n\n        if rec.count() > 0:\n            logger.info('Usage update: {uid}'.format(uid=post_id))\n            rec = rec.get()\n            query = TabUsage.update(kind=kind).where(TabUsage.uid == rec.uid)\n            query.execute()\n            MUsage.count_increate(rec.uid, cat_id, rec.count)\n        else:\n            logger.info('Usage create: {uid}'.format(uid=post_id))\n            TabUsage.create(\n                uid=tools.get_uuid(),\n                post_id=post_id,\n                user_id=user_id,\n                count=1,\n                tag_id=cat_id,\n                timestamp=int(time.time()),\n                kind=kind,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_send_all(*args):\n    '''\n    Send email to all user.\n    '''\n    for user_rec in MUser.query_all():\n        email_add = user_rec.user_email\n        send_mail([email_add],\n                  \"{0}|{1}\".format(SMTP_CFG['name'], email_cfg['title']),\n                  email_cfg['content'])", "response": "Send email to all users."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending email to who not logged in recently.", "response": "def run_send_nologin(*args):\n    '''\n    Send email to who not logged in recently.\n    '''\n    for user_rec in MUser.query_nologin():\n        email_add = user_rec.user_email\n        print(email_add)\n        send_mail([email_add],\n                  \"{0}|{1}\".format(SMTP_CFG['name'], email_cfg['title']),\n                  email_cfg['content'])\n        MUser.set_sendemail_time(user_rec.uid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gen_xlsx_category():\n    '''\n    Genereting catetory from xlsx file.\n    '''\n    if os.path.exists(XLSX_FILE):\n        pass\n    else:\n        return\n    # \u5728\u5206\u7c7b\u4e2d\u6392\u5e8f\n    order_index = 1\n\n    all_cate_arr = []\n\n    for sheet_ranges in load_workbook(filename=XLSX_FILE):\n        kind_sig = str(sheet_ranges['A1'].value).strip()\n\n        for row_num in range(3, 10000):\n\n            # \u7236\u7c7b\n            a_cell_val = sheet_ranges['A{0}'.format(row_num)].value\n            b_cell_val = sheet_ranges['B{0}'.format(row_num)].value\n            c_cell_val = sheet_ranges['C{0}'.format(row_num)].value\n\n\n            if a_cell_val or b_cell_val or c_cell_val:\n                pass\n            else:\n                break\n\n            if a_cell_val and a_cell_val != '':\n                cell_arr = a_cell_val.strip()\n                p_uid = cell_arr[1:]  # \u6240\u6709\u4ee5 t \u5f00\u5934\n                t_slug = sheet_ranges['C{0}'.format(row_num)].value.strip()\n                t_title = sheet_ranges['D{0}'.format(row_num)].value.strip()\n                u_uid = p_uid + (4 - len(p_uid)) * '0'\n                pp_uid = '0000'\n            elif b_cell_val and b_cell_val != '':\n                cell_arr = b_cell_val\n                c_iud = cell_arr[1:]\n                t_slug = sheet_ranges['C{0}'.format(row_num)].value.strip()\n                t_title = sheet_ranges['D{0}'.format(row_num)].value.strip()\n                if len(c_iud) == 4:\n                    u_uid = c_iud\n                else:\n                    u_uid = '{0}{1}'.format(p_uid, c_iud)\n                pp_uid = p_uid + (4 - len(p_uid)) * '0'\n            else:\n                continue\n\n            post_data = {\n                'name': t_title,\n                'slug': t_slug,\n                'order': order_index,\n                'uid': u_uid,\n                'pid': pp_uid,\n                'kind': kind_sig,\n            }\n            all_cate_arr.append(post_data)\n            MCategory.add_or_update(u_uid, post_data)\n            order_index += 1\n    return all_cate_arr", "response": "Generate a category from an Excel file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a category from a YAML file.", "response": "def gen_category(yaml_file, sig):\n    '''\n    Genereting catetory from YAML file.\n    '''\n\n    out_dic = yaml.load(open(yaml_file))\n\n    for key in out_dic:\n\n        if key.endswith('00'):\n            uid = key[1:]\n            cur_dic = out_dic[key]\n            porder = cur_dic['order']\n            cat_dic = {\n                'uid': uid,\n                'slug': cur_dic['slug'],\n                'name': cur_dic['name'],\n                'count': 0,\n                'tmpl': 1,\n                'pid': '0000',\n                'order': porder * 100,\n                'kind': '{0}'.format(sig),\n            }\n\n            MCategory.add_or_update(uid, cat_dic)\n        else:\n            sub_arr = out_dic[key]\n            pid = key[1:3]\n\n            for sub_dic in sub_arr:\n                porder = out_dic['z' + pid + '00']['order']\n\n                for key2 in sub_dic:\n                    uid = key2[1:]\n\n                    cur_dic = sub_dic[key2]\n\n                    sorder = cur_dic['order']\n                    cat_dic = {\n                        'uid': uid,\n                        'slug': cur_dic['slug'],\n                        'name': cur_dic['name'],\n                        'count': 0,\n                        'tmpl': 1,\n                        'pid': pid + '00',\n                        'order': porder * 100 + sorder,\n                        'kind': '{0}'.format(sig),\n                    }\n\n                    MCategory.add_or_update(pid + uid, cat_dic)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the difference as the table format.", "response": "def diff_table(rawinfo, newinfo):\n    '''\n    Generate the difference as the table format.\n    :param rawinfo:\n    :param newinfo:\n    :return:\n    '''\n    return HtmlDiff.make_table(HtmlDiff(), rawinfo.split('\\n'), newinfo.split('\\n'),\n                               context=True,\n                               numlines=1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef markdown2html(markdown_text):\n    '''\n    Convert markdown text to HTML. with extensions.\n    :param markdown_text:   The markdown text.\n    :return:  The HTML text.\n    '''\n    html = markdown.markdown(\n        markdown_text,\n        extensions=[\n            WikiLinkExtension(base_url='/wiki/', end_url=''),\n            'markdown.extensions.extra',\n            'markdown.extensions.toc',\n            'markdown.extensions.codehilite',\n            'markdown.extensions.meta'\n        ]\n    )\n    han_biaodians = ['\u3002', '\uff0c', '\uff1b', '\u3001', '\uff01', '\uff1f']\n    for han_biaodian in han_biaodians:\n        html = html.replace(han_biaodian + '\\n', han_biaodian)\n    return tornado.escape.xhtml_escape(html)", "response": "Convert markdown text to HTML."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a single page of purecss.", "response": "def gen_pager_purecss(cat_slug, page_num, current):\n    '''\n    Generate pager of purecss.\n    '''\n    if page_num == 1:\n        return ''\n\n    pager_shouye = '''<li class=\"pure-menu-item {0}\">\n    <a class=\"pure-menu-link\" href=\"{1}\">&lt;&lt; \u9996\u9875</a></li>'''.format(\n        'hidden' if current <= 1 else '', cat_slug\n    )\n\n    pager_pre = '''<li class=\"pure-menu-item {0}\">\n                <a class=\"pure-menu-link\" href=\"{1}/{2}\">&lt; \u524d\u9875</a>\n                </li>'''.format('hidden' if current <= 1 else '',\n                                cat_slug,\n                                current - 1)\n    pager_mid = ''\n    for ind in range(0, page_num):\n        tmp_mid = '''<li class=\"pure-menu-item {0}\">\n                <a class=\"pure-menu-link\" href=\"{1}/{2}\">{2}</a></li>\n                '''.format('selected' if ind + 1 == current else '',\n                           cat_slug,\n                           ind + 1)\n        pager_mid += tmp_mid\n    pager_next = '''<li class=\"pure-menu-item {0}\">\n                <a class=\"pure-menu-link\" href=\"{1}/{2}\">\u540e\u9875 &gt;</a>\n                </li> '''.format('hidden' if current >= page_num else '',\n                                 cat_slug,\n                                 current + 1)\n    pager_last = '''<li class=\"pure-menu-item {0}\">\n                <a hclass=\"pure-menu-link\" ref=\"{1}/{2}\">\u672b\u9875\n                &gt;&gt;</a>\n                </li> '''.format('hidden' if current >= page_num else '',\n                                 cat_slug,\n                                 page_num)\n    pager = pager_shouye + pager_pre + pager_mid + pager_next + pager_last\n    return pager"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the configure value.", "response": "def get_cfg():\n    '''\n    Get the configure value.\n    '''\n\n    cfg_var = dir(cfg)\n\n    if 'DB_CFG' in cfg_var:\n        db_cfg = cfg.DB_CFG\n    else:\n        db_cfg = ConfigDefault.DB_CFG\n\n    if 'SMTP_CFG' in cfg_var:\n        smtp_cfg = cfg.SMTP_CFG\n    else:\n        smtp_cfg = ConfigDefault.SMTP_CFG\n\n    if 'SITE_CFG' in cfg_var:\n        site_cfg = cfg.SITE_CFG\n    else:\n        site_cfg = ConfigDefault.SITE_CFG\n\n    if 'ROLE_CFG' in cfg_var:\n        role_cfg = cfg.ROLE_CFG\n    else:\n        role_cfg = ConfigDefault.ROLE_CFG\n\n    role_cfg['view'] = role_cfg.get('view', '')\n    role_cfg['add'] = role_cfg.get('add', '1000')\n    role_cfg['edit'] = role_cfg.get('edit', '2000')\n    role_cfg['delete'] = role_cfg.get('delete', '3000')\n    role_cfg['admin'] = role_cfg.get('admin', '0300')\n\n    ###################################################################\n\n    site_url = site_cfg['site_url'].strip('/')\n    site_cfg['site_url'] = site_url\n    infor = site_url.split(':')\n    if len(infor) == 1:\n        site_cfg['PORT'] = 8888\n    else:\n        site_cfg['PORT'] = infor[-1]\n\n    if 'DEBUG' in site_cfg:\n        pass\n    else:\n        site_cfg['DEBUG'] = False\n\n    db_con = PostgresqlExtDatabase(\n        db_cfg['db'],\n        user=db_cfg.get('user', db_cfg['db']),\n        password=db_cfg['pass'],\n        host='127.0.0.1',\n        port=db_cfg.get('port', '5432'),\n        autocommit=True,\n        autorollback=True)\n\n    return (db_con, smtp_cfg, site_cfg, role_cfg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest if the user could edit the page.", "response": "def __could_edit(self, slug):\n        '''\n        Test if the user could edit the page.\n        '''\n        page_rec = MWiki.get_by_uid(slug)\n        if not page_rec:\n            return False\n        if self.check_post_role()['EDIT']:\n            return True\n        elif page_rec.user_name == self.userinfo.user_name:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to modify the page.", "response": "def to_modify(self, uid):\n        '''\n        Try to modify the page.\n        '''\n\n        kwd = {\n            'pager': '',\n\n        }\n        self.render('wiki_page/page_edit.html',\n                    postinfo=MWiki.get_by_uid(uid),\n                    kwd=kwd,\n                    cfg=CMS_CFG,\n                    userinfo=self.userinfo)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncounting plus one via ajax.", "response": "def ajax_count_plus(self, slug):\n        '''\n        post count plus one via ajax.\n        '''\n        output = {\n            'status': 1 if MWiki.view_count_plus(slug) else 0,\n        }\n\n        return json.dump(output, self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(self):\n        '''\n        View the list of the pages.\n        '''\n        kwd = {\n            'pager': '',\n            'title': '\u5355\u9875\u5217\u8868',\n        }\n        self.render('wiki_page/page_list.html',\n                    kwd=kwd,\n                    view=MWiki.query_recent(),\n                    view_all=MWiki.query_all(),\n                    format_date=tools.format_date,\n                    userinfo=self.userinfo,\n                    cfg=CMS_CFG)", "response": "View the list of the pages."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd new log entry", "response": "def add(self, **kwargs):\n        '''\n        in infor.\n        '''\n\n        post_data = {}\n\n        for key in self.request.arguments:\n            post_data[key] = self.get_arguments(key)[0]\n\n        MLog.add(post_data)\n        kwargs.pop('uid', None)  # delete `uid` if exists in kwargs\n\n        self.redirect('/log/')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list(self, cur_p=''):\n        '''\n        View the list of the Log.\n        '''\n\n        if cur_p == '':\n            current_page_number = 1\n        else:\n            current_page_number = int(cur_p)\n\n        current_page_number = 1 if current_page_number < 1 else current_page_number\n\n        pager_num = int(MLog.total_number() / CMS_CFG['list_num'])\n        kwd = {\n            'pager': '',\n            'title': '',\n            'current_page': current_page_number,\n        }\n\n        if self.is_p:\n            self.render('admin/log_ajax/user_list.html',\n                        kwd=kwd,\n                        user_list=MLog.query_all_user(),\n                        no_user_list=MLog.query_all(current_page_num=current_page_number),\n                        format_date=tools.format_date,\n                        userinfo=self.userinfo)\n        else:\n            self.render('misc/log/user_list.html',\n                        kwd=kwd,\n                        user_list=MLog.query_all_user(),\n                        no_user_list=MLog.query_all(current_page_num=current_page_number),\n                        format_date=tools.format_date,\n                        userinfo=self.userinfo)", "response": "View the list of the Log."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nviews the list of the Log.", "response": "def user_log_list(self, userid, cur_p=''):\n        '''\n        View the list of the Log.\n        '''\n\n        if cur_p == '':\n            current_page_number = 1\n        else:\n            current_page_number = int(cur_p)\n\n        current_page_number = 1 if current_page_number < 1 else current_page_number\n\n        pager_num = int(MLog.total_number() / CMS_CFG['list_num'])\n        kwd = {\n            'pager': '',\n            'title': '',\n            'current_page': current_page_number,\n            'user_id': userid,\n        }\n\n        if self.is_p:\n            self.render('admin/log_ajax/user_log_list.html',\n                        kwd=kwd,\n                        infos=MLog.query_pager_by_user(\n                            userid,\n                            current_page_num=current_page_number\n                        ),\n                        format_date=tools.format_date,\n                        userinfo=self.userinfo)\n        else:\n            self.render('misc/log/user_log_list.html',\n                        kwd=kwd,\n                        infos=MLog.query_pager_by_user(\n                            userid,\n                            current_page_num=current_page_number\n                        ),\n                        format_date=tools.format_date,\n                        userinfo=self.userinfo)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pageview(self, cur_p=''):\n        '''\n        View the list of the Log.\n        '''\n\n        if cur_p == '':\n            current_page_number = 1\n        else:\n            current_page_number = int(cur_p)\n\n        current_page_number = 1 if current_page_number < 1 else current_page_number\n\n        pager_num = int(MLog.total_number() / CMS_CFG['list_num'])\n\n        kwd = {\n            'pager': '',\n            'title': '',\n            'current_page': current_page_number,\n        }\n        arr_num = []\n        postinfo = MLog.query_all_current_url()\n\n        for i in postinfo:\n            postnum = MLog.count_of_current_url(i.current_url)\n            arr_num.append(postnum)\n\n        self.render('misc/log/pageview.html',\n                    kwd=kwd,\n                    infos=MLog.query_all_pageview(current_page_num=current_page_number),\n                    postinfo=postinfo,\n                    arr_num=arr_num,\n                    format_date=tools.format_date,\n                    userinfo=self.userinfo)", "response": "View the list of the Log."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_cnt(uid, post_data):\n        '''\n        Update the content by ID.\n        '''\n        entry = TabPostHist.update(\n            user_name=post_data['user_name'],\n            cnt_md=tornado.escape.xhtml_escape(post_data['cnt_md']),\n            time_update=tools.timestamp(),\n        ).where(TabPostHist.uid == uid)\n        entry.execute()", "response": "Update the content by ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_by_postid(postid, limit=5):\n        '''\n        Query history of certian records.\n        '''\n        recs = TabPostHist.select().where(\n            TabPostHist.post_id == postid\n        ).order_by(\n            TabPostHist.time_update.desc()\n        ).limit(limit)\n        return recs", "response": "Query certian records by post id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the last record in the record table.", "response": "def get_last(postid, limit=10):\n        '''\n        Get the last one of the records.\n        '''\n        recs = TabPostHist.select().where(\n            TabPostHist.post_id == postid\n        ).order_by(TabPostHist.time_update.desc()).limit(limit)\n        if recs.count():\n            return recs.get()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the history of certain post.", "response": "def create_post_history(raw_data):\n        '''\n        Create the history of certain post.\n        '''\n        uid = tools.get_uuid()\n        TabPostHist.create(\n            uid=uid,\n            title=raw_data.title,\n            post_id=raw_data.uid,\n            user_name=raw_data.user_name,\n            cnt_md=raw_data.cnt_md,\n            time_update=tools.timestamp(),\n            logo=raw_data.logo,\n        )\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting posts of certain catid. In Json. \u6839\u636e\u5206\u7c7bID\uff08catid\uff09\u83b7\u53d6 \u8be5\u5206\u7c7b\u4e0b post \u7684\u76f8\u5173\u4fe1\u606f\uff0c\u8fd4\u56deJson\u683c\u5f0f", "response": "def ajax_list_catalog(self, catid):\n        '''\n        Get posts of certain catid. In Json.\n\n        \u6839\u636e\u5206\u7c7bID\uff08catid\uff09\u83b7\u53d6 \u8be5\u5206\u7c7b\u4e0b post \u7684\u76f8\u5173\u4fe1\u606f\uff0c\u8fd4\u56deJson\u683c\u5f0f\n        '''\n        out_arr = {}\n        for catinfo in MPost2Catalog.query_postinfo_by_cat(catid):\n            out_arr[catinfo.uid] = catinfo.title\n\n        json.dump(out_arr, self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the sub category. ToDo : The menu should display by order. Error fond in DRR.", "response": "def ajax_subcat_arr(self, pid):\n        '''\n        Get the sub category.\n        ToDo: The menu should display by order. Error fond in DRR.\n\n        \u6839\u636e\u7236\u7c7bID\uff08pid\uff09\u83b7\u53d6\u5b50\u7c7b\uff0c\u8fd4\u56deJson\u683c\u5f0f\n        '''\n        out_arr = {}\n        for catinfo in MCategory.query_sub_cat(pid):\n            out_arr[catinfo.uid] = catinfo.name\n        json.dump(out_arr, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ajax_kindcat_arr(self, kind_sig):\n        '''\n        Get the sub category.\n\n        \u6839\u636ekind\u503c\uff08kind_sig\uff09\u83b7\u53d6\u76f8\u5e94\u5206\u7c7b\uff0c\u8fd4\u56deJson\u683c\u5f0f\n        '''\n        out_arr = {}\n        for catinfo in MCategory.query_kind_cat(kind_sig):\n            out_arr[catinfo.uid] = catinfo.name\n        json.dump(out_arr, self)", "response": "Get the sub category.\n            \u6839\u636e kind_sig \u83b7\u53d6\u76f8\u5e94\u5206\u7c7b\uff0c\u8fd4\u56deJson\u683c\u5f0f"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_catalog(self, cat_slug, **kwargs):\n        '''\n        listing the posts via category\n\n        \u6839\u636e\u5206\u7c7b\uff08cat_slug\uff09\u663e\u793a\u5206\u7c7b\u5217\u8868\n        '''\n        post_data = self.get_post_data()\n        tag = post_data.get('tag', '')\n\n        def get_pager_idx():\n            '''\n            Get the pager index.\n            '''\n            cur_p = kwargs.get('cur_p')\n            the_num = int(cur_p) if cur_p else 1\n            the_num = 1 if the_num < 1 else the_num\n            return the_num\n\n        current_page_num = get_pager_idx()\n        cat_rec = MCategory.get_by_slug(cat_slug)\n        if not cat_rec:\n            return False\n\n        num_of_cat = MPost2Catalog.count_of_certain_category(cat_rec.uid, tag=tag)\n\n        page_num = int(num_of_cat / CMS_CFG['list_num']) + 1\n        cat_name = cat_rec.name\n        kwd = {'cat_name': cat_name,\n               'cat_slug': cat_slug,\n               'title': cat_name,\n               'router': router_post[cat_rec.kind],\n               'current_page': current_page_num,\n               'kind': cat_rec.kind,\n               'tag': tag}\n\n\n        # Todo: review the following codes.\n\n\n        if self.order:\n            tmpl = 'list/catalog_list.html'\n        else:\n            tmpl = 'list/category_list.html'\n\n        infos = MPost2Catalog.query_pager_by_slug(\n            cat_slug,\n            current_page_num,\n            tag=tag,\n            order=self.order\n        )\n\n        # ToDo: `gen_pager_purecss` should not use any more.\n        self.render(tmpl,\n                    catinfo=cat_rec,\n                    infos=infos,\n                    pager=tools.gen_pager_purecss(\n                        '/list/{0}'.format(cat_slug),\n                        page_num,\n                        current_page_num),\n                    userinfo=self.userinfo,\n                    html2text=html2text,\n                    cfg=CMS_CFG,\n                    kwd=kwd,\n                    router=router_post[cat_rec.kind])", "response": "List the posts via category."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_mail(to_list, sub, content, cc=None):\n    '''\n    Sending email via Python.\n    '''\n    sender = SMTP_CFG['name'] + \"<\" + SMTP_CFG['user'] + \">\"\n    msg = MIMEText(content, _subtype='html', _charset='utf-8')\n    msg['Subject'] = sub\n    msg['From'] = sender\n    msg['To'] = \";\".join(to_list)\n    if cc:\n        msg['cc'] = ';'.join(cc)\n    try:\n        # Using SMTP_SSL. The alinyun ECS has masked the 25 port since 9,2016.\n        smtper = smtplib.SMTP_SSL(SMTP_CFG['host'], port=994)\n        smtper.login(SMTP_CFG['user'], SMTP_CFG['pass'])\n        smtper.sendmail(sender, to_list, msg.as_string())\n        smtper.close()\n        return True\n    except:\n        return False", "response": "Send an email via Python."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gen_pager_bootstrap_url(cat_slug, page_num, current):\n    '''\n    pager for searching results.\n    '''\n    pager = ''\n    if page_num == 1 or page_num == 0:\n        pager = ''\n    elif page_num > 1:\n        pager_mid, pager_pre, pager_next, pager_last, pager_home = '', '', '', '', ''\n\n        pager = '<ul class=\"pagination\">'\n\n        if current > 1:\n            pager_home = '''<li class=\"{0}\" name='fenye' onclick='change(this);'>\n                <a href=\"{1}/{2}\">\u9996\u9875</a></li>'''.format('', cat_slug, 1)\n\n            pager_pre = ''' <li class=\"{0}\" name='fenye' onclick='change(this);'>\n                <a href=\"{1}/{2}\">\u4e0a\u4e00\u9875</a></li>'''.format('', cat_slug, current - 1)\n        if current > 5:\n            cur_num = current - 4\n        else:\n            cur_num = 1\n\n        if page_num > 10 and cur_num < page_num - 10:\n            show_num = cur_num + 10\n\n        else:\n            show_num = page_num + 1\n\n        for num in range(cur_num, show_num):\n            if num == current:\n                checkstr = 'active'\n            else:\n                checkstr = ''\n\n            tmp_str_df = '''<li class=\"{0}\" name='fenye' onclick='change(this);'>\n                  <a href=\"{1}/{2}\">{2}</a></li>'''.format(checkstr, cat_slug, num)\n\n            pager_mid += tmp_str_df\n        if current < page_num:\n            pager_next = '''\n\n                  <li class=\"{0}\" name='fenye' onclick='change(this);'\n                  ><a href=\"{1}/{2}\">\u4e0b\u4e00\u9875</a></li>'''.format('', cat_slug, current + 1)\n            pager_last = '''\n\n                  <li class=\"{0}\" name='fenye' onclick='change(this);'\n                 ><a href=\"{1}/{2}\">\u672b\u9875</a></li>'''.format('', cat_slug, page_num)\n\n        pager += pager_home + pager_pre + pager_mid + pager_next + pager_last\n        pager += '</ul>'\n    else:\n        pass\n\n    return pager", "response": "Generate a bootstrap url for the page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_cat(self, catid, keyword, p_index=1):\n        '''\n        Searching according the kind.\n        '''\n        catid = 'sid' + catid\n        logger.info('-' * 20)\n        logger.info('search cat')\n        logger.info('catid: {0}'.format(catid))\n        logger.info('keyword: {0}'.format(keyword))\n\n        # catid = ''\n        if p_index == '' or p_index == '-1':\n            current_page_number = 1\n        else:\n            current_page_number = int(p_index)\n        res_all = self.ysearch.get_all_num(keyword, catid=catid)\n\n        results = self.ysearch.search_pager(\n            keyword,\n            catid=catid,\n            page_index=current_page_number,\n            doc_per_page=CMS_CFG['list_num']\n        )\n        page_num = int(res_all / CMS_CFG['list_num'])\n\n        kwd = {'title': '\u67e5\u627e\u7ed3\u679c',\n               'pager': '',\n               'count': res_all,\n               'current_page': current_page_number,\n               'catid': catid,\n               'keyword': keyword}\n\n        self.render('misc/search/search_list.html',\n                    kwd=kwd,\n                    srecs=results,\n                    pager=gen_pager_bootstrap_url(\n                        '/search/{0}/{1}'.format(catid, keyword),\n                        page_num,\n                        current_page_number\n                    ),\n                    userinfo=self.userinfo,\n                    cfg=CMS_CFG)", "response": "Search the list of all the related objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist posts that recent edited, partially.", "response": "def p_recent(self, kind, cur_p='', with_catalog=True, with_date=True):\n        '''\n        List posts that recent edited, partially.\n        '''\n        if cur_p == '':\n            current_page_number = 1\n        else:\n            current_page_number = int(cur_p)\n\n        current_page_number = 1 if current_page_number < 1 else current_page_number\n\n        pager_num = int(MPost.total_number(kind) / CMS_CFG['list_num'])\n        kwd = {\n            'pager': '',\n            'title': 'Recent posts.',\n            'with_catalog': with_catalog,\n            'with_date': with_date,\n            'kind': kind,\n            'current_page': current_page_number,\n            'post_count': MPost.get_counts(),\n            'router': config.router_post[kind],\n        }\n        self.render('admin/post_ajax/post_list.html',\n                    kwd=kwd,\n                    view=MPost.query_recent(num=20, kind=kind),\n                    infos=MPost.query_pager_by_slug(\n                        kind=kind,\n                        current_page_num=current_page_number\n                    ),\n                    format_date=tools.format_date,\n                    userinfo=self.userinfo,\n                    cfg=CMS_CFG, )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting the post but return the JSON.", "response": "def j_delete(self, *args):\n        '''\n        Delete the post, but return the JSON.\n        '''\n\n        uid = args[0]\n\n        current_infor = MPost.get_by_uid(uid)\n        tslug = MCategory.get_by_uid(current_infor.extinfo['def_cat_uid'])\n        is_deleted = MPost.delete(uid)\n        MCategory.update_count(current_infor.extinfo['def_cat_uid'])\n        if is_deleted:\n            output = {\n                'del_info': 1,\n                'cat_slug': tslug.slug,\n                'cat_id': tslug.uid,\n                'kind': current_infor.kind\n\n            }\n        else:\n            output = {\n                'del_info': 0,\n            }\n        return json.dump(output, self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning to init tables.", "response": "def run_init_tables(*args):\n    '''\n    Run to init tables.\n    '''\n    print('--')\n\n    create_table(TabPost)\n    create_table(TabTag)\n    create_table(TabMember)\n    create_table(TabWiki)\n    create_table(TabLink)\n    create_table(TabEntity)\n    create_table(TabPostHist)\n    create_table(TabWikiHist)\n    create_table(TabCollect)\n    create_table(TabPost2Tag)\n    create_table(TabRel)\n    create_table(TabEvaluation)\n    create_table(TabUsage)\n    create_table(TabReply)\n    create_table(TabUser2Reply)\n    create_table(TabRating)\n    create_table(TabEntity2User)\n    create_table(TabLog)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist the entities of the user.", "response": "def all_list(self, cur_p=''):\n        '''\n        List the entities of the user.\n        '''\n        # ToDo: \u4ee3\u7801\u4e0e entity_handler \u4e2d list \u65b9\u6cd5\u6709\u91cd\u590d\n        current_page_number = int(cur_p) if cur_p else 1\n        current_page_number = 1 if current_page_number < 1 else current_page_number\n\n        kwd = {\n            'current_page': current_page_number\n        }\n\n        recs = MEntity2User.get_all_pager(current_page_num=current_page_number).objects()\n        self.render('misc/entity/entity_download.html',\n                    imgs=recs,\n                    cfg=config.CMS_CFG,\n                    kwd=kwd,\n                    userinfo=self.userinfo)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting the entities of the user.", "response": "def user_list(self, userid, cur_p=''):\n        '''\n        List the entities of the user.\n        '''\n        current_page_number = int(cur_p) if cur_p else 1\n        current_page_number = 1 if current_page_number < 1 else current_page_number\n\n        kwd = {\n            'current_page': current_page_number\n        }\n\n        recs = MEntity2User.get_all_pager_by_username(userid, current_page_num=current_page_number).objects()\n\n        self.render('misc/entity/entity_user_download.html',\n                    imgs=recs,\n                    cfg=config.CMS_CFG,\n                    kwd=kwd,\n                    userinfo=self.userinfo)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the whoosh database.", "response": "def gen_whoosh_database(kind_arr, post_type):\n    '''\n    kind_arr, define the `type` except Post, Page, Wiki\n    post_type, define the templates for different kind.\n    '''\n    SITE_CFG['LANG'] = SITE_CFG.get('LANG', 'zh')\n\n    # Using jieba lib for Chinese.\n    if SITE_CFG['LANG'] == 'zh' and ChineseAnalyzer:\n        schema = Schema(title=TEXT(stored=True, analyzer=ChineseAnalyzer()),\n                        catid=TEXT(stored=True),\n                        type=TEXT(stored=True),\n                        link=ID(unique=True, stored=True),\n                        content=TEXT(stored=True, analyzer=ChineseAnalyzer()))\n    else:\n        schema = Schema(title=TEXT(stored=True, analyzer=StemmingAnalyzer()),\n                        catid=TEXT(stored=True),\n                        type=TEXT(stored=True),\n                        link=ID(unique=True, stored=True),\n                        content=TEXT(stored=True, analyzer=StemmingAnalyzer()))\n\n    whoosh_db = 'database/whoosh'\n    if os.path.exists(whoosh_db):\n        create_idx = open_dir(whoosh_db)\n    else:\n        os.makedirs(whoosh_db)\n        create_idx = create_in(whoosh_db, schema)\n    writer = create_idx.writer()\n\n    for switch in [True, False]:\n        do_for_post(writer, rand=switch, doc_type=post_type['1'])\n        do_for_wiki(writer, rand=switch, doc_type=post_type['1'])\n        do_for_page(writer, rand=switch, doc_type=post_type['1'])\n        for kind in kind_arr:\n            do_for_app(writer, rand=switch, kind=kind, doc_type=post_type)\n    writer.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nview the class 1 published page.", "response": "def view_class1(self, kind_sig):\n        '''\n        Publishing from 1st range category.\n        '''\n        dbdata = MCategory.get_parent_list(kind=kind_sig)\n        class1str = ''\n        for rec in dbdata:\n            class1str += '''\n             <a onclick=\"select_sub_tag('/publish/2{0}');\" class=\"btn btn-primary\"\n             style=\"display: inline-block;margin:3px;\" >\n             {1}</a>'''.format(rec.uid, rec.name)\n\n        kwd = {'class1str': class1str,\n               'parentid': '0',\n               'parentlist': MCategory.get_parent_list()}\n        self.render('misc/publish/publish.html',\n                    userinfo=self.userinfo,\n                    kwd=kwd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nview 2ed range category.", "response": "def view_class2(self, fatherid=''):\n        '''\n        Publishing from 2ed range category.\n        '''\n\n        if self.is_admin():\n            pass\n        else:\n            return False\n\n        kwd = {'class1str': self.format_class2(fatherid),\n               'parentid': '0',\n               'parentlist': MCategory.get_parent_list()}\n\n        if fatherid.endswith('00'):\n            self.render('misc/publish/publish2.html',\n                        userinfo=self.userinfo,\n                        kwd=kwd)\n        else:\n            catinfo = MCategory.get_by_uid(fatherid)\n            self.redirect('/{1}/_cat_add/{0}'.format(fatherid, router_post[catinfo.kind]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef app_evaluation_count(app_id, value=1):\n        '''\n        Get the Evalution sum.\n        '''\n        return TabEvaluation.select().where(\n            (TabEvaluation.post_id == app_id) & (TabEvaluation.value == value)\n        ).count()", "response": "Get the number of Evalution for a given app."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting by user ID and app ID.", "response": "def get_by_signature(user_id, app_id):\n        '''\n        get by user ID, and app ID.\n        '''\n        try:\n            return TabEvaluation.get(\n                (TabEvaluation.user_id == user_id) & (TabEvaluation.post_id == app_id)\n            )\n        except:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd or updates an entry in the database.", "response": "def add_or_update(user_id, app_id, value):\n        '''\n        Editing evaluation.\n        '''\n        rec = MEvaluation.get_by_signature(user_id, app_id)\n        if rec:\n            entry = TabEvaluation.update(\n                value=value,\n            ).where(TabEvaluation.uid == rec.uid)\n            entry.execute()\n        else:\n            TabEvaluation.create(\n                uid=tools.get_uuid(),\n                user_id=user_id,\n                post_id=app_id,\n                value=value,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef j_count_plus(self, slug):\n        '''\n        plus count via ajax.\n        '''\n        output = {'status': 1 if MWiki.view_count_plus(slug) else 0}\n        return json.dump(output, self)", "response": "count plus count via ajax."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist the recent post.", "response": "def p_list(self, kind, cur_p='', ):\n        '''\n        List the post .\n        '''\n        if cur_p == '':\n            current_page_number = 1\n        else:\n            current_page_number = int(cur_p)\n\n        current_page_number = 1 if current_page_number < 1 else current_page_number\n\n        pager_num = int(MWiki.total_number(kind) / CMS_CFG['list_num'])\n\n        kwd = {\n            'pager': '',\n            'title': 'Recent pages.',\n            'kind': kind,\n            'current_page': current_page_number,\n            'page_count': MWiki.get_counts(),\n        }\n\n        self.render('admin/page_ajax/page_list.html',\n                    postrecs=MWiki.query_pager_by_kind(kind=kind,\n                                                       current_page_num=current_page_number),\n                    kwd=kwd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the time that send E - mail to user.", "response": "def set_sendemail_time(uid):\n        '''\n        Set the time that send E-mail to user.\n        '''\n        entry = TabMember.update(\n            time_email=tools.timestamp(),\n        ).where(TabMember.uid == uid)\n        entry.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_user(user_id, u_pass):\n        '''\n        Checking the password by user's ID.\n        '''\n        user_count = TabMember.select().where(TabMember.uid == user_id).count()\n        if user_count == 0:\n            return -1\n        the_user = TabMember.get(uid=user_id)\n        if the_user.user_pass == tools.md5(u_pass):\n            return 1\n        return 0", "response": "Checks the password by user s ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks the password by user s name.", "response": "def check_user_by_name(user_name, u_pass):\n        '''\n        Checking the password by user's name.\n        '''\n        the_query = TabMember.select().where(TabMember.user_name == user_name)\n        if the_query.count() == 0:\n            return -1\n\n        the_user = the_query.get()\n        if the_user.user_pass == tools.md5(u_pass):\n            return 1\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_pass(user_id, newpass):\n        '''\n        Update the password of a user.\n        '''\n\n        out_dic = {'success': False, 'code': '00'}\n\n        entry = TabMember.update(user_pass=tools.md5(newpass)).where(TabMember.uid == user_id)\n        entry.execute()\n\n        out_dic['success'] = True\n\n        return out_dic", "response": "Update the password of a user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_nologin():\n        '''\n        Query the users who do not login recently (90 days).\n        and not send email (120 days).\n        time_model: num * month * hours * minite * second\n        time_login: 3 * 30 * 24 * 60 * 60\n        time_email: 4 * 30 * 24 * 60 * 60\n        '''\n        time_now = tools.timestamp()\n        return TabMember.select().where(\n            ((time_now - TabMember.time_login) > 7776000)\n            & ((time_now - TabMember.time_email) > 10368000)\n        )", "response": "Query the users who do not login recently and not send email recently."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_info(user_id, newemail, extinfo=None):\n        '''\n        Update the user info by user_id.\n        21: standsfor invalide E-mail.\n        91: standsfor unkown reson.\n        '''\n\n        if extinfo is None:\n            extinfo = {}\n\n        out_dic = {'success': False, 'code': '00'}\n        if not tools.check_email_valid(newemail):\n            out_dic['code'] = '21'\n            return out_dic\n        cur_info = MUser.get_by_uid(user_id)\n        cur_extinfo = cur_info.extinfo\n        for key in extinfo:\n            cur_extinfo[key] = extinfo[key]\n\n        try:\n            entry = TabMember.update(\n                user_email=newemail,\n                extinfo=cur_extinfo\n            ).where(\n                TabMember.uid == user_id\n            )\n            entry.execute()\n\n            out_dic['success'] = True\n        except:\n            out_dic['code'] = '91'\n\n        return out_dic", "response": "Update the user info by user_id with new email."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the time when user reset passwd.", "response": "def update_time_reset_passwd(user_name, the_time):\n        '''\n        Update the time when user reset passwd.\n        '''\n        entry = TabMember.update(\n            time_reset_passwd=the_time,\n        ).where(TabMember.user_name == user_name)\n        try:\n            entry.execute()\n            return True\n        except:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_role(u_name, newprivilege):\n        '''\n        Update the role of the usr.\n        '''\n        entry = TabMember.update(\n            role=newprivilege\n        ).where(TabMember.user_name == u_name)\n        try:\n            entry.execute()\n            return True\n        except:\n            return False", "response": "Update the role of the usr."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_time_login(u_name):\n        '''\n        Update the login time for user.\n        '''\n        entry = TabMember.update(\n            time_login=tools.timestamp()\n        ).where(\n            TabMember.user_name == u_name\n        )\n        entry.execute()", "response": "Update the login time for user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the user. The code used if `False`. 11: standsfor invalid username. 21: standsfor invalide E-mail. 91: standsfor unkown reson.", "response": "def create_user(post_data):\n        '''\n        Create the user.\n        The code used if `False`.\n        11: standsfor invalid username.\n        21: standsfor invalide E-mail.\n        91: standsfor unkown reson.\n        '''\n        out_dic = {'success': False, 'code': '00'}\n\n        if not tools.check_username_valid(post_data['user_name']):\n            out_dic['code'] = '11'\n            return out_dic\n\n        if not tools.check_email_valid(post_data['user_email']):\n            out_dic['code'] = '21'\n            return out_dic\n\n        try:\n            TabMember.create(uid=tools.get_uuid(),\n                             user_name=post_data['user_name'],\n                             user_pass=tools.md5(post_data['user_pass']),\n                             user_email=post_data['user_email'],\n                             role='1000',  # \u20181000' as default role.\n                             time_create=tools.timestamp(),\n                             time_update=tools.timestamp(),\n                             time_reset_passwd=tools.timestamp(),\n                             time_login=tools.timestamp(),\n                             time_email=tools.timestamp())\n\n            out_dic['success'] = True\n        except:\n            out_dic['code'] = '91'\n        return out_dic"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete user in the database by user_name.", "response": "def delete_by_user_name(user_name):\n        '''\n        Delete user in the database by `user_name`.\n        '''\n        try:\n            del_count = TabMember.delete().where(TabMember.user_name == user_name)\n            del_count.execute()\n            return True\n        except:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the user in the database by user_id.", "response": "def delete(user_id):\n        '''\n        Delele the  user in the database by `user_id`.\n        '''\n        try:\n            del_count = TabMember.delete().where(TabMember.uid == user_id)\n            del_count.execute()\n            return True\n        except:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the urls for posts.", "response": "def gen_post_map(file_name, ext_url=''):\n    '''\n    Generate the urls for posts.\n    :return: None\n    '''\n    with open(file_name, 'a') as fout:\n        for kind_key in router_post:\n            recent_posts = MPost.query_all(kind=kind_key, limit=1000000)\n            for recent_post in recent_posts:\n                url = os.path.join(SITE_CFG['site_url'],\n                                   router_post[recent_post.kind],\n                                   ext_url,\n                                   recent_post.uid)\n                fout.write('{url}\\n'.format(url=url))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gen_wiki_map(file_name, ext_url=''):\n    '''\n    Generate the urls for wiki.\n    :return: None\n    '''\n\n    # wiki\n    wiki_recs = MWiki.query_all(limit=10000, kind='1')\n\n    with open(file_name, 'a') as fileout:\n        for rec in wiki_recs:\n            url = os.path.join(SITE_CFG['site_url'],\n                               'wiki' + '/_edit' if ext_url else '',\n                               rec.title)\n            fileout.write('{url}\\n'.format(url=url))\n\n    ## page.\n    page_recs = MWiki.query_all(limit=10000, kind='2')\n\n    with open(file_name, 'a') as fileout:\n        for rec in page_recs:\n            url = os.path.join(SITE_CFG['site_url'],\n                               'page' + '/_edit' if ext_url else '',\n                               rec.uid)\n\n            fileout.write('{url}\\n'.format(url=url))", "response": "Generate the urls for wiki."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_sitemap(_):\n    '''\n    Generate the sitemap file.\n    :param args: args\n    :return: None\n    '''\n    site_map_file = 'xx_sitemap.txt'\n    if os.path.exists(site_map_file):\n        os.remove(site_map_file)\n\n    gen_wiki_map(site_map_file)\n    gen_post_map(site_map_file)", "response": "Generate the sitemap file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_editmap(_):\n    '''\n    Generate the urls file for editing.\n    :param args: args\n    :return: None\n    '''\n    edit_map_file = 'xx_editmap.txt'\n    if os.path.exists(edit_map_file):\n        os.remove(edit_map_file)\n\n    gen_wiki_map(edit_map_file, ext_url='_edit')\n    gen_post_map(edit_map_file, ext_url='_edit')", "response": "Generate the urls file for editing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_meta(catid, sig):\n    '''\n    Get metadata of dataset via ID.\n    '''\n    meta_base = './static/dataset_list'\n    if os.path.exists(meta_base):\n        pass\n    else:\n        return False\n\n    pp_data = {'logo': '', 'kind': '9'}\n    for wroot, wdirs, wfiles in os.walk(meta_base):\n        for wdir in wdirs:\n            if wdir.lower().endswith(sig):\n                #  Got the dataset of certain ID.\n                ds_base = pathlib.Path(os.path.join(wroot, wdir))\n\n                for uu in ds_base.iterdir():\n                    if uu.name.endswith('.xlsx'):\n                        meta_dic = chuli_meta('u' + sig[2:], uu)\n                        pp_data['title'] = meta_dic['title']\n                        pp_data['cnt_md'] = meta_dic['anytext']\n                        pp_data['user_name'] = 'admin'\n                        pp_data['def_cat_uid'] = catid\n                        pp_data['gcat0'] = catid\n                        pp_data['def_cat_pid'] = catid[:2] + '00'\n                        pp_data['extinfo'] = {}\n                    elif uu.name.startswith('thumbnail_'):\n                        pp_data['logo'] = os.path.join(wroot, wdir, uu.name).strip('.')\n\n    return pp_data", "response": "Get metadata of dataset via ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the category of the post.", "response": "def update_category(uid, post_data):\n    '''\n    Update the category of the post.\n    :param uid:  The ID of the post. Extra info would get by requests.\n    '''\n\n    # deprecated\n    # catid = kwargs['catid'] if MCategory.get_by_uid(kwargs.get('catid')) else None\n    # post_data = self.get_post_data()\n    if 'gcat0' in post_data:\n        pass\n    else:\n        return False\n\n    # Used to update MPost2Category, to keep order.\n    the_cats_arr = []\n    # Used to update post extinfo.\n    the_cats_dict = {}\n\n    # for old page. deprecated\n    # def_cate_arr.append('def_cat_uid')\n\n    def_cate_arr = ['gcat{0}'.format(x) for x in range(10)]\n    for key in def_cate_arr:\n        if key not in post_data:\n            continue\n        if post_data[key] == '' or post_data[key] == '0':\n            continue\n        # \u6709\u53ef\u80fd\u9009\u91cd\u590d\u4e86\u3002\u4fdd\u7559\u524d\u9762\u7684\n        if post_data[key] in the_cats_arr:\n            continue\n\n        the_cats_arr.append(post_data[key] + ' ' * (4 - len(post_data[key])))\n        the_cats_dict[key] = post_data[key] + ' ' * (4 - len(post_data[key]))\n\n    # if catid:\n    #     def_cat_id = catid\n    if the_cats_arr:\n        def_cat_id = the_cats_arr[0]\n    else:\n        def_cat_id = None\n\n    if def_cat_id:\n        the_cats_dict['gcat0'] = def_cat_id\n        the_cats_dict['def_cat_uid'] = def_cat_id\n        the_cats_dict['def_cat_pid'] = MCategory.get_by_uid(def_cat_id).pid\n\n    # Add the category\n    logger.info('Update category: {0}'.format(the_cats_arr))\n    logger.info('Update category: {0}'.format(the_cats_dict))\n\n    MPost.update_jsonb(uid, the_cats_dict)\n\n    for index, idx_catid in enumerate(the_cats_arr):\n        MPost2Catalog.add_record(uid, idx_catid, index)\n\n    # Delete the old category if not in post requests.\n    current_infos = MPost2Catalog.query_by_entity_uid(uid, kind='').objects()\n    for cur_info in current_infos:\n        if cur_info.tag_id not in the_cats_arr:\n            MPost2Catalog.remove_relation(uid, cur_info.tag_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_label(signature, post_data):\n    '''\n    Update the label when updating.\n    '''\n    current_tag_infos = MPost2Label.get_by_uid(signature).objects()\n    if 'tags' in post_data:\n        pass\n    else:\n        return False\n\n    tags_arr = [x.strip() for x in post_data['tags'].split(',')]\n    for tag_name in tags_arr:\n        if tag_name == '':\n            pass\n        else:\n            MPost2Label.add_record(signature, tag_name, 1)\n\n    for cur_info in current_tag_infos:\n        if cur_info.tag_name in tags_arr:\n            pass\n        else:\n            MPost2Label.remove_relation(signature, cur_info.tag_id)", "response": "Update the label when updating."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the ID for post.", "response": "def _gen_uid(self):\n        '''\n        Generate the ID for post.\n        :return: the new ID.\n        '''\n        cur_uid = self.kind + tools.get_uu4d()\n        while MPost.get_by_uid(cur_uid):\n            cur_uid = self.kind + tools.get_uu4d()\n        return cur_uid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the template path for the given App record.", "response": "def _get_tmpl_view(self, rec):\n        '''\n        According to the application, each info of it's classification could\n        has different temaplate.\n        :param rec: the App record.\n        :return: the temaplte path.\n        '''\n\n        if 'def_cat_uid' in rec.extinfo and rec.extinfo['def_cat_uid'] != '':\n            cat_id = rec.extinfo['def_cat_uid']\n        elif 'gcat0' in rec.extinfo and rec.extinfo['gcat0'] != '':\n            cat_id = rec.extinfo['gcat0']\n        else:\n            cat_id = None\n\n        logger.info('For templates: catid: {0},  filter_view: {1}'.format(cat_id, self.filter_view))\n\n        if cat_id and self.filter_view:\n            tmpl = 'autogen/view/view_{0}.html'.format(cat_id)\n        else:\n            tmpl = 'post_{0}/post_view.html'.format(self.kind)\n        return tmpl"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _to_add_with_category(self, catid):\n        '''\n        Used for info2.\n        :param catid: the uid of category\n        '''\n\n        catinfo = MCategory.get_by_uid(catid)\n        kwd = {\n            'uid': self._gen_uid(),\n            'userid': self.userinfo.user_name if self.userinfo else '',\n            'gcat0': catid,\n            'parentname': MCategory.get_by_uid(catinfo.pid).name,\n            'catname': MCategory.get_by_uid(catid).name,\n        }\n\n        self.render('autogen/add/add_{0}.html'.format(catid),\n                    userinfo=self.userinfo,\n                    kwd=kwd)", "response": "Used for info2. add_with_category."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _view_or_add(self, uid):\n        '''\n        Try to get the post. If not, to add the wiki.\n        '''\n        postinfo = MPost.get_by_uid(uid)\n        if postinfo:\n            self.viewinfo(postinfo)\n        elif self.userinfo:\n            self._to_add(uid=uid)\n        else:\n            self.show404()", "response": "Try to get the post. If not to add the wiki."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _to_edit(self, infoid):\n        '''\n        render the HTML page for post editing.\n        '''\n\n        postinfo = MPost.get_by_uid(infoid)\n\n        if postinfo:\n            pass\n        else:\n            return self.show404()\n\n        if 'def_cat_uid' in postinfo.extinfo:\n            catid = postinfo.extinfo['def_cat_uid']\n        elif 'gcat0' in postinfo.extinfo:\n            catid = postinfo.extinfo['gcat0']\n        else:\n            catid = ''\n\n        if len(catid) == 4:\n            pass\n        else:\n            catid = ''\n\n        catinfo = None\n        p_catinfo = None\n\n        post2catinfo = MPost2Catalog.get_first_category(postinfo.uid)\n        if post2catinfo:\n            catid = post2catinfo.tag_id\n            catinfo = MCategory.get_by_uid(catid)\n            if catinfo:\n                p_catinfo = MCategory.get_by_uid(catinfo.pid)\n\n        kwd = {\n            'gcat0': catid,\n            'parentname': '',\n            'catname': '',\n            'parentlist': MCategory.get_parent_list(),\n            'userip': self.request.remote_ip,\n            'extinfo': json.dumps(postinfo.extinfo, indent=2, ensure_ascii=False),\n        }\n\n        if self.filter_view:\n            tmpl = 'autogen/edit/edit_{0}.html'.format(catid)\n        else:\n            tmpl = 'post_{0}/post_edit.html'.format(self.kind)\n\n        logger.info('Meta template: {0}'.format(tmpl))\n\n        self.render(\n            tmpl,\n            kwd=kwd,\n            postinfo=postinfo,\n            catinfo=catinfo,\n            pcatinfo=p_catinfo,\n            userinfo=self.userinfo,\n            cat_enum=MCategory.get_qian2(catid[:2]),\n            tag_infos=MCategory.query_all(by_order=True, kind=self.kind),\n            tag_infos2=MCategory.query_all(by_order=True, kind=self.kind),\n            app2tag_info=MPost2Catalog.query_by_entity_uid(infoid, kind=self.kind).objects(),\n            app2label_info=MPost2Label.get_by_uid(infoid).objects()\n        )", "response": "render the HTML page for post editing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _gen_last_current_relation(self, post_id):\n        '''\n        Generate the relation for the post and last post viewed.\n        '''\n        last_post_id = self.get_secure_cookie('last_post_uid')\n        if last_post_id:\n            last_post_id = last_post_id.decode('utf-8')\n        self.set_secure_cookie('last_post_uid', post_id)\n\n        if last_post_id and MPost.get_by_uid(last_post_id):\n            self._add_relation(last_post_id, post_id)", "response": "Generate the relation for the post and last post viewed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nredirecting according to the kind of the post.", "response": "def redirect_kind(self, postinfo):\n        '''\n        Redirect according the kind of the post.\n        :param postinfo: the postinfo\n        :return: None\n        '''\n        logger.warning('info kind:{0} '.format(postinfo.kind))\n\n        # If not, there must be something wrong.\n        if postinfo.kind == self.kind:\n            pass\n        else:\n            self.redirect('/{0}/{1}'.format(router_post[postinfo.kind], postinfo.uid),\n                          permanent=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nview the post info.", "response": "def viewinfo(self, postinfo):\n        '''\n        In infor.\n        '''\n        self.redirect_kind(postinfo)\n\n        # ToDo: \u539f\u4e3a\u4e0b\u9762\u4ee3\u7801\u3002\n        # ext_catid = postinfo.extinfo['def_cat_uid'] if 'def_cat_uid' in postinfo.extinfo else ''\n        # ext_catid2 = postinfo.extinfo['def_cat_uid'] if 'def_cat_uid' in postinfo.extinfo else None\n\n        ext_catid = postinfo.extinfo['def_cat_uid'] if 'def_cat_uid' in postinfo.extinfo else ''\n\n        cat_enum1 = MCategory.get_qian2(ext_catid[:2]) if ext_catid else []\n\n        rand_recs, rel_recs = self.fetch_additional_posts(postinfo.uid)\n\n        self._chuli_cookie_relation(postinfo.uid)\n\n        catinfo = None\n        p_catinfo = None\n\n        post2catinfo = MPost2Catalog.get_first_category(postinfo.uid)\n        if post2catinfo:\n            catinfo = MCategory.get_by_uid(post2catinfo.tag_id)\n            if catinfo:\n                p_catinfo = MCategory.get_by_uid(catinfo.pid)\n\n        kwd = self._the_view_kwd(postinfo)\n\n        MPost.update_misc(postinfo.uid, count=True)\n        if self.get_current_user() and self.userinfo:\n            MUsage.add_or_update(self.userinfo.uid, postinfo.uid, postinfo.kind)\n\n        self.set_cookie('user_pass', kwd['cookie_str'])\n\n        tmpl = self.ext_tmpl_view(postinfo)\n\n        if self.userinfo:\n            recent_apps = MUsage.query_recent(self.userinfo.uid, postinfo.kind, 6).objects()[1:]\n        else:\n            recent_apps = []\n        logger.info('The Info Template: {0}'.format(tmpl))\n        self.render(tmpl,\n                    kwd=dict(kwd, **self.ext_view_kwd(postinfo)),\n                    postinfo=postinfo,\n                    userinfo=self.userinfo,\n                    author=postinfo.user_name,  # Todo: remove the key `author`.\n                    catinfo=catinfo,\n                    pcatinfo=p_catinfo,\n                    relations=rel_recs,\n                    rand_recs=rand_recs,\n                    subcats=MCategory.query_sub_cat(p_catinfo.uid),\n                    ad_switch=random.randint(1, 18),\n                    tag_info=filter(lambda x: not x.tag_name.startswith('_'),\n                                    MPost2Label.get_by_uid(postinfo.uid).objects()),\n                    recent_apps=recent_apps,\n                    cat_enum=cat_enum1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _the_view_kwd(self, postinfo):\n        '''\n        Generate the kwd dict for view.\n        :param postinfo: the postinfo\n        :return:  dict\n        '''\n        kwd = {\n            'pager': '',\n            'url': self.request.uri,\n            'cookie_str': tools.get_uuid(),\n            'daohangstr': '',\n            'signature': postinfo.uid,\n            'tdesc': '',\n            'eval_0': MEvaluation.app_evaluation_count(postinfo.uid, 0),\n            'eval_1': MEvaluation.app_evaluation_count(postinfo.uid, 1),\n            'login': 1 if self.get_current_user() else 0,\n            'has_image': 0,\n            'parentlist': MCategory.get_parent_list(),\n            'parentname': '',\n            'catname': '',\n            'router': router_post[postinfo.kind]\n        }\n        return kwd", "response": "Generate the kwd dict for view."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches the rel_recs and random recs when view the post.", "response": "def fetch_additional_posts(self, uid):\n        '''\n        fetch the rel_recs, and random recs when view the post.\n        '''\n        cats = MPost2Catalog.query_by_entity_uid(uid, kind=self.kind)\n        cat_uid_arr = []\n        for cat_rec in cats:\n            cat_uid = cat_rec.tag_id\n            cat_uid_arr.append(cat_uid)\n        logger.info('info category: {0}'.format(cat_uid_arr))\n        rel_recs = MRelation.get_app_relations(uid, 8, kind=self.kind).objects()\n\n        logger.info('rel_recs count: {0}'.format(rel_recs.count()))\n        if cat_uid_arr:\n            rand_recs = MPost.query_cat_random(cat_uid_arr[0], limit=4 - rel_recs.count() + 4)\n        else:\n            rand_recs = MPost.query_random(num=4 - rel_recs.count() + 4, kind=self.kind)\n        return rand_recs, rel_recs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the relation. And the from and to should have different weight.", "response": "def _add_relation(self, f_uid, t_uid):\n        '''\n        Add the relation. And the from and to, should have different weight.\n        :param f_uid: the uid of `from` post.\n        :param t_uid: the uid of `to` post.\n        :return: return True if the relation has been succesfully added.\n        '''\n        if not MPost.get_by_uid(t_uid):\n            return False\n        if f_uid == t_uid:\n            return False\n\n        # \u9488\u5bf9\u5206\u7c7b\u8fdb\u884c\u5904\u7406\u3002\u53ea\u6709\u843d\u5165\u76f8\u540c\u5206\u7c7b\u7684\uff0c\u624d\u52a01\n        f_cats = MPost2Catalog.query_by_entity_uid(f_uid)\n        t_cats = MPost2Catalog.query_by_entity_uid(t_uid)\n        flag = False\n        for f_cat in f_cats:\n            for t_cat in t_cats:\n                if f_cat.tag_id == t_cat.tag_id:\n                    flag = True\n        if flag:\n            pass\n        else:\n            return False\n        # \u53cc\u5411\u5173\u8054\uff0c\u4f46\u6743\u91cd\u4e0d\u4e00\u6837.\n        MRelation.add_relation(f_uid, t_uid, 2)\n        MRelation.add_relation(t_uid, f_uid, 1)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches post accessed data. post_data and ext_dic. fetch post accessed data. ext_dic and ext_dic. fetch post accessed data. post_data and ext_dic. return tuple of post_data ext_dic.", "response": "def fetch_post_data(self):\n        '''\n        fetch post accessed data. post_data, and ext_dic.\n        '''\n        post_data = {}\n        ext_dic = {}\n        for key in self.request.arguments:\n            if key.startswith('ext_') or key.startswith('tag_'):\n                ext_dic[key] = self.get_argument(key)\n            else:\n                post_data[key] = self.get_arguments(key)[0]\n\n        post_data['user_name'] = self.userinfo.user_name\n        post_data['kind'] = self.kind\n\n        # append external infor.\n\n        if 'tags' in post_data:\n            ext_dic['def_tag_arr'] = [x.strip() for x\n                                      in post_data['tags'].strip().strip(',').split(',')]\n        ext_dic = dict(ext_dic, **self.ext_post_data(postdata=post_data))\n\n        return (post_data, ext_dic)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, **kwargs):\n        '''\n        in infor.\n        '''\n        if 'uid' in kwargs:\n            uid = kwargs['uid']\n        else:\n            uid = self._gen_uid()\n\n        post_data, ext_dic = self.fetch_post_data()\n        if 'gcat0' in post_data:\n            pass\n        else:\n            return False\n\n        if 'valid' in post_data:\n            post_data['valid'] = int(post_data['valid'])\n        else:\n            post_data['valid'] = 1\n\n        ext_dic['def_uid'] = uid\n        ext_dic['gcat0'] = post_data['gcat0']\n        ext_dic['def_cat_uid'] = post_data['gcat0']\n\n        MPost.modify_meta(ext_dic['def_uid'],\n                          post_data,\n                          extinfo=ext_dic)\n        kwargs.pop('uid', None)  # delete `uid` if exists in kwargs\n\n        self._add_download_entity(ext_dic)\n\n        # self.update_tag(uid=ext_dic['def_uid'], **kwargs)\n\n        update_category(ext_dic['def_uid'], post_data)\n        update_label(ext_dic['def_uid'], post_data)\n        # self.update_label(uid)\n\n        # cele_gen_whoosh.delay()\n        tornado.ioloop.IOLoop.instance().add_callback(self.cele_gen_whoosh)\n        self.redirect('/{0}/{1}'.format(router_post[self.kind], uid))", "response": "Add new entry in infor."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the post with the given uid.", "response": "def update(self, uid):\n        '''\n        in infor.\n        '''\n\n        postinfo = MPost.get_by_uid(uid)\n        if postinfo.kind == self.kind:\n            pass\n        else:\n            return False\n\n        post_data, ext_dic = self.fetch_post_data()\n        if 'gcat0' in post_data:\n            pass\n        else:\n            return False\n\n        if 'valid' in post_data:\n            post_data['valid'] = int(post_data['valid'])\n        else:\n            post_data['valid'] = postinfo.valid\n\n        ext_dic['def_uid'] = str(uid)\n\n        cnt_old = tornado.escape.xhtml_unescape(postinfo.cnt_md).strip()\n        cnt_new = post_data['cnt_md'].strip()\n        if cnt_old == cnt_new:\n            pass\n        else:\n            MPostHist.create_post_history(postinfo)\n\n        MPost.modify_meta(uid, post_data, extinfo=ext_dic)\n\n        self._add_download_entity(ext_dic)\n        # self.update_tag(uid=uid)\n\n        update_category(uid, post_data)\n        update_label(uid, post_data)\n        # self.update_label(uid)\n\n        logger.info('post kind:' + self.kind)\n        # cele_gen_whoosh.delay()\n        tornado.ioloop.IOLoop.instance().add_callback(self.cele_gen_whoosh)\n        self.redirect('/{0}/{1}'.format(router_post[postinfo.kind], uid))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds relation to Info and Info viewed last.", "response": "def _chuli_cookie_relation(self, app_id):\n        '''\n        The current Info and the Info viewed last should have some relation.\n        And the last viewed Info could be found from cookie.\n        '''\n        last_app_uid = self.get_secure_cookie('use_app_uid')\n        if last_app_uid:\n            last_app_uid = last_app_uid.decode('utf-8')\n        self.set_secure_cookie('use_app_uid', app_id)\n        if last_app_uid and MPost.get_by_uid(last_app_uid):\n            self._add_relation(last_app_uid, app_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _to_edit_kind(self, post_uid):\n        '''\n        Show the page for changing the category.\n        '''\n        if self.userinfo and self.userinfo.role[1] >= '3':\n            pass\n        else:\n            self.redirect('/')\n        postinfo = MPost.get_by_uid(post_uid, )\n        json_cnt = json.dumps(postinfo.extinfo, indent=True)\n        kwd = {}\n        self.render('man_info/post_kind.html',\n                    postinfo=postinfo,\n                    sig_dic=router_post,\n                    userinfo=self.userinfo,\n                    json_cnt=json_cnt,\n                    kwd=kwd)", "response": "Show the page for changing the category."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchanges the kind of the post and kind.", "response": "def _change_kind(self, post_uid):\n        '''\n        To modify the category of the post, and kind.\n        '''\n\n        post_data = self.get_post_data()\n\n        logger.info('admin post update: {0}'.format(post_data))\n\n        MPost.update_misc(post_uid, kind=post_data['kcat'])\n        # self.update_category(post_uid)\n\n        update_category(post_uid, post_data)\n        self.redirect('/{0}/{1}'.format(router_post[post_data['kcat']], post_uid))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(self, cur_p=''):\n        '''\n        Lists of the entities.\n        '''\n        current_page_number = int(cur_p) if cur_p else 1\n        current_page_number = 1 if current_page_number < 1 else current_page_number\n\n        kwd = {\n            'current_page': current_page_number\n        }\n        recs = MEntity.get_all_pager(current_page_num=current_page_number)\n        self.render('misc/entity/entity_list.html',\n                    imgs=recs,\n                    cfg=config.CMS_CFG,\n                    kwd=kwd,\n                    userinfo=self.userinfo)", "response": "Lists of the entities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading the entity by UID.", "response": "def down(self, down_uid):\n        '''\n        Download the entity by UID.\n        '''\n        down_url = MPost.get_by_uid(down_uid).extinfo.get('tag__file_download', '')\n        print('=' * 40)\n        print(down_url)\n        str_down_url = str(down_url)[15:]\n\n\n        if down_url:\n            ment_id = MEntity.get_id_by_impath(str_down_url)\n            if ment_id:\n                MEntity2User.create_entity2user(ment_id, self.userinfo.uid)\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_entity(self):\n        '''\n        Add the entity. All the information got from the post data.\n        '''\n        post_data = self.get_post_data()\n\n        if 'kind' in post_data:\n            if post_data['kind'] == '1':\n                self.add_pic(post_data)\n            elif post_data['kind'] == '2':\n                self.add_pdf(post_data)\n            elif post_data['kind'] == '3':\n                self.add_url(post_data)\n            else:\n                pass\n        else:\n            self.add_pic(post_data)", "response": "Add the entity. All the information got from the post data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_pdf(self, post_data):\n        '''\n        Adding the pdf file.\n        '''\n\n        img_entity = self.request.files['file'][0]\n        img_desc = post_data['desc']\n        filename = img_entity[\"filename\"]\n\n        if filename and allowed_file_pdf(filename):\n            pass\n        else:\n            return False\n\n        _, hou = os.path.splitext(filename)\n        signature = str(uuid.uuid1())\n        outfilename = '{0}{1}'.format(signature, hou)\n        outpath = 'static/upload/{0}'.format(signature[:2])\n        if os.path.exists(outpath):\n            pass\n        else:\n            os.makedirs(outpath)\n        with open(os.path.join(outpath, outfilename), \"wb\") as fout:\n            fout.write(img_entity[\"body\"])\n\n        sig_save = os.path.join(signature[:2], signature)\n        path_save = os.path.join(signature[:2], outfilename)\n        create_pdf = MEntity.create_entity(signature, path_save, img_desc,\n                                           kind=post_data['kind'] if 'kind' in post_data else '2')\n        if self.entity_ajax == False:\n            self.redirect('/entity/{0}{1}'.format(sig_save, hou.lower()))\n        else:\n            if create_pdf:\n                output = {'path_save': path_save}\n            else:\n                output = {'path_save': ''}\n            return json.dump(output, self)", "response": "Add the pdf file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_url(self, post_data):\n        '''\n        Adding the URL as entity.\n        '''\n        img_desc = post_data['desc']\n        img_path = post_data['file1']\n        cur_uid = tools.get_uudd(4)\n        while MEntity.get_by_uid(cur_uid):\n            cur_uid = tools.get_uudd(4)\n        MEntity.create_entity(cur_uid, img_path, img_desc, kind=post_data['kind'] if 'kind' in post_data else '3')\n        kwd = {\n            'kind': post_data['kind'] if 'kind' in post_data else '3',\n\n        }\n        self.render('misc/entity/entity_view.html',\n                    filename=img_path,\n                    cfg=config.CMS_CFG,\n                    kwd=kwd,\n                    userinfo=self.userinfo)", "response": "Add the URL as entity."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_changeinfo(self):\n        '''\n        Change Infor via Ajax.\n        '''\n\n        post_data, def_dic = self.fetch_post_data()\n\n        usercheck = MUser.check_user(self.userinfo.uid, post_data['rawpass'])\n        if usercheck == 1:\n            MUser.update_info(self.userinfo.uid, post_data['user_email'], extinfo=def_dic)\n            output = {'changeinfo ': usercheck}\n        else:\n            output = {'changeinfo ': 0}\n        return json.dump(output, self)", "response": "P change info via Ajax."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch_post_data(self):\n        '''\n        fetch post accessed data. post_data, and ext_dic.\n        '''\n        post_data = {}\n        ext_dic = {}\n        for key in self.request.arguments:\n            if key.startswith('def_'):\n                ext_dic[key] = self.get_argument(key)\n            else:\n                post_data[key] = self.get_arguments(key)[0]\n\n        post_data['user_name'] = self.userinfo.user_name\n\n        ext_dic = dict(ext_dic, **self.ext_post_data(postdata=post_data))\n\n        return (post_data, ext_dic)", "response": "fetch post accessed data. post_data and ext_dic.\n        fetch post accessed data. ext_dic and ext_dic.\n        return the post_data and ext_dic."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __check_valid(self, post_data):\n        '''\n        To check if the user is succesfully created.\n        Return the status code dict.\n        '''\n        user_create_status = {'success': False, 'code': '00'}\n\n        if not tools.check_username_valid(post_data['user_name']):\n            user_create_status['code'] = '11'\n            return user_create_status\n        elif not tools.check_email_valid(post_data['user_email']):\n            user_create_status['code'] = '21'\n            return user_create_status\n        elif MUser.get_by_name(post_data['user_name']):\n            user_create_status['code'] = '12'\n            return user_create_status\n        elif MUser.get_by_email(post_data['user_email']):\n            user_create_status['code'] = '22'\n            return user_create_status\n\n        user_create_status['success'] = True\n        return user_create_status", "response": "Check if the user is succesfully created."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef json_changeinfo(self):\n        '''\n        The first char of 'code' stands for the different field.\n        '1' for user_name\n        '2' for user_email\n        '3' for user_pass\n        '4' for user_role\n        The seconde char of 'code' stands for different status.\n        '1' for invalide\n        '2' for already exists.\n        '''\n\n        # user_create_status = {'success': False, 'code': '00'}\n        post_data = self.get_post_data()\n\n        is_user_passed = MUser.check_user(self.userinfo.uid, post_data['rawpass'])\n\n        if is_user_passed == 1:\n\n            user_create_status = self.__check_valid_info(post_data)\n            if not user_create_status['success']:\n                return json.dump(user_create_status, self)\n\n            form_info = SumFormInfo(self.request.arguments)\n\n            if form_info.validate():\n                user_create_status = MUser.update_info(self.userinfo.uid, post_data['user_email'])\n                return json.dump(user_create_status, self)\n            return json.dump(user_create_status, self)\n        return False", "response": "Return the json of the changeinfo of the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef json_changepass(self):\n        '''\n        The first char of 'code' stands for the different field.\n        '1' for user_name\n        '2' for user_email\n        '3' for user_pass\n        '4' for user_role\n        The seconde char of 'code' stands for different status.\n        '1' for invalide\n        '2' for already exists.\n        '''\n\n        # user_create_status = {'success': False, 'code': '00'} # Not used currently.\n        post_data = self.get_post_data()\n\n        check_usr_status = MUser.check_user(self.userinfo.uid, post_data['rawpass'])\n\n        if check_usr_status == 1:\n\n            user_create_status = self.__check_valid_pass(post_data)\n            if not user_create_status['success']:\n                return json.dump(user_create_status, self)\n\n            form_pass = SumFormPass(self.request.arguments)\n\n            if form_pass.validate():\n                MUser.update_pass(self.userinfo.uid, post_data['user_pass'])\n                return json.dump(user_create_status, self)\n\n            return json.dump(user_create_status, self)\n\n        return False", "response": "Return a json representation of the user s pass."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresets password of a user.", "response": "def reset_password(self):\n        '''\n        Do reset password\n        :return:\n        '''\n        post_data = self.get_post_data()\n\n        if 'email' in post_data:\n            userinfo = MUser.get_by_email(post_data['email'])\n\n            if tools.timestamp() - userinfo.time_reset_passwd < 70:\n                self.set_status(400)\n                kwd = {\n                    'info': '\u4e24\u6b21\u91cd\u7f6e\u5bc6\u7801\u65f6\u95f4\u5e94\u8be5\u5927\u4e8e1\u5206\u949f',\n                    'link': '/user/reset-password',\n                }\n                self.render('misc/html/404.html', kwd=kwd, userinfo=self.userinfo)\n                return False\n\n            if userinfo:\n                timestamp = tools.timestamp()\n                passwd = userinfo.user_pass\n                username = userinfo.user_name\n                hash_str = tools.md5(username + str(timestamp) + passwd)\n                url_reset = '{0}/user/reset-passwd?u={1}&t={2}&p={3}'.format(\n                    config.SITE_CFG['site_url'],\n                    username,\n                    timestamp,\n                    hash_str)\n                email_cnt = '''<div>\u8bf7\u67e5\u770b\u4e0b\u9762\u7684\u4fe1\u606f\uff0c\u5e76<span style=\"color:red\">\u8c28\u614e\u64cd\u4f5c</span>\uff1a</div>\n            <div>\u60a8\u5728\"{0}\"\u7f51\u7ad9\uff08{1}\uff09\u7533\u8bf7\u4e86\u5bc6\u7801\u91cd\u7f6e\uff0c\u5982\u679c\u786e\u5b9a\u8981\u8fdb\u884c\u5bc6\u7801\u91cd\u7f6e\uff0c\u8bf7\u6253\u5f00\u4e0b\u9762\u94fe\u63a5\uff1a</div>\n            <div><a href={2}>{2}</a></div>\n            <div>\u5982\u679c\u65e0\u6cd5\u786e\u5b9a\u672c\u4fe1\u606f\u7684\u6709\u6548\u6027\uff0c\u8bf7\u5ffd\u7565\u672c\u90ae\u4ef6\u3002</div>'''.format(config.SMTP_CFG['name'],\n                                                       config.SITE_CFG['site_url'],\n                                                       url_reset)\n\n                if send_mail([userinfo.user_email], \"{0}|\u5bc6\u7801\u91cd\u7f6e\".format(config.SMTP_CFG['name']),\n                             email_cnt):\n                    MUser.update_time_reset_passwd(username, timestamp)\n                    self.set_status(200)\n                    logger.info('password has been reset.')\n                    return True\n\n                self.set_status(400)\n                return False\n            self.set_status(400)\n            return False\n        self.set_status(400)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate password for a user", "response": "def gen_passwd(self):\n        '''\n        reseting password\n        '''\n        post_data = self.get_post_data()\n\n        userinfo = MUser.get_by_name(post_data['u'])\n\n        sub_timestamp = int(post_data['t'])\n        cur_timestamp = tools.timestamp()\n        if cur_timestamp - sub_timestamp < 600 and cur_timestamp > sub_timestamp:\n            pass\n        else:\n            kwd = {\n                'info': '\u5bc6\u7801\u91cd\u7f6e\u5df2\u8d85\u65f6\uff01',\n                'link': '/user/reset-password',\n            }\n            self.set_status(400)\n            self.render('misc/html/404.html',\n                        kwd=kwd,\n                        userinfo=self.userinfo)\n\n        hash_str = tools.md5(userinfo.user_name + post_data['t'] + userinfo.user_pass)\n        if hash_str == post_data['p']:\n            pass\n        else:\n            kwd = {\n                'info': '\u5bc6\u7801\u91cd\u7f6e\u9a8c\u8bc1\u51fa\u9519\uff01',\n                'link': '/user/reset-password',\n            }\n            self.set_status(400)\n            self.render('misc/html/404.html',\n                        kwd=kwd,\n                        userinfo=self.userinfo, )\n\n        new_passwd = tools.get_uu8d()\n        MUser.update_pass(userinfo.uid, new_passwd)\n        kwd = {\n            'user_name': userinfo.user_name,\n            'new_pass': new_passwd,\n        }\n        self.render('user/user_show_pass.html',\n                    cfg=config.CMS_CFG,\n                    kwd=kwd,\n                    userinfo=self.userinfo, )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_language(self, language):\n        '''\n        Set the cookie for locale.\n        '''\n        if language == 'ZH':\n            self.set_cookie('ulocale', 'zh_CN')\n            self.set_cookie('blocale', 'zh_CN')\n        else:\n            self.set_cookie('ulocale', 'en_US')\n            self.set_cookie('blocale', 'en_US')", "response": "Set the cookie for locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a checkbox view from a dictionary", "response": "def gen_checkbox_view(sig_dic):\n    '''\n    for checkbox\n    '''\n    view_zuoxiang = '''\n    <div class=\"col-sm-4\"><span class=\"des\">{0}</span></div>\n    <div class=\"col-sm-8\">\n    '''.format(sig_dic['zh'])\n\n    dic_tmp = sig_dic['dic']\n    for key in dic_tmp.keys():\n        tmp_str = '''\n         <span>\n         {{% if \"{0}\" in postinfo.extinfo[\"{1}\"] %}}\n         {2}\n         {{% end %}}\n         </span>\n         '''.format(key, sig_dic['en'], dic_tmp[key])\n        view_zuoxiang += tmp_str\n\n    view_zuoxiang += '''</div>'''\n    return view_zuoxiang"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a list of radio items for each item in dic.", "response": "def gen_radio_list(sig_dic):\n    '''\n    For generating List view HTML file for RADIO.\n    for each item.\n    '''\n    view_zuoxiang = '''<span class=\"iga_pd_val\">'''\n\n    dic_tmp = sig_dic['dic']\n    for key in dic_tmp.keys():\n        tmp_str = '''{{% if postinfo.extinfo['{0}'][0] == \"{1}\" %}} {2} {{% end %}}\n        '''.format(sig_dic['en'], key, dic_tmp[key])\n        view_zuoxiang += tmp_str\n\n    view_zuoxiang += '''</span>'''\n    return view_zuoxiang"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gen_checkbox_list(sig_dic):\n    '''\n    For generating List view HTML file for CHECKBOX.\n    for each item.\n    '''\n    view_zuoxiang = '''<span class=\"iga_pd_val\">'''\n\n    dic_tmp = sig_dic['dic']\n    for key in dic_tmp.keys():\n        tmp_str = '''{{% if \"{0}\" in postinfo.extinfo[\"{1}\"] %}} {2}  {{% end %}}\n        '''.format(key, sig_dic['en'], dic_tmp[key])\n        view_zuoxiang += tmp_str\n\n    view_zuoxiang += '''</span>'''\n    return view_zuoxiang", "response": "Generate a list view HTML file for CHECKBOX."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating SELECT list view HTML file for SELECT.", "response": "def gen_select_list(sig_dic):\n    '''\n    For generating List view HTML file for SELECT.\n    for each item.\n    '''\n    view_jushi = '''<span class=\"label label-primary\" style=\"margin-right:10px\">'''\n\n    dic_tmp = sig_dic['dic']\n    for key in dic_tmp.keys():\n        tmp_str = '''{{% if '{0}' in postinfo.extinfo and postinfo.extinfo[\"{0}\"][0] == \"{1}\" %}}\n         {2} {{% end %}}'''.format(sig_dic['en'], key, dic_tmp[key])\n        view_jushi += tmp_str\n\n    view_jushi += '''</span>'''\n    return view_jushi"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gen_input_add(sig_dic):\n    '''\n    Adding for HTML Input control.\n    '''\n    if sig_dic['en'] == 'tag_file_download':\n        html_str = HTML_TPL_DICT['input_add_download'].format(\n            sig_en=sig_dic['en'],\n            sig_zh=sig_dic['zh'],\n            sig_dic=sig_dic['dic'][1],\n            sig_type=sig_dic['type']\n        )\n    else:\n        html_str = HTML_TPL_DICT['input_add'].format(\n            sig_en=sig_dic['en'],\n            sig_zh=sig_dic['zh'],\n            sig_dic=sig_dic['dic'][1],\n            sig_type=sig_dic['type']\n        )\n    return html_str", "response": "Generate HTML Input control."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gen_input_edit(sig_dic):\n    '''\n    Editing for HTML input control.\n    '''\n    if sig_dic['en'] == 'tag_file_download':\n        html_str = HTML_TPL_DICT['input_edit_download'].format(\n            sig_en=sig_dic['en'],\n            sig_zh=sig_dic['zh'],\n            sig_dic=sig_dic['dic'][1],\n            sig_type=sig_dic['type']\n        )\n    else:\n        html_str = HTML_TPL_DICT['input_edit'].format(\n            sig_en=sig_dic['en'],\n            sig_zh=sig_dic['zh'],\n            sig_dic=sig_dic['dic'][1],\n            sig_type=sig_dic['type']\n        )\n    return html_str", "response": "Generates HTML input editing for HTML input control."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating the input view for the given signature.", "response": "def gen_input_view(sig_dic):\n    '''\n    Viewing the HTML text.\n    '''\n    if sig_dic['en'] == 'tag_file_download':\n        html_str = HTML_TPL_DICT['input_view_download'].format(\n            sig_zh=sig_dic['zh'],\n            sig_unit=sig_dic['dic'][1]\n        )\n    elif sig_dic['en'] in ['tag_access_link', 'tag_dmoz_url',\n                           'tag_online_link', 'tag_event_url',\n                           'tag_expert_home', 'tag_pic_url']:\n        html_str = HTML_TPL_DICT['input_view_link'].format(\n            sig_dic['en'],\n            sig_dic['zh'],\n            sig_dic['dic'][1]\n        )\n\n    else:\n        html_str = HTML_TPL_DICT['input_view'].format(\n            sig_dic['en'],\n            sig_dic['zh'],\n            sig_dic['dic'][1]\n        )\n    return html_str"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gen_radio_add(sig_dic):\n    '''\n    Adding for HTML radio control.\n    '''\n    # html_zuoxiang = '''\n    # <label for=\"{0}\"><span>\n    # <a class=\"glyphicon glyphicon-star\" style=\"color: red;font-size: xx-small;\"></a> {1}</span>\n    # '''.format(sig['en'], sig['zh'])\n\n    # each item for radio.\n    radio_control_str = ''\n    dic_tmp = sig_dic['dic']\n    for key, val in dic_tmp.items():\n        tmp_str = '''\n        <input id=\"{0}\" name=\"{0}\" type=\"radio\" class=\"form-control\" value=\"{1}\">{2}\n       '''.format(sig_dic['en'], key, val)\n        radio_control_str += tmp_str\n\n    # html_zuoxiang += '''</label>'''\n\n    return '''<label for=\"{sig_en}\"><span>\n    <a class=\"glyphicon glyphicon-star\" style=\"color: red;font-size: xx-small;\">\n    </a>{sig_zh}</span>\n    {radio_str}</label>\n    '''.format(\n        sig_en=sig_dic['en'],\n        sig_zh=sig_dic['zh'],\n        radio_str=radio_control_str\n    )", "response": "Generate HTML radio control."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gen_radio_edit(sig_dic):\n    '''\n    editing for HTML radio control.\n    '''\n    edit_zuoxiang = '''7\n    <label  for=\"{0}\"><span>\n    <a class=\"glyphicon glyphicon-star\" style=\"color: red;font-size: xx-small;\">\n    </a>{1}</span>\n    '''.format(sig_dic['en'], sig_dic['zh'])\n\n    dic_tmp = sig_dic['dic']\n    for key in dic_tmp.keys():\n        tmp_str = '''\n        <input id=\"{0}\" name=\"{0}\" type=\"radio\"  class=\"form-control\" value=\"{1}\"\n        {{% if  '{0}' in postinfo.extinfo and postinfo.extinfo['{0}'] == '{1}' %}}\n        checked\n        {{% end %}}\n        >{2}\n        '''.format(sig_dic['en'], key, dic_tmp[key])\n        edit_zuoxiang += tmp_str\n\n    edit_zuoxiang += '''</label>'''\n    return edit_zuoxiang", "response": "Generate HTML radio edit for the current post."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a checkbox edit wunisheshi", "response": "def gen_checkbox_edit(sig_dic):\n    '''\n    for checkbox\n    '''\n    edit_wuneisheshi = '''<label for=\"{0}\"><span>\n     <a class=\"glyphicon glyphicon-star\" style=\"color: red;font-size: xx-small;\">\n     </a>{1}</span>\n     '''.format(sig_dic['en'], sig_dic['zh'])\n\n    dic_tmp = sig_dic['dic']\n    for key in dic_tmp.keys():\n        tmp_str = '''\n         <input id=\"{0}\" name=\"{0}\" type=\"checkbox\" class=\"form-control\" value=\"{1}\"\n         {{% if \"{1}\" in postinfo.extinfo[\"{0}\"] %}}\n         checked=\"checked\"\n         {{% end %}}\n         >{2} '''.format(sig_dic['en'], key, dic_tmp[key])\n        edit_wuneisheshi += tmp_str\n\n    edit_wuneisheshi += '''</label>'''\n    return edit_wuneisheshi"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the select control.", "response": "def gen_select_add(sig_dic):\n    '''\n    Adding for select control.\n    :param sig_dic:\n        html_media_type = {\n        'en': 'tag_media_type',\n        'zh': 'Media_type',\n        'dic': {1: 'Document', 2: 'Data', 3: 'Program'},\n        'type': 'select',\n        }\n    '''\n\n    option_str = ''\n\n    for key, val in sig_dic['dic'].items():\n        tmp_str = '''<option value=\"{0}\">{1}</option>'''.format(key, val)\n        option_str += tmp_str\n\n    return '''<div class=\"form-group\">\n    <label for=\"{sig_en}\" class=\"col-sm-2 control-label\"><span>\n    <a class=\"glyphicon glyphicon-star\" style=\"color: red;font-size: xx-small;\"></a>\n    {sig_zh}</span></label>\n    <div class=\"col-sm-10\"><select id=\"{sig_en}\" name=\"{sig_en}\" class=\"form-control\">\n    {option_str}</select></div></div>\n    '''.format(sig_en=sig_dic['en'], sig_zh=sig_dic['zh'], option_str=option_str)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery the most recent posts from the database.", "response": "def query_recent_most(num=8, recent=30):\n        '''\n        Query the records from database that recently updated.\n        :param num: the number that will returned.\n        :param recent: the number of days recent.\n        '''\n        time_that = int(time.time()) - recent * 24 * 3600\n        return TabPost.select().where(\n            TabPost.time_update > time_that\n        ).order_by(\n            TabPost.view_count.desc()\n        ).limit(num)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the rating for a specific post.", "response": "def __update_rating(uid, rating):\n        '''\n        Update the rating for post.\n        '''\n        entry = TabPost.update(\n            rating=rating\n        ).where(TabPost.uid == uid)\n        entry.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the kind of post.", "response": "def __update_kind(uid, kind):\n        '''\n        update the kind of post.\n        '''\n\n        entry = TabPost.update(\n            kind=kind,\n        ).where(TabPost.uid == uid)\n        entry.execute()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the order of the posts.", "response": "def update_order(uid, order):\n        '''\n        Update the order of the posts.\n        '''\n        entry = TabPost.update(\n            order=order\n        ).where(TabPost.uid == uid)\n        entry.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_or_update(uid, post_data):\n        '''\n        Add or update the post.\n        '''\n        cur_rec = MPost.get_by_uid(uid)\n        if cur_rec:\n            MPost.update(uid, post_data)\n        else:\n            MPost.create_post(uid, post_data)", "response": "Add or update the post."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nquerying random lists of certain category.", "response": "def query_cat_random(catid, **kwargs):\n        '''\n        Get random lists of certain category.\n        '''\n        num = kwargs.get('limit', 8)\n        if catid == '':\n            rand_recs = TabPost.select().order_by(peewee.fn.Random()).limit(num)\n        else:\n            rand_recs = TabPost.select().join(\n                TabPost2Tag,\n                on=(TabPost.uid == TabPost2Tag.post_id)\n            ).where(\n                (TabPost.valid == 1) & (TabPost2Tag.tag_id == catid)\n            ).order_by(\n                peewee.fn.Random()\n            ).limit(num)\n        return rand_recs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef query_random(**kwargs):\n        '''\n        Return the random records of centain kind.\n        '''\n\n        if 'limit' in kwargs:\n            limit = kwargs['limit']\n        elif 'num' in kwargs:\n            limit = kwargs['num']\n        else:\n            limit = 10\n\n        kind = kwargs.get('kind', None)\n\n        if kind:\n            rand_recs = TabPost.select().where(\n                (TabPost.kind == kind) &\n                (TabPost.valid == 1)\n            ).order_by(\n                peewee.fn.Random()\n            ).limit(limit)\n        else:\n            rand_recs = TabPost.select().where(\n                TabPost.valid == 1\n            ).order_by(\n                peewee.fn.Random()\n            ).limit(limit)\n        return rand_recs", "response": "Query random records of centain kind."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquerying all the posts.", "response": "def query_all(**kwargs):\n        '''\n        query all the posts.\n        '''\n        kind = kwargs.get('kind', '1')\n        limit = kwargs.get('limit', 10)\n\n        return TabPost.select().where(\n            (TabPost.kind == kind) &\n            (TabPost.valid == 1)\n        ).order_by(\n            TabPost.time_update.desc()\n        ).limit(limit)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_keywords_empty(kind='1'):\n        '''\n        Query keywords, empty.\n        '''\n        return TabPost.select().where((TabPost.kind == kind) & (TabPost.keywords == ''))", "response": "Query keywords that are empty."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery posts recently edited.", "response": "def query_recent_edited(timstamp, kind='1'):\n        '''\n        Query posts recently update.\n        '''\n        return TabPost.select().where(\n            (TabPost.kind == kind) &\n            (TabPost.time_update > timstamp)\n        ).order_by(\n            TabPost.time_update.desc()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef query_dated(num=8, kind='1'):\n        '''\n        Query posts, outdate.\n        '''\n        return TabPost.select().where(\n            TabPost.kind == kind\n        ).order_by(\n            TabPost.time_update.asc()\n        ).limit(num)", "response": "Query posts that are outdate."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries recent posts of a catalog.", "response": "def query_cat_recent(cat_id, label=None, num=8, kind='1', order=False):\n        '''\n        Query recent posts of catalog.\n        '''\n\n        if label:\n            recent_recs = MPost.query_cat_recent_with_label(\n                cat_id,\n                label=label,\n                num=num,\n                kind=kind,\n                order=order\n            )\n        else:\n            recent_recs = MPost.query_cat_recent_no_label(\n                cat_id,\n                num=num,\n                kind=kind,\n                order=order\n            )\n        return recent_recs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying recent posts of a given category.", "response": "def query_by_tag(cat_id, kind='1'):\n        '''\n        Query recent posts of catalog.\n        '''\n\n        return TabPost.select().join(\n            TabPost2Tag,\n            on=(TabPost.uid == TabPost2Tag.post_id)\n        ).where(\n            (TabPost.kind == kind) &\n            (TabPost2Tag.tag_id == cat_id)\n        ).order_by(\n            TabPost.time_create.desc()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query_total_cat_recent(cat_id_arr, label=None, num=8, kind='1'):\n        '''\n        :param cat_id_arr:   list of categories. ['0101', '0102']\n        :param label: the additional label\n        '''\n        if label:\n            return MPost.__query_with_label(\n                cat_id_arr,\n                label=label,\n                num=num,\n                kind=kind\n            )\n        return MPost.query_total_cat_recent_no_label(cat_id_arr, num=num, kind=kind)", "response": "Query the total number of recent entries in the category list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __query_with_label(cat_id_arr, label=None, num=8, kind='1'):\n        '''\n        :param cat_id_arr:   list of categories. ['0101', '0102']\n        '''\n        return TabPost.select().join(\n            TabPost2Tag,\n            on=(TabPost.uid == TabPost2Tag.post_id)\n        ).where(\n            (TabPost.kind == kind) &\n            (TabPost2Tag.tag_id << cat_id_arr) &  # the \"<<\" operator signifies an \"IN\" query\n            (TabPost.extinfo['def_tag_arr'].contains(label))\n        ).order_by(\n            TabPost.time_create.desc()\n        ).limit(num)", "response": "Query the post table with the given label."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nquery the total number of recent categories.", "response": "def query_total_cat_recent_no_label(cat_id_arr, num=8, kind='1'):\n        '''\n        :param cat_id_arr:   list of categories. ['0101', '0102']\n        '''\n        return TabPost.select().join(\n            TabPost2Tag,\n            on=(TabPost.uid == TabPost2Tag.post_id)\n        ).where(\n            (TabPost.kind == kind) &\n            (TabPost2Tag.tag_id << cat_id_arr)  # the \"<<\" operator signifies an \"IN\" query\n        ).order_by(\n            TabPost.time_create.desc()\n        ).limit(num)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_misc(uid, **kwargs):\n        '''\n        update rating, kind, or count\n        '''\n        if 'rating' in kwargs:\n            MPost.__update_rating(uid, kwargs['rating'])\n        elif 'kind' in kwargs:\n            MPost.__update_kind(uid, kwargs['kind'])\n        elif 'keywords' in kwargs:\n            MPost.__update_keywords(uid, kwargs['keywords'])\n        elif 'count' in kwargs:\n            MPost.__update_view_count(uid)", "response": "update the user s misc data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_next_record(in_uid, kind='1'):\n        '''\n        Get next record by time_create.\n        '''\n        current_rec = MPost.get_by_uid(in_uid)\n        recs = TabPost.select().where(\n            (TabPost.kind == kind) &\n            (TabPost.time_create < current_rec.time_create)\n        ).order_by(TabPost.time_create.desc())\n        if recs.count():\n            return recs.get()\n        return None", "response": "Get next record by time_create."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets All the records.", "response": "def get_all(kind='2'):\n        '''\n        Get All the records.\n        '''\n        return TabPost.select().where(\n            (TabPost.kind == kind) &\n            (TabPost.valid == 1)\n        ).order_by(\n            TabPost.time_update.desc()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the json. table.", "response": "def update_jsonb(uid, extinfo):\n        '''\n        Update the json.\n        '''\n        cur_extinfo = MPost.get_by_uid(uid).extinfo\n        for key in extinfo:\n            cur_extinfo[key] = extinfo[key]\n        entry = TabPost.update(\n            extinfo=cur_extinfo,\n        ).where(TabPost.uid == uid)\n        entry.execute()\n        return uid"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef modify_meta(uid, data_dic, extinfo=None):\n        '''\n        update meta of the rec.\n        '''\n        if extinfo is None:\n            extinfo = {}\n        title = data_dic['title'].strip()\n        if len(title) < 2:\n            return False\n\n        cur_info = MPost.get_by_uid(uid)\n        if cur_info:\n            # ToDo: should not do this. Not for 's'\n            if DB_CFG['kind'] == 's':\n                entry = TabPost.update(\n                    title=title,\n                    user_name=data_dic['user_name'],\n                    keywords='',\n                    time_update=tools.timestamp(),\n                    date=datetime.now(),\n                    cnt_md=data_dic['cnt_md'],\n                    memo=data_dic['memo'] if 'memo' in data_dic else '',\n                    logo=data_dic['logo'],\n                    order=data_dic['order'],\n                    cnt_html=tools.markdown2html(data_dic['cnt_md']),\n                    valid=data_dic['valid']\n                ).where(TabPost.uid == uid)\n                entry.execute()\n            else:\n                cur_extinfo = cur_info.extinfo\n                # Update the extinfo, Not replace\n                for key in extinfo:\n                    cur_extinfo[key] = extinfo[key]\n\n                entry = TabPost.update(\n                    title=title,\n                    user_name=data_dic['user_name'],\n                    keywords='',\n                    time_update=tools.timestamp(),\n                    date=datetime.now(),\n                    cnt_md=data_dic['cnt_md'],\n                    memo=data_dic['memo'] if 'memo' in data_dic else '',\n                    logo=data_dic['logo'],\n                    order=data_dic['order'] if 'order' in data_dic else '',\n                    cnt_html=tools.markdown2html(data_dic['cnt_md']),\n                    extinfo=cur_extinfo,\n                    valid=data_dic['valid']\n                ).where(TabPost.uid == uid)\n                entry.execute()\n        else:\n            return MPost.add_meta(uid, data_dic, extinfo)\n        return uid", "response": "update meta of the rec."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmodifies when init. update when init.", "response": "def modify_init(uid, data_dic):\n        '''\n        update when init.\n        '''\n        postinfo = MPost.get_by_uid(uid)\n        entry = TabPost.update(\n            time_update=tools.timestamp(),\n            date=datetime.now(),\n            kind=data_dic['kind'] if 'kind' in data_dic else postinfo.kind,\n            keywords=data_dic['keywords'] if 'keywords' in data_dic else postinfo.keywords,\n        ).where(TabPost.uid == uid)\n        entry.execute()\n        return uid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef query_under_condition(condition, kind='2'):\n        '''\n        Get All data of certain kind according to the condition\n        '''\n        if DB_CFG['kind'] == 's':\n            return TabPost.select().where(\n                (TabPost.kind == kind) & (TabPost.valid == 1)\n            ).order_by(\n                TabPost.time_update.desc()\n            )\n\n        return TabPost.select().where(\n            (TabPost.kind == kind) &\n            (TabPost.valid == 1) &\n            TabPost.extinfo.contains(condition)\n        ).order_by(TabPost.time_update.desc())", "response": "Get All data of certain kind according to the condition"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_list_pager(con, idx, kind='2'):\n        '''\n        Get records of certain pager.\n        '''\n        all_list = MPost.query_under_condition(con, kind=kind)\n        return all_list[(idx - 1) * CMS_CFG['list_num']: idx * CMS_CFG['list_num']]", "response": "Query the records of certain pager."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the count of certain kind.", "response": "def count_of_certain_kind(kind):\n        '''\n        Get the count of certain kind.\n        '''\n\n        recs = TabPost.select().where(TabPost.kind == kind)\n\n        return recs.count()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_pager_by_slug(kind, current_page_num=1):\n        '''\n        Query pager\n        '''\n        return TabPost.select().where(TabPost.kind == kind).order_by(\n            TabPost.time_create.desc()\n        ).paginate(\n            current_page_num, CMS_CFG['list_num']\n        )", "response": "Query pager by kind and slug"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate an Excel table", "response": "def gen_xlsx_table():\n    '''\n    excel\u4e2d\u7684\u6570\u636e\u4f5c\u4e3a\u8868\u4e2d\u7684\u5b57\u6bb5\uff0c\u521b\u5efa\u8868\n    '''\n\n\n    XLSX_FILE = './database/esheet/20180811.xlsx'\n    if os.path.exists(XLSX_FILE):\n        pass\n    else:\n        return\n\n    fields = []\n    for sheet_ranges in load_workbook(filename=XLSX_FILE):\n\n        for xr in FILTER_COLUMNS:\n            row1_val = sheet_ranges[xr + \"1\"].value\n            row2_val = sheet_ranges[xr + \"2\"].value\n            row3_val = sheet_ranges[xr + \"3\"].value\n            row4_val = sheet_ranges[xr + \"4\"].value\n            if row1_val and row1_val.strip() != '':\n                desc = {\n                    'slug': row1_val,\n                    'name': row2_val,\n                    'type': row3_val,\n                    'display_mode': row4_val\n                }\n\n                fields.append(desc)\n\n    create_tab(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef viewinfo(self, postinfo):\n        '''\n        In infor.\n        '''\n        self.redirect_kind(postinfo)\n\n        if DB_CFG['kind'] == 's':\n            cat_enum1 = []\n\n        else:\n            ext_catid = postinfo.extinfo['def_cat_uid'] if 'def_cat_uid' in postinfo.extinfo else ''\n            ext_catid2 = postinfo.extinfo[\n                'def_cat_uid'] if 'def_cat_uid' in postinfo.extinfo else None\n            cat_enum1 = MCategory.get_qian2(ext_catid2[:2]) if ext_catid else []\n\n        catinfo = None\n        p_catinfo = None\n\n        post2catinfo = MPost2Catalog.get_first_category(postinfo.uid)\n\n        catalog_infors = None\n        if post2catinfo:\n            catinfo = MCategory.get_by_uid(post2catinfo.tag_id)\n            if catinfo:\n                p_catinfo = MCategory.get_by_uid(catinfo.pid)\n                catalog_infors = MPost2Catalog.query_pager_by_slug(catinfo.slug,\n                                                                   current_page_num=1,\n                                                                   order=True)\n\n        kwd = self._the_view_kwd(postinfo)\n\n        MPost.update_misc(postinfo.uid, count=True)\n        if self.get_current_user():\n            MUsage.add_or_update(self.userinfo.uid, postinfo.uid, postinfo.kind)\n\n        tmpl = 'post_{0}/leaf_view.html'.format(self.kind)\n\n        logger.info('The Info Template: {0}'.format(tmpl))\n\n        self.render(tmpl,\n                    kwd=dict(kwd, **self.ext_view_kwd(postinfo)),\n                    postinfo=postinfo,\n                    userinfo=self.userinfo,\n                    catinfo=catinfo,\n                    pcatinfo=p_catinfo,\n                    ad_switch=random.randint(1, 18),\n                    tag_info=MPost2Label.get_by_uid(postinfo.uid),\n                    catalog_infos=catalog_infors,\n                    cat_enum=cat_enum1)", "response": "View the info of the post."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the view template", "response": "def __get_view_tmpl(tag_key):\n    '''\n    \u6839\u636e\u5206\u7c7buid\u76844\u4f4d\u7f16\u7801\u6765\u627e\u6a21\u677f\u3002\u5982\u679c4\u4f4d\u7684\u5b58\u5728\uff0c\u5219\u4f7f\u75284\u4f4d\u7684\uff1b\u4e0d\u7136\u627e\u5176\u7236\u7c7b\uff1b\u518d\u4e0d\u7136\u5219\u4f7f\u7528\u901a\u7528\u6a21\u677f\n    \u53ea\u6709View\u9700\u8981\uff0cedit, list\u4f7f\u7528\u901a\u7528\u6a21\u677f\n    :return String.\n    '''\n    the_view_file_4 = './templates/tmpl_{0}/tpl_view_{1}.html'.format(\n        KIND_DICS['kind_' + tag_key.split('_')[-1]],\n        tag_key.split('_')[1]\n    )\n    the_view_file_2 = './templates/tmpl_{0}/tpl_view_{1}.html'.format(\n        KIND_DICS['kind_' + tag_key.split('_')[-1]],\n        tag_key.split('_')[1][:2]\n    )\n    if os.path.exists(the_view_file_4):\n        the_view_sig_str = '_{0}'.format(tag_key.split('_')[1])\n    elif os.path.exists(the_view_file_2):\n        the_view_sig_str = '_{0}'.format(tag_key.split('_')[1][:2])\n    else:\n        the_view_sig_str = ''\n    return the_view_sig_str"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __gen_select_filter(bl_str):\n    '''\n    Convert to html.\n    :return String.\n    '''\n    bianliang = HTML_DICS[bl_str]\n    # bianliang = eval('html_vars.' + bl_str)\n    html_out = '''<li class=\"list-group-item\">\n    <div class=\"row\"><div class=\"col-sm-3\">{0}</div><div class=\"col-sm-9\">\n     <span class=\"label label-default\"  name='{1}' onclick='change(this);' value=''>{{{{_('All')}}}}</span>\n    '''.format(bianliang['zh'], '_'.join(bl_str.split('_')[1:]))\n\n    tmp_dic = bianliang['dic']\n    for key in tmp_dic.keys():\n        tmp_str = '''\n        <span  class=\"label label-default\" name='{0}' onclick='change(this);' value='{1}'>\n        {2}</span>'''.format('_'.join(bl_str.split('_')[1:]), key, tmp_dic[key])\n        html_out += tmp_str\n    html_out += '''</div></div></li>'''\n    return html_out", "response": "Convert to html.\n    :return String."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_html_files(*args):\n    '''\n    Generate the templates for adding, editing, viewing.\n    :return: None\n    '''\n    _ = args\n    for tag_key, tag_list in SWITCH_DICS.items():\n        if tag_key.startswith('dic_') and (not tag_key.endswith('00')):\n            __write_add_tmpl(tag_key, tag_list)\n            __write_edit_tmpl(tag_key, tag_list)\n            __write_view_tmpl(tag_key, tag_list)\n\n    __write_filter_tmpl(TPL_LIST)\n    __write_list_tmpl(TPL_LISTINFO)", "response": "Generate the templates for adding editing viewing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the HTML file for editing.", "response": "def __write_edit_tmpl(tag_key, tag_list):\n    '''\n    Generate the HTML file for editing.\n    :param tag_key: key of the tags.\n    :param tag_list: list of the tags.\n    :return: None\n    '''\n    edit_file = os.path.join(OUT_DIR, 'edit', 'edit_' + tag_key.split('_')[1] + '.html')\n    edit_widget_arr = []\n    for sig in tag_list:\n        html_sig = '_'.join(['html', sig])\n        # var_html = eval('html_vars.' + html_sig)\n        var_html = HTML_DICS[html_sig]\n\n        if var_html['type'] in INPUT_ARR:\n            tmpl = func_gen_html.gen_input_edit(var_html)\n        elif var_html['type'] == 'select':\n            tmpl = func_gen_html.gen_select_edit(var_html)\n        elif var_html['type'] == 'radio':\n            tmpl = func_gen_html.gen_radio_edit(var_html)\n        elif var_html['type'] == 'checkbox':\n            tmpl = func_gen_html.gen_checkbox_edit(var_html)\n        elif var_html['type'] == 'file':\n            tmpl = func_gen_html.gen_file_edit(var_html)\n        else:\n            tmpl = ''\n        edit_widget_arr.append(tmpl)\n    with open(edit_file, 'w') as fileout2:\n        outstr = minify(\n            TPL_EDIT.replace(\n                'xxxxxx',\n                ''.join(edit_widget_arr)\n            ).replace(\n                'yyyyyy',\n                tag_key.split('_')[1][:2]\n            ).replace(\n                'kkkk',\n                KIND_DICS['kind_' + tag_key.split('_')[-1]]\n            )\n        )\n        fileout2.write(outstr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the HTML file for viewing the tags.", "response": "def __write_view_tmpl(tag_key, tag_list):\n    '''\n    Generate the HTML file for viewing.\n    :param tag_key: key of the tags.\n    :param tag_list: list of the tags.\n    :return: None\n    '''\n    view_file = os.path.join(OUT_DIR, 'view', 'view_' + tag_key.split('_')[1] + '.html')\n    view_widget_arr = []\n    for sig in tag_list:\n        html_sig = '_'.join(['html', sig])\n        # var_html = eval('html_vars.' + html_sig)\n        var_html = HTML_DICS[html_sig]\n\n        if var_html['type'] in INPUT_ARR:\n            tmpl = func_gen_html.gen_input_view(var_html)\n        elif var_html['type'] == 'select':\n            tmpl = func_gen_html.gen_select_view(var_html)\n        elif var_html['type'] == 'radio':\n            tmpl = func_gen_html.gen_radio_view(var_html)\n        elif var_html['type'] == 'checkbox':\n            tmpl = func_gen_html.gen_checkbox_view(var_html)\n        elif var_html['type'] == 'file':\n            tmpl = func_gen_html.gen_file_view(var_html)\n        else:\n            tmpl = ''\n\n        # The admin information should be hidden for user.\n        if sig.startswith('_'):\n            tmpl = '''{% if userinfo and userinfo.role[1] > '0' %}''' + tmpl + '''{% end %}'''\n        view_widget_arr.append(tmpl)\n    the_view_sig_str = __get_view_tmpl(tag_key)\n    with open(view_file, 'w') as fileout:\n        outstr = minify(\n            TPL_VIEW.replace(\n                'xxxxxx', ''.join(view_widget_arr)\n            ).replace(\n                'yyyyyy',\n                tag_key.split('_')[1][:2]\n            ).replace(\n                'ssss',\n                the_view_sig_str\n            ).replace(\n                'kkkk',\n                KIND_DICS['kind_' + tag_key.split('_')[-1]]\n            )\n        )\n        fileout.write(outstr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the HTML file for adding.", "response": "def __write_add_tmpl(tag_key, tag_list):\n    '''\n    Generate the HTML file for adding.\n    :param tag_key: key of the tags.\n    :param tag_list: list of the tags.\n    :return: None\n    '''\n    add_file = os.path.join(OUT_DIR, 'add', 'add_' + tag_key.split('_')[1] + '.html')\n    add_widget_arr = []\n    # var_dic = eval('dic_vars.' + bianliang)\n    for sig in tag_list:\n        html_sig = '_'.join(['html', sig])\n        # var_html = eval('html_vars.' + html_sig)\n        var_html = HTML_DICS[html_sig]\n\n        if var_html['type'] in INPUT_ARR:\n            tmpl = func_gen_html.gen_input_add(var_html)\n        elif var_html['type'] == 'select':\n            tmpl = func_gen_html.gen_select_add(var_html)\n        elif var_html['type'] == 'radio':\n            tmpl = func_gen_html.gen_radio_add(var_html)\n        elif var_html['type'] == 'checkbox':\n            tmpl = func_gen_html.gen_checkbox_add(var_html)\n        elif var_html['type'] == 'file':\n            tmpl = func_gen_html.gen_file_add(var_html)\n        else:\n            tmpl = ''\n        add_widget_arr.append(tmpl)\n    with open(add_file, 'w') as fileout:\n        outstr = minify(\n            TPL_ADD.replace(\n                'xxxxxx',\n                ''.join(add_widget_arr)\n            ).replace(\n                'yyyyyy',\n                tag_key.split('_')[1][:2]\n            ).replace(\n                'kkkk',\n                KIND_DICS['kind_' + tag_key.split('_')[-1]]\n            )\n        )\n        fileout.write(outstr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __write_filter_tmpl(html_tpl):\n    '''\n    doing for directory.\n    '''\n    out_dir = os.path.join(os.getcwd(), CRUD_PATH, 'list')\n    if os.path.exists(out_dir):\n        pass\n    else:\n        os.mkdir(out_dir)\n    # for var_name in VAR_NAMES:\n    for var_name, bl_val in SWITCH_DICS.items():\n        if var_name.startswith('dic_'):\n            # \u6b64\u5904\u7b80\u5316\u4e00\u4e0b\uff0c\u4e0d\u8003\u8651\u5b50\u7c7b\u7684\u95ee\u9898\u3002\n            subdir = ''\n            outfile = os.path.join(out_dir, 'list' + '_' + var_name.split('_')[1] + '.html')\n            html_view_str_arr = []\n            # tview_var = eval('dic_vars.' + var_name)\n            for the_val in bl_val:\n                # sig = eval('html_vars.html_' + x)\n                sig = HTML_DICS['html_' + the_val]\n                if sig['type'] == 'select':\n                    html_view_str_arr.append(__gen_select_filter('html_' + the_val))\n\n            with open(outfile, 'w') as outfileo:\n                outstr = minify(\n                    html_tpl.replace(\n                        'xxxxxx',\n                        ''.join(html_view_str_arr)\n                    ).replace(\n                        'yyyyyy',\n                        var_name.split('_')[1][:2]\n                    ).replace(\n                        'ssssss',\n                        subdir\n                    ).replace(\n                        'kkkk',\n                        KIND_DICS['kind_' + var_name.split('_')[-1]]\n                    )\n                )\n                outfileo.write(outstr)", "response": "Write filter template to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __write_list_tmpl(html_tpl):\n    '''\n    doing for directory.\n    '''\n    out_dir = os.path.join(os.getcwd(), CRUD_PATH, 'infolist')\n    if os.path.exists(out_dir):\n        pass\n    else:\n        os.mkdir(out_dir)\n    # for var_name in VAR_NAMES:\n    for var_name, bl_val in SWITCH_DICS.items():\n        if var_name.startswith('dic_'):\n            outfile = os.path.join(out_dir, 'infolist' + '_' + var_name.split('_')[1] + '.html')\n            html_view_str_arr = []\n            # tview_var = eval('dic_vars.' + var_name)\n            subdir = ''\n            for the_val2 in bl_val:\n                # sig = eval('html_vars.html_' + x)\n\n                sig = HTML_DICS['html_' + the_val2]\n                if sig['type'] == 'select':\n                    html_view_str_arr.append(func_gen_html.gen_select_list(sig))\n                elif sig['type'] == 'radio':\n                    html_view_str_arr.append(func_gen_html.gen_radio_list(sig))\n                elif sig['type'] == 'checkbox':\n                    html_view_str_arr.append(func_gen_html.gen_checkbox_list(sig))\n\n            with open(outfile, 'w') as outfileo:\n                outstr = minify(\n                    html_tpl.replace(\n                        'xxxxxx',\n                        ''.join(html_view_str_arr)\n                    ).replace(\n                        'yyyyyy',\n                        var_name.split('_')[1][:2]\n                    ).replace(\n                        'ssssss',\n                        subdir\n                    ).replace(\n                        'kkkk',\n                        KIND_DICS['kind_' + var_name.split('_')[-1]]\n                    )\n                )\n                outfileo.write(outstr)", "response": "Write list of templates to file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_find(self):\n        '''\n        Todo: the name should be changed.\n        list the infors.\n        '''\n        kwd = {'pager': ''}\n        self.render('user/info_list/most.html',\n                    topmenu='',\n                    userinfo=self.userinfo,\n                    kwd=kwd)", "response": "To find the most infors."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_by_id(self, reply_id):\n        '''\n        Get the reply by id.\n        '''\n        reply = MReply.get_by_uid(reply_id)\n        logger.info('get_reply: {0}'.format(reply_id))\n\n        self.render('misc/reply/show_reply.html',\n                    reply=reply,\n                    username=reply.user_name,\n                    date=reply.date,\n                    vote=reply.vote,\n                    uid=reply.uid,\n                    userinfo=self.userinfo,\n                    kwd={})", "response": "Get the reply by id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, post_id):\n        '''\n        Adding reply to a post.\n        '''\n        post_data = self.get_post_data()\n\n        post_data['user_name'] = self.userinfo.user_name\n        post_data['user_id'] = self.userinfo.uid\n        post_data['post_id'] = post_id\n        replyid = MReply.create_reply(post_data)\n        if replyid:\n            out_dic = {'pinglun': post_data['cnt_reply'],\n                       'uid': replyid}\n            logger.info('add reply result dic: {0}'.format(out_dic))\n            return json.dump(out_dic, self)", "response": "Adds reply to a post."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_all():\n        '''\n        \u67e5\u8be2\u5927\u7c7b\u8bb0\u5f55\n        '''\n\n        recs = TabTag.select().where(TabTag.uid.endswith('00')).order_by(TabTag.uid)\n        return recs", "response": "Query all the records in the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the post via ID.", "response": "def update(self, uid):\n        '''\n        Update the post via ID.\n        '''\n        if self.userinfo.role[0] > '0':\n            pass\n        else:\n            return False\n\n        post_data = self.get_post_data()\n        post_data['user_name'] = self.userinfo.user_name if self.userinfo else ''\n        cur_info = MWiki.get_by_uid(uid)\n        MWikiHist.create_wiki_history(cur_info)\n        MWiki.update_cnt(uid, post_data)\n        if cur_info.kind == '1':\n            self.redirect('/wiki/{0}'.format(cur_info.title))\n        elif cur_info.kind == '2':\n            self.redirect('/page/{0}.html'.format(cur_info.uid))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_edit(self, postid):\n        '''\n        Try to edit the Post.\n        '''\n        if self.userinfo.role[0] > '0':\n            pass\n        else:\n            return False\n        kwd = {}\n        self.render('man_info/wiki_man_edit.html',\n                    userinfo=self.userinfo,\n                    postinfo=MWiki.get_by_uid(postid),\n                    kwd=kwd)", "response": "Try to edit the Post."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, uid):\n        '''\n        Delete the history of certain ID.\n        '''\n        if self.check_post_role()['DELETE']:\n            pass\n        else:\n            return False\n\n        histinfo = MWikiHist.get_by_uid(uid)\n        if histinfo:\n            pass\n        else:\n            return False\n\n        postinfo = MWiki.get_by_uid(histinfo.wiki_id)\n        MWikiHist.delete(uid)\n        self.redirect('/wiki_man/view/{0}'.format(postinfo.uid))", "response": "Delete the history of certain ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nquery pager by user.", "response": "def query_pager_by_user(userid, current_page_num=1):\n        '''\n        Query pager\n        '''\n        return TabLog.select().where(TabLog.user_id == userid).order_by(\n            TabLog.time_create.desc()\n        ).paginate(\n            current_page_num, CMS_CFG['list_num']\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query_all_user():\n        '''\n        \u67e5\u8be2\u6240\u6709\u767b\u5f55\u7528\u6237\u7684\u8bbf\u95ee\u8bb0\u5f55\n        ToDo:  ``None`` ?\n        '''\n        return TabLog.select().where(TabLog.user_id != 'None').distinct(TabLog.user_id).order_by(\n            TabLog.user_id\n        )", "response": "\u67e5\u8be2\u6240\u6709\u767b\u5f55\u7528\u6237\u7684\u8bbf\u95ee\u8bb0\u5f55\n        ToDo:  ``None`` ?"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_all(current_page_num=1):\n        '''\n        \u67e5\u8be2\u6240\u6709\u672a\u767b\u5f55\u7528\u6237\u7684\u8bbf\u95ee\u8bb0\u5f55\n        ToDo:  ``None`` ?\n        '''\n        return TabLog.select().where(TabLog.user_id == 'None').order_by(TabLog.time_out.desc()).paginate(\n            current_page_num, CMS_CFG['list_num']\n        )", "response": "Query all the user s log entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef count_of_current_url(current_url):\n        '''\n        \u957f\u8be2\u5236\u8ba2\u9875\u9762\uff08current_url\uff09\u7684\u8bbf\u95ee\u91cf\n        '''\n        res = TabLog.select().where(TabLog.current_url == current_url)\n        return res.count()", "response": "Count the number of log entries for the given url."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_by_signature(user_id, app_id):\n        '''\n        Get the collection.\n        '''\n        try:\n            return TabCollect.get(\n                (TabCollect.user_id == user_id) &\n                (TabCollect.post_id == app_id)\n            )\n        except:\n            return None", "response": "Get the collection by signature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the cound of views.", "response": "def count_of_user(user_id):\n        '''\n        Get the cound of views.\n        '''\n        return TabCollect.select(\n            TabCollect, TabPost.uid.alias('post_uid'),\n            TabPost.title.alias('post_title'),\n            TabPost.view_count.alias('post_view_count')\n        ).where(\n            TabCollect.user_id == user_id\n        ).join(\n            TabPost, on=(TabCollect.post_id == TabPost.uid)\n        ).count()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_or_update(user_id, app_id):\n        '''\n        Add the collection or update.\n        '''\n\n        rec = MCollect.get_by_signature(user_id, app_id)\n\n        if rec:\n            entry = TabCollect.update(\n                timestamp=int(time.time())\n            ).where(TabCollect.uid == rec.uid)\n            entry.execute()\n        else:\n            TabCollect.create(\n                uid=tools.get_uuid(),\n                user_id=user_id,\n                post_id=app_id,\n                timestamp=int(time.time()),\n            )", "response": "Add the collection or update."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecorates a function to signify its deprecation ifest", "response": "def deprecated(deprecated_in=None, removed_in=None, current_version=None, details=\"\"):\n    \"\"\"Decorate a function to signify its deprecation\n\n    This function wraps a method that will soon be removed and does two things:\n        * The docstring of the method will be modified to include a notice\n          about deprecation, e.g., \"Deprecated since 0.9.11. Use foo instead.\"\n        * Raises a :class:`~deprecation.DeprecatedWarning`\n          via the :mod:`warnings` module, which is a subclass of the built-in\n          :class:`DeprecationWarning`. Note that built-in\n          :class:`DeprecationWarning`\\\\s are ignored by default, so for users\n          to be informed of said warnings they will need to enable them--see\n          the :mod:`warnings` module documentation for more details.\n\n    :param deprecated_in: The version at which the decorated method is\n                          considered deprecated. This will usually be the\n                          next version to be released when the decorator is\n                          added. The default is **None**, which effectively\n                          means immediate deprecation. If this is not\n                          specified, then the `removed_in` and\n                          `current_version` arguments are ignored.\n    :param removed_in: The version when the decorated method will be removed.\n                       The default is **None**, specifying that the function\n                       is not currently planned to be removed.\n                       Note: This cannot be set to a value if\n                       `deprecated_in=None`.\n    :param current_version: The source of version information for the\n                            currently running code. This will usually be\n                            a `__version__` attribute on your library.\n                            The default is `None`.\n                            When `current_version=None` the automation to\n                            determine if the wrapped function is actually\n                            in a period of deprecation or time for removal\n                            does not work, causing a\n                            :class:`~deprecation.DeprecatedWarning`\n                            to be raised in all cases.\n    :param details: Extra details to be added to the method docstring and\n                    warning. For example, the details may point users to\n                    a replacement method, such as \"Use the foo_bar\n                    method instead\". By default there are no details.\n    \"\"\"\n    # You can't just jump to removal. It's weird, unfair, and also makes\n    # building up the docstring weird.\n    if deprecated_in is None and removed_in is not None:\n        raise TypeError(\"Cannot set removed_in to a value \"\n                        \"without also setting deprecated_in\")\n\n    # Only warn when it's appropriate. There may be cases when it makes sense\n    # to add this decorator before a formal deprecation period begins.\n    # In CPython, PendingDeprecatedWarning gets used in that period,\n    # so perhaps mimick that at some point.\n    is_deprecated = False\n    is_unsupported = False\n\n    # StrictVersion won't take a None or a \"\", so make whatever goes to it\n    # is at least *something*.\n    if current_version:\n        current_version = version.StrictVersion(current_version)\n\n        if removed_in and current_version >= version.StrictVersion(removed_in):\n            is_unsupported = True\n        elif deprecated_in and current_version >= version.StrictVersion(deprecated_in):\n            is_deprecated = True\n    else:\n        # If we can't actually calculate that we're in a period of\n        # deprecation...well, they used the decorator, so it's deprecated.\n        # This will cover the case of someone just using\n        # @deprecated(\"1.0\") without the other advantages.\n        is_deprecated = True\n\n    should_warn = any([is_deprecated, is_unsupported])\n\n    def _function_wrapper(function):\n        if should_warn:\n            # Everything *should* have a docstring, but just in case...\n            existing_docstring = function.__doc__ or \"\"\n\n            # The various parts of this decorator being optional makes for\n            # a number of ways the deprecation notice could go. The following\n            # makes for a nicely constructed sentence with or without any\n            # of the parts.\n            parts = {\n                \"deprecated_in\":\n                    \" in %s\" % deprecated_in if deprecated_in else \"\",\n                \"removed_in\":\n                    \", to be removed in %s\" % removed_in if removed_in else \"\",\n                \"period\":\n                    \".\" if deprecated_in or removed_in or details else \"\",\n                \"details\":\n                    \" %s\" % details if details else \"\"}\n\n            deprecation_note = (\"*Deprecated{deprecated_in}{removed_in}\"\n                                \"{period}{details}*\".format(**parts))\n\n            function.__doc__ = \"\\n\\n\".join([existing_docstring,\n                                            deprecation_note])\n\n        @functools.wraps(function)\n        def _inner(*args, **kwargs):\n            if should_warn:\n                if is_unsupported:\n                    cls = UnsupportedWarning\n                else:\n                    cls = DeprecatedWarning\n\n                the_warning = cls(function.__name__, deprecated_in,\n                                  removed_in, details)\n                warnings.warn(the_warning)\n\n            return function(*args, **kwargs)\n\n        return _inner\n\n    return _function_wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fail_if_not_removed(method):\n\n    def _inner(*args, **kwargs):\n        with warnings.catch_warnings(record=True) as caught_warnings:\n            warnings.simplefilter(\"always\")\n            rval = method(*args, **kwargs)\n\n        for warning in caught_warnings:\n            if warning.category == UnsupportedWarning:\n                raise AssertionError(\n                    (\"%s uses a function that should be removed: %s\" %\n                     (method, str(warning.message))))\n        return rval\n\n    return _inner", "response": "Decorator that ensures that the deprecated code is removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gen_xlsx_table_info():\n    '''\n    \u5411\u8868\u4e2d\u63d2\u5165\u6570\u636e\n    '''\n\n    XLSX_FILE = './database/esheet/20180811.xlsx'\n    if os.path.exists(XLSX_FILE):\n        pass\n    else:\n        return\n\n    RAW_LIST = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n                'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n\n    FILTER_COLUMNS = RAW_LIST + [\"A\" + x for x in RAW_LIST] + \\\n                     [\"B\" + x for x in RAW_LIST] + \\\n                     [\"C\" + x for x in RAW_LIST] + \\\n                     [\"D\" + x for x in RAW_LIST]\n\n    tvalue = []\n\n    file_d = open_workbook(XLSX_FILE)\n    # \u83b7\u5f97\u7b2c\u4e00\u4e2a\u9875\u7b7e\u5bf9\u8c61\n\n\n    x = 0\n    for sheet_ranges in load_workbook(filename=XLSX_FILE):\n\n        select_sheet = file_d.sheets()[x]\n\n        # \u83b7\u53d6\u603b\u5171\u7684\u884c\u6570\n        rows_num = select_sheet.nrows + 1\n\n        for row_num in range(6, rows_num):\n            tvalue = []\n            for xr in FILTER_COLUMNS:\n\n                row1_val = sheet_ranges[xr + '1'].value\n                row4_val = sheet_ranges[xr + '{0}'.format(row_num)].value\n\n                if row1_val:\n                    if row4_val == None:\n                        row4_val = ''\n                    tvalue.append(row4_val)\n\n            insert_tab(tvalue)\n        x = x + 1\n    print(\"\u6210\u529f\u63d2\u5165 \" + str(rows_num - 6) + \" \u884c\u6570\u636e\")", "response": "Generate an XLSX table info file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all the arguments from the post request. Only get the first argument by default.", "response": "def get_post_data(self):\n        '''\n        Get all the arguments from post request. Only get the first argument by default.\n        '''\n        post_data = {}\n        for key in self.request.arguments:\n            post_data[key] = self.get_arguments(key)[0]\n        return post_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the user role for docs.", "response": "def check_post_role(self):\n        '''\n        check the user role for docs.\n        '''\n        priv_dic = {'ADD': False, 'EDIT': False, 'DELETE': False, 'ADMIN': False}\n        if self.userinfo:\n            if self.userinfo.role[1] > '0':\n                priv_dic['ADD'] = True\n            if self.userinfo.role[1] >= '1':\n                priv_dic['EDIT'] = True\n            if self.userinfo.role[1] >= '3':\n                priv_dic['DELETE'] = True\n            if self.userinfo.role[1] >= '2':\n                priv_dic['ADMIN'] = True\n        return priv_dic"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding the function to control the UI language.", "response": "def get_user_locale(self):\n        '''\n        Override the function, to control the UI language.\n        '''\n        locale_id = self.get_cookie('ulocale')\n        if locale_id:\n            return tornado.locale.get(locale_id)\n        else:\n            return tornado.locale.get('en_US')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverriding the function to control the UI language.", "response": "def get_browser_locale(self):\n        '''\n        Override the function, to control the UI language.\n        '''\n        locale_id = self.get_cookie('blocale')\n        if locale_id:\n            return tornado.locale.get(locale_id)\n        else:\n            return tornado.locale.get('en_US')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wrap_tmpl(self, tmpl):\n        '''\n        return the warpped template path.\n        :param tmpl:\n        '''\n        return 'admin/' + tmpl.format(sig='p') if self.is_p else tmpl.format(sig='')", "response": "Wrap a template path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the entity id by the path.", "response": "def get_id_by_impath(path):\n        '''\n        The the entity id by the path.\n        '''\n        logger.info('Get Entiry, Path: {0}'.format(path))\n\n        entity_list = TabEntity.select().where(TabEntity.path == path)\n        out_val = None\n        if entity_list.count() == 1:\n            out_val = entity_list.get()\n        elif entity_list.count() > 1:\n            for rec in entity_list:\n                MEntity.delete(rec.uid)\n            out_val = None\n        else:\n            pass\n        return out_val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate entity in the database", "response": "def create_entity(uid='', path='', desc='', kind='1'):\n        '''\n        create entity record in the database.\n        '''\n\n        if path:\n            pass\n        else:\n            return False\n\n        if uid:\n            pass\n        else:\n            uid = get_uuid()\n        try:\n            TabEntity.create(\n                uid=uid,\n                path=path,\n                desc=desc,\n                time_create=time.time(),\n                kind=kind\n            )\n            return True\n        except:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_html_files(*args):\n    '''\n    Generate the templates for adding, editing, viewing.\n    :return: None\n    '''\n    _ = args\n\n    for tag_key, tag_list in SWITCH_DICS.items():\n        if tag_key.startswith('dic_'):\n            __write_view_tmpl(tag_list)\n\n    __write_filter_tmpl(TPL_LIST)\n    __write_list_tmpl(TPL_LISTINFO)", "response": "Generate the templates for adding editing viewing."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds or update the category.", "response": "def add_or_update(self, app_id):\n        '''\n        Add or update the category.\n        '''\n        logger.info('Collect info: user-{0}, uid-{1}'.format(self.userinfo.uid, app_id))\n        MCollect.add_or_update(self.userinfo.uid, app_id)\n        out_dic = {'success': True}\n        return json.dump(out_dic, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows the list of the user collections.", "response": "def show_list(self, the_list, cur_p=''):\n        '''\n        List of the user collections.\n        '''\n\n        current_page_num = int(cur_p) if cur_p else 1\n        current_page_num = 1 if current_page_num < 1 else current_page_num\n\n        num_of_cat = MCollect.count_of_user(self.userinfo.uid)\n        page_num = int(num_of_cat / CMS_CFG['list_num']) + 1\n\n        kwd = {'current_page': current_page_num}\n\n        self.render('misc/collect/list.html',\n                    recs_collect=MCollect.query_pager_by_all(self.userinfo.uid,\n                                                             current_page_num).objects(),\n                    pager=tools.gen_pager_purecss('/collect/{0}'.format(the_list),\n                                                  page_num,\n                                                  current_page_num),\n                    userinfo=self.userinfo,\n\n                    cfg=CMS_CFG,\n                    kwd=kwd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a page with the given slug.", "response": "def create_page(slug, post_data):\n        '''\n        The page would be created with slug.\n        '''\n        logger.info('Call create Page')\n        if MWiki.get_by_uid(slug):\n            return False\n\n        title = post_data['title'].strip()\n        if len(title) < 2:\n            return False\n        return MWiki.__create_rec(slug, '2', post_data=post_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries the wiki of dated.", "response": "def query_dated(num=10, kind='1'):\n        '''\n        List the wiki of dated.\n        '''\n        return TabWiki.select().where(\n            TabWiki.kind == kind\n        ).order_by(\n            TabWiki.time_update.desc()\n        ).limit(num)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery the most viewed wiki.", "response": "def query_most(num=8, kind='1'):\n        '''\n        List the most viewed wiki.\n        '''\n        return TabWiki.select().where(\n            TabWiki.kind == kind\n        ).order_by(\n            TabWiki.view_count.desc()\n        ).limit(num)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_view_count(citiao):\n        '''\n        view count of the wiki, plus 1. By wiki\n        '''\n        entry = TabWiki.update(\n            view_count=TabWiki.view_count + 1\n        ).where(\n            TabWiki.title == citiao\n        )\n        entry.execute()", "response": "Update the view count of the wiki plus 1. By wiki\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_view_count_by_uid(uid):\n        '''\n        update the count of wiki, by uid.\n        '''\n        entry = TabWiki.update(\n            view_count=TabWiki.view_count + 1\n        ).where(\n            TabWiki.uid == uid\n        )\n        entry.execute()", "response": "update the count of wiki by uid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_by_wiki(citiao):\n        '''\n        Get the wiki record by title.\n        '''\n        q_res = TabWiki.select().where(TabWiki.title == citiao)\n        the_count = q_res.count()\n        if the_count == 0 or the_count > 1:\n            return None\n        else:\n            MWiki.update_view_count(citiao)\n            return q_res.get()", "response": "Get the wiki record by title."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nviews count plus one.", "response": "def view_count_plus(slug):\n        '''\n        View count plus one.\n        '''\n        entry = TabWiki.update(\n            view_count=TabWiki.view_count + 1,\n        ).where(TabWiki.uid == slug)\n        entry.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries pager by kind", "response": "def query_pager_by_kind(kind, current_page_num=1):\n        '''\n        Query pager\n        '''\n        return TabWiki.select().where(TabWiki.kind == kind).order_by(TabWiki.time_create.desc()).paginate(current_page_num, CMS_CFG['list_num'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the count of certain kind.", "response": "def count_of_certain_kind(kind):\n        '''\n        Get the count of certain kind.\n        '''\n\n        recs = TabWiki.select().where(TabWiki.kind == kind)\n\n        return recs.count()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the ID of a tag by its name.", "response": "def get_id_by_name(tag_name, kind='z'):\n        '''\n        Get ID by tag_name of the label.\n        '''\n        recs = TabTag.select().where(\n            (TabTag.name == tag_name) & (TabTag.kind == kind)\n        )\n        logger.info('tag count of {0}: {1} '.format(tag_name, recs.count()))\n        # the_id = ''\n        if recs.count() == 1:\n            the_id = recs.get().uid\n        elif recs.count() > 1:\n            rec0 = None\n            for rec in recs:\n                # Only keep one.\n                if rec0:\n                    TabPost2Tag.delete().where(TabPost2Tag.tag_id == rec.uid).execute()\n                    TabTag.delete().where(TabTag.uid == rec.uid).execute()\n                else:\n                    rec0 = rec\n\n            the_id = rec0.uid\n        else:\n            the_id = MLabel.create_tag(tag_name)\n        return the_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting label by slug.", "response": "def get_by_slug(tag_slug):\n        '''\n        Get label by slug.\n        '''\n        label_recs = TabTag.select().where(TabTag.slug == tag_slug)\n        return label_recs.get() if label_recs else False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_tag(tag_name, kind='z'):\n        '''\n        Create tag record by tag_name\n        '''\n        cur_recs = TabTag.select().where(\n            (TabTag.name == tag_name) &\n            (TabTag.kind == kind)\n        )\n        if cur_recs.count():\n            uid = cur_recs.get().uid\n\n            # TabTag.delete().where(\n            #     (TabTag.name == tag_name) &\n            #     (TabTag.kind == kind)\n            # ).execute()\n        else:\n            uid = tools.get_uu4d_v2()  # Label with the ID of v2.\n            while TabTag.select().where(TabTag.uid == uid).count() > 0:\n                uid = tools.get_uu4d_v2()\n\n            TabTag.create(\n                uid=uid,\n                slug=uid,\n                name=tag_name,\n                order=1,\n                count=0,\n                kind='z',\n                tmpl=9,\n                pid='zzzz',\n            )\n        return uid", "response": "Create tag record by tag_name and kind."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets records by post id.", "response": "def get_by_uid(post_id):\n        '''\n        Get records by post id.\n        '''\n        return TabPost2Tag.select(\n            TabPost2Tag,\n            TabTag.name.alias('tag_name'),\n            TabTag.uid.alias('tag_uid')\n        ).join(\n            TabTag, on=(TabPost2Tag.tag_id == TabTag.uid)\n        ).where(\n            (TabPost2Tag.post_id == post_id) & (TabTag.kind == 'z')\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of certian slug.", "response": "def total_number(slug, kind='1'):\n        '''\n        Return the number of certian slug.\n        '''\n        return TabPost.select().join(\n            TabPost2Tag,\n            on=(TabPost.uid == TabPost2Tag.post_id)\n        ).where(\n            (TabPost2Tag.tag_id == slug) & (TabPost.kind == kind)\n        ).count()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_pager_by_slug(slug, kind='1', current_page_num=1):\n        '''\n        Query pager\n        '''\n        return TabPost.select().join(\n            TabPost2Tag, on=(TabPost.uid == TabPost2Tag.post_id)\n        ).where(\n            (TabPost2Tag.tag_id == slug) &\n            (TabPost.kind == kind)\n        ).paginate(current_page_num, CMS_CFG['list_num'])", "response": "Query pager by slug."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_or_update(self, app_id, value):\n        '''\n        Adding or updating the evalution.\n        :param app_id:  the ID of the post.\n        :param value: the evaluation\n        :return:  in JSON format.\n        '''\n        MEvaluation.add_or_update(self.userinfo.uid, app_id, value)\n\n        out_dic = {\n            'eval0': MEvaluation.app_evaluation_count(app_id, 0),\n            'eval1': MEvaluation.app_evaluation_count(app_id, 1)\n        }\n\n        return json.dump(out_dic, self)", "response": "Adds or updates the evalution."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate entity2user record in the database.", "response": "def create_entity2user(enti_uid, user_id):\n        '''\n        create entity2user record in the database.\n        '''\n        record = TabEntity2User.select().where(\n            (TabEntity2User.entity_id == enti_uid) & (TabEntity2User.user_id == user_id)\n        )\n\n        if record.count() > 0:\n            record = record.get()\n            MEntity2User.count_increate(record.uid, record.count)\n        else:\n            TabEntity2User.create(\n                uid=tools.get_uuid(),\n                entity_id=enti_uid,\n                user_id=user_id,\n                count=1,\n                timestamp=time.time()\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck the HTML file for the specific page.", "response": "def check_html(html_file, begin):\n    '''\n    Checking the HTML\n    '''\n    sig = False\n    for html_line in open(html_file).readlines():\n\n        # uu = x.find('{% extends')\n        uuu = pack_str(html_line).find('%extends')\n        # print(pack_str(x))\n        if uuu > 0:\n            f_tmpl = html_line.strip().split()[-2].strip('\"')\n            curpath, curfile = os.path.split(html_file)\n            ff_tmpl = os.path.abspath(os.path.join(curpath, f_tmpl))\n            if os.path.isfile(ff_tmpl):\n                # print(os.path.abspath(ff_tmpl))\n                pass\n            else:\n                print('=' *10 + 'ERROR' + '=' *10)\n                print('The file:')\n                print(' ' * 4 + html_file)\n                print('needs:')\n                print(' ' * 4 +ff_tmpl)\n                print('Error, tmpl not find.')\n                # continue\n                sys.exit(1)\n            sig = True\n        if sig:\n            pass\n        else:\n            continue\n        vvv = pack_str(html_line).find('%block')\n        if vvv > 0:\n            test_fig = False\n            for the_line in open(ff_tmpl).readlines():\n                if the_line.find(pack_str(html_line)) > 0:\n                    test_fig = True\n\n            # fff = sim_filename(ff_tmpl)\n            # sss = sim_filename(html_file)\n\n            fff = ff_tmpl[begin:]\n            sss = html_file[begin:]\n\n            tmplsig = [fff, sss]\n\n            if tmplsig in RELS_UNIQ_ARR:\n                pass\n            else:\n                RELS_UNIQ_ARR.append(tmplsig)\n                DOT_OBJ.edge(fff, sss)\n            if test_fig:\n                # G.add_edge(ff_tmpl[begin], html_file[begin])\n                pass\n            else:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_for_dir(inws, begin):\n    '''\n    do something in the directory.\n    '''\n    inws = os.path.abspath(inws)\n    for wroot, wdirs, wfiles in os.walk(inws):\n        for wfile in wfiles:\n            if wfile.endswith('.html'):\n                if 'autogen' in wroot:\n                    continue\n                check_html(os.path.abspath(os.path.join(wroot, wfile)), begin)", "response": "do something in the directory inws"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndoing check it. srws is a list of srws to check it.", "response": "def run_checkit(srws=None):\n    '''\n    do check it.\n    '''\n    begin = len(os.path.abspath('templates')) + 1\n    inws = os.path.abspath(os.getcwd())\n    if srws:\n        do_for_dir(srws[0], begin)\n    else:\n        do_for_dir(os.path.join(inws, 'templates'), begin)\n\n    DOT_OBJ.render('xxtmpl', view=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_all():\n        '''\n        Query all the records from TabPost2Tag.\n        '''\n        recs = TabPost2Tag.select(\n            TabPost2Tag,\n            TabTag.kind.alias('tag_kind'),\n        ).join(\n            TabTag,\n            on=(TabPost2Tag.tag_id == TabTag.uid)\n        )\n        return recs", "response": "Query all the records from TabPost2Tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves the relation between post and tag.", "response": "def remove_relation(post_id, tag_id):\n        '''\n        Delete the record of post 2 tag.\n        '''\n        entry = TabPost2Tag.delete().where(\n            (TabPost2Tag.post_id == post_id) &\n            (TabPost2Tag.tag_id == tag_id)\n        )\n        entry.execute()\n        MCategory.update_count(tag_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_tag(tag_id):\n        '''\n        Delete the records of certain tag.\n        '''\n        entry = TabPost2Tag.delete().where(\n            TabPost2Tag.tag_id == tag_id\n        )\n        entry.execute()", "response": "Remove the records of certain tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying records by post.", "response": "def query_by_post(postid):\n        '''\n        Query records by post.\n        '''\n        return TabPost2Tag.select().where(\n            TabPost2Tag.post_id == postid\n        ).order_by(TabPost2Tag.order)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the record by post and catalog.", "response": "def __get_by_info(post_id, catalog_id):\n        '''\n        Geo the record by post and catalog.\n        '''\n        recs = TabPost2Tag.select().where(\n            (TabPost2Tag.post_id == post_id) &\n            (TabPost2Tag.tag_id == catalog_id)\n        )\n\n        if recs.count() == 1:\n            return recs.get()\n        elif recs.count() > 1:\n            # return the first one, and delete others.\n            out_rec = None\n            for rec in recs:\n                if out_rec:\n                    entry = TabPost2Tag.delete().where(\n                        TabPost2Tag.uid == rec.uid\n                    )\n                    entry.execute()\n                else:\n                    out_rec = rec\n            return out_rec\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the count of post2tag.", "response": "def query_count():\n        '''\n        The count of post2tag.\n        '''\n        recs = TabPost2Tag.select(\n            TabPost2Tag.tag_id,\n            peewee.fn.COUNT(TabPost2Tag.tag_id).alias('num')\n        ).group_by(\n            TabPost2Tag.tag_id\n        )\n        return recs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the field of post2tag.", "response": "def update_field(uid, post_id=None, tag_id=None, par_id=None):\n        '''\n        Update the field of post2tag.\n        '''\n        if post_id:\n            entry = TabPost2Tag.update(\n                post_id=post_id\n            ).where(TabPost2Tag.uid == uid)\n            entry.execute()\n\n        if tag_id:\n            entry2 = TabPost2Tag.update(\n                par_id=tag_id[:2] + '00',\n                tag_id=tag_id,\n            ).where(TabPost2Tag.uid == uid)\n            entry2.execute()\n        if par_id:\n            entry2 = TabPost2Tag.update(\n                par_id=par_id\n            ).where(TabPost2Tag.uid == uid)\n            entry2.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a record of post 2 tag.", "response": "def add_record(post_id, catalog_id, order=0):\n        '''\n        Create the record of post 2 tag, and update the count in g_tag.\n        '''\n\n        rec = MPost2Catalog.__get_by_info(post_id, catalog_id)\n        if rec:\n            entry = TabPost2Tag.update(\n                order=order,\n                # For migration. the value should be added when created.\n                par_id=rec.tag_id[:2] + '00',\n            ).where(TabPost2Tag.uid == rec.uid)\n            entry.execute()\n        else:\n            TabPost2Tag.create(\n                uid=tools.get_uuid(),\n                par_id=catalog_id[:2] + '00',\n                post_id=post_id,\n                tag_id=catalog_id,\n                order=order,\n            )\n\n        MCategory.update_count(catalog_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_of_certain_category(cat_id, tag=''):\n        '''\n        Get the count of certain category.\n        '''\n\n        if cat_id.endswith('00'):\n            # The first level category, using the code bellow.\n            cat_con = TabPost2Tag.par_id == cat_id\n        else:\n            cat_con = TabPost2Tag.tag_id == cat_id\n\n        if tag:\n            condition = {\n                'def_tag_arr': [tag]\n            }\n            recs = TabPost2Tag.select().join(\n                TabPost,\n                on=((TabPost2Tag.post_id == TabPost.uid) & (TabPost.valid == 1))\n            ).where(\n                cat_con & TabPost.extinfo.contains(condition)\n            )\n        else:\n            recs = TabPost2Tag.select().where(\n                cat_con\n            )\n\n        return recs.count()", "response": "Get the count of certain category."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query_pager_by_slug(slug, current_page_num=1, tag='', order=False):\n        '''\n        Query pager via category slug.\n        '''\n        cat_rec = MCategory.get_by_slug(slug)\n        if cat_rec:\n            cat_id = cat_rec.uid\n        else:\n            return None\n\n        # The flowing code is valid.\n        if cat_id.endswith('00'):\n            # The first level category, using the code bellow.\n            cat_con = TabPost2Tag.par_id == cat_id\n        else:\n            cat_con = TabPost2Tag.tag_id == cat_id\n\n        if tag:\n            condition = {\n                'def_tag_arr': [tag]\n            }\n            recs = TabPost.select().join(\n                TabPost2Tag,\n                on=((TabPost.uid == TabPost2Tag.post_id) & (TabPost.valid == 1))\n            ).where(\n                cat_con & TabPost.extinfo.contains(condition)\n            ).order_by(\n                TabPost.time_update.desc()\n            ).paginate(current_page_num, CMS_CFG['list_num'])\n        elif order:\n            recs = TabPost.select().join(\n                TabPost2Tag,\n                on=((TabPost.uid == TabPost2Tag.post_id) & (TabPost.valid == 1))\n            ).where(\n                cat_con\n            ).order_by(\n                TabPost.order.asc()\n            )\n        else:\n            recs = TabPost.select().join(\n                TabPost2Tag,\n                on=((TabPost.uid == TabPost2Tag.post_id) & (TabPost.valid == 1))\n            ).where(\n                cat_con\n            ).order_by(\n                TabPost.time_update.desc()\n            ).paginate(current_page_num, CMS_CFG['list_num'])\n\n        return recs", "response": "Query pager via category slug."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_by_entity_uid(idd, kind=''):\n        '''\n        Query post2tag by certain post.\n        '''\n\n        if kind == '':\n            return TabPost2Tag.select(\n                TabPost2Tag,\n                TabTag.slug.alias('tag_slug'),\n                TabTag.name.alias('tag_name')\n            ).join(\n                TabTag, on=(TabPost2Tag.tag_id == TabTag.uid)\n            ).where(\n                (TabPost2Tag.post_id == idd) &\n                (TabTag.kind != 'z')\n            ).order_by(\n                TabPost2Tag.order\n            )\n        return TabPost2Tag.select(\n            TabPost2Tag,\n            TabTag.slug.alias('tag_slug'),\n            TabTag.name.alias('tag_name')\n        ).join(TabTag, on=(TabPost2Tag.tag_id == TabTag.uid)).where(\n            (TabTag.kind == kind) &\n            (TabPost2Tag.post_id == idd)\n        ).order_by(\n            TabPost2Tag.order\n        )", "response": "Query post2tag by certain post."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_first_category(app_uid):\n        '''\n        Get the first, as the uniqe category of post.\n        '''\n        recs = MPost2Catalog.query_by_entity_uid(app_uid).objects()\n        if recs.count() > 0:\n            return recs.get()\n\n        return None", "response": "Get the first uniqe category of post."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender the info page for the current user.", "response": "def render(self, *args, **kwargs):\n        '''\n        fun(uid_with_str)\n        fun(uid_with_str, slug = val1, glyph = val2)\n        '''\n\n        uid_with_str = args[0]\n\n        slug = kwargs.get('slug', False)\n\n        with_title = kwargs.get('with_title', False)\n\n        glyph = kwargs.get('glyph', '')\n\n        kwd = {\n            'glyph': glyph\n        }\n        curinfo = MCategory.get_by_uid(uid_with_str)\n\n        sub_cats = MCategory.query_sub_cat(uid_with_str)\n\n        if slug:\n            tmpl = 'modules/info/catalog_slug.html'\n\n        else:\n            tmpl = 'modules/info/catalog_of.html'\n        return self.render_string(tmpl,\n                                  pcatinfo=curinfo,\n                                  sub_cats=sub_cats,\n                                  recs=sub_cats,\n                                  with_title=with_title,\n                                  kwd=kwd)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, *args, **kwargs):\n        '''\n        fun(user_name, kind)\n        fun(user_name, kind, num)\n        fun(user_name, kind, num, with_tag = val1, glyph = val2)\n        fun(user_name = vala, kind = valb, num = valc, with_tag = val1, glyph = val2)\n        '''\n        user_name = kwargs.get('user_name', args[0])\n        kind = kwargs.get('kind', args[1])\n        num = kwargs.get('num', args[2] if len(args) > 2 else 6)\n        with_tag = kwargs.get('with_tag', False)\n        glyph = kwargs.get('glyph', '')\n\n        all_cats = MUsage.query_most(user_name, kind, num).objects()\n        kwd = {\n            'with_tag': with_tag,\n            'router': router_post[kind],\n            'glyph': glyph\n        }\n        return self.render_string('modules/info/list_user_equation.html',\n                                  recs=all_cats,\n                                  kwd=kwd)", "response": "Render the most recent user - related entries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_it(self, *args, **kwargs):\n        '''\n        Render without userinfo.\n        fun(kind, num)\n        fun(kind, num, with_tag = val1)\n        fun(kind, num, with_tag = val1, glyph = val2)\n        '''\n        kind = kwargs.get('kind', args[0])\n        num = kwargs.get('num', args[1] if len(args) > 1 else 6)\n        with_tag = kwargs.get('with_tag', False)\n        glyph = kwargs.get('glyph', '')\n\n        all_cats = MPost.query_most(kind=kind, num=num).objects()\n        kwd = {\n            'with_tag': with_tag,\n            'router': router_post[kind],\n            'glyph': glyph\n        }\n        return self.render_string('modules/info/list_equation.html',\n                                  recs=all_cats,\n                                  kwd=kwd)", "response": "Render without userinfo.\n        fun(kind, num)\n        fun(kind, num, with_tag = val1)\n        fun(kind, num, with_tag = val1, glyph = val2)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender no user logged in render no user logged in", "response": "def render_it(self, kind, num, with_tag=False, glyph=''):\n        '''\n        render, no user logged in\n        '''\n        all_cats = MPost.query_recent(num, kind=kind)\n        kwd = {\n            'with_tag': with_tag,\n            'router': router_post[kind],\n            'glyph': glyph\n        }\n        return self.render_string('modules/info/list_equation.html',\n                                  recs=all_cats,\n                                  kwd=kwd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_user(self, *args, **kwargs):\n        '''\n        render, with userinfo\n        fun(kind, num)\n        fun(kind, num, with_tag = val1)\n        fun(kind, num, with_tag = val1, user_id = val2)\n        fun(kind, num, with_tag = val1, user_id = val2, glyph = val3)\n        '''\n\n        kind = kwargs.get('kind', args[0])\n        num = kwargs.get('num', args[1] if len(args) > 1 else 6)\n        with_tag = kwargs.get('with_tag', False)\n        user_id = kwargs.get('user_id', '')\n        glyph = kwargs.get('glyph', '')\n\n        logger.info(\n            'Infor user recent, username: {user_name}, kind: {kind}, num: {num}'.format(\n                user_name=user_id, kind=kind, num=num\n            )\n        )\n\n        all_cats = MUsage.query_recent(user_id, kind, num).objects()\n        kwd = {\n            'with_tag': with_tag,\n            'router': router_post[kind],\n            'glyph': glyph\n        }\n        return self.render_string('modules/info/list_user_equation.html',\n                                  recs=all_cats,\n                                  kwd=kwd)", "response": "render, with userinfo\n        fun(kind, num)\n        fun(kind, num, with_tag = val1)\n        fun(kind, num, with_tag = val1, user_id = val2)\n        fun(kind, num, with_tag = val1, user_id = val2, glyph = val3)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_modify(self, uid):\n        '''\n        Try to edit the link.\n        '''\n        if self.userinfo.role[1] >= '3':\n            pass\n        else:\n            return False\n\n        self.render('misc/link/link_edit.html',\n                    kwd={},\n                    postinfo=MLink.get_by_uid(uid),\n                    userinfo=self.userinfo)", "response": "Try to edit the link."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate link by user.", "response": "def user_add_link(self):\n        '''\n        Create link by user.\n        '''\n        if self.check_post_role()['ADD']:\n            pass\n        else:\n            return False\n        post_data = self.get_post_data()\n\n        post_data['user_name'] = self.get_current_user()\n\n        cur_uid = tools.get_uudd(2)\n        while MLink.get_by_uid(cur_uid):\n            cur_uid = tools.get_uudd(2)\n\n        MLink.create_link(cur_uid, post_data)\n\n        self.redirect('/link/list')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_by_id(self, del_id):\n        '''\n        Delete a link by id.\n        '''\n        if self.check_post_role()['DELETE']:\n            pass\n        else:\n            return False\n        if self.is_p:\n            if MLink.delete(del_id):\n                output = {'del_link': 1}\n            else:\n                output = {'del_link': 0}\n            return json.dump(output, self)\n        else:\n            is_deleted = MLink.delete(del_id)\n            if is_deleted:\n                self.redirect('/link/list')", "response": "Delete a link by id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_rating(postid, userid):\n        '''\n        Get the rating of certain post and user.\n        '''\n        try:\n            recs = TabRating.select().where(\n                (TabRating.post_id == postid) & (TabRating.user_id == userid)\n            )\n        except:\n            return False\n        if recs.count() > 0:\n            return recs.get().rating\n        else:\n            return False", "response": "Get the rating of certain post and user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the rating of certain post and user.", "response": "def update(postid, userid, rating):\n        '''\n        Update the rating of certain post and user.\n        The record will be created if no record exists.\n        '''\n        rating_recs = TabRating.select().where(\n            (TabRating.post_id == postid) & (TabRating.user_id == userid)\n        )\n        if rating_recs.count() > 0:\n            MRating.__update_rating(rating_recs.get().uid, rating)\n        else:\n            MRating.__insert_data(postid, userid, rating)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __update_rating(uid, rating):\n        '''\n        Update rating.\n        '''\n        entry = TabRating.update(\n            rating=rating\n        ).where(TabRating.uid == uid)\n        entry.execute()", "response": "Update the rating table with the given uid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert data into the record.", "response": "def __insert_data(postid, userid, rating):\n        '''\n        Inert new record.\n        '''\n        uid = tools.get_uuid()\n        TabRating.create(\n            uid=uid,\n            post_id=postid,\n            user_id=userid,\n            rating=rating,\n            timestamp=tools.timestamp(),\n        )\n        return uid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_category(uid, postdata, kwargs):\n    '''\n    Update the category of the post.\n    '''\n    catid = kwargs['catid'] if ('catid' in kwargs and MCategory.get_by_uid(kwargs['catid'])) else None\n\n    post_data = postdata\n\n    current_infos = MPost2Catalog.query_by_entity_uid(uid, kind='').objects()\n\n    new_category_arr = []\n    # Used to update post2category, to keep order.\n    def_cate_arr = ['gcat{0}'.format(x) for x in range(10)]\n\n    # for old page.\n    def_cate_arr.append('def_cat_uid')\n\n    # Used to update post extinfo.\n    cat_dic = {}\n    for key in def_cate_arr:\n        if key not in post_data:\n            continue\n        if post_data[key] == '' or post_data[key] == '0':\n            continue\n        # \u6709\u53ef\u80fd\u9009\u91cd\u590d\u4e86\u3002\u4fdd\u7559\u524d\u9762\u7684\n        if post_data[key] in new_category_arr:\n            continue\n\n        new_category_arr.append(post_data[key] + ' ' * (4 - len(post_data[key])))\n        cat_dic[key] = post_data[key] + ' ' * (4 - len(post_data[key]))\n\n    if catid:\n        def_cat_id = catid\n    elif new_category_arr:\n        def_cat_id = new_category_arr[0]\n    else:\n        def_cat_id = None\n\n    if def_cat_id:\n        cat_dic['def_cat_uid'] = def_cat_id\n        cat_dic['def_cat_pid'] = MCategory.get_by_uid(def_cat_id).pid\n\n    print('=' * 40)\n    print(uid)\n    print(cat_dic)\n    MPost.update_jsonb(uid, cat_dic)\n\n    for index, catid in enumerate(new_category_arr):\n        MPost2Catalog.add_record(uid, catid, index)\n\n    # Delete the old category if not in post requests.\n    for cur_info in current_infos:\n        if cur_info.tag_id not in new_category_arr:\n            MPost2Catalog.remove_relation(uid, cur_info.tag_id)", "response": "Update the category of the post."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_relation(app_f, app_t, weight=1):\n        '''\n        Adding relation between two posts.\n        '''\n        recs = TabRel.select().where(\n            (TabRel.post_f_id == app_f) & (TabRel.post_t_id == app_t)\n        )\n        if recs.count() > 1:\n            for record in recs:\n                MRelation.delete(record.uid)\n\n        if recs.count() == 0:\n            uid = tools.get_uuid()\n            entry = TabRel.create(\n                uid=uid,\n                post_f_id=app_f,\n                post_t_id=app_t,\n                count=1,\n            )\n            return entry.uid\n        elif recs.count() == 1:\n            MRelation.update_relation(app_f, app_t, weight)\n        else:\n            return False", "response": "Adds relation between two posts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_app_relations(app_id, num=20, kind='1'):\n        '''\n        The the related infors.\n        '''\n        info_tag = MInfor2Catalog.get_first_category(app_id)\n        if info_tag:\n            return TabPost2Tag.select(\n                TabPost2Tag,\n                TabPost.title.alias('post_title'),\n                TabPost.valid.alias('post_valid')\n            ).join(\n                TabPost, on=(TabPost2Tag.post_id == TabPost.uid)\n            ).where(\n                (TabPost2Tag.tag_id == info_tag.tag_id) &\n                (TabPost.kind == kind)\n            ).order_by(\n                peewee.fn.Random()\n            ).limit(num)\n        return TabPost2Tag.select(\n            TabPost2Tag,\n            TabPost.title.alias('post_title'),\n            TabPost.valid.alias('post_valid')\n        ).join(\n            TabPost, on=(TabPost2Tag.post_id == TabPost.uid)\n        ).where(\n            TabPost.kind == kind\n        ).order_by(peewee.fn.Random()).limit(num)", "response": "Get the related infors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, *args, **kwargs):\n        '''\n        /label/s/view\n        '''\n        url_arr = self.parse_url(args[0])\n\n        if len(url_arr) == 2:\n            if url_arr[0] == 'remove':\n                self.remove_redis_keyword(url_arr[1])\n            else:\n                self.list(url_arr[0], url_arr[1])\n        elif len(url_arr) == 3:\n            self.list(url_arr[0], url_arr[1], url_arr[2])\n        else:\n            return False", "response": "Get a specific resource from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the keyword for redis.", "response": "def remove_redis_keyword(self, keyword):\n        '''\n        Remove the keyword for redis.\n        '''\n        redisvr.srem(CMS_CFG['redis_kw'] + self.userinfo.user_name, keyword)\n        return json.dump({}, self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nview the label list.", "response": "def list(self, kind, tag_slug, cur_p=''):\n        '''\n        \u6839\u636e cat_handler.py \u4e2d\u7684 def view_cat_new(self, cat_slug, cur_p = '')\n        '''\n        # \u4e0b\u9762\u7528\u6765\u4f7f\u7528\u5173\u952e\u5b57\u8fc7\u6ee4\u4fe1\u606f\uff0c\u5982\u679c\u7f51\u7ad9\u4fe1\u606f\u91cf\u4e0d\u662f\u5f88\u5927\u4e0d\u8981\u5f00\u542f\n        # Todo:\n        # if self.get_current_user():\n        #     redisvr.sadd(config.redis_kw + self.userinfo.user_name, tag_slug)\n\n        if cur_p == '':\n            current_page_number = 1\n        else:\n            current_page_number = int(cur_p)\n\n        current_page_number = 1 if current_page_number < 1 else current_page_number\n\n        pager_num = int(MPost2Label.total_number(tag_slug, kind) / CMS_CFG['list_num'])\n        tag_info = MLabel.get_by_slug(tag_slug)\n        if tag_info:\n            tag_name = tag_info.name\n        else:\n            tag_name = 'Label search results'\n        kwd = {'tag_name': tag_name,\n               'tag_slug': tag_slug,\n               'title': tag_name,\n               'current_page': current_page_number,\n               'router': router_post[kind],\n               'kind': kind\n               }\n\n        the_list_file = './templates/list/label_{kind}.html'.format(kind=kind)\n\n        if os.path.exists(the_list_file):\n            tmpl = 'list/label_{kind}.html'.format(kind=kind)\n\n        else:\n            tmpl = 'list/label.html'\n\n        self.render(tmpl,\n                    infos=MPost2Label.query_pager_by_slug(\n                        tag_slug,\n                        kind=kind,\n                        current_page_num=current_page_number\n                    ),\n                    kwd=kwd,\n                    userinfo=self.userinfo,\n                    pager=self.gen_pager(kind, tag_slug, pager_num, current_page_number),\n                    cfg=CMS_CFG)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gen_pager(self, kind, cat_slug, page_num, current):\n        '''\n        cat_slug \u5206\u7c7b\n        page_num \u9875\u9762\u603b\u6570\n        current \u5f53\u524d\u9875\u9762\n        '''\n        if page_num == 1:\n            return ''\n\n        pager_shouye = '''<li class=\"{0}\">   <a href=\"/label/{1}/{2}\">&lt;&lt; \u9996\u9875</a>\n        </li>'''.format(\n            'hidden' if current <= 1 else '', kind, cat_slug\n        )\n\n        pager_pre = '''<li class=\"{0}\"><a href=\"/label/{1}/{2}/{3}\">&lt; \u524d\u9875</a>\n        </li>'''.format(\n            'hidden' if current <= 1 else '', kind, cat_slug, current - 1\n        )\n        pager_mid = ''\n        for ind in range(0, page_num):\n            tmp_mid = '''<li class=\"{0}\"><a  href=\"/label/{1}/{2}/{3}\">{3}</a>\n            </li>'''.format(\n                'active' if ind + 1 == current else '', kind, cat_slug, ind + 1\n            )\n            pager_mid += tmp_mid\n        pager_next = '''<li class=\" {0}\"><a  href=\"/label/{1}/{2}/{3}\">\u540e\u9875 &gt;</a>\n        </li>'''.format(\n            'hidden' if current >= page_num else '', kind, cat_slug, current + 1\n        )\n        pager_last = '''<li class=\" {0}\"><a href=\"/label/{1}/{2}/{3}\">\u672b\u9875&gt;&gt;</a>\n        </li>'''.format(\n            'hidden' if current >= page_num else '', kind, cat_slug, page_num\n        )\n        pager = pager_shouye + pager_pre + pager_mid + pager_next + pager_last\n        return pager", "response": "Generate a pager for the page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild the directory for Whoosh database and locale.", "response": "def build_directory():\n    '''\n    Build the directory for Whoosh database, and locale.\n    '''\n    if os.path.exists('locale'):\n        pass\n    else:\n        os.mkdir('locale')\n    if os.path.exists(WHOOSH_DB_DIR):\n        pass\n    else:\n        os.makedirs(WHOOSH_DB_DIR)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_check_kind(_):\n    '''\n    Running the script.\n    '''\n    for kindv in router_post:\n        for rec_cat in MCategory.query_all(kind=kindv):\n            catid = rec_cat.uid\n            catinfo = MCategory.get_by_uid(catid)\n            for rec_post2tag in MPost2Catalog.query_by_catid(catid):\n                postinfo = MPost.get_by_uid(rec_post2tag.post_id)\n                if postinfo.kind == catinfo.kind:\n                    pass\n                else:\n                    print(postinfo.uid)", "response": "Check if the kind of post is the same as the category."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_create_admin(*args):\n    '''\n    creating the default administrator.\n    '''\n    post_data = {\n        'user_name': 'giser',\n        'user_email': 'giser@osgeo.cn',\n        'user_pass': '131322',\n        'role': '3300',\n    }\n    if MUser.get_by_name(post_data['user_name']):\n        print('User {user_name} already exists.'.format(user_name='giser'))\n    else:\n        MUser.create_user(post_data)", "response": "Create the default administrator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_post(self, postid):\n        '''\n        The rating of Post should be updaed if the count is greater than 10\n\n\n        '''\n        voted_recs = MRating.query_by_post(postid)\n        if voted_recs.count() > 10:\n            rating = MRating.query_average_rating(postid)\n        else:\n            rating = 5\n\n        logger.info('Get post rating: {rating}'.format(rating=rating))\n        # MPost.__update_rating(postid, rating)\n        MPost.update_misc(postid, rating=rating)", "response": "Update the post with the rating of the given postid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_rating(self, postid):\n        '''\n        only the used who logged in would voting.\n        '''\n        post_data = self.get_post_data()\n        rating = float(post_data['rating'])\n        postinfo = MPost.get_by_uid(postid)\n        if postinfo and self.userinfo:\n            MRating.update(postinfo.uid, self.userinfo.uid, rating=rating)\n            self.update_post(postid)\n        else:\n            return False", "response": "update the rating of the user"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __get_diff_recent():\n    '''\n    Generate the difference of posts. recently.\n    '''\n    diff_str = ''\n\n    for key in router_post:\n        recent_posts = MPost.query_recent_edited(tools.timestamp() - TIME_LIMIT, kind=key)\n        for recent_post in recent_posts:\n            hist_rec = MPostHist.get_last(recent_post.uid)\n            if hist_rec:\n                raw_title = hist_rec.title\n                new_title = recent_post.title\n\n                infobox = diff_table(raw_title, new_title)\n\n                diff_str = diff_str + '''\n                <h2 style=\"color:red;font-size:larger;font-weight:70;\">TITLE: {0}</h2>\n                '''.format(recent_post.title) + infobox\n\n                infobox = diff_table(hist_rec.cnt_md, recent_post.cnt_md)\n\n                diff_str = diff_str + '<h3>CONTENT:{0}</h3>'.format(\n                    recent_post.title\n                ) + infobox + '</hr>'\n            else:\n                continue\n    return diff_str", "response": "Generate the difference of posts. recently."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets Review for wikis.", "response": "def __get_wiki_review(email_cnt, idx):\n    '''\n    Review for wikis.\n    '''\n    recent_posts = MWiki.query_recent_edited(tools.timestamp() - TIME_LIMIT, kind='2')\n    for recent_post in recent_posts:\n        hist_rec = MWikiHist.get_last(recent_post.uid)\n        if hist_rec:\n            foo_str = '''\n                    <tr><td>{0}</td><td>{1}</td><td class=\"diff_chg\">Edit</td><td>{2}</td>\n                    <td><a href=\"{3}\">{3}</a></td></tr>\n                    '''.format(idx, recent_post.user_name, recent_post.title,\n                               os.path.join(SITE_CFG['site_url'], 'page', recent_post.uid))\n            email_cnt = email_cnt + foo_str\n        else:\n            foo_str = '''\n                    <tr><td>{0}</td><td>{1}</td><td class=\"diff_add\">New </td><td>{2}</td>\n                    <td><a href=\"{3}\">{3}</a></td></tr>\n                    '''.format(idx, recent_post.user_name, recent_post.title,\n                               os.path.join(SITE_CFG['site_url'], 'page', recent_post.uid))\n            email_cnt = email_cnt + foo_str\n        idx = idx + 1\n    email_cnt = email_cnt + '</table>'\n    return email_cnt, idx"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting Review for posts.", "response": "def __get_post_review(email_cnt, idx):\n    '''\n    Review for posts.\n    '''\n    for key in router_post:\n        recent_posts = MPost.query_recent_edited(tools.timestamp() - TIME_LIMIT, kind=key)\n        for recent_post in recent_posts:\n            hist_rec = MPostHist.get_last(recent_post.uid)\n            if hist_rec:\n                foo_str = '''\n                    <tr><td>{0}</td><td>{1}</td><td class=\"diff_chg\">Edit</td><td>{2}</td>\n                    <td><a href=\"{3}\">{3}</a></td></tr>\n                    '''.format(idx, recent_post.user_name, recent_post.title,\n                               os.path.join(SITE_CFG['site_url'], router_post[key],\n                                            recent_post.uid))\n                email_cnt = email_cnt + foo_str\n            else:\n                foo_str = '''\n                    <tr><td>{0}</td><td>{1}</td><td class=\"diff_add\">New </td><td>{2}</td>\n                    <td><a href=\"{3}\">{3}</a></td></tr>\n                    '''.format(idx, recent_post.user_name, recent_post.title,\n                               os.path.join(SITE_CFG['site_url'], router_post[key],\n                                            recent_post.uid))\n                email_cnt = email_cnt + foo_str\n            idx = idx + 1\n\n    return email_cnt, idx"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the Review command.", "response": "def run_review(*args):\n    '''\n    Get the difference of recents modification, and send the Email.\n    For: wiki, page, and post.\n    '''\n    email_cnt = '''<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n    <title></title>\n    <style type=\"text/css\">\n        table.diff {font-family:Courier; border:medium;}\n        .diff_header {background-color:#e0e0e0}\n        td.diff_header {text-align:right}\n        .diff_next {background-color:#c0c0c0}\n        .diff_add {background-color:#aaffaa}\n        .diff_chg {background-color:#ffff77}\n        .diff_sub {background-color:#ffaaaa}\n    </style></head><body>'''\n\n    idx = 1\n\n    email_cnt = email_cnt + '<table border=1>'\n\n    email_cnt, idx = __get_post_review(email_cnt, idx)  # post\n    email_cnt, idx = __get_page_review(email_cnt, idx)  # page.\n    email_cnt, idx = __get_wiki_review(email_cnt, idx)  # wiki\n\n    ###########################################################\n\n    diff_str = __get_diff_recent()\n\n    if len(diff_str) < 20000:\n        email_cnt = email_cnt + diff_str\n    email_cnt = email_cnt + '''</body></html>'''\n\n    if idx > 1:\n        send_mail(post_emails, \"{0}|{1}|{2}\".format(SMTP_CFG['name'], '\u6587\u6863\u66f4\u65b0\u60c5\u51b5', DATE_STR), email_cnt)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying the count of certain category.", "response": "def query_field_count(limit_num, kind='1'):\n        '''\n        Query the posts count of certain category.\n        '''\n        return TabTag.select().where(\n            TabTag.kind == kind\n        ).order_by(\n            TabTag.count.desc()\n        ).limit(limit_num)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the category record by its slug", "response": "def get_by_slug(slug):\n        '''\n        return the category record .\n        '''\n        rec = TabTag.select().where(TabTag.slug == slug)\n        if rec.count() > 0:\n            return rec.get()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the count of certain category.", "response": "def update_count(cat_id):\n        '''\n        Update the count of certain category.\n        '''\n        # Todo: the record not valid should not be counted.\n        entry2 = TabTag.update(\n            count=TabPost2Tag.select().where(\n                TabPost2Tag.tag_id == cat_id\n            ).count()\n        ).where(TabTag.uid == cat_id)\n        entry2.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd or update the data by the given ID of post.", "response": "def add_or_update(uid, post_data):\n        '''\n        Add or update the data by the given ID of post.\n        '''\n        catinfo = MCategory.get_by_uid(uid)\n        if catinfo:\n            MCategory.update(uid, post_data)\n        else:\n            TabTag.create(\n                uid=uid,\n                name=post_data['name'],\n                slug=post_data['slug'],\n                order=post_data['order'],\n                kind=post_data['kind'] if 'kind' in post_data else '1',\n                pid=post_data['pid'],\n            )\n        return uid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recent(self, with_catalog=True, with_date=True):\n        '''\n        List posts that recent edited.\n        '''\n        kwd = {\n            'pager': '',\n            'title': 'Recent posts.',\n            'with_catalog': with_catalog,\n            'with_date': with_date,\n        }\n        self.render('list/post_list.html',\n                    kwd=kwd,\n                    view=MPost.query_recent(num=20),\n                    postrecs=MPost.query_recent(num=2),\n                    format_date=tools.format_date,\n                    userinfo=self.userinfo,\n                    cfg=CMS_CFG, )", "response": "List posts that recent edited."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting the posts to be modified.", "response": "def errcat(self):\n        '''\n        List the posts to be modified.\n        '''\n        post_recs = MPost.query_random(limit=1000)\n        outrecs = []\n        errrecs = []\n        idx = 0\n        for postinfo in post_recs:\n            if idx > 16:\n                break\n            cat = MPost2Catalog.get_first_category(postinfo.uid)\n            if cat:\n                if 'def_cat_uid' in postinfo.extinfo:\n                    if postinfo.extinfo['def_cat_uid'] == cat.tag_id:\n                        pass\n                    else:\n                        errrecs.append(postinfo)\n                        idx += 1\n                else:\n                    errrecs.append(postinfo)\n                    idx += 1\n            else:\n                outrecs.append(postinfo)\n                idx += 1\n        self.render('list/errcat.html',\n                    kwd={},\n                    norecs=outrecs,\n                    errrecs=errrecs,\n                    userinfo=self.userinfo)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists the post of dated.", "response": "def refresh(self):\n        '''\n        List the post of dated.\n        '''\n        kwd = {\n            'pager': '',\n            'title': '',\n        }\n        self.render('list/post_list.html',\n                    kwd=kwd,\n                    userinfo=self.userinfo,\n                    view=MPost.query_dated(10),\n                    postrecs=MPost.query_dated(10),\n                    format_date=tools.format_date,\n                    cfg=CMS_CFG)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_dir():\n    '''\n    Build the directory used for templates.\n    '''\n    tag_arr = ['add', 'edit', 'view', 'list', 'infolist']\n    path_arr = [os.path.join(CRUD_PATH, x) for x in tag_arr]\n    for wpath in path_arr:\n        if os.path.exists(wpath):\n            continue\n        os.makedirs(wpath)", "response": "Build the directory used for templates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget reply list of certain post.", "response": "def query_by_post(postid):\n        '''\n        Get reply list of certain post.\n        '''\n        return TabReply.select().where(\n            TabReply.post_id == postid\n        ).order_by(TabReply.timestamp.desc())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __write_filter_dic(wk_sheet, column):\n    '''\n    return filter dic for certain column\n    '''\n    row1_val = wk_sheet['{0}1'.format(column)].value\n    row2_val = wk_sheet['{0}2'.format(column)].value\n    row3_val = wk_sheet['{0}3'.format(column)].value\n    row4_val = wk_sheet['{0}4'.format(column)].value\n\n    if row1_val and row1_val.strip() != '':\n        row2_val = row2_val.strip()\n\n        slug_name = row1_val.strip()\n        c_name = row2_val.strip()\n\n        tags1 = [x.strip() for x in row3_val.split(',')]\n        tags_dic = {}\n\n        #  if only one tag,\n        if len(tags1) == 1:\n            xx_1 = row2_val.split(':')  # 'text'  # HTML text input control.\n\n            if xx_1[0].lower() in INPUT_ARR:\n                xx_1[0] = xx_1[0].lower()\n            else:\n                xx_1[0] = 'text'\n\n            if len(xx_1) == 2:\n                ctr_type, unit = xx_1\n            else:\n                ctr_type = xx_1[0]\n                unit = ''\n            tags_dic[1] = unit\n\n        else:\n            ctr_type = 'select'  # HTML selectiom control.\n            for index, tag_val in enumerate(tags1):\n                # the index of tags_dic starts from 1.\n                tags_dic[index + 1] = tag_val.strip()\n\n        outkey = 'html_{0}'.format(slug_name)\n        outval = {\n            'en': slug_name,\n            'zh': c_name,\n            'dic': tags_dic,\n            'type': ctr_type,\n            'display': row4_val,\n        }\n        return (outkey, outval)\n    else:\n        return (None, None)", "response": "write filter dic for certain column"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_last(postid):\n        '''\n        Get the last wiki in history.\n        '''\n        recs = TabWikiHist.select().where(\n            TabWikiHist.wiki_id == postid\n        ).order_by(TabWikiHist.time_update.desc())\n\n        return None if recs.count() == 0 else recs.get()", "response": "Get the last wiki in history."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if user is prived from a given rule.", "response": "def is_prived(usr_rule, def_rule):\n    '''\n    Compare between two role string.\n    '''\n    for iii in range(4):\n        if def_rule[iii] == '0':\n            continue\n        if usr_rule[iii] >= def_rule[iii]:\n            return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndrops the tables in the base xml file.", "response": "def run_drop_tables(_):\n    '''\n    Running the script.\n    '''\n    print('--')\n\n    drop_the_table(TabPost)\n    drop_the_table(TabTag)\n    drop_the_table(TabMember)\n    drop_the_table(TabWiki)\n    drop_the_table(TabLink)\n    drop_the_table(TabEntity)\n    drop_the_table(TabPostHist)\n    drop_the_table(TabWikiHist)\n    drop_the_table(TabCollect)\n    drop_the_table(TabPost2Tag)\n    drop_the_table(TabRel)\n    drop_the_table(TabEvaluation)\n    drop_the_table(TabUsage)\n    drop_the_table(TabReply)\n    drop_the_table(TabUser2Reply)\n    drop_the_table(TabRating)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetect the name and version of a node in the system.", "response": "def detect(agent, fill_none=False):\n    \"\"\"\n    fill_none: if name/version is not detected respective key is still added to the result with value None\n    \"\"\"\n    result = dict(platform=dict(name=None, version=None))\n    _suggested_detectors = []\n\n    for info_type in detectorshub:\n        detectors = _suggested_detectors or detectorshub[info_type]\n        for detector in detectors:\n            try:\n                detector.detect(agent, result)\n            except Exception as _err:\n                pass\n\n    if fill_none:\n        for outer_key in ('os', 'browser'):\n            outer_value = result.setdefault(outer_key, dict())\n            for inner_key in ('name', 'version'):\n                outer_value.setdefault(inner_key, None)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getVersion(self, agent, word):\n        version_markers = self.version_markers if \\\n            isinstance(self.version_markers[0], (list, tuple)) else [self.version_markers]\n        version_part = agent.split(word, 1)[-1]\n        for start, end in version_markers:\n            if version_part.startswith(start) and end in version_part:\n                version = version_part[1:]\n                if end:  # end could be empty string\n                    version = version.split(end)[0]\n                if not self.allow_space_in_version:\n                    version = version.split()[0]\n                return version", "response": "returns the version string for the given word"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying the files and runs memory tests if needed.", "response": "def compile_files(args, mem_test=False):\n    ''' Copiles the files and runs memory tests\n        if needed.\n        PARAM args: list of files passed as CMD args\n                    to be compiled.\n        PARAM mem_test: Weither to perform memory test ?\n    '''\n    for filename in args:\n        if not os.path.isfile(filename):\n            print('The file doesn\\'t exits')\n            return\n        build_and_run_file(filename)\n        print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild and runs the file specified by filename according to the extension specified by the extension parameter returns the resulting string.", "response": "def build_and_run_file(filename):\n    ''' Builds and runs the filename specified\n        according to the extension\n        PARAM filename: name of file to build and run\n    '''\n    (directory, name, extension) = get_file_tuple(filename)\n    if extension == 'c':\n        print(\" = = = = = = \", YELLOW, \"GCC: Compiling \" + filename + \" file\", \\\n              RESET, \" = = = = = =\\n\")\n        compiler = Compiler(filename)\n        out = compiler.compile()\n        if out != 0:\n            print('Error while compiling. Code:', out, 'Please retry.')\n            return out\n        print(\"\")\n\n        out = compiler.run()\n        return out\n\n    elif extension == 'cpp':\n        print(\" = = = = = = \", YELLOW, \"GPP: Compiling \" + filename + \" file\", \\\n              RESET, \" = = = = = =\\n\")\n        compiler = Compiler(filename)\n        out = compiler.compile()\n        if out != 0:\n            print('Error while compiling. Code:', out, 'Please retry.')\n            return out\n        print(\"\")\n\n        out = compiler.run()\n        return out\n\n    elif extension == 'py':\n        print(\" = = = = = = \", YELLOW, \"PYTHON: Executing \" + filename + \" file\", \\\n              RESET, \" = = = = = =\\n\")\n        compiler = Compiler(filename)\n        out = compiler.run()\n        return out\n    elif extension == 'java':\n        command = EXECUTABLE_JAVAC + ' ' + filename\n        perform_system_command(command)\n        command_run = EXECUTABLE_JAVA + ' ' + name\n        test_file = directory + \"/\" + name + \".input\"\n        if os.path.exists(test_file):\n            command_run += \" < \" + test_file\n        return perform_system_command(command_run)\n    else:\n        print(\"Language yet not supported\")\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if all of the required programs are installed.", "response": "def check_exec_installed(exec_list):\n    \"\"\" Check the required programs are\n        installed.\n        PARAM exec_list: list of programs to check\n        RETURN: True if all installed else False\n    \"\"\"\n    all_installed = True\n    for exe in exec_list:\n        if not is_tool(exe):\n            print(\"Executable: \" + exe + \" is not installed\")\n            all_installed = False\n    return all_installed"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_known_args():\n    parser = ArgumentParser()\n    parser.add_argument(\"-l\", \"--loop\", type=int, help=\"Loop every X seconds\")\n    parser.add_argument('-V', '--version',\n                        action='store_true',\n                        dest='version',\n                        help='Print the version number and exit')\n    parser.add_argument(\"-u\", \"--update\",\n                        action='store_true',\n                        dest=\"update\",\n                        help=\"Update the software from online repo\")\n    parser.add_argument(\"-p\", \"--problem\",\n                        action='store_true',\n                        dest=\"problem\",\n                        help=\"Report a problem\")\n    parser.add_argument(\"-m\", \"--memory\",\n                        action='store_true',\n                        dest=\"memory\",\n                        help=\"Run memory tests\")\n    args, otherthings = parser.parse_known_args()\n    return args, otherthings, parser", "response": "Parse command line arguments\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef multi_process(func, data, num_process=None, verbose=True, **args):\n    '''Function to use multiprocessing to process pandas Dataframe.\n\n    This function applies a function on each row of the input DataFrame by\n    multiprocessing.\n\n    Args:\n        func (function): The function to apply on each row of the input\n            Dataframe. The func must accept pandas.Series as the first\n            positional argument and return a pandas.Series.\n        data (pandas.DataFrame): A DataFrame to be processed.\n        num_process (int, optional): The number of processes to run in\n            parallel. Defaults to be the number of CPUs of the computer.\n        verbose (bool, optional): Set to False to disable verbose output.\n        args (dict): Keyword arguments to pass as keywords arguments to `func`\n    return:\n        A dataframe containing the results\n    '''\n    # Check arguments value\n    assert isinstance(data, pd.DataFrame), \\\n        'Input data must be a pandas.DataFrame instance'\n    if num_process is None:\n        num_process = multiprocessing.cpu_count()\n    # Establish communication queues\n    tasks = multiprocessing.JoinableQueue()\n    results = multiprocessing.Queue()\n    error_queue = multiprocessing.Queue()\n    start_time = time.time()\n    # Enqueue tasks\n    num_task = len(data)\n    for i in range(num_task):\n        tasks.put(data.iloc[i, :])\n    # Add a poison pill for each consumer\n    for i in range(num_process):\n        tasks.put(None)\n\n    logger.info('Create {} processes'.format(num_process))\n    consumers = [Consumer(func, tasks, results, error_queue, **args)\n                 for i in range(num_process)]\n    for w in consumers:\n        w.start()\n    # Add a task tracking process\n    task_tracker = TaskTracker(tasks, verbose)\n    task_tracker.start()\n    # Wait for all input data to be processed\n    tasks.join()\n    # If there is any error in any process, output the error messages\n    num_error = error_queue.qsize()\n    if num_error > 0:\n        for i in range(num_error):\n            logger.error(error_queue.get())\n        raise RuntimeError('Multi process jobs failed')\n    else:\n        # Collect results\n        result_table = []\n        while num_task:\n            result_table.append(results.get())\n            num_task -= 1\n        df_results = pd.DataFrame(result_table)\n        logger.info(\"Jobs finished in {0:.2f}s\".format(\n            time.time()-start_time))\n        return df_results", "response": "Function to use multiprocessing to process pandas Dataframe by using multiprocessing to process pandas Dataframe by multiprocessing."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the job in a loop.", "response": "def run(self):\n        '''Define the job of each process to run.\n        '''\n        while True:\n            next_task = self._task_queue.get()\n            # If there is any error, only consume data but not run the job\n            if self._error_queue.qsize() > 0:\n                self._task_queue.task_done()\n                continue\n            if next_task is None:\n                # Poison pill means shutdown\n                self._task_queue.task_done()\n                break\n            try:\n                answer = self._func(next_task, **self._args)\n                self._task_queue.task_done()\n                self._result_queue.put(answer)\n            except Exception as e:\n                self._task_queue.task_done()\n                self._error_queue.put((os.getpid(), e))\n                logger.error(e)\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        '''Define the job of each process to run.\n        '''\n        if self.verbose:\n            pbar = tqdm(total=100)\n        while True:\n            task_remain = self._task_queue.qsize()\n            task_finished = int((float(self.total_task - task_remain) /\n                                 float(self.total_task)) * 100)\n            if task_finished % 20 == 0 and task_finished != self.current_state:\n                self.current_state = task_finished\n                logger.info('{0}% done'.format(task_finished))\n                if self.verbose and task_finished > 0:\n                    pbar.update(20)\n            if task_remain == 0:\n                break\n        logger.debug('All task data cleared')", "response": "Define the job of each process to run."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef func(data_row, wait):\n    ''' A sample function\n    It takes 'wait' seconds to calculate the sum of each row\n    '''\n    time.sleep(wait)\n    data_row['sum'] = data_row['col_1'] + data_row['col_2']\n    return data_row", "response": "A sample function that calculates the sum of each row"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the mean error of the simulated and observed data.", "response": "def me(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n       remove_neg=False, remove_zero=False):\n    \"\"\"Compute the mean error of the simulated and observed data.\n\n    .. image:: /pictures/ME.png\n\n    **Range:** -inf < MAE < inf, data units, closer to zero is better, indicates bias.\n\n    **Notes:** The mean error (ME) measures the difference between the simulated data and the\n    observed data. For the mean error, a smaller number indicates a better fit to the original\n    data. Note that if the error is in the form of random noise, the mean error will be very small,\n    which can skew the accuracy of this metric. ME is cumulative and will be small even if there\n    are large positive and negative errors that balance.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The mean error value.\n\n    Examples\n    --------\n    Note that in this example the random noise cancels, leaving a very small ME.\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> # Seed for reproducibility\n    >>> np.random.seed(54839)\n\n    >>> x = np.arange(100) / 20\n    >>> sim = np.sin(x) + 2\n    >>> obs = sim * (((np.random.rand(100) - 0.5) / 10) + 1)\n    >>> he.me(sim, obs)\n    -0.006832220968967168\n\n    References\n    ----------\n    - Fisher, R.A., 1920. A Mathematical Examination of the Methods of Determining the Accuracy of\n      an Observation by the Mean Error, and by the Mean Square Error. Monthly Notices of the Royal\n      Astronomical Society 80 758 - 770.\n    \"\"\"\n    # Treating missing values\n    simulated_array, observed_array = treat_values(simulated_array, observed_array,\n                                                   replace_nan=replace_nan,\n                                                   replace_inf=replace_inf,\n                                                   remove_neg=remove_neg,\n                                                   remove_zero=remove_zero)\n    return np.mean(simulated_array - observed_array)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mae(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n        remove_neg=False, remove_zero=False):\n    \"\"\"Compute the mean absolute error of the simulated and observed data.\n\n    .. image:: /pictures/MAE.png\n\n    **Range:** 0 \u2264 MAE < inf, data units, smaller is better.\n\n    **Notes:** The ME measures the absolute difference between the simulated data and the observed\n    data. For the mean abolute error, a smaller number indicates a better fit to the original data.\n    Also note that random errors do not cancel. Also referred to as an L1-norm.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The mean absolute error value.\n\n    References\n    ----------\n    - Willmott, Cort J., and Kenji Matsuura. \u201cAdvantages of the Mean Absolute Error (MAE) over the\n      Root Mean Square Error (RMSE) in Assessing Average Model Performance.\u201d Climate Research 30,\n      no. 1 (2005): 79\u201382.\n    - Willmott, Cort J., and Kenji Matsuura. \u201cOn the Use of Dimensioned Measures of Error to\n      Evaluate the Performance of Spatial Interpolators.\u201d International Journal of Geographical\n      Information Science 20, no. 1 (2006): 89\u2013102.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 6.8])\n    >>> he.mae(sim, obs)\n    0.5666666666666665\n    \"\"\"\n\n    # Checking and cleaning the data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    return np.mean(np.absolute(simulated_array - observed_array))", "response": "Compute the mean absolute error of the simulated and observed data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mle(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n        remove_neg=False, remove_zero=False):\n    \"\"\"\n    Compute the mean log error of the simulated and observed data.\n\n    .. image:: /pictures/MLE.png\n\n    **Range:** -inf < MLE < inf, data units, closer to zero is better.\n\n    **Notes** Same as the mean erro (ME) only use log ratios as the error term. Limits the impact of outliers, more\n    evenly weights high and low data values.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The mean log error value.\n\n    Examples\n    --------\n\n    Note that the value is very small because it is in log space.\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 6.8])\n    >>> he.mle(sim, obs)\n    0.002961767058151136\n\n    References\n    ----------\n    - T\u00f6rnqvist, Leo, Pentti Vartia, and Yrj\u00f6 O. Vartia. \u201cHow Should Relative Changes Be Measured?\u201d\n      The American Statistician 39, no. 1 (1985): 43\u201346.\n    \"\"\"\n\n    # Checking and cleaning the data\n    \n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    sim_log = np.log1p(simulated_array)\n    obs_log = np.log1p(observed_array)\n    return np.mean(sim_log - obs_log)", "response": "Compute the mean log error of the simulated and observed data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mde(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n        remove_neg=False, remove_zero=False):\n    \"\"\"\n    Compute the median error (MdE) between the simulated and observed data.\n\n    .. image:: /pictures/MdE.png\n\n    **Range** -inf < MdE < inf, closer to zero is better.\n\n    **Notes** This metric indicates bias. It is similar to the mean error (ME), only it takes the\n    median rather than the mean. Median measures reduces the impact of outliers.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Examples\n    --------\n\n    Note that the last outlier residual in the time series is negated using the median.\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 100])\n    >>> he.mde(sim, obs)\n    -0.10000000000000009\n\n    Returns\n    -------\n    float\n        The median error value.\n\n    \"\"\"\n\n    # Checking and cleaning the data\n    \n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    return np.median(simulated_array - observed_array)", "response": "Compute the median error between the simulated and observed data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mdae(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n         remove_neg=False, remove_zero=False):\n    \"\"\"\n    Compute the median absolute error (MdAE) between the simulated and observed data.\n\n    .. image:: /pictures/MdAE.png\n\n    **Range** 0 \u2264 MdAE < inf, closer to zero is better.\n\n    **Notes** Random errors (noise) do not cancel. It is the same as the mean absolute error (MAE), only it takes the\n    median rather than the mean. Median measures reduces the impact of outliers.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Examples\n    --------\n\n    Note that the last outlier residual in the time series is negated using the median.\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 100])\n    >>> he.mdae(sim, obs)\n    0.75\n\n    Returns\n    -------\n    float\n        The median absolute error value.\n\n    \"\"\"\n\n    # Checking and cleaning the data\n    \n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    return np.median(np.abs(simulated_array - observed_array))", "response": "Compute the median absolute error between the simulated and observed data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ed(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n       remove_neg=False, remove_zero=False):\n    \"\"\"\n    Compute the Euclidean distance between predicted and observed values in vector space.\n\n    .. image:: /pictures/ED.png\n\n    **Range** 0 \u2264 ED < inf, smaller is better.\n    **Notes** Also sometimes referred to as the L2-norm.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.ed(sim, obs)\n    1.63707055437449\n\n    Returns\n    -------\n    float\n        The euclidean distance error value.\n\n    References\n    ----------\n    - Kennard, M. J., Mackay, S. J., Pusey, B. J., Olden, J. D., & Marsh, N. (2010). Quantifying\n      uncertainty in estimation of hydrologic metrics for ecohydrological studies. River Research\n      and Applications, 26(2), 137-156.\n    \"\"\"\n\n    # Checking and cleaning the data\n    \n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    return np.linalg.norm(observed_array - simulated_array)", "response": "Compute the Euclidean distance between predicted and observed values in vector space."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ned(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n        remove_neg=False, remove_zero=False):\n    \"\"\"\n    Compute the normalized Euclidian distance between the simulated and observed data in vector\n    space.\n\n    .. image:: /pictures/NED.png\n\n    **Range** 0 \u2264 NED < inf, smaller is better.\n\n    **Notes** Also sometimes referred to as the squared L2-norm.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The normalized euclidean distance value.\n\n    Examples\n    --------\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.ned(sim, obs)\n    0.2872053604165771\n\n    References\n    ----------\n    - Kennard, M. J., Mackay, S. J., Pusey, B. J., Olden, J. D., & Marsh, N. (2010). Quantifying\n      uncertainty in estimation of hydrologic metrics for ecohydrological studies. River Research\n      and Applications, 26(2), 137-156.\n    \"\"\"\n\n    # Checking and cleaning the data\n    \n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    a = observed_array / np.mean(observed_array)\n    b = simulated_array / np.mean(simulated_array)\n    return np.linalg.norm(a - b)", "response": "Compute the normalized euclidean distance between the simulated and observed data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the range normalized root square error between the simulated and observed data sets.", "response": "def nrmse_range(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n                remove_neg=False, remove_zero=False):\n    \"\"\"Compute the range normalized root mean square error between the simulated and observed data.\n\n    .. image:: /pictures/NRMSE_Range.png\n\n    **Range:** 0 \u2264 NRMSE < inf.\n\n    **Notes:** This metric is the RMSE normalized by the range of the observed time series (x).\n    Normalizing allows comparison between data sets with different scales. The NRMSErange is the\n    most sensitive to outliers of the three normalized rmse metrics.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The range normalized root mean square error value.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.nrmse_range(sim, obs)\n    0.0891108340256152\n\n    References\n    ----------\n    - Pontius, R.G., Thontteh, O., Chen, H., 2008. Components of information for multiple\n      resolution comparison between maps that share a real variable. Environmental and Ecological\n      Statistics 15(2) 111-142.\n    \"\"\"\n\n    # Checking and cleaning the data\n    \n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    rmse_value = np.sqrt(np.mean((simulated_array - observed_array) ** 2))\n    obs_max = np.max(observed_array)\n    obs_min = np.min(observed_array)\n    return rmse_value / (obs_max - obs_min)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the mean normalized root mean square error between the simulated and observed data sets.", "response": "def nrmse_mean(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n               remove_neg=False, remove_zero=False):\n    \"\"\"Compute the mean normalized root mean square error between the simulated and observed data.\n\n    .. image:: /pictures/NRMSE_Mean.png\n\n    **Range:** 0 \u2264 NRMSE < inf.\n\n    **Notes:** This metric is the RMSE normalized by the mean of the observed time series (x).\n    Normalizing allows comparison between data sets with different scales.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The mean normalized root mean square error.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.nrmse_mean(sim, obs)\n    0.11725109740212526\n\n    References\n    ----------\n    - Pontius, R.G., Thontteh, O., Chen, H., 2008. Components of information for multiple\n      resolution comparison between maps that share a real variable. Environmental and Ecological\n      Statistics 15(2) 111-142.\n\n    \"\"\"\n\n    # Checking and cleaning the data\n    \n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    rmse_value = np.sqrt(np.mean((simulated_array - observed_array) ** 2))\n    obs_mean = np.mean(observed_array)\n    return rmse_value / obs_mean"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the NRMSE root square error between the simulated and observed data sets.", "response": "def nrmse_iqr(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n              remove_neg=False, remove_zero=False):\n    \"\"\"Compute the IQR normalized root mean square error between the simulated and observed data.\n\n    .. image:: /pictures/NRMSE_IQR.png\n\n    **Range:** 0 \u2264 NRMSE < inf.\n\n    **Notes:** This metric is the RMSE normalized by the interquartile range of the observed time\n    series (x). Normalizing allows comparison between data sets with different scales.\n    The NRMSEquartile is the least sensitive to outliers of the three normalized rmse metrics.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The IQR normalized root mean square error.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.nrmse_iqr(sim, obs)\n    0.2595461185212093\n\n    References\n    ----------\n    - Pontius, R.G., Thontteh, O., Chen, H., 2008. Components of information for multiple\n      resolution comparison between maps that share a real variable. Environmental and Ecological\n      Statistics 15(2) 111-142.\n\n    \"\"\"\n\n    # Checking and cleaning the data\n    \n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    rmse_value = np.sqrt(np.mean((simulated_array - observed_array) ** 2))\n    q1 = np.percentile(observed_array, 25)\n    q3 = np.percentile(observed_array, 75)\n    iqr = q3 - q1\n    return rmse_value / iqr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mase(simulated_array, observed_array, m=1, replace_nan=None, replace_inf=None,\n         remove_neg=False, remove_zero=False):\n    \"\"\"Compute the mean absolute scaled error between the simulated and observed data.\n\n    .. image:: /pictures/MASE.png\n\n    **Range:**\n\n    **Notes:**\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    m: int\n        If given, indicates the seasonal period m. If not given, the default is 1.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The mean absolute scaled error.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.mase(sim, obs)\n    0.17341040462427745\n\n    References\n    ----------\n    - Hyndman, R.J., Koehler, A.B., 2006. Another look at measures of forecast accuracy.\n      International Journal of Forecasting 22(4) 679-688.\n    \"\"\"\n\n    # Checking and cleaning the data\n\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    start = m\n    end = simulated_array.size - m\n    a = np.mean(np.abs(simulated_array - observed_array))\n    b = np.abs(observed_array[start:observed_array.size] - observed_array[:end])\n    return a / (np.sum(b) / end)", "response": "Compute the mean absolute scaled error between the simulated and observed data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef maape(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n          remove_neg=False, remove_zero=False):\n    \"\"\"Compute the the Mean Arctangent Absolute Percentage Error (MAAPE).\n\n    .. image:: /pictures/MAAPE.png\n\n    **Range:** 0 \u2264 MAAPE < \u03c0/2, does not indicate bias, smaller is better.\n\n    **Notes:** Represents the mean absolute error as a percentage of the observed values. Handles\n    0s in the observed data. This metric is not as biased as MAPE by under-over predictions.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The mean arctangent absolute percentage error.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.mape(sim, obs)\n    11.639226612630866\n\n    References\n    ----------\n    - Kim, S., Kim, H., 2016. A new metric of absolute percentage error for intermittent demand\n      forecasts. International Journal of Forecasting 32(3) 669-679.\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    a = simulated_array - observed_array\n    b = np.abs(a / observed_array)\n    return np.mean(np.arctan(b))", "response": "Compute the mean arctangent absolute percentage error of the simulated and observed data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drel(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n         remove_neg=False, remove_zero=False):\n    \"\"\"Compute the the relative index of agreement (drel).\n\n    .. image:: /pictures/drel.png\n\n    **Range:** 0 \u2264 drel < 1, does not indicate bias, larger is better.\n\n    **Notes:** Instead of absolute differences, this metric uses relative differences.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The relative index of agreement.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.drel(sim, obs)\n    0.9740868625579597\n\n    References\n    ----------\n    - Krause, P., Boyle, D., B\u00e4se, F., 2005. Comparison of different efficiency criteria for\n      hydrological model assessment. Advances in geosciences 5 89-97.\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    a = ((simulated_array - observed_array) / observed_array) ** 2\n    b = np.abs(simulated_array - np.mean(observed_array))\n    c = np.abs(observed_array - np.mean(observed_array))\n    e = ((b + c) / np.mean(observed_array)) ** 2\n    return 1 - (np.sum(a) / np.sum(e))", "response": "Compute the relative index of agreement for a given set of simulated and observed data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the Watterson s M value from the simulated and observed data.", "response": "def watt_m(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n           remove_neg=False, remove_zero=False):\n    \"\"\"Compute Watterson's M (M).\n\n    .. image:: /pictures/M.png\n\n    **Range:** -1 \u2264 M < 1, does not indicate bias, larger is better.\n\n    **Notes:**\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        Watterson's M value.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.watt_m(sim, obs)\n    0.8307913876595929\n\n    References\n    ----------\n    - Watterson, I.G., 1996. Non\u2010dimensional measures of climate model performance. International\n      Journal of Climatology 16(4) 379-391.\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    a = 2 / np.pi\n    b = np.mean((simulated_array - observed_array) ** 2)  # MSE\n    c = np.std(observed_array, ddof=1) ** 2 + np.std(simulated_array, ddof=1) ** 2\n    e = (np.mean(simulated_array) - np.mean(observed_array)) ** 2\n    f = c + e\n    return a * np.arcsin(1 - (b / f))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the Kling - Gupta efficiency of the NSE in the time series.", "response": "def kge_2009(simulated_array, observed_array, s=(1, 1, 1), replace_nan=None,\n             replace_inf=None, remove_neg=False, remove_zero=False, return_all=False):\n    \"\"\"Compute the Kling-Gupta efficiency (2009).\n\n    .. image:: /pictures/KGE_2009.png\n\n    **Range:** -inf < KGE (2009) < 1, larger is better.\n\n    **Notes:** Gupta et al. (2009) created this metric to demonstrate the relative importance of\n    the three components of the NSE, which are correlation, bias and variability. This was done\n    with hydrologic modeling as the context. This metric is meant to address issues with the NSE.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    s: tuple of length three\n        Represents the scaling factors to be used for re-scaling the Pearson product-moment\n        correlation coefficient (r), Alpha, and Beta, respectively.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    return_all: bool\n        If True, returns all of the components of the KGE metric, which are r, alpha, and beta, respectively.\n\n    Returns\n    -------\n    float (tuple of float)\n        The Kling-Gupta (2009) efficiency value, unless the return_all parameter is True.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 6.8])\n    >>> he.kge_2009(sim, obs)\n    0.912223072345668\n\n    >>> he.kge_2009(sim, obs, return_all=True)  # Returns (r, alpha, beta, kge)\n    (0.9615951377405804, 0.927910707932087, 1.0058823529411764, 0.9181073779138655)\n\n    References\n    ----------\n    - Gupta, H. V., Kling, H., Yilmaz, K. K., & Martinez, G. F. (2009). Decomposition of the mean\n      squared error and NSE performance criteria: Implications for improving hydrological modelling.\n      Journal of Hydrology, 377(1-2), 80-91.\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    # Means\n    sim_mean = np.mean(simulated_array)\n    obs_mean = np.mean(observed_array)\n\n    # Standard Deviations\n    sim_sigma = np.std(simulated_array, ddof=1)\n    obs_sigma = np.std(observed_array, ddof=1)\n\n    # Pearson R\n    top_pr = np.sum((observed_array - obs_mean) * (simulated_array - sim_mean))\n    bot1_pr = np.sqrt(np.sum((observed_array - obs_mean) ** 2))\n    bot2_pr = np.sqrt(np.sum((simulated_array - sim_mean) ** 2))\n    pr = top_pr / (bot1_pr * bot2_pr)\n\n    # Ratio between mean of simulated and observed data\n    if obs_mean != 0:\n        beta = sim_mean / obs_mean\n    else:\n        beta = np.nan\n\n    # Relative variability between simulated and observed values\n    if obs_sigma != 0:\n        alpha = sim_sigma / obs_sigma\n    else:\n        alpha = np.nan\n\n    if not np.isnan(beta) and not np.isnan(alpha):\n        kge = 1 - np.sqrt(\n            (s[0] * (pr - 1)) ** 2 + (s[1] * (alpha - 1)) ** 2 + (s[2] * (beta - 1)) ** 2)\n    else:\n        if obs_mean == 0:\n            warnings.warn(\n                'Warning: The observed data mean is 0. Therefore, Beta is infinite and the KGE '\n                'value cannot be computed.')\n        if obs_sigma == 0:\n            warnings.warn(\n                'Warning: The observed data standard deviation is 0. Therefore, Alpha is infinite '\n                'and the KGE value cannot be computed.')\n        kge = np.nan\n\n    assert type(return_all) == bool, \"expected <type 'bool'> for parameter return_all, got {}\".format(type(return_all))\n\n    if return_all:\n        return pr, alpha, beta, kge\n    else:\n        return kge"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sa(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n       remove_neg=False, remove_zero=False):\n    \"\"\"Compute the Spectral Angle (SA).\n\n    .. image:: /pictures/SA.png\n\n    **Range:** -\u03c0/2 \u2264 SA < \u03c0/2, closer to 0 is better.\n\n    **Notes:** The spectral angle metric measures the angle between the two vectors in hyperspace.\n    It indicates how well the shape of the two series match \u2013 not magnitude.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The Spectral Angle value.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.sa(sim, obs)\n    0.10816831366492945\n\n    References\n    ----------\n    - Robila, S.A., Gershman, A., 2005. Spectral matching accuracy in processing hyperspectral\n      data, Signals, Circuits and Systems, 2005. ISSCS 2005. International Symposium on. IEEE,\n      pp. 163-166.\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    a = np.dot(simulated_array, observed_array)\n    b = np.linalg.norm(simulated_array) * np.linalg.norm(observed_array)\n    return np.arccos(a / b)", "response": "Compute the Spectral Angle of a two - dimensional array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sc(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n       remove_neg=False, remove_zero=False):\n    \"\"\"Compute the Spectral Correlation (SC).\n\n    .. image:: /pictures/SC.png\n\n    **Range:** -\u03c0/2 \u2264 SA < \u03c0/2, closer to 0 is better.\n\n    **Notes:** The spectral correlation metric measures the angle between the two vectors in\n    hyperspace. It indicates how well the shape of the two series match \u2013 not magnitude.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The Spectral Correlation value.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.sc(sim, obs)\n    0.27991341383646606\n\n    References\n    ----------\n    - Robila, S.A., Gershman, A., 2005. Spectral matching accuracy in processing hyperspectral\n      data, Signals, Circuits and Systems, 2005. ISSCS 2005. International Symposium on. IEEE,\n      pp. 163-166.\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    a = np.dot(observed_array - np.mean(observed_array), simulated_array - np.mean(simulated_array))\n    b = np.linalg.norm(observed_array - np.mean(observed_array))\n    c = np.linalg.norm(simulated_array - np.mean(simulated_array))\n    e = b * c\n    return np.arccos(a / e)", "response": "Compute the Spectral Correlation of a two - dimensional array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sid(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n        remove_neg=False, remove_zero=False):\n    \"\"\"Compute the Spectral Information Divergence (SID).\n\n    .. image:: /pictures/SID.png\n\n    **Range:** -\u03c0/2 \u2264 SID < \u03c0/2, closer to 0 is better.\n\n    **Notes:** The spectral information divergence measures the angle between the two vectors in\n    hyperspace. It indicates how well the shape of the two series match \u2013 not magnitude.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The Spectral information divergence value.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.sid(sim, obs)\n    0.03517616895318012\n\n    References\n    ----------\n    - Robila, S.A., Gershman, A., 2005. Spectral matching accuracy in processing hyperspectral\n      data, Signals, Circuits and Systems, 2005. ISSCS 2005. International Symposium on. IEEE,\n      pp. 163-166.\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    first = (observed_array / np.mean(observed_array)) - (\n            simulated_array / np.mean(simulated_array))\n    second1 = np.log10(observed_array) - np.log10(np.mean(observed_array))\n    second2 = np.log10(simulated_array) - np.log10(np.mean(simulated_array))\n    return np.dot(first, second1 - second2)", "response": "Compute the Spectral Information Divergence value for a given set of simulated and observed data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sga(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n        remove_neg=False, remove_zero=False):\n    \"\"\"Compute the Spectral Gradient Angle (SGA).\n\n    .. image:: /pictures/SGA.png\n\n    **Range:** -\u03c0/2 \u2264 SID < \u03c0/2, closer to 0 is better.\n\n    **Notes:** The spectral gradient angle measures the angle between the two vectors in\n    hyperspace. It indicates how well the shape of the two series match \u2013 not magnitude.\n    SG is the gradient of the simulated or observed time series.\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The Spectral Gradient Angle.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.sga(sim, obs)\n    0.26764286472739834\n\n    References\n    ----------\n    - Robila, S.A., Gershman, A., 2005. Spectral matching accuracy in processing hyperspectral\n      data, Signals, Circuits and Systems, 2005. ISSCS 2005. International Symposium on. IEEE,\n      pp. 163-166.\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    sgx = observed_array[1:] - observed_array[:observed_array.size - 1]\n    sgy = simulated_array[1:] - simulated_array[:simulated_array.size - 1]\n    a = np.dot(sgx, sgy)\n    b = np.linalg.norm(sgx) * np.linalg.norm(sgy)\n    return np.arccos(a / b)", "response": "Compute the Spectral Gradient Angle of a two - dimensional array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef h1_mhe(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n           remove_neg=False, remove_zero=False):\n    \"\"\"Compute the H1 mean error.\n\n    .. image:: /pictures/H1.png\n    .. image:: /pictures/MHE.png\n\n    **Range:**\n\n    **Notes:**\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The mean H1 error.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.h1_mhe(sim, obs)\n    0.002106551840594386\n\n    References\n    ----------\n    - Tornquist, L., Vartia, P., Vartia, Y.O., 1985. How Should Relative Changes be Measured?\n      The American Statistician 43-46.\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    h = (simulated_array - observed_array) / observed_array\n    return np.mean(h)", "response": "Compute the H1 mean error."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef h6_mahe(simulated_array, observed_array, k=1, replace_nan=None, replace_inf=None,\n            remove_neg=False,\n            remove_zero=False):\n    \"\"\"Compute the H6 mean absolute error.\n\n    .. image:: /pictures/H6.png\n    .. image:: /pictures/AHE.png\n\n    **Range:**\n\n    **Notes:**\n\n    Parameters\n    ----------\n    simulated_array: one dimensional ndarray\n        An array of simulated data from the time series.\n\n    observed_array: one dimensional ndarray\n        An array of observed data from the time series.\n\n    k: int or float\n        If given, sets the value of k. If None, k=1.\n\n    replace_nan: float, optional\n        If given, indicates which value to replace NaN values with in the two arrays. If None, when\n        a NaN value is found at the i-th position in the observed OR simulated array, the i-th value\n        of the observed and simulated array are removed before the computation.\n\n    replace_inf: float, optional\n        If given, indicates which value to replace Inf values with in the two arrays. If None, when\n        an inf value is found at the i-th position in the observed OR simulated array, the i-th\n        value of the observed and simulated array are removed before the computation.\n\n    remove_neg: boolean, optional\n        If True, when a negative value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    remove_zero: boolean, optional\n        If true, when a zero value is found at the i-th position in the observed OR simulated\n        array, the i-th value of the observed AND simulated array are removed before the\n        computation.\n\n    Returns\n    -------\n    float\n        The mean absolute H6 error.\n\n    Examples\n    --------\n\n    >>> import HydroErr as he\n    >>> import numpy as np\n\n    >>> sim = np.array([5, 7, 9, 2, 4.5, 6.7])\n    >>> obs = np.array([4.7, 6, 10, 2.5, 4, 7])\n    >>> he.h6_mahe(sim, obs)\n    0.11743831388794852\n\n    References\n    ----------\n    - Tornquist, L., Vartia, P., Vartia, Y.O., 1985. How Should Relative Changes be Measured?\n      The American Statistician 43-46.\n\n    \"\"\"\n\n    # Treats data\n    simulated_array, observed_array = treat_values(\n        simulated_array,\n        observed_array,\n        replace_nan=replace_nan,\n        replace_inf=replace_inf,\n        remove_neg=remove_neg,\n        remove_zero=remove_zero\n    )\n\n    top = (simulated_array / observed_array - 1)\n    bot = np.power(0.5 * (1 + np.power(simulated_array / observed_array, k)), 1 / k)\n    h = top / bot\n    return np.mean(np.abs(h))", "response": "Compute the H6 mean absolute error."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef treat_values(simulated_array, observed_array, replace_nan=None, replace_inf=None,\n                 remove_neg=False, remove_zero=False):\n    \"\"\"Removes the nan, negative, and inf values in two numpy arrays\"\"\"\n    sim_copy = np.copy(simulated_array)\n    obs_copy = np.copy(observed_array)\n\n    # Checking to see if the vectors are the same length\n    assert sim_copy.ndim == 1, \"The simulated array is not one dimensional.\"\n    assert obs_copy.ndim == 1, \"The observed array is not one dimensional.\"\n\n    if sim_copy.size != obs_copy.size:\n        raise RuntimeError(\"The two ndarrays are not the same size.\")\n\n    # Treat missing data in observed_array and simulated_array, rows in simulated_array or\n    # observed_array that contain nan values\n    all_treatment_array = np.ones(obs_copy.size, dtype=bool)\n\n    if np.any(np.isnan(obs_copy)) or np.any(np.isnan(sim_copy)):\n        if replace_nan is not None:\n            # Finding the NaNs\n            sim_nan = np.isnan(sim_copy)\n            obs_nan = np.isnan(obs_copy)\n            # Replacing the NaNs with the input\n            sim_copy[sim_nan] = replace_nan\n            obs_copy[obs_nan] = replace_nan\n\n            warnings.warn(\"Elements(s) {} contained NaN values in the simulated array and \"\n                          \"elements(s) {} contained NaN values in the observed array and have been \"\n                          \"replaced (Elements are zero indexed).\".format(np.where(sim_nan)[0],\n                                                                         np.where(obs_nan)[0]),\n                          UserWarning)\n        else:\n            # Getting the indices of the nan values, combining them, and informing user.\n            nan_indices_fcst = ~np.isnan(sim_copy)\n            nan_indices_obs = ~np.isnan(obs_copy)\n            all_nan_indices = np.logical_and(nan_indices_fcst, nan_indices_obs)\n            all_treatment_array = np.logical_and(all_treatment_array, all_nan_indices)\n\n            warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n                          \"removed (Rows are zero indexed).\".format(np.where(~all_nan_indices)[0]),\n                          UserWarning)\n\n    if np.any(np.isinf(obs_copy)) or np.any(np.isinf(sim_copy)):\n        if replace_nan is not None:\n            # Finding the NaNs\n            sim_inf = np.isinf(sim_copy)\n            obs_inf = np.isinf(obs_copy)\n            # Replacing the NaNs with the input\n            sim_copy[sim_inf] = replace_inf\n            obs_copy[obs_inf] = replace_inf\n\n            warnings.warn(\"Elements(s) {} contained Inf values in the simulated array and \"\n                          \"elements(s) {} contained Inf values in the observed array and have been \"\n                          \"replaced (Elements are zero indexed).\".format(np.where(sim_inf)[0],\n                                                                         np.where(obs_inf)[0]),\n                          UserWarning)\n        else:\n            inf_indices_fcst = ~(np.isinf(sim_copy))\n            inf_indices_obs = ~np.isinf(obs_copy)\n            all_inf_indices = np.logical_and(inf_indices_fcst, inf_indices_obs)\n            all_treatment_array = np.logical_and(all_treatment_array, all_inf_indices)\n\n            warnings.warn(\n                \"Row(s) {} contained Inf or -Inf values and the row(s) have been removed (Rows \"\n                \"are zero indexed).\".format(np.where(~all_inf_indices)[0]),\n                UserWarning\n            )\n\n    # Treat zero data in observed_array and simulated_array, rows in simulated_array or\n    # observed_array that contain zero values\n    if remove_zero:\n        if (obs_copy == 0).any() or (sim_copy == 0).any():\n            zero_indices_fcst = ~(sim_copy == 0)\n            zero_indices_obs = ~(obs_copy == 0)\n            all_zero_indices = np.logical_and(zero_indices_fcst, zero_indices_obs)\n            all_treatment_array = np.logical_and(all_treatment_array, all_zero_indices)\n\n            warnings.warn(\n                \"Row(s) {} contained zero values and the row(s) have been removed (Rows are \"\n                \"zero indexed).\".format(np.where(~all_zero_indices)[0]),\n                UserWarning\n            )\n\n    # Treat negative data in observed_array and simulated_array, rows in simulated_array or\n    # observed_array that contain negative values\n\n    # Ignore runtime warnings from comparing\n    if remove_neg:\n        with np.errstate(invalid='ignore'):\n            obs_copy_bool = obs_copy < 0\n            sim_copy_bool = sim_copy < 0\n\n        if obs_copy_bool.any() or sim_copy_bool.any():\n            neg_indices_fcst = ~sim_copy_bool\n            neg_indices_obs = ~obs_copy_bool\n            all_neg_indices = np.logical_and(neg_indices_fcst, neg_indices_obs)\n            all_treatment_array = np.logical_and(all_treatment_array, all_neg_indices)\n\n            warnings.warn(\"Row(s) {} contained negative values and the row(s) have been \"\n                          \"removed (Rows are zero indexed).\".format(np.where(~all_neg_indices)[0]),\n                          UserWarning)\n\n    obs_copy = obs_copy[all_treatment_array]\n    sim_copy = sim_copy[all_treatment_array]\n\n    return sim_copy, obs_copy", "response": "Treat the nan values in two numpy arrays."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef facebook_authorization_required(redirect_uri=FACEBOOK_AUTHORIZATION_REDIRECT_URL, permissions=None):\n\n    def decorator(function):\n        @wraps(function)\n        def wrapper(request, *args, **kwargs):\n\n            # We know the user has been authenticated via a canvas page if a signed request is set.\n            canvas = request.facebook is not False and hasattr(request.facebook, \"signed_request\")\n\n            # The user has already authorized the application, but the given view requires\n            # permissions besides the defaults listed in ``FACEBOOK_APPLICATION_DEFAULT_PERMISSIONS``.\n            #\n            # Derive a list of outstanding permissions and prompt the user to grant them.\n            if request.facebook and request.facebook.user and permissions:\n                outstanding_permissions = [p for p in permissions if p not in request.facebook.user.permissions]\n\n                if outstanding_permissions:\n                    return authorize_application(\n                        request = request,\n                        redirect_uri = redirect_uri or get_post_authorization_redirect_url(request, canvas=canvas),\n                        permissions = outstanding_permissions\n                    )\n\n            # The user has not authorized the application yet.\n            #\n            # Concatenate the default permissions with permissions required for this particular view.\n            if not request.facebook or not request.facebook.user:\n                return authorize_application(\n                    request = request,\n                    redirect_uri = redirect_uri or get_post_authorization_redirect_url(request, canvas=canvas),\n                    permissions = (FACEBOOK_APPLICATION_INITIAL_PERMISSIONS or []) + (permissions or [])\n                )\n\n            return function(request, *args, **kwargs)\n        return wrapper\n\n    if callable(redirect_uri):\n        function = redirect_uri\n        redirect_uri = None\n\n        return decorator(function)\n    else:\n        return decorator", "response": "Decorator that allows the user to authorize the application."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef full_name(self):\n        if self.first_name and self.middle_name and self.last_name:\n            return \"%s %s %s\" % (self.first_name, self.middle_name, self.last_name)\n        if self.first_name and self.last_name:\n            return \"%s %s\" % (self.first_name, self.last_name)", "response": "Return the user s first name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef permissions(self):\n        records = self.graph.get('me/permissions')['data']\n\n        permissions = []\n        for record in records:\n            if record['status'] == 'granted':\n                permissions.append(record['permission'])\n\n        return permissions", "response": "A list of strings describing permissions the user has granted your application."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef synchronize(self, graph_data=None):\n        profile = graph_data or self.graph.get('me')\n\n        self.facebook_username = profile.get('username')\n        self.first_name = profile.get('first_name')\n        self.middle_name = profile.get('middle_name')\n        self.last_name = profile.get('last_name')\n        self.birthday = datetime.strptime(profile['birthday'], '%m/%d/%Y') if profile.has_key('birthday') else None\n        self.email = profile.get('email')\n        self.locale = profile.get('locale')\n        self.gender = profile.get('gender')\n        self.extra_data = profile\n        self.save()", "response": "Synchronize facebook_username first_name middle_name last_name and birthday with Facebook."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extended(self):\n        if self.expires_at:\n            return self.expires_at - self.issued_at > timedelta(days=30)\n        else:\n            return False", "response": "Determine whether the OAuth token has been extended."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extend(self):\n        graph = GraphAPI()\n\n        response = graph.get('oauth/access_token',\n            client_id = FACEBOOK_APPLICATION_ID,\n            client_secret = FACEBOOK_APPLICATION_SECRET_KEY,\n            grant_type = 'fb_exchange_token',\n            fb_exchange_token = self.token\n        )\n\n        components = parse_qs(response)\n\n        self.token = components['access_token'][0]\n        self.expires_at = now() + timedelta(seconds = int(components['expires'][0]))\n\n        self.save()", "response": "Extend the OAuth token."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the signed request and return the appropriate entry in the dictionary.", "response": "def process_request(self, request):\n        \"\"\"Process the signed request.\"\"\"\n\n        # User has already been authed by alternate middleware\n        if hasattr(request, \"facebook\") and request.facebook:\n            return\n\n        request.facebook = False\n\n        if not self.is_valid_path(request):\n            return\n\n        if self.is_access_denied(request):\n            return authorization_denied_view(request)\n\n        # No signed request found in either GET, POST nor COOKIES...\n        if 'signed_request' not in request.REQUEST and 'signed_request' not in request.COOKIES:\n            return\n\n        # If the request method is POST and its body only contains the signed request,\n        # chances are it's a request from the Facebook platform and we'll override\n        # the request method to HTTP GET to rectify their misinterpretation\n        # of the HTTP standard.\n        #\n        # References:\n        # \"POST for Canvas\" migration at http://developers.facebook.com/docs/canvas/post/\n        # \"Incorrect use of the HTTP protocol\" discussion at http://forum.developers.facebook.net/viewtopic.php?id=93554\n        if request.method == 'POST' and 'signed_request' in request.POST:\n            request.POST = QueryDict('')\n            request.method = 'GET'\n\n        request.facebook = Facebook()\n\n        try:\n            request.facebook.signed_request = SignedRequest(\n                signed_request = request.REQUEST.get('signed_request') or request.COOKIES.get('signed_request'),\n                application_secret_key = FACEBOOK_APPLICATION_SECRET_KEY\n            )\n        except SignedRequest.Error:\n            request.facebook = False\n\n        # Valid signed request and user has authorized the application\n        if request.facebook \\\n            and request.facebook.signed_request.user.has_authorized_application \\\n            and not request.facebook.signed_request.user.oauth_token.has_expired:\n\n            # Initialize a User object and its corresponding OAuth token\n            try:\n                user = User.objects.get(facebook_id=request.facebook.signed_request.user.id)\n            except User.DoesNotExist:\n                oauth_token = OAuthToken.objects.create(\n                    token = request.facebook.signed_request.user.oauth_token.token,\n                    issued_at = request.facebook.signed_request.user.oauth_token.issued_at.replace(tzinfo=tzlocal()),\n                    expires_at = request.facebook.signed_request.user.oauth_token.expires_at.replace(tzinfo=tzlocal())\n                )\n\n                user = User.objects.create(\n                    facebook_id = request.facebook.signed_request.user.id,\n                    oauth_token = oauth_token\n                )\n\n                user.synchronize()\n\n            # Update the user's details and OAuth token\n            else:\n                user.last_seen_at = now()\n\n                if 'signed_request' in request.REQUEST:\n                    user.authorized = True\n\n                    if request.facebook.signed_request.user.oauth_token:\n                        user.oauth_token.token = request.facebook.signed_request.user.oauth_token.token\n                        user.oauth_token.issued_at = request.facebook.signed_request.user.oauth_token.issued_at.replace(tzinfo=tzlocal())\n                        user.oauth_token.expires_at = request.facebook.signed_request.user.oauth_token.expires_at.replace(tzinfo=tzlocal())\n                        user.oauth_token.save()\n\n                user.save()\n\n            if not user.oauth_token.extended:\n                # Attempt to extend the OAuth token, but ignore exceptions raised by\n                # bug #102727766518358 in the Facebook Platform.\n                #\n                # http://developers.facebook.com/bugs/102727766518358/\n                try:\n                    user.oauth_token.extend()\n                except:\n                    pass\n\n            request.facebook.user = user"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_response(self, request, response):\n        response['P3P'] = 'CP=\"IDC CURa ADMa OUR IND PHY ONL COM STA\"'\n\n        if FANDJANGO_CACHE_SIGNED_REQUEST:\n            if hasattr(request, \"facebook\") and request.facebook and request.facebook.signed_request:\n                response.set_cookie('signed_request', request.facebook.signed_request.generate())\n            else:\n                response.delete_cookie('signed_request')\n        \n        return response", "response": "Set compact P3P policies and save signed request to cookie."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_request(self, request):\n\n        # User has already been authed by alternate middleware\n        if hasattr(request, \"facebook\") and request.facebook:\n            return\n\n        request.facebook = False\n\n        if not self.is_valid_path(request):\n            return\n\n        if self.is_access_denied(request):\n            return authorization_denied_view(request)\n\n        request.facebook = Facebook()\n        oauth_token = False\n\n        # Is there a token cookie already present?\n        if 'oauth_token' in request.COOKIES:\n            try:\n                # Check if the current token is already in DB\n                oauth_token = OAuthToken.objects.get(token=request.COOKIES['oauth_token'])\n            except OAuthToken.DoesNotExist:\n                request.facebook = False\n                return\n\n        # Is there a code in the GET request?\n        elif 'code' in request.GET:\n            try:\n                graph = GraphAPI()\n\n                # Exchange code for an access_token\n                response = graph.get('oauth/access_token',\n                    client_id = FACEBOOK_APPLICATION_ID,\n                    redirect_uri = get_post_authorization_redirect_url(request, canvas=False),\n                    client_secret = FACEBOOK_APPLICATION_SECRET_KEY,\n                    code = request.GET['code'],\n                )\n        \n                components = parse_qs(response)\n                \n                # Save new OAuth-token in DB\n                oauth_token, new_oauth_token = OAuthToken.objects.get_or_create(\n                    token = components['access_token'][0],\n                    issued_at = now(),\n                    expires_at = now() + timedelta(seconds = int(components['expires'][0]))\n                )\n\n            except GraphAPI.OAuthError:\n                pass\n        \n        # There isn't a valid access_token\n        if not oauth_token or oauth_token.expired:\n            request.facebook = False\n            return\n        \n        # Is there a user already connected to the current token?\n        try:\n            user = oauth_token.user\n            if not user.authorized:\n                request.facebook = False\n                return\n            user.last_seen_at = now()\n            user.save()\n        except User.DoesNotExist:\n            graph = GraphAPI(oauth_token.token)\n            profile = graph.get('me')\n            \n            # Either the user already exists and its just a new token, or user and token both are new\n            try:\n                user = User.objects.get(facebook_id = profile.get('id'))\n                if not user.authorized:\n                    if new_oauth_token:\n                        user.last_seen_at = now()\n                        user.authorized = True\n                    else:\n                        request.facebook = False\n                        return\n            except User.DoesNotExist:\n                # Create a new user to go with token\n                user = User.objects.create(\n                    facebook_id = profile.get('id'),\n                    oauth_token = oauth_token\n                )                    \n            \n            user.synchronize(profile)\n            \n            # Delete old access token if there is any and  only if the new one is different\n            old_oauth_token = None\n            if user.oauth_token != oauth_token:\n                old_oauth_token = user.oauth_token\n                user.oauth_token = oauth_token\n            \n            user.save()\n\n            if old_oauth_token:\n                old_oauth_token.delete()\n\n        if not user.oauth_token.extended:\n            # Attempt to extend the OAuth token, but ignore exceptions raised by\n            # bug #102727766518358 in the Facebook Platform.\n            #\n            # http://developers.facebook.com/bugs/102727766518358/\n            try:\n                user.oauth_token.extend()\n            except:\n                pass\n\n        request.facebook.user = user\n        request.facebook.oauth_token = oauth_token", "response": "Process the web - based auth request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_response(self, request, response):\n        if hasattr(request, \"facebook\") and request.facebook and request.facebook.oauth_token:\n            if \"code\" in request.REQUEST:\n                \"\"\" Remove auth related query params \"\"\"\n                path = get_full_path(request, remove_querystrings=['code', 'web_canvas'])\n                response = HttpResponseRedirect(path)\n\n            response.set_cookie('oauth_token', request.facebook.oauth_token.token)\n        else:\n            response.delete_cookie('oauth_token')\n\n        response['P3P'] = 'CP=\"IDC CURa ADMa OUR IND PHY ONL COM STA\"'\n\n        return response", "response": "Set compact P3P policies and save auth token to cookie."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_log_level(log_level):\n\n    if not LOGBOOK_INSTALLED:\n        return\n\n    # validate log level\n    logbook.get_level_name(log_level)\n\n    if log_level == logger.level:\n        return\n\n    if log_level == logbook.NOTSET:\n        set_logger(is_enable=False)\n    else:\n        set_logger(is_enable=True)\n\n    logger.level = log_level\n    tabledata.set_log_level(log_level)\n    sqliteschema.set_log_level(log_level)\n    try:\n        import pytablereader\n\n        pytablereader.set_log_level(log_level)\n    except ImportError:\n        pass", "response": "Sets the log level of this module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a list of values to a record.", "response": "def to_record(cls, attr_names, values):\n        \"\"\"\n        Convert values to a record to be inserted into a database.\n\n        :param list attr_names:\n            List of attributes for the converting record.\n        :param values: Values to be converted.\n        :type values: |dict|/|namedtuple|/|list|/|tuple|\n        :raises ValueError: If the ``values`` is invalid.\n        \"\"\"\n\n        try:\n            # from a namedtuple to a dict\n            values = values._asdict()\n        except AttributeError:\n            pass\n\n        try:\n            # from a dictionary to a list\n            return [cls.__to_sqlite_element(values.get(attr_name)) for attr_name in attr_names]\n        except AttributeError:\n            pass\n\n        if isinstance(values, (tuple, list)):\n            return [cls.__to_sqlite_element(value) for value in values]\n\n        raise ValueError(\"cannot convert from {} to list\".format(type(values)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_records(cls, attr_names, value_matrix):\n\n        return [cls.to_record(attr_names, record) for record in value_matrix]", "response": "Converts a value matrix to records to be inserted into a database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_disabled_path(path):\n    for disabled_path in DISABLED_PATHS:\n        match = re.search(disabled_path, path[1:])\n        if match:\n            return True\n    return False", "response": "Determines whether or not the path matches one or more paths\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_enabled_path(path):\n    for enabled_path in ENABLED_PATHS:\n        match = re.search(enabled_path, path[1:])\n        if match:\n            return True\n    return False", "response": "Determines whether or not the path matches one or more paths\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncache the return value of a property.", "response": "def cached_property(**kwargs):\n    \"\"\"Cache the return value of a property.\"\"\"\n    def decorator(function):\n        @wraps(function)\n        def wrapper(self):\n            key = 'fandjango.%(model)s.%(property)s_%(pk)s' % {\n                'model': self.__class__.__name__,\n                'pk': self.pk,\n                'property': function.__name__\n            }\n\n            cached_value = cache.get(key)\n\n            delta = timedelta(**kwargs)\n\n            if cached_value is None:\n                value = function(self)\n                cache.set(key, value, delta.days * 86400 + delta.seconds)\n            else:\n                value = cached_value\n\n            return value\n        return wrapper\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_post_authorization_redirect_url(request, canvas=True):\n\n    path = request.get_full_path()\n\n    if canvas:\n\n        if FACEBOOK_APPLICATION_CANVAS_URL:\n            path = path.replace(urlparse(FACEBOOK_APPLICATION_CANVAS_URL).path, '')\n\n        redirect_uri = 'https://%(domain)s/%(namespace)s%(path)s' % {\n            'domain': FACEBOOK_APPLICATION_DOMAIN,\n            'namespace': FACEBOOK_APPLICATION_NAMESPACE,\n            'path': path\n        }\n    else:\n        if FANDJANGO_SITE_URL:\n            site_url = FANDJANGO_SITE_URL\n            path = path.replace(urlparse(site_url).path, '')\n        else:\n            protocol = \"https\" if request.is_secure() else \"http\"\n            site_url = \"%s://%s\" % (protocol, request.get_host())\n        redirect_uri = site_url + path\n\n    return redirect_uri", "response": "Determine the URL users should be redirected to upon authorization the application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_full_path(request, remove_querystrings=[]):\n\n    path = request.get_full_path()\n    for qs in remove_querystrings:\n        path = re.sub(r'&?' + qs + '=?(.+)?&?', '', path)\n    return path", "response": "Gets the current path removing specified querstrings"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nredirects the user to authorize the application.", "response": "def authorize_application(\n    request,\n    redirect_uri = 'https://%s/%s' % (FACEBOOK_APPLICATION_DOMAIN, FACEBOOK_APPLICATION_NAMESPACE),\n    permissions = FACEBOOK_APPLICATION_INITIAL_PERMISSIONS\n    ):\n    \"\"\"\n    Redirect the user to authorize the application.\n\n    Redirection is done by rendering a JavaScript snippet that redirects the parent\n    window to the authorization URI, since Facebook will not allow this inside an iframe.\n    \"\"\"\n    query = {\n        'client_id': FACEBOOK_APPLICATION_ID,\n        'redirect_uri': redirect_uri\n    }\n\n    if permissions:\n        query['scope'] = ', '.join(permissions)\n\n    return render(\n        request = request,\n        template_name = 'fandjango/authorize_application.html',\n        dictionary = {\n            'url': 'https://www.facebook.com/dialog/oauth?%s' % urlencode(query)\n        },\n        status = 401\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake an INSERT query.", "response": "def make_insert(cls, table, insert_tuple):\n        \"\"\"\n        [Deprecated] Make INSERT query.\n\n        :param str table: Table name of executing the query.\n        :param list/tuple insert_tuple: Insertion data.\n        :return: Query of SQLite.\n        :rtype: str\n        :raises ValueError: If ``insert_tuple`` is empty |list|/|tuple|.\n        :raises simplesqlite.NameValidationError:\n            |raises_validate_table_name|\n        \"\"\"\n\n        validate_table_name(table)\n\n        table = Table(table)\n\n        if typepy.is_empty_sequence(insert_tuple):\n            raise ValueError(\"empty insert list/tuple\")\n\n        return \"INSERT INTO {:s} VALUES ({:s})\".format(\n            table, \",\".join([\"?\" for _i in insert_tuple])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_update(cls, table, set_query, where=None):\n\n        validate_table_name(table)\n        if typepy.is_null_string(set_query):\n            raise ValueError(\"SET query is null\")\n\n        query_list = [\"UPDATE {:s}\".format(Table(table)), \"SET {:s}\".format(set_query)]\n        if where and isinstance(where, (six.text_type, Where, And, Or)):\n            query_list.append(\"WHERE {:s}\".format(where))\n\n        return \" \".join(query_list)", "response": "Make UPDATE query.\n\n        :param str table: Table name of executing the query.\n        :param str set_query: SET part of the UPDATE query.\n        :param str where:\n            Add a WHERE clause to execute query,\n            if the value is not |None|.\n        :return: Query of SQLite.\n        :rtype: str\n        :raises ValueError: If ``set_query`` is empty string.\n        :raises simplesqlite.NameValidationError:\n            |raises_validate_table_name|"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a WHERE IN query.", "response": "def make_where_in(cls, key, value_list):\n        \"\"\"\n        Make part of WHERE IN query.\n\n        :param str key: Attribute name of the key.\n        :param str value_list:\n            List of values that the right hand side associated with the key.\n        :return: Part of WHERE query of SQLite.\n        :rtype: str\n\n        :Examples:\n            >>> from simplesqlite.sqlquery import SqlQuery\n            >>> SqlQuery.make_where_in(\"key\", [\"hoge\", \"foo\", \"bar\"])\n            \"key IN ('hoge', 'foo', 'bar')\"\n        \"\"\"\n\n        return \"{:s} IN ({:s})\".format(\n            Attr(key), \", \".join([Value(value).to_query() for value in value_list])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect(self, database_path, mode=\"a\"):\n\n        self.close()\n\n        logger.debug(\"connect to a SQLite database: path='{}', mode={}\".format(database_path, mode))\n\n        if mode == \"r\":\n            self.__verify_db_file_existence(database_path)\n        elif mode in [\"w\", \"a\"]:\n            self.__validate_db_path(database_path)\n        else:\n            raise ValueError(\"unknown connection mode: \" + mode)\n\n        if database_path == MEMORY_DB_NAME:\n            self.__database_path = database_path\n        else:\n            self.__database_path = os.path.realpath(database_path)\n\n        try:\n            self.__connection = sqlite3.connect(database_path)\n        except sqlite3.OperationalError as e:\n            raise OperationalError(e)\n\n        self.__mode = mode\n\n        try:\n            # validate connection after connect\n            self.fetch_table_names()\n        except sqlite3.DatabaseError as e:\n            raise DatabaseError(e)\n\n        if mode != \"w\":\n            return\n\n        for table in self.fetch_table_names():\n            self.drop_table(table)", "response": "Connect to a SQLite database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute_query(self, query, caller=None):\n\n        import time\n\n        self.check_connection()\n        if typepy.is_null_string(query):\n            return None\n\n        if self.debug_query or self.global_debug_query:\n            logger.debug(query)\n\n        if self.__is_profile:\n            exec_start_time = time.time()\n\n        try:\n            result = self.connection.execute(six.text_type(query))\n        except (sqlite3.OperationalError, sqlite3.IntegrityError) as e:\n            if caller is None:\n                caller = logging.getLogger().findCaller()\n            file_path, line_no, func_name = caller[:3]\n\n            raise OperationalError(\n                message=\"\\n\".join(\n                    [\n                        \"failed to execute query at {:s}({:d}) {:s}\".format(\n                            file_path, line_no, func_name\n                        ),\n                        \"  - query: {}\".format(MultiByteStrDecoder(query).unicode_str),\n                        \"  - msg:   {}\".format(e),\n                        \"  - db:    {}\".format(self.database_path),\n                    ]\n                )\n            )\n\n        if self.__is_profile:\n            self.__dict_query_count[query] = self.__dict_query_count.get(query, 0) + 1\n\n            elapse_time = time.time() - exec_start_time\n            self.__dict_query_totalexectime[query] = (\n                self.__dict_query_totalexectime.get(query, 0) + elapse_time\n            )\n\n        return result", "response": "Send arbitrary SQLite query to the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a SELECT query to the database.", "response": "def select(self, select, table_name, where=None, extra=None):\n        \"\"\"\n        Send a SELECT query to the database.\n\n        :param str select: Attribute for the ``SELECT`` query.\n        :param str table_name: |arg_select_table_name|\n        :param where: |arg_select_where|\n        :type where: |arg_where_type|\n        :param str extra: |arg_select_extra|\n        :return: Result of the query execution.\n        :rtype: sqlite3.Cursor\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n        :raises simplesqlite.OperationalError: |raises_operational_error|\n        \"\"\"\n\n        self.verify_table_existence(table_name)\n\n        return self.execute_query(\n            six.text_type(Select(select, table_name, where, extra)),\n            logging.getLogger().findCaller(),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets data in the database and return fetched data as a pandas. DataFrame.", "response": "def select_as_dataframe(self, table_name, columns=None, where=None, extra=None):\n        \"\"\"\n        Get data in the database and return fetched data as a\n        :py:class:`pandas.Dataframe` instance.\n\n        :param str table_name: |arg_select_table_name|\n        :param list columns: |arg_select_as_xx_columns|\n        :param str where: |arg_select_where|\n        :param str extra: |arg_select_extra|\n        :return: Table data as a :py:class:`pandas.Dataframe` instance.\n        :rtype: pandas.DataFrame\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n        :raises simplesqlite.OperationalError: |raises_operational_error|\n\n        :Example:\n            :ref:`example-select-as-dataframe`\n\n        .. note::\n            ``pandas`` package required to execute this method.\n        \"\"\"\n\n        import pandas\n\n        if columns is None:\n            columns = self.fetch_attr_names(table_name)\n\n        result = self.select(\n            select=AttrList(columns), table_name=table_name, where=where, extra=extra\n        )\n\n        if result is None:\n            return pandas.DataFrame()\n\n        return pandas.DataFrame(result.fetchall(), columns=columns)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef select_as_tabledata(\n        self, table_name, columns=None, where=None, extra=None, type_hints=None\n    ):\n        \"\"\"\n        Get data in the database and return fetched data as a\n        :py:class:`tabledata.TableData` instance.\n\n        :param str table_name: |arg_select_table_name|\n        :param list columns: |arg_select_as_xx_columns|\n        :param where: |arg_select_where|\n        :type where: |arg_where_type|\n        :param str extra: |arg_select_extra|\n        :return: Table data as a :py:class:`tabledata.TableData` instance.\n        :rtype: tabledata.TableData\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n        :raises simplesqlite.OperationalError: |raises_operational_error|\n\n        .. note::\n            ``pandas`` package required to execute this method.\n        \"\"\"\n\n        if columns is None:\n            columns = self.fetch_attr_names(table_name)\n\n        result = self.select(\n            select=AttrList(columns), table_name=table_name, where=where, extra=extra\n        )\n\n        if result is None:\n            return TableData(None, [], [])\n\n        if type_hints is None:\n            type_hints = self.fetch_data_types(table_name)\n\n        return TableData(\n            table_name,\n            columns,\n            result.fetchall(),\n            type_hints=[type_hints.get(col) for col in columns],\n        )", "response": "Select data from the database and return it as a TableData instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting data in the database and return fetched data as |OrderedDict| instances.", "response": "def select_as_dict(self, table_name, columns=None, where=None, extra=None):\n        \"\"\"\n        Get data in the database and return fetched data as a\n        |OrderedDict| list.\n\n        :param str table_name: |arg_select_table_name|\n        :param list columns: |arg_select_as_xx_columns|\n        :param where: |arg_select_where|\n        :type where: |arg_where_type|\n        :param str extra: |arg_select_extra|\n        :return: Table data as |OrderedDict| instances.\n        :rtype: |list| of |OrderedDict|\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n        :raises simplesqlite.OperationalError: |raises_operational_error|\n\n        :Example:\n            :ref:`example-select-as-dict`\n        \"\"\"\n\n        return self.select_as_tabledata(table_name, columns, where, extra).as_dict().get(table_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets data in the database and return fetched data as a SimpleSQLite instance.", "response": "def select_as_memdb(self, table_name, columns=None, where=None, extra=None):\n        \"\"\"\n        Get data in the database and return fetched data as a\n        in-memory |SimpleSQLite| instance.\n\n        :param str table_name: |arg_select_table_name|\n        :param list columns: |arg_select_as_xx_columns|\n        :param where: |arg_select_where|\n        :type where: |arg_where_type|\n        :param str extra: |arg_select_extra|\n        :return:\n            Table data as a |SimpleSQLite| instance that connected to in\n            memory database.\n        :rtype: |SimpleSQLite|\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n        :raises simplesqlite.OperationalError: |raises_operational_error|\n        \"\"\"\n\n        table_schema = self.schema_extractor.fetch_table_schema(table_name)\n\n        memdb = connect_memdb()\n        memdb.create_table_from_tabledata(\n            self.select_as_tabledata(table_name, columns, where, extra),\n            primary_key=table_schema.primary_key,\n            index_attrs=table_schema.index_list,\n        )\n\n        return memdb"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend an INSERT query to the database.", "response": "def insert(self, table_name, record, attr_names=None):\n        \"\"\"\n        Send an INSERT query to the database.\n\n        :param str table_name: Table name of executing the query.\n        :param record: Record to be inserted.\n        :type record: |dict|/|namedtuple|/|list|/|tuple|\n        :raises IOError: |raises_write_permission|\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.OperationalError: |raises_operational_error|\n\n        :Example:\n            :ref:`example-insert-records`\n        \"\"\"\n\n        self.insert_many(table_name, records=[record], attr_names=attr_names)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_many(self, table_name, records, attr_names=None):\n\n        self.validate_access_permission([\"w\", \"a\"])\n        self.verify_table_existence(table_name)\n\n        if attr_names:\n            logger.debug(\n                \"insert {number} records into {table}({attrs})\".format(\n                    number=len(records) if records else 0, table=table_name, attrs=attr_names\n                )\n            )\n        else:\n            logger.debug(\n                \"insert {number} records into {table}\".format(\n                    number=len(records) if records else 0, table=table_name\n                )\n            )\n\n        if typepy.is_empty_sequence(records):\n            return 0\n\n        if attr_names is None:\n            attr_names = self.fetch_attr_names(table_name)\n        records = RecordConvertor.to_records(attr_names, records)\n        query = Insert(table_name, AttrList(attr_names)).to_query()\n\n        if self.debug_query or self.global_debug_query:\n            logging_count = 8\n            num_records = len(records)\n\n            logs = [query] + [\n                \"    record {:4d}: {}\".format(i, record)\n                for i, record in enumerate(records[:logging_count])\n            ]\n            if num_records - logging_count > 0:\n                logs.append(\n                    \"    and other {} records will be inserted\".format(num_records - logging_count)\n                )\n\n            logger.debug(\"\\n\".join(logs))\n\n        try:\n            self.connection.executemany(query, records)\n        except (sqlite3.OperationalError, sqlite3.IntegrityError) as e:\n            caller = logging.getLogger().findCaller()\n            file_path, line_no, func_name = caller[:3]\n            raise OperationalError(\n                \"{:s}({:d}) {:s}: failed to execute query:\\n\".format(file_path, line_no, func_name)\n                + \"  query={}\\n\".format(query)\n                + \"  msg='{}'\\n\".format(e)\n                + \"  db={}\\n\".format(self.database_path)\n                + \"  records={}\\n\".format(records[:2])\n            )\n\n        return len(records)", "response": "Send an INSERT query with multiple records to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, table_name, set_query, where=None):\n\n        self.validate_access_permission([\"w\", \"a\"])\n        self.verify_table_existence(table_name)\n\n        query = SqlQuery.make_update(table_name, set_query, where)\n\n        return self.execute_query(query, logging.getLogger().findCaller())", "response": "Execute an UPDATE query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a DELETE query to the database.", "response": "def delete(self, table_name, where=None):\n        \"\"\"\n        Send a DELETE query to the database.\n\n        :param str table_name: Table name of executing the query.\n        :param where: |arg_select_where|\n        :type where: |arg_where_type|\n        \"\"\"\n\n        self.validate_access_permission([\"w\", \"a\"])\n        self.verify_table_existence(table_name)\n\n        query = \"DELETE FROM {:s}\".format(table_name)\n        if where:\n            query += \" WHERE {:s}\".format(where)\n\n        return self.execute_query(query, logging.getLogger().findCaller())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_value(self, select, table_name, where=None, extra=None):\n\n        try:\n            self.verify_table_existence(table_name)\n        except TableNotFoundError as e:\n            logger.debug(e)\n            return None\n\n        result = self.execute_query(\n            Select(select, table_name, where, extra), logging.getLogger().findCaller()\n        )\n        if result is None:\n            return None\n\n        fetch = result.fetchone()\n        if fetch is None:\n            return None\n\n        return fetch[0]", "response": "Fetch a value from the table. Return |None| if no value matches the conditions."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of table names in the database.", "response": "def fetch_table_names(self, include_system_table=False):\n        \"\"\"\n        :return: List of table names in the database.\n        :rtype: list\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.OperationalError: |raises_operational_error|\n\n        :Sample Code:\n            .. code:: python\n\n                from simplesqlite import SimpleSQLite\n\n                con = SimpleSQLite(\"sample.sqlite\", \"w\")\n                con.create_table_from_data_matrix(\n                    \"hoge\",\n                    [\"attr_a\", \"attr_b\"],\n                    [[1, \"a\"], [2, \"b\"]])\n                print(con.fetch_table_names())\n        :Output:\n            .. code-block:: python\n\n                ['hoge']\n        \"\"\"\n\n        self.check_connection()\n\n        return self.schema_extractor.fetch_table_names(include_system_table)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_attr_names(self, table_name):\n\n        self.verify_table_existence(table_name)\n\n        return self.schema_extractor.fetch_table_schema(table_name).get_attr_names()", "response": "Returns a list of attribute names in the table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching the attribute types of the specified table.", "response": "def fetch_attr_type(self, table_name):\n        \"\"\"\n        :return:\n            Dictionary of attribute names and attribute types in the table.\n        :rtype: dict\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n        :raises simplesqlite.OperationalError: |raises_operational_error|\n        \"\"\"\n\n        self.verify_table_existence(table_name)\n\n        result = self.execute_query(\n            \"SELECT sql FROM sqlite_master WHERE type='table' and name={:s}\".format(\n                Value(table_name)\n            )\n        )\n        query = result.fetchone()[0]\n        match = re.search(\"[(].*[)]\", query)\n\n        def get_entry(items):\n            key = \" \".join(items[:-1])\n            value = items[-1]\n\n            return [key, value]\n\n        return dict([get_entry(item.split(\" \")) for item in match.group().strip(\"()\").split(\", \")])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches the number of records in a table.", "response": "def fetch_num_records(self, table_name, where=None):\n        \"\"\"\n        Fetch the number of records in a table.\n\n        :param str table_name: Table name to get number of records.\n        :param where: |arg_select_where|\n        :type where: |arg_where_type|\n        :return:\n            Number of records in the table.\n            |None| if no value matches the conditions,\n            or the table not found in the database.\n        :rtype: int\n        \"\"\"\n\n        return self.fetch_value(select=\"COUNT(*)\", table_name=table_name, where=where)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the profile of query execution time.", "response": "def get_profile(self, profile_count=50):\n        \"\"\"\n        Get profile of query execution time.\n\n        :param int profile_count:\n            Number of profiles to retrieve,\n            counted from the top query in descending order by\n            the cumulative execution time.\n        :return: Profile information for each query.\n        :rtype: list of |namedtuple|\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.OperationalError: |raises_operational_error|\n\n        :Example:\n            :ref:`example-get-profile`\n        \"\"\"\n\n        from collections import namedtuple\n\n        profile_table_name = \"sql_profile\"\n\n        value_matrix = [\n            [query, execute_time, self.__dict_query_count.get(query, 0)]\n            for query, execute_time in six.iteritems(self.__dict_query_totalexectime)\n        ]\n        attr_names = (\"sql_query\", \"cumulative_time\", \"count\")\n        con_tmp = connect_memdb()\n        try:\n            con_tmp.create_table_from_data_matrix(\n                profile_table_name, attr_names, data_matrix=value_matrix\n            )\n        except ValueError:\n            return []\n\n        try:\n            result = con_tmp.select(\n                select=\"{:s},SUM({:s}),SUM({:s})\".format(*attr_names),\n                table_name=profile_table_name,\n                extra=\"GROUP BY {:s} ORDER BY {:s} DESC LIMIT {:d}\".format(\n                    attr_names[0], attr_names[1], profile_count\n                ),\n            )\n        except sqlite3.OperationalError:\n            return []\n        if result is None:\n            return []\n\n        SqliteProfile = namedtuple(\"SqliteProfile\", \" \".join(attr_names))\n\n        return [SqliteProfile(*profile) for profile in result.fetchall()]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_table(self, table_name):\n\n        try:\n            validate_table_name(table_name)\n        except NameValidationError:\n            return False\n\n        return table_name in self.fetch_table_names()", "response": "Return |True| if the database has the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests if the table with the given attribute exists.", "response": "def has_attr(self, table_name, attr_name):\n        \"\"\"\n        :param str table_name: Table name that the attribute exists.\n        :param str attr_name: Attribute name to be tested.\n        :return: |True| if the table has the attribute.\n        :rtype: bool\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n\n        :Sample Code:\n            .. code:: python\n\n                import simplesqlite\n\n                table_name = \"sample_table\"\n                con = simplesqlite.SimpleSQLite(\"sample.sqlite\", \"w\")\n                con.create_table_from_data_matrix(\n                    table_name,\n                    [\"attr_a\", \"attr_b\"],\n                    [[1, \"a\"], [2, \"b\"]])\n\n                print(con.has_attr(table_name, \"attr_a\"))\n                print(con.has_attr(table_name, \"not_existing\"))\n                try:\n                    print(con.has_attr(\"not_existing\", \"attr_a\"))\n                except simplesqlite.TableNotFoundError as e:\n                    print(e)\n        :Output:\n            .. parsed-literal::\n\n                True\n                False\n                'not_existing' table not found in /tmp/sample.sqlite\n        \"\"\"\n\n        self.verify_table_existence(table_name)\n\n        if typepy.is_null_string(attr_name):\n            return False\n\n        return attr_name in self.fetch_attr_names(table_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntest if a table has all of the attributes.", "response": "def has_attrs(self, table_name, attr_names):\n        \"\"\"\n        :param str table_name: Table name that attributes exists.\n        :param str attr_names: Attribute names to tested.\n        :return: |True| if the table has all of the attribute.\n        :rtype: bool\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n\n        :Sample Code:\n            .. code:: python\n\n                import simplesqlite\n\n                table_name = \"sample_table\"\n                con = simplesqlite.SimpleSQLite(\"sample.sqlite\", \"w\")\n                con.create_table_from_data_matrix(\n                    table_name,\n                    [\"attr_a\", \"attr_b\"],\n                    [[1, \"a\"], [2, \"b\"]])\n\n                print(con.has_attrs(table_name, [\"attr_a\"]))\n                print(con.has_attrs(table_name, [\"attr_a\", \"attr_b\"]))\n                print(con.has_attrs(table_name, [\"attr_a\", \"attr_b\", \"not_existing\"]))\n                try:\n                    print(con.has_attr(\"not_existing\", [\"attr_a\"]))\n                except simplesqlite.TableNotFoundError as e:\n                    print(e)\n        :Output:\n            .. parsed-literal::\n\n                True\n                True\n                False\n                'not_existing' table not found in /tmp/sample.sqlite\n        \"\"\"\n\n        if typepy.is_empty_sequence(attr_names):\n            return False\n\n        not_exist_fields = [\n            attr_name for attr_name in attr_names if not self.has_attr(table_name, attr_name)\n        ]\n\n        if not_exist_fields:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that the table exists in the database.", "response": "def verify_table_existence(self, table_name):\n        \"\"\"\n        :param str table_name: Table name to be tested.\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n        :raises simplesqlite.NameValidationError:\n            |raises_validate_table_name|\n\n        :Sample Code:\n            .. code:: python\n\n                import simplesqlite\n\n                table_name = \"sample_table\"\n                con = simplesqlite.SimpleSQLite(\"sample.sqlite\", \"w\")\n                con.create_table_from_data_matrix(\n                    table_name,\n                    [\"attr_a\", \"attr_b\"],\n                    [[1, \"a\"], [2, \"b\"]])\n\n                con.verify_table_existence(table_name)\n                try:\n                    con.verify_table_existence(\"not_existing\")\n                except simplesqlite.TableNotFoundError as e:\n                    print(e)\n        :Output:\n            .. parsed-literal::\n\n                'not_existing' table not found in /tmp/sample.sqlite\n        \"\"\"\n\n        validate_table_name(table_name)\n\n        if self.has_table(table_name):\n            return\n\n        raise TableNotFoundError(\n            \"'{}' table not found in '{}' database\".format(table_name, self.database_path)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nverify that the attribute exists in the table with the given name.", "response": "def verify_attr_existence(self, table_name, attr_name):\n        \"\"\"\n        :param str table_name: Table name that the attribute exists.\n        :param str attr_name: Attribute name to tested.\n        :raises simplesqlite.AttributeNotFoundError:\n            If attribute not found in the table\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n\n        :Sample Code:\n            .. code:: python\n\n                from simplesqlite import (\n                    SimpleSQLite,\n                    TableNotFoundError,\n                    AttributeNotFoundError\n                )\n\n                table_name = \"sample_table\"\n                con = SimpleSQLite(\"sample.sqlite\", \"w\")\n                con.create_table_from_data_matrix(\n                    table_name,\n                    [\"attr_a\", \"attr_b\"],\n                    [[1, \"a\"], [2, \"b\"]])\n\n                con.verify_attr_existence(table_name, \"attr_a\")\n                try:\n                    con.verify_attr_existence(table_name, \"not_existing\")\n                except AttributeNotFoundError as e:\n                    print(e)\n                try:\n                    con.verify_attr_existence(\"not_existing\", \"attr_a\")\n                except TableNotFoundError as e:\n                    print(e)\n        :Output:\n            .. parsed-literal::\n\n                'not_existing' attribute not found in 'sample_table' table\n                'not_existing' table not found in /tmp/sample.sqlite\n        \"\"\"\n\n        self.verify_table_existence(table_name)\n\n        if self.has_attr(table_name, attr_name):\n            return\n\n        raise AttributeNotFoundError(\n            \"'{}' attribute not found in '{}' table\".format(attr_name, table_name)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_access_permission(self, valid_permissions):\n\n        self.check_connection()\n\n        if typepy.is_null_string(self.mode):\n            raise ValueError(\"mode is not set\")\n\n        if self.mode not in valid_permissions:\n            raise IOError(\n                \"invalid access: expected-mode='{}', current-mode='{}'\".format(\n                    \"' or '\".join(valid_permissions), self.mode\n                )\n            )", "response": "Validate that the current user can access the given attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef drop_table(self, table_name):\n\n        self.validate_access_permission([\"w\", \"a\"])\n\n        if table_name in SQLITE_SYSTEM_TABLES:\n            # warning message\n            return\n\n        if self.has_table(table_name):\n            query = \"DROP TABLE IF EXISTS '{:s}'\".format(table_name)\n            self.execute_query(query, logging.getLogger().findCaller())\n            self.commit()", "response": "Drop a table from the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_table(self, table_name, attr_descriptions):\n\n        self.validate_access_permission([\"w\", \"a\"])\n\n        table_name = table_name.strip()\n        if self.has_table(table_name):\n            return True\n\n        query = \"CREATE TABLE IF NOT EXISTS '{:s}' ({:s})\".format(\n            table_name, \", \".join(attr_descriptions)\n        )\n        logger.debug(query)\n\n        if self.execute_query(query, logging.getLogger().findCaller()) is None:\n            return False\n\n        return True", "response": "Creates a new table in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an index for the specified attribute in the specified table.", "response": "def create_index(self, table_name, attr_name):\n        \"\"\"\n        :param str table_name:\n            Table name that contains the attribute to be indexed.\n        :param str attr_name: Attribute name to create index.\n        :raises IOError: |raises_write_permission|\n        :raises simplesqlite.NullDatabaseConnectionError:\n            |raises_check_connection|\n        :raises simplesqlite.TableNotFoundError:\n            |raises_verify_table_existence|\n        \"\"\"\n\n        self.verify_table_existence(table_name)\n        self.validate_access_permission([\"w\", \"a\"])\n\n        query_format = \"CREATE INDEX IF NOT EXISTS {index:s} ON {table}({attr})\"\n        query = query_format.format(\n            index=make_index_name(table_name, attr_name),\n            table=Table(table_name),\n            attr=Attr(attr_name),\n        )\n\n        logger.debug(query)\n        self.execute_query(query, logging.getLogger().findCaller())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates indices for the specified list of attributes.", "response": "def create_index_list(self, table_name, attr_names):\n        \"\"\"\n        :param str table_name: Table name that exists attribute.\n        :param list attr_names:\n            List of attribute names to create indices.\n            Ignore attributes that are not existing in the table.\n\n        .. seealso:: :py:meth:`.create_index`\n        \"\"\"\n\n        self.validate_access_permission([\"w\", \"a\"])\n\n        if typepy.is_empty_sequence(attr_names):\n            return\n\n        table_attr_set = set(self.fetch_attr_names(table_name))\n        index_attr_set = set(AttrList.sanitize(attr_names))\n\n        for attribute in list(table_attr_set.intersection(index_attr_set)):\n            self.create_index(table_name, attribute)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new table from a data matrix.", "response": "def create_table_from_data_matrix(\n        self,\n        table_name,\n        attr_names,\n        data_matrix,\n        primary_key=None,\n        add_primary_key_column=False,\n        index_attrs=None,\n    ):\n        \"\"\"\n        Create a table if not exists. Moreover, insert data into the created\n        table.\n\n        :param str table_name: Table name to create.\n        :param list attr_names: Attribute names of the table.\n        :param data_matrix: Data to be inserted into the table.\n        :type data_matrix: List of |dict|/|namedtuple|/|list|/|tuple|\n        :param str primary_key: |primary_key|\n        :param tuple index_attrs: |index_attrs|\n        :raises simplesqlite.NameValidationError:\n            |raises_validate_table_name|\n        :raises simplesqlite.NameValidationError:\n            |raises_validate_attr_name|\n        :raises ValueError: If the ``data_matrix`` is empty.\n\n        :Example:\n            :ref:`example-create-table-from-data-matrix`\n\n        .. seealso::\n            :py:meth:`.create_table`\n            :py:meth:`.insert_many`\n            :py:meth:`.create_index_list`\n        \"\"\"\n\n        self.__create_table_from_tabledata(\n            TableData(table_name, attr_names, data_matrix),\n            primary_key,\n            add_primary_key_column,\n            index_attrs,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a table from tabledata. TableData.", "response": "def create_table_from_tabledata(\n        self, table_data, primary_key=None, add_primary_key_column=False, index_attrs=None\n    ):\n        \"\"\"\n        Create a table from :py:class:`tabledata.TableData`.\n\n        :param tabledata.TableData table_data: Table data to create.\n        :param str primary_key: |primary_key|\n        :param tuple index_attrs: |index_attrs|\n\n        .. seealso::\n            :py:meth:`.create_table_from_data_matrix`\n        \"\"\"\n\n        self.__create_table_from_tabledata(\n            table_data, primary_key, add_primary_key_column, index_attrs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new table from a CSV file.", "response": "def create_table_from_csv(\n        self,\n        csv_source,\n        table_name=\"\",\n        attr_names=(),\n        delimiter=\",\",\n        quotechar='\"',\n        encoding=\"utf-8\",\n        primary_key=None,\n        add_primary_key_column=False,\n        index_attrs=None,\n    ):\n        \"\"\"\n        Create a table from a CSV file/text.\n\n        :param str csv_source: Path to the CSV file or CSV text.\n        :param str table_name:\n            Table name to create.\n            Using CSV file basename as the table name if the value is empty.\n        :param list attr_names:\n            Attribute names of the table.\n            Use the first line of the CSV file as attributes if ``attr_names`` is empty.\n        :param str delimiter:\n            A one-character string used to separate fields.\n        :param str quotechar:\n            A one-character string used to quote fields containing special\n            characters, such as the ``delimiter`` or ``quotechar``,\n            or which contain new-line characters.\n        :param str encoding: CSV file encoding.\n        :param str primary_key: |primary_key|\n        :param tuple index_attrs: |index_attrs|\n        :raises ValueError: If the CSV data is invalid.\n\n        :Dependency Packages:\n            - `pytablereader <https://github.com/thombashi/pytablereader>`__\n\n        :Example:\n            :ref:`example-create-table-from-csv`\n\n        .. seealso::\n            :py:meth:`.create_table_from_data_matrix`\n            :py:func:`csv.reader`\n            :py:meth:`.pytablereader.CsvTableFileLoader.load`\n            :py:meth:`.pytablereader.CsvTableTextLoader.load`\n        \"\"\"\n\n        import pytablereader as ptr\n\n        loader = ptr.CsvTableFileLoader(csv_source)\n        if typepy.is_not_null_string(table_name):\n            loader.table_name = table_name\n        loader.headers = attr_names\n        loader.delimiter = delimiter\n        loader.quotechar = quotechar\n        loader.encoding = encoding\n        try:\n            for table_data in loader.load():\n                self.__create_table_from_tabledata(\n                    table_data, primary_key, add_primary_key_column, index_attrs\n                )\n            return\n        except (ptr.InvalidFilePathError, IOError):\n            pass\n\n        loader = ptr.CsvTableTextLoader(csv_source)\n        if typepy.is_not_null_string(table_name):\n            loader.table_name = table_name\n        loader.headers = attr_names\n        loader.delimiter = delimiter\n        loader.quotechar = quotechar\n        loader.encoding = encoding\n        for table_data in loader.load():\n            self.__create_table_from_tabledata(\n                table_data, primary_key, add_primary_key_column, index_attrs\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_table_from_json(\n        self,\n        json_source,\n        table_name=\"\",\n        primary_key=None,\n        add_primary_key_column=False,\n        index_attrs=None,\n    ):\n        \"\"\"\n        Create a table from a JSON file/text.\n\n        :param str json_source: Path to the JSON file or JSON text.\n        :param str table_name: Table name to create.\n        :param str primary_key: |primary_key|\n        :param tuple index_attrs: |index_attrs|\n\n        :Dependency Packages:\n            - `pytablereader <https://github.com/thombashi/pytablereader>`__\n\n        :Examples:\n            :ref:`example-create-table-from-json`\n\n        .. seealso::\n            :py:meth:`.pytablereader.JsonTableFileLoader.load`\n            :py:meth:`.pytablereader.JsonTableTextLoader.load`\n        \"\"\"\n\n        import pytablereader as ptr\n\n        loader = ptr.JsonTableFileLoader(json_source)\n        if typepy.is_not_null_string(table_name):\n            loader.table_name = table_name\n        try:\n            for table_data in loader.load():\n                self.__create_table_from_tabledata(\n                    table_data, primary_key, add_primary_key_column, index_attrs\n                )\n            return\n        except (ptr.InvalidFilePathError, IOError):\n            pass\n\n        loader = ptr.JsonTableTextLoader(json_source)\n        if typepy.is_not_null_string(table_name):\n            loader.table_name = table_name\n        for table_data in loader.load():\n            self.__create_table_from_tabledata(\n                table_data, primary_key, add_primary_key_column, index_attrs\n            )", "response": "Create a table from a JSON file or text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a table from a pandas. DataFrame instance.", "response": "def create_table_from_dataframe(\n        self,\n        dataframe,\n        table_name=\"\",\n        primary_key=None,\n        add_primary_key_column=False,\n        index_attrs=None,\n    ):\n        \"\"\"\n        Create a table from a pandas.DataFrame instance.\n\n        :param pandas.DataFrame dataframe: DataFrame instance to convert.\n        :param str table_name: Table name to create.\n        :param str primary_key: |primary_key|\n        :param tuple index_attrs: |index_attrs|\n\n        :Examples:\n            :ref:`example-create-table-from-df`\n        \"\"\"\n\n        self.__create_table_from_tabledata(\n            TableData.from_dataframe(dataframe=dataframe, table_name=table_name),\n            primary_key,\n            add_primary_key_column,\n            index_attrs,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef commit(self):\n\n        try:\n            self.check_connection()\n        except NullDatabaseConnectionError:\n            return\n\n        logger.debug(\"commit: path='{}'\".format(self.database_path))\n\n        try:\n            self.connection.commit()\n        except sqlite3.ProgrammingError:\n            pass", "response": "Commits the current state of the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self):\n\n        if self.__delayed_connection_path and self.__connection is None:\n            self.__initialize_connection()\n            return\n\n        try:\n            self.check_connection()\n        except (SystemError, NullDatabaseConnectionError):\n            return\n\n        logger.debug(\"close connection to a SQLite database: path='{}'\".format(self.database_path))\n\n        self.commit()\n        self.connection.close()\n        self.__initialize_connection()", "response": "Commit and close the connection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure that the database file exists and opens a connection.", "response": "def __verify_db_file_existence(self, database_path):\n        \"\"\"\n        :raises SimpleSQLite.OperationalError: If unable to open database file.\n        \"\"\"\n\n        self.__validate_db_path(database_path)\n        if not os.path.isfile(os.path.realpath(database_path)):\n            raise IOError(\"file not found: \" + database_path)\n\n        try:\n            connection = sqlite3.connect(database_path)\n        except sqlite3.OperationalError as e:\n            raise OperationalError(e)\n\n        connection.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __extract_col_type_from_tabledata(table_data):\n\n        typename_table = {\n            typepy.Typecode.INTEGER: \"INTEGER\",\n            typepy.Typecode.REAL_NUMBER: \"REAL\",\n            typepy.Typecode.STRING: \"TEXT\",\n        }\n\n        return dict(\n            [\n                [col_idx, typename_table.get(col_dp.typecode, \"TEXT\")]\n                for col_idx, col_dp in enumerate(table_data.column_dp_list)\n            ]\n        )", "response": "Extract data type name for each column as SQLite names."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_table_name(name):\n\n    try:\n        validate_sqlite_table_name(name)\n    except (InvalidCharError, InvalidReservedNameError) as e:\n        raise NameValidationError(e)\n    except NullNameError:\n        raise NameValidationError(\"table name is empty\")\n    except ValidReservedNameError:\n        pass", "response": "Raises NameValidationError if the table name is invalid or invalid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_attr_name(name):\n\n    try:\n        validate_sqlite_attr_name(name)\n    except (InvalidCharError, InvalidReservedNameError) as e:\n        raise NameValidationError(e)\n    except NullNameError:\n        raise NameValidationError(\"attribute name is empty\")", "response": "Raises NameValidationError if name is invalid or invalid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef append_table(src_con, dst_con, table_name):\n\n    logger.debug(\n        \"append table: src={src_db}.{src_tbl}, dst={dst_db}.{dst_tbl}\".format(\n            src_db=src_con.database_path,\n            src_tbl=table_name,\n            dst_db=dst_con.database_path,\n            dst_tbl=table_name,\n        )\n    )\n\n    src_con.verify_table_existence(table_name)\n    dst_con.validate_access_permission([\"w\", \"a\"])\n\n    if dst_con.has_table(table_name):\n        src_attrs = src_con.fetch_attr_names(table_name)\n        dst_attrs = dst_con.fetch_attr_names(table_name)\n        if src_attrs != dst_attrs:\n            raise ValueError(\n                dedent(\n                    \"\"\"\n                    source and destination attribute is different from each other\n                    src: {}\n                    dst: {}\n                    \"\"\".format(\n                        src_attrs, dst_attrs\n                    )\n                )\n            )\n\n    primary_key, index_attrs, type_hints = extract_table_metadata(src_con, table_name)\n\n    dst_con.create_table_from_tabledata(\n        src_con.select_as_tabledata(table_name, type_hints=type_hints),\n        primary_key=primary_key,\n        index_attrs=index_attrs,\n    )\n\n    return True", "response": "Append a table from source database to destination database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies a table from source to destination.", "response": "def copy_table(src_con, dst_con, src_table_name, dst_table_name, is_overwrite=True):\n    \"\"\"\n    Copy a table from source to destination.\n\n    :param SimpleSQLite src_con: Connection to the source database.\n    :param SimpleSQLite dst_con: Connection to the destination database.\n    :param str src_table_name: Source table name to copy.\n    :param str dst_table_name: Destination table name.\n    :param bool is_overwrite: If |True|, overwrite existing table.\n    :return: |True| if the copy operation succeed.\n    :rtype: bool\n    :raises simplesqlite.TableNotFoundError:\n        |raises_verify_table_existence|\n    :raises ValueError:\n        If attributes of the table are different from each other.\n    \"\"\"\n\n    logger.debug(\n        \"copy table: src={src_db}.{src_tbl}, dst={dst_db}.{dst_tbl}\".format(\n            src_db=src_con.database_path,\n            src_tbl=src_table_name,\n            dst_db=dst_con.database_path,\n            dst_tbl=dst_table_name,\n        )\n    )\n\n    src_con.verify_table_existence(src_table_name)\n    dst_con.validate_access_permission([\"w\", \"a\"])\n\n    if dst_con.has_table(dst_table_name):\n        if is_overwrite:\n            dst_con.drop_table(dst_table_name)\n        else:\n            logger.error(\n                \"failed to copy table: the table already exists \"\n                \"(src_table={}, dst_table={})\".format(src_table_name, dst_table_name)\n            )\n            return False\n\n    primary_key, index_attrs, _ = extract_table_metadata(src_con, src_table_name)\n\n    result = src_con.select(select=\"*\", table_name=src_table_name)\n    if result is None:\n        return False\n\n    dst_con.create_table_from_data_matrix(\n        dst_table_name,\n        src_con.fetch_attr_names(src_table_name),\n        result.fetchall(),\n        primary_key=primary_key,\n        index_attrs=index_attrs,\n    )\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_sqlite_table_name(name):\n\n    if not name:\n        raise NullNameError(\"null name\")\n\n    if __RE_INVALID_CHARS.search(name):\n        raise InvalidCharError(\"unprintable character found\")\n\n    name = name.upper()\n\n    if name in __SQLITE_INVALID_RESERVED_KEYWORDS_TABLE:\n        raise InvalidReservedNameError(\"'{:s}' is a reserved keyword by sqlite\".format(name))\n\n    if name in __SQLITE_VALID_RESERVED_KEYWORDS_TABLE:\n        raise ValidReservedNameError(\"'{:s}' is a reserved keyword by sqlite\".format(name))", "response": "Validates that the given name is a valid SQL table name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that the given name is a valid SQLite attribute name.", "response": "def validate_sqlite_attr_name(name):\n    \"\"\"\n    :param str name: Name to validate.\n    :raises pathvalidate.NullNameError: If the ``name`` is empty.\n    :raises pathvalidate.InvalidCharError:\n        If the ``name`` includes unprintable character(s).\n    :raises pathvalidate.InvalidReservedNameError:\n        |raises_sqlite_keywords|\n        And invalid as an attribute name.\n    :raises pathvalidate.ValidReservedNameError:\n        |raises_sqlite_keywords|\n        However, valid as an attribute name.\n    \"\"\"\n\n    if not name:\n        raise NullNameError(\"null name\")\n\n    if __RE_INVALID_CHARS.search(name):\n        raise InvalidCharError(\"unprintable character found\")\n\n    name = name.upper()\n\n    if name in __SQLITE_INVALID_RESERVED_KEYWORDS_ATTR:\n        raise InvalidReservedNameError(\"'{}' is a reserved keyword by sqlite\".format(name))\n\n    if name in __SQLITE_VALID_RESERVED_KEYWORDS_ATTR:\n        raise ValidReservedNameError(\"'{}' is a reserved keyword by sqlite\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generic_convert_string(v, from_type, to_type, encoding):\n\n    assert six.PY2, \"This function should be used with Python 2 only\"\n    assert from_type != to_type\n\n    if from_type == six.binary_type and isinstance(v, six.binary_type):\n        return six.text_type(v, encoding)\n\n    elif from_type == six.text_type and isinstance(v, six.text_type):\n        return v.encode(encoding)\n\n    elif isinstance(v, (list, tuple, set)):\n        return type(v)([_generic_convert_string(element, from_type, to_type, encoding) for element in v])\n\n    elif isinstance(v, dict):\n        return {k: _generic_convert_string(v, from_type, to_type, encoding) for k, v in v.iteritems()}\n\n    return v", "response": "Generic method to convert any argument type from_type to to_type"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to convert a date to a builtin datetime. datetime instance.", "response": "def get_builtin_date(date, date_format=\"%Y-%m-%dT%H:%M:%S\", raise_exception=False):\n    \"\"\"\n    Try to convert a date to a builtin instance of ``datetime.datetime``.\n    The input date can be a ``str``, a ``datetime.datetime``, a ``xmlrpc.client.Datetime`` or a ``xmlrpclib.Datetime``\n    instance. The returned object is a ``datetime.datetime``.\n\n    :param date: The date object to convert.\n    :param date_format: If the given date is a str, format is passed to strptime to parse it\n    :param raise_exception: If set to True, an exception will be raised if the input string cannot be parsed\n    :return: A valid ``datetime.datetime`` instance\n    \"\"\"\n    if isinstance(date, datetime.datetime):\n        # Default XML-RPC handler is configured to decode dateTime.iso8601 type\n        # to builtin datetime.datetim instance\n        return date\n    elif isinstance(date, xmlrpc_client.DateTime):\n        # If constant settings.MODERNRPC_XMLRPC_USE_BUILTIN_TYPES has been set to True\n        # the date is decoded as DateTime object\n        return datetime.datetime.strptime(date.value, \"%Y%m%dT%H:%M:%S\")\n    else:\n        # If date is given as str (or unicode for python 2)\n        # This is the normal behavior for JSON-RPC\n        try:\n            return datetime.datetime.strptime(date, date_format)\n        except ValueError:\n            if raise_exception:\n                raise\n            else:\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassign a new authentication predicate to an RPC method. This is the most generic decorator used to implement authentication. Predicate is a standard function with the following signature: .. code:: python def my_predicate(request, *params): # Inspect request and extract required information if <condition>: # The condition to execute the method are met return True return False :param predicate: :param params: :return:", "response": "def set_authentication_predicate(predicate, params=()):\n    \"\"\"\n    Assign a new authentication predicate to an RPC method.\n    This is the most generic decorator used to implement authentication.\n    Predicate is a standard function with the following signature:\n\n    .. code:: python\n\n       def my_predicate(request, *params):\n           # Inspect request and extract required information\n\n           if <condition>:\n               # The condition to execute the method are met\n               return True\n           return False\n\n    :param predicate:\n    :param params:\n    :return:\n    \"\"\"\n\n    def wrapper(rpc_method):\n\n        if hasattr(rpc_method, 'modernrpc_auth_predicates'):\n            rpc_method.modernrpc_auth_predicates.append(predicate)\n            rpc_method.modernrpc_auth_predicates_params.append(params)\n\n        else:\n            rpc_method.modernrpc_auth_predicates = [predicate]\n            rpc_method.modernrpc_auth_predicates_params = [params]\n\n        return rpc_method\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the given user is in given group", "response": "def user_in_group(user, group):\n    \"\"\"Returns True if the given user is in given group\"\"\"\n    if isinstance(group, Group):\n        return user_is_superuser(user) or group in user.groups.all()\n    elif isinstance(group, six.string_types):\n        return user_is_superuser(user) or user.groups.filter(name=group).exists()\n    raise TypeError(\"'group' argument must be a string or a Group instance\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the given user is in at least 1 of the given groups", "response": "def user_in_any_group(user, groups):\n    \"\"\"Returns True if the given user is in at least 1 of the given groups\"\"\"\n    return user_is_superuser(user) or any(user_in_group(user, group) for group in groups)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the given user is in all given groups", "response": "def user_in_all_groups(user, groups):\n    \"\"\"Returns True if the given user is in all given groups\"\"\"\n    return user_is_superuser(user) or all(user_in_group(user, group) for group in groups)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_handler_classes(self):\n\n        handler_classes = [import_string(handler_cls) for handler_cls in settings.MODERNRPC_HANDLERS]\n\n        if self.protocol == ALL:\n            return handler_classes\n        else:\n            return [cls for cls in handler_classes if cls.protocol in ensure_sequence(self.protocol)]", "response": "Return the list of handlers to use when receiving RPC requests."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle a request from the modernizr server.", "response": "def post(self, request, *args, **kwargs):\n        \"\"\"\n        Handle a XML-RPC or JSON-RPC request.\n\n        :param request: Incoming request\n        :param args: Additional arguments\n        :param kwargs: Additional named arguments\n        :return: A HttpResponse containing XML-RPC or JSON-RPC response, depending on the incoming request\n        \"\"\"\n\n        logger.debug('RPC request received...')\n\n        for handler_cls in self.get_handler_classes():\n\n            handler = handler_cls(request, self.entry_point)\n\n            try:\n                if not handler.can_handle():\n                    continue\n\n                logger.debug('Request will be handled by {}'.format(handler_cls.__name__))\n\n                result = handler.process_request()\n\n                return handler.result_success(result)\n\n            except AuthenticationFailed as e:\n                # Customize HttpResponse instance used when AuthenticationFailed was raised\n                logger.warning(e)\n                return handler.result_error(e, HttpResponseForbidden)\n\n            except RPCException as e:\n                logger.warning('RPC exception: {}'.format(e), exc_info=settings.MODERNRPC_LOG_EXCEPTIONS)\n                return handler.result_error(e)\n\n            except Exception as e:\n                logger.error('Exception raised from a RPC method: \"{}\"'.format(e),\n                             exc_info=settings.MODERNRPC_LOG_EXCEPTIONS)\n                return handler.result_error(RPCInternalError(str(e)))\n\n        logger.error('Unable to handle incoming request.')\n\n        return HttpResponse('Unable to handle your request. Please ensure you called the right entry point. If not, '\n                            'this could be a server error.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate context data with list of RPC methods of the current entry point.", "response": "def get_context_data(self, **kwargs):\n        \"\"\"Update context data with list of RPC methods of the current entry point.\n        Will be used to display methods documentation page\"\"\"\n        kwargs.update({\n            'methods': registry.get_all_methods(self.entry_point, sort_methods=True),\n        })\n        return super(RPCEntryPoint, self).get_context_data(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rpc_methods_registration():\n\n        # In previous version, django-modern-rpc used the django cache system to store methods registry.\n        # It is useless now, so clean the cache from old data\n        clean_old_cache_content()\n        # For security (and unit tests), make sure the registry is empty before registering rpc methods\n        registry.reset()\n\n        if not settings.MODERNRPC_METHODS_MODULES:\n            # settings.MODERNRPC_METHODS_MODULES is undefined or empty, but we already notified user\n            # with check_required_settings_defined() function. See http://docs.djangoproject.com/en/1.10/topics/checks/\n            return\n\n        # Lookup content of MODERNRPC_METHODS_MODULES, and add the module containing system methods\n        for module_name in settings.MODERNRPC_METHODS_MODULES + ['modernrpc.system_methods']:\n\n            try:\n                # Import the module in current scope\n                rpc_module = import_module(module_name)\n\n            except ImportError:\n                msg = 'Unable to load module \"{}\" declared in settings.MODERNRPC_METHODS_MODULES. Please ensure ' \\\n                      'it is available and doesn\\'t contains any error'.format(module_name)\n                warnings.warn(msg, category=Warning)\n                continue\n\n            # Lookup all global functions in module\n            for _, func in inspect.getmembers(rpc_module, inspect.isfunction):\n                # And register only functions with attribute 'modernrpc_enabled' defined to True\n                if getattr(func, 'modernrpc_enabled', False):\n                    registry.register_method(func)\n\n        logger.info('django-modern-rpc initialized: {} RPC methods registered'.format(registry.total_count()))", "response": "Look into each module listed in settings. MODERNRPC_METHODS_MODULES and register all RPC methods annotated with the rpc_method decorator in the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef http_basic_auth_get_user(request):\n\n    try:\n        # If standard auth middleware already authenticated a user, use it\n        if user_is_authenticated(request.user):\n            return request.user\n    except AttributeError:\n        pass\n\n    # This was grabbed from https://www.djangosnippets.org/snippets/243/\n    # Thanks to http://stackoverflow.com/a/1087736/1887976\n    if 'HTTP_AUTHORIZATION' in request.META:\n        auth_data = request.META['HTTP_AUTHORIZATION'].split()\n        if len(auth_data) == 2 and auth_data[0].lower() == \"basic\":\n            uname, passwd = base64.b64decode(auth_data[1]).decode('utf-8').split(':')\n            django_user = authenticate(username=uname, password=passwd)\n            if django_user is not None:\n                login(request, django_user)\n\n    # In all cases, return the current request's user (may be anonymous user if no login succeed)\n    try:\n        return request.user\n    except AttributeError:\n        return AnonymousUser()", "response": "Inspects the given request to find a logged user. If not found returns AnonymousUser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef http_basic_auth_login_required(func=None):\n\n    wrapper = auth.set_authentication_predicate(http_basic_auth_check_user, [auth.user_is_authenticated])\n\n    # If @http_basic_auth_login_required() is used (with parenthesis)\n    if func is None:\n        return wrapper\n\n    # If @http_basic_auth_login_required is used without parenthesis\n    return wrapper(func)", "response": "Decorator. Use it to specify a RPC method is available only to logged users"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef http_basic_auth_superuser_required(func=None):\n\n    wrapper = auth.set_authentication_predicate(http_basic_auth_check_user, [auth.user_is_superuser])\n\n    # If @http_basic_auth_superuser_required() is used (with parenthesis)\n    if func is None:\n        return wrapper\n\n    # If @http_basic_auth_superuser_required is used without parenthesis\n    return wrapper(func)", "response": "Decorator. Use it to specify a RPC method is available only to logged superusers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef http_basic_auth_group_member_required(groups):\n\n    if isinstance(groups, six.string_types):\n        # Check user is in a group\n        return auth.set_authentication_predicate(http_basic_auth_check_user, [auth.user_in_group, groups])\n    else:\n        # Check user is in many group\n        return auth.set_authentication_predicate(http_basic_auth_check_user, [auth.user_in_any_group, groups])", "response": "Decorator. Use it to specify a RPC method is available only to logged users with given permissions"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmarks a standard python function as RPC method.", "response": "def rpc_method(func=None, name=None, entry_point=ALL, protocol=ALL,\n               str_standardization=settings.MODERNRPC_PY2_STR_TYPE,\n               str_standardization_encoding=settings.MODERNRPC_PY2_STR_ENCODING):\n    \"\"\"\n    Mark a standard python function as RPC method.\n\n    All arguments are optional\n\n    :param func: A standard function\n    :param name: Used as RPC method name instead of original function name\n    :param entry_point: Default: ALL. Used to limit usage of the RPC method for a specific set of entry points\n    :param protocol: Default: ALL. Used to limit usage of the RPC method for a specific protocol (JSONRPC or XMLRPC)\n    :param str_standardization: Default: settings.MODERNRPC_PY2_STR_TYPE. Configure string standardization on python 2.\n    Ignored on python 3.\n    :param str_standardization_encoding: Default: settings.MODERNRPC_PY2_STR_ENCODING. Configure the encoding used\n    to perform string standardization conversion. Ignored on python 3.\n    :type name: str\n    :type entry_point: str\n    :type protocol: str\n    :type str_standardization: type str or unicode\n    :type str_standardization_encoding: str\n    \"\"\"\n\n    def decorated(_func):\n\n        _func.modernrpc_enabled = True\n        _func.modernrpc_name = name or _func.__name__\n        _func.modernrpc_entry_point = entry_point\n        _func.modernrpc_protocol = protocol\n        _func.str_standardization = str_standardization\n        _func.str_standardization_encoding = str_standardization_encoding\n\n        return _func\n\n    # If @rpc_method() is used with parenthesis (with or without argument)\n    if func is None:\n        return decorated\n\n    # If @rpc_method is used without parenthesis\n    return decorated(func)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the given full docstring and extracts the method description arguments and return documentation.", "response": "def parse_docstring(self, content):\n        \"\"\"\n        Parse the given full docstring, and extract method description, arguments, and return documentation.\n\n        This method try to find arguments description and types, and put the information in \"args_doc\" and \"signature\"\n        members. Also parse return type and description, and put the information in \"return_doc\" member.\n        All other lines are added to the returned string\n        :param content: The full docstring\n        :type content: str\n        :return: The parsed method description\n        :rtype: str\n        \"\"\"\n\n        if not content:\n            return\n\n        raw_docstring = ''\n        # We use the helper defined in django admindocs app to remove indentation chars from docstring,\n        # and parse it as title, body, metadata. We don't use metadata for now.\n        docstring = trim_docstring(content)\n\n        for line in docstring.split('\\n'):\n\n            # Empty line\n            if not line:\n                raw_docstring += '\\n'\n                continue\n\n            param_match = PARAM_REXP.match(line)\n            if param_match:\n\n                param_name, description = param_match.group(1, 2)\n                if param_name == 'kwargs':\n                    continue\n\n                doc = self.args_doc.setdefault(param_name, {})\n                doc['text'] = description\n                continue\n\n            param_type_match = PARAM_TYPE_REXP.match(line)\n            if param_type_match:\n\n                param_name, param_type = param_type_match.group(1, 2)\n                if param_name == 'kwargs':\n                    continue\n\n                doc = self.args_doc.setdefault(param_name, {})\n                doc['type'] = param_type\n                self.signature.append(param_type)\n                continue\n\n            return_match = RETURN_REXP.match(line)\n            if return_match:\n                return_description = return_match.group(1)\n                self.return_doc['text'] = return_description\n                continue\n\n            return_type_match = RETURN_TYPE_REXP.match(line)\n            if return_type_match:\n                return_description = return_type_match.group(1)\n                self.return_doc['type'] = return_description\n                self.signature.insert(0, return_description)\n                continue\n\n            # Line doesn't match with known args/return regular expressions,\n            # add the line to raw help text\n            raw_docstring += line + '\\n'\n        return raw_docstring"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the request has permission to call the method.", "response": "def check_permissions(self, request):\n        \"\"\"Call the predicate(s) associated with the RPC method, to check if the current request\n        can actually call the method.\n        Return a boolean indicating if the method should be executed (True) or not (False)\"\"\"\n\n        if not self.predicates:\n            return True\n\n        # All registered authentication predicates must return True\n        return all(\n            predicate(request, *self.predicates_params[i])\n            for i, predicate in enumerate(self.predicates)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the current function can be executed from a request defining the given protocol", "response": "def available_for_protocol(self, protocol):\n        \"\"\"Check if the current function can be executed from a request defining the given protocol\"\"\"\n        if self.protocol == ALL or protocol == ALL:\n            return True\n\n        return protocol in ensure_sequence(self.protocol)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the current function can be executed from a given entry point", "response": "def available_for_entry_point(self, entry_point):\n        \"\"\"Check if the current function can be executed from a request to the given entry point\"\"\"\n        if self.entry_point == ALL or entry_point == ALL:\n            return True\n\n        return entry_point in ensure_sequence(self.entry_point)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_valid_for(self, entry_point, protocol):\n        return self.available_for_entry_point(entry_point) and self.available_for_protocol(protocol)", "response": "Check if the current function can be executed from the given entry point and with the given protocol"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if this method s return is documented", "response": "def is_return_doc_available(self):\n        \"\"\"Returns True if this method's return is documented\"\"\"\n        return bool(self.return_doc and (self.return_doc.get('text') or self.return_doc.get('type')))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a function to be available as RPC method.", "response": "def register_method(self, func):\n        \"\"\"\n        Register a function to be available as RPC method.\n\n        The given function will be inspected to find external_name, protocol and entry_point values set by the decorator\n        @rpc_method.\n        :param func: A function previously decorated using @rpc_method\n        :return: The name of registered method\n        \"\"\"\n        if not getattr(func, 'modernrpc_enabled', False):\n            raise ImproperlyConfigured('Error: trying to register {} as RPC method, but it has not been decorated.'\n                                       .format(func.__name__))\n\n        # Define the external name of the function\n        name = getattr(func, 'modernrpc_name', func.__name__)\n\n        logger.debug('Register RPC method \"{}\"'.format(name))\n\n        if name.startswith('rpc.'):\n            raise ImproperlyConfigured('According to RPC standard, method names starting with \"rpc.\" are reserved for '\n                                       'system extensions and must not be used. See '\n                                       'http://www.jsonrpc.org/specification#extensions for more information.')\n\n        # Encapsulate the function in a RPCMethod object\n        method = RPCMethod(func)\n\n        # Ensure method names are unique in the registry\n        existing_method = self.get_method(method.name, ALL, ALL)\n        if existing_method is not None:\n            # Trying to register many times the same function is OK, because if a method is decorated\n            # with @rpc_method(), it could be imported in different places of the code\n            if method == existing_method:\n                return method.name\n            # But if we try to use the same name to register 2 different methods, we\n            # must inform the developer there is an error in the code\n            else:\n                raise ImproperlyConfigured(\"A RPC method with name {} has already been registered\".format(method.name))\n\n        # Store the method\n        self._registry[method.name] = method\n        logger.debug('Method registered. len(registry): {}'.format(len(self._registry)))\n\n        return method.name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the names of all RPC methods registered by the given entry_point / protocol pair.", "response": "def get_all_method_names(self, entry_point=ALL, protocol=ALL, sort_methods=False):\n        \"\"\"Return the names of all RPC methods registered supported by the given entry_point / protocol pair\"\"\"\n\n        method_names = [\n            name for name, method in self._registry.items() if method.is_valid_for(entry_point, protocol)\n        ]\n\n        if sort_methods:\n            method_names = sorted(method_names)\n\n        return method_names"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all methods in the registry supported by the given entry_point / protocol pair.", "response": "def get_all_methods(self, entry_point=ALL, protocol=ALL, sort_methods=False):\n        \"\"\"Return a list of all methods in the registry supported by the given entry_point / protocol pair\"\"\"\n\n        if sort_methods:\n            return [\n                method for (_, method) in sorted(self._registry.items()) if method.is_valid_for(entry_point, protocol)\n            ]\n\n        return self._registry.values()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_method(self, name, entry_point, protocol):\n\n        if name in self._registry and self._registry[name].is_valid_for(entry_point, protocol):\n            return self._registry[name]\n\n        return None", "response": "Retrieve a method from the given name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if given logger has at least 1 handler associated return a boolean value.", "response": "def logger_has_handlers(logger):\n    \"\"\"\n    Check if given logger has at least 1 handler associated, return a boolean value.\n\n    Since Python 2 doesn't provide Logger.hasHandlers(), we have to perform the lookup by ourself.\n    \"\"\"\n    if six.PY3:\n        return logger.hasHandlers()\n    else:\n        c = logger\n        rv = False\n        while c:\n            if c.handlers:\n                rv = True\n                break\n            if not c.propagate:\n                break\n            else:\n                c = c.parent\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_modernrpc_logger(name):\n    logger = logging.getLogger(name)\n    if not logger_has_handlers(logger):\n        # If logging is not configured in the current project, configure this logger to discard all logs messages.\n        # This will prevent the 'No handlers could be found for logger XXX' error on Python 2,\n        # and avoid redirecting errors to the default 'lastResort' StreamHandler on Python 3\n        logger.addHandler(logging.NullHandler())\n    return logger", "response": "Get a logger from default logging manager. If no handler is associated add a default NullHandler"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute_procedure(self, name, args=None, kwargs=None):\n\n        _method = registry.get_method(name, self.entry_point, self.protocol)\n\n        if not _method:\n            raise RPCUnknownMethod(name)\n\n        logger.debug('Check authentication / permissions for method {} and user {}'\n                     .format(name, self.request.user))\n\n        if not _method.check_permissions(self.request):\n            raise AuthenticationFailed(name)\n\n        logger.debug('RPC method {} will be executed'.format(name))\n\n        # Replace default None value with empty instance of corresponding type\n        args = args or []\n        kwargs = kwargs or {}\n\n        # If the RPC method needs to access some internals, update kwargs dict\n        if _method.accept_kwargs:\n            kwargs.update({\n                REQUEST_KEY: self.request,\n                ENTRY_POINT_KEY: self.entry_point,\n                PROTOCOL_KEY: self.protocol,\n                HANDLER_KEY: self,\n            })\n\n        if six.PY2:\n            method_std, encoding = _method.str_standardization, _method.str_std_encoding\n            args = modernrpc.compat.standardize_strings(args, strtype=method_std, encoding=encoding)\n            kwargs = modernrpc.compat.standardize_strings(kwargs, strtype=method_std, encoding=encoding)\n\n        logger.debug('Params: args = {} - kwargs = {}'.format(args, kwargs))\n\n        try:\n            # Call the rpc method, as standard python function\n            return _method.function(*args, **kwargs)\n\n        except TypeError as e:\n            # If given arguments cannot be transmitted properly to python function,\n            # raise an Invalid Params exceptions\n            raise RPCInvalidParams(str(e))", "response": "Execute the given RPC Method name and return the result."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __system_listMethods(**kwargs):\n    entry_point = kwargs.get(ENTRY_POINT_KEY)\n    protocol = kwargs.get(PROTOCOL_KEY)\n\n    return registry.get_all_method_names(entry_point, protocol, sort_methods=True)", "response": "Returns a list of all methods available in the current entry point and protocol"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __system_methodSignature(method_name, **kwargs):\n    entry_point = kwargs.get(ENTRY_POINT_KEY)\n    protocol = kwargs.get(PROTOCOL_KEY)\n\n    method = registry.get_method(method_name, entry_point, protocol)\n    if method is None:\n        raise RPCInvalidParams('Unknown method {}. Unable to retrieve signature.'.format(method_name))\n    return method.signature", "response": "Returns the signature of the given method name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the documentation text for the given method name.", "response": "def __system_methodHelp(method_name, **kwargs):\n    \"\"\"\n    Returns the documentation of the given method name.\n\n    :param method_name: Name of a method available for current entry point (and protocol)\n    :param kwargs:\n    :return: Documentation text for the RPC method\n    \"\"\"\n    entry_point = kwargs.get(ENTRY_POINT_KEY)\n    protocol = kwargs.get(PROTOCOL_KEY)\n\n    method = registry.get_method(method_name, entry_point, protocol)\n    if method is None:\n        raise RPCInvalidParams('Unknown method {}. Unable to retrieve its documentation.'.format(method_name))\n    return method.html_doc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall multiple RPC methods at once.", "response": "def __system_multiCall(calls, **kwargs):\n    \"\"\"\n    Call multiple RPC methods at once.\n\n    :param calls: An array of struct like {\"methodName\": string, \"params\": array }\n    :param kwargs: Internal data\n    :type calls: list\n    :type kwargs: dict\n    :return:\n    \"\"\"\n    if not isinstance(calls, list):\n        raise RPCInvalidParams('system.multicall first argument should be a list, {} given.'.format(type(calls)))\n\n    handler = kwargs.get(HANDLER_KEY)\n\n    results = []\n\n    for call in calls:\n        try:\n            result = handler.execute_procedure(call['methodName'], args=call.get('params'))\n\n            # From https://mirrors.talideon.com/articles/multicall.html:\n            # \"Notice that regular return values are always nested inside a one-element array. This allows you to\n            # return structs from functions without confusing them with faults.\"\n            results.append([result])\n\n        except RPCException as e:\n            results.append({\n                'faultCode': e.code,\n                'faultString': e.message,\n            })\n        except Exception as e:\n            results.append({\n                'faultCode': RPC_INTERNAL_ERROR,\n                'faultString': str(e),\n            })\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the user s token serial number MFA token code and an anonymization error code.", "response": "def acquire_code(args, session, session3):\n    \"\"\"returns the user's token serial number, MFA token code, and an\n    error code.\"\"\"\n    serial_number = find_mfa_for_user(args.serial_number, session, session3)\n    if not serial_number:\n        print(\"There are no MFA devices associated with this user.\",\n              file=sys.stderr)\n        return None, None, USER_RECOVERABLE_ERROR\n\n    token_code = args.token_code\n    if token_code is None:\n        while token_code is None or len(token_code) != 6:\n            token_code = getpass.getpass(\"MFA Token Code: \")\n    return serial_number, token_code, OK"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrotating the identity profile s AWS access key pair.", "response": "def rotate(args, credentials):\n    \"\"\"rotate the identity profile's AWS access key pair.\"\"\"\n    current_access_key_id = credentials.get(\n        args.identity_profile, 'aws_access_key_id')\n\n    # create new sessions using the MFA credentials\n    session, session3, err = make_session(args.target_profile)\n    if err:\n        return err\n    iam = session3.resource('iam')\n\n    # find the AccessKey corresponding to the identity profile and delete it.\n    current_access_key = next((key for key\n                               in iam.CurrentUser().access_keys.all()\n                               if key.access_key_id == current_access_key_id))\n    current_access_key.delete()\n\n    # create the new access key pair\n    iam_service = session3.client('iam')\n    new_access_key_pair = iam_service.create_access_key()[\"AccessKey\"]\n\n    print(\"Rotating from %s to %s.\" % (current_access_key.access_key_id,\n                                       new_access_key_pair['AccessKeyId']),\n          file=sys.stderr)\n    update_credentials_file(args.aws_credentials,\n                            args.identity_profile,\n                            args.identity_profile,\n                            credentials,\n                            new_access_key_pair)\n    print(\"%s profile updated.\" % args.identity_profile, file=sys.stderr)\n\n    return OK"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef coerce(self, value):\n        if self._coerce is not None:\n            value = self._coerce(value)\n        return value", "response": "Coerce a cleaned value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery for items passing PyQuery args explicitly.", "response": "def all_from(cls, *args, **kwargs):\n        \"\"\"Query for items passing PyQuery args explicitly.\"\"\"\n        pq_items = cls._get_items(*args, **kwargs)\n        return [cls(item=i) for i in pq_items.items()]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef one(cls, path='', index=0):\n        url = urljoin(cls._meta.base_url, path)\n        pq_items = cls._get_items(url=url, **cls._meta._pyquery_kwargs)\n        item = pq_items.eq(index)\n        if not item:\n            raise ItemDoesNotExist(\"%s not found\" % cls.__name__)\n        return cls(item=item)", "response": "Return the first one of the item."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all(cls, path=''):\n        url = urljoin(cls._meta.base_url, path)\n        pq_items = cls._get_items(url=url, **cls._meta._pyquery_kwargs)\n        return [cls(item=i) for i in pq_items.items()]", "response": "Return all ocurrences of the item."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving customer data :param id: ID of customer :param attributes: `List` of attributes needed", "response": "def info(self, id, attributes=None):\n        \"\"\"\n        Retrieve customer data\n\n        :param id: ID of customer\n        :param attributes: `List` of attributes needed\n        \"\"\"\n        if attributes:\n            return self.call('customer.info', [id, attributes])\n        else:\n            return self.call('customer.info', [id])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, filters=None, fields=None, limit=None, page=1):\n        options = {\n            'imported': False,\n            'filters': filters or {},\n            'fields': fields or [],\n            'limit': limit or 1000,\n            'page': page,\n        }\n        return self.call('sales_order.search', [options])", "response": "Retrieve order list by options using search api. Using this result can be paginated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addcomment(self, order_increment_id,\n            status, comment=None, notify=False):\n        \"\"\"\n        Add comment to order or change its state\n\n        :param order_increment_id: Order ID\n        TODO: Identify possible values for status\n        \"\"\"\n        if comment is None:\n            comment = \"\"\n        return bool(self.call(\n                'sales_order.addComment',\n                [order_increment_id, status, comment, notify]\n            )\n        )", "response": "Add comment to order or change its state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(\n            self,\n            order_increment_id,\n            creditmemo_data=None,\n            comment=None,\n            email=False,\n            include_comment=False,\n            refund_to_store_credit_amount=None):\n        \"\"\"\n        Create new credit_memo for order\n\n        :param order_increment_id: Order Increment ID\n        :type order_increment_id: str\n        :param creditmemo_data: Sales order credit memo data (optional)\n        :type creditmemo_data: associative array as dict\n\n            {\n                'qtys': [\n                    {\n                        'order_item_id': str,   # Order item ID to be refunded\n                        'qty': int              # Items quantity to be refunded\n                    },\n                    ...\n                ],\n                'shipping_amount': float        # refund shipping amount (optional)\n                'adjustment_positive': float    # adjustment refund amount (optional)\n                'adjustment_negative': float    # adjustment fee amount (optional)\n            }\n\n        :param comment: Credit memo Comment\n        :type comment: str\n        :param email: send e-mail flag (optional)\n        :type email: bool\n        :param include_comment: include comment in e-mail flag (optional)\n        :type include_comment: bool\n        :param refund_to_store_credit_amount: amount to refund to store credit\n        :type refund_to_store_credit_amount: float\n\n        :return str, increment id of credit memo created\n        \"\"\"\n        if comment is None:\n            comment = ''\n        return self.call(\n            'sales_order_creditmemo.create', [\n                order_increment_id, creditmemo_data, comment, email, include_comment, refund_to_store_credit_amount\n            ]\n        )", "response": "Creates a new credit memo for the order"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a comment to a credit memo entry", "response": "def addcomment(self, creditmemo_increment_id,\n            comment, email=True, include_in_email=False):\n        \"\"\"\n        Add new comment to credit memo\n\n        :param creditmemo_increment_id: Credit memo increment ID\n\n        :return: bool\n        \"\"\"\n        return bool(\n            self.call(\n                'sales_order_creditmemo.addComment',\n                [creditmemo_increment_id, comment, email, include_in_email]\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, order_increment_id,\n            items_qty, comment=None, email=True, include_comment=False):\n        \"\"\"\n        Create new shipment for order\n\n        :param order_increment_id: Order Increment ID\n        :type order_increment_id: str\n        :param items_qty: items qty to ship\n        :type items_qty: associative array (order_item_id \u21d2 qty) as dict\n        :param comment: Shipment Comment\n        :type comment: str\n        :param email: send e-mail flag (optional)\n        :type email: bool\n        :param include_comment: include comment in e-mail flag (optional)\n        :type include_comment: bool\n        \"\"\"\n        if comment is None:\n            comment = ''\n        return self.call(\n            'sales_order_shipment.create', [\n                order_increment_id, items_qty, comment, email, include_comment\n            ]\n        )", "response": "Create new shipment for order_increment_id items_qty comment email include_comment"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addtrack(self, shipment_increment_id, carrier, title, track_number):\n        return self.call(\n            'sales_order_shipment.addTrack',\n            [shipment_increment_id, carrier, title, track_number]\n        )", "response": "Adds a new tracking number to the order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addcomment(self, invoice_increment_id,\n            comment=None, email=False, include_comment=False):\n        \"\"\"\n        Add comment to invoice or change its state\n\n        :param invoice_increment_id: Invoice ID\n        \"\"\"\n        if comment is None:\n            comment = \"\"\n        return bool(\n            self.call(\n                'sales_order_invoice.addComment',\n                [invoice_increment_id, comment, email, include_comment]\n            )\n        )", "response": "Add comment to invoice or change its state"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expand_url(url, protocol):\n    if protocol == 'soap':\n        ws_part = 'api/?wsdl'\n    elif protocol == 'xmlrpc':\n        ws_part = 'index.php/api/xmlrpc'\n    else:\n        ws_part = 'index.php/rest/V1'\n    return url.endswith('/') and url + ws_part or url + '/' + ws_part", "response": "Expands the given URL to a full URL by adding the SOAP and WSDL parts."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef camel_2_snake(name):\n    \"Converts CamelCase to camel_case\"\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()", "response": "Converts CamelCase to camel_case"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves one level of categories by website store view and parent category.", "response": "def level(self, website=None, store_view=None, parent_category=None):\n        \"\"\"\n        Retrieve one level of categories by website/store view/parent category\n\n        :param website: Website code or ID\n        :param store_view: storeview code or ID\n        :param parent_category: Parent Category ID\n        :return: Dictionary\n        \"\"\"\n        return self.call(\n            'catalog_category.level', [website, store_view, parent_category]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef info(self, category_id, store_view=None, attributes=None):\n        return self.call(\n            'catalog_category.info', [category_id, store_view, attributes]\n        )", "response": "Retrieve Category details\n\n        :param category_id: ID of category to retrieve\n        :param store_view: Store view ID or code\n        :param attributes: Return the fields specified\n        :return: Dictionary of data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating new category and return its ID.", "response": "def create(self, parent_id, data, store_view=None):\n        \"\"\"\n        Create new category and return its ID\n\n        :param parent_id: ID of parent\n        :param data: Data for category\n        :param store_view: Store view ID or Code\n        :return: Integer ID\n        \"\"\"\n        return int(self.call(\n            'catalog_category.create', [parent_id, data, store_view])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, category_id, data, store_view=None):\n        return bool(\n            self.call(\n                'catalog_category.update', [category_id, data, store_view]\n            )\n        )", "response": "Update Category s data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving a category in tree.", "response": "def move(self, category_id, parent_id, after_id=None):\n        \"\"\"\n        Move category in tree\n\n        :param category_id: ID of category to move\n        :param parent_id: New parent of the category\n        :param after_id: Category ID after what position it will be moved\n        :return: Boolean\n        \"\"\"\n        return bool(self.call(\n            'catalog_category.move', [category_id, parent_id, after_id])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assignproduct(self, category_id, product, position=None):\n        return bool(self.call(\n            'catalog_category.assignProduct', [category_id, product, position])\n        )", "response": "Assign a product to a category"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef updateproduct(self, category_id, product, position=None):\n        return bool(self.call(\n            'catalog_category.updateProduct', [category_id, product, position])\n        )", "response": "Update assigned product in a category"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the current store ID", "response": "def currentStore(self, store_view=None):\n        \"\"\"\n        Set/Get current store view\n\n        :param store_view: Store view ID or Code\n        :return: int\n        \"\"\"\n        args = [store_view] if store_view else []\n        return int(self.call('catalog_category_attribute.currentStore', args))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info(self, product, store_view=None, attributes=None,\n             identifierType=None):\n        \"\"\"\n        Retrieve product data\n\n        :param product: ID or SKU of product\n        :param store_view: ID or Code of store view\n        :param attributes: List of fields required\n        :param identifierType: Defines whether the product or SKU value is\n                               passed in the \"product\" parameter.\n\n        :return: `dict` of values\n        \"\"\"\n        return self.call(\n            'catalog_product.info', [\n                product, store_view, attributes, identifierType\n            ]\n        )", "response": "Retrieve product data and return it as dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate Product and return ID", "response": "def create(self, product_type, attribute_set_id, sku, data):\n        \"\"\"\n        Create Product and return ID\n\n        :param product_type: String type of product\n        :param attribute_set_id: ID of attribute set\n        :param sku: SKU of the product\n        :param data: Dictionary of data\n        :return: INT id of product created\n        \"\"\"\n        return int(self.call(\n            'catalog_product.create',\n            [product_type, attribute_set_id, sku, data]\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the information of a specific product.", "response": "def update(self, product, data, store_view=None, identifierType=None):\n        \"\"\"\n        Update product Information\n\n        :param product: ID or SKU of product\n        :param data: Dictionary of attributes to update\n        :param store_view: ID or Code of store view\n        :param identifierType: Defines whether the product or SKU value is\n                               passed in the \"product\" parameter.\n\n        :return: Boolean\n        \"\"\"\n        return bool(self.call(\n            'catalog_product.update',\n            [product, data, store_view, identifierType]\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the product s special price.", "response": "def setSpecialPrice(self, product, special_price=None,\n                        from_date=None, to_date=None, store_view=None,\n                        identifierType=None):\n        \"\"\"\n        Update product's special price\n\n        :param product: ID or SKU of product\n        :param special_price: Special Price\n        :param from_date: From date\n        :param to_date: To Date\n        :param store_view: ID or Code of Store View\n        :param identifierType: Defines whether the product or SKU value is\n                               passed in the \"product\" parameter.\n\n        :return: Boolean\n        \"\"\"\n        return bool(self.call(\n            'catalog_product.setSpecialPrice', [\n                product, special_price, from_date, to_date, store_view,\n                identifierType\n            ]\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getSpecialPrice(self, product, store_view=None, identifierType=None):\n        return self.call(\n            'catalog_product.getSpecialPrice', [\n                product, store_view, identifierType\n            ]\n        )", "response": "Get product special price data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving product image list", "response": "def list(self, product, store_view=None, identifierType=None):\n        \"\"\"\n        Retrieve product image list\n\n        :param product: ID or SKU of product\n        :param store_view: Code or ID of store view\n        :param identifierType: Defines whether the product or SKU value is\n                               passed in the \"product\" parameter.\n\n        :return: `list` of `dict`\n        \"\"\"\n        return self.call('catalog_product_attribute_media.list',\n                [product, store_view, identifierType])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info(self, product, image_file, store_view=None, identifierType=None):\n        return self.call('catalog_product_attribute_media.info',\n                [product, image_file, store_view, identifierType])", "response": "Retrieve product image data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, product, data, store_view=None, identifierType=None):\n        return self.call('catalog_product_attribute_media.create',\n                [product, data, store_view, identifierType])", "response": "Upload a new product image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a product image.", "response": "def update(self, product, img_file_name, data, store_view=None,\n               identifierType=None):\n        \"\"\"\n        Update a product image.\n\n        :param product: ID or SKU of product\n        :param img_file_name: The image file name\n            Example: '/m/y/my_image_thumb.jpg'\n        :param data: `dict` of image data (label, position, exclude, types)\n            Example: { 'label': 'description of photo',\n                'position': '1', 'exclude': '0',\n                'types': ['image', 'small_image', 'thumbnail']}\n        :param store_view: Store view ID or Code\n        :param identifierType: Defines whether the product or SKU value is\n                               passed in the \"product\" parameter.\n\n        :return: string - image file name\n        \"\"\"\n        return self.call('catalog_product_attribute_media.update',\n                [product, img_file_name, data, store_view, identifierType])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove(self, product, img_file_name, identifierType=None):\n        return self.call('catalog_product_attribute_media.remove',\n                [product, img_file_name, identifierType])", "response": "Remove a product image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list(self, link_type, product, identifierType=None):\n        return self.call('catalog_product_link.list',\n                         [link_type, product, identifierType])", "response": "Retrieve list of linked products"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassigns a product link to a linked product", "response": "def assign(self, link_type, product, linked_product, data=None,\n               identifierType=None):\n        \"\"\"\n        Assign a product link\n\n        :param link_type: type of link, one of 'cross_sell', 'up_sell',\n                'related' or 'grouped'\n        :param product: ID or SKU of product\n        :param linked_product: ID or SKU of linked product\n        :param data: dictionary of link data, (position, qty, etc.)\n                Example: { 'position': '0', 'qty': 1}\n        :param identifierType: Defines whether the product or SKU value is\n                               passed in the \"product\" parameter.\n\n        :return: boolean\n        \"\"\"\n        return bool(self.call('catalog_product_link.assign',\n                [link_type, product, linked_product, data, identifierType]))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self, link_type, product, linked_product, identifierType=None):\n        return bool(self.call('catalog_product_link.remove',\n                [link_type, product, linked_product, identifierType]))", "response": "Remove a product link in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nallowing you to create an order from a shopping cart (quote). Before placing the order, you need to add the customer, customer address, shipping and payment methods. :param quote_id: Shopping cart ID (quote ID) :param store_view: Store view ID or code :param license_id: Website license ID :return: string, result of creating order", "response": "def order(self, quote_id, store_view=None, license_id=None):\n        \"\"\"\n        Allows you to create an order from a shopping cart (quote).\n        Before placing the order, you need to add the customer, customer\n        address, shipping and payment methods.\n\n        :param quote_id: Shopping cart ID (quote ID)\n        :param store_view: Store view ID or code\n        :param license_id: Website license ID\n        :return: string, result of creating order\n        \"\"\"\n        return self.call('cart.order', [quote_id, store_view, license_id])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a coupon code to a quote.", "response": "def add(self, quote_id, coupon_code, store_view=None):\n        \"\"\"\n        Add a coupon code to a quote.\n\n        :param quote_id: Shopping cart ID (quote ID)\n        :param coupon_code, string, Coupon code\n        :param store_view: Store view ID or code\n        :return: boolean, True if the coupon code is added\n        \"\"\"\n        return bool(\n            self.call('cart_coupon.add', [quote_id, coupon_code, store_view])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addresses(self, quote_id, address_data, store_view=None):\n        return bool(\n            self.call('cart_customer.addresses',\n                [quote_id, address_data, store_view])\n        )", "response": "Add customer information into a shopping cart"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set(self, quote_id, customer_data, store_view=None):\n        return bool(\n            self.call('cart_customer.set',\n                [quote_id, customer_data, store_view])\n        )", "response": "Add customer information into a shopping cart"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef method(self, quote_id, payment_data, store_view=None):\n        return bool(\n            self.call('cart_payment.method',\n                [quote_id, payment_data, store_view])\n        )", "response": "Allows you to set a payment method for a shopping cart."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, quote_id, product_data, store_view=None):\n        return bool(\n            self.call('cart_product.add', [quote_id, product_data, store_view])\n        )", "response": "Adds one or more products to the shopping cart."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nallow you to move products from the current quote to the customer quote.", "response": "def move_to_customer_quote(self, quote_id, product_data, store_view=None):\n        \"\"\"\n        Allows you to move products from the current quote to a customer quote.\n\n        :param quote_id: Shopping cart ID (quote ID)\n        :param product_data, list of dicts of product details, example\n            [\n                {\n                    'product_id': 1,\n                    'qty': 2,\n                    'options': {\n                        'option_1': 'value_1',\n                        'option_2': 'value_2',\n                        ...\n                    },\n                    'bundle_option': {},\n                    'bundle_option_qty': {},\n                    'links': [],\n                },\n                {\n                    'sku': 'S0012345',\n                    'qty': 4,\n                },\n            ]\n        :param store_view: Store view ID or code\n        :return: boolean, True if the product is moved to customer quote\n        \"\"\"\n        return bool(\n            self.call('cart_product.moveToCustomerQuote',\n                [quote_id, product_data, store_view])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self, quote_id, product_data, store_view=None):\n        return bool(\n            self.call('cart_product.remove',\n                [quote_id, product_data, store_view])\n        )", "response": "Removes one or several products from a shopping cart."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, quote_id, product_data, store_view=None):\n        return bool(\n            self.call('cart_product.update',\n                [quote_id, product_data, store_view])\n        )", "response": "Allows you to update one or several products in the shopping cart."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nallow you to set a shipping method for a shopping cart.", "response": "def method(self, quote_id, shipping_method, store_view=None):\n        \"\"\"\n        Allows you to set a shipping method for a shopping cart (quote).\n\n        :param quote_id: Shopping cart ID (quote ID)\n        :param shipping_method, string, shipping method code\n        :param store_view: Store view ID or code\n        :return: boolean, True if the shipping method is set\n        \"\"\"\n        return bool(\n            self.call('cart_shipping.method',\n                [quote_id, shipping_method, store_view])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pack(ctx, remove_lib=True):\n    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n    with ROOT.joinpath('Pipfile.lock').open() as f:\n        lockfile = plette.Lockfile.load(f)\n\n    libdir = OUTPUT_DIR.joinpath('lib')\n\n    paths = {'purelib': libdir, 'platlib': libdir}\n    sources = lockfile.meta.sources._data\n    maker = distlib.scripts.ScriptMaker(None, None)\n\n    # Install packages from Pipfile.lock.\n    for name, package in lockfile.default._data.items():\n        if name in DONT_PACKAGE:\n            continue\n        print(f'[pack] Installing {name}')\n        package.pop('editable', None)   # Don't install things as editable.\n        package.pop('markers', None)    # Always install everything.\n        r = requirementslib.Requirement.from_pipfile(name, package)\n        wheel = passa.internals._pip.build_wheel(\n            r.as_ireq(), sources, r.hashes or None,\n        )\n        wheel.install(paths, maker, lib_only=True)\n\n    for pattern in IGNORE_LIB_PATTERNS:\n        for path in libdir.rglob(pattern):\n            print(f'[pack] Removing {path}')\n            path.unlink()\n\n    # Pack everything into ZIP.\n    zipname = OUTPUT_DIR.joinpath('passa.zip')\n    with zipfile.ZipFile(zipname, 'w') as zf:\n        _recursive_write_to_zip(zf, OUTPUT_DIR)\n        _recursive_write_to_zip(zf, STUBFILES_DIR)\n    print(f'[pack] Written archive {zipname}')\n\n    if remove_lib and libdir.exists():\n        print(f'[pack] Removing {libdir}')\n        shutil.rmtree(str(libdir))", "response": "Packs a single isolated runnable package."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a new release.", "response": "def release(ctx, type_, repo=None, prebump_to=PREBUMP):\n    \"\"\"Make a new release.\n    \"\"\"\n    unprebump(ctx)\n    if bump_release(ctx, type_=type_):\n        return\n\n    this_version = _read_version()\n    ctx.run('towncrier')\n    ctx.run(f'git commit -am \"Release {this_version}\"')\n    ctx.run(f'git tag -fa {this_version} -m \"Version {this_version}\"')\n\n    if repo:\n        if upload(ctx, repo=repo):\n            return\n    else:\n        print('[release] Missing --repo, skip uploading')\n\n    prebump(ctx, type_=prebump_to)\n\n    next_version = _read_version()\n    ctx.run(f'git commit -am \"Prebump to {next_version}\"')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a bunch of metrics for Sanic server.", "response": "def monitor(app, endpoint_type='url:1',\n            get_endpoint_fn=None,\n            latency_buckets=None,\n            mmc_period_sec=30,\n            multiprocess_mode='all'):\n    \"\"\"\n    Regiesters a bunch of metrics for Sanic server\n    (request latency, count, etc) and exposes /metrics endpoint\n    to allow Prometheus to scrape them out.\n\n    :param app: an instance of sanic.app\n    :param endpoint_type: All request related metrics have a label called\n                         'endpoint'. It can be fetched from Sanic `request`\n                          object using different strategies specified by\n                          `endpoint_type`:\n                            url - full relative path of a request URL\n                                (i.e. for http://something/a/b/c?f=x you end up\n                                having `/a/b/c` as the endpoint)\n                            url:n - like URL but with at most `n` path elements\n                                in the endpoint (i.e. with `url:1`\n                                http://something/a/b/c becomes `/a`).\n                            custom - custom endpoint fetching funciton that\n                                should be specified by `get_endpoint_fn`\n    :param get_endpoint_fn: a custom endpoint fetching function that is ignored\n                            until `endpoint_type='custom'`.\n                              get_endpoint_fn = lambda r: ...\n                            where `r` is Sanic request object\n    :param latency_buckets: an optional list of bucket sizes for latency\n                            histogram (see prometheus `Histogram` metric)\n    :param mmc_period_sec: set a period (in seconds) of how frequently memory\n                            usage related metrics are collected.\n                            Setting it to None will disable memory metrics\n                            collection.\n\n    NOTE: memory usage is not collected when when multiprocessing is enabled\n    \"\"\"\n    multiprocess_on = 'prometheus_multiproc_dir' in os.environ\n    get_endpoint = endpoint.fn_by_type(endpoint_type, get_endpoint_fn)\n    memcollect_enabled = mmc_period_sec is not None\n\n    @app.listener('before_server_start')\n    def before_start(app, loop):\n        metrics.init(\n            latency_buckets, multiprocess_mode,\n            memcollect_enabled=memcollect_enabled\n        )\n\n    @app.middleware('request')\n    async def before_request(request):\n        if request.path != '/metrics':\n            metrics.before_request_handler(request)\n\n    @app.middleware('response')\n    async def before_response(request, response):\n        if request.path != '/metrics':\n            metrics.after_request_handler(request, response, get_endpoint)\n\n    if multiprocess_on:\n        @app.listener('after_server_stop')\n        def after_stop(app, loop):\n            multiprocess.mark_process_dead(os.getpid())\n    elif memcollect_enabled:\n        @app.listener('before_server_start')\n        async def start_memcollect_task(app, loop):\n            app.memcollect_task = loop.create_task(\n                metrics.periodic_memcollect_task(\n                    mmc_period_sec,\n                    loop\n                )\n            )\n\n        @app.listener('after_server_stop')\n        async def stop_memcollect_task(app, loop):\n            app.memcollect_task.cancel()\n\n    return MonitorSetup(app, multiprocess_on)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expose_endpoint(self):\n        @self._app.route('/metrics', methods=['GET'])\n        async def expose_metrics(request):\n            return raw(self._get_metrics_data(),\n                       content_type=CONTENT_TYPE_LATEST)", "response": "Exposes the metrics endpoint on the same Sanic server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_server(self, addr='', port=8000):\n        if self._multiprocess_on:\n            raise SanicPrometheusError(\n                \"start_server can not be used when multiprocessing \" +\n                \"is turned on\")\n        start_http_server(addr=addr, port=port)", "response": "Start a new HTTP server that will serve the metrics data for the current application."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_feed(\n    inpath: str, outpath: str, view: View, config: nx.DiGraph = None\n) -> str:\n    \"\"\"Extract a subset of a GTFS zip into a new file\"\"\"\n    config = default_config() if config is None else config\n    config = remove_node_attributes(config, \"converters\")\n    feed = load_feed(inpath, view, config)\n    return write_feed_dangerously(feed, outpath)", "response": "Extract a subset of a GTFS zip into a new file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the earliest date with the most trips", "response": "def read_busiest_date(path: str) -> Tuple[datetime.date, FrozenSet[str]]:\n    \"\"\"Find the earliest date with the most trips\"\"\"\n    feed = load_raw_feed(path)\n    return _busiest_date(feed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the earliest week with the most trips", "response": "def read_busiest_week(path: str) -> Dict[datetime.date, FrozenSet[str]]:\n    \"\"\"Find the earliest week with the most trips\"\"\"\n    feed = load_raw_feed(path)\n    return _busiest_week(feed)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding all service identifiers by date", "response": "def read_service_ids_by_date(path: str) -> Dict[datetime.date, FrozenSet[str]]:\n    \"\"\"Find all service identifiers by date\"\"\"\n    feed = load_raw_feed(path)\n    return _service_ids_by_date(feed)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding dates with identical service ids in the raw feed.", "response": "def read_dates_by_service_ids(\n    path: str\n) -> Dict[FrozenSet[str], FrozenSet[datetime.date]]:\n    \"\"\"Find dates with identical service\"\"\"\n    feed = load_raw_feed(path)\n    return _dates_by_service_ids(feed)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_trip_counts_by_date(path: str) -> Dict[datetime.date, int]:\n    feed = load_raw_feed(path)\n    return _trip_counts_by_date(feed)", "response": "A useful proxy for busyness"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_feed(path: str, view: View, config: nx.DiGraph) -> Feed:\n    config_ = remove_node_attributes(config, [\"converters\", \"transformations\"])\n    feed_ = Feed(path, view={}, config=config_)\n    for filename, column_filters in view.items():\n        config_ = reroot_graph(config_, filename)\n        view_ = {filename: column_filters}\n        feed_ = Feed(feed_, view=view_, config=config_)\n    return Feed(feed_, config=config)", "response": "Load a feed from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply view filters to the given dataframe", "response": "def _filter(self, filename: str, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Apply view filters\"\"\"\n        view = self._view.get(filename)\n        if view is None:\n            return df\n\n        for col, values in view.items():\n            # If applicable, filter this dataframe by the given set of values\n            if col in df.columns:\n                df = df[df[col].isin(setwrap(values))]\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply type conversions to the given file.", "response": "def _convert_types(self, filename: str, df: pd.DataFrame) -> None:\n        \"\"\"\n        Apply type conversions\n        \"\"\"\n        if df.empty:\n            return\n\n        converters = self._config.nodes.get(filename, {}).get(\"converters\", {})\n        for col, converter in converters.items():\n            if col in df.columns:\n                df[col] = converter(df[col])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a copy of the graph rooted at the given node", "response": "def reroot_graph(G: nx.DiGraph, node: str) -> nx.DiGraph:\n    \"\"\"Return a copy of the graph rooted at the given node\"\"\"\n    G = G.copy()\n    for n, successors in list(nx.bfs_successors(G, source=node)):\n        for s in successors:\n            G.add_edge(s, n, **G.edges[n, s])\n            G.remove_edge(n, s)\n    return G"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setwrap(value: Any) -> Set[str]:\n    return set(map(str, set(flatten([value]))))", "response": "Returns a flattened and stringified set from the given object or iterable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_node_attributes(G: nx.DiGraph, attributes: Union[str, Iterable[str]]):\n    G = G.copy()\n    for _, data in G.nodes(data=True):\n        for attribute in setwrap(attributes):\n            if attribute in data:\n                del data[attribute]\n    return G", "response": "Returns a copy of the graph with the given attributes deleted from all nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncoerces a topic name into a sequence of bytes.", "response": "def _coerce_topic(topic):\n    \"\"\"\n    Ensure that the topic name is text string of a valid length.\n\n    :param topic: Kafka topic name. Valid characters are in the set ``[a-zA-Z0-9._-]``.\n    :raises ValueError: when the topic name exceeds 249 bytes\n    :raises TypeError: when the topic is not :class:`unicode` or :class:`str`\n    \"\"\"\n    if not isinstance(topic, string_types):\n        raise TypeError('topic={!r} must be text'.format(topic))\n    if not isinstance(topic, text_type):\n        topic = topic.decode('ascii')\n    if len(topic) < 1:\n        raise ValueError('invalid empty topic name')\n    if len(topic) > 249:\n        raise ValueError('topic={!r} name is too long: {} > 249'.format(\n            topic, len(topic)))\n    return topic"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _coerce_consumer_group(consumer_group):\n    if not isinstance(consumer_group, string_types):\n        raise TypeError('consumer_group={!r} must be text'.format(consumer_group))\n    if not isinstance(consumer_group, text_type):\n        consumer_group = consumer_group.decode('utf-8')\n    return consumer_group", "response": "Ensures that the consumer group is a text string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _coerce_client_id(client_id):\n    if isinstance(client_id, type(u'')):\n        client_id = client_id.encode('utf-8')\n    if not isinstance(client_id, bytes):\n        raise TypeError('{!r} is not a valid consumer group (must be'\n                        ' str or bytes)'.format(client_id))\n    return client_id", "response": "Coerce the provided client ID to a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding a Kafka short string which represents text.", "response": "def write_short_ascii(s):\n    \"\"\"\n    Encode a Kafka short string which represents text.\n\n    :param str s:\n        Text string (`str` on Python 3, `str` or `unicode` on Python 2) or\n        ``None``. The string will be ASCII-encoded.\n\n    :returns: length-prefixed `bytes`\n    :raises:\n        `struct.error` for strings longer than 32767 characters\n    \"\"\"\n    if s is None:\n        return _NULL_SHORT_STRING\n    if not isinstance(s, string_types):\n        raise TypeError('{!r} is not text'.format(s))\n    return write_short_bytes(s.encode('ascii'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencoding a Kafka short string which contains arbitrary bytes.", "response": "def write_short_bytes(b):\n    \"\"\"\n    Encode a Kafka short string which contains arbitrary bytes. A short string\n    is limited to 32767 bytes in length by the signed 16-bit length prefix.\n    A length prefix of -1 indicates ``null``, represented as ``None`` in\n    Python.\n\n    :param bytes b:\n        No more than 32767 bytes, or ``None`` for the null encoding.\n    :return: length-prefixed `bytes`\n    :raises:\n        `struct.error` for strings longer than 32767 characters\n    \"\"\"\n    if b is None:\n        return _NULL_SHORT_STRING\n    if not isinstance(b, bytes):\n        raise TypeError('{!r} is not bytes'.format(b))\n    elif len(b) > 32767:\n        raise struct.error(len(b))\n    else:\n        return struct.pack('>h', len(b)) + b"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a crontab line and returns only starting time string", "response": "def parse_cron_line(self, line):\n        \"\"\"Parses crontab line and returns only starting time string\n\n        Args:\n            line: crontab line\n        Returns:\n            Time part of cron line\n        \"\"\"\n        stripped = line.strip()\n\n        if stripped and stripped.startswith('#') is False:\n            rexres = self.rex.search(stripped)\n            if rexres:\n                return ' '.join(rexres.group(1).split())\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the broker metadata with the new metadata.", "response": "def updateMetadata(self, new):\n        \"\"\"\n        Update the metadata stored for this broker.\n\n        Future connections made to the broker will use the host and port\n        defined in the new metadata. Any existing connection is not dropped,\n        however.\n\n        :param new:\n            :clas:`afkak.common.BrokerMetadata` with the same node ID as the\n            current metadata.\n        \"\"\"\n        if self.node_id != new.node_id:\n            raise ValueError(\"Broker metadata {!r} doesn't match node_id={}\".format(new, self.node_id))\n\n        self.node_id = new.node_id\n        self.host = new.host\n        self.port = new.port"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a request to the broker via our self. proto KafkaProtocol object.", "response": "def makeRequest(self, requestId, request, expectResponse=True):\n        \"\"\"\n        Send a request to our broker via our self.proto KafkaProtocol object.\n\n        Return a deferred which will fire when the reply matching the requestId\n        comes back from the server, or, if expectResponse is False, then\n        return None instead.\n        If we are not currently connected, then we buffer the request to send\n        when the connection comes back up.\n        \"\"\"\n        if requestId in self.requests:\n            # Id is duplicate to 'in-flight' request. Reject it, as we\n            # won't be able to properly deliver the response(s)\n            # Note that this won't protect against a client calling us\n            # twice with the same ID, but first with expectResponse=False\n            # But that's pathological, and the only defense is to track\n            # all requestIds sent regardless of whether we expect to see\n            # a response, which is effectively a memory leak...\n            raise DuplicateRequestError(\n                'Reuse of requestId:{}'.format(requestId))\n\n        # If we've been told to shutdown (close() called) then fail request\n        if self._dDown:\n            return fail(ClientError('makeRequest() called after close()'))\n\n        # Ok, we are going to save/send it, create a _Request object to track\n        canceller = partial(\n            self.cancelRequest, requestId,\n            CancelledError(message=\"Request correlationId={} was cancelled\".format(requestId)))\n        tReq = _Request(requestId, request, expectResponse, canceller)\n\n        # add it to our requests dict\n        self.requests[requestId] = tReq\n\n        # Add an errback to the tReq.d to remove it from our requests dict\n        # if something goes wrong...\n        tReq.d.addErrback(self._handleRequestFailure, requestId)\n\n        # Do we have a connection over which to send the request?\n        if self.proto:\n            # Send the request\n            self._sendRequest(tReq)\n        # Have we not even started trying to connect yet? Do so now\n        elif not self.connector:\n            self._connect()\n        return tReq.d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disconnect(self):\n        if self.proto:\n            log.debug('%r Disconnecting from %r', self, self.proto.transport.getPeer())\n            self.proto.transport.loseConnection()", "response": "Disconnect from the Kafka broker."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self):\n        log.debug('%r: close() proto=%r connector=%r', self, self.proto, self.connector)\n        assert self._dDown is None\n        self._dDown = Deferred()\n\n        if self.proto is not None:\n            self.proto.transport.loseConnection()\n        elif self.connector is not None:\n            def connectingFailed(reason):\n                \"\"\"\n                Handle the failure resulting from cancellation.\n\n                :reason: a `Failure`, most likely a cancellation error (but\n                    that's not guaranteed).\n                :returns: `None` to handle the failure\n                \"\"\"\n                log.debug('%r: connection attempt has been cancelled: %r', self, reason)\n                self._dDown.callback(None)\n\n            self.connector.addErrback(connectingFailed)\n            self.connector.cancel()\n        else:\n            # Fake a cleanly closing connection\n            self._dDown.callback(None)\n\n        try:\n            raise CancelledError(message=\"Broker client for node_id={} {}:{} was closed\".format(\n                self.node_id, self.host, self.port))\n        except Exception:\n            reason = Failure()\n        # Cancel any requests\n        for correlation_id in list(self.requests.keys()):  # must copy, may del\n            self.cancelRequest(correlation_id, reason)\n        return self._dDown", "response": "Permanently close the broker client."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _connectionLost(self, reason):\n        log.info('%r: Connection closed: %r', self, reason)\n\n        # Reset our proto so we don't try to send to a down connection\n        self.proto = None\n\n        # Mark any in-flight requests as unsent.\n        for tReq in self.requests.values():\n            tReq.sent = False\n\n        if self._dDown:\n            self._dDown.callback(None)\n        elif self.requests:\n            self._connect()", "response": "Called when the protocol connection is lost."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles the response received by KafkaProtocol.", "response": "def handleResponse(self, response):\n        \"\"\"Handle the response string received by KafkaProtocol.\n\n        Ok, we've received the response from the broker. Find the requestId\n        in the message, lookup & fire the deferred with the response.\n        \"\"\"\n        requestId = KafkaCodec.get_response_correlation_id(response)\n        # Protect against responses coming back we didn't expect\n        tReq = self.requests.pop(requestId, None)\n        if tReq is None:\n            # This could happen if we've sent it, are waiting on the response\n            # when it's cancelled, causing us to remove it from self.requests\n            log.warning('Unexpected response with correlationId=%d: %r',\n                        requestId, reprlib.repr(response))\n        else:\n            tReq.d.callback(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _sendRequest(self, tReq):\n        try:\n            tReq.sent = True\n            self.proto.sendString(tReq.data)\n        except Exception as e:\n            log.exception('%r: Failed to send request %r', self, tReq)\n            del self.requests[tReq.id]\n            tReq.d.errback(e)\n        else:\n            if not tReq.expect:\n                # Once we've sent a request for which we don't expect a reply,\n                # we're done, remove it from requests, and fire the deferred\n                # with 'None', since there is no reply to be expected\n                del self.requests[tReq.id]\n                tReq.d.callback(None)", "response": "Send a single request over our protocol to the Kafka broker."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sendQueued(self):\n        for tReq in list(self.requests.values()):  # must copy, may del\n            if not tReq.sent:\n                self._sendRequest(tReq)", "response": "Send the unsent requests."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cancelRequest(self, requestId, reason=None, _=None):\n        if reason is None:\n            reason = CancelledError()\n        tReq = self.requests.pop(requestId)\n        tReq.d.errback(reason)", "response": "Cancel a request: remove it from requests, & errback the deferred.\n\n        NOTE: Attempts to cancel a request which is no longer tracked\n          (expectResponse == False and already sent, or response already\n          received) will raise KeyError"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects to the Kafka Broker returning a new broker entry.", "response": "def _connect(self):\n        \"\"\"Connect to the Kafka Broker\n\n        This routine will repeatedly try to connect to the broker (with backoff\n        according to the retry policy) until it succeeds.\n        \"\"\"\n        def tryConnect():\n            self.connector = d = maybeDeferred(connect)\n            d.addCallback(cbConnect)\n            d.addErrback(ebConnect)\n\n        def connect():\n            endpoint = self._endpointFactory(self._reactor, self.host, self.port)\n            log.debug('%r: connecting with %s', self, endpoint)\n            return endpoint.connect(self)\n\n        def cbConnect(proto):\n            log.debug('%r: connected to %r', self, proto.transport.getPeer())\n            self._failures = 0\n            self.connector = None\n            self.proto = proto\n            if self._dDown:\n                proto.transport.loseConnection()\n            else:\n                self._sendQueued()\n\n        def ebConnect(fail):\n            if self._dDown:\n                log.debug('%r: breaking connect loop due to %r after close()', self, fail)\n                return fail\n            self._failures += 1\n            delay = self._retryPolicy(self._failures)\n            log.debug('%r: failure %d to connect -> %s; retry in %.2f seconds.',\n                      self, self._failures, fail.value, delay)\n\n            self.connector = d = deferLater(self._reactor, delay, lambda: None)\n            d.addCallback(cbDelayed)\n\n        def cbDelayed(result):\n            tryConnect()\n\n        self._failures = 0\n        tryConnect()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self):\n        # Initialize all elements of parsed array to empty strings\n        parsed = ['', '', '', '', '', '', '']\n\n        if self._expression is None or len(self._expression) == 0:\n            raise MissingFieldException(\"ExpressionDescriptor.expression\")\n        else:\n            expression_parts_temp = self._expression.split()\n            expression_parts_temp_length = len(expression_parts_temp)\n            if expression_parts_temp_length < 5:\n                raise FormatException(\n                    \"Error: Expression only has {0} parts.  At least 5 part are required.\".format(\n                        expression_parts_temp_length))\n            elif expression_parts_temp_length == 5:\n                # 5 part cron so shift array past seconds element\n                for i, expression_part_temp in enumerate(expression_parts_temp):\n                    parsed[i + 1] = expression_part_temp\n            elif expression_parts_temp_length == 6:\n                # If last element ends with 4 digits, a year element has been\n                # supplied and no seconds element\n                year_regex = re.compile(r\"\\d{4}$\")\n                if year_regex.search(expression_parts_temp[5]) is not None:\n                    for i, expression_part_temp in enumerate(expression_parts_temp):\n                        parsed[i + 1] = expression_part_temp\n                else:\n                    for i, expression_part_temp in enumerate(expression_parts_temp):\n                        parsed[i] = expression_part_temp\n            elif expression_parts_temp_length == 7:\n                parsed = expression_parts_temp\n            else:\n                raise FormatException(\n                    \"Error: Expression has too many parts ({0}).  Expression must not have more than 7 parts.\".format(\n                        expression_parts_temp_length))\n        self.normalize_expression(parsed)\n\n        return parsed", "response": "Parses the cron expression string and returns a 7 part string array one part for each component of the cron expression."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_expression(self, expression_parts):\n        # convert ? to * only for DOM and DOW\n        expression_parts[3] = expression_parts[3].replace(\"?\", \"*\")\n        expression_parts[5] = expression_parts[5].replace(\"?\", \"*\")\n\n        # convert 0/, 1/ to */\n        if expression_parts[0].startswith(\"0/\"):\n            expression_parts[0] = expression_parts[\n                0].replace(\"0/\", \"*/\")  # seconds\n\n        if expression_parts[1].startswith(\"0/\"):\n            expression_parts[1] = expression_parts[\n                1].replace(\"0/\", \"*/\")  # minutes\n\n        if expression_parts[2].startswith(\"0/\"):\n            expression_parts[2] = expression_parts[\n                2].replace(\"0/\", \"*/\")  # hours\n\n        if expression_parts[3].startswith(\"1/\"):\n            expression_parts[3] = expression_parts[3].replace(\"1/\", \"*/\")  # DOM\n\n        if expression_parts[4].startswith(\"1/\"):\n            expression_parts[4] = expression_parts[\n                4].replace(\"1/\", \"*/\")  # Month\n\n        if expression_parts[5].startswith(\"1/\"):\n            expression_parts[5] = expression_parts[5].replace(\"1/\", \"*/\")  # DOW\n\n        if expression_parts[6].startswith(\"1/\"):\n            expression_parts[6] = expression_parts[6].replace(\"1/\", \"*/\")\n\n        # handle DayOfWeekStartIndexZero option where SUN=1 rather than SUN=0\n        if self._options.day_of_week_start_index_zero is False:\n            expression_parts[5] = self.decrease_days_of_week(expression_parts[5])\n\n        if expression_parts[3] == \"?\":\n            expression_parts[3] = \"*\"\n\n        # convert SUN-SAT format to 0-6 format\n        for day_number in self._cron_days:\n            expression_parts[5] = expression_parts[5].upper().replace(self._cron_days[day_number], str(day_number))\n\n        # convert JAN-DEC format to 1-12 format\n        for month_number in self._cron_months:\n            expression_parts[4] = expression_parts[4].upper().replace(\n                self._cron_months[month_number], str(month_number))\n\n        # convert 0 second to (empty)\n        if expression_parts[0] == \"0\":\n            expression_parts[0] = ''\n\n        # Loop through all parts and apply global normalization\n        length = len(expression_parts)\n        for i in range(length):\n\n            # convert all '*/1' to '*'\n            if expression_parts[i] == \"*/1\":\n                expression_parts[i] = \"*\"\n\n            \"\"\"\n            Convert Month,DOW,Year step values with a starting value (i.e. not '*') to between expressions.\n            This allows us to reuse the between expression handling for step values.\n\n            For Example:\n            - month part '3/2' will be converted to '3-12/2' (every 2 months between March and December)\n            - DOW part '3/2' will be converted to '3-6/2' (every 2 days between Tuesday and Saturday)\n            \"\"\"\n\n            if \"/\" in expression_parts[i] and any(exp in expression_parts[i] for exp in ['*', '-', ',']) is False:\n                choices = {\n                    4: \"12\",\n                    5: \"6\",\n                    6: \"9999\"\n                }\n\n                step_range_through = choices.get(i)\n\n                if step_range_through is not None:\n                    parts = expression_parts[i].split('/')\n                    expression_parts[i] = \"{0}-{1}/{2}\".format(parts[0], step_range_through, parts[1])", "response": "Normalizes the given cron expression components into consistent predictable formats."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngroup Tox environments for Travis CI builds and unit tests and linting together.", "response": "def group_envs(envlist):\n    \"\"\"Group Tox environments for Travis CI builds\n\n    Separate by Python version so that they can go in different Travis jobs:\n\n    >>> group_envs('py37-int-snappy', 'py36-int')\n    [('py36', 'int', ['py36-int']), ('py37', 'int', ['py37-int-snappy'])]\n\n    Group unit tests and linting together:\n\n    >>> group_envs(['py27-unit', 'py27-lint'])\n    [('py27', 'unit', ['py27-unit', 'py27-lint'])]\n    \"\"\"\n    groups = {}\n    for env in envlist:\n        envpy, category = env.split('-')[0:2]\n\n        if category == 'lint':\n            category = 'unit'\n\n        try:\n            groups[envpy, category].append(env)\n        except KeyError:\n            groups[envpy, category] = [env]\n\n    return sorted((envpy, category, envs) for (envpy, category), envs in groups.items())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_message(payload, key=None):\n    assert payload is None or isinstance(payload, bytes), 'payload={!r} should be bytes or None'.format(payload)\n    assert key is None or isinstance(key, bytes), 'key={!r} should be bytes or None'.format(key)\n    return Message(0, 0, key, payload)", "response": "Create a new message in the KAFKA node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_gzip_message(message_set):\n    encoded_message_set = KafkaCodec._encode_message_set(message_set)\n\n    gzipped = gzip_encode(encoded_message_set)\n    return Message(0, CODEC_GZIP, None, gzipped)", "response": "Construct a gzip - compressed message containing multiple messages\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_snappy_message(message_set):\n    encoded_message_set = KafkaCodec._encode_message_set(message_set)\n    snapped = snappy_encode(encoded_message_set)\n    return Message(0, CODEC_SNAPPY, None, snapped)", "response": "Construct a Snappy - compressed message containing multiple messages\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_message_set(requests, codec=CODEC_NONE):\n    msglist = []\n    for req in requests:\n        msglist.extend([create_message(m, key=req.key) for m in req.messages])\n\n    if codec == CODEC_NONE:\n        return msglist\n    elif codec == CODEC_GZIP:\n        return [create_gzip_message(msglist)]\n    elif codec == CODEC_SNAPPY:\n        return [create_snappy_message(msglist)]\n    else:\n        raise UnsupportedCodecError(\"Codec 0x%02x unsupported\" % codec)", "response": "Create a message set from a list of requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _encode_message_header(cls, client_id, correlation_id, request_key,\n                               api_version=0):\n        \"\"\"\n        Encode the common request envelope\n        \"\"\"\n        return (struct.pack('>hhih',\n                            request_key,          # ApiKey\n                            api_version,          # ApiVersion\n                            correlation_id,       # CorrelationId\n                            len(client_id)) +     # ClientId size\n                client_id)", "response": "Encode the message header."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencode a list of messages into a message set.", "response": "def _encode_message_set(cls, messages, offset=None):\n        \"\"\"\n        Encode a MessageSet. Unlike other arrays in the protocol,\n        MessageSets are not length-prefixed.  Format::\n\n            MessageSet => [Offset MessageSize Message]\n              Offset => int64\n              MessageSize => int32\n        \"\"\"\n        message_set = []\n        incr = 1\n        if offset is None:\n            incr = 0\n            offset = 0\n        for message in messages:\n            encoded_message = KafkaCodec._encode_message(message)\n            message_set.append(struct.pack('>qi', offset, len(encoded_message)))\n            message_set.append(encoded_message)\n            offset += incr\n        return b''.join(message_set)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes a single message.", "response": "def _encode_message(cls, message):\n        \"\"\"\n        Encode a single message.\n\n        The magic number of a message is a format version number.  The only\n        supported magic number right now is zero.  Format::\n\n            Message => Crc MagicByte Attributes Key Value\n              Crc => int32\n              MagicByte => int8\n              Attributes => int8\n              Key => bytes\n              Value => bytes\n        \"\"\"\n        if message.magic == 0:\n            msg = struct.pack('>BB', message.magic, message.attributes)\n            msg += write_int_string(message.key)\n            msg += write_int_string(message.value)\n            crc = zlib.crc32(msg) & 0xffffffff  # Ensure unsigned\n            msg = struct.pack('>I', crc) + msg\n        else:\n            raise ProtocolError(\"Unexpected magic number: %d\" % message.magic)\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes some ProduceRequest structs :param bytes client_id: :param int correlation_id: :param list payloads: list of ProduceRequest :param int acks: How \"acky\" you want the request to be: 0: immediate response 1: written to disk by the leader 2+: waits for this many number of replicas to sync -1: waits for all replicas to be in sync :param int timeout: Maximum time the server will wait for acks from replicas. This is _not_ a socket timeout.", "response": "def encode_produce_request(cls, client_id, correlation_id,\n                               payloads=None, acks=1,\n                               timeout=DEFAULT_REPLICAS_ACK_TIMEOUT_MSECS):\n        \"\"\"\n        Encode some ProduceRequest structs\n\n        :param bytes client_id:\n        :param int correlation_id:\n        :param list payloads: list of ProduceRequest\n        :param int acks:\n\n            How \"acky\" you want the request to be:\n\n            0: immediate response\n            1: written to disk by the leader\n            2+: waits for this many number of replicas to sync\n            -1: waits for all replicas to be in sync\n\n        :param int timeout:\n            Maximum time the server will wait for acks from replicas.  This is\n            _not_ a socket timeout.\n        \"\"\"\n        if not isinstance(client_id, bytes):\n            raise TypeError('client_id={!r} should be bytes'.format(client_id))\n        payloads = [] if payloads is None else payloads\n        grouped_payloads = group_by_topic_and_partition(payloads)\n\n        message = cls._encode_message_header(client_id, correlation_id,\n                                             KafkaCodec.PRODUCE_KEY)\n\n        message += struct.pack('>hii', acks, timeout, len(grouped_payloads))\n\n        for topic, topic_payloads in grouped_payloads.items():\n            message += write_short_ascii(topic)\n\n            message += struct.pack('>i', len(topic_payloads))\n            for partition, payload in topic_payloads.items():\n                msg_set = KafkaCodec._encode_message_set(payload.messages)\n                message += struct.pack('>ii', partition, len(msg_set))\n                message += msg_set\n\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding the bytes to a ProduceResponse object.", "response": "def decode_produce_response(cls, data):\n        \"\"\"\n        Decode bytes to a ProduceResponse\n\n        :param bytes data: bytes to decode\n        :returns: iterable of `afkak.common.ProduceResponse`\n        \"\"\"\n        ((correlation_id, num_topics), cur) = relative_unpack('>ii', data, 0)\n\n        for _i in range(num_topics):\n            topic, cur = read_short_ascii(data, cur)\n            ((num_partitions,), cur) = relative_unpack('>i', data, cur)\n            for _i in range(num_partitions):\n                ((partition, error, offset), cur) = relative_unpack('>ihq', data, cur)\n\n                yield ProduceResponse(topic, partition, error, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode_fetch_request(cls, client_id, correlation_id, payloads=None,\n                             max_wait_time=100, min_bytes=4096):\n        \"\"\"\n        Encodes some FetchRequest structs\n\n        :param bytes client_id:\n        :param int correlation_id:\n        :param list payloads: list of :class:`FetchRequest`\n        :param int max_wait_time: how long to block waiting on min_bytes of data\n        :param int min_bytes:\n            the minimum number of bytes to accumulate before returning the\n            response\n        \"\"\"\n        payloads = [] if payloads is None else payloads\n        grouped_payloads = group_by_topic_and_partition(payloads)\n\n        message = cls._encode_message_header(client_id, correlation_id,\n                                             KafkaCodec.FETCH_KEY)\n\n        assert isinstance(max_wait_time, int)\n\n        # -1 is the replica id\n        message += struct.pack('>iiii', -1, max_wait_time, min_bytes,\n                               len(grouped_payloads))\n\n        for topic, topic_payloads in grouped_payloads.items():\n            message += write_short_ascii(topic)\n            message += struct.pack('>i', len(topic_payloads))\n            for partition, payload in topic_payloads.items():\n                message += struct.pack('>iqi', partition, payload.offset,\n                                       payload.max_bytes)\n\n        return message", "response": "Encodes some FetchRequest structs into a byte string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecodes bytes to a FetchResponse object.", "response": "def decode_fetch_response(cls, data):\n        \"\"\"\n        Decode bytes to a FetchResponse\n\n        :param bytes data: bytes to decode\n        \"\"\"\n        ((correlation_id, num_topics), cur) = relative_unpack('>ii', data, 0)\n\n        for _i in range(num_topics):\n            (topic, cur) = read_short_ascii(data, cur)\n            ((num_partitions,), cur) = relative_unpack('>i', data, cur)\n\n            for _i in range(num_partitions):\n                ((partition, error, highwater_mark_offset), cur) = \\\n                    relative_unpack('>ihq', data, cur)\n\n                (message_set, cur) = read_int_string(data, cur)\n\n                yield FetchResponse(\n                    topic, partition, error,\n                    highwater_mark_offset,\n                    KafkaCodec._decode_message_set_iter(message_set))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes a byte string to an iterable of OffsetResponse objects.", "response": "def decode_offset_response(cls, data):\n        \"\"\"\n        Decode bytes to an :class:`OffsetResponse`\n\n        :param bytes data: bytes to decode\n        \"\"\"\n        ((correlation_id, num_topics), cur) = relative_unpack('>ii', data, 0)\n\n        for _i in range(num_topics):\n            (topic, cur) = read_short_ascii(data, cur)\n            ((num_partitions,), cur) = relative_unpack('>i', data, cur)\n\n            for _i in range(num_partitions):\n                ((partition, error, num_offsets), cur) = \\\n                    relative_unpack('>ihi', data, cur)\n\n                offsets = []\n                for _i in range(num_offsets):\n                    ((offset,), cur) = relative_unpack('>q', data, cur)\n                    offsets.append(offset)\n\n                yield OffsetResponse(topic, partition, error, tuple(offsets))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encode_metadata_request(cls, client_id, correlation_id, topics=None):\n        topics = [] if topics is None else topics\n        message = [\n            cls._encode_message_header(client_id, correlation_id,\n                                       KafkaCodec.METADATA_KEY),\n            struct.pack('>i', len(topics)),\n        ]\n        for topic in topics:\n            message.append(write_short_ascii(topic))\n        return b''.join(message)", "response": "Encode a MetadataRequest object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes the metadata response from the byte stream into a MetadataResponse object.", "response": "def decode_metadata_response(cls, data):\n        \"\"\"\n        Decode bytes to a MetadataResponse\n\n        :param bytes data: bytes to decode\n        \"\"\"\n        ((correlation_id, numbrokers), cur) = relative_unpack('>ii', data, 0)\n\n        # In testing, I saw this routine swap my machine to death when\n        # passed bad data. So, some checks are in order...\n        if numbrokers > MAX_BROKERS:\n            raise InvalidMessageError(\n                \"Brokers:{} exceeds max:{}\".format(numbrokers, MAX_BROKERS))\n\n        # Broker info\n        brokers = {}\n        for _i in range(numbrokers):\n            ((nodeId, ), cur) = relative_unpack('>i', data, cur)\n            (host, cur) = read_short_ascii(data, cur)\n            ((port,), cur) = relative_unpack('>i', data, cur)\n            brokers[nodeId] = BrokerMetadata(nodeId, nativeString(host), port)\n\n        # Topic info\n        ((num_topics,), cur) = relative_unpack('>i', data, cur)\n        topic_metadata = {}\n\n        for _i in range(num_topics):\n            ((topic_error,), cur) = relative_unpack('>h', data, cur)\n            (topic_name, cur) = read_short_ascii(data, cur)\n            ((num_partitions,), cur) = relative_unpack('>i', data, cur)\n            partition_metadata = {}\n\n            for _j in range(num_partitions):\n                ((partition_error_code, partition, leader, numReplicas),\n                 cur) = relative_unpack('>hiii', data, cur)\n\n                (replicas, cur) = relative_unpack(\n                    '>%di' % numReplicas, data, cur)\n\n                ((num_isr,), cur) = relative_unpack('>i', data, cur)\n                (isr, cur) = relative_unpack('>%di' % num_isr, data, cur)\n\n                partition_metadata[partition] = \\\n                    PartitionMetadata(\n                        topic_name, partition, partition_error_code, leader,\n                        replicas, isr)\n\n            topic_metadata[topic_name] = TopicMetadata(\n                topic_name, topic_error, partition_metadata)\n\n        return brokers, topic_metadata"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode a ConsumerMetadataRequest object.", "response": "def encode_consumermetadata_request(cls, client_id, correlation_id,\n                                        consumer_group):\n        \"\"\"\n        Encode a ConsumerMetadataRequest\n\n        :param bytes client_id: string\n        :param int correlation_id: int\n        :param str consumer_group: string\n        \"\"\"\n        message = cls._encode_message_header(client_id, correlation_id,\n                                             KafkaCodec.CONSUMER_METADATA_KEY)\n        message += write_short_ascii(consumer_group)\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecode a byte array into a ConsumerMetadataResponse object.", "response": "def decode_consumermetadata_response(cls, data):\n        \"\"\"\n        Decode bytes to a ConsumerMetadataResponse\n\n        :param bytes data: bytes to decode\n        \"\"\"\n        (correlation_id, error_code, node_id), cur = \\\n            relative_unpack('>ihi', data, 0)\n        host, cur = read_short_ascii(data, cur)\n        (port,), cur = relative_unpack('>i', data, cur)\n\n        return ConsumerMetadataResponse(\n            error_code, node_id, nativeString(host), port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencode the OffsetCommitRequest struct.", "response": "def encode_offset_commit_request(cls, client_id, correlation_id,\n                                     group, group_generation_id, consumer_id,\n                                     payloads):\n        \"\"\"\n        Encode some OffsetCommitRequest structs (v1)\n\n        :param bytes client_id: string\n        :param int correlation_id: int\n        :param str group: the consumer group to which you are committing offsets\n        :param int group_generation_id: int32, generation ID of the group\n        :param str consumer_id: string, Identifier for the consumer\n        :param list payloads: list of :class:`OffsetCommitRequest`\n        \"\"\"\n        grouped_payloads = group_by_topic_and_partition(payloads)\n\n        message = cls._encode_message_header(\n            client_id, correlation_id, KafkaCodec.OFFSET_COMMIT_KEY,\n            api_version=1,\n        )\n\n        message += write_short_ascii(group)\n        message += struct.pack('>i', group_generation_id)\n        message += write_short_ascii(consumer_id)\n        message += struct.pack('>i', len(grouped_payloads))\n\n        for topic, topic_payloads in grouped_payloads.items():\n            message += write_short_ascii(topic)\n            message += struct.pack('>i', len(topic_payloads))\n\n            for partition, payload in topic_payloads.items():\n                message += struct.pack('>iqq', partition, payload.offset,\n                                       payload.timestamp)\n                message += write_short_bytes(payload.metadata)\n\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode_offset_commit_response(cls, data):\n        ((correlation_id,), cur) = relative_unpack('>i', data, 0)\n        ((num_topics,), cur) = relative_unpack('>i', data, cur)\n\n        for _i in range(num_topics):\n            (topic, cur) = read_short_ascii(data, cur)\n            ((num_partitions,), cur) = relative_unpack('>i', data, cur)\n\n            for _i in range(num_partitions):\n                ((partition, error), cur) = relative_unpack('>ih', data, cur)\n                yield OffsetCommitResponse(topic, partition, error)", "response": "Decode bytes to an OffsetCommitResponse object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode_offset_fetch_request(cls, client_id, correlation_id,\n                                    group, payloads):\n        \"\"\"\n        Encode some OffsetFetchRequest structs\n\n        :param bytes client_id: string\n        :param int correlation_id: int\n        :param bytes group: string, the consumer group you are fetching offsets for\n        :param list payloads: list of :class:`OffsetFetchRequest`\n        \"\"\"\n        grouped_payloads = group_by_topic_and_partition(payloads)\n        message = cls._encode_message_header(\n            client_id, correlation_id, KafkaCodec.OFFSET_FETCH_KEY,\n            api_version=1)\n\n        message += write_short_ascii(group)\n        message += struct.pack('>i', len(grouped_payloads))\n\n        for topic, topic_payloads in grouped_payloads.items():\n            message += write_short_ascii(topic)\n            message += struct.pack('>i', len(topic_payloads))\n\n            for partition in topic_payloads:\n                message += struct.pack('>i', partition)\n\n        return message", "response": "Encode some OffsetFetchRequest structs that are used to fetch the offsets for a specific consumer group."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode_offset_fetch_response(cls, data):\n\n        ((correlation_id,), cur) = relative_unpack('>i', data, 0)\n        ((num_topics,), cur) = relative_unpack('>i', data, cur)\n\n        for _i in range(num_topics):\n            (topic, cur) = read_short_ascii(data, cur)\n            ((num_partitions,), cur) = relative_unpack('>i', data, cur)\n\n            for _i in range(num_partitions):\n                ((partition, offset), cur) = relative_unpack('>iq', data, cur)\n                (metadata, cur) = read_short_bytes(data, cur)\n                ((error,), cur) = relative_unpack('>h', data, cur)\n\n                yield OffsetFetchResponse(topic, partition, offset,\n                                          metadata, error)", "response": "Decode bytes to an OffsetFetchResponse object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling a response from the broker.", "response": "def stringReceived(self, response):\n        \"\"\"\n        Handle a response from the broker.\n        \"\"\"\n        correlation_id = response[0:4]\n        try:\n            d = self._pending.pop(correlation_id)\n        except KeyError:\n            self._log.warn((\n                \"Response has unknown correlation ID {correlation_id!r}.\"\n                \" Dropping connection to {peer}.\"\n            ), correlation_id=correlation_id, peer=self.transport.getPeer())\n            self.transport.loseConnection()\n        else:\n            d.callback(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connectionLost(self, reason=connectionDone):\n        self._failed = reason\n        pending, self._pending = self._pending, None\n        for d in pending.values():\n            d.errback(reason)", "response": "Mark the protocol as failed and fail all pending operations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a request to the Kafka broker.", "response": "def request(self, request):\n        \"\"\"\n        Send a request to the Kafka broker.\n\n        :param bytes request:\n            The bytes of a Kafka `RequestMessage`_ structure. It must have\n            a unique (to this connection) correlation ID.\n\n        :returns:\n            `Deferred` which will:\n\n              - Succeed with the bytes of a Kafka `ResponseMessage`_\n              - Fail when the connection terminates\n\n        .. _RequestMessage:: https://kafka.apache.org/protocol.html#protocol_messages\n\n        \"\"\"\n        if self._failed is not None:\n            return fail(self._failed)\n        correlation_id = request[4:8]\n        assert correlation_id not in self._pending\n        d = Deferred()\n        self.sendString(request)\n        self._pending[correlation_id] = d\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_messages(self, topic, key=None, msgs=()):\n        try:\n            topic = _coerce_topic(topic)\n            if key is not None and not isinstance(key, bytes):\n                raise TypeError('key={!r} must be bytes or None'.format(key))\n\n            if not msgs:\n                raise ValueError(\"msgs must be a non-empty sequence\")\n\n            msg_cnt = len(msgs)\n            byte_cnt = 0\n            for index, m in enumerate(msgs):\n                if m is None:\n                    continue\n\n                if not isinstance(m, bytes):\n                    raise TypeError('Message {} to topic {} ({!r:.100}) has type {}, but must have type {}'.format(\n                        index, topic, m, type(m).__name__, type(bytes).__name__))\n\n                byte_cnt += len(m)\n        except Exception:\n            return fail()\n\n        d = Deferred(self._cancel_send_messages)\n        self._batch_reqs.append(SendRequest(topic, key, msgs, d))\n        self._waitingMsgCount += msg_cnt\n        self._waitingByteCount += byte_cnt\n\n        # Add request to list of outstanding reqs' callback to remove\n        self._outstanding.append(d)\n        d.addBoth(self._remove_from_outstanding, d)\n        # See if we have enough messages in the batch to do a send.\n        self._check_send_batch()\n        return d", "response": "Sends a list of messages to Kafka."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping any outstanding requests and returns a Deferred which fires when fully stopped.", "response": "def stop(self):\n        \"\"\"\n        Terminate any outstanding requests.\n\n        :returns: :class:``Deferred` which fires when fully stopped.\n        \"\"\"\n        self.stopping = True\n        # Cancel any outstanding request to our client\n        if self._batch_send_d:\n            self._batch_send_d.cancel()\n        # Do we have to worry about our looping call?\n        if self.batch_every_t is not None:\n            # Stop our looping call, and wait for the deferred to be called\n            if self._sendLooper is not None:\n                self._sendLooper.stop()\n        # Make sure requests that wasn't cancelled above are now\n        self._cancel_outstanding()\n        return self._sendLooperD or succeed(None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls by the LoopingCall when the send_batch function failed.", "response": "def _send_timer_failed(self, fail):\n        \"\"\"\n        Our _send_batch() function called by the LoopingCall failed. Some\n        error probably came back from Kafka and _check_error() raised the\n        exception\n        For now, just log the failure and restart the loop\n        \"\"\"\n        log.warning('_send_timer_failed:%r: %s', fail,\n                    fail.getBriefTraceback())\n        self._sendLooperD = self._sendLooper.start(\n            self.batch_every_t, now=False)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _send_timer_stopped(self, lCall):\n        if self._sendLooper is not lCall:\n            log.warning('commitTimerStopped with wrong timer:%s not:%s',\n                        lCall, self._sendLooper)\n        else:\n            self._sendLooper = None\n            self._sendLooperD = None", "response": "Called when a timer is stopped."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _next_partition(self, topic, key=None):\n        # check if the client has metadata for the topic\n        while self.client.metadata_error_for_topic(topic):\n            # client doesn't have good metadata for topic. ask to fetch...\n            # check if we have request attempts left\n            if self._req_attempts >= self._max_attempts:\n                # No, no attempts left, so raise the error\n                _check_error(self.client.metadata_error_for_topic(topic))\n            yield self.client.load_metadata_for_topics(topic)\n            if not self.client.metadata_error_for_topic(topic):\n                break\n            self._req_attempts += 1\n            d = Deferred()\n            self.client.reactor.callLater(\n                self._retry_interval, d.callback, True)\n            self._retry_interval *= self.RETRY_INTERVAL_FACTOR\n            yield d\n\n        # Ok, should be safe to get the partitions now...\n        partitions = self.client.topic_partitions[topic]\n        # Do we have a partitioner for this topic already?\n        if topic not in self.partitioners:\n            # No, create a new paritioner for topic, partitions\n            self.partitioners[topic] = \\\n                self.partitioner_class(topic, partitions)\n        # Lookup the next partition\n        partition = self.partitioners[topic].partition(key, partitions)\n        returnValue(partition)", "response": "Get the next partition to which to publish for the given topic."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _send_requests(self, parts_results, requests):\n        # We use these dictionaries to be able to combine all the messages\n        # destined to the same topic/partition into one request\n        # the messages & deferreds, both by topic+partition\n        reqsByTopicPart = defaultdict(list)\n        payloadsByTopicPart = defaultdict(list)\n        deferredsByTopicPart = defaultdict(list)\n\n        # We now have a list of (succeeded/failed, partition/None) tuples\n        # for the partition lookups we did on each message group, zipped with\n        # the requests\n        for (success, part_or_failure), req in zip(parts_results, requests):\n            if req.deferred.called:\n                # Submitter cancelled the request while we were waiting for\n                # the topic/partition, skip it\n                continue\n            if not success:\n                # We failed to get a partition for this request, errback to the\n                # caller with the failure. Maybe this should retry? However,\n                # since this failure is likely to affect an entire Topic, there\n                # should be no issues with ordering of messages within a\n                # partition of a topic getting out of order. Let the caller\n                # retry the particular request if they like, or they could\n                # cancel all their outstanding requests in\n                req.deferred.errback(part_or_failure)\n                continue\n            # Ok, we now have a partition for this request, we can add the\n            # request for this topic/partition to reqsByTopicPart, and the\n            # caller's deferred to deferredsByTopicPart\n            topicPart = TopicAndPartition(req.topic, part_or_failure)\n            reqsByTopicPart[topicPart].append(req)\n            deferredsByTopicPart[topicPart].append(req.deferred)\n\n        # Build list of payloads grouped by topic/partition\n        # That is, we bundle all the messages destined for a given\n        # topic/partition, even if they were submitted by different\n        # requests into a single 'payload', and then we submit all the\n        # payloads as a list to the client for sending to the various\n        # brokers. The finest granularity of success/failure is at the\n        # payload (topic/partition) level.\n        payloads = []\n        for (topic, partition), reqs in reqsByTopicPart.items():\n            msgSet = create_message_set(reqs, self.codec)\n            req = ProduceRequest(topic, partition, msgSet)\n            topicPart = TopicAndPartition(topic, partition)\n            payloads.append(req)\n            payloadsByTopicPart[topicPart] = req\n        # Make sure we have some payloads to send\n        if not payloads:\n            return\n        # send the request\n        d = self.client.send_produce_request(\n            payloads, acks=self.req_acks, timeout=self.ack_timeout,\n            fail_on_error=False)\n        self._req_attempts += 1\n        # add our handlers\n        d.addBoth(self._handle_send_response, payloadsByTopicPart,\n                  deferredsByTopicPart)\n        return d", "response": "Send the requests to the specified topic and partition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _complete_batch_send(self, resp):\n        self._batch_send_d = None\n        self._req_attempts = 0\n        self._retry_interval = self._init_retry_interval\n        if isinstance(resp, Failure) and not resp.check(tid_CancelledError,\n                                                        CancelledError):\n            log.error(\"Failure detected in _complete_batch_send: %r\\n%r\",\n                      resp, resp.getTraceback())\n        return", "response": "Complete the processing of our current batch send operation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if we have enough messages to send", "response": "def _check_send_batch(self, result=None):\n        \"\"\"Check if we have enough messages/bytes to send\n        Since this can be called from the callback chain, we\n        pass through our first (non-self) arg\n        \"\"\"\n        if (\n            (self.batch_every_n and self.batch_every_n <= self._waitingMsgCount) or\n            (self.batch_every_b and self.batch_every_b <= self._waitingByteCount)\n        ):\n            self._send_batch()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send_batch(self):\n        # We can be triggered by the LoopingCall, and have nothing to send...\n        # Or, we've got SendRequest(s) to send, but are still processing the\n        # previous batch...\n        if (not self._batch_reqs) or self._batch_send_d:\n            return\n\n        # Save a local copy, and clear the global list & metrics\n        requests, self._batch_reqs = self._batch_reqs, []\n        self._waitingByteCount = 0\n        self._waitingMsgCount = 0\n\n        # Iterate over them, fetching the partition for each message batch\n        d_list = []\n        for req in requests:\n            # For each request, we get the topic & key and use that to lookup\n            # the next partition on which we should produce\n            d_list.append(self._next_partition(req.topic, req.key))\n        d = self._batch_send_d = Deferred()\n        # Since DeferredList doesn't propagate cancel() calls to deferreds it\n        # might be waiting on for a result, we need to use this structure,\n        # rather than just using the DeferredList directly\n        d.addCallback(lambda r: DeferredList(d_list, consumeErrors=True))\n        d.addCallback(self._send_requests, requests)\n        # Once we finish fully processing the current batch, clear the\n        # _batch_send_d and check if any more requests piled up when we\n        # were busy.\n        d.addBoth(self._complete_batch_send)\n        d.addBoth(self._check_send_batch)\n        # Fire off the callback to start processing...\n        d.callback(None)", "response": "Send the messages in the current batch and return the result."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _cancel_send_messages(self, d):\n        # Is the request in question in an unsent batch?\n        for req in self._batch_reqs:\n            if req.deferred == d:\n                # Found the request, remove it and return.\n                msgs = req.messages\n                self._waitingMsgCount -= len(msgs)\n                for m in (_m for _m in msgs if _m is not None):\n                    self._waitingByteCount -= len(m)\n                # This _should_ be safe as we abort the iteration upon removal\n                self._batch_reqs.remove(req)\n                d.errback(CancelledError(request_sent=False))\n                return\n\n        # If it wasn't found in the unsent batch. We just rely on the\n        # downstream processing of the request to check if the deferred\n        # has been called and skip further processing for this request\n        # Errback the deferred with whether or not we sent the request\n        # to Kafka already\n        d.errback(\n            CancelledError(request_sent=(self._batch_send_d is not None)))\n        return", "response": "Cancel a send_messages request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_send_response(self, result, payloadsByTopicPart,\n                              deferredsByTopicPart):\n        \"\"\"Handle the response from our client to our send_produce_request\n\n        This is a bit complex. Failures can happen in a few ways:\n\n          1. The client sent an empty list, False, None or some similar thing\n             as the result, but we were expecting real responses.\n          2. The client had a failure before it even tried sending any requests\n             to any brokers.\n\n               a. Kafka error: See if we can retry the whole request\n               b. Non-kafka: Figure it's a programming error, fail all deferreds\n\n          3. The client sent all the requests (it's all or none) to the brokers\n             but one or more request failed (timed out before receiving a\n             response, or the brokerclient threw some sort of exception on send\n             In this case, the client throws FailedPayloadsError, and attaches\n             the responses (NOTE: some can have errors!), and the payloads\n             where the send itself failed to the exception.\n          4. The client sent all the requests, all responses were received, but\n             the Kafka broker indicated an error with servicing the request on\n             some of the responses.\n        \"\"\"\n\n        def _deliver_result(d_list, result=None):\n            \"\"\"Possibly callback each deferred in a list with single result\"\"\"\n            for d in d_list:\n                if not isinstance(d, Deferred):\n                    # nested list...\n                    _deliver_result(d, result)\n                else:\n                    # We check d.called since the request could have been\n                    # cancelled while we waited for the response\n                    if not d.called:\n                        d.callback(result)\n\n        def _do_retry(payloads):\n            # We use 'fail_on_error=False' because we want our client to\n            # process every response that comes back from the brokers so\n            # we can determine which requests were successful, and which\n            # failed for retry\n            d = self.client.send_produce_request(\n                payloads, acks=self.req_acks, timeout=self.ack_timeout,\n                fail_on_error=False)\n            self._req_attempts += 1\n            # add our handlers\n            d.addBoth(self._handle_send_response, payloadsByTopicPart,\n                      deferredsByTopicPart)\n            return d\n\n        def _cancel_retry(failure, dc):\n            # Cancel the retry callLater and pass-thru the failure\n            dc.cancel()\n            # cancel all the top-level deferreds associated with the request\n            _deliver_result(deferredsByTopicPart.values(), failure)\n            return failure\n\n        def _check_retry_payloads(failed_payloads_with_errs):\n            \"\"\"Check our retry count and retry after a delay or errback\n\n            If we have more retries to try, create a deferred that will fire\n            with the result of delayed retry. If not, errback the remaining\n            deferreds with failure\n\n            Params:\n            failed_payloads - list of (payload, failure) tuples\n            \"\"\"\n            # Do we have retries left?\n            if self._req_attempts >= self._max_attempts:\n                # No, no retries left, fail each failed_payload with its\n                # associated failure\n                for p, f in failed_payloads_with_errs:\n                    t_and_p = TopicAndPartition(p.topic, p.partition)\n                    _deliver_result(deferredsByTopicPart[t_and_p], f)\n                return\n            # Retries remain!  Schedule one...\n            d = Deferred()\n            dc = self.client.reactor.callLater(\n                self._retry_interval, d.callback, [p for p, f in\n                                                   failed_payloads])\n            self._retry_interval *= self.RETRY_INTERVAL_FACTOR\n            # Cancel the callLater when request is cancelled before it fires\n            d.addErrback(_cancel_retry, dc)\n\n            # Reset the topic metadata for all topics which had failed_requests\n            # where the failures were of the kind UnknownTopicOrPartitionError\n            # or NotLeaderForPartitionError, since those indicate our client's\n            # metadata is out of date.\n            reset_topics = set()\n            for payload, e in failed_payloads:\n                if (isinstance(e, NotLeaderForPartitionError) or\n                        isinstance(e, UnknownTopicOrPartitionError)):\n                    reset_topics.add(payload.topic)\n            if reset_topics:\n                self.client.reset_topic_metadata(*reset_topics)\n\n            d.addCallback(_do_retry)\n            return d\n\n        # The payloads we need to retry, if we still can..\n        failed_payloads = []\n        # In the case we are sending requests without requiring acks, the\n        # brokerclient will immediately callback() the deferred upon send with\n        # None. In that case, we just iterate over all the deferreds in\n        # deferredsByTopicPart and callback them with None\n        # If we are expecting responses/acks, and we get an empty result, we\n        # callback with a Failure of NoResponseError\n        if not result:\n            # Success, but no results, is that what we're expecting?\n            if self.req_acks == PRODUCER_ACK_NOT_REQUIRED:\n                result = None\n            else:\n                # We got no result, but we were expecting one? Fail everything!\n                result = Failure(NoResponseError())\n            _deliver_result(deferredsByTopicPart.values(), result)\n            return\n        elif isinstance(result, Failure):\n            # Failure!  Was it total, or partial?\n            if not result.check(FailedPayloadsError):\n                # Total failure of some sort!\n                # The client was unable to send the request at all. If it's\n                # a KafkaError (probably Leader/Partition unavailable), retry\n                if result.check(KafkaError):\n                    # Yep, a kafak error. Set failed_payloads, and we'll retry\n                    # them all below. Set failure for errback to callers if we\n                    # are all out of retries\n                    failure, result = result, []  # no succesful results, retry\n                    failed_payloads = [(p, failure) for p in\n                                       payloadsByTopicPart.values()]\n                else:\n                    # Was the request cancelled?\n                    if not result.check(tid_CancelledError):\n                        # Uh Oh, programming error? Log it!\n                        log.error(\"Unexpected failure: %r in \"\n                                  \"_handle_send_response\", result)\n                    # Cancelled, or programming error, we fail the requests\n                    _deliver_result(deferredsByTopicPart.values(), result)\n                    return\n            else:\n                # FailedPayloadsError: This means that some/all of the\n                # requests to a/some brokerclients failed to send.\n                # Pull the successful responses and the failed_payloads off\n                # the exception and handle them below. Preserve the\n                # FailedPayloadsError as 'failure'\n                failure = result\n                result = failure.value.args[0]\n                failed_payloads = failure.value.args[1]\n\n        # Do we have results? Iterate over them and if the response indicates\n        # success, then callback the associated deferred. If the response\n        # indicates an error, then setup that request for retry.\n        # NOTE: In this case, each failed_payload get it's own error...\n        for res in result:\n            t_and_p = TopicAndPartition(res.topic, res.partition)\n            t_and_p_err = _check_error(res, raiseException=False)\n            if not t_and_p_err:\n                # Success for this topic/partition\n                d_list = deferredsByTopicPart[t_and_p]\n                _deliver_result(d_list, res)\n            else:\n                p = payloadsByTopicPart[t_and_p]\n                failed_payloads.append((p, t_and_p_err))\n\n        # Were there any failed requests to possibly retry?\n        if failed_payloads:\n            return _check_retry_payloads(failed_payloads)\n        return", "response": "Handle the response from our client to our send_produce_request\nCOOKIE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncancel all of our outstanding requests", "response": "def _cancel_outstanding(self):\n        \"\"\"Cancel all of our outstanding requests\"\"\"\n        for d in list(self._outstanding):\n            d.addErrback(lambda _: None)  # Eat any uncaught errors\n            d.cancel()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset_consumer_group_metadata(self, *groups):\n        groups = tuple(_coerce_consumer_group(g) for g in groups)\n        for group in groups:\n            if group in self.consumer_group_to_brokers:\n                del self.consumer_group_to_brokers[group]", "response": "Reset the cache of what broker manages the offset for a given set of consumer groups."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear all cached metadata", "response": "def reset_all_metadata(self):\n        \"\"\"Clear all cached metadata\n\n        Metadata will be re-fetched as required to satisfy requests.\n        \"\"\"\n        self.topics_to_brokers.clear()\n        self.topic_partitions.clear()\n        self.topic_errors.clear()\n        self.consumer_group_to_brokers.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if the given topic is fully replicated according to the currently known cluster metadata.", "response": "def topic_fully_replicated(self, topic):\n        \"\"\"\n        Determine if the given topic is fully replicated according to the\n        currently known cluster metadata.\n\n        .. note::\n\n            This relies on cached cluster metadata. You may call\n            :meth:`load_metadata_for_topics()` first to refresh this cache.\n\n        :param str topic: Topic name\n\n        :returns:\n            A boolean indicating that:\n\n            1. The number of partitions in the topic is non-zero.\n            2. For each partition, all replicas are in the in-sync replica\n               (ISR) set.\n        :rtype: :class:`bool`\n        \"\"\"\n        topic = _coerce_topic(topic)\n        if topic not in self.topic_partitions:\n            return False\n        if not self.topic_partitions[topic]:\n            # Don't consider an empty partition list 'fully replicated'\n            return False\n        return all(\n            self.partition_fully_replicated(TopicAndPartition(topic, p))\n            for p in self.topic_partitions[topic]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_metadata_for_topics(self, *topics):\n        topics = tuple(_coerce_topic(t) for t in topics)\n        log.debug(\"%r: load_metadata_for_topics(%s)\", self, ', '.join(repr(t) for t in topics))\n        fetch_all_metadata = not topics\n\n        # create the request\n        requestId = self._next_id()\n        request = KafkaCodec.encode_metadata_request(self._clientIdBytes,\n                                                     requestId, topics)\n\n        # Callbacks for the request deferred...\n        def _handleMetadataResponse(response):\n            # Decode the response\n            brokers, topics = KafkaCodec.decode_metadata_response(response)\n            log.debug(\"%r: got metadata brokers=%r topics=%r\", self, brokers, topics)\n\n            # If we fetched the metadata for all topics, then store away the\n            # received metadata for diagnostics.\n            if fetch_all_metadata:\n                self._brokers = brokers\n                self._topics = topics\n\n            # Iff we were fetching for all topics, and we got at least one\n            # broker back, then remove brokers when we update our brokers\n            ok_to_remove = (fetch_all_metadata and len(brokers))\n            # Take the metadata we got back, update our self.clients, and\n            # if needed disconnect or connect from/to old/new brokers\n            self._update_brokers(brokers.values(), remove=ok_to_remove)\n\n            # Now loop through all the topics/partitions in the response\n            # and setup our cache/data-structures\n            for topic, topic_metadata in topics.items():\n                _, topic_error, partitions = topic_metadata\n                self.reset_topic_metadata(topic)\n                self.topic_errors[topic] = topic_error\n                if not partitions:\n                    log.warning('No partitions for %s, Err:%d',\n                                topic, topic_error)\n                    continue\n\n                self.topic_partitions[topic] = []\n                for partition, meta in partitions.items():\n                    self.topic_partitions[topic].append(partition)\n                    topic_part = TopicAndPartition(topic, partition)\n                    self.partition_meta[topic_part] = meta\n                    if meta.leader == -1:\n                        log.warning('No leader for topic %s partition %s',\n                                    topic, partition)\n                        self.topics_to_brokers[topic_part] = None\n                    else:\n                        self.topics_to_brokers[\n                            topic_part] = brokers[meta.leader]\n                self.topic_partitions[topic] = sorted(\n                    self.topic_partitions[topic])\n            return True\n\n        def _handleMetadataErr(err):\n            # This should maybe do more cleanup?\n            if err.check(t_CancelledError, CancelledError):\n                # Eat the error\n                # XXX Shouldn't this return False? The success branch\n                # returns True.\n                return None\n            log.error(\"Failed to retrieve metadata:%s\", err)\n            raise KafkaUnavailableError(\n                \"Unable to load metadata from configured \"\n                \"hosts: {!r}\".format(err))\n\n        # Send the request, add the handlers\n        d = self._send_broker_unaware_request(requestId, request)\n        d.addCallbacks(_handleMetadataResponse, _handleMetadataErr)\n        return d", "response": "Discover topic metadata and brokers and topics and return the metadata for that topic."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_consumer_metadata_for_group(self, group):\n        group = _coerce_consumer_group(group)\n        log.debug(\"%r: load_consumer_metadata_for_group(%r)\", self, group)\n\n        # If we are already loading the metadata for this group, then\n        # just return the outstanding deferred\n        if group in self.coordinator_fetches:\n            d = defer.Deferred()\n            self.coordinator_fetches[group][1].append(d)\n            return d\n\n        # No outstanding request, create a new one\n        requestId = self._next_id()\n        request = KafkaCodec.encode_consumermetadata_request(\n            self._clientIdBytes, requestId, group)\n\n        # Callbacks for the request deferred...\n        def _handleConsumerMetadataResponse(response_bytes):\n            # Decode the response (returns ConsumerMetadataResponse)\n            response = KafkaCodec.decode_consumermetadata_response(response_bytes)\n            log.debug(\"%r: load_consumer_metadata_for_group(%r) -> %r\", self, group, response)\n            if response.error:\n                raise BrokerResponseError.errnos.get(response.error, UnknownError)(response)\n\n            bm = BrokerMetadata(response.node_id, response.host, response.port)\n            self.consumer_group_to_brokers[group] = bm\n            self._update_brokers([bm])\n            return True\n\n        def _handleConsumerMetadataErr(err):\n            log.error(\"Failed to retrieve consumer metadata for group %r\", group,\n                      exc_info=(err.type, err.value, err.getTracebackObject()))\n            # Clear any stored value for the group's coordinator\n            self.reset_consumer_group_metadata(group)\n            # FIXME: This exception should chain from err.\n            raise ConsumerCoordinatorNotAvailableError(\n                \"Coordinator for group {!r} not available\".format(group),\n            )\n\n        def _propagate(result):\n            [_, ds] = self.coordinator_fetches.pop(group, None)\n            for d in ds:\n                d.callback(result)\n\n        # Send the request, add the handlers\n        request_d = self._send_broker_unaware_request(requestId, request)\n        d = defer.Deferred()\n        # Save the deferred under the fetches for this group\n        self.coordinator_fetches[group] = (request_d, [d])\n        request_d.addCallback(_handleConsumerMetadataResponse)\n        request_d.addErrback(_handleConsumerMetadataErr)\n        request_d.addBoth(_propagate)\n        return d", "response": "Load the consumer metadata for the specified group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a ProduceRequest to the broker.", "response": "def send_produce_request(self, payloads=None, acks=1,\n                             timeout=DEFAULT_REPLICAS_ACK_MSECS,\n                             fail_on_error=True, callback=None):\n        \"\"\"\n        Encode and send some ProduceRequests\n\n        ProduceRequests will be grouped by (topic, partition) and then\n        sent to a specific broker. Output is a list of responses in the\n        same order as the list of payloads specified\n\n        Parameters\n        ----------\n        payloads:\n            list of ProduceRequest\n        acks:\n            How many Kafka broker replicas need to write before\n            the leader replies with a response\n        timeout:\n            How long the server has to receive the acks from the\n            replicas before returning an error.\n        fail_on_error:\n            boolean, should we raise an Exception if we encounter an API error?\n        callback:\n            function, instead of returning the ProduceResponse,\n            first pass it through this function\n\n        Return\n        ------\n        a deferred which callbacks with a list of ProduceResponse\n\n        Raises\n        ------\n        FailedPayloadsError, LeaderUnavailableError, PartitionUnavailableError\n        \"\"\"\n\n        encoder = partial(\n            KafkaCodec.encode_produce_request,\n            acks=acks,\n            timeout=timeout)\n\n        if acks == 0:\n            decoder = None\n        else:\n            decoder = KafkaCodec.decode_produce_response\n\n        resps = yield self._send_broker_aware_request(\n            payloads, encoder, decoder)\n\n        returnValue(self._handle_responses(resps, fail_on_error, callback))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend FetchRequest to all brokers.", "response": "def send_fetch_request(self, payloads=None, fail_on_error=True,\n                           callback=None,\n                           max_wait_time=DEFAULT_FETCH_SERVER_WAIT_MSECS,\n                           min_bytes=DEFAULT_FETCH_MIN_BYTES):\n        \"\"\"\n        Encode and send a FetchRequest\n\n        Payloads are grouped by topic and partition so they can be pipelined\n        to the same brokers.\n\n        Raises\n        ======\n        FailedPayloadsError, LeaderUnavailableError, PartitionUnavailableError\n        \"\"\"\n        if (max_wait_time / 1000) > (self.timeout - 0.1):\n            raise ValueError(\n                \"%r: max_wait_time: %d must be less than client.timeout by \"\n                \"at least 100 milliseconds.\", self, max_wait_time)\n\n        encoder = partial(KafkaCodec.encode_fetch_request,\n                          max_wait_time=max_wait_time,\n                          min_bytes=min_bytes)\n\n        # resps is a list of FetchResponse() objects, each of which can hold\n        # 1-n messages.\n        resps = yield self._send_broker_aware_request(\n            payloads, encoder,\n            KafkaCodec.decode_fetch_response)\n\n        returnValue(self._handle_responses(resps, fail_on_error, callback))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_offset_fetch_request(self, group, payloads=None,\n                                  fail_on_error=True, callback=None):\n        \"\"\"\n        Takes a group (string) and list of OffsetFetchRequest and returns\n        a list of OffsetFetchResponse objects\n        \"\"\"\n        encoder = partial(KafkaCodec.encode_offset_fetch_request,\n                          group=group)\n        decoder = KafkaCodec.decode_offset_fetch_response\n        resps = yield self._send_broker_aware_request(\n            payloads, encoder, decoder, consumer_group=group)\n\n        returnValue(self._handle_responses(\n            resps, fail_on_error, callback, group))", "response": "Sends an OffsetFetchRequest to the broker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a list of OffsetCommitRequest objects to the Kafka broker for the given consumer group.", "response": "def send_offset_commit_request(self, group, payloads=None,\n                                   fail_on_error=True, callback=None,\n                                   group_generation_id=-1,\n                                   consumer_id=''):\n        \"\"\"Send a list of OffsetCommitRequests to the Kafka broker for the\n        given consumer group.\n\n        Args:\n          group (str): The consumer group to which to commit the offsets\n          payloads ([OffsetCommitRequest]): List of topic, partition, offsets\n            to commit.\n          fail_on_error (bool): Whether to raise an exception if a response\n            from the Kafka broker indicates an error\n          callback (callable): a function to call with each of the responses\n            before returning the returned value to the caller.\n          group_generation_id (int): Must currently always be -1\n          consumer_id (str): Must currently always be empty string\n        Returns:\n          [OffsetCommitResponse]: List of OffsetCommitResponse objects.\n          Will raise KafkaError for failed requests if fail_on_error is True\n        \"\"\"\n        group = _coerce_consumer_group(group)\n        encoder = partial(KafkaCodec.encode_offset_commit_request,\n                          group=group, group_generation_id=group_generation_id,\n                          consumer_id=consumer_id)\n        decoder = KafkaCodec.decode_offset_commit_response\n        resps = yield self._send_broker_aware_request(\n            payloads, encoder, decoder, consumer_group=group)\n\n        returnValue(self._handle_responses(\n            resps, fail_on_error, callback, group))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_brokerclient(self, node_id):\n        if self._closing:\n            raise ClientError(\"Cannot get broker client for node_id={}: {} has been closed\".format(node_id, self))\n        if node_id not in self.clients:\n            broker_metadata = self._brokers[node_id]\n            log.debug(\"%r: creating client for %s\", self, broker_metadata)\n            self.clients[node_id] = _KafkaBrokerClient(\n                self.reactor, self._endpoint_factory,\n                broker_metadata, self.clientId, self._retry_policy,\n            )\n        return self.clients[node_id]", "response": "Get a broker client."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _close_brokerclients(self, clients):\n        def _log_close_failure(failure, brokerclient):\n            log.debug(\n                'BrokerClient: %s close result: %s: %s', brokerclient,\n                failure.type.__name__, failure.getErrorMessage())\n\n        def _clean_close_dlist(result, close_dlist):\n            # If there aren't any other outstanding closings going on, then\n            # close_dlist == self.close_dlist, and we can reset it.\n            if close_dlist == self.close_dlist:\n                self.close_dlist = None\n\n        if not self.close_dlist:\n            dList = []\n        else:\n            log.debug(\"%r: _close_brokerclients has nested deferredlist: %r\",\n                      self, self.close_dlist)\n            dList = [self.close_dlist]\n        for brokerClient in clients:\n            log.debug(\"Calling close on: %r\", brokerClient)\n            d = brokerClient.close().addErrback(_log_close_failure, brokerClient)\n            dList.append(d)\n        self.close_dlist = DeferredList(dList)\n        self.close_dlist.addBoth(_clean_close_dlist, self.close_dlist)", "response": "Close the given broker clients."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_brokers(self, brokers, remove=False):\n        log.debug(\"%r: _update_brokers(%r, remove=%r)\",\n                  self, brokers, remove)\n        brokers_by_id = {bm.node_id: bm for bm in brokers}\n        self._brokers.update(brokers_by_id)\n\n        # Update the metadata of broker clients that already exist.\n        for node_id, broker_meta in brokers_by_id.items():\n            if node_id not in self.clients:\n                continue\n            self.clients[node_id].updateMetadata(broker_meta)\n\n        # Remove any clients for brokers which no longer exist.\n        if remove:\n            to_close = [\n                self.clients.pop(node_id)\n                for node_id in set(self.clients) - set(brokers_by_id)\n            ]\n\n            if to_close:\n                self._close_brokerclients(to_close)", "response": "Update our self. brokers and self. clients based on brokers in received metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_leader_for_partition(self, topic, partition):\n\n        key = TopicAndPartition(topic, partition)\n        # reload metadata whether the partition is not available\n        # or has no leader (broker is None)\n        if self.topics_to_brokers.get(key) is None:\n            yield self.load_metadata_for_topics(topic)\n\n        if key not in self.topics_to_brokers:\n            raise PartitionUnavailableError(\"%s not available\" % str(key))\n\n        returnValue(self.topics_to_brokers[key])", "response": "Get the leader for a topic and partition."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_coordinator_for_group(self, consumer_group):\n        if self.consumer_group_to_brokers.get(consumer_group) is None:\n            yield self.load_consumer_metadata_for_group(consumer_group)\n\n        returnValue(self.consumer_group_to_brokers.get(consumer_group))", "response": "Returns the broker for a given consumer group"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_request_to_broker(self, broker, requestId, request, **kwArgs):\n        def _timeout_request(broker, requestId):\n            \"\"\"The time we allotted for the request expired, cancel it.\"\"\"\n            try:\n                # FIXME: This should be done by calling .cancel() on the Deferred\n                # returned by the broker client.\n                broker.cancelRequest(requestId, reason=RequestTimedOutError(\n                    'Request: {} cancelled due to timeout'.format(requestId)))\n            except KeyError:  # pragma: no cover This should never happen...\n                log.exception('ERROR: Failed to find key for timed-out '\n                              'request. Broker: %r Req: %d',\n                              broker, requestId)\n                raise\n            if self._disconnect_on_timeout:\n                broker.disconnect()\n\n        def _alert_blocked_reactor(timeout, start):\n            \"\"\"Complain if this timer didn't fire before the timeout elapsed\"\"\"\n            now = self.reactor.seconds()\n            if now >= (start + timeout):\n                log.warning('Reactor was starved for %r seconds', now - start)\n\n        def _cancel_timeout(result, dc):\n            \"\"\"Request completed/cancelled, cancel the timeout delayedCall.\"\"\"\n            if dc.active():\n                dc.cancel()\n            return result\n\n        # Make the request to the specified broker\n        log.debug('_mrtb: sending request: %d to broker: %r',\n                  requestId, broker)\n        d = broker.makeRequest(requestId, request, **kwArgs)\n        # Set a delayedCall to fire if we don't get a reply in time\n        dc = self.reactor.callLater(\n            self.timeout, _timeout_request, broker, requestId)\n        # Set a delayedCall to complain if the reactor has been blocked\n        rc = self.reactor.callLater(\n            (self.timeout * 0.9), _alert_blocked_reactor, self.timeout,\n            self.reactor.seconds())\n        # Setup a callback on the request deferred to cancel both callLater\n        d.addBoth(_cancel_timeout, dc)\n        d.addBoth(_cancel_timeout, rc)\n        return d", "response": "Send a request to the specified broker."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a broker - agnostic request to all known brokers.", "response": "def _send_broker_unaware_request(self, requestId, request):\n        \"\"\"\n        Attempt to send a broker-agnostic request to one of the known brokers:\n\n        1. Try each connected broker (in random order)\n        2. Try each known but unconnected broker (in random order)\n        3. Try each of the bootstrap hosts (in random order)\n\n        :param bytes request:\n            The bytes of a Kafka `RequestMessage`_ structure. It must have\n            a unique (to this connection) correlation ID.\n\n        :returns: API response message for *request*\n        :rtype: Deferred[bytes]\n\n        :raises:\n            `KafkaUnavailableError` when making the request of all known hosts\n            has failed.\n        \"\"\"\n        node_ids = list(self._brokers.keys())\n        # Randomly shuffle the brokers to distribute the load\n        random.shuffle(node_ids)\n\n        # Prioritize connected brokers\n        def connected(node_id):\n            try:\n                return self.clients[node_id].connected()\n            except KeyError:\n                return False\n\n        node_ids.sort(reverse=True, key=connected)\n\n        for node_id in node_ids:\n            broker = self._get_brokerclient(node_id)\n            try:\n                log.debug('_sbur: sending request %d to broker %r', requestId, broker)\n                d = self._make_request_to_broker(broker, requestId, request)\n                resp = yield d\n                returnValue(resp)\n            except KafkaError as e:\n                log.warning((\n                    \"Will try next server after request with correlationId=%d\"\n                    \" failed against server %s:%i. Error: %s\"\n                ), requestId, broker.host, broker.port, e)\n\n        # The request was not handled, likely because no broker metadata has\n        # loaded yet (or all broker connections have failed). Fall back to\n        # boostrapping.\n        returnValue((yield self._send_bootstrap_request(request)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a request to all configured hosts and return the response.", "response": "def _send_bootstrap_request(self, request):\n        \"\"\"Make a request using an ephemeral broker connection\n\n        This routine is used to make broker-unaware requests to get the initial\n        cluster metadata. It cycles through the configured hosts, trying to\n        connect and send the request to each in turn. This temporary connection\n        is closed once a response is received.\n\n        Note that most Kafka APIs require requests be sent to a specific\n        broker. This method will only function for broker-agnostic requests\n        like:\n\n          * `Metadata <https://kafka.apache.org/protocol.html#The_Messages_Metadata>`_\n          * `FindCoordinator <https://kafka.apache.org/protocol.html#The_Messages_FindCoordinator>`_\n\n        :param bytes request:\n            The bytes of a Kafka `RequestMessage`_ structure. It must have\n            a unique (to this connection) correlation ID.\n\n        :returns: API response message for *request*\n        :rtype: Deferred[bytes]\n\n        :raises:\n            - `KafkaUnavailableError` when making the request of all known hosts\n               has failed.\n            - `twisted.internet.defer.TimeoutError` when connecting or making\n               a request exceeds the timeout.\n        \"\"\"\n        hostports = list(self._bootstrap_hosts)\n        random.shuffle(hostports)\n        for host, port in hostports:\n            ep = self._endpoint_factory(self.reactor, host, port)\n            try:\n                protocol = yield ep.connect(_bootstrapFactory)\n            except Exception as e:\n                log.debug(\"%s: bootstrap connect to %s:%s -> %s\", self, host, port, e)\n                continue\n\n            try:\n                response = yield protocol.request(request).addTimeout(self.timeout, self.reactor)\n            except Exception:\n                log.debug(\"%s: bootstrap request to %s:%s failed\", self, host, port, exc_info=True)\n            else:\n                returnValue(response)\n            finally:\n                protocol.transport.loseConnection()\n\n        raise KafkaUnavailableError(\"Failed to bootstrap from hosts {}\".format(hostports))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _send_broker_aware_request(self, payloads, encoder_fn, decode_fn,\n                                   consumer_group=None):\n        \"\"\"\n        Group a list of request payloads by topic+partition and send them to\n        the leader broker for that partition using the supplied encode/decode\n        functions\n\n        Params\n        ======\n        payloads: list of object-like entities with a topic and\n                  partition attribute. payloads must be grouped by\n                  (topic, partition) tuples.\n        encode_fn: a method to encode the list of payloads to a request body,\n                   must accept client_id, correlation_id, and payloads as\n                   keyword arguments\n        decode_fn: a method to decode a response body into response objects.\n                   The response objects must be object-like and have topic\n                   and partition attributes\n        consumer_group: [string], optional. Indicates the request should be\n                   directed to the Offset Coordinator for the specified\n                   consumer_group.\n\n        Return\n        ======\n        deferred yielding a list of response objects in the same order\n        as the supplied payloads, or None if decode_fn is None.\n\n        Raises\n        ======\n        FailedPayloadsError, LeaderUnavailableError, PartitionUnavailableError,\n\n        \"\"\"\n\n        # Calling this without payloads is nonsensical\n        if not payloads:\n            raise ValueError(\"Payloads parameter is empty\")\n\n        # Group the requests by topic+partition\n        original_keys = []\n        payloads_by_broker = collections.defaultdict(list)\n\n        # Go through all the payloads, lookup the leader/coordinator for that\n        # payload's topic/partition or consumer group. If there's no\n        # leader/coordinator (broker), raise. For each broker, keep\n        # a list of the payloads to be sent to it. Also, for each payload in\n        # the list of payloads, make a corresponding list (original_keys) with\n        # the topic/partition in the same order, so we can lookup the returned\n        # result(s) by that topic/partition key in the set of returned results\n        # and return them in a list the same order the payloads were supplied\n        for payload in payloads:\n            # get leader/coordinator, depending on consumer_group\n            if consumer_group is None:\n                leader = yield self._get_leader_for_partition(\n                    payload.topic, payload.partition)\n                if leader is None:\n                    raise LeaderUnavailableError(\n                        \"Leader not available for topic %s partition %s\" %\n                        (payload.topic, payload.partition))\n            else:\n                leader = yield self._get_coordinator_for_group(consumer_group)\n                if leader is None:\n                    raise ConsumerCoordinatorNotAvailableError(\n                        \"Coordinator not available for group: %s\" %\n                        (consumer_group))\n\n            payloads_by_broker[leader].append(payload)\n            original_keys.append((payload.topic, payload.partition))\n\n        # Accumulate the responses in a dictionary\n        acc = {}\n\n        # The kafka server doesn't send replies to produce requests\n        # with acks=0. In that case, our decode_fn will be\n        # None, and we need to let the brokerclient know not\n        # to expect a reply. makeRequest() returns a deferred\n        # regardless, but in the expectResponse=False case, it will\n        # fire as soon as the request is sent, and it can errBack()\n        # due to being cancelled prior to the broker being able to\n        # send the request.\n        expectResponse = decode_fn is not None\n\n        # keep a list of payloads that were failed to be sent to brokers\n        failed_payloads = []\n\n        # Keep track of outstanding requests in a list of deferreds\n        inFlight = []\n        # and the payloads that go along with them\n        payloadsList = []\n        # For each broker, send the list of request payloads,\n        for broker_meta, payloads in payloads_by_broker.items():\n            broker = self._get_brokerclient(broker_meta.node_id)\n            requestId = self._next_id()\n            request = encoder_fn(client_id=self._clientIdBytes,\n                                 correlation_id=requestId, payloads=payloads)\n\n            # Make the request\n            d = self._make_request_to_broker(broker, requestId, request,\n                                             expectResponse=expectResponse)\n            inFlight.append(d)\n            payloadsList.append(payloads)\n\n        # Wait for all the responses to come back, or the requests to fail\n        results = yield DeferredList(inFlight, consumeErrors=True)\n        # We now have a list of (succeeded, response/Failure) tuples. Check 'em\n        for (success, response), payloads in zip(results, payloadsList):\n            if not success:\n                # The brokerclient deferred was errback()'d:\n                #   The send failed, or this request was cancelled (by timeout)\n                log.debug(\"%r: request:%r to broker failed: %r\", self,\n                          payloads, response)\n                failed_payloads.extend([(p, response) for p in payloads])\n                continue\n            if not expectResponse:\n                continue\n            # Successful request/response. Decode it and store by topic/part\n            for response in decode_fn(response):\n                acc[(response.topic, response.partition)] = response\n\n        # Order the accumulated responses by the original key order\n        # Note that this scheme will throw away responses which we did\n        # not request.  See test_send_fetch_request, where the response\n        # includes an error, but for a topic/part we didn't request.\n        # Since that topic/partition isn't in original_keys, we don't pass\n        # it back from here and it doesn't error out.\n        # If any of the payloads failed, fail\n        responses = [acc[k] for k in original_keys if k in acc] if acc else []\n        if failed_payloads:\n            self.reset_all_metadata()\n            raise FailedPayloadsError(responses, failed_payloads)\n\n        returnValue(responses)", "response": "Send a request to the broker for the specified topic + partition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_description(expression, options=None):\n    descripter = ExpressionDescriptor(expression, options)\n    return descripter.get_description(DescriptionTypeEnum.FULL)", "response": "Generates a human readable string for the Cron Expression\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a human readable string for the Cron Expression", "response": "def get_description(self, description_type=DescriptionTypeEnum.FULL):\n        \"\"\"Generates a human readable string for the Cron Expression\n\n        Args:\n            description_type: Which part(s) of the expression to describe\n        Returns:\n            The cron expression description\n        Raises:\n            Exception: if throw_exception_on_parse_error is True\n\n        \"\"\"\n        try:\n            if self._parsed is False:\n                parser = ExpressionParser(self._expression, self._options)\n                self._expression_parts = parser.parse()\n                self._parsed = True\n\n            choices = {\n                DescriptionTypeEnum.FULL: self.get_full_description,\n                DescriptionTypeEnum.TIMEOFDAY: self.get_time_of_day_description,\n                DescriptionTypeEnum.HOURS: self.get_hours_description,\n                DescriptionTypeEnum.MINUTES: self.get_minutes_description,\n                DescriptionTypeEnum.SECONDS: self.get_seconds_description,\n                DescriptionTypeEnum.DAYOFMONTH: self.get_day_of_month_description,\n                DescriptionTypeEnum.MONTH: self.get_month_description,\n                DescriptionTypeEnum.DAYOFWEEK: self.get_day_of_week_description,\n                DescriptionTypeEnum.YEAR: self.get_year_description,\n            }\n\n            description = choices.get(description_type, self.get_seconds_description)()\n\n        except Exception as ex:\n            if self._options.throw_exception_on_parse_error:\n                raise\n            else:\n                description = str(ex)\n        return description"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the FULL description of the current entry in the cron expression", "response": "def get_full_description(self):\n        \"\"\"Generates the FULL description\n\n        Returns:\n            The FULL description\n        Raises:\n            FormatException: if formating fails and throw_exception_on_parse_error is True\n\n        \"\"\"\n\n        try:\n            time_segment = self.get_time_of_day_description()\n            day_of_month_desc = self.get_day_of_month_description()\n            month_desc = self.get_month_description()\n            day_of_week_desc = self.get_day_of_week_description()\n            year_desc = self.get_year_description()\n\n            description = \"{0}{1}{2}{3}{4}\".format(\n                time_segment,\n                day_of_month_desc,\n                day_of_week_desc,\n                month_desc,\n                year_desc)\n\n            description = self.transform_verbosity(\n                description, self._options.verbose)\n            description = self.transform_case(\n                description,\n                self._options.casing_type)\n        except Exception:\n            description = _(\n                \"An error occured when generating the expression description.  Check the cron expression syntax.\")\n            if self._options.throw_exception_on_parse_error:\n                raise FormatException(description)\n\n        return description"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a description for only the TIMEOFDAY portion of the expression.", "response": "def get_time_of_day_description(self):\n        \"\"\"Generates a description for only the TIMEOFDAY portion of the expression\n\n        Returns:\n            The TIMEOFDAY description\n\n        \"\"\"\n        seconds_expression = self._expression_parts[0]\n        minute_expression = self._expression_parts[1]\n        hour_expression = self._expression_parts[2]\n\n        description = StringBuilder()\n\n        # handle special cases first\n        if any(exp in minute_expression for exp in self._special_characters) is False and \\\n            any(exp in hour_expression for exp in self._special_characters) is False and \\\n                any(exp in seconds_expression for exp in self._special_characters) is False:\n            # specific time of day (i.e. 10 14)\n            description.append(_(\"At \"))\n            description.append(\n                self.format_time(\n                    hour_expression,\n                    minute_expression,\n                    seconds_expression))\n        elif \"-\" in minute_expression and \\\n            \",\" not in minute_expression and \\\n                any(exp in hour_expression for exp in self._special_characters) is False:\n            # minute range in single hour (i.e. 0-10 11)\n            minute_parts = minute_expression.split('-')\n            description.append(_(\"Every minute between {0} and {1}\").format(\n                self.format_time(hour_expression, minute_parts[0]), self.format_time(hour_expression, minute_parts[1])))\n        elif \",\" in hour_expression and \"-\" not in hour_expression and \\\n                any(exp in minute_expression for exp in self._special_characters) is False:\n            # hours list with single minute (o.e. 30 6,14,16)\n            hour_parts = hour_expression.split(',')\n            description.append(_(\"At\"))\n            for i, hour_part in enumerate(hour_parts):\n                description.append(\" \")\n                description.append(\n                    self.format_time(hour_part, minute_expression))\n\n                if i < (len(hour_parts) - 2):\n                    description.append(\",\")\n\n                if i == len(hour_parts) - 2:\n                    description.append(_(\" and\"))\n        else:\n            # default time description\n            seconds_description = self.get_seconds_description()\n            minutes_description = self.get_minutes_description()\n            hours_description = self.get_hours_description()\n\n            description.append(seconds_description)\n\n            if description:\n                description.append(\", \")\n\n            description.append(minutes_description)\n\n            if description:\n                description.append(\", \")\n\n            description.append(hours_description)\n        return str(description)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_seconds_description(self):\n\n        return self.get_segment_description(\n            self._expression_parts[0],\n            _(\"every second\"),\n            lambda s: s,\n            lambda s: _(\"every {0} seconds\").format(s),\n            lambda s: _(\"seconds {0} through {1} past the minute\"),\n            lambda s: _(\"at {0} seconds past the minute\")\n        )", "response": "Generates a description for only the SECONDS portion of the expression\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_minutes_description(self):\n\n        return self.get_segment_description(\n            self._expression_parts[1],\n            _(\"every minute\"),\n            lambda s: s,\n            lambda s: _(\"every {0} minutes\").format(s),\n            lambda s: _(\"minutes {0} through {1} past the hour\"),\n            lambda s: '' if s == \"0\" else _(\"at {0} minutes past the hour\")\n        )", "response": "Generates a description for only the MINUTE portion of the expression\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_hours_description(self):\n        expression = self._expression_parts[2]\n        return self.get_segment_description(\n            expression,\n            _(\"every hour\"),\n            lambda s: self.format_time(s, \"0\"),\n            lambda s: _(\"every {0} hours\").format(s),\n            lambda s: _(\"between {0} and {1}\"),\n            lambda s: _(\"at {0}\")\n        )", "response": "Generates a description for only the HOUR portion of the expression\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_day_of_week_description(self):\n\n        if self._expression_parts[5] == \"*\" and self._expression_parts[3] != \"*\":\n            # DOM is specified and DOW is * so to prevent contradiction like \"on day 1 of the month, every day\"\n            # we will not specified a DOW description.\n            return \"\"\n\n        def get_day_name(s):\n            exp = s\n            if \"#\" in s:\n                exp, useless = s.split(\"#\", 2)\n            elif \"L\" in s:\n                exp = exp.replace(\"L\", '')\n            return self.number_to_day(int(exp))\n\n        def get_format(s):\n            if \"#\" in s:\n                day_of_week_of_month = s[s.find(\"#\") + 1:]\n\n                try:\n                    day_of_week_of_month_number = int(day_of_week_of_month)\n                    choices = {\n                        1: _(\"first\"),\n                        2: _(\"second\"),\n                        3: _(\"third\"),\n                        4: _(\"forth\"),\n                        5: _(\"fifth\"),\n                    }\n                    day_of_week_of_month_description = choices.get(day_of_week_of_month_number, '')\n                except ValueError:\n                    day_of_week_of_month_description = ''\n\n                formated = \"{}{}{}\".format(_(\", on the \"),\n                                           day_of_week_of_month_description, _(\" {0} of the month\"))\n            elif \"L\" in s:\n                formated = _(\", on the last {0} of the month\")\n            else:\n                formated = _(\", only on {0}\")\n\n            return formated\n\n        return self.get_segment_description(\n            self._expression_parts[5],\n            _(\", every day\"),\n            lambda s: get_day_name(s),\n            lambda s: _(\", every {0} days of the week\").format(s),\n            lambda s: _(\", {0} through {1}\"),\n            lambda s: get_format(s)\n        )", "response": "Generates a description for only the DAYOFWEEK portion of the expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_month_description(self):\n        return self.get_segment_description(\n            self._expression_parts[4],\n            '',\n            lambda s: datetime.date(datetime.date.today().year, int(s), 1).strftime(\"%B\"),\n            lambda s: _(\", every {0} months\").format(s),\n            lambda s: _(\", {0} through {1}\"),\n            lambda s: _(\", only in {0}\")\n        )", "response": "Generates a description for only the MONTH portion of the expression\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_day_of_month_description(self):\n        expression = self._expression_parts[3]\n        expression = expression.replace(\"?\", \"*\")\n\n        if expression == \"L\":\n            description = _(\", on the last day of the month\")\n        elif expression == \"LW\" or expression == \"WL\":\n            description = _(\", on the last weekday of the month\")\n        else:\n            regex = re.compile(\"(\\\\d{1,2}W)|(W\\\\d{1,2})\")\n            if regex.match(expression):\n                m = regex.match(expression)\n                day_number = int(m.group().replace(\"W\", \"\"))\n\n                day_string = _(\"first weekday\") if day_number == 1 else _(\"weekday nearest day {0}\").format(\n                    day_number)\n                description = _(\", on the {0} of the month\").format(\n                    day_string)\n            else:\n                description = self.get_segment_description(\n                    expression,\n                    _(\", every day\"),\n                    lambda s: s,\n                    lambda s: _(\", every day\") if s == \"1\" else _(\", every {0} days\"),\n                    lambda s: _(\", between day {0} and {1} of the month\"),\n                    lambda s: _(\", on day {0} of the month\")\n                )\n\n        return description", "response": "Generates a description for only the DAYOFMONTH portion of the expression"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a description for only the YEAR portion of the expression", "response": "def get_year_description(self):\n        \"\"\"Generates a description for only the YEAR portion of the expression\n\n        Returns:\n            The YEAR description\n\n        \"\"\"\n\n        def format_year(s):\n            regex = re.compile(r\"^\\d+$\")\n            if regex.match(s):\n                year_int = int(s)\n                if year_int < 1900:\n                    return year_int\n                return datetime.date(year_int, 1, 1).strftime(\"%Y\")\n            else:\n                return s\n\n        return self.get_segment_description(\n            self._expression_parts[6],\n            '',\n            lambda s: format_year(s),\n            lambda s: _(\", every {0} years\").format(s),\n            lambda s: _(\", {0} through {1}\"),\n            lambda s: _(\", only in {0}\")\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the string representation of the current entry in the language of the item in the archive.", "response": "def get_segment_description(\n        self,\n        expression,\n        all_description,\n        get_single_item_description,\n        get_interval_description_format,\n        get_between_description_format,\n        get_description_format\n    ):\n        \"\"\"Returns segment description\n        Args:\n            expression: Segment to descript\n            all_description: *\n            get_single_item_description: 1\n            get_interval_description_format: 1/2\n            get_between_description_format: 1-2\n            get_description_format: format get_single_item_description\n        Returns:\n            segment description\n\n        \"\"\"\n        description = None\n        if expression is None or expression == '':\n            description = ''\n        elif expression == \"*\":\n            description = all_description\n        elif any(ext in expression for ext in ['/', '-', ',']) is False:\n            description = get_description_format(expression).format(\n                get_single_item_description(expression))\n        elif \"/\" in expression:\n            segments = expression.split('/')\n            description = get_interval_description_format(\n                segments[1]).format(get_single_item_description(segments[1]))\n\n            # interval contains 'between' piece (i.e. 2-59/3 )\n            if \"-\" in segments[0]:\n                between_segment_description = self.generate_between_segment_description(\n                    segments[0], get_between_description_format, get_single_item_description)\n                if not between_segment_description.startswith(\", \"):\n                    description += \", \"\n                description += between_segment_description\n            elif any(ext in segments[0] for ext in ['*', ',']) is False:\n                range_item_description = get_description_format(segments[0]).format(\n                    get_single_item_description(segments[0])\n                )\n                range_item_description = range_item_description.replace(\", \", \"\")\n\n                description += _(\", starting {0}\").format(range_item_description)\n        elif \",\" in expression:\n            segments = expression.split(',')\n\n            description_content = ''\n            for i, segment in enumerate(segments):\n                if i > 0 and len(segments) > 2:\n                    description_content += \",\"\n\n                    if i < len(segments) - 1:\n                        description_content += \" \"\n\n                if i > 0 and len(segments) > 1 and (i == len(segments) - 1 or len(segments) == 2):\n                    description_content += _(\" and \")\n\n                if \"-\" in segment:\n                    between_description = self.generate_between_segment_description(\n                        segment,\n                        lambda s: _(\", {0} through {1}\"),\n                        get_single_item_description\n                    )\n\n                    between_description = between_description.replace(\", \", \"\")\n\n                    description_content += between_description\n                else:\n                    description_content += get_single_item_description(segment)\n\n            description = get_description_format(\n                expression).format(\n                    description_content)\n        elif \"-\" in expression:\n            description = self.generate_between_segment_description(\n                expression, get_between_description_format, get_single_item_description)\n\n        return description"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate the between segment description", "response": "def generate_between_segment_description(\n            self,\n            between_expression,\n            get_between_description_format,\n            get_single_item_description\n    ):\n        \"\"\"\n        Generates the between segment description\n        :param between_expression:\n        :param get_between_description_format:\n        :param get_single_item_description:\n        :return: The between segment description\n        \"\"\"\n        description = \"\"\n        between_segments = between_expression.split('-')\n        between_segment_1_description = get_single_item_description(between_segments[0])\n        between_segment_2_description = get_single_item_description(between_segments[1])\n        between_segment_2_description = between_segment_2_description.replace(\n            \":00\", \":59\")\n\n        between_description_format = get_between_description_format(between_expression)\n        description += between_description_format.format(between_segment_1_description, between_segment_2_description)\n\n        return description"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives time parts, will contruct a formatted time description Args: hour_expression: Hours part minute_expression: Minutes part second_expression: Seconds part Returns: Formatted time description", "response": "def format_time(\n        self,\n        hour_expression,\n        minute_expression,\n        second_expression=''\n    ):\n        \"\"\"Given time parts, will contruct a formatted time description\n        Args:\n            hour_expression: Hours part\n            minute_expression: Minutes part\n            second_expression: Seconds part\n        Returns:\n            Formatted time description\n\n        \"\"\"\n        hour = int(hour_expression)\n\n        period = ''\n        if self._options.use_24hour_time_format is False:\n            period = \" PM\" if (hour >= 12) else \" AM\"\n            if hour > 12:\n                hour -= 12\n\n        minute = str(int(minute_expression))  # !FIXME WUT ???\n        second = ''\n        if second_expression is not None and second_expression:\n            second = \"{}{}\".format(\":\", str(int(second_expression)).zfill(2))\n\n        return \"{0}:{1}{2}{3}\".format(str(hour).zfill(2), minute.zfill(2), second, period)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform_verbosity(self, description, use_verbose_format):\n        if use_verbose_format is False:\n            description = description.replace(\n                _(\", every minute\"), '')\n            description = description.replace(_(\", every hour\"), '')\n            description = description.replace(_(\", every day\"), '')\n        return description", "response": "Transforms the verbosity of the expression description by stripping the verbosity from original description"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms the case of the expression description based on options", "response": "def transform_case(self, description, case_type):\n        \"\"\"Transforms the case of the expression description, based on options\n        Args:\n            description: The description to transform\n            case_type: The casing type that controls the output casing\n            second_expression: Seconds part\n        Returns:\n            The transformed description with proper casing\n\n        \"\"\"\n        if case_type == CasingTypeEnum.Sentence:\n            description = \"{}{}\".format(\n                description[0].upper(),\n                description[1:])\n        elif case_type == CasingTypeEnum.Title:\n            description = description.title()\n        else:\n            description = description.lower()\n        return description"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn localized day name by its CRON number", "response": "def number_to_day(self, day_number):\n        \"\"\"Returns localized day name by its CRON number\n\n        Args:\n            day_number: Number of a day\n        Returns:\n            Day corresponding to day_number\n        Raises:\n            IndexError: When day_number is not found\n        \"\"\"\n        return [\n            calendar.day_name[6],\n            calendar.day_name[0],\n            calendar.day_name[1],\n            calendar.day_name[2],\n            calendar.day_name[3],\n            calendar.day_name[4],\n            calendar.day_name[5]\n        ][day_number]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self, start_offset):\n        # Have we been started already, and not stopped?\n        if self._start_d is not None:\n            raise RestartError(\"Start called on already-started consumer\")\n\n        # Keep track of state for debugging\n        self._state = '[started]'\n\n        # Create and return a deferred for alerting on errors/stoppage\n        start_d = self._start_d = Deferred()\n\n        # Start a new fetch request, possibly just for the starting offset\n        self._fetch_offset = start_offset\n        self._do_fetch()\n\n        # Set up the auto-commit timer, if needed\n        if self.consumer_group and self.auto_commit_every_s:\n            self._commit_looper = LoopingCall(self._auto_commit)\n            self._commit_looper.clock = self.client.reactor\n            self._commit_looper_d = self._commit_looper.start(\n                self.auto_commit_every_s, now=False)\n            self._commit_looper_d.addCallbacks(self._commit_timer_stopped,\n                                               self._commit_timer_failed)\n        return start_d", "response": "Starts fetching messages from Kafka and deliver them to Kafka."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shutdown(self):\n        def _handle_shutdown_commit_success(result):\n            \"\"\"Handle the result of the commit attempted by shutdown\"\"\"\n            self._shutdown_d, d = None, self._shutdown_d\n            self.stop()\n            self._shuttingdown = False  # Shutdown complete\n            d.callback((self._last_processed_offset,\n                       self._last_committed_offset))\n\n        def _handle_shutdown_commit_failure(failure):\n            \"\"\"Handle failure of commit() attempted by shutdown\"\"\"\n            if failure.check(OperationInProgress):\n                failure.value.deferred.addCallback(_commit_and_stop)\n                return\n\n            self._shutdown_d, d = None, self._shutdown_d\n            self.stop()\n            self._shuttingdown = False  # Shutdown complete\n            d.errback(failure)\n\n        def _commit_and_stop(result):\n            \"\"\"Commit the current offsets (if needed) and stop the consumer\"\"\"\n            if not self.consumer_group:  # No consumer group, no committing\n                return _handle_shutdown_commit_success(None)\n\n            # Need to commit prior to stopping\n            self.commit().addCallbacks(_handle_shutdown_commit_success,\n                                       _handle_shutdown_commit_failure)\n\n        # If we're not running, return an failure\n        if self._start_d is None:\n            return fail(Failure(\n                RestopError(\"Shutdown called on non-running consumer\")))\n        # If we're called multiple times, return a failure\n        if self._shutdown_d:\n            return fail(Failure(\n                RestopError(\"Shutdown called more than once.\")))\n        # Set our _shuttingdown flag, so our _process_message routine will stop\n        # feeding new messages to the processor, and fetches won't be retried\n        self._shuttingdown = True\n        # Keep track of state for debugging\n        self._state = '[shutting down]'\n\n        # Create a deferred to track the shutdown\n        self._shutdown_d = d = Deferred()\n\n        # Are we waiting for the processor to complete? If so, when it's done,\n        # commit our offsets and stop.\n        if self._processor_d:\n            self._processor_d.addCallback(_commit_and_stop)\n        else:\n            # No need to wait for the processor, we can commit and stop now\n            _commit_and_stop(None)\n\n        # return the deferred\n        return d", "response": "Gracefully shutdown the consumer and return a deferred which will be called with a tuple of the last processed offset last committed offset and the state of the current consumer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self):\n        if self._start_d is None:\n            raise RestopError(\"Stop called on non-running consumer\")\n\n        self._stopping = True\n        # Keep track of state for debugging\n        self._state = '[stopping]'\n        # Are we waiting for a request to come back?\n        if self._request_d:\n            self._request_d.cancel()\n        # Are we working our way through a block of messages?\n        if self._msg_block_d:\n            # Need to add a cancel handler...\n            _msg_block_d, self._msg_block_d = self._msg_block_d, None\n            _msg_block_d.addErrback(lambda fail: fail.trap(CancelledError))\n            _msg_block_d.cancel()\n        # Are we waiting for the processor to complete?\n        if self._processor_d:\n            self._processor_d.cancel()\n        # Are we waiting to retry a request?\n        if self._retry_call:\n            self._retry_call.cancel()\n        # Are we waiting on a commit request?\n        if self._commit_ds:\n            while self._commit_ds:\n                d = self._commit_ds.pop()\n                d.cancel()\n        if self._commit_req:\n            self._commit_req.cancel()\n        # Are we waiting to retry a commit?\n        if self._commit_call:\n            self._commit_call.cancel()\n        # Do we have an auto-commit looping call?\n        if self._commit_looper is not None:\n            self._commit_looper.stop()\n        # Done stopping\n        self._stopping = False\n        # Keep track of state for debugging\n        self._state = '[stopped]'\n\n        # Clear and possibly callback our start() Deferred\n        self._start_d, d = None, self._start_d\n        if not d.called:\n            d.callback((self._last_processed_offset,\n                        self._last_committed_offset))\n\n        # Return the offset of the message we last processed\n        return self._last_processed_offset", "response": "Stops the consumer and returns the offset of the last processed message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef commit(self):\n        # Can't commit without a consumer_group\n        if not self.consumer_group:\n            return fail(Failure(InvalidConsumerGroupError(\n                \"Bad Group_id:{0!r}\".format(self.consumer_group))))\n        # short circuit if we are 'up to date', or haven't processed anything\n        if ((self._last_processed_offset is None) or\n                (self._last_processed_offset == self._last_committed_offset)):\n            return succeed(self._last_committed_offset)\n\n        # If we're currently processing a commit we return a failure\n        # with a deferred we'll fire when the in-progress one completes\n        if self._commit_ds:\n            d = Deferred()\n            self._commit_ds.append(d)\n            return fail(OperationInProgress(d))\n\n        # Ok, we have processed messages since our last commit attempt, and\n        # we're not currently waiting on a commit request to complete:\n        # Start a new one\n        d = Deferred()\n        self._commit_ds.append(d)\n\n        # Send the request\n        self._send_commit_request()\n\n        # Reset the commit_looper here, rather than on success to give\n        # more stability to the commit interval.\n        if self._commit_looper is not None:\n            self._commit_looper.reset()\n\n        # return the deferred\n        return d", "response": "Commits the current offset of the message we last processed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if we should start a new commit operation and commit if so retry if necessary", "response": "def _auto_commit(self, by_count=False):\n        \"\"\"Check if we should start a new commit operation and commit\"\"\"\n        # Check if we are even supposed to do any auto-committing\n        if (self._stopping or self._shuttingdown or (not self._start_d) or\n                (self._last_processed_offset is None) or\n                (not self.consumer_group) or\n                (by_count and not self.auto_commit_every_n)):\n            return\n\n        # If we're auto_committing because the timer expired, or by count and\n        # we don't have a record of our last_committed_offset, or we've\n        # processed enough messages since our last commit, then try to commit\n        if (not by_count or self._last_committed_offset is None or\n            (self._last_processed_offset - self._last_committed_offset\n             ) >= self.auto_commit_every_n):\n            if not self._commit_ds:\n                commit_d = self.commit()\n                commit_d.addErrback(self._handle_auto_commit_error)\n            else:\n                # We're waiting on the last commit to complete, so add a\n                # callback to be called when the current request completes\n                d = Deferred()\n                d.addCallback(self._retry_auto_commit, by_count)\n                self._commit_ds.append(d)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nscheduling a delayed fetch of the resource.", "response": "def _retry_fetch(self, after=None):\n        \"\"\"\n        Schedule a delayed :meth:`_do_fetch` call after a failure\n\n        :param float after:\n            The delay in seconds after which to do the retried fetch. If\n            `None`, our internal :attr:`retry_delay` is used, and adjusted by\n            :const:`REQUEST_RETRY_FACTOR`.\n        \"\"\"\n\n        # Have we been told to stop or shutdown?  Then don't actually retry.\n        if self._stopping or self._shuttingdown or self._start_d is None:\n            # Stopping, or stopped already? No more fetching.\n            return\n        if self._retry_call is None:\n            if after is None:\n                after = self.retry_delay\n                self.retry_delay = min(self.retry_delay * REQUEST_RETRY_FACTOR,\n                                       self.retry_max_delay)\n\n            self._fetch_attempt_count += 1\n            self._retry_call = self.client.reactor.callLater(\n                after, self._do_fetch)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_offset_response(self, response):\n        # Got a response, clear our outstanding request deferred\n        self._request_d = None\n\n        # Successful request, reset our retry delay, count, etc\n        self.retry_delay = self.retry_init_delay\n        self._fetch_attempt_count = 1\n\n        response = response[0]\n        if hasattr(response, 'offsets'):\n            # It's a response to an OffsetRequest\n            self._fetch_offset = response.offsets[0]\n        else:\n            # It's a response to an OffsetFetchRequest\n            # Make sure we got a valid offset back. Kafka uses -1 to indicate\n            # no committed offset was retrieved\n            if response.offset == OFFSET_NOT_COMMITTED:\n                self._fetch_offset = OFFSET_EARLIEST\n            else:\n                self._fetch_offset = response.offset + 1\n                self._last_committed_offset = response.offset\n        self._do_fetch()", "response": "Handle responses to OffsetRequest and OffsetFetchRequest since\n            they are similar enough."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling an error in fetching the offset from Kafka.", "response": "def _handle_offset_error(self, failure):\n        \"\"\"\n        Retry the offset fetch request if appropriate.\n\n        Once the :attr:`.retry_delay` reaches our :attr:`.retry_max_delay`, we\n        log a warning.  This should perhaps be extended to abort sooner on\n        certain errors.\n        \"\"\"\n        # outstanding request got errback'd, clear it\n        self._request_d = None\n\n        if self._stopping and failure.check(CancelledError):\n            # Not really an error\n            return\n        # Do we need to abort?\n        if (self.request_retry_max_attempts != 0 and\n                self._fetch_attempt_count >= self.request_retry_max_attempts):\n            log.debug(\n                \"%r: Exhausted attempts: %d fetching offset from kafka: %r\",\n                self, self.request_retry_max_attempts, failure)\n            self._start_d.errback(failure)\n            return\n        # Decide how to log this failure... If we have retried so many times\n        # we're at the retry_max_delay, then we log at warning every other time\n        # debug otherwise\n        if (self.retry_delay < self.retry_max_delay or\n                0 == (self._fetch_attempt_count % 2)):\n            log.debug(\"%r: Failure fetching offset from kafka: %r\", self,\n                      failure)\n        else:\n            # We've retried until we hit the max delay, log at warn\n            log.warning(\"%r: Still failing fetching offset from kafka: %r\",\n                        self, failure)\n        self._retry_fetch()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a commit request to the Kafka broker.", "response": "def _send_commit_request(self, retry_delay=None, attempt=None):\n        \"\"\"Send a commit request with our last_processed_offset\"\"\"\n        # If there's a _commit_call, and it's not active, clear it, it probably\n        # just called us...\n        if self._commit_call and not self._commit_call.active():\n            self._commit_call = None\n\n        # Make sure we only have one outstanding commit request at a time\n        if self._commit_req is not None:\n            raise OperationInProgress(self._commit_req)\n\n        # Handle defaults\n        if retry_delay is None:\n            retry_delay = self.retry_init_delay\n        if attempt is None:\n            attempt = 1\n\n        # Create new OffsetCommitRequest with the latest processed offset\n        commit_offset = self._last_processed_offset\n        commit_request = OffsetCommitRequest(\n            self.topic, self.partition, commit_offset,\n            TIMESTAMP_INVALID, self.commit_metadata)\n        log.debug(\"Committing off=%d grp=%s tpc=%s part=%s req=%r\",\n                  self._last_processed_offset, self.consumer_group,\n                  self.topic, self.partition, commit_request)\n\n        # Send the request, add our callbacks\n        self._commit_req = d = self.client.send_offset_commit_request(\n            self.consumer_group, [commit_request])\n\n        d.addBoth(self._clear_commit_req)\n        d.addCallbacks(\n            self._update_committed_offset, self._handle_commit_error,\n            callbackArgs=(commit_offset,),\n            errbackArgs=(retry_delay, attempt))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_commit_error(self, failure, retry_delay, attempt):\n        # Check if we are stopping and the request was cancelled\n        if self._stopping and failure.check(CancelledError):\n            # Not really an error\n            return self._deliver_commit_result(self._last_committed_offset)\n\n        # Check that the failure type is a Kafka error...this could maybe be\n        # a tighter check to determine whether a retry will succeed...\n        if not failure.check(KafkaError):\n            log.error(\"Unhandleable failure during commit attempt: %r\\n\\t%r\",\n                      failure, failure.getBriefTraceback())\n            return self._deliver_commit_result(failure)\n\n        # Do we need to abort?\n        if (self.request_retry_max_attempts != 0 and\n                attempt >= self.request_retry_max_attempts):\n            log.debug(\"%r: Exhausted attempts: %d to commit offset: %r\",\n                      self, self.request_retry_max_attempts, failure)\n            return self._deliver_commit_result(failure)\n\n        # Check the retry_delay to see if we should log at the higher level\n        # Using attempts % 2 gets us 1-warn/minute with defaults timings\n        if retry_delay < self.retry_max_delay or 0 == (attempt % 2):\n            log.debug(\"%r: Failure committing offset to kafka: %r\", self,\n                      failure)\n        else:\n            # We've retried until we hit the max delay, log alternately at warn\n            log.warning(\"%r: Still failing committing offset to kafka: %r\",\n                        self, failure)\n\n        # Schedule a delayed call to retry the commit\n        retry_delay = min(retry_delay * REQUEST_RETRY_FACTOR,\n                          self.retry_max_delay)\n        self._commit_call = self.client.reactor.callLater(\n            retry_delay, self._send_commit_request, retry_delay, attempt + 1)", "response": "Handle a commit error."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_processor_error(self, failure):\n        # Check if we're stopping/stopped and the errback of the processor\n        # deferred is just the cancelling we initiated.  If so, we skip\n        # notifying via the _start_d deferred, as it will be 'callback'd at the\n        # end of stop()\n        if not (self._stopping and failure.check(CancelledError)):\n            if self._start_d:  # Make sure we're not already stopped\n                self._start_d.errback(failure)", "response": "Handle a failure in processing a block of messages with a specific entry in the a\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles an error in a fetch request.", "response": "def _handle_fetch_error(self, failure):\n        \"\"\"A fetch request resulted in an error. Retry after our current delay\n\n        When a fetch error occurs, we check to see if the Consumer is being\n        stopped, and if so just return, trapping the CancelledError. If not, we\n        check if the Consumer has a non-zero setting for\n        :attr:`request_retry_max_attempts` and if so and we have reached that limit we\n        errback() the Consumer's start() deferred with the failure. If not, we\n        determine whether to log at debug or warning (we log at warning every\n        other retry after backing off to the max retry delay, resulting in a\n        warning message approximately once per minute with the default timings)\n        We then wait our current :attr:`retry_delay`, and retry the fetch. We\n        also increase our retry_delay by Apery's constant (1.20205) and note\n        the failed fetch by incrementing :attr:`_fetch_attempt_count`.\n\n        NOTE: this may retry forever.\n        TODO: Possibly make this differentiate based on the failure\n        \"\"\"\n        # The _request_d deferred has fired, clear it.\n        self._request_d = None\n\n        if failure.check(OffsetOutOfRangeError):\n            if self.auto_offset_reset is None:\n                self._start_d.errback(failure)\n                return\n            self._fetch_offset = self.auto_offset_reset\n\n        if self._stopping and failure.check(CancelledError):\n            # Not really an error\n            return\n        # Do we need to abort?\n        if (self.request_retry_max_attempts != 0 and\n                self._fetch_attempt_count >= self.request_retry_max_attempts):\n            log.debug(\n                \"%r: Exhausted attempts: %d fetching messages from kafka: %r\",\n                self, self.request_retry_max_attempts, failure)\n            self._start_d.errback(failure)\n            return\n\n        # Decide how to log this failure... If we have retried so many times\n        # we're at the retry_max_delay, then we log at warning every other time\n        # debug otherwise\n        if (self.retry_delay < self.retry_max_delay or\n                0 == (self._fetch_attempt_count % 2)):\n            log.debug(\"%r: Failure fetching messages from kafka: %r\", self,\n                      failure)\n        else:\n            # We've retried until we hit the max delay, log at warn\n            log.warning(\"%r: Still failing fetching messages from kafka: %r\",\n                        self, failure)\n        self._retry_fetch()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_fetch_response(self, responses):\n        # Successful fetch, reset our retry delay\n        self.retry_delay = self.retry_init_delay\n        self._fetch_attempt_count = 1\n\n        # Check to see if we are still processing the last block we fetched...\n        if self._msg_block_d:\n            # We are still working through the last block of messages...\n            # We have to wait until it's done, then process this response\n            self._msg_block_d.addCallback(\n                lambda _: self._handle_fetch_response(responses))\n            return\n\n        # No ongoing processing, great, let's get some started.\n        # Request no longer outstanding, clear the deferred tracker so we\n        # can refetch\n        self._request_d = None\n        messages = []\n        try:\n            for resp in responses:  # We should really only ever get one...\n                if resp.partition != self.partition:\n                    log.warning(\n                        \"%r: Got response with partition: %r not our own: %r\",\n                        self, resp.partition, self.partition)\n                    continue\n                # resp.messages is a KafkaCodec._decode_message_set_iter\n                # Note that 'message' here is really an OffsetAndMessage\n                for message in resp.messages:\n                    # Check for messages included which are from prior to our\n                    # desired offset: can happen due to compressed message sets\n                    if message.offset < self._fetch_offset:\n                        log.debug(\n                            'Skipping message at offset: %d, because its '\n                            'offset is less that our fetch offset: %d.',\n                            message.offset, self._fetch_offset)\n                        continue\n                    # Create a 'SourcedMessage' and add it to the messages list\n                    messages.append(\n                        SourcedMessage(\n                            message=message.message,\n                            offset=message.offset, topic=self.topic,\n                            partition=self.partition))\n                    # Update our notion of from where to fetch.\n                    self._fetch_offset = message.offset + 1\n        except ConsumerFetchSizeTooSmall:\n            # A message was too large for us to receive, given our current\n            # buffer size. Grow it until it works, or we hit our max\n            # Grow by 16x up to 1MB (could result in 16MB buf), then by 2x\n            factor = 2\n            if self.buffer_size <= 2**20:\n                factor = 16\n            if self.max_buffer_size is None:\n                # No limit, increase until we succeed or fail to alloc RAM\n                self.buffer_size *= factor\n            elif (self.max_buffer_size is not None and\n                    self.buffer_size < self.max_buffer_size):\n                # Limited, but currently below it.\n                self.buffer_size = min(\n                    self.buffer_size * factor, self.max_buffer_size)\n            else:\n                # We failed, and are already at our max. Nothing we can do but\n                # create a Failure and errback() our start() deferred\n                log.error(\"Max fetch size %d too small\", self.max_buffer_size)\n                failure = Failure(\n                    ConsumerFetchSizeTooSmall(\n                        \"Max buffer size:%d too small for message\",\n                        self.max_buffer_size))\n                self._start_d.errback(failure)\n                return\n\n            log.debug(\n                \"Next message larger than fetch size, increasing \"\n                \"to %d (~2x) and retrying\", self.buffer_size)\n\n        finally:\n            # If we were able to extract any messages, deliver them to the\n            # processor now.\n            if messages:\n                self._msg_block_d = Deferred()\n                self._process_messages(messages)\n\n        # start another fetch, if needed, but use callLater to avoid recursion\n        self._retry_fetch(0)", "response": "The callback handling the successful response from the fetch request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_messages(self, messages):\n        # Have we been told to shutdown?\n        if self._shuttingdown:\n            return\n        # Do we have any messages to process?\n        if not messages:\n            # No, we're done with this block. If we had another fetch result\n            # waiting, this callback will trigger the processing thereof.\n            if self._msg_block_d:\n                _msg_block_d, self._msg_block_d = self._msg_block_d, None\n                _msg_block_d.callback(True)\n            return\n        # Yes, we've got some messages to process.\n        # Default to processing the entire block...\n        proc_block_size = sys.maxsize\n        # Unless our auto commit_policy restricts us to process less\n        if self.auto_commit_every_n:\n            proc_block_size = self.auto_commit_every_n\n\n        # Divide messages into two lists: one to process now, and remainder\n        msgs_to_proc = messages[:proc_block_size]\n        msgs_remainder = messages[proc_block_size:]\n        # Call our processor callable and handle the possibility it returned\n        # a deferred...\n        last_offset = msgs_to_proc[-1].offset\n        self._processor_d = d = maybeDeferred(self.processor, self, msgs_to_proc)\n        log.debug('self.processor return: %r, last_offset: %r', d, last_offset)\n        # Once the processor completes, clear our _processor_d\n        d.addBoth(self._clear_processor_deferred)\n        # Record the offset of the last processed message and check autocommit\n        d.addCallback(self._update_processed_offset, last_offset)\n        # If we were stopped, cancel the processor deferred. Note, we have to\n        # do this here, in addition to in stop() because the processor func\n        # itself could have called stop(), and then when it returned, we re-set\n        # self._processor_d to the return of maybeDeferred().\n        if self._stopping or self._start_d is None:\n            d.cancel()\n        else:\n            # Setup to process the rest of our messages\n            d.addCallback(lambda _: self._process_messages(msgs_remainder))\n        # Add an error handler\n        d.addErrback(self._handle_processor_error)", "response": "Process the given message block and return the result of the processor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _do_fetch(self):\n        # Check for outstanding request.\n        if self._request_d:\n            log.debug(\"_do_fetch: Outstanding request: %r\", self._request_d)\n            return\n\n        # Cleanup our _retry_call, if we have one\n        if self._retry_call is not None:\n            if self._retry_call.active():\n                self._retry_call.cancel()\n            self._retry_call = None\n\n        # Do we know our offset yet, or do we need to figure it out?\n        if (self._fetch_offset == OFFSET_EARLIEST or\n                self._fetch_offset == OFFSET_LATEST):\n            # We need to fetch the offset for our topic/partition\n            offset_request = OffsetRequest(\n                self.topic, self.partition, self._fetch_offset, 1)\n            self._request_d = self.client.send_offset_request([offset_request])\n            self._request_d.addCallbacks(\n                self._handle_offset_response, self._handle_offset_error)\n        elif self._fetch_offset == OFFSET_COMMITTED:\n            # We need to fetch the committed offset for our topic/partition\n            # Note we use the same callbacks, as the responses are \"close\n            # enough\" for our needs here\n            if not self.consumer_group:\n                # consumer_group must be set for OFFSET_COMMITTED\n                failure = Failure(\n                    InvalidConsumerGroupError(\"Bad Group_id:{0!r}\".format(\n                        self.consumer_group)))\n                self._start_d.errback(failure)\n            request = OffsetFetchRequest(self.topic, self.partition)\n            self._request_d = self.client.send_offset_fetch_request(\n                self.consumer_group, [request])\n            self._request_d.addCallbacks(\n                self._handle_offset_response, self._handle_offset_error)\n        else:\n            # Create fetch request payload for our partition\n            request = FetchRequest(\n                self.topic, self.partition, self._fetch_offset,\n                self.buffer_size)\n            # Send request and add handlers for the response\n            self._request_d = self.client.send_fetch_request(\n                [request], max_wait_time=self.fetch_max_wait_time,\n                min_bytes=self.fetch_min_bytes)\n            # We need a temp for this because if the response is already\n            # available, _handle_fetch_response() will clear self._request_d\n            d = self._request_d\n            d.addCallback(self._handle_fetch_response)\n            d.addErrback(self._handle_fetch_error)", "response": "Send a fetch request to the Kafka cluster to get the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling an error in the commit function in the LoopingCall function.", "response": "def _commit_timer_failed(self, fail):\n        \"\"\"Handle an error in the commit() function\n\n        Our commit() function called by the LoopingCall failed. Some error\n        probably came back from Kafka and _check_error() raised the exception\n        For now, just log the failure and restart the loop\n        \"\"\"\n        log.warning(\n            '_commit_timer_failed: uncaught error %r: %s in _auto_commit',\n            fail, fail.getBriefTraceback())\n        self._commit_looper_d = self._commit_looper.start(\n            self.auto_commit_every_s, now=False)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _commit_timer_stopped(self, lCall):\n        if self._commit_looper is not lCall:\n            log.warning('_commit_timer_stopped with wrong timer:%s not:%s',\n                        lCall, self._commit_looper)\n        else:\n            log.debug('_commit_timer_stopped: %s %s', lCall,\n                      self._commit_looper)\n            self._commit_looper = None\n            self._commit_looper_d = None", "response": "Clean up our looping call..."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting a partition based on the hash of the key.", "response": "def partition(self, key, partitions):\n        \"\"\"\n        Select a partition based on the hash of the key.\n\n        :param key: Partition key\n        :type key: text string or UTF-8 `bytes` or `bytearray`\n        :param list partitions:\n            An indexed sequence of partition identifiers.\n        :returns:\n            One of the given partition identifiers. The result will be the same\n            each time the same key and partition list is passed.\n        \"\"\"\n        return partitions[(self._hash(key) & 0x7FFFFFFF) % len(partitions)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompresses the given data with the Snappy algorithm.", "response": "def snappy_encode(payload, xerial_compatible=False,\n                  xerial_blocksize=32 * 1024):\n    \"\"\"\n    Compress the given data with the Snappy algorithm.\n\n    :param bytes payload: Data to compress.\n    :param bool xerial_compatible:\n        If set then the stream is broken into length-prefixed blocks in\n        a fashion compatible with the xerial snappy library.\n\n        The format winds up being::\n\n            +-------------+------------+--------------+------------+--------------+\n            |   Header    | Block1_len | Block1 data  | BlockN len | BlockN data  |\n            |-------------+------------+--------------+------------+--------------|\n            |  16 bytes   |  BE int32  | snappy bytes |  BE int32  | snappy bytes |\n            +-------------+------------+--------------+------------+--------------+\n\n    :param int xerial_blocksize:\n        Number of bytes per chunk to independently Snappy encode. 32k is the\n        default in the xerial library.\n\n    :returns: Compressed bytes.\n    :rtype: :class:`bytes`\n    \"\"\"\n    if not has_snappy():  # FIXME This should be static, not checked every call.\n        raise NotImplementedError(\"Snappy codec is not available\")\n\n    if xerial_compatible:\n        def _chunker():\n            for i in range(0, len(payload), xerial_blocksize):\n                yield payload[i:i+xerial_blocksize]\n\n        out = BytesIO()\n        out.write(_XERIAL_HEADER)\n\n        for chunk in _chunker():\n            block = snappy.compress(chunk)\n            out.write(struct.pack('!i', len(block)))\n            out.write(block)\n\n        out.seek(0)\n        return out.read()\n\n    else:\n        return snappy.compress(payload)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_video_info(self):\n        if not hasattr(self, '_info_cache'):\n            encoding_backend = get_backend()\n            try:\n                path = os.path.abspath(self.path)\n            except AttributeError:\n                path = os.path.abspath(self.name)\n            self._info_cache = encoding_backend.get_media_info(path)\n        return self._info_cache", "response": "Returns basic information about the video as dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding a video to a specified file.", "response": "def encode(self, source_path, target_path, params):  # NOQA: C901\n        \"\"\"\n        Encodes a video to a specified file. All encoder specific options\n        are passed in using `params`.\n        \"\"\"\n        total_time = self.get_media_info(source_path)['duration']\n\n        cmds = [self.ffmpeg_path, '-i', source_path]\n        cmds.extend(self.params)\n        cmds.extend(params)\n        cmds.extend([target_path])\n\n        process = self._spawn(cmds)\n\n        buf = output = ''\n        # update progress\n        while True:\n            # any more data?\n            out = process.stderr.read(10)\n            if not out:\n                break\n\n            out = out.decode(console_encoding)\n            output += out\n            buf += out\n\n            try:\n                line, buf = buf.split('\\r', 1)\n            except ValueError:\n                continue\n\n            try:\n                time_str = RE_TIMECODE.findall(line)[0]\n            except IndexError:\n                continue\n\n            # convert progress to percent\n            time = 0\n            for part in time_str.split(':'):\n                time = 60 * time + float(part)\n\n            percent = time / total_time\n            logger.debug('yield {}%'.format(percent))\n            yield percent\n\n        if os.path.getsize(target_path) == 0:\n            raise exceptions.FFmpegError(\"File size of generated file is 0\")\n\n        # wait for process to exit\n        self._check_returncode(process)\n\n        logger.debug(output)\n        if not output:\n            raise exceptions.FFmpegError(\"No output from FFmpeg.\")\n\n        yield 100"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_media_info(self, video_path):\n        cmds = [self.ffprobe_path, '-i', video_path]\n        cmds.extend(['-print_format', 'json'])\n        cmds.extend(['-show_format', '-show_streams'])\n\n        process = self._spawn(cmds)\n        stdout, __ = self._check_returncode(process)\n\n        media_info = self._parse_media_info(stdout)\n\n        return {\n            'duration': float(media_info['format']['duration']),\n            'width': int(media_info['video'][0]['width']),\n            'height': int(media_info['video'][0]['height']),\n        }", "response": "Returns information about the given video as dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_thumbnail(self, video_path, at_time=0.5):\n        filename = os.path.basename(video_path)\n        filename, __ = os.path.splitext(filename)\n        _, image_path = tempfile.mkstemp(suffix='_{}.jpg'.format(filename))\n\n        video_duration = self.get_media_info(video_path)['duration']\n        if at_time > video_duration:\n            raise exceptions.InvalidTimeError()\n        thumbnail_time = at_time\n\n        cmds = [self.ffmpeg_path, '-i', video_path, '-vframes', '1']\n        cmds.extend(['-ss', str(thumbnail_time), '-y', image_path])\n\n        process = self._spawn(cmds)\n        self._check_returncode(process)\n\n        if not os.path.getsize(image_path):\n            # we somehow failed to generate thumbnail\n            os.unlink(image_path)\n            raise exceptions.InvalidTimeError()\n\n        return image_path", "response": "Extracts an image of a video and returns its path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a given video file into all defined formats.", "response": "def convert_video(fieldfile, force=False):\n    \"\"\"\n    Converts a given video file into all defined formats.\n    \"\"\"\n    instance = fieldfile.instance\n    field = fieldfile.field\n\n    filename = os.path.basename(fieldfile.path)\n    source_path = fieldfile.path\n\n    encoding_backend = get_backend()\n\n    for options in settings.VIDEO_ENCODING_FORMATS[encoding_backend.name]:\n        video_format, created = Format.objects.get_or_create(\n            object_id=instance.pk,\n            content_type=ContentType.objects.get_for_model(instance),\n            field_name=field.name, format=options['name'])\n\n        # do not reencode if not requested\n        if video_format.file and not force:\n            continue\n        else:\n            # set progress to 0\n            video_format.reset_progress()\n\n        # TODO do not upscale videos\n\n        _, target_path = tempfile.mkstemp(\n            suffix='_{name}.{extension}'.format(**options))\n\n        try:\n            encoding = encoding_backend.encode(\n                source_path, target_path, options['params'])\n            while encoding:\n                try:\n                    progress = next(encoding)\n                except StopIteration:\n                    break\n                video_format.update_progress(progress)\n        except VideoEncodingError:\n            # TODO handle with more care\n            video_format.delete()\n            os.remove(target_path)\n            continue\n\n        # save encoded file\n        video_format.file.save(\n            '{filename}_{name}.{extension}'.format(filename=filename,\n                                                   **options),\n            File(open(target_path, mode='rb')))\n\n        video_format.update_progress(100)  # now we are ready\n\n        # remove temporary file\n        os.remove(target_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntunes a kernel configuration in the parameter space.", "response": "def tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: dict\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: dict\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: dict\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    results = []\n    cache = {}\n\n    #scale variables in x because PSO works with velocities to visit different configurations\n    tuning_options[\"scaling\"] = True\n\n    #using this instead of get_bounds because scaling is used\n    bounds, _, _ = get_bounds_x0_eps(tuning_options)\n\n    args = (kernel_options, tuning_options, runner, results, cache)\n\n    num_particles = 20\n    maxiter = 100\n\n    #parameters needed by the Firefly Algorithm\n    B0 = 1.0\n    gamma = 1.0\n    alpha = 0.20\n\n    best_time_global = 1e20\n    best_position_global = []\n\n    # init particle swarm\n    swarm = []\n    for i in range(0, num_particles):\n        swarm.append(Firefly(bounds, args))\n\n    # compute initial intensities\n    for j in range(num_particles):\n        swarm[j].compute_intensity(_cost_func)\n\n    for c in range(maxiter):\n        if tuning_options.verbose:\n            print(\"start iteration \", c, \"best time global\", best_time_global)\n\n        # compare all to all and compute attractiveness\n        for i in range(num_particles):\n            for j in range(num_particles):\n\n                if swarm[i].intensity < swarm[j].intensity:\n                    dist = swarm[i].distance_to(swarm[j])\n                    beta = B0 * np.exp(-gamma * dist * dist)\n\n                    swarm[i].move_towards(swarm[j], beta, alpha)\n                    swarm[i].compute_intensity(_cost_func)\n\n                    # update global best if needed, actually only used for printing\n                    if swarm[i].time <= best_time_global:\n                        best_position_global = swarm[i].position\n                        best_time_global = swarm[i].time\n\n        swarm.sort(key=lambda x: x.time)\n\n    if tuning_options.verbose:\n        print('Final result:')\n        print(best_position_global)\n        print(best_time_global)\n\n    return results, runner.dev.get_environment()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn Euclidian distance between self and other Firefly", "response": "def distance_to(self, other):\n        \"\"\"Return Euclidian distance between self and other Firefly\"\"\"\n        return np.linalg.norm(self.position-other.position)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate cost function and compute intensity at this position", "response": "def compute_intensity(self, _cost_func):\n        \"\"\"Evaluate cost function and compute intensity at this position\"\"\"\n        self.evaluate(_cost_func)\n        self.intensity = 1 / self.time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove firefly towards another given beta and alpha values", "response": "def move_towards(self, other, beta, alpha):\n        \"\"\"Move firefly towards another given beta and alpha values\"\"\"\n        self.position += beta * (other.position - self.position)\n        self.position += alpha * (np.random.uniform(-0.5, 0.5, len(self.position)))\n        self.position = np.minimum(self.position, [b[1] for b in self.bounds])\n        self.position = np.maximum(self.position, [b[0] for b in self.bounds])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndefault verify function based on numpy. allclose", "response": "def _default_verify_function(instance, answer, result_host, atol, verbose):\n    \"\"\"default verify function based on numpy.allclose\"\"\"\n\n    #first check if the length is the same\n    if len(instance.arguments) != len(answer):\n        raise TypeError(\"The length of argument list and provided results do not match.\")\n    #for each element in the argument list, check if the types match\n    for i, arg in enumerate(instance.arguments):\n        if answer[i] is not None: #skip None elements in the answer list\n            if isinstance(answer[i], numpy.ndarray) and isinstance(arg, numpy.ndarray):\n                if answer[i].dtype != arg.dtype:\n                    raise TypeError(\"Element \" + str(i)\n                                    + \" of the expected results list is not of the same dtype as the kernel output: \"\n                                    + str(answer[i].dtype) + \" != \" + str(arg.dtype) + \".\")\n                if answer[i].size != arg.size:\n                    raise TypeError(\"Element \" + str(i)\n                                    + \" of the expected results list has a size different from \"\n                                    + \"the kernel argument: \"\n                                    + str(answer[i].size) + \" != \" + str(arg.size) + \".\")\n            elif isinstance(answer[i], numpy.number) and isinstance(arg, numpy.number):\n                if answer[i].dtype != arg.dtype:\n                    raise TypeError(\"Element \" + str(i)\n                                    + \" of the expected results list is not the same as the kernel output: \"\n                                    + str(answer[i].dtype) + \" != \" + str(arg.dtype) + \".\")\n            else:\n                #either answer[i] and argument have different types or answer[i] is not a numpy type\n                if not isinstance(answer[i], numpy.ndarray) or not isinstance(answer[i], numpy.number):\n                    raise TypeError(\"Element \" + str(i)\n                                    + \" of expected results list is not a numpy array or numpy scalar.\")\n                else:\n                    raise TypeError(\"Element \" + str(i)\n                                    + \" of expected results list and kernel arguments have different types.\")\n\n    def _ravel(a):\n        if hasattr(a, 'ravel') and len(a.shape) > 1:\n            return a.ravel()\n        return a\n\n    def _flatten(a):\n        if hasattr(a, 'flatten'):\n            return a.flatten()\n        return a\n\n    correct = True\n    for i, arg in enumerate(instance.arguments):\n        expected = answer[i]\n        if expected is not None:\n\n            result = _ravel(result_host[i])\n            expected = _flatten(expected)\n            output_test = numpy.allclose(expected, result, atol=atol)\n\n            if not output_test and verbose:\n                print(\"Error: \" + util.get_config_string(instance.params) + \" detected during correctness check\")\n                print(\"this error occured when checking value of the %oth kernel argument\" % (i,))\n                print(\"Printing kernel output and expected result, set verbose=False to suppress this debug print\")\n                numpy.set_printoptions(edgeitems=50)\n                print(\"Kernel output:\")\n                print(result)\n                print(\"Expected:\")\n                print(expected)\n            correct = correct and output_test\n\n    if not correct:\n        logging.debug('correctness check has found a correctness issue')\n        raise Exception(\"Error: \" + util.get_config_string(instance.params) + \" failed correctness check\")\n\n    return correct"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef benchmark(self, func, gpu_args, instance, times, verbose):\n        logging.debug('benchmark ' + instance.name)\n        logging.debug('thread block dimensions x,y,z=%d,%d,%d', *instance.threads)\n        logging.debug('grid dimensions x,y,z=%d,%d,%d', *instance.grid)\n\n        time = None\n        try:\n            time = self.dev.benchmark(func, gpu_args, instance.threads, instance.grid, times)\n        except Exception as e:\n            #some launches may fail because too many registers are required\n            #to run the kernel given the current thread block size\n            #the desired behavior is to simply skip over this configuration\n            #and proceed to try the next one\n            skippable_exceptions = [\"too many resources requested for launch\", \"OUT_OF_RESOURCES\", \"INVALID_WORK_GROUP_SIZE\"]\n            if any([skip_str in str(e) for skip_str in skippable_exceptions]):\n                logging.debug('benchmark fails due to runtime failure too many resources required')\n                if verbose:\n                    print(\"skipping config\", instance.name, \"reason: too many resources requested for launch\")\n            else:\n                logging.debug('benchmark encountered runtime failure: ' + str(e))\n                print(\"Error while benchmarking:\", instance.name)\n                raise e\n        return time", "response": "benchmark the kernel instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_kernel_output(self, func, gpu_args, instance, answer, atol, verify, verbose):\n        logging.debug('check_kernel_output')\n\n        #if not using custom verify function, check if the length is the same\n        if not verify and len(instance.arguments) != len(answer):\n            raise TypeError(\"The length of argument list and provided results do not match.\")\n\n        #zero GPU memory for output arguments\n        for i, arg in enumerate(instance.arguments):\n            if verify or answer[i] is not None:\n                if isinstance(arg, numpy.ndarray):\n                    self.dev.memcpy_htod(gpu_args[i], arg)\n\n        #run the kernel\n        check = self.run_kernel(func, gpu_args, instance)\n        if not check:\n            return True #runtime failure occured that should be ignored, skip correctness check\n\n        #retrieve gpu results to host memory\n        result_host = []\n        for i, arg in enumerate(instance.arguments):\n            if verify or answer[i] is not None:\n                if isinstance(arg, numpy.ndarray):\n                    result_host.append(numpy.zeros_like(arg))\n                    self.dev.memcpy_dtoh(result_host[-1], gpu_args[i])\n            else:\n                result_host.append(None)\n\n        #if the user has specified a custom verify function, then call it, else use default based on numpy allclose\n        if verify:\n            try:\n                return verify(answer, result_host, atol=atol)\n            except TypeError:\n                return verify(answer, result_host)\n        else:\n            return _default_verify_function(instance, answer, result_host, atol, verbose)", "response": "runs the kernel once and checks the result against answer"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compile_and_benchmark(self, gpu_args, params, kernel_options, tuning_options):\n\n        instance_string = util.get_instance_string(params)\n\n        logging.debug('compile_and_benchmark ' + instance_string)\n        mem_usage = round(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024.0, 1)\n        logging.debug('Memory usage : %2.2f MB', mem_usage)\n\n        verbose = tuning_options.verbose\n\n        instance = self.create_kernel_instance(kernel_options, params, verbose)\n        if instance is None:\n            return None\n\n        try:\n            #compile the kernel\n            func = self.compile_kernel(instance, verbose)\n            if func is None:\n                return None\n\n            #add constant memory arguments to compiled module\n            if kernel_options.cmem_args is not None:\n                self.dev.copy_constant_memory_args(kernel_options.cmem_args)\n            #add texture memory arguments to compiled module\n            if kernel_options.texmem_args is not None:\n                self.dev.copy_texture_memory_args(kernel_options.texmem_args)\n\n            #test kernel for correctness and benchmark\n            if tuning_options.answer is not None:\n                self.check_kernel_output(func, gpu_args, instance, tuning_options.answer, tuning_options.atol, tuning_options.verify, verbose)\n\n            #benchmark\n            time = self.benchmark(func, gpu_args, instance, tuning_options.times, verbose)\n\n        except Exception as e:\n            #dump kernel_string to temp file\n            temp_filename = util.get_temp_filename(suffix=\".c\")\n            util.write_file(temp_filename, instance.kernel_string)\n            print(\"Error while compiling or benchmarking, see source files: \" + temp_filename + \" \".join(instance.temp_files.values()))\n            raise e\n\n        #clean up any temporary files, if no error occured\n        for v in instance.temp_files.values():\n            util.delete_temp_file(v)\n\n        return time", "response": "Compile and benchmark a kernel instance based on the kernel strings and parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompiles the kernel for this specific instance", "response": "def compile_kernel(self, instance, verbose):\n        \"\"\"compile the kernel for this specific instance\"\"\"\n        logging.debug('compile_kernel ' + instance.name)\n\n        #compile kernel_string into device func\n        func = None\n        try:\n            func = self.dev.compile(instance.name, instance.kernel_string)\n        except Exception as e:\n            #compiles may fail because certain kernel configurations use too\n            #much shared memory for example, the desired behavior is to simply\n            #skip over this configuration and try the next one\n            if \"uses too much shared data\" in str(e):\n                logging.debug('compile_kernel failed due to kernel using too much shared memory')\n                if verbose:\n                    print(\"skipping config\", instance.name, \"reason: too much shared memory used\")\n            else:\n                logging.debug('compile_kernel failed due to error: ' + str(e))\n                print(\"Error while compiling:\", instance.name)\n                raise e\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds constant memory arguments to the most recently compiled module if using CUDA", "response": "def copy_constant_memory_args(self, cmem_args):\n        \"\"\"adds constant memory arguments to the most recently compiled module, if using CUDA\"\"\"\n        if self.lang == \"CUDA\":\n            self.dev.copy_constant_memory_args(cmem_args)\n        else:\n            raise Exception(\"Error cannot copy constant memory arguments when language is not CUDA\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds texture memory arguments to the most recently compiled module if using CUDA", "response": "def copy_texture_memory_args(self, texmem_args):\n        \"\"\"adds texture memory arguments to the most recently compiled module, if using CUDA\"\"\"\n        if self.lang == \"CUDA\":\n            self.dev.copy_texture_memory_args(texmem_args)\n        else:\n            raise Exception(\"Error cannot copy texture memory arguments when language is not CUDA\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_kernel_instance(self, kernel_options, params, verbose):\n        instance_string = util.get_instance_string(params)\n        grid_div = (kernel_options.grid_div_x, kernel_options.grid_div_y, kernel_options.grid_div_z)\n\n        #insert default block_size_names if needed\n        if not kernel_options.block_size_names:\n            kernel_options.block_size_names = util.default_block_size_names\n\n        #setup thread block and grid dimensions\n        threads, grid = util.setup_block_and_grid(kernel_options.problem_size, grid_div, params, kernel_options.block_size_names)\n        if numpy.prod(threads) > self.dev.max_threads:\n            if verbose:\n                print(\"skipping config\", instance_string, \"reason: too many threads per block\")\n            return None\n\n        #obtain the kernel_string and prepare additional files, if any\n        temp_files = dict()\n        kernel_source = kernel_options.kernel_string\n        if not isinstance(kernel_source, list):\n            kernel_source = [kernel_source]\n        name, kernel_string, temp_files = util.prepare_list_of_files(kernel_options.kernel_name, kernel_source, params, grid, threads, kernel_options.block_size_names)\n\n        #collect everything we know about this instance and return it\n        return KernelInstance(name, kernel_string, temp_files, threads, grid, params, kernel_options.arguments)", "response": "create kernel instance from kernel options"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a compiled kernel instance on a device", "response": "def run_kernel(self, func, gpu_args, instance):\n        \"\"\" Run a compiled kernel instance on a device \"\"\"\n        logging.debug('run_kernel %s', instance.name)\n        logging.debug('thread block dims (%d, %d, %d)', *instance.threads)\n        logging.debug('grid dims (%d, %d, %d)', *instance.grid)\n\n        try:\n            self.dev.run_kernel(func, gpu_args, instance.threads, instance.grid)\n        except Exception as e:\n            if \"too many resources requested for launch\" in str(e) or \"OUT_OF_RESOURCES\" in str(e):\n                logging.debug('ignoring runtime failure due to too many resources required')\n                return False\n            else:\n                logging.debug('encountered unexpected runtime failure: ' + str(e))\n                raise e\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _chunk_list(l, n):\n    for i in range(0, len(l), n):\n        yield l[i:i + n]", "response": "Yield successive n - sized chunks from l."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, parameter_space, kernel_options, tuning_options):\n        workflow = self._parameter_sweep(parameter_space, kernel_options, self.device_options,\n                                         tuning_options)\n        if tuning_options.verbose:\n            with NCDisplay(_error_filter) as display:\n                answer = run_parallel_with_display(workflow, self.max_threads, display)\n        else:\n            answer = run_parallel(workflow, self.max_threads)\n\n        if answer is None:\n            print(\"Tuning did not return any results, did an error occur?\")\n            return None\n\n        # Filter out None times\n        result = []\n        for chunk in answer:\n            result += [d for d in chunk if d['time']]\n\n        return result, {}", "response": "Runs the tuning process on the specified parameter space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a Noodles workflow by sweeping the parameter space", "response": "def _parameter_sweep(self, parameter_space, kernel_options, device_options, tuning_options):\n        \"\"\"Build a Noodles workflow by sweeping the parameter space\"\"\"\n        results = []\n\n        #randomize parameter space to do pseudo load balancing\n        parameter_space = list(parameter_space)\n        random.shuffle(parameter_space)\n\n        #split parameter space into chunks\n        work_per_thread = int(numpy.ceil(len(parameter_space) / float(self.max_threads)))\n        chunks = _chunk_list(parameter_space, work_per_thread)\n\n        for chunk in chunks:\n\n            chunked_result = self._run_chunk(chunk, kernel_options, device_options, tuning_options)\n\n            results.append(lift(chunked_result))\n\n        return gather(*results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run_chunk(self, chunk, kernel_options, device_options, tuning_options):\n\n        #detect language and create high-level device interface\n        self.dev = DeviceInterface(kernel_options.kernel_string, iterations=tuning_options.iterations, **device_options)\n\n        #move data to the GPU\n        gpu_args = self.dev.ready_argument_list(kernel_options.arguments)\n\n        results = []\n\n        for element in chunk:\n            params = dict(OrderedDict(zip(tuning_options.tune_params.keys(), element)))\n\n            try:\n                time = self.dev.compile_and_benchmark(gpu_args, params, kernel_options, tuning_options)\n\n                params['time'] = time\n                results.append(params)\n            except Exception:\n                params['time'] = None\n                results.append(params)\n\n        return results", "response": "Benchmark a single kernel instance in the parameter space"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntuning a random sample of sample_fraction fraction in the parameter space.", "response": "def tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Tune a random sample of sample_fraction fraction in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    tune_params = tuning_options.tune_params\n\n    #compute cartesian product of all tunable parameters\n    parameter_space = itertools.product(*tune_params.values())\n\n    #check for search space restrictions\n    if tuning_options.restrictions is not None:\n        parameter_space = filter(lambda p: util.check_restrictions(tuning_options.restrictions, p,\n                                                                   tune_params.keys(),\n                                                                   tuning_options.verbose),\n                                 parameter_space)\n\n    #reduce parameter space to a random sample using sample_fraction\n    parameter_space = numpy.array(list(parameter_space))\n    size = len(parameter_space)\n    fraction = int(numpy.ceil(size * float(tuning_options.sample_fraction)))\n    sample_indices = numpy.random.choice(range(size), size=fraction, replace=False)\n    parameter_space = parameter_space[sample_indices]\n\n    #call the runner\n    results, env = runner.run(parameter_space, kernel_options, tuning_options)\n\n    return results, env"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_argument_type(dtype, kernel_argument, i):\n    types_map = {\"uint8\": [\"uchar\", \"unsigned char\", \"uint8_t\"],\n                 \"int8\": [\"char\", \"int8_t\"],\n                 \"uint16\": [\"ushort\", \"unsigned short\", \"uint16_t\"],\n                 \"int16\": [\"short\", \"int16_t\"],\n                 \"uint32\": [\"uint\", \"unsigned int\", \"uint32_t\"],\n                 \"int32\": [\"int\", \"int32_t\"],   #discrepancy between OpenCL and C here, long may be 32bits in C\n                 \"uint64\": [\"ulong\", \"unsigned long\", \"uint64_t\"],\n                 \"int64\": [\"long\", \"int64_t\"],\n                 \"float16\": [\"half\"],\n                 \"float32\": [\"float\"],\n                 \"float64\": [\"double\"]}\n    if dtype in types_map:\n        return any([substr in kernel_argument for substr in types_map[dtype]])\n    else:\n        return False", "response": "check if the numpy. dtype matches the type used in the code"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if kernel arguments match host arguments", "response": "def check_argument_list(kernel_name, kernel_string, args):\n    \"\"\" raise an exception if a kernel arguments do not match host arguments \"\"\"\n    kernel_arguments = list()\n    collected_errors = list()\n    for iterator in re.finditer(kernel_name + \"[ \\n\\t]*\" + \"\\(\", kernel_string):\n        kernel_start = iterator.end()\n        kernel_end = kernel_string.find(\")\", kernel_start)\n        if kernel_start != 0:\n            kernel_arguments.append(kernel_string[kernel_start:kernel_end].split(\",\"))\n    for arguments_set, arguments in enumerate(kernel_arguments):\n        collected_errors.append(list())\n        if len(arguments) != len(args):\n            collected_errors[arguments_set].append(\"Kernel and host argument lists do not match in size.\")\n            continue\n        for (i, arg) in enumerate(args):\n            kernel_argument = arguments[i]\n\n            if not isinstance(arg, (numpy.ndarray, numpy.generic)):\n                raise TypeError(\"Argument at position \" + str(i) + \" of type: \" + str(type(arg)) + \" should be of type numpy.ndarray or numpy scalar\")\n\n            correct = True\n            if isinstance(arg, numpy.ndarray) and not \"*\" in kernel_argument:\n                correct = False  #array is passed to non-pointer kernel argument\n\n            if correct and check_argument_type(str(arg.dtype), kernel_argument, i):\n                continue\n\n            collected_errors[arguments_set].append(\"Argument at position \" + str(i) + \" of dtype: \" + str(arg.dtype) +\n                                                   \" does not match \" + kernel_argument + \".\")\n        if not collected_errors[arguments_set]:\n            # We assume that if there is a possible list of arguments that matches with the provided one\n            # it is the right one\n            return\n    for errors in collected_errors:\n        warnings.warn(errors[0], UserWarning)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_tune_params_list(tune_params):\n    forbidden_names = (\"grid_size_x\", \"grid_size_y\", \"grid_size_z\")\n    forbidden_name_substr = (\"time\", \"times\")\n    for name, param in tune_params.items():\n        if name in forbidden_names:\n            raise ValueError(\"Tune parameter \" + name + \" with value \" + str(param) + \" has a forbidden name!\")\n        for forbidden_substr in forbidden_name_substr:\n            if forbidden_substr in name:\n                raise ValueError(\"Tune parameter \" + name + \" with value \" + str(param) + \" has a forbidden name: not allowed to use \" + forbidden_substr + \" in tune parameter names!\")", "response": "raise an exception if a tune parameter has a forbidden name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether a specific instance meets the search space restrictions", "response": "def check_restrictions(restrictions, element, keys, verbose):\n    \"\"\" check whether a specific instance meets the search space restrictions \"\"\"\n    params = OrderedDict(zip(keys, element))\n    for restrict in restrictions:\n        if not eval(replace_param_occurrences(restrict, params)):\n            if verbose:\n                print(\"skipping config\", get_instance_string(params), \"reason: config fails restriction\")\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattempts to detect language from the kernel_string", "response": "def detect_language(lang, kernel_source):\n    \"\"\"attempt to detect language from the kernel_string if not specified\"\"\"\n    if lang is None:\n        if callable(kernel_source):\n            raise TypeError(\"Please specify language when using a code generator function\")\n        kernel_string = get_kernel_string(kernel_source)\n        if \"__global__\" in kernel_string:\n            lang = \"CUDA\"\n        elif \"__kernel\" in kernel_string:\n            lang = \"OpenCL\"\n        else:\n            lang = \"C\"\n    return lang"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a compact string representation of a dictionary", "response": "def get_config_string(params, units=None):\n    \"\"\" return a compact string representation of a dictionary \"\"\"\n    compact_str_items = []\n    # first make a list of compact strings for each parameter\n    for k, v in params.items():\n        unit = \"\"\n        if isinstance(units, dict): #check if not None not enough, units could be mocked which causes errors\n            unit = units.get(k, \"\")\n        compact_str_items.append(k + \"=\" + str(v) + unit)\n    # and finally join them\n    compact_str = \", \".join(compact_str_items)\n    return compact_str"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes grid dims based on problem sizes and listed grid divisors", "response": "def get_grid_dimensions(current_problem_size, params, grid_div, block_size_names):\n    \"\"\"compute grid dims based on problem sizes and listed grid divisors\"\"\"\n    def get_dimension_divisor(divisor_list, default, params):\n        if divisor_list is None:\n            if default in params:\n                divisor_list = [default]\n            else:\n                return 1\n        return numpy.prod([int(eval(replace_param_occurrences(s, params))) for s in divisor_list])\n    divisors = [get_dimension_divisor(d, block_size_names[i], params) for i, d in enumerate(grid_div)]\n    return tuple(int(numpy.ceil(float(current_problem_size[i]) / float(d))) for i, d in enumerate(divisors))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_kernel_string(kernel_source, params=None):\n    #logging.debug('get_kernel_string called with %s', str(kernel_source))\n    logging.debug('get_kernel_string called')\n\n    kernel_string = None\n    if callable(kernel_source):\n        kernel_string = kernel_source(params)\n    elif isinstance(kernel_source, str):\n        if looks_like_a_filename(kernel_source):\n            kernel_string = read_file(kernel_source) or kernel_source\n        else:\n            kernel_string = kernel_source\n    else:\n        raise TypeError(\"Error kernel_source is not a string nor a callable function\")\n    return kernel_string", "response": "retrieve the kernel source and return as a string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute current problem size", "response": "def get_problem_size(problem_size, params):\n    \"\"\"compute current problem size\"\"\"\n    if isinstance(problem_size, (str, int, numpy.integer)):\n        problem_size = (problem_size, )\n    current_problem_size = [1, 1, 1]\n    for i, s in enumerate(problem_size):\n        if isinstance(s, str):\n            current_problem_size[i] = int(eval(replace_param_occurrences(s, params)))\n        elif isinstance(s, (int, numpy.integer)):\n            current_problem_size[i] = s\n        else:\n            raise TypeError(\"Error: problem_size should only contain strings or integers\")\n    return current_problem_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_temp_filename(suffix=None):\n    file = tempfile.mkstemp(suffix=suffix or \"\", prefix=\"temp_\", dir=os.getcwd()) # or \"\" for Python 2 compatibility\n    os.close(file[0])\n    return file[1]", "response": "returns a string in the form of temp_X where X is a large integer"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nthreads block size from tuning params currently using convention", "response": "def get_thread_block_dimensions(params, block_size_names=None):\n    \"\"\"thread block size from tuning params, currently using convention\"\"\"\n    if not block_size_names:\n        block_size_names = default_block_size_names\n\n    block_size_x = params.get(block_size_names[0], 256)\n    block_size_y = params.get(block_size_names[1], 1)\n    block_size_z = params.get(block_size_names[2], 1)\n    return (int(block_size_x), int(block_size_y), int(block_size_z))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef looks_like_a_filename(kernel_source):\n    logging.debug('looks_like_a_filename called')\n    result = False\n    if isinstance(kernel_source, str):\n        result = True\n        #test if not too long\n        if len(kernel_source) > 250:\n            result = False\n        #test if not contains special characters\n        for c in \"();{}\\\\\":\n            if c in kernel_source:\n                result = False\n        #just a safeguard for stuff that looks like code\n        for s in [\"__global__ \", \"__kernel \", \"void \", \"float \"]:\n            if s in kernel_source:\n                result = False\n        #string must contain substring \".c\", \".opencl\", or \".F\"\n        result = result and any([s in kernel_source for s in (\".c\", \".opencl\", \".F\")])\n    logging.debug('kernel_source is a filename: %s' % str(result))\n    return result", "response": "detect whether kernel_source is a filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares the kernel string for compilation", "response": "def prepare_kernel_string(kernel_name, kernel_string, params, grid, threads, block_size_names):\n    \"\"\" prepare kernel string for compilation\n\n    Prepends the kernel with a series of C preprocessor defines specific\n    to this kernel instance:\n\n     * the thread block dimensions\n     * the grid dimensions\n     * tunable parameters\n\n    Additionally the name of kernel is replace with an instance specific name. This\n    is done to prevent that the kernel compilation could be skipped by PyCUDA and/or PyOpenCL,\n    which may use caching to save compilation time. This feature could lead to strange bugs\n    in the source code if the name of the kernel is also used for other stuff.\n\n    :param kernel_name: Name of the kernel.\n    :type kernel_name: string\n\n    :param kernel_string: One of the source files of the kernel as a string containing code.\n    :type kernel_string: string\n\n    :param params: A dictionary containing the tunable parameters specific to this instance.\n    :type params: dict\n\n    :param grid: A tuple with the grid dimensions for this specific instance.\n    :type grid: tuple(x,y,z)\n\n    :param threads: A tuple with the thread block dimensions for this specific instance.\n    :type threads: tuple(x,y,z)\n\n    :param block_size_names: A tuple with the names of the thread block dimensions used\n        in the code. By default this is [\"block_size_x\", ...], but the user\n        may supply different names if they prefer.\n    :type block_size_names: tuple(string)\n\n    :returns: A string containing the source code made specific to this kernel instance.\n    :rtype: string\n\n    \"\"\"\n    logging.debug('prepare_kernel_string called for %s', kernel_name)\n\n    grid_dim_names = [\"grid_size_x\", \"grid_size_y\", \"grid_size_z\"]\n    for i, g in enumerate(grid):\n        kernel_string = \"#define \" + grid_dim_names[i] + \" \" + str(g) + \"\\n\" + kernel_string\n    for i, g in enumerate(threads):\n        kernel_string = \"#define \" + block_size_names[i] + \" \" + str(g) + \"\\n\" + kernel_string\n    for k, v in params.items():\n        if k not in block_size_names:\n            kernel_string = \"#define \" + k + \" \" + str(v) + \"\\n\" + kernel_string\n    name = kernel_name\n    #name = kernel_name + \"_\" + get_instance_string(params)\n    #kernel_string = kernel_string.replace(kernel_name, name)\n    return name, kernel_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare_list_of_files(kernel_name, kernel_file_list, params, grid, threads, block_size_names):\n    temp_files = dict()\n\n    kernel_string = get_kernel_string(kernel_file_list[0], params)\n    name, kernel_string = prepare_kernel_string(kernel_name, kernel_string, params, grid, threads, block_size_names)\n\n    if len(kernel_file_list) > 1:\n        for f in kernel_file_list[1:]:\n            #generate temp filename with the same extension\n            temp_file = get_temp_filename(suffix=\".\" + f.split(\".\")[-1])\n            temp_files[f] = temp_file\n            #add preprocessor statements to the additional file\n            _, temp_file_string = prepare_kernel_string(kernel_name, get_kernel_string(f, params), params, grid, threads, block_size_names)\n            write_file(temp_file, temp_file_string)\n            #replace occurences of the additional file's name in the first kernel_string with the name of the temp file\n            kernel_string = kernel_string.replace(f, temp_file)\n\n    return name, kernel_string, temp_files", "response": "This function takes a list of files and creates a temporary file with the appropriate preprocessor statements."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_file(filename):\n    if os.path.isfile(filename):\n        with open(filename, 'r') as f:\n            return f.read()", "response": "read the contents of the file named filename"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_param_occurrences(string, params):\n    for k, v in params.items():\n        string = string.replace(k, str(v))\n    return string", "response": "replace occurrences of the tuning params with their current value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_block_and_grid(problem_size, grid_div, params, block_size_names=None):\n    threads = get_thread_block_dimensions(params, block_size_names)\n    current_problem_size = get_problem_size(problem_size, params)\n    grid = get_grid_dimensions(current_problem_size, params, grid_div, block_size_names)\n    return threads, grid", "response": "compute problem size thread block and grid dimensions for this kernel"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps the contents of string to a file called filename", "response": "def write_file(filename, string):\n    \"\"\"dump the contents of string to a file called filename\"\"\"\n    import sys\n    #ugly fix, hopefully we can find a better one\n    if sys.version_info[0] >= 3:\n        with open(filename, 'w', encoding=\"utf-8\") as f:\n            f.write(string)\n    else:\n        with open(filename, 'w') as f:\n            f.write(string.encode(\"utf-8\"))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nready argument list to be passed to the kernel allocates gpu mem", "response": "def ready_argument_list(self, arguments):\n        \"\"\"ready argument list to be passed to the kernel, allocates gpu mem\n\n        :param arguments: List of arguments to be passed to the kernel.\n            The order should match the argument list on the OpenCL kernel.\n            Allowed values are numpy.ndarray, and/or numpy.int32, numpy.float32, and so on.\n        :type arguments: list(numpy objects)\n\n        :returns: A list of arguments that can be passed to an OpenCL kernel.\n        :rtype: list( pyopencl.Buffer, numpy.int32, ... )\n        \"\"\"\n        gpu_args = []\n        for arg in arguments:\n            # if arg i is a numpy array copy to device\n            if isinstance(arg, numpy.ndarray):\n                gpu_args.append(cl.Buffer(self.ctx, self.mf.READ_WRITE | self.mf.COPY_HOST_PTR, hostbuf=arg))\n            else: # if not an array, just pass argument along\n                gpu_args.append(arg)\n        return gpu_args"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile(self, kernel_name, kernel_string):\n        prg = cl.Program(self.ctx, kernel_string).build(options=self.compiler_options)\n        func = getattr(prg, kernel_name)\n        return func", "response": "call the OpenCL compiler to compile the kernel return the device function\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the kernel and measures time repeatedly returns average time", "response": "def benchmark(self, func, gpu_args, threads, grid, times):\n        \"\"\"runs the kernel and measures time repeatedly, returns average time\n\n        Runs the kernel and measures kernel execution time repeatedly, number of\n        iterations is set during the creation of OpenCLFunctions. Benchmark returns\n        a robust average, from all measurements the fastest and slowest runs are\n        discarded and the rest is included in the returned average. The reason for\n        this is to be robust against initialization artifacts and other exceptional\n        cases.\n\n        :param func: A PyOpenCL kernel compiled for this specific kernel configuration\n        :type func: pyopencl.Kernel\n\n        :param gpu_args: A list of arguments to the kernel, order should match the\n            order in the code. Allowed values are either variables in global memory\n            or single values passed by value.\n        :type gpu_args: list( pyopencl.Buffer, numpy.int32, ...)\n\n        :param threads: A tuple listing the number of work items in each dimension of\n            the work group.\n        :type threads: tuple(int, int, int)\n\n        :param grid: A tuple listing the number of work groups in each dimension\n            of the NDRange.\n        :type grid: tuple(int, int)\n\n        :param times: Return the execution time of all iterations.\n        :type times: bool\n\n        :returns: All execution times, if times=True, or a robust average for the\n            kernel execution time.\n        :rtype: float\n        \"\"\"\n        global_size = (grid[0]*threads[0], grid[1]*threads[1], grid[2]*threads[2])\n        local_size = threads\n        time = []\n        for _ in range(self.iterations):\n            event = func(self.queue, global_size, local_size, *gpu_args)\n            event.wait()\n            time.append((event.profile.end - event.profile.start)*1e-6)\n        time = sorted(time)\n        if times:\n            return time\n        else:\n            if self.iterations > 4:\n                return numpy.mean(time[1:-1])\n            else:\n                return numpy.mean(time)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the OpenCL kernel passed as func", "response": "def run_kernel(self, func, gpu_args, threads, grid):\n        \"\"\"runs the OpenCL kernel passed as 'func'\n\n        :param func: An OpenCL Kernel\n        :type func: pyopencl.Kernel\n\n        :param gpu_args: A list of arguments to the kernel, order should match the\n            order in the code. Allowed values are either variables in global memory\n            or single values passed by value.\n        :type gpu_args: list( pyopencl.Buffer, numpy.int32, ...)\n\n        :param threads: A tuple listing the number of work items in each dimension of\n            the work group.\n        :type threads: tuple(int, int, int)\n\n        :param grid: A tuple listing the number of work groups in each dimension\n            of the NDRange.\n        :type grid: tuple(int, int)\n        \"\"\"\n        global_size = (grid[0]*threads[0], grid[1]*threads[1], grid[2]*threads[2])\n        local_size = threads\n        event = func(self.queue, global_size, local_size, *gpu_args)\n        event.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the memory in allocation to the value in value", "response": "def memset(self, buffer, value, size):\n        \"\"\"set the memory in allocation to the value in value\n\n        :param allocation: An OpenCL Buffer to fill\n        :type allocation: pyopencl.Buffer\n\n        :param value: The value to set the memory to\n        :type value: a single 32-bit int\n\n        :param size: The size of to the allocation unit in bytes\n        :type size: int\n\n        \"\"\"\n        if isinstance(buffer, cl.Buffer):\n            try:\n                cl.enqueue_fill_buffer(self.queue, buffer, numpy.uint32(value), 0, size)\n            except AttributeError:\n                src=numpy.zeros(size, dtype='uint8')+numpy.uint8(value)\n                cl.enqueue_copy(self.queue, buffer, src)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform a device to host memory copy", "response": "def memcpy_dtoh(self, dest, src):\n        \"\"\"perform a device to host memory copy\n\n        :param dest: A numpy array in host memory to store the data\n        :type dest: numpy.ndarray\n\n        :param src: An OpenCL Buffer to copy data from\n        :type src: pyopencl.Buffer\n        \"\"\"\n        if isinstance(src, cl.Buffer):\n            cl.enqueue_copy(self.queue, dest, src)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tune(runner, kernel_options, device_options, tuning_options):\n\n    results = []\n    cache = {}\n\n    tuning_options[\"scaling\"] = False\n    #build a bounds array as needed for the optimizer\n    bounds = get_bounds(tuning_options.tune_params)\n\n    args = (kernel_options, tuning_options, runner, results, cache)\n\n    #call the differential evolution optimizer\n    opt_result = differential_evolution(_cost_func, bounds, args, maxiter=1,\n                                        polish=False, disp=tuning_options.verbose)\n\n    if tuning_options.verbose:\n        print(opt_result.message)\n\n    return results, runner.dev.get_environment()", "response": "Tune the kernel in the parameter space."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tune(runner, kernel_options, device_options, tuning_options):\n\n    results = []\n    cache = {}\n\n    #scale variables in x because PSO works with velocities to visit different configurations\n    tuning_options[\"scaling\"] = True\n\n    #using this instead of get_bounds because scaling is used\n    bounds, _, _ = get_bounds_x0_eps(tuning_options)\n\n    args = (kernel_options, tuning_options, runner, results, cache)\n\n    num_particles = 20\n    maxiter = 100\n\n    best_time_global = 1e20\n    best_position_global = []\n\n    # init particle swarm\n    swarm = []\n    for i in range(0, num_particles):\n        swarm.append(Particle(bounds, args))\n\n    for i in range(maxiter):\n        if tuning_options.verbose:\n            print(\"start iteration \", i, \"best time global\", best_time_global)\n\n        # evaluate particle positions\n        for j in range(num_particles):\n            swarm[j].evaluate(_cost_func)\n\n            # update global best if needed\n            if swarm[j].time <= best_time_global:\n                best_position_global = swarm[j].position\n                best_time_global = swarm[j].time\n\n        # update particle velocities and positions\n        for j in range(0, num_particles):\n            swarm[j].update_velocity(best_position_global)\n            swarm[j].update_position(bounds)\n\n    if tuning_options.verbose:\n        print('Final result:')\n        print(best_position_global)\n        print(best_time_global)\n\n    return results, runner.dev.get_environment()", "response": "Tune a kernel configuration in the parameter space."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntunes the kernel configuration in the parameter space.", "response": "def tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: kernel_tuner.interface.Options\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: kernel_tuner.interface.Options\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: kernel_tuner.interface.Options\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    dna_size = len(tuning_options.tune_params.keys())\n    pop_size = 20\n    generations = 100\n    tuning_options[\"scaling\"] = False\n\n    tune_params = tuning_options.tune_params\n\n    population = random_population(dna_size, pop_size, tune_params)\n\n    best_time = 1e20\n    all_results = []\n    cache = {}\n\n    for generation in range(generations):\n        if tuning_options.verbose:\n            print(\"Generation %d, best_time %f\" % (generation, best_time))\n\n        #determine fitness of population members\n        weighted_population = []\n        for dna in population:\n            time = _cost_func(dna, kernel_options, tuning_options, runner, all_results, cache)\n            weighted_population.append((dna, time))\n        population = []\n\n        #'best_time' is used only for printing\n        if tuning_options.verbose and all_results:\n            best_time = min(all_results, key=lambda x: x[\"time\"])[\"time\"]\n\n        #population is sorted such that better configs have higher chance of reproducing\n        weighted_population.sort(key=lambda x: x[1])\n\n        #crossover and mutate\n        for _ in range(pop_size//2):\n            ind1 = weighted_choice(weighted_population)\n            ind2 = weighted_choice(weighted_population)\n\n            ind1, ind2 = crossover(ind1, ind2)\n\n            population.append(mutate(ind1, dna_size, tune_params))\n            population.append(mutate(ind2, dna_size, tune_params))\n\n    return all_results, runner.dev.get_environment()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a random population of DNA and other attributes", "response": "def random_population(dna_size, pop_size, tune_params):\n    \"\"\"create a random population\"\"\"\n    population = []\n    for _ in range(pop_size):\n        dna = []\n        for i in range(dna_size):\n            dna.append(random_val(i, tune_params))\n        population.append(dna)\n    return population"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a random value for a parameter", "response": "def random_val(index, tune_params):\n    \"\"\"return a random value for a parameter\"\"\"\n    key = list(tune_params.keys())[index]\n    return random.choice(tune_params[key])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmutating DNA with 1 / mutation_chance chance", "response": "def mutate(dna, dna_size, tune_params):\n    \"\"\"Mutate DNA with 1/mutation_chance chance\"\"\"\n    dna_out = []\n    mutation_chance = 10\n    for i in range(dna_size):\n        if int(random.random()*mutation_chance) == 1:\n            dna_out.append(random_val(i, tune_params))\n        else:\n            dna_out.append(dna[i])\n    return dna_out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tune(runner, kernel_options, device_options, tuning_options):\n\n    results = []\n    cache = {}\n\n    method = tuning_options.method\n\n    #scale variables in x to make 'eps' relevant for multiple variables\n    tuning_options[\"scaling\"] = True\n\n    bounds, x0, _ = get_bounds_x0_eps(tuning_options)\n    kwargs = setup_method_arguments(method, bounds)\n    options = setup_method_options(method, tuning_options)\n\n    #not all methods support 'disp' option\n    if not method in ['TNC']:\n        options['disp'] = tuning_options.verbose\n\n    args = (kernel_options, tuning_options, runner, results, cache)\n\n    opt_result = scipy.optimize.minimize(_cost_func, x0, args=args, method=method, options=options, **kwargs)\n\n    if tuning_options.verbose:\n        print(opt_result.message)\n\n    return results, runner.dev.get_environment()", "response": "Tune the kernel in the parameter space."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _cost_func(x, kernel_options, tuning_options, runner, results, cache):\n\n    error_time = 1e20\n    logging.debug('_cost_func called')\n    logging.debug('x: ' + str(x))\n\n    x_key = \",\".join([str(i) for i in x])\n    if x_key in cache:\n        return cache[x_key]\n\n    #snap values in x to nearest actual value for each parameter unscale x if needed\n    if tuning_options.scaling:\n        params = unscale_and_snap_to_nearest(x, tuning_options.tune_params, tuning_options.eps)\n    else:\n        params = snap_to_nearest_config(x, tuning_options.tune_params)\n\n    logging.debug('params ' + str(params))\n\n    x_int = \",\".join([str(i) for i in params])\n    if x_int in cache:\n        return cache[x_int]\n\n    #check if this is a legal (non-restricted) parameter instance\n    if tuning_options.restrictions:\n        legal = util.check_restrictions(tuning_options.restrictions, params, tuning_options.tune_params.keys(), tuning_options.verbose)\n        if not legal:\n            cache[x_int] = error_time\n            cache[x_key] = error_time\n            return error_time\n\n    #compile and benchmark this instance\n    res, _ = runner.run([params], kernel_options, tuning_options)\n\n    #append to tuning results\n    if res:\n        results.append(res[0])\n        cache[x_int] = res[0]['time']\n        cache[x_key] = res[0]['time']\n        return res[0]['time']\n\n    cache[x_int] = error_time\n    cache[x_key] = error_time\n    return error_time", "response": "This function is used by minimize. It is used by minimize."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute bounds x0 and eps", "response": "def get_bounds_x0_eps(tuning_options):\n    \"\"\"compute bounds, x0 (the initial guess), and eps\"\"\"\n    values = tuning_options.tune_params.values()\n\n    if tuning_options.scaling:\n        #bounds = [(0, 1) for _ in values]\n        #x0 = [0.5 for _ in bounds]\n        eps = numpy.amin([1.0/len(v) for v in values])\n\n        #reducing interval from [0, 1] to [0, eps*len(v)]\n        bounds = [(0, eps*len(v)) for v in values]\n        x0 = [0.5*eps*len(v) for v in values]\n    else:\n        bounds = get_bounds(tuning_options.tune_params)\n        x0 = [(min_v+max_v)/2.0 for (min_v, max_v) in bounds]\n        eps = 1e9\n        for v_list in values:\n            vals = numpy.sort(v_list)\n            eps = min(eps, numpy.amin(numpy.gradient(vals)))\n\n    tuning_options[\"eps\"] = eps\n    logging.debug('get_bounds_x0_eps called')\n    logging.debug('bounds ' + str(bounds))\n    logging.debug('x0 ' + str(x0))\n    logging.debug('eps ' + str(eps))\n\n    return bounds, x0, eps"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_bounds(tune_params):\n    bounds = []\n    for values in tune_params.values():\n        sorted_values = numpy.sort(values)\n        bounds.append((sorted_values[0], sorted_values[-1]))\n    return bounds", "response": "create a bounds array from the tunable parameters"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_method_options(method, tuning_options):\n    kwargs = {}\n\n    #pass size of parameter space as max iterations to methods that support it\n    #it seems not all methods iterpret this value in the same manner\n    maxiter = numpy.prod([len(v) for v in tuning_options.tune_params.values()])\n    kwargs['maxiter'] = maxiter\n    if method in [\"Nelder-Mead\", \"Powell\"]:\n        kwargs['maxfev'] = maxiter\n    elif method == \"L-BFGS-B\":\n        kwargs['maxfun'] = maxiter\n\n    #pass eps to methods that support it\n    if method in [\"CG\", \"BFGS\", \"L-BFGS-B\", \"TNC\", \"SLSQP\"]:\n        kwargs['eps'] = tuning_options.eps\n    elif method == \"COBYLA\":\n        kwargs['rhobeg'] = tuning_options.eps\n\n    return kwargs", "response": "prepare method specific options"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef snap_to_nearest_config(x, tune_params):\n    params = []\n    for i, k in enumerate(tune_params.keys()):\n        values = numpy.array(tune_params[k])\n        idx = numpy.abs(values-x[i]).argmin()\n        params.append(int(values[idx]))\n    return params", "response": "helper function that for each param selects the closest actual value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unscale_and_snap_to_nearest(x, tune_params, eps):\n    x_u = [i for i in x]\n    for i, v in enumerate(tune_params.values()):\n        #create an evenly spaced linear space to map [0,1]-interval\n        #to actual values, giving each value an equal chance\n        #pad = 0.5/len(v)  #use when interval is [0,1]\n        pad = 0.5*eps      #use when interval is [0, eps*len(v)]\n        linspace = numpy.linspace(pad, (eps*len(v))-pad, len(v))\n\n        #snap value to nearest point in space, store index\n        idx = numpy.abs(linspace-x[i]).argmin()\n\n        #safeguard that should not be needed\n        idx = min(max(idx, 0), len(v)-1)\n\n        #use index into array of actual values\n        x_u[i] = v[idx]\n    return x_u", "response": "helper function that unscale a variable to the nearest config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the kernel tuning process for the entire parameter space.", "response": "def run(self, parameter_space, kernel_options, tuning_options):\n        \"\"\" Iterate through the entire parameter space using a single Python process\n\n        :param parameter_space: The parameter space as an iterable.\n        :type parameter_space: iterable\n\n        :param kernel_options: A dictionary with all options for the kernel.\n        :type kernel_options: kernel_tuner.interface.Options\n\n        :param tuning_options: A dictionary with all options regarding the tuning\n            process.\n        :type tuning_options: kernel_tuner.iterface.Options\n\n        :returns: A list of dictionaries for executed kernel configurations and their\n            execution times. And a dictionary that contains a information\n            about the hardware/software environment on which the tuning took place.\n        :rtype: list(dict()), dict()\n\n        \"\"\"\n        logging.debug('sequential runner started for ' + kernel_options.kernel_name)\n\n        results = []\n\n        #iterate over parameter space\n        for element in parameter_space:\n            params = OrderedDict(zip(tuning_options.tune_params.keys(), element))\n\n            time = self.dev.compile_and_benchmark(self.gpu_args, params, kernel_options, tuning_options)\n\n            if time is None:\n                logging.debug('received time is None, kernel configuration was skipped silently due to compile or runtime failure')\n                continue\n\n            #print and append to results\n            params['time'] = time\n            output_string = get_config_string(params, self.units)\n            logging.debug(output_string)\n            if not self.quiet:\n                print(output_string)\n            results.append(params)\n\n        return results, self.dev.get_environment()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tune(runner, kernel_options, device_options, tuning_options):\n\n    results = []\n    cache = {}\n\n    method = tuning_options.method\n\n    #scale variables in x to make 'eps' relevant for multiple variables\n    tuning_options[\"scaling\"] = True\n\n    bounds, x0, eps = get_bounds_x0_eps(tuning_options)\n\n    kwargs = setup_method_arguments(method, bounds)\n    options = setup_method_options(method, tuning_options)\n    kwargs['options'] = options\n\n    args = (kernel_options, tuning_options, runner, results, cache)\n\n    minimizer_kwargs = dict(**kwargs)\n    minimizer_kwargs[\"method\"] = method\n    minimizer_kwargs[\"args\"] = args\n\n    opt_result = scipy.optimize.basinhopping(_cost_func, x0, stepsize=eps, minimizer_kwargs=minimizer_kwargs, disp=tuning_options.verbose)\n\n    if tuning_options.verbose:\n        print(opt_result.message)\n\n    return results, runner.dev.get_environment()", "response": "Tune the kernel configuration in the parameter space."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nallocates n context - portable pinned host memory", "response": "def allocate(n, dtype=numpy.float32):\n    \"\"\" allocate context-portable pinned host memory \"\"\"\n    return drv.pagelocked_empty(int(n), dtype, order='C', mem_flags=drv.host_alloc_flags.PORTABLE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreadies argument list to be passed to the kernel, allocates gpu mem :param arguments: List of arguments to be passed to the kernel. The order should match the argument list on the CUDA kernel. Allowed values are numpy.ndarray, and/or numpy.int32, numpy.float32, and so on. :type arguments: list(numpy objects) :returns: A list of arguments that can be passed to an CUDA kernel. :rtype: list( pycuda.driver.DeviceAllocation, numpy.int32, ... )", "response": "def ready_argument_list(self, arguments):\n        \"\"\"ready argument list to be passed to the kernel, allocates gpu mem\n\n        :param arguments: List of arguments to be passed to the kernel.\n            The order should match the argument list on the CUDA kernel.\n            Allowed values are numpy.ndarray, and/or numpy.int32, numpy.float32, and so on.\n        :type arguments: list(numpy objects)\n\n        :returns: A list of arguments that can be passed to an CUDA kernel.\n        :rtype: list( pycuda.driver.DeviceAllocation, numpy.int32, ... )\n        \"\"\"\n        gpu_args = []\n        for arg in arguments:\n            # if arg i is a numpy array copy to device\n            if isinstance(arg, numpy.ndarray):\n                alloc = drv.mem_alloc(arg.nbytes)\n                self.allocations.append(alloc)\n                gpu_args.append(alloc)\n                drv.memcpy_htod(gpu_args[-1], arg)\n            else: # if not an array, just pass argument along\n                gpu_args.append(arg)\n        return gpu_args"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compile(self, kernel_name, kernel_string):\n        try:\n            no_extern_c = 'extern \"C\"' in kernel_string\n\n            compiler_options = ['-Xcompiler=-Wall']\n            if self.compiler_options:\n                compiler_options += self.compiler_options\n\n            self.current_module = self.source_mod(kernel_string, options=compiler_options + [\"-e\", kernel_name],\n                                             arch=('compute_' + self.cc) if self.cc != \"00\" else None,\n                                             code=('sm_' + self.cc) if self.cc != \"00\" else None,\n                                             cache_dir=False, no_extern_c=no_extern_c)\n\n            func = self.current_module.get_function(kernel_name)\n            return func\n        except drv.CompileError as e:\n            if \"uses too much shared data\" in e.stderr:\n                raise Exception(\"uses too much shared data\")\n            else:\n                raise e", "response": "call the CUDA compiler to compile the kernel return the device function\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the kernel and measures time repeatedly returns average time", "response": "def benchmark(self, func, gpu_args, threads, grid, times):\n        \"\"\"runs the kernel and measures time repeatedly, returns average time\n\n        Runs the kernel and measures kernel execution time repeatedly, number of\n        iterations is set during the creation of CudaFunctions. Benchmark returns\n        a robust average, from all measurements the fastest and slowest runs are\n        discarded and the rest is included in the returned average. The reason for\n        this is to be robust against initialization artifacts and other exceptional\n        cases.\n\n        :param func: A PyCuda kernel compiled for this specific kernel configuration\n        :type func: pycuda.driver.Function\n\n        :param gpu_args: A list of arguments to the kernel, order should match the\n            order in the code. Allowed values are either variables in global memory\n            or single values passed by value.\n        :type gpu_args: list( pycuda.driver.DeviceAllocation, numpy.int32, ...)\n\n        :param threads: A tuple listing the number of threads in each dimension of\n            the thread block\n        :type threads: tuple(int, int, int)\n\n        :param grid: A tuple listing the number of thread blocks in each dimension\n            of the grid\n        :type grid: tuple(int, int)\n\n        :param times: Return the execution time of all iterations.\n        :type times: bool\n\n        :returns: All execution times, if times=True, or a robust average for the\n            kernel execution time.\n        :rtype: float\n        \"\"\"\n        start = drv.Event()\n        end = drv.Event()\n        time = []\n        for _ in range(self.iterations):\n            self.context.synchronize()\n            start.record()\n            self.run_kernel(func, gpu_args, threads, grid)\n            end.record()\n            self.context.synchronize()\n            time.append(end.time_since(start))\n        time = sorted(time)\n        if times:\n            return time\n        else:\n            if self.iterations > 4:\n                return numpy.mean(time[1:-1])\n            else:\n                return numpy.mean(time)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd constant memory arguments to the most recently compiled module", "response": "def copy_constant_memory_args(self, cmem_args):\n        \"\"\"adds constant memory arguments to the most recently compiled module\n\n        :param cmem_args: A dictionary containing the data to be passed to the\n            device constant memory. The format to be used is as follows: A\n            string key is used to name the constant memory symbol to which the\n            value needs to be copied. Similar to regular arguments, these need\n            to be numpy objects, such as numpy.ndarray or numpy.int32, and so on.\n        :type cmem_args: dict( string: numpy.ndarray, ... )\n        \"\"\"\n        logging.debug('copy_constant_memory_args called')\n        logging.debug('current module: ' + str(self.current_module))\n        for k, v in cmem_args.items():\n            symbol = self.current_module.get_global(k)[0]\n            logging.debug('copying to symbol: ' + str(symbol))\n            logging.debug('array to be copied: ')\n            logging.debug(v.nbytes)\n            logging.debug(v.dtype)\n            logging.debug(v.flags)\n            drv.memcpy_htod(symbol, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy_texture_memory_args(self, texmem_args):\n\n\n        filter_mode_map = { 'point': drv.filter_mode.POINT,\n                            'linear': drv.filter_mode.LINEAR }\n        address_mode_map = { 'border': drv.address_mode.BORDER,\n                             'clamp': drv.address_mode.CLAMP,\n                             'mirror': drv.address_mode.MIRROR,\n                             'wrap': drv.address_mode.WRAP }\n\n        logging.debug('copy_texture_memory_args called')\n        logging.debug('current module: ' + str(self.current_module))\n        self.texrefs = []\n        for k, v in texmem_args.items():\n            tex = self.current_module.get_texref(k)\n            self.texrefs.append(tex)\n\n            logging.debug('copying to texture: ' + str(k))\n            if not isinstance(v, dict):\n                data = v\n            else:\n                data = v['array']\n            logging.debug('texture to be copied: ')\n            logging.debug(data.nbytes)\n            logging.debug(data.dtype)\n            logging.debug(data.flags)\n\n            drv.matrix_to_texref(data, tex, order=\"C\")\n\n            if isinstance(v, dict):\n                if 'address_mode' in v and v['address_mode'] is not None:\n                    # address_mode is set per axis\n                    amode = v['address_mode']\n                    if not isinstance(amode, list):\n                        amode = [ amode ] * data.ndim\n                    for i, m in enumerate(amode):\n                        try:\n                            if m is not None:\n                                tex.set_address_mode(i, address_mode_map[m])\n                        except KeyError:\n                            raise ValueError('Unknown address mode: ' + m)\n                if 'filter_mode' in v and v['filter_mode'] is not None:\n                    fmode = v['filter_mode']\n                    try:\n                        tex.set_filter_mode(filter_mode_map[fmode])\n                    except KeyError:\n                        raise ValueError('Unknown filter mode: ' + fmode)\n                if 'normalized_coordinates' in v and v['normalized_coordinates']:\n                    tex.set_flags(tex.get_flags() | drv.TRSF_NORMALIZED_COORDINATES)", "response": "adds texture memory arguments to the most recently compiled module"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_kernel(self, func, gpu_args, threads, grid):\n        func(*gpu_args, block=threads, grid=grid, texrefs=self.texrefs)", "response": "runs the CUDA kernel passed as func"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the memory in allocation to the value in value", "response": "def memset(self, allocation, value, size):\n        \"\"\"set the memory in allocation to the value in value\n\n        :param allocation: A GPU memory allocation unit\n        :type allocation: pycuda.driver.DeviceAllocation\n\n        :param value: The value to set the memory to\n        :type value: a single 8-bit unsigned int\n\n        :param size: The size of to the allocation unit in bytes\n        :type size: int\n\n        \"\"\"\n        drv.memset_d8(allocation, value, size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef memcpy_dtoh(self, dest, src):\n        if isinstance(src, drv.DeviceAllocation):\n            drv.memcpy_dtoh(dest, src)\n        else:\n            dest = src", "response": "perform a device to host memory copy\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef memcpy_htod(self, dest, src):\n        if isinstance(dest, drv.DeviceAllocation):\n            drv.memcpy_htod(dest, src)\n        else:\n            dest = src", "response": "perform a host to device memory copy\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntunes the kernel configuration in the parameter space.", "response": "def tune(runner, kernel_options, device_options, tuning_options):\n    \"\"\" Find the best performing kernel configuration in the parameter space\n\n    :params runner: A runner from kernel_tuner.runners\n    :type runner: kernel_tuner.runner\n\n    :param kernel_options: A dictionary with all options for the kernel.\n    :type kernel_options: dict\n\n    :param device_options: A dictionary with all options for the device\n        on which the kernel should be tuned.\n    :type device_options: dict\n\n    :param tuning_options: A dictionary with all options regarding the tuning\n        process.\n    :type tuning_options: dict\n\n    :returns: A list of dictionaries for executed kernel configurations and their\n        execution times. And a dictionary that contains a information\n        about the hardware/software environment on which the tuning took place.\n    :rtype: list(dict()), dict()\n\n    \"\"\"\n\n    results = []\n    cache = {}\n\n    # SA works with real parameter values and does not need scaling\n    tuning_options[\"scaling\"] = False\n    args = (kernel_options, tuning_options, runner, results, cache)\n    tune_params = tuning_options.tune_params\n\n    # optimization parameters\n    T = 1.0\n    T_min = 0.001\n    alpha = 0.9\n    niter = 20\n\n    # generate random starting point and evaluate cost\n    pos = []\n    for i, _ in enumerate(tune_params.keys()):\n        pos.append(random_val(i, tune_params))\n    old_cost = _cost_func(pos, *args)\n\n    if tuning_options.verbose:\n        c = 0\n    # main optimization loop\n    while T > T_min:\n        if tuning_options.verbose:\n            print(\"iteration: \", c, \"T\", T, \"cost: \", old_cost)\n            c += 1\n\n        for i in range(niter):\n\n            new_pos = neighbor(pos, tune_params)\n            new_cost = _cost_func(new_pos, *args)\n\n            ap = acceptance_prob(old_cost, new_cost, T)\n            r = random.random()\n\n            if ap > r:\n                if tuning_options.verbose:\n                    print(\"new position accepted\", new_pos, new_cost, 'old:', pos, old_cost, 'ap', ap, 'r', r, 'T', T)\n                pos = new_pos\n                old_cost = new_cost\n\n        T = T * alpha\n\n    return results, runner.dev.get_environment()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating acceptance probability of a new resource based on old cost and new cost", "response": "def acceptance_prob(old_cost, new_cost, T):\n    \"\"\"annealing equation, with modifications to work towards a lower value\"\"\"\n    #if start pos is not valid, always move\n    if old_cost == 1e20:\n        return 1.0\n    #if we have found a valid ps before, never move to nonvalid pos\n    if new_cost == 1e20:\n        return 0.0\n    #always move if new cost is better\n    if new_cost < old_cost:\n        return 1.0\n    #maybe move if old cost is better than new cost depending on T and random value\n    return np.exp(((old_cost-new_cost)/old_cost)/T)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a random neighbor of pos", "response": "def neighbor(pos, tune_params):\n    \"\"\"return a random neighbor of pos\"\"\"\n    size = len(pos)\n    pos_out = []\n    # random mutation\n    # expected value is set that values all dimensions attempt to get mutated\n    for i in range(size):\n        key = list(tune_params.keys())[i]\n        values = tune_params[key]\n\n        if random.random() < 0.2:  #replace with random value\n            new_value = random_val(i, tune_params)\n        else: #adjacent value\n            ind = values.index(pos[i])\n            if random.random() > 0.5:\n                ind += 1\n            else:\n                ind -= 1\n            ind = min(max(ind, 0), len(values)-1)\n            new_value = values[ind]\n\n        pos_out.append(new_value)\n    return pos_out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tune(runner, kernel_options, device_options, tuning_options):\n\n    tune_params = tuning_options.tune_params\n    restrictions = tuning_options.restrictions\n    verbose = tuning_options.verbose\n\n    #compute cartesian product of all tunable parameters\n    parameter_space = itertools.product(*tune_params.values())\n\n    #check for search space restrictions\n    if restrictions is not None:\n        parameter_space = filter(lambda p: util.check_restrictions(restrictions, p, tune_params.keys(), verbose), parameter_space)\n\n    results, env = runner.run(parameter_space, kernel_options, tuning_options)\n\n    return results, env", "response": "Tune all instances in the parameter space"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a wrapper to call C++ functions from Python This function allows Kernel Tuner to call templated C++ functions that use primitive data types (double, float, int, ...). There is support to convert function arguments from plain pointers to array references. If this is needed, there should be a True value in convert_to_array in the location corresponding to the location in the args array. For example, a Numpy array argument of type float64 and length 10 will be cast using: ``*reinterpret_cast<double(*)[10]>(arg)`` which allows it to be used to call a C++ that is defined as: ``template<typename T, int s>void my_function(T (&arg)[s], ...)`` Arrays of size 1 will be converted to simple non-array references. False indicates that no conversion is performed. Conversion is only support for numpy array arguments. If convert_to_array is passed it should have the same length as the args array. :param function_name: A string containing the name of the C++ function to be wrapped :type function_name: string :param kernel_source: One of the sources for the kernel, could be a function that generates the kernel code, a string containing a filename that points to the kernel source, or just a string that contains the code. :type kernel_source: string or callable :param args: A list of kernel arguments, use numpy arrays for arrays, use numpy.int32 or numpy.float32 for scalars. :type args: list :param convert_to_array: A list of same length as args, containing True or False values indicating whether the corresponding argument in args should be cast to a reference to an array or not. :type convert_to_array: list (True or False) :returns: A string containing the orignal code extended with the wrapper function. The wrapper has \"extern C\" binding and can be passed to other Kernel Tuner functions, for example run_kernel with lang=\"C\". The name of the wrapper function will be the name of the function with a \"_wrapper\" postfix. :rtype: string", "response": "def cpp(function_name, kernel_source, args, convert_to_array=None):\n    \"\"\" Generate a wrapper to call C++ functions from Python\n\n    This function allows Kernel Tuner to call templated C++ functions\n    that use primitive data types (double, float, int, ...).\n\n    There is support to convert function arguments from plain pointers\n    to array references. If this is needed, there should be a True value\n    in convert_to_array in the location corresponding to the location in\n    the args array.\n\n    For example, a Numpy array argument of type float64 and length 10\n    will be cast using:\n    ``*reinterpret_cast<double(*)[10]>(arg)``\n    which allows it to be used to call a C++ that is defined as:\n    ``template<typename T, int s>void my_function(T (&arg)[s], ...)``\n\n    Arrays of size 1 will be converted to simple non-array references.\n    False indicates that no conversion is performed. Conversion\n    is only support for numpy array arguments. If convert_to_array is\n    passed it should have the same length as the args array.\n\n    :param function_name: A string containing the name of the C++ function\n        to be wrapped\n    :type function_name: string\n\n    :param kernel_source: One of the sources for the kernel, could be a\n        function that generates the kernel code, a string containing a filename\n        that points to the kernel source, or just a string that contains the code.\n    :type kernel_source: string or callable\n\n    :param args: A list of kernel arguments, use numpy arrays for\n        arrays, use numpy.int32 or numpy.float32 for scalars.\n    :type args: list\n\n    :param convert_to_array: A list of same length as args, containing\n        True or False values indicating whether the corresponding argument\n        in args should be cast to a reference to an array or not.\n    :type convert_to_array: list (True or False)\n\n    :returns: A string containing the orignal code extended with the wrapper\n        function. The wrapper has \"extern C\" binding and can be passed to\n        other Kernel Tuner functions, for example run_kernel with lang=\"C\".\n        The name of the wrapper function will be the name of the function with\n        a \"_wrapper\" postfix.\n    :rtype: string\n\n    \"\"\"\n\n    if convert_to_array and len(args) != len(convert_to_array):\n        raise ValueError(\"convert_to_array length should be same as args\")\n\n    type_map = {\"int8\": \"char\",\n                \"int16\": \"short\",\n                \"int32\": \"int\",\n                \"float32\": \"float\",\n                \"float64\": \"double\"}\n\n    def type_str(arg):\n        if not str(arg.dtype) in type_map:\n            raise Value(\"only primitive data types are supported by the C++ wrapper\")\n        typestring = type_map[str(arg.dtype)]\n        if isinstance(arg, np.ndarray):\n            typestring += \" *\"\n        return typestring + \" \"\n\n    signature = \",\".join([type_str(arg) + \"arg\" + str(i) for i, arg in enumerate(args)])\n\n    if not convert_to_array:\n        call_args = \",\".join([\"arg\" + str(i) for i in range(len(args))])\n    else:\n        call_args = []\n        for i, arg in enumerate(args):\n            if convert_to_array[i]:\n                if not isinstance(arg, np.ndarray):\n                    ValueError(\"conversion to array reference only supported for arguments that are numpy arrays, use length-1 numpy array to pass a scalar by reference\")\n                if np.prod(arg.shape) > 1:\n                    #convert pointer to a reference to an array\n                    arg_shape = \"\".join(\"[%d]\" % i for i in arg.shape)\n                    arg_str = \"*reinterpret_cast<\" + type_map[str(arg.dtype)] + \"(*)\" + arg_shape + \">(arg\" + str(i) + \")\"\n                else:\n                    #a reference is accepted rather than a pointer, just dereference\n                    arg_str = \"*arg\" + str(i)\n                call_args.append(arg_str)\n                #call_args = \",\".join([\"*reinterpret_cast<double(*)[9]>(arg\" + str(i) + \")\" for i in range(len(args))])\n            else:\n                call_args.append(\"arg\" + str(i))\n        call_args_str = \",\".join(call_args)\n\n    kernel_string = util.get_kernel_string(kernel_source)\n\n    return \"\"\"\n\n    %s\n\n    extern \"C\"\n    float %s_wrapper(%s) {\n\n        %s(%s);\n\n        return 0.0f;\n    }\"\"\" % (kernel_string, function_name, signature, function_name, call_args_str)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ready_argument_list(self, arguments):\n        ctype_args = [ None for _ in arguments]\n\n        for i, arg in enumerate(arguments):\n            if not isinstance(arg, (numpy.ndarray, numpy.number)):\n                raise TypeError(\"Argument is not numpy ndarray or numpy scalar %s\" % type(arg))\n            dtype_str = str(arg.dtype)\n            data = arg.copy()\n            if isinstance(arg, numpy.ndarray):\n                if dtype_str in dtype_map.keys():\n                    # In numpy <= 1.15, ndarray.ctypes.data_as does not itself keep a reference\n                    # to its underlying array, so we need to store a reference to arg.copy()\n                    # in the Argument object manually to avoid it being deleted.\n                    # (This changed in numpy > 1.15.)\n                    data_ctypes = data.ctypes.data_as(C.POINTER(dtype_map[dtype_str]))\n                else:\n                    raise TypeError(\"unknown dtype for ndarray\")\n            elif isinstance(arg, numpy.generic):\n                data_ctypes = dtype_map[dtype_str](arg)\n            ctype_args[i] = Argument(numpy=data, ctypes=data_ctypes)\n        return ctype_args", "response": "This method is used to create a list of arguments that can be passed to the C function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compile(self, kernel_name, kernel_string):\n        logging.debug('compiling ' + kernel_name)\n\n        if self.lib != None:\n            self.cleanup_lib()\n\n        compiler_options = [\"-fPIC\"]\n\n        #detect openmp\n        if \"#include <omp.h>\" in kernel_string or \"use omp_lib\" in kernel_string:\n            logging.debug('set using_openmp to true')\n            self.using_openmp = True\n            if self.compiler == \"pgfortran\":\n                compiler_options.append(\"-mp\")\n            else:\n                compiler_options.append(\"-fopenmp\")\n\n        #select right suffix based on compiler\n        suffix = \".cc\"\n\n        #detect whether to use nvcc as default instead of g++, may overrule an explicitly passed g++\n        if (\"#include <cuda\" in kernel_string) or (\"cudaMemcpy\" in kernel_string):\n            if self.compiler == \"g++\" and self.nvcc_available:\n                self.compiler = \"nvcc\"\n\n        #if contains device code suffix .cu is required by nvcc\n        if self.compiler == \"nvcc\" and \"__global__\" in kernel_string:\n            suffix = \".cu\"\n        if self.compiler in [\"gfortran\", \"pgfortran\", \"ftn\", \"ifort\"]:\n            suffix = \".F90\"\n\n        if self.compiler == \"nvcc\":\n            compiler_options = [\"-Xcompiler=\" + c for c in compiler_options]\n\n        if \".c\" in suffix:\n            if not \"extern \\\"C\\\"\" in kernel_string:\n                kernel_string = \"extern \\\"C\\\" {\\n\" + kernel_string + \"\\n}\"\n\n        #copy user specified compiler options to current list\n        if self.compiler_options:\n            compiler_options += self.compiler_options\n\n        lib_args = []\n        if \"CL/cl.h\" in kernel_string:\n            lib_args = [\"-lOpenCL\"]\n\n        logging.debug('using compiler ' + self.compiler)\n        logging.debug('compiler_options ' + \" \".join(compiler_options))\n        logging.debug('lib_args ' + \" \".join(lib_args))\n\n        source_file = get_temp_filename(suffix=suffix)\n        filename = \".\".join(source_file.split(\".\")[:-1])\n\n        #detect Fortran modules\n        match = re.search(r\"\\s*module\\s+([a-zA-Z_]*)\", kernel_string)\n        if match:\n            if self.compiler == \"gfortran\":\n                kernel_name = \"__\" + match.group(1) + \"_MOD_\" + kernel_name\n            elif self.compiler in [\"ftn\", \"ifort\"]:\n                kernel_name = match.group(1) + \"_mp_\" + kernel_name + \"_\"\n            elif self.compiler == \"pgfortran\":\n                kernel_name = match.group(1) + \"_\" + kernel_name + \"_\"\n\n\n        try:\n            write_file(source_file, kernel_string)\n\n            lib_extension = \".so\"\n            if platform.system() == \"Darwin\":\n                lib_extension = \".dylib\"\n\n            subprocess.check_call([self.compiler, \"-c\", source_file] + compiler_options + [\"-o\", filename + \".o\"])\n            subprocess.check_call([self.compiler, filename + \".o\"] + compiler_options + [\"-shared\", \"-o\", filename + lib_extension] + lib_args)\n\n\n            self.lib = numpy.ctypeslib.load_library(filename, '.')\n            func = getattr(self.lib, kernel_name)\n            func.restype = C.c_float\n\n        finally:\n            delete_temp_file(source_file)\n            delete_temp_file(filename+\".o\")\n            delete_temp_file(filename+\".so\")\n            delete_temp_file(filename+\".dylib\")\n\n        return func", "response": "compiles the kernel and returns the function that can be called directly."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef benchmark(self, func, c_args, threads, grid, times):\n        time = []\n        for _ in range(self.iterations):\n            value = self.run_kernel(func, c_args, threads, grid)\n\n            #I would like to replace the following with actually capturing\n            #stderr and detecting the error directly in Python, it proved\n            #however that capturing stderr for non-Python functions from Python\n            #is a rather difficult thing to do\n            #\n            #The current, less than ideal, scheme uses the convention that a\n            #negative time indicates a 'too many resources requested for launch'\n            if value < 0.0:\n                raise Exception(\"too many resources requested for launch\")\n\n            time.append(value)\n        time = sorted(time)\n        if times:\n            return time\n        else:\n            if self.iterations > 4:\n                return numpy.mean(time[1:-1])\n            else:\n                return numpy.mean(time)", "response": "Benchmarks the kernel for the specific CUDA configuration and returns the average of the CUDA configuration values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the kernel once returns whatever the kernel returns", "response": "def run_kernel(self, func, c_args, threads, grid):\n        \"\"\"runs the kernel once, returns whatever the kernel returns\n\n        :param func: A C function compiled for this specific configuration\n        :type func: ctypes._FuncPtr\n\n        :param c_args: A list of arguments to the function, order should match the\n            order in the code. The list should be prepared using\n            ready_argument_list().\n        :type c_args: list(Argument)\n\n        :param threads: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type threads: any\n\n        :param grid: Ignored, but left as argument for now to have the same\n            interface as CudaFunctions and OpenCLFunctions.\n        :type grid: any\n\n        :returns: A robust average of values returned by the C function.\n        :rtype: float\n        \"\"\"\n        logging.debug(\"run_kernel\")\n        logging.debug(\"arguments=\" + str([str(arg.ctypes) for arg in c_args]))\n\n        time = func(*[arg.ctypes for arg in c_args])\n\n        return time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the memory in allocation to the value in value in size", "response": "def memset(self, allocation, value, size):\n        \"\"\"set the memory in allocation to the value in value\n\n        :param allocation: An Argument for some memory allocation unit\n        :type allocation: Argument\n\n        :param value: The value to set the memory to\n        :type value: a single 8-bit unsigned int\n\n        :param size: The size of to the allocation unit in bytes\n        :type size: int\n        \"\"\"\n        C.memset(allocation.ctypes, value, size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nunload the previously loaded shared library.", "response": "def cleanup_lib(self):\n        \"\"\" unload the previously loaded shared library \"\"\"\n        if not self.using_openmp:\n            #this if statement is necessary because shared libraries that use\n            #OpenMP will core dump when unloaded, this is a well-known issue with OpenMP\n            logging.debug('unloading shared library')\n            _ctypes.dlclose(self.lib._handle)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clock(rpc):\n\n    while True:\n        yield from rpc.notify('clock', str(datetime.datetime.now()))\n        yield from asyncio.sleep(1)", "response": "This task runs forever and notifies all clients subscribed to\n    clock once a second."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode_msg(raw_msg):\n\n    try:\n        msg_data = json.loads(raw_msg)\n\n    except ValueError:\n        raise RpcParseError\n\n    # check jsonrpc version\n    if 'jsonrpc' not in msg_data or not msg_data['jsonrpc'] == JSONRPC:\n        raise RpcInvalidRequestError(msg_id=msg_data.get('id', None))\n\n    # check requierd fields\n    if not len(set(['error', 'result', 'method']) & set(msg_data)) == 1:\n        raise RpcInvalidRequestError(msg_id=msg_data.get('id', None))\n\n    # find message type\n    if 'method' in msg_data:\n        if 'id' in msg_data and msg_data['id'] is not None:\n            msg_type = JsonRpcMsgTyp.REQUEST\n\n        else:\n            msg_type = JsonRpcMsgTyp.NOTIFICATION\n\n    elif 'result' in msg_data:\n        msg_type = JsonRpcMsgTyp.RESULT\n\n    elif 'error' in msg_data:\n        msg_type = JsonRpcMsgTyp.ERROR\n\n    # Request Objects\n    if msg_type in (JsonRpcMsgTyp.REQUEST, JsonRpcMsgTyp.NOTIFICATION):\n\n        # 'method' fields have to be strings\n        if type(msg_data['method']) is not str:\n            raise RpcInvalidRequestError\n\n        # set empty 'params' if not set\n        if 'params' not in msg_data:\n            msg_data['params'] = None\n\n        # set empty 'id' if not set\n        if 'id' not in msg_data:\n            msg_data['id'] = None\n\n    # Response Objects\n    if msg_type in (JsonRpcMsgTyp.RESULT, JsonRpcMsgTyp.ERROR):\n\n        # every Response object has to define an id\n        if 'id' not in msg_data:\n            raise RpcInvalidRequestError(msg_id=msg_data.get('id', None))\n\n    # Error objects\n    if msg_type == JsonRpcMsgTyp.ERROR:\n\n        # the error field has to be a dict\n        if type(msg_data['error']) is not dict:\n            raise RpcInvalidRequestError(msg_id=msg_data.get('id', None))\n\n        # the error field has to define 'code' and 'message'\n        if not len(set(['code', 'message']) & set(msg_data['error'])) == 2:\n            raise RpcInvalidRequestError(msg_id=msg_data.get('id', None))\n\n        # the error code has to be in the specified ranges\n        if not msg_data['error']['code'] in RpcError.lookup_table.keys():\n            raise RpcInvalidRequestError(msg_id=msg_data.get('id', None))\n\n        # set empty 'data' field if not set\n        if 'data' not in msg_data['error']:\n            msg_data['error']['data'] = None\n\n    return JsonRpcMsg(msg_type, msg_data)", "response": "Decodes a jsonrpc 2. 0 raw message into JsonRpcMsg objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nswitch the schema of the task before it has been run.", "response": "def switch_schema(task, kwargs, **kw):\n    \"\"\" Switches schema of the task, before it has been run. \"\"\"\n    # Lazily load needed functions, as they import django model functions which\n    # in turn load modules that need settings to be loaded and we can't\n    # guarantee this module was loaded when the settings were ready.\n    from .compat import get_public_schema_name, get_tenant_model\n\n    old_schema = (connection.schema_name, connection.include_public_schema)\n    setattr(task, '_old_schema', old_schema)\n\n    schema = (\n        get_schema_name_from_task(task, kwargs) or\n        get_public_schema_name()\n    )\n\n    # If the schema has not changed, don't do anything.\n    if connection.schema_name == schema:\n        return\n\n    if connection.schema_name != get_public_schema_name():\n        connection.set_schema_to_public()\n\n    if schema == get_public_schema_name():\n        return\n\n    tenant = get_tenant_model().objects.get(schema_name=schema)\n    connection.set_tenant(tenant, include_public=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nswitch the schema back to the one from before running the task.", "response": "def restore_schema(task, **kwargs):\n    \"\"\" Switches the schema back to the one from before running the task. \"\"\"\n    from .compat import get_public_schema_name\n\n    schema_name = get_public_schema_name()\n    include_public = True\n\n    if hasattr(task, '_old_schema'):\n        schema_name, include_public = task._old_schema\n\n    # If the schema names match, don't do anything.\n    if connection.schema_name == schema_name:\n        return\n\n    connection.set_schema(schema_name, include_public=include_public)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef node_link_data(G, attrs=_attrs):\n    id_ = attrs['id']\n\n    data = {}\n    data['directed'] = G.is_directed()\n    data['graph'] = G.graph\n    data['nodes'] = [dict(chain(G.node[n].items(), [(id_, n)])) for n in G]\n    data['links'] = []\n    for u, v, timeline in G.interactions_iter():\n        for t in timeline['t']:\n            for tid in past.builtins.xrange(t[0], t[-1]+1):\n                data['links'].append({\"source\": u, \"target\": v, \"time\": tid})\n\n    return data", "response": "Return data in node - link format that is suitable for JSON serialization of a DyNetx graph."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef node_link_graph(data, directed=False, attrs=_attrs):\n\n    directed = data.get('directed', directed)\n    graph = dn.DynGraph()\n    if directed:\n        graph = graph.to_directed()\n\n    id_ = attrs['id']\n    mapping = []\n    graph.graph = data.get('graph', {})\n    c = count()\n    for d in data['nodes']:\n        node = d.get(id_, next(c))\n        mapping.append(node)\n        nodedata = dict((make_str(k), v) for k, v in d.items() if k != id_)\n        graph.add_node(node, **nodedata)\n    for d in data['links']:\n        graph.add_interaction(d['source'], d[\"target\"], d['time'])\n\n    return graph", "response": "Return a DyNetx graph from node - link data format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compact_timeslot(sind_list):\n    tls = sorted(sind_list)\n    conversion = {val: idx for idx, val in enumerate(tls)}\n    return conversion", "response": "Test method. Compact all snapshots into a single one."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nodes_iter(self, t=None, data=False):\n        if t is not None:\n            return iter([n for n in self.degree(t=t).values() if n > 0])\n        return iter(self._node)", "response": "Return an iterator over the nodes with respect to a given temporal snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of the nodes in the flattened graph at a given snapshot.", "response": "def nodes(self, t=None, data=False):\n        \"\"\"Return a list of the nodes in the graph at a given snapshot.\n\n        Parameters\n        ----------\n        t : snapshot id (default=None)\n            If None the the method returns all the nodes of the flattened graph.\n        data : boolean, optional (default=False)\n               If False return a list of nodes.  If True return a\n               two-tuple of node and node data dictionary\n\n        Returns\n        -------\n        nlist : list\n            A list of nodes.  If data=True a list of two-tuples containing\n            (node, node data dictionary).\n\n        Examples\n        --------\n        >>> G = dn.DynGraph()   # or DiGraph, MultiGraph, MultiDiGraph, etc\n        >>> G.add_path([0,1,2], 0)\n        >>> G.nodes(t=0)\n        [0, 1, 2]\n        >>> G.add_edge(1, 4, t=1)\n        >>> G.nodes(t=0)\n        [0, 1, 2]\n        \"\"\"\n        return list(self.nodes_iter(t=t, data=data))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterator over the interaction present in a given snapshot.", "response": "def interactions_iter(self, nbunch=None, t=None):\n        \"\"\"Return an iterator over the interaction present in a given snapshot.\n\n        Edges are returned as tuples\n        in the order (node, neighbor).\n\n        Parameters\n        ----------\n        nbunch : iterable container, optional (default= all nodes)\n            A container of nodes.  The container will be iterated\n            through once.\n        t : snapshot id (default=None)\n            If None the the method returns an iterator over the edges of the flattened graph.\n\n        Returns\n        -------\n        edge_iter : iterator\n            An iterator of (u,v) tuples of interaction.\n\n        See Also\n        --------\n        interaction : return a list of interaction\n\n        Notes\n        -----\n        Nodes in nbunch that are not in the graph will be (quietly) ignored.\n        For directed graphs this returns the out-interaction.\n\n        Examples\n        --------\n        >>> G = dn.DynGraph()\n        >>> G.add_path([0,1,2], 0)\n        >>> G.add_interaction(2,3,1)\n        >>> [e for e in G.interactions_iter(t=0)]\n        [(0, 1), (1, 2)]\n        >>> list(G.interactions_iter())\n        [(0, 1), (1, 2), (2, 3)]\n        \"\"\"\n        seen = {}  # helper dict to keep track of multiply stored interactions\n        if nbunch is None:\n            nodes_nbrs = self._adj.items()\n        else:\n            nodes_nbrs = ((n, self._adj[n]) for n in self.nbunch_iter(nbunch))\n\n        for n, nbrs in nodes_nbrs:\n            for nbr in nbrs:\n                if t is not None:\n                    if nbr not in seen and self.__presence_test(n, nbr, t):\n                        yield (n, nbr, {\"t\": [t]})\n                else:\n                    if nbr not in seen:\n                        yield (n, nbr, self._adj[n][nbr])\n                seen[n] = 1\n        del seen"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an interaction between nodes u and v at time t and e.", "response": "def add_interaction(self, u, v, t=None, e=None):\n        \"\"\"Add an interaction between u and v at time t vanishing (optional) at time e.\n\n        The nodes u and v will be automatically added if they are\n        not already in the graph.\n\n        Parameters\n        ----------\n        u, v : nodes\n            Nodes can be, for example, strings or numbers.\n            Nodes must be hashable (and not None) Python objects.\n        t : appearance snapshot id, mandatory\n        e : vanishing snapshot id, optional (default=None)\n\n        See Also\n        --------\n        add_edges_from : add a collection of interaction at time t\n\n        Notes\n        -----\n        Adding an interaction that already exists but with different snapshot id updates the interaction data.\n\n        Examples\n        --------\n        The following all add the interaction e=(1,2, 0) to graph G:\n\n        >>> G = dn.DynGraph()\n        >>> G.add_interaction(1, 2, 0)           # explicit two-node form\n        >>> G.add_interaction( [(1,2)], t=0 ) # add interaction from iterable container\n\n        Specify the vanishing of the interaction\n\n        >>>> G.add_interaction(1, 3, t=1, e=10)\n\n        will produce an interaction present in snapshots [0, 9]\n        \"\"\"\n        if t is None:\n            raise nx.NetworkXError(\n                \"The t argument must be specified.\")\n\n        if u not in self._node:\n            self._adj[u] = self.adjlist_inner_dict_factory()\n            self._node[u] = {}\n        if v not in self._node:\n            self._adj[v] = self.adjlist_inner_dict_factory()\n            self._node[v] = {}\n\n        if type(t) != list:\n            t = [t, t]\n\n        for idt in [t[0]]:\n            if self.has_edge(u, v) and not self.edge_removal:\n                continue\n            else:\n                if idt not in self.time_to_edge:\n                    self.time_to_edge[idt] = {(u, v, \"+\"): None}\n                else:\n                    if (u, v, \"+\") not in self.time_to_edge[idt]:\n                        self.time_to_edge[idt][(u, v, \"+\")] = None\n\n        if e is not None and self.edge_removal:\n\n            t[1] = e - 1\n            if e not in self.time_to_edge:\n                self.time_to_edge[e] = {(u, v, \"-\"): None}\n            else:\n                self.time_to_edge[e][(u, v, \"-\")] = None\n\n        # add the interaction\n        datadict = self._adj[u].get(v, self.edge_attr_dict_factory())\n\n        if 't' in datadict:\n            app = datadict['t']\n            max_end = app[-1][1]\n\n            if max_end == app[-1][0] and t[0] == app[-1][0] + 1:\n\n                app[-1] = [app[-1][0], t[1]]\n                if app[-1][0] + 1 in self.time_to_edge and (u, v, \"+\") in self.time_to_edge[app[-1][0] + 1]:\n                    del self.time_to_edge[app[-1][0] + 1][(u, v, \"+\")]\n\n            else:\n                if t[0] < app[-1][0]:\n                    raise ValueError(\"The specified interaction extension is broader than \"\n                                     \"the ones already present for the given nodes.\")\n\n                if t[0] <= max_end < t[1]:\n                    app[-1][1] = t[1]\n                    if max_end + 1 in self.time_to_edge:\n                        if self.edge_removal:\n                            del self.time_to_edge[max_end + 1][(u, v, \"-\")]\n                        del self.time_to_edge[t[0]][(u, v, \"+\")]\n\n                elif max_end == t[0] - 1:\n                    if max_end + 1 in self.time_to_edge and (u, v, \"+\") in self.time_to_edge[max_end + 1]:\n                        del self.time_to_edge[max_end + 1][(u, v, \"+\")]\n                        if self.edge_removal:\n                            if max_end + 1 in self.time_to_edge and (u, v, '-') in self.time_to_edge[max_end + 1]:\n                                del self.time_to_edge[max_end + 1][(u, v, '-')]\n                            if t[1] + 1 in self.time_to_edge:\n                                self.time_to_edge[t[1] + 1][(u, v, \"-\")] = None\n                            else:\n                                self.time_to_edge[t[1] + 1] = {(u, v, \"-\"): None}\n\n                    app[-1][1] = t[1]\n                else:\n                    app.append(t)\n        else:\n            datadict['t'] = [t]\n\n        if e is not None:\n            span = range(t[0], t[1] + 1)\n            for idt in span:\n                if idt not in self.snapshots:\n                    self.snapshots[idt] = 1\n                else:\n                    self.snapshots[idt] += 1\n        else:\n            for idt in t:\n                if idt is not None:\n                    if idt not in self.snapshots:\n                        self.snapshots[idt] = 1\n                    else:\n                        self.snapshots[idt] += 1\n\n        self._adj[u][v] = datadict\n        self._adj[v][u] = datadict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_interactions_from(self, ebunch, t=None, e=None):\n        # set up attribute dict\n        if t is None:\n            raise nx.NetworkXError(\n                \"The t argument must be a specified.\")\n        # process ebunch\n        for ed in ebunch:\n            self.add_interaction(ed[0], ed[1], t, e)", "response": "Add all the interaction in ebunch at time t to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef neighbors(self, n, t=None):\n        try:\n            if t is None:\n                return list(self._adj[n])\n            else:\n                return [i for i in self._adj[n] if self.__presence_test(n, i, t)]\n        except KeyError:\n            raise nx.NetworkXError(\"The node %s is not in the graph.\" % (n,))", "response": "Return a list of the nodes connected to the node n at time t."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterator over all neighbors of node n at time t.", "response": "def neighbors_iter(self, n, t=None):\n        \"\"\"Return an iterator over all neighbors of node n at time t.\n\n        Parameters\n        ----------\n        n : node\n           A node in the graph\n        t : snapshot id (default=None)\n            If None will be returned an iterator over the neighbors of the node on the flattened graph.\n\n        Examples\n        --------\n        >>> G = dn.DynGraph()\n        >>> G.add_path([0,1,2,3], t=0)\n        >>> [n for n in G.neighbors_iter(0, t=0)]\n        [1]\n        \"\"\"\n        try:\n            if t is None:\n                return iter(self._adj[n])\n            else:\n                return iter([i for i in self._adj[n] if self.__presence_test(n, i, t)])\n        except KeyError:\n            raise nx.NetworkXError(\"The node %s is not in the graph.\" % (n,))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef degree(self, nbunch=None, t=None):\n        if nbunch in self:  # return a single node\n            return next(self.degree_iter(nbunch, t))[1]\n        else:  # return a dict\n            return dict(self.degree_iter(nbunch, t))", "response": "Return the degree of a node or nodes at time t."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an iterator over the degree of the nodes in a given timeframe.", "response": "def degree_iter(self, nbunch=None, t=None):\n        \"\"\"Return an iterator for (node, degree) at time t.\n\n        The node degree is the number of edges adjacent to the node in a given timeframe.\n\n        Parameters\n        ----------\n        nbunch : iterable container, optional (default=all nodes)\n            A container of nodes.  The container will be iterated\n            through once.\n\n        t : snapshot id (default=None)\n            If None will be returned an iterator over the degree of nodes on the flattened graph.\n\n\n        Returns\n        -------\n        nd_iter : an iterator\n            The iterator returns two-tuples of (node, degree).\n\n        See Also\n        --------\n        degree\n\n        Examples\n        --------\n        >>> G = dn.DynGraph()\n        >>> G.add_path([0,1,2,3], t=0)\n        >>> list(G.degree_iter(0, t=0))\n        [(0, 1)]\n        >>> list(G.degree_iter([0,1], t=0))\n        [(0, 1), (1, 2)]\n        \"\"\"\n        if nbunch is None:\n            nodes_nbrs = self._adj.items()\n        else:\n            nodes_nbrs = ((n, self._adj[n]) for n in self.nbunch_iter(nbunch))\n\n        if t is None:\n            for n, nbrs in nodes_nbrs:\n                deg = len(self._adj[n])\n                yield (n, deg)\n        else:\n            for n, nbrs in nodes_nbrs:\n                edges_t = len([v for v in nbrs.keys() if self.__presence_test(n, v, t)])\n                if edges_t > 0:\n                    yield (n, edges_t)\n                else:\n                    yield (n, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef size(self, t=None):\n        s = sum(self.degree(t=t).values()) / 2\n        return int(s)", "response": "Return the number of edges at time t."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the number of nodes in the t snpashot of a dynamic graph.", "response": "def number_of_nodes(self, t=None):\n        \"\"\"Return the number of nodes in the t snpashot of a dynamic graph.\n\n        Parameters\n        ----------\n        t : snapshot id (default=None)\n               If None return the number of nodes in the flattened graph.\n\n\n        Returns\n        -------\n        nnodes : int\n            The number of nodes in the graph.\n\n        See Also\n        --------\n        order  which is identical\n\n        Examples\n        --------\n        >>> G = dn.DynGraph()   # or DiGraph, MultiGraph, MultiDiGraph, etc\n        >>> G.add_path([0,1,2], t=0)\n        >>> G.number_of_nodes(0)\n        3\n        \"\"\"\n        if t is None:\n            return len(self._node)\n        else:\n            nds = sum([1 for n in self.degree(t=t).values() if n > 0])\n            return nds"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the graph at time t contains the node n.", "response": "def has_node(self, n, t=None):\n        \"\"\"Return True if the graph, at time t, contains the node n.\n\n        Parameters\n        ----------\n        n : node\n        t : snapshot id (default None)\n                If None return the presence of the node in the flattened graph.\n\n        Examples\n        --------\n        >>> G = dn.DynGraph()   # or DiGraph, MultiGraph, MultiDiGraph, etc\n        >>> G.add_path([0,1,2], t=0)\n        >>> G.has_node(0, t=0)\n        True\n\n        It is more readable and simpler to use\n\n        >>> 0 in G\n        True\n\n        \"\"\"\n        if t is None:\n            try:\n                return n in self._node\n            except TypeError:\n                return False\n        else:\n            deg = list(self.degree([n], t).values())\n            if len(deg) > 0:\n                return deg[0] > 0\n            else:\n                return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_star(self, nodes, t=None):\n        nlist = list(nodes)\n        v = nlist[0]\n        interaction = ((v, n) for n in nlist[1:])\n        self.add_interactions_from(interaction, t)", "response": "Add a star at time t."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a path at time t.", "response": "def add_path(self, nodes, t=None):\n        \"\"\"Add a path at time t.\n\n        Parameters\n        ----------\n        nodes : iterable container\n            A container of nodes.\n        t : snapshot id (default=None)\n\n        See Also\n        --------\n        add_path, add_cycle\n\n        Examples\n        --------\n        >>> G = dn.DynGraph()\n        >>> G.add_path([0,1,2,3], t=0)\n        \"\"\"\n        nlist = list(nodes)\n        interaction = zip(nlist[:-1], nlist[1:])\n        self.add_interactions_from(interaction, t)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_directed(self):\n        from .dyndigraph import DynDiGraph\n        G = DynDiGraph()\n        G.name = self.name\n        G.add_nodes_from(self)\n        for it in self.interactions_iter():\n            for t in it[2]['t']:\n                G.add_interaction(it[0], it[1], t=t[0], e=t[1])\n\n        G.graph = deepcopy(self.graph)\n        G._node = deepcopy(self._node)\n        return G", "response": "Return a directed representation of the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stream_interactions(self):\n        timestamps = sorted(self.time_to_edge.keys())\n        for t in timestamps:\n            for e in self.time_to_edge[t]:\n                yield (e[0], e[1], e[2], t)", "response": "Generate a temporal ordered stream of interactions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef time_slice(self, t_from, t_to=None):\n        # create new graph and copy subgraph into it\n        H = self.__class__()\n\n        if t_to is not None:\n            if t_to < t_from:\n                raise ValueError(\"Invalid range: t_to must be grater that t_from\")\n        else:\n            t_to = t_from\n\n        for u, v, ts in self.interactions_iter():\n            I = t_to\n            F = t_from\n\n            for a, b in ts['t']:\n                if I <= a and b <= F:\n                    H.add_interaction(u, v, a, b)\n                elif a <= I and F <= b:\n                    H.add_interaction(u, v, I, F)\n                elif a <= I <= b and b <= F:\n                    H.add_interaction(u, v, I, b)\n                elif I <= a <= F and F <= b:\n                    H.add_interaction(u, v, a, F)\n        return H", "response": "Return a DynGraph object containing nodes and interactions present in the given time slice."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interactions_per_snapshots(self, t=None):\n        if t is None:\n            return {k: v / 2 for k, v in self.snapshots.items()}\n        else:\n            try:\n                return self.snapshots[t] / 2\n            except KeyError:\n                return 0", "response": "Return the number of interactions within a single snapshot t."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the inter event time distribution of interactions involving u and v.", "response": "def inter_event_time_distribution(self, u=None, v=None):\n        \"\"\"Return the distribution of inter event time.\n        If u and v are None the dynamic graph intere event distribution is returned.\n        If u is specified the inter event time distribution of interactions involving u is returned.\n        If u and v are specified the inter event time distribution of (u, v) interactions is returned\n\n        Parameters\n        ----------\n\n        u : node id\n        v : node id\n\n        Returns\n        -------\n\n        nd : dictionary\n            A dictionary from inter event time to number of occurrences\n\n        \"\"\"\n        dist = {}\n        if u is None:\n            # global inter event\n            first = True\n            delta = None\n            for ext in self.stream_interactions():\n                if first:\n                    delta = ext\n                    first = False\n                    continue\n                disp = ext[-1] - delta[-1]\n                delta = ext\n                if disp in dist:\n                    dist[disp] += 1\n                else:\n                    dist[disp] = 1\n\n        elif u is not None and v is None:\n            # node inter event\n            delta = (0, 0, 0, 0)\n            flag = False\n            for ext in self.stream_interactions():\n                if ext[0] == u or ext[1] == u:\n                    if flag:\n                        disp = ext[-1] - delta[-1]\n                        delta = ext\n                        if disp in dist:\n                            dist[disp] += 1\n                        else:\n                            dist[disp] = 1\n                    else:\n                        delta = ext\n                        flag = True\n        else:\n            # interaction inter event\n            evt = self._adj[u][v]['t']\n            delta = []\n\n            for i in evt:\n                if i[0] != i[1]:\n                    for j in [0, 1]:\n                        delta.append(i[j])\n                else:\n                    delta.append(i[0])\n\n            if len(delta) == 2 and delta[0] == delta[1]:\n                return {}\n\n            for i in range(0, len(delta) - 1):\n                e = delta[i + 1] - delta[i]\n                if e not in dist:\n                    dist[e] = 1\n                else:\n                    dist[e] += 1\n\n        return dist"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator over the degree of the node in a given timeframe.", "response": "def degree_iter(self, nbunch=None, t=None):\n        \"\"\"Return an iterator for (node, degree) at time t.\n\n            The node degree is the number of edges adjacent to the node in a given timeframe.\n\n            Parameters\n            ----------\n            nbunch : iterable container, optional (default=all nodes)\n                A container of nodes.  The container will be iterated\n                through once.\n\n            t : snapshot id (default=None)\n                If None will be returned an iterator over the degree of nodes on the flattened graph.\n\n\n            Returns\n            -------\n            nd_iter : an iterator\n                The iterator returns two-tuples of (node, degree).\n\n            See Also\n            --------\n            degree\n\n            Examples\n            --------\n            >>> G = dn.DynDiGraph()\n            >>> G.add_interaction(0, 1, t=0)\n            >>> list(G.degree_iter(0, t=0))\n            [(0, 1)]\n            >>> list(G.degree_iter([0,1], t=0))\n            [(0, 1), (1, 1)]\n            \"\"\"\n\n        if nbunch is None:\n            nodes_nbrs = ((n, succs, self._pred[n]) for n, succs in self._succ.items())\n        else:\n            nodes_nbrs = ((n, self._succ[n], self._pred[n]) for n in self.nbunch_iter(nbunch))\n\n        if t is None:\n            for n, succ, pred in nodes_nbrs:\n                yield (n, len(succ) + len(pred))\n\n        else:\n            for n, succ, pred in nodes_nbrs:\n                edges_succ = len([v for v in succ.keys() if self.__presence_test(n, v, t)])\n                edges_pred = len([v for v in pred.keys() if self.__presence_test(v, n, t)])\n                yield (n, edges_succ + edges_pred)"}
