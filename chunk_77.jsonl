{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch(self):\n        resp = self.r_session.get(self.document_url)\n        resp.raise_for_status()\n        self.clear()\n        self.update(response_to_json_dict(resp))", "response": "Fetches the content of the current security document from the remote database and populates the locally cached SecurityDocument object with that content."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the object to the remote database.", "response": "def save(self):\n        \"\"\"\n        Saves changes made to the locally cached SecurityDocument object's data\n        structures to the remote database.\n        \"\"\"\n        resp = self.r_session.put(\n            self.document_url,\n            data=self.json(),\n            headers={'Content-Type': 'application/json'}\n        )\n        resp.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xpm(Pdb=Pdb):\n    info = sys.exc_info()\n    print(traceback.format_exc())\n    post_mortem(info[2], Pdb)", "response": "A function that prints the traceback and logs it to the console."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle completions from fancycompleter and original pdb.", "response": "def complete(self, text, state):\n        \"\"\"Handle completions from fancycompleter and original pdb.\"\"\"\n        if state == 0:\n            local._pdbpp_completing = True\n            mydict = self.curframe.f_globals.copy()\n            mydict.update(self.curframe_locals)\n            completer = Completer(mydict)\n            self._completions = self._get_all_completions(\n                completer.complete, text)\n\n            real_pdb = super(Pdb, self)\n            for x in self._get_all_completions(real_pdb.complete, text):\n                if x not in self._completions:\n                    self._completions.append(x)\n\n            self._filter_completions(text)\n\n            del local._pdbpp_completing\n\n            # Remove \"\\t\" from fancycompleter if there are pdb completions.\n            if len(self._completions) > 1 and self._completions[0] == \"\\t\":\n                self._completions.pop(0)\n\n        try:\n            return self._completions[state]\n        except IndexError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_interact(self, arg):\n        ns = self.curframe.f_globals.copy()\n        ns.update(self.curframe_locals)\n        code.interact(\"*interactive*\", local=ns)", "response": "Start an interative interpreter whose global namespace\n        contains all the names found in the current scope."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_track(self, arg):\n        try:\n            from rpython.translator.tool.reftracker import track\n        except ImportError:\n            print('** cannot import pypy.translator.tool.reftracker **',\n                  file=self.stdout)\n            return\n        try:\n            val = self._getval(arg)\n        except:\n            pass\n        else:\n            track(val)", "response": "Display a graph showing which objects are referred by the specified expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays the value of the key - value entry in the log.", "response": "def do_display(self, arg):\n        \"\"\"\n        display expression\n\n        Add expression to the display list; expressions in this list\n        are evaluated at each step, and printed every time its value\n        changes.\n\n        WARNING: since the expressions is evaluated multiple time, pay\n        attention not to put expressions with side-effects in the\n        display list.\n        \"\"\"\n        try:\n            value = self._getval_or_undefined(arg)\n        except:\n            return\n        self._get_display_list()[arg] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_undisplay(self, arg):\n        try:\n            del self._get_display_list()[arg]\n        except KeyError:\n            print('** %s not in the display list **' % arg, file=self.stdout)", "response": "Undisplay an expression from the display list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the sticky flag of the current locale.", "response": "def do_sticky(self, arg):\n        \"\"\"\n        sticky [start end]\n\n        Toggle sticky mode. When in sticky mode, it clear the screen\n        and longlist the current functions, making the source\n        appearing always in the same position. Useful to follow the\n        flow control of a function when doing step-by-step execution.\n\n        If ``start`` and ``end`` are given, sticky mode is enabled and\n        only lines within that range (extremes included) will be\n        displayed.\n        \"\"\"\n        if arg:\n            try:\n                start, end = map(int, arg.split())\n            except ValueError:\n                print('** Error when parsing argument: %s **' % arg,\n                      file=self.stdout)\n                return\n            self.sticky = True\n            self.sticky_ranges[self.curframe] = start, end+1\n        else:\n            self.sticky = not self.sticky\n            self.sticky_range = None\n        self._print_if_sticky()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens an editor visiting the current file at the current line", "response": "def do_edit(self, arg):\n        \"Open an editor visiting the current file at the current line\"\n        if arg == '':\n            filename, lineno = self._get_current_position()\n        else:\n            filename, lineno, _ = self._get_position_of_arg(arg)\n            if filename is None:\n                return\n        # this case handles code generated with py.code.Source()\n        # filename is something like '<0-codegen foo.py:18>'\n        match = re.match(r'.*<\\d+-codegen (.*):(\\d+)>', filename)\n        if match:\n            filename = match.group(1)\n            lineno = int(match.group(2))\n\n        try:\n            self._open_editor(self._get_editor_cmd(filename, lineno))\n        except Exception as exc:\n            self.error(exc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremember starting frame. This is used with pytest which does not use pdb. set_trace.", "response": "def set_trace(self, frame=None):\n        \"\"\"Remember starting frame.\n\n        This is used with pytest, which does not use pdb.set_trace().\n        \"\"\"\n        if hasattr(local, '_pdbpp_completing'):\n            # Handle set_trace being called during completion, e.g. with\n            # fancycompleter's attr_matches.\n            return\n        if frame is None:\n            frame = sys._getframe().f_back\n        self._via_set_trace_frame = frame\n        return super(Pdb, self).set_trace(frame)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_skipped_module(self, module_name):\n        if module_name is None:\n            return False\n        return super(Pdb, self).is_skipped_module(module_name)", "response": "Check if the module_name is skipped."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef error(self, msg):\n        print(\"***\", msg, file=self.stdout)\n\n        if not self.config.show_traceback_on_error:\n            return\n\n        etype, evalue, tb = sys.exc_info()\n        if tb and tb.tb_frame.f_code.co_name == \"default\":\n            tb = tb.tb_next\n            if tb and tb.tb_frame.f_code.co_filename == \"<stdin>\":\n                tb = tb.tb_next\n                if tb:  # only display with actual traceback.\n                    self._remove_bdb_context(evalue)\n                    tb_limit = self.config.show_traceback_on_error_limit\n                    fmt_exc = traceback.format_exception(\n                        etype, evalue, tb, limit=tb_limit\n                    )\n\n                    # Remove last line (exception string again).\n                    if len(fmt_exc) > 1 and fmt_exc[-1][0] != \" \":\n                        fmt_exc.pop()\n\n                    print(\"\".join(fmt_exc).rstrip(), file=self.stdout)", "response": "Override default error method to display tracebacks."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _remove_bdb_context(evalue):\n        removed_bdb_context = evalue\n        while removed_bdb_context.__context__:\n            ctx = removed_bdb_context.__context__\n            if (\n                isinstance(ctx, AttributeError)\n                and ctx.__traceback__.tb_frame.f_code.co_name == \"onecmd\"\n            ):\n                removed_bdb_context.__context__ = None\n                break\n            removed_bdb_context = removed_bdb_context.__context__", "response": "Remove exception context from Pdb from the exception."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_kwargs(func, **kwargs):\n    new_kwargs = {}\n    params = signature(func).parameters\n    for param_name in params.keys():\n        if param_name in kwargs:\n            new_kwargs[param_name] = kwargs[param_name]\n    return func(**new_kwargs)", "response": "Call func with kwargs but only those kwargs that it accepts."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the current process memory usage in MB.", "response": "def memory_usage_psutil():\n    \"\"\"Return the current process memory usage in MB.\n    \"\"\"\n    process = psutil.Process(os.getpid())\n    mem = process.memory_info()[0] / float(2 ** 20)\n    mem_vms = process.memory_info()[1] / float(2 ** 20)\n    return mem, mem_vms"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export_cmd(argv=sys.argv[1:]):  # pragma: no cover\n    arguments = docopt(export_cmd.__doc__, argv=argv)\n    model_version = export(\n        model_version=arguments['--version'],\n        activate=not arguments['--no-activate'],\n        )\n    logger.info(\"Exported model. New version number: {}\".format(model_version))", "response": "\\ Export a model from one model persister to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nallows the use of partially applied functions in the configuration.", "response": "def Partial(func, **kwargs):\n    \"\"\"Allows the use of partially applied functions in the\n    configuration.\n    \"\"\"\n    if isinstance(func, str):\n        func = resolve_dotted_name(func)\n    partial_func = partial(func, **kwargs)\n    update_wrapper(partial_func, func)\n    return partial_func"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode the given object to json and wraps it in a Flask response.", "response": "def make_ujson_response(obj, status_code=200):\n    \"\"\"Encodes the given *obj* to json and wraps it in a response.\n\n    :return:\n      A Flask response.\n    \"\"\"\n    json_encoded = ujson.encode(obj, ensure_ascii=False, double_precision=-1)\n    resp = make_response(json_encoded)\n    resp.mimetype = 'application/json'\n    resp.content_type = 'application/json; charset=utf-8'\n    resp.status_code = status_code\n    return resp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_predict_function(\n        route, predict_service, decorator_list_name, config):\n    \"\"\"Creates a predict function and registers it to\n    the Flask app using the route decorator.\n\n    :param str route:\n      Path of the entry point.\n\n    :param palladium.interfaces.PredictService predict_service:\n      The predict service to be registered to this entry point.\n\n    :param str decorator_list_name:\n      The decorator list to be used for this predict service. It is\n      OK if there is no such entry in the active Palladium config.\n\n    :return:\n      A predict service function that will be used to process\n      predict requests.\n    \"\"\"\n    model_persister = config.get('model_persister')\n\n    @app.route(route, methods=['GET', 'POST'], endpoint=route)\n    @PluggableDecorator(decorator_list_name)\n    def predict_func():\n        return predict(model_persister, predict_service)\n\n    return predict_func", "response": "Creates a predict function and registers it to the Flask app using the route decorator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef devserver_cmd(argv=sys.argv[1:]):  # pragma: no cover\n    arguments = docopt(devserver_cmd.__doc__, argv=argv)\n    initialize_config()\n    app.run(\n        host=arguments['--host'],\n        port=int(arguments['--port']),\n        debug=int(arguments['--debug']),\n        )", "response": "\\ Several command line interface for development."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stream_cmd(argv=sys.argv[1:]):  # pragma: no cover\n    docopt(stream_cmd.__doc__, argv=argv)\n    initialize_config()\n    stream = PredictStream()\n    stream.listen(sys.stdin, sys.stdout, sys.stderr)", "response": "\\ A function which starts a streaming server which processes line\nby line and returns predictions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sample_from_data(self, model, data):\n        values = []\n        for key, type_name in self.mapping:\n            value_type = self.types[type_name]\n            values.append(value_type(data[key]))\n        if self.unwrap_sample:\n            assert len(values) == 1\n            return np.array(values[0])\n        else:\n            return np.array(values, dtype=object)", "response": "Convert incoming sample data into a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef params_from_data(self, model, data):\n        params = {}\n        for key, type_name in self.params:\n            value_type = self.types[type_name]\n            if key in data:\n                params[key] = value_type(data[key])\n            elif hasattr(model, key):\n                params[key] = getattr(model, key)\n        return params", "response": "Retrieve additional parameters for the current model from request data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nturn a model s prediction in y_pred into a JSON response.", "response": "def response_from_prediction(self, y_pred, single=True):\n        \"\"\"Turns a model's prediction in *y_pred* into a JSON\n        response.\n        \"\"\"\n        result = y_pred.tolist()\n        if single:\n            result = result[0]\n        response = {\n            'metadata': get_metadata(),\n            'result': result,\n            }\n        return make_ujson_response(response, status_code=200)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlistening to provided io stream and writes predictions to output.", "response": "def listen(self, io_in, io_out, io_err):\n        \"\"\"Listens to provided io stream and writes predictions\n        to output. In case of errors, the error stream will be used.\n        \"\"\"\n        for line in io_in:\n            if line.strip().lower() == 'exit':\n                break\n\n            try:\n                y_pred = self.process_line(line)\n            except Exception as e:\n                io_out.write('[]\\n')\n                io_err.write(\n                    \"Error while processing input row: {}\"\n                    \"{}: {}\\n\".format(line, type(e), e))\n                io_err.flush()\n            else:\n                io_out.write(ujson.dumps(y_pred.tolist()))\n                io_out.write('\\n')\n                io_out.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef admin_cmd(argv=sys.argv[1:]):  # pragma: no cover\n    arguments = docopt(admin_cmd.__doc__, argv=argv)\n    initialize_config(__mode__='fit')\n    if arguments['activate']:\n        activate(model_version=int(arguments['<version>']))\n    elif arguments['delete']:\n        delete(model_version=int(arguments['<version>']))", "response": "\\ admin_cmd - admin command line interface for all\n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef grid_search_cmd(argv=sys.argv[1:]):  # pragma: no cover\n    arguments = docopt(grid_search_cmd.__doc__, argv=argv)\n    initialize_config(__mode__='fit')\n    grid_search(\n        save_results=arguments['--save-results'],\n        persist_best=arguments['--persist-best'],\n        )", "response": "\\ Sequences of the grid search command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat exception message + cause", "response": "def error_message(e, message=None, cause=None):\n    \"\"\"\n    Formats exception message + cause\n    :param e:\n    :param message:\n    :param cause:\n    :return: formatted message, includes cause if any is set\n    \"\"\"\n    if message is None and cause is None:\n        return None\n    elif message is None:\n        return '%s, caused by %r' % (e.__class__, cause)\n    elif cause is None:\n        return message\n    else:\n        return '%s, caused by %r' % (message, cause)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat PGP key in 16hex digits.", "response": "def format_pgp_key(key):\n    \"\"\"\n    Formats PGP key in 16hex digits\n    :param key:\n    :return:\n    \"\"\"\n    if key is None:\n        return None\n    if isinstance(key, (int, long)):\n        return '%016x' % key\n    elif isinstance(key, list):\n        return [format_pgp_key(x) for x in key]\n    else:\n        key = key.strip()\n        key = strip_hex_prefix(key)\n        return format_pgp_key(int(key, 16))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the value of key in js if set otherwise default.", "response": "def defvalkey(js, key, default=None, take_none=True):\n    \"\"\"\n    Returns js[key] if set, otherwise default. Note js[key] can be None.\n    :param js:\n    :param key:\n    :param default:\n    :param take_none:\n    :return:\n    \"\"\"\n    if js is None:\n        return default\n    if key not in js:\n        return default\n    if js[key] is None and not take_none:\n        return default\n    return js[key]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndropping empty array element", "response": "def drop_empty(arr):\n    \"\"\"\n    Drop empty array element\n    :param arr:\n    :return:\n    \"\"\"\n    return [x for x in arr if not isinstance(x, list) or len(x) > 0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding results to the accumulator", "response": "def add_res(acc, elem):\n    \"\"\"\n    Adds results to the accumulator\n    :param acc:\n    :param elem:\n    :return:\n    \"\"\"\n    if not isinstance(elem, list):\n        elem = [elem]\n    if acc is None:\n        acc = []\n    for x in elem:\n        acc.append(x)\n    return acc"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to extract the OID from the X500 name.", "response": "def try_get_dn_part(subject, oid=None):\n    \"\"\"\n    Tries to extracts the OID from the X500 name.\n    :param subject:\n    :param oid:\n    :return:\n    \"\"\"\n    try:\n        if subject is None:\n            return None\n        if oid is None:\n            return None\n\n        for sub in subject:\n            if oid is not None and sub.oid == oid:\n                return sub.value\n    except:\n        pass\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to get the DN string from a subject.", "response": "def try_get_dn_string(subject, shorten=False):\n    \"\"\"\n    Returns DN as a string\n    :param subject:\n    :param shorten:\n    :return:\n    \"\"\"\n    try:\n        from cryptography.x509.oid import NameOID\n        from cryptography.x509 import ObjectIdentifier\n        oid_names = {\n            getattr(NameOID, 'COMMON_NAME', ObjectIdentifier(\"2.5.4.3\")): \"CN\",\n            getattr(NameOID, 'COUNTRY_NAME', ObjectIdentifier(\"2.5.4.6\")): \"C\",\n            getattr(NameOID, 'LOCALITY_NAME', ObjectIdentifier(\"2.5.4.7\")): \"L\",\n            getattr(NameOID, 'STATE_OR_PROVINCE_NAME', ObjectIdentifier(\"2.5.4.8\")): \"ST\",\n            getattr(NameOID, 'STREET_ADDRESS', ObjectIdentifier(\"2.5.4.9\")): \"St\",\n            getattr(NameOID, 'ORGANIZATION_NAME', ObjectIdentifier(\"2.5.4.10\")): \"O\",\n            getattr(NameOID, 'ORGANIZATIONAL_UNIT_NAME', ObjectIdentifier(\"2.5.4.11\")): \"OU\",\n            getattr(NameOID, 'SERIAL_NUMBER', ObjectIdentifier(\"2.5.4.5\")): \"SN\",\n            getattr(NameOID, 'USER_ID', ObjectIdentifier(\"0.9.2342.19200300.100.1.1\")): \"userID\",\n            getattr(NameOID, 'DOMAIN_COMPONENT', ObjectIdentifier(\"0.9.2342.19200300.100.1.25\")): \"domainComponent\",\n            getattr(NameOID, 'EMAIL_ADDRESS', ObjectIdentifier(\"1.2.840.113549.1.9.1\")): \"emailAddress\",\n            getattr(NameOID, 'POSTAL_CODE', ObjectIdentifier(\"2.5.4.17\")): \"ZIP\",\n        }\n\n        ret = []\n        try:\n            for attribute in subject:\n                oid = attribute.oid\n                dot = oid.dotted_string\n                oid_name = oid_names[oid] if shorten and oid in oid_names else oid._name\n                val = attribute.value\n                ret.append('%s: %s' % (oid_name, val))\n        except:\n            pass\n        return ', '.join(ret)\n\n    except Exception as e:\n        logger.warning('Unexpected error: %s' % e)\n        return 'N/A'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef startswith(haystack, prefix):\n    if haystack is None:\n        return None\n\n    if sys.version_info[0] < 3:\n        return haystack.startswith(prefix)\n\n    return to_bytes(haystack).startswith(to_bytes(prefix))", "response": "py3 comp startswith\n    :param haystack:\n    :param prefix:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert bytes to string", "response": "def to_string(x):\n    \"\"\"\n    Utf8 conversion\n    :param x:\n    :return:\n    \"\"\"\n    if isinstance(x, bytes):\n        return x.decode('utf-8')\n    if isinstance(x, basestring):\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a string or bytes object to bytes.", "response": "def to_bytes(x):\n    \"\"\"\n    Byte conv\n    :param x:\n    :return:\n    \"\"\"\n    if isinstance(x, bytes):\n        return x\n    if isinstance(x, basestring):\n        return x.encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contains(haystack, needle):\n    if sys.version_info[0] < 3:\n        return needle in haystack\n    else:\n        return to_bytes(needle) in to_bytes(haystack)", "response": "py3 contains\n    :param haystack:\n    :param needle:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstrip spaces from a sequence of bytes.", "response": "def strip_spaces(x):\n    \"\"\"\n    Strips spaces\n    :param x:\n    :return:\n    \"\"\"\n    x = x.replace(b' ', b'')\n    x = x.replace(b'\\t', b'')\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstrips PEM to bare base64 encoded form", "response": "def strip_pem(x):\n    \"\"\"\n    Strips PEM to bare base64 encoded form\n    :param x:\n    :return:\n    \"\"\"\n    if x is None:\n        return None\n\n    x = to_string(x)\n    pem = x.replace('-----BEGIN CERTIFICATE-----', '')\n    pem = pem.replace('-----END CERTIFICATE-----', '')\n    pem = re.sub(r'-----BEGIN .+?-----', '', pem)\n    pem = re.sub(r'-----END .+?-----', '', pem)\n    pem = pem.replace(' ', '')\n    pem = pem.replace('\\t', '')\n    pem = pem.replace('\\r', '')\n    pem = pem.replace('\\n', '')\n    return pem.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log(self, cause=None, do_message=True, custom_msg=None):\n        message = error_message(self, cause=cause)\n        exc_type, exc_value, exc_traceback = sys.exc_info()\n        traceback_formatted = traceback.format_exc()\n        traceback_val = traceback.extract_tb(exc_traceback)\n\n        md5 = hashlib.md5(traceback_formatted.encode('utf-8')).hexdigest()\n\n        if md5 in self._db:\n            # self.logger.debug('Exception trace logged: %s' % md5)\n            return\n\n        if custom_msg is not None and cause is not None:\n            self.logger.debug('%s : %s' % (custom_msg, cause))\n        elif custom_msg is not None:\n            self.logger.debug(custom_msg)\n        elif cause is not None:\n            self.logger.debug('%s' % cause)\n\n        self.logger.debug(traceback_formatted)\n        self._db.add(md5)", "response": "Log the current exception frame into the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fprint(self, modulus):\n        if modulus <= 2:\n            return False\n\n        d = DlogFprint.discrete_log(modulus, self.generator,\n                                    self.generator_order, self.generator_order_decomposition, self.m)\n        return d is not None", "response": "Returns True if fingerprint is present or detected."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning primorial and phi of all the keys in the current object.", "response": "def primorial(self, max_prime=167):\n        \"\"\"\n        Returns primorial (and its totient) with max prime inclusive - product of all primes below the value\n        :param max_prime:\n        :param dummy:\n        :return: primorial, phi(primorial)\n        \"\"\"\n        mprime = max(self.primes)\n        if max_prime > mprime:\n            raise ValueError('Current primorial implementation does not support values above %s' % mprime)\n\n        primorial = 1\n        phi_primorial = 1\n        for prime in self.primes:\n            primorial *= prime\n            phi_primorial *= prime - 1\n        return primorial, phi_primorial"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prime_factors(n, limit=None):\n        num = []\n\n        # add 2, 3 to list or prime factors and remove all even numbers(like sieve of ertosthenes)\n        while n % 2 == 0:\n            num.append(2)\n            n = n // 2\n\n        while n % 3 == 0:\n            num.append(3)\n            n = n // 3\n\n        max_divisor = int(math.ceil(n ** 0.5)) if limit is None else limit\n        d, i = 5, 2\n        while d <= max_divisor:\n            while n % d == 0:\n                num.append(d)\n                n = n // d\n\n            d += i\n            i = 6 - i  # this modifies 2 into 4 and vice versa\n\n        # if no is > 2 i.e no is a prime number that is only divisible by itself add it\n        if n > 2:\n            num.append(n)\n\n        return num", "response": "Simple trial division factorization of a set of log entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dict mapping factor names to power names.", "response": "def factor_list_to_map(factors):\n        \"\"\"\n        Factor list to map factor -> power\n        :param factors:\n        :return:\n        \"\"\"\n        ret = {}\n        for k, g in itertools.groupby(factors):\n            ret[k] = len(list(g))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the order of the element in Zmod ( modulus ).", "response": "def element_order(element, modulus, phi_m, phi_m_decomposition):\n        \"\"\"\n        Returns order of the element in Zmod(modulus)\n        :param element:\n        :param modulus:\n        :param phi_m: phi(modulus)\n        :param phi_m_decomposition: factorization of phi(modulus)\n        :return:\n        \"\"\"\n        if element == 1:\n            return 1  # by definition\n\n        if pow(element, phi_m, modulus) != 1:\n            return None  # not an element of the group\n\n        order = phi_m\n        for factor, power in list(phi_m_decomposition.items()):\n            for p in range(1, power + 1):\n                next_order = order // factor\n                if pow(element, next_order, modulus) == 1:\n                    order = next_order\n                else:\n                    break\n        return order"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chinese_remainder(n, a):\n        sum = 0\n        prod = reduce(lambda a, b: a * b, n)\n\n        for n_i, a_i in zip(n, a):\n            p = prod // n_i\n            sum += a_i * DlogFprint.mul_inv(p, n_i) * p\n        return sum % prod", "response": "Solves CRT for moduli and remainders\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfactorizes x up to max_prime limit.", "response": "def small_factors(x, max_prime):\n        \"\"\"\n        Factorizing x up to max_prime limit.\n        :param x:\n        :param max_prime:\n        :return:\n        \"\"\"\n        factors = DlogFprint.prime_factors(x, limit=max_prime)\n        return DlogFprint.factor_list_to_map(factors)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the fingerprint was detected in the key .", "response": "def has_fingerprint_moduli(self, modulus):\n        \"\"\"\n        Returns true if the fingerprint was detected in the key\n        :param modulus:\n        :return:\n        \"\"\"\n        if not self.is_acceptable_modulus(modulus):\n            return False\n\n        self.tested += 1\n        for i in range(0, len(self.primes)):\n            if (1 << (modulus % self.primes[i])) & self.prints[i] == 0:\n                return False\n\n        self.found += 1\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_fingerprint_dlog(self, modulus):\n        if not self.is_acceptable_modulus(modulus):\n            return False\n\n        self.tested += 1\n        positive = self.dlog_fprinter.fprint(modulus)\n\n        if positive:\n            self.found += 1\n\n        return positive", "response": "Returns True if the log of the log has a fingerprint of the given modulus False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nswitching main fingerprinting method.", "response": "def switch_fingerprint_method(self, old=False):\n        \"\"\"\n        Switches main fingerprinting method.\n\n        :param old: if True old fingerprinting method will be used.\n        :return:\n        \"\"\"\n        if old:\n            self.has_fingerprint = self.has_fingerprint_moduli\n        else:\n            self.has_fingerprint = self.has_fingerprint_dlog"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmark and add the effort for a given modulus into the given json_info dictionary.", "response": "def mark_and_add_effort(self, modulus, json_info):\n        \"\"\"\n        Inserts factorization effort for vulnerable modulus into json_info\n        :param modulus:\n        :param json_info:\n        :return:\n        \"\"\"\n        META_AMZ_FACT = 92. / 152.  # conversion from university cluster to AWS\n        AMZ_C4_PRICE = 0.1  # price of 2 AWS CPUs per hour\n\n        length = int(ceil(log(modulus, 2)))\n        length_ceiling = int(ceil(length / 32)) * 32\n\n        if length_ceiling in self.length_to_time_years:\n            effort_time = self.length_to_time_years[length_ceiling]\n        else:\n            effort_time = -1\n        if effort_time > 0:\n            effort_time *= META_AMZ_FACT  # scaling to more powerful AWS CPU\n            effort_price = effort_time * 365.25 * 24 * 0.5 * AMZ_C4_PRICE\n        else:\n            effort_price = -1\n        json_info['marked'] = True\n        json_info['time_years'] = effort_time\n        json_info['price_aws_c4'] = effort_price\n        return json_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_matches_extensions(self, fname, extensions):\n        if not isinstance(extensions, list):\n            extensions = [extensions]\n        for ext in extensions:\n            if fname.endswith('.%s' % ext):\n                return True\n        return False", "response": "Returns True if file fname matches one of extensions\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_inputs(self):\n        ret = []\n        files = self.args.files\n        if files is None:\n            return ret\n\n        for fname in files:\n            if fname == '-':\n                if self.args.base64stdin:\n                    for line in sys.stdin:\n                        data = base64.b64decode(line)\n                        ret.append(self.process_file(data, fname))\n\n                    continue\n                else:\n                    fh = sys.stdin\n\n            elif fname.endswith('.tar') or fname.endswith('.tar.gz'):\n                sub = self.process_tar(fname)\n                ret.append(sub)\n                continue\n\n            elif not os.path.isfile(fname):\n                sub = self.process_dir(fname)\n                ret.append(sub)\n                continue\n\n            else:\n                fh = open(fname, 'rb')\n\n            with fh:\n                data = fh.read()\n                sub = self.process_file(data, fname)\n                ret.append(sub)\n\n        return ret", "response": "Processes input data\nSetException"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_tar(self, fname):\n        import tarfile  # lazy import, only when needed\n        ret = []\n        with tarfile.open(fname) as tr:\n            members = tr.getmembers()\n            for member in members:\n                if not member.isfile():\n                    continue\n                fh = tr.extractfile(member)\n                sub = self.process_file(fh.read(), member.name)\n                ret.append(sub)\n        return ret", "response": "Process a tar file and return a list of the related items"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_dir(self, dirname):\n        ret = []\n        sub_rec = [f for f in os.listdir(dirname)]\n        for fname in sub_rec:\n            full_path = os.path.join(dirname, fname)\n\n            if os.path.isfile(full_path):\n                with open(full_path, 'rb') as fh:\n                    sub = self.process_file(fh.read(), fname)\n                    ret.append(sub)\n\n            elif os.path.isdir(full_path):\n                sub = self.process_dir(full_path)\n                ret.append(sub)\n        return ret", "response": "Directory processing\n        :param dirname:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses a single file and returns a list of the related objects.", "response": "def process_file(self, data, name):\n        \"\"\"\n        Processes a single file\n        :param data:\n        :param name:\n        :return:\n        \"\"\"\n        try:\n            return self.process_file_autodetect(data, name)\n\n        except Exception as e:\n            logger.debug('Exception processing file %s : %s' % (name, e))\n            self.trace_logger.log(e)\n\n        # autodetection fallback - all formats\n        ret = []\n        logger.debug('processing %s as PEM' % name)\n        ret.append(self.process_pem(data, name))\n\n        logger.debug('processing %s as DER' % name)\n        ret.append(self.process_der(data, name))\n\n        logger.debug('processing %s as PGP' % name)\n        ret.append(self.process_pgp(data, name))\n\n        logger.debug('processing %s as SSH' % name)\n        ret.append(self.process_ssh(data, name))\n\n        logger.debug('processing %s as JSON' % name)\n        ret.append(self.process_json(data, name))\n\n        logger.debug('processing %s as APK' % name)\n        ret.append(self.process_apk(data, name))\n\n        logger.debug('processing %s as MOD' % name)\n        ret.append(self.process_mod(data, name))\n\n        logger.debug('processing %s as LDIFF' % name)\n        ret.append(self.process_ldiff(data, name))\n\n        logger.debug('processing %s as JKS' % name)\n        ret.append(self.process_jks(data, name))\n\n        logger.debug('processing %s as PKCS7' % name)\n        ret.append(self.process_pkcs7(data, name))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_file_autodetect(self, data, name):\n        is_ssh_file = startswith(data, 'ssh-rsa') or contains(data, 'ssh-rsa ')\n        is_pgp_file = startswith(data, '-----BEGIN PGP')\n        is_pkcs7_file = startswith(data, '-----BEGIN PKCS7')\n        is_pem_file = startswith(data, '-----BEGIN') and not is_pgp_file\n        is_ldiff_file = contains(data, 'binary::')\n\n        is_pgp = is_pgp_file or (self.file_matches_extensions(name, ['pgp', 'gpg', 'key', 'pub', 'asc'])\n                                 and not is_ssh_file\n                                 and not is_pem_file)\n        is_pgp |= self.args.file_pgp\n\n        is_crt_ext = self.file_matches_extensions(name, ['der', 'crt', 'cer', 'cert', 'x509', 'key', 'pub', 'ca'])\n\n        is_pem = self.file_matches_extensions(name, 'pem') or is_pem_file\n        is_pem |= self.args.file_pem\n\n        is_der = not is_pem and not is_ssh_file and not is_pgp_file and is_crt_ext\n        is_der |= self.args.file_der\n\n        is_ssh = self.file_matches_extensions(name, ['ssh', 'pub']) or is_ssh_file\n        is_ssh |= self.args.file_ssh\n\n        is_apk = self.file_matches_extensions(name, 'apk')\n\n        is_mod = self.file_matches_extensions(name, ['txt', 'mod', 'mods', 'moduli'])\n        is_mod |= not is_pem and not is_der and not is_pgp and not is_ssh_file and not is_apk\n        is_mod |= self.args.file_mod\n\n        is_json = self.file_matches_extensions(name, ['json', 'js']) or startswith(data, '{') or startswith(data, '[')\n        is_json |= self.args.file_json\n\n        is_ldiff = self.file_matches_extensions(name, ['ldiff', 'ldap']) or is_ldiff_file\n        is_ldiff |= self.args.file_ldiff\n\n        is_jks = self.file_matches_extensions(name, ['jks', 'bks'])\n        is_pkcs7 = self.file_matches_extensions(name, ['pkcs7', 'p7s', 'p7'])\n        is_pkcs7 |= is_pkcs7_file\n        is_pkcs7 |= self.args.file_pkcs7\n\n        det = is_pem or is_der or is_pgp or is_ssh or is_mod or is_json or is_apk or is_ldiff or is_jks\n        ret = []\n        if is_pem:\n            logger.debug('processing %s as PEM' % name)\n            ret.append(self.process_pem(data, name))\n\n        if is_der:\n            logger.debug('processing %s as DER' % name)\n            ret.append(self.process_der(data, name))\n\n        if is_pgp:\n            logger.debug('processing %s as PGP' % name)\n            ret.append(self.process_pgp(data, name))\n\n        if is_ssh:\n            logger.debug('processing %s as SSH' % name)\n            ret.append(self.process_ssh(data, name))\n\n        if is_json:\n            logger.debug('processing %s as JSON' % name)\n            ret.append(self.process_json(data, name))\n\n        if is_apk:\n            logger.debug('processing %s as APK' % name)\n            ret.append(self.process_apk(data, name))\n\n        if is_mod:\n            logger.debug('processing %s as MOD' % name)\n            ret.append(self.process_mod(data, name))\n\n        if is_ldiff:\n            logger.debug('processing %s as LDIFF' % name)\n            ret.append(self.process_ldiff(data, name))\n\n        if is_jks:\n            logger.debug('processing %s as JKS' % name)\n            ret.append(self.process_jks(data, name))\n\n        if is_pkcs7:\n            logger.debug('processing %s as PKCS7' % name)\n            ret.append(self.process_pkcs7(data, name))\n\n        if not det:\n            logger.debug('Undetected (skipped) file: %s' % name)\n        return ret", "response": "Process a single file - format autodetection of the cache entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_pem(self, data, name):\n        try:\n            ret = []\n            data = to_string(data)\n            parts = re.split(r'-----BEGIN', data)\n            if len(parts) == 0:\n                return None\n\n            if len(parts[0]) == 0:\n                parts.pop(0)\n\n            crt_arr = ['-----BEGIN' + x for x in parts]\n            for idx, pem_rec in enumerate(crt_arr):\n                pem_rec = pem_rec.strip()\n                if len(pem_rec) == 0:\n                    continue\n\n                if startswith(pem_rec, '-----BEGIN CERTIFICATE REQUEST'):\n                    return self.process_pem_csr(pem_rec, name, idx)\n                elif startswith(pem_rec, '-----BEGIN CERTIF'):\n                    return self.process_pem_cert(pem_rec, name, idx)\n                elif startswith(pem_rec, '-----BEGIN '):  # fallback\n                    return self.process_pem_rsakey(pem_rec, name, idx)\n            return ret\n\n        except Exception as e:\n            logger.debug('Exception processing PEM file %s : %s' % (name, e))\n            self.trace_logger.log(e)\n        return None", "response": "Process PEM file and return a list of the records that are available in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_pem_cert(self, data, name, idx):\n        from cryptography.x509.base import load_der_x509_certificate\n        try:\n            x509 = load_der_x509_certificate(pem_to_der(data), self.get_backend())\n            self.num_pem_certs += 1\n            return self.process_x509(x509, name=name, idx=idx, data=data, pem=True, source='pem-cert')\n\n        except Exception as e:\n            logger.debug('PEM processing failed: %s' % e)\n            self.trace_logger.log(e)", "response": "Process PEM encoded certificate and store in self. num_pem_certs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_pem_csr(self, data, name, idx):\n        from cryptography.x509.base import load_der_x509_csr\n        try:\n            csr = load_der_x509_csr(pem_to_der(data), self.get_backend())\n            self.num_pem_csr += 1\n            return self.process_csr(csr, name=name, idx=idx, data=data, pem=True, source='pem-csr')\n\n        except Exception as e:\n            logger.debug('PEM processing failed: %s' % e)\n            self.trace_logger.log(e)", "response": "Process PEM encoded certificate request PKCS#10 and return a dict of certificate attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_pem_rsakey(self, data, name, idx):\n        from cryptography.hazmat.primitives.serialization import load_der_public_key\n        from cryptography.hazmat.primitives.serialization import load_der_private_key\n        try:\n            if startswith(data, '-----BEGIN RSA PUBLIC KEY') or startswith(data, '-----BEGIN PUBLIC KEY'):\n                rsa = load_der_public_key(pem_to_der(data), self.get_backend())\n                public_numbers = rsa.public_numbers()\n            elif startswith(data, '-----BEGIN RSA PRIVATE KEY') or startswith(data, '-----BEGIN PRIVATE KEY'):\n                rsa = load_der_private_key(pem_to_der(data), None, self.get_backend())\n                public_numbers = rsa.private_numbers().public_numbers\n            else:\n                return None\n            self.num_rsa_keys += 1\n            self.num_rsa += 1\n\n            js = collections.OrderedDict()\n            js['type'] = 'pem-rsa-key'\n            js['fname'] = name\n            js['idx'] = idx\n            js['pem'] = data\n            js['e'] = '0x%x' % public_numbers.e\n            js['n'] = '0x%x' % public_numbers.n\n\n            if self.has_fingerprint(public_numbers.n):\n                logger.warning('Fingerprint found in PEM RSA key %s ' % name)\n                self.mark_and_add_effort(public_numbers.n, js)\n\n                if self.do_print:\n                    print(json.dumps(js))\n\n            return TestResult(js)\n\n        except Exception as e:\n            logger.debug('Pubkey loading error: %s : %s [%s] : %s' % (name, idx, data[:20], e))\n            self.trace_logger.log(e)", "response": "Processes PEM encoded RSA key and returns a TestResult object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_der(self, data, name):\n        from cryptography.x509.base import load_der_x509_certificate\n        try:\n            x509 = load_der_x509_certificate(data, self.get_backend())\n            self.num_der_certs += 1\n            return self.process_x509(x509, name=name, pem=False, source='der-cert')\n\n        except Exception as e:\n            logger.debug('DER processing failed: %s : %s' % (name, e))\n            self.trace_logger.log(e)", "response": "DER processing\n        :param data:\n        :param name:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing a single X509 certificate and return a dictionary of the data that can be used to store the certificate in the cache.", "response": "def process_x509(self, x509, name, idx=None, data=None, pem=True, source='', aux=None):\n        \"\"\"\n        Processing parsed X509 certificate\n        :param x509:\n        :param name:\n        :param idx:\n        :param data:\n        :param pem:\n        :param source:\n        :param aux:\n        :return:\n        \"\"\"\n        if x509 is None:\n            return\n\n        from cryptography.hazmat.primitives import hashes\n        from cryptography.hazmat.primitives.asymmetric.rsa import RSAPublicKey\n        from cryptography.x509.oid import NameOID\n\n        pub = x509.public_key()\n        if not isinstance(pub, RSAPublicKey):\n            return\n\n        self.num_rsa += 1\n        pubnum = x509.public_key().public_numbers()\n\n        js = collections.OrderedDict()\n        js['type'] = source\n        js['fname'] = name\n        js['idx'] = idx\n        js['fprint'] = binascii.hexlify(x509.fingerprint(hashes.SHA256()))\n        js['subject'] = utf8ize(try_get_dn_string(x509.subject, shorten=True))\n        js['issuer'] = utf8ize(try_get_dn_string(x509.issuer, shorten=True))\n        js['issuer_org'] = utf8ize(try_get_dn_part(x509.issuer, NameOID.ORGANIZATION_NAME))\n        js['created_at'] = self.strtime(x509.not_valid_before)\n        js['created_at_utc'] = unix_time(x509.not_valid_before)\n        js['not_valid_after_utc'] = unix_time(x509.not_valid_after)\n        js['pem'] = data if pem else None\n        js['aux'] = aux\n        js['e'] = '0x%x' % pubnum.e\n        js['n'] = '0x%x' % pubnum.n\n\n        if self.has_fingerprint(pubnum.n):\n            logger.warning('Fingerprint found in the Certificate %s idx %s ' % (name, idx))\n            self.mark_and_add_effort(pubnum.n, js)\n\n            if self.do_print:\n                print(json.dumps(js))\n\n        return TestResult(js)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses a cryptography. x509. CertificateSigningRequest object and return a TestResult object.", "response": "def process_csr(self, csr, name, idx=None, data=None, pem=True, source='', aux=None):\n        \"\"\"\n        Processing parsed X509 csr\n        :param csr:\n        :type csr: cryptography.x509.CertificateSigningRequest\n        :param name:\n        :param idx:\n        :param data:\n        :param pem:\n        :param source:\n        :param aux:\n        :return:\n        \"\"\"\n        if csr is None:\n            return\n\n        from cryptography.hazmat.primitives.asymmetric.rsa import RSAPublicKey\n\n        pub = csr.public_key()\n        if not isinstance(pub, RSAPublicKey):\n            return\n\n        self.num_rsa += 1\n        pubnum = csr.public_key().public_numbers()\n\n        js = collections.OrderedDict()\n        js['type'] = source\n        js['fname'] = name\n        js['idx'] = idx\n        js['subject'] = utf8ize(try_get_dn_string(csr.subject, shorten=True))\n        js['pem'] = data if pem else None\n        js['aux'] = aux\n        js['e'] = '0x%x' % pubnum.e\n        js['n'] = '0x%x' % pubnum.n\n\n        if self.has_fingerprint(pubnum.n):\n            logger.warning('Fingerprint found in the CSR %s idx %s ' % (name, idx))\n            self.mark_and_add_effort(pubnum.n, js)\n\n            if self.do_print:\n                print(json.dumps(js))\n\n        return TestResult(js)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing a PGP key.", "response": "def process_pgp(self, data, name):\n        \"\"\"\n        PGP key processing\n        :param data:\n        :param name:\n        :return:\n        \"\"\"\n        ret = []\n        try:\n            data = to_string(data)\n            parts = re.split(r'-{5,}BEGIN', data)\n            if len(parts) == 0:\n                return\n\n            if len(parts[0]) == 0:\n                parts.pop(0)\n\n            crt_arr = ['-----BEGIN' + x for x in parts]\n            for idx, pem_rec in enumerate(crt_arr):\n                try:\n                    pem_rec = pem_rec.strip()\n                    if len(pem_rec) == 0:\n                        continue\n\n                    ret.append(self.process_pgp_raw(pem_rec.encode(), name, idx))\n\n                except Exception as e:\n                    logger.error('Exception in processing PGP rec file %s: %s' % (name, e))\n                    self.trace_logger.log(e)\n\n        except Exception as e:\n            logger.error('Exception in processing PGP file %s: %s' % (name, e))\n            self.trace_logger.log(e)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_pgp_raw(self, data, name, file_idx=None):\n        try:\n            from pgpdump.data import AsciiData\n            from pgpdump.packet import SignaturePacket, PublicKeyPacket, PublicSubkeyPacket, UserIDPacket\n\n        except Exception as e:\n            logger.warning('Could not import pgpdump, try running: pip install pgpdump')\n            return [TestResult(fname=name, type='pgp', error='cannot-import')]\n\n        ret = []\n        js_base = collections.OrderedDict()\n\n        pgp_key_data = AsciiData(data)\n        packets = list(pgp_key_data.packets())\n        self.num_pgp_masters += 1\n\n        master_fprint = None\n        master_key_id = None\n        identities = []\n        pubkeys = []\n        sign_key_ids = []\n        sig_cnt = 0\n        for idx, packet in enumerate(packets):\n            if isinstance(packet, PublicKeyPacket):\n                master_fprint = packet.fingerprint\n                master_key_id = format_pgp_key(packet.key_id)\n                pubkeys.append(packet)\n            elif isinstance(packet, PublicSubkeyPacket):\n                pubkeys.append(packet)\n            elif isinstance(packet, UserIDPacket):\n                identities.append(packet)\n            elif isinstance(packet, SignaturePacket):\n                sign_key_ids.append(packet.key_id)\n                sig_cnt += 1\n\n        # Names / identities\n        ids_arr = []\n        identity = None\n        for packet in identities:\n            idjs = collections.OrderedDict()\n            idjs['name'] = packet.user_name\n            idjs['email'] = packet.user_email\n            ids_arr.append(idjs)\n\n            if identity is None:\n                identity = '%s <%s>' % (packet.user_name, packet.user_email)\n\n        js_base['type'] = 'pgp'\n        js_base['fname'] = name\n        js_base['fname_idx'] = file_idx\n        js_base['master_key_id'] = master_key_id\n        js_base['master_fprint'] = master_fprint\n        js_base['identities'] = ids_arr\n        js_base['signatures_count'] = sig_cnt\n        js_base['packets_count'] = len(packets)\n        js_base['keys_count'] = len(pubkeys)\n        js_base['signature_keys'] = list(set(sign_key_ids))\n\n        # Public keys processing\n        for packet in pubkeys:\n            try:\n                self.num_pgp_total += 1\n                if packet.modulus is None:\n                    continue\n\n                self.num_rsa += 1\n                js = collections.OrderedDict(js_base)\n                js['created_at'] = self.strtime(packet.creation_time)\n                js['created_at_utc'] = unix_time(packet.creation_time)\n                js['is_master'] = master_fprint == packet.fingerprint\n                js['kid'] = format_pgp_key(packet.key_id)\n                js['bitsize'] = packet.modulus_bitlen\n                js['master_kid'] = master_key_id\n                js['e'] = '0x%x' % packet.exponent\n                js['n'] = '0x%x' % packet.modulus\n\n                if self.has_fingerprint(packet.modulus):\n                    self.mark_and_add_effort(packet.modulus, js)\n                    logger.warning('Fingerprint found in PGP key %s key ID 0x%s' % (name, js['kid']))\n\n                    if self.do_print:\n                        print(json.dumps(js))\n\n                ret.append(TestResult(js))\n\n            except Exception as e:\n                logger.error('Excetion in processing the key: %s' % e)\n                self.trace_logger.log(e)\n        return ret", "response": "Processes single PGP key and returns a list of TestResult objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_ssh(self, data, name):\n        if data is None or len(data) == 0:\n            return\n\n        ret = []\n        try:\n            lines = [x.strip() for x in data.split(b'\\n')]\n            for idx, line in enumerate(lines):\n                ret.append(self.process_ssh_line(line, name, idx))\n\n        except Exception as e:\n            logger.debug('Exception in processing SSH public key %s : %s' % (name, e))\n            self.trace_logger.log(e)\n        return ret", "response": "Processes SSH keys\n        :param data:\n        :param name:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess a single SSH key in the file.", "response": "def process_ssh_line(self, data, name, idx):\n        \"\"\"\n        Processes single SSH key\n        :param data:\n        :param name:\n        :param idx:\n        :return:\n        \"\"\"\n        data = data.strip()\n        if not contains(data, 'ssh-rsa'):\n            return\n\n        # strip ssh params / adjustments\n        try:\n            data = data[to_bytes(data).find(b'ssh-rsa'):]\n        except Exception as e:\n            pass\n\n        from cryptography.hazmat.primitives.serialization import load_ssh_public_key\n        from cryptography.hazmat.primitives.asymmetric.rsa import RSAPublicKey\n        try:\n            key_obj = load_ssh_public_key(data, self.get_backend())\n            self.num_ssh += 1\n\n            if not isinstance(key_obj, RSAPublicKey):\n                return\n\n            self.num_rsa += 1\n            numbers = key_obj.public_numbers()\n\n            js = collections.OrderedDict()\n            js['type'] = 'ssh-rsa'\n            js['fname'] = name\n            js['idx'] = idx\n            js['e'] = '0x%x' % numbers.e\n            js['n'] = '0x%x' % numbers.n\n            js['ssh'] = data\n\n            if self.has_fingerprint(numbers.n):\n                logger.warning('Fingerprint found in the SSH key %s idx %s ' % (name, idx))\n                self.mark_and_add_effort(numbers.n, js)\n\n                if self.do_print:\n                    print(json.dumps(js))\n\n            return TestResult(js)\n\n        except Exception as e:\n            logger.debug('Exception in processing SSH public key %s idx %s : %s' % (name, idx, e))\n            self.trace_logger.log(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses a single json line", "response": "def process_json_line(self, data, name, idx):\n        \"\"\"\n        Processes single json line\n        :param data:\n        :param name:\n        :param idx:\n        :return:\n        \"\"\"\n        data = data.strip()\n        if len(data) == 0:\n            return\n\n        ret = []\n        try:\n            js = json.loads(data)\n            self.num_json += 1\n            ret.append(self.process_json_rec(js, name, idx, []))\n\n        except Exception as e:\n            logger.debug('Exception in processing JSON %s idx %s : %s' % (name, idx, e))\n            self.trace_logger.log(e)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_json_rec(self, data, name, idx, sub_idx):\n        ret = []\n        if isinstance(data, list):\n            for kidx, rec in enumerate(data):\n                sub = self.process_json_rec(rec, name, idx, list(sub_idx + [kidx]))\n                ret.append(sub)\n            return ret\n\n        if isinstance(data, dict):\n            for key in data:\n                rec = data[key]\n                sub = self.process_json_rec(rec, name, idx, list(sub_idx + [rec]))\n                ret.append(sub)\n\n            if 'n' in data:\n                ret.append(self.process_js_mod(data['n'], name, idx, sub_idx))\n            if 'mod' in data:\n                ret.append(self.process_js_mod(data['mod'], name, idx, sub_idx))\n            if 'cert' in data:\n                ret.append(self.process_js_certs([data['cert']], name, idx, sub_idx))\n            if 'certs' in data:\n                ret.append(self.process_js_certs(data['certs'], name, idx, sub_idx))\n        return ret", "response": "Processes json object containing js object and returns a list of js object containing the js object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses one moduli from JSON data", "response": "def process_js_mod(self, data, name, idx, sub_idx):\n        \"\"\"\n        Processes one moduli from JSON\n        :param data:\n        :param name:\n        :param idx:\n        :param sub_idx:\n        :return:\n        \"\"\"\n        if isinstance(data, (int, long)):\n            js = collections.OrderedDict()\n            js['type'] = 'js-mod-num'\n            js['fname'] = name\n            js['idx'] = idx\n            js['sub_idx'] = sub_idx\n            js['n'] = '0x%x' % data\n\n            if self.has_fingerprint(data):\n                logger.warning('Fingerprint found in json int modulus %s idx %s %s' % (name, idx, sub_idx))\n                self.mark_and_add_effort(data, js)\n\n                if self.do_print:\n                    print(json.dumps(js))\n\n            return TestResult(js)\n\n        self.process_mod_line(data, name, idx, aux={'stype': 'json', 'sub_idx': sub_idx})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_js_certs(self, data, name, idx, sub_idx):\n        from cryptography.x509.base import load_der_x509_certificate\n\n        ret = []\n        for crt_hex in data:\n            try:\n                bindata = base64.b64decode(crt_hex)\n                x509 = load_der_x509_certificate(bindata, self.get_backend())\n\n                self.num_ldiff_cert += 1\n                sub = self.process_x509(x509, name=name, pem=False, source='ldiff-cert')\n                ret.append(sub)\n\n            except Exception as e:\n                logger.debug('Error in line JSON cert file processing %s, idx %s, subidx %s : %s'\n                             % (name, idx, sub_idx, e))\n                self.trace_logger.log(e)\n        return ret", "response": "Process one certificate from JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_apk(self, data, name):\n        try:\n            from apk_parse.apk import APK\n        except Exception as e:\n            logger.warning('Could not import apk_parse, try running: pip install apk_parse_ph4')\n            return [TestResult(fname=name, type='apk-pem-cert', error='cannot-import')]\n\n        ret = []\n        try:\n            from cryptography.x509.base import load_der_x509_certificate\n            apkf = APK(data, process_now=False, process_file_types=False, raw=True,\n                       temp_dir=self.args.tmp_dir)\n            apkf.process()\n            self.num_apk += 1\n\n            pem = apkf.cert_pem\n            aux = {'subtype': 'apk'}\n\n            x509 = load_der_x509_certificate(pem_to_der(pem), self.get_backend())\n\n            sub = self.process_x509(x509, name=name, idx=0, data=data, pem=True, source='apk-pem-cert', aux=aux)\n            ret.append(sub)\n\n        except Exception as e:\n            logger.debug('Exception in processing APK %s : %s' % (name, e))\n            self.trace_logger.log(e)\n        return ret", "response": "Processes Android application APK"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess one mod file per line", "response": "def process_mod(self, data, name):\n        \"\"\"\n        Processing one modulus per line\n        :param data:\n        :param name:\n        :return:\n        \"\"\"\n        ret = []\n        try:\n            lines = [x.strip() for x in data.split(bytes(b'\\n'))]\n            for idx, line in enumerate(lines):\n                sub = self.process_mod_line(line, name, idx)\n                ret.append(sub)\n\n        except Exception as e:\n            logger.debug('Error in line mod file processing %s : %s' % (name, e))\n            self.trace_logger.log(e)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses one line mod related info.", "response": "def process_mod_line(self, data, name, idx, aux=None):\n        \"\"\"\n        Processes one line mod\n        :param data:\n        :param name:\n        :param idx:\n        :param aux:\n        :return:\n        \"\"\"\n        if data is None or len(data) == 0:\n            return\n\n        ret = []\n        try:\n            if self.args.key_fmt_base64 or self.re_match(r'^[a-zA-Z0-9+/=\\s\\t]+$', data):\n                ret.append(self.process_mod_line_num(strip_spaces(data), name, idx, 'base64', aux))\n\n            if self.args.key_fmt_hex or self.re_match(r'^(0x)?[a-fA-F0-9\\s\\t]+$', data):\n                ret.append(self.process_mod_line_num(strip_spaces(data), name, idx, 'hex', aux))\n\n            if self.args.key_fmt_dec or self.re_match(r'^[0-9\\s\\t]+$', data):\n                ret.append(self.process_mod_line_num(strip_spaces(data), name, idx, 'dec', aux))\n\n        except Exception as e:\n            logger.debug('Error in line mod processing %s idx %s : %s' % (name, idx, e))\n            self.trace_logger.log(e)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing LDAP output of the ldiff file.", "response": "def process_ldiff(self, data, name):\n        \"\"\"\n        Processes LDAP output\n        field;binary::blob\n        :param data:\n        :param name:\n        :return:\n        \"\"\"\n        from cryptography.x509.base import load_der_x509_certificate\n        reg = re.compile(r'binary::\\s*([0-9a-zA-Z+/=\\s\\t\\r\\n]{20,})$', re.MULTILINE | re.DOTALL)\n        matches = re.findall(reg, str(data))\n\n        ret = []\n        num_certs_found = 0\n        for idx, match in enumerate(matches):\n            match = re.sub('[\\r\\t\\n\\s]', '', match)\n            try:\n                bindata = base64.b64decode(match)\n                x509 = load_der_x509_certificate(bindata, self.get_backend())\n\n                self.num_ldiff_cert += 1\n                sub = self.process_x509(x509, name=name, pem=False, source='ldiff-cert')\n                ret.append(sub)\n\n            except Exception as e:\n                logger.debug('Error in line ldiff file processing %s, idx %s, matchlen %s : %s'\n                             % (name, idx, len(match), e))\n                self.trace_logger.log(e)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess Java Key Store file and returns a list of objects.", "response": "def process_jks(self, data, name):\n        \"\"\"\n        Processes Java Key Store file\n        :param data:\n        :param name:\n        :return:\n        \"\"\"\n        if self.jks_file_passwords is None and self.args.jks_pass_file is not None:\n            self.jks_file_passwords = []\n            if not os.path.exists(self.args.jks_pass_file):\n                logger.warning('JKS password file %s does not exist' % self.args.jks_pass_file)\n            with open(self.args.jks_pass_file) as fh:\n                self.jks_file_passwords = sorted(list(set([x.strip() for x in fh])))\n                \n        if self.jks_file_passwords is None:\n            self.jks_file_passwords = []\n\n        try:\n            ks = self.try_open_jks(data, name)\n            if ks is None:\n                logger.warning('Could not open JKS file: %s, password not valid, '\n                               'try specify passwords in --jks-pass-file' % name)\n                return\n\n            # certs\n            from cryptography.x509.base import load_der_x509_certificate\n\n            ret = []\n            for alias, cert in list(ks.certs.items()):\n                try:\n                    x509 = load_der_x509_certificate(cert.cert, self.get_backend())\n\n                    self.num_jks_cert += 1\n                    sub = self.process_x509(x509, name=name, pem=False, source='jks-cert', aux='cert-%s' % alias)\n                    ret.append(sub)\n\n                except Exception as e:\n                    logger.debug('Error in JKS cert processing %s, alias %s : %s' % (name, alias, e))\n                    self.trace_logger.log(e)\n\n            # priv key chains\n            for alias, pk in list(ks.private_keys.items()):\n                for idx, cert in enumerate(pk.cert_chain):\n                    try:\n                        x509 = load_der_x509_certificate(cert[1], self.get_backend())\n\n                        self.num_jks_cert += 1\n                        sub = self.process_x509(x509, name=name, pem=False, source='jks-cert-chain',\n                                                aux='cert-chain-%s-%s' % (alias, idx))\n                        ret.append(sub)\n\n                    except Exception as e:\n                        logger.debug('Error in JKS priv key cert-chain processing %s, alias %s %s : %s'\n                                     % (name, alias, idx, e))\n                        self.trace_logger.log(e)\n            return ret\n\n        except ImportException:\n            return [TestResult(fname=name, type='jks-cert', error='cannot-import')]\n\n        except Exception as e:\n            logger.warning('Exception in JKS processing: %s' % e)\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry to open JKS and return the object.", "response": "def try_open_jks(self, data, name):\n        \"\"\"\n        Tries to guess JKS password\n        :param name:\n        :param data:\n        :return:\n        \"\"\"\n        try:\n            import jks\n        except:\n            logger.warning('Could not import jks, try running: pip install pyjks')\n            raise ImportException('Cannot import pyjks')\n\n        pwdlist = sorted(list(set(self.jks_file_passwords + self.jks_passwords)))\n        for cur in pwdlist:\n            try:\n                return jks.KeyStore.loads(data, cur)\n            except Exception as e:\n                pass\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_pkcs7(self, data, name):\n        from cryptography.hazmat.backends.openssl.backend import backend\n        from cryptography.hazmat.backends.openssl.x509 import _Certificate\n\n        # DER conversion\n        is_pem = startswith(data, '-----')\n        if self.re_match(r'^[a-zA-Z0-9-\\s+=/]+$', data):\n            is_pem = True\n\n        try:\n            der = data\n            if is_pem:\n                data = data.decode('utf8')\n                data = re.sub(r'\\s*-----\\s*BEGIN\\s+PKCS7\\s*-----', '', data)\n                data = re.sub(r'\\s*-----\\s*END\\s+PKCS7\\s*-----', '', data)\n                der = base64.b64decode(data)\n\n            bio = backend._bytes_to_bio(der)\n            pkcs7 = backend._lib.d2i_PKCS7_bio(bio.bio, backend._ffi.NULL)\n            backend.openssl_assert(pkcs7 != backend._ffi.NULL)\n            signers = backend._lib.PKCS7_get0_signers(pkcs7, backend._ffi.NULL, 0)\n            backend.openssl_assert(signers != backend._ffi.NULL)\n            backend.openssl_assert(backend._lib.sk_X509_num(signers) > 0)\n            x509_ptr = backend._lib.sk_X509_value(signers, 0)\n            backend.openssl_assert(x509_ptr != backend._ffi.NULL)\n            x509_ptr = backend._ffi.gc(x509_ptr, backend._lib.X509_free)\n            x509 = _Certificate(backend, x509_ptr)\n\n            self.num_pkcs7_cert += 1\n\n            return [self.process_x509(x509, name=name, pem=False, source='pkcs7-cert', aux='')]\n\n        except Exception as e:\n            logger.debug('Error in PKCS7 processing %s: %s' % (name, e))\n            self.trace_logger.log(e)", "response": "Process PKCS7 signature with certificate in it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_backend(self, backend=None):\n        from cryptography.hazmat.backends import default_backend\n        return default_backend() if backend is None else backend", "response": "Get the backend that is used to store the key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dump(self, ret):\n        if self.args.flatten:\n            ret = drop_none(flatten(ret))\n\n        logger.info('Dump: \\n' + json.dumps(ret, cls=AutoJSONEncoder, indent=2 if self.args.indent else None))", "response": "Dumps the return value of a get_key_value function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef work(self):\n        self.do_print = True\n        if self.args.old:\n            self.switch_fingerprint_method(True)\n\n        ret = self.process_inputs()\n\n        if self.args.dump:\n            self.dump(ret)\n\n        logger.info('### SUMMARY ####################')\n        logger.info('Records tested: %s' % self.tested)\n        logger.info('.. PEM certs: . . . %s' % self.num_pem_certs)\n        logger.info('.. DER certs: . . . %s' % self.num_der_certs)\n        logger.info('.. RSA key files: . %s' % self.num_rsa_keys)\n        logger.info('.. PGP master keys: %s' % self.num_pgp_masters)\n        logger.info('.. PGP total keys:  %s' % self.num_pgp_total)\n        logger.info('.. SSH keys:  . . . %s' % self.num_ssh)\n        logger.info('.. APK keys:  . . . %s' % self.num_apk)\n        logger.info('.. JSON keys: . . . %s' % self.num_json)\n        logger.info('.. LDIFF certs: . . %s' % self.num_ldiff_cert)\n        logger.info('.. JKS certs: . . . %s' % self.num_jks_cert)\n        logger.info('.. PKCS7: . . . . . %s' % self.num_pkcs7_cert)\n        logger.debug('. Total RSA keys . %s  (# of keys RSA extracted & analyzed)' % self.num_rsa)\n        if self.found > 0:\n            logger.info('Fingerprinted keys found: %s' % self.found)\n            logger.info('WARNING: Potential vulnerability')\n        else:\n            logger.info('No fingerprinted keys found (OK)')\n        logger.info('################################')", "response": "Entry point after argument processing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize command line parser", "response": "def init_parser(self):\n        \"\"\"\n        Init command line parser\n        :return:\n        \"\"\"\n        parser = argparse.ArgumentParser(description='ROCA Fingerprinter')\n\n        parser.add_argument('--tmp', dest='tmp_dir', default='.',\n                            help='Temporary dir for subprocessing (e.g. APK parsing scratch)')\n\n        parser.add_argument('--debug', dest='debug', default=False, action='store_const', const=True,\n                            help='Debugging logging')\n\n        parser.add_argument('--dump', dest='dump', default=False, action='store_const', const=True,\n                            help='Dump all processed info')\n\n        parser.add_argument('--flatten', dest='flatten', default=False, action='store_const', const=True,\n                            help='Flatten the dump')\n\n        parser.add_argument('--indent', dest='indent', default=False, action='store_const', const=True,\n                            help='Indent the dump')\n\n        parser.add_argument('--old', dest='old', default=False, action='store_const', const=True,\n                            help='Old fingerprinting algorithm - moduli detector')\n\n        parser.add_argument('--base64-stdin', dest='base64stdin', default=False, action='store_const', const=True,\n                            help='Decode STDIN as base64')\n\n        parser.add_argument('--file-pem', dest='file_pem', default=False, action='store_const', const=True,\n                            help='Force read as PEM encoded file')\n\n        parser.add_argument('--file-der', dest='file_der', default=False, action='store_const', const=True,\n                            help='Force read as DER encoded file')\n\n        parser.add_argument('--file-pgp', dest='file_pgp', default=False, action='store_const', const=True,\n                            help='Force read as PGP ASC encoded file')\n\n        parser.add_argument('--file-ssh', dest='file_ssh', default=False, action='store_const', const=True,\n                            help='Force read as SSH public key file')\n\n        parser.add_argument('--file-mod', dest='file_mod', default=False, action='store_const', const=True,\n                            help='Force read as One modulus per line')\n\n        parser.add_argument('--file-json', dest='file_json', default=False, action='store_const', const=True,\n                            help='Force read as JSON file')\n\n        parser.add_argument('--file-ldiff', dest='file_ldiff', default=False, action='store_const', const=True,\n                            help='Force read as LDIFF file')\n\n        parser.add_argument('--file-pkcs7', dest='file_pkcs7', default=False, action='store_const', const=True,\n                            help='Force read as PKCS7 file')\n\n        parser.add_argument('--key-fmt-base64', dest='key_fmt_base64', default=False, action='store_const', const=True,\n                            help='Modulus per line, base64 encoded')\n\n        parser.add_argument('--key-fmt-hex', dest='key_fmt_hex', default=False, action='store_const', const=True,\n                            help='Modulus per line, hex encoded')\n\n        parser.add_argument('--key-fmt-dec', dest='key_fmt_dec', default=False, action='store_const', const=True,\n                            help='Modulus per line, dec encoded')\n\n        parser.add_argument('--jks-pass-file', dest='jks_pass_file', default=None,\n                            help='Password file for JKS, one per line')\n\n        parser.add_argument('files', nargs=argparse.ZERO_OR_MORE, default=[],\n                            help='files to process')\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_tls(self, data, name):\n        ret = []\n        try:\n            lines = [x.strip() for x in data.split('\\n')]\n            for idx, line in enumerate(lines):\n                if line == '':\n                    continue\n\n                sub = self.process_host(line, name, idx)\n                if sub is not None:\n                    ret.append(sub)\n\n        except Exception as e:\n            logger.error('Error in file processing %s : %s' % (name, e))\n            self.roca.trace_logger.log(e)\n        return ret", "response": "Process the remote TLS data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_host(self, host_spec, name, line_idx=0):\n        try:\n            parts = host_spec.split(':', 1)\n            host = parts[0].strip()\n            port = parts[1] if len(parts) > 1 else 443\n            pem_cert = self.get_server_certificate(host, port)\n            if pem_cert:\n                sub = self.roca.process_pem_cert(pem_cert, name, line_idx)\n                return sub\n\n        except Exception as e:\n            logger.error('Error in file processing %s (%s) : %s' % (host_spec, name, e))\n            self.roca.trace_logger.log(e)", "response": "Process one host spec and return a set of related objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_server_certificate(self, host, port):\n        logger.info(\"Fetching server certificate from %s:%s\" % (host,port))\n        try:\n            return get_server_certificate((host, int(port)))\n        except Exception as e:\n            logger.error('Error getting server certificate from %s:%s: %s' %\n                         (host, port, e))\n            return False", "response": "Get the remote x. 509 certificate containing the remote x. 509 certificate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess input data :return:", "response": "def process_inputs(self):\n        \"\"\"\n        Processes input data\n        :return:\n        \"\"\"\n        ret = []\n        files = self.args.files\n        if files is None:\n            return ret\n\n        for fname in files:\n\n            # arguments are host specs\n            if self.args.hosts:\n                sub = self.process_host(fname, fname, 0)\n                if sub is not None:\n                    ret.append(sub)\n                continue\n\n            # arguments are file names\n            fh = open(fname, 'r')\n            with fh:\n                data = fh.read()\n                sub = self.process_tls(data, fname)\n                ret.append(sub)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef work(self):\n        self.roca.do_print = True\n        ret = self.process_inputs()\n\n        if self.args.dump:\n            self.roca.dump(ret)\n\n        if self.roca.found > 0:\n            logger.info('Fingerprinted keys found: %s' % self.roca.found)\n            logger.info('WARNING: Potential vulnerability')\n        else:\n            logger.info('No fingerprinted keys found (OK)')", "response": "Entry point after argument processing."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes command line parser", "response": "def init_parser(self):\n        \"\"\"\n        Init command line parser\n        :return:\n        \"\"\"\n        parser = argparse.ArgumentParser(description='ROCA TLS Fingerprinter')\n\n        parser.add_argument('--debug', dest='debug', default=False, action='store_const', const=True,\n                            help='Debugging logging')\n\n        parser.add_argument('--dump', dest='dump', default=False, action='store_const', const=True,\n                            help='Dump all processed info')\n\n        parser.add_argument('--flatten', dest='flatten', default=False, action='store_const', const=True,\n                            help='Flatten the dump')\n\n        parser.add_argument('--indent', dest='indent', default=False, action='store_const', const=True,\n                            help='Indent the dump')\n\n        parser.add_argument('--hosts', dest='hosts', default=False, action='store_const', const=True,\n                            help='Arguments are host names not file names')\n\n        parser.add_argument('files', nargs=argparse.ZERO_OR_MORE, default=[],\n                            help='files to process')\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(self):\n        parser = self.init_parser()\n        if len(sys.argv) < 2:\n            parser.print_usage()\n            sys.exit(0)\n\n        self.args = parser.parse_args()\n        self.roca.args.flatten = self.args.flatten\n        self.roca.args.indent = self.args.indent\n\n        if self.args.debug:\n            coloredlogs.install(level=logging.DEBUG)\n            self.roca.args.debug = True\n\n        self.work()", "response": "Main entry point for the main function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _map_tril_1d_on_2d(indices, dims):\n\n    N = (dims * dims - dims) / 2\n\n    m = np.ceil(np.sqrt(2 * N))\n    c = m - np.round(np.sqrt(2 * (N - indices))) - 1\n    r = np.mod(indices + (c + 1) * (c + 2) / 2 - 1, m) + 1\n\n    return np.array([r, c], dtype=np.int64)", "response": "Map 1d indices on lower triangular matrix in 2d."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef random_pairs_with_replacement(n, shape, random_state=None):\n\n    if not isinstance(random_state, np.random.RandomState):\n        random_state = np.random.RandomState(random_state)\n\n    n_max = max_pairs(shape)\n\n    if n_max <= 0:\n        raise ValueError('n_max must be larger than 0')\n\n    # make random pairs\n    indices = random_state.randint(0, n_max, n)\n\n    if len(shape) == 1:\n        return _map_tril_1d_on_2d(indices, shape[0])\n    else:\n        return np.unravel_index(indices, shape)", "response": "make random record pairs with replacement"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef random_pairs_without_replacement_large_frames(\n        n, shape, random_state=None):\n    \"\"\"Make a sample of random pairs with replacement\"\"\"\n\n    n_max = max_pairs(shape)\n\n    sample = np.array([])\n\n    # Run as long as the number of pairs is less than the requested number\n    # of pairs n.\n    while len(sample) < n:\n\n        # The number of pairs to sample (sample twice as much record pairs\n        # because the duplicates are dropped).\n        n_sample_size = (n - len(sample)) * 2\n        sample = random_state.randint(n_max, size=n_sample_size)\n\n        # concatenate pairs and deduplicate\n        pairs_non_unique = np.append(sample, sample)\n        sample = _unique_rows_numpy(pairs_non_unique)\n\n    # return 2d indices\n    if len(shape) == 1:\n        return _map_tril_1d_on_2d(sample[0:n], shape[0])\n    else:\n        return np.unravel_index(sample[0:n], shape)", "response": "Make a sample of random pairs with replacement large frames."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncleaning a Series of strings into a single recordlinkage tree.", "response": "def clean(s, lowercase=True, replace_by_none=r'[^ \\-\\_A-Za-z0-9]+',\n          replace_by_whitespace=r'[\\-\\_]', strip_accents=None,\n          remove_brackets=True, encoding='utf-8', decode_error='strict'):\n    \"\"\"Clean string variables.\n\n    Clean strings in the Series by removing unwanted tokens,\n    whitespace and brackets.\n\n    Parameters\n    ----------\n    s : pandas.Series\n        A Series to clean.\n    lower : bool, optional\n        Convert strings in the Series to lowercase. Default True.\n    replace_by_none : str, optional\n        The matches of this regular expression are replaced by ''.\n    replace_by_whitespace : str, optional\n        The matches of this regular expression are replaced by a\n        whitespace.\n    remove_brackets : bool, optional\n        Remove all content between brackets and the bracket\n        themselves. Default True.\n    strip_accents : {'ascii', 'unicode', None}, optional\n        Remove accents during the preprocessing step. 'ascii' is a\n        fast method that only works on characters that have an direct\n        ASCII mapping. 'unicode' is a slightly slower method that\n        works on any characters. None (default) does nothing.\n    encoding : str, optional\n        If bytes are given, this encoding is used to decode. Default\n        is 'utf-8'.\n    decode_error : {'strict', 'ignore', 'replace'}, optional\n        Instruction on what to do if a byte Series is given that\n        contains characters not of the given `encoding`. By default,\n        it is 'strict', meaning that a UnicodeDecodeError will be\n        raised. Other values are 'ignore' and 'replace'.\n\n    Example\n    -------\n    >>> import pandas\n    >>> from recordlinkage.preprocessing import clean\n    >>>\n    >>> names = ['Mary-ann',\n                'Bob :)',\n                'Angel',\n                'Bob (alias Billy)',\n                None]\n    >>> s = pandas.Series(names)\n    >>> print(clean(s))\n    0    mary ann\n    1         bob\n    2       angel\n    3         bob\n    4         NaN\n    dtype: object\n\n    Returns\n    -------\n    pandas.Series:\n        A cleaned Series of strings.\n\n    \"\"\"\n\n    if s.shape[0] == 0:\n        return s\n\n    # Lower s if lower is True\n    if lowercase is True:\n        s = s.str.lower()\n\n    # Accent stripping based on https://github.com/scikit-learn/\n    # scikit-learn/blob/412996f/sklearn/feature_extraction/text.py\n    # BSD license\n    if not strip_accents:\n        pass\n    elif callable(strip_accents):\n        strip_accents_fn = strip_accents\n    elif strip_accents == 'ascii':\n        strip_accents_fn = strip_accents_ascii\n    elif strip_accents == 'unicode':\n        strip_accents_fn = strip_accents_unicode\n    else:\n        raise ValueError(\n            \"Invalid value for 'strip_accents': {}\".format(strip_accents)\n        )\n\n    # Remove accents etc\n    if strip_accents:\n        def strip_accents_fn_wrapper(x):\n            if sys.version_info[0] >= 3:\n                if isinstance(x, str):\n                    return strip_accents_fn(x)\n                else:\n                    return x\n            else:\n                if isinstance(x, unicode):  # noqa\n                    return strip_accents_fn(x)\n                else:\n                    return x\n\n        # encoding\n        s = s.apply(\n            lambda x: x.decode(encoding, decode_error) if\n            type(x) == bytes else x)\n        s = s.map(lambda x: strip_accents_fn_wrapper(x))\n\n    # Remove all content between brackets\n    if remove_brackets is True:\n        s = s.str.replace(r'(\\[.*?\\]|\\(.*?\\)|\\{.*?\\})', '')\n\n    # Remove the special characters\n    if replace_by_none:\n        s = s.str.replace(replace_by_none, '')\n\n    if replace_by_whitespace:\n        s = s.str.replace(replace_by_whitespace, ' ')\n\n    # Remove multiple whitespaces\n    s = s.str.replace(r'\\s\\s+', ' ')\n\n    # Strip s\n    s = s.str.lstrip().str.rstrip()\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncounts the number of times each value occurs.", "response": "def value_occurence(s):\n    \"\"\"Count the number of times each value occurs.\n\n    This function returns the counts for each row, in contrast with\n    `pandas.value_counts <http://pandas.pydata.org/pandas-\n    docs/stable/generated/pandas.Series.value_counts.html>`_.\n\n    Returns\n    -------\n    pandas.Series\n        A Series with value counts.\n\n    \"\"\"\n\n    # https://github.com/pydata/pandas/issues/3729\n    value_count = s.fillna('NAN')\n\n    return value_count.groupby(by=value_count).transform('count')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef smith_waterman_similarity(s1,\n                              s2,\n                              match=5,\n                              mismatch=-5,\n                              gap_start=-5,\n                              gap_continue=-1,\n                              norm=\"mean\"):\n    \"\"\"Smith-Waterman string comparison.\n\n    An implementation of the Smith-Waterman string comparison algorithm\n    described in Christen, Peter (2012).\n\n    Parameters\n    ----------\n    s1 : label, pandas.Series\n        Series or DataFrame to compare all fields.\n    s2 : label, pandas.Series\n        Series or DataFrame to compare all fields.\n    match : float\n        The value added to the match score if two characters match.\n        Greater than mismatch, gap_start, and gap_continue. Default: 5.\n    mismatch : float\n        The value added to the match score if two characters do not match.\n        Less than match. Default: -5.\n    gap_start : float\n        The value added to the match score upon encountering the start of\n        a gap. Default: -5.\n    gap_continue : float\n        The value added to the match score for positions where a previously\n        started gap is continuing. Default: -1.\n    norm : str\n        The name of the normalization metric to be used. Applied by dividing\n        the match score by the normalization metric multiplied by match. One\n        of \"min\", \"max\",or \"mean\". \"min\" will use the minimum string length\n        as the normalization metric. \"max\" and \"mean\" use the maximum and\n        mean string length respectively. Default: \"mean\"\"\n\n    Returns\n    -------\n    pandas.Series\n        A pandas series with similarity values. Values equal or between 0\n        and 1.\n    \"\"\"\n\n    # Assert that match is greater than or equal to mismatch, gap_start, and\n    # gap_continue.\n    assert match >= max(mismatch, gap_start, gap_continue), \\\n        \"match must be greater than or equal to mismatch, \" \\\n        \"gap_start, and gap_continue\"\n\n    if len(s1) != len(s2):\n        raise ValueError('Arrays or Series have to be same length.')\n\n    if len(s1) == len(s2) == 0:\n        return []\n\n    concat = pandas.Series(list(zip(s1, s2)))\n\n    def sw_apply(t):\n        \"\"\"\n        sw_apply(t)\n\n        A helper function that is applied to each pair of records\n        in s1 and s2. Assigns a similarity score to each pair,\n        between 0 and 1. Used by the pandas.apply method.\n\n        Parameters\n        ----------\n        t : pandas.Series\n            A pandas Series containing two strings to be compared.\n\n        Returns\n        -------\n        Float\n            A similarity score between 0 and 1.\n        \"\"\"\n        str1 = t[0]\n        str2 = t[1]\n\n        def compute_score():\n            \"\"\"\n            compute_score()\n\n            The helper function that produces the non-normalized\n            similarity score between two strings. The scores are\n            determined using the Smith-Waterman dynamic programming\n            algorithm. The scoring scheme is determined from the\n            parameters provided to the parent smith_waterman_similarity()\n            function.\n\n            Returns\n            -------\n            Float\n                A score 0 or greater. Indicates similarity between two strings.\n            \"\"\"\n\n            # Initialize the score matrix with 0s\n\n            m = [[0] * (1 + len(str2)) for i in range(1 + len(str1))]\n\n            # Initialize the trace matrix with empty lists\n            trace = [[[] for _ in range(1 + len(str2))]\n                     for _ in range(1 + len(str1))]\n\n            # Initialize the highest seen score to 0\n            highest = 0\n\n            # Iterate through the matrix\n            for x in range(1, 1 + len(str1)):\n                for y in range(1, 1 + len(str2)):\n                    # Calculate Diagonal Score\n                    if str1[x - 1] == str2[y - 1]:\n                        # If characters match, add the match score to the\n                        # diagonal score\n                        diagonal = m[x - 1][y - 1] + match\n                    else:\n                        # If characters do not match, add the mismatch score\n                        # to the diagonal score\n                        diagonal = m[x - 1][y - 1] + mismatch\n\n                    # Calculate the Left Gap Score\n                    if \"H\" in trace[x - 1][y]:\n                        # If cell to the left's score was calculated based on\n                        # a horizontal gap, add the gap continuation penalty\n                        # to the left score.\n                        gap_horizontal = m[x - 1][y] + gap_continue\n                    else:\n                        # Otherwise, add the gap start penalty to the left\n                        # score\n                        gap_horizontal = m[x - 1][y] + gap_start\n\n                    # Calculate the Above Gap Score\n                    if \"V\" in trace[x][y - 1]:\n                        # If above cell's score was calculated based on a\n                        # vertical gap, add the gap continuation penalty to\n                        # the above score.\n                        gap_vertical = m[x][y - 1] + gap_continue\n                    else:\n                        # Otherwise, add the gap start penalty to the above\n                        # score\n                        gap_vertical = m[x][y - 1] + gap_start\n\n                    # Choose the highest of the three scores\n                    score = max(diagonal, gap_horizontal, gap_vertical)\n\n                    if score <= 0:\n                        # If score is less than 0, boost to 0\n                        score = 0\n                    else:\n                        # If score is greater than 0, determine whether it was\n                        # calculated based on a diagonal score, horizontal gap,\n                        # or vertical gap. Store D, H, or V in the trace matrix\n                        # accordingly.\n                        if score == diagonal:\n                            trace[x][y].append(\"D\")\n                        if score == gap_horizontal:\n                            trace[x][y].append(\"H\")\n                        if score == gap_vertical:\n                            trace[x][y].append(\"V\")\n\n                    # If the cell's score is greater than the highest score\n                    # previously present, record the score as the highest.\n                    if score > highest:\n                        highest = score\n\n                    # Set the cell's score to score\n                    m[x][y] = score\n\n            # After iterating through the entire matrix, return the highest\n            # score found.\n            return highest\n\n        def normalize(score):\n            \"\"\"\n            normalize(score)\n\n            A helper function used to normalize the score produced by\n            compute_score() to a score between 0 and 1. The method for\n            normalization is determined by the norm argument provided\n            to the parent, smith_waterman_similarity function.\n\n            Parameters\n            ----------\n            score : Float\n                The score produced by the compute_score() function.\n\n            Returns\n            -------\n            Float\n                A normalized score between 0 and 1.\n            \"\"\"\n            if norm == \"min\":\n                # Normalize by the shorter string's length\n                return score / (min(len(str1), len(str2)) * match)\n            if norm == \"max\":\n                # Normalize by the longer string's length\n                return score / (max(len(str1), len(str2)) * match)\n            if norm == \"mean\":\n                # Normalize by the mean length of the two strings\n                return 2 * score / ((len(str1) + len(str2)) * match)\n            else:\n                warnings.warn(\n                    'Unrecognized longest common substring normalization. '\n                    'Defaulting to \"mean\" method.')\n                return 2 * score / ((len(str1) + len(str2)) * match)\n\n        try:\n            if len(str1) == 0 or len(str2) == 0:\n                return 0\n            return normalize(compute_score())\n\n        except Exception as err:\n            if pandas.isnull(t[0]) or pandas.isnull(t[1]):\n                return np.nan\n            else:\n                raise err\n\n    return concat.apply(sw_apply)", "response": "Returns a new series with similarity values between two strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms is_fitted validation for an estimator.", "response": "def check_is_fitted(estimator, attributes, msg=None, all_or_any=all):\n    \"\"\"Perform is_fitted validation for estimator.\n    Checks if the estimator is fitted by verifying the presence of\n    \"all_or_any\" of the passed attributes and raises a NotFittedError with the\n    given message.\n    Parameters\n    ----------\n    estimator : estimator instance.\n        estimator instance for which the check is performed.\n    attributes : attribute name(s) given as string or a list/tuple of strings\n        Eg.:\n            ``[\"coef_\", \"estimator_\", ...], \"coef_\"``\n    msg : string\n        The default error message is, \"This %(name)s instance is not fitted\n        yet. Call 'fit' with appropriate arguments before using this method.\"\n        For custom messages if \"%(name)s\" is present in the message string,\n        it is substituted for the estimator name.\n        Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\".\n    all_or_any : callable, {all, any}, default all\n        Specify whether all or any of the given attributes must exist.\n    Returns\n    -------\n    None\n    Raises\n    ------\n    NotFittedError\n        If the attributes are not found.\n    \"\"\"\n    if msg is None:\n        msg = (\"This %(name)s instance is not fitted yet. Call 'fit' with \"\n               \"appropriate arguments before using this method.\")\n\n    if not hasattr(estimator, 'fit'):\n        raise TypeError(\"%s is not an estimator instance.\" % (estimator))\n\n    if not isinstance(attributes, (list, tuple)):\n        attributes = [attributes]\n\n    if not all_or_any([hasattr(estimator, attr) for attr in attributes]):\n        raise NotFittedError(msg % {'name': type(estimator).__name__})"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndots product that handle the sparse matrix case correctly.", "response": "def safe_sparse_dot(a, b, dense_output=False):\n    \"\"\"Dot product that handle the sparse matrix case correctly\n    Uses BLAS GEMM as replacement for numpy.dot where possible\n    to avoid unnecessary copies.\n\n    Parameters\n    ----------\n    a : array or sparse matrix\n    b : array or sparse matrix\n    dense_output : boolean, default False\n        When False, either ``a`` or ``b`` being sparse will yield sparse\n        output. When True, output will always be an array.\n    Returns\n    -------\n    dot_product : array or sparse matrix\n        sparse if ``a`` or ``b`` is sparse and ``dense_output=False``.\n    \"\"\"\n    if issparse(a) or issparse(b):\n        ret = a * b\n        if dense_output and hasattr(ret, \"toarray\"):\n            ret = ret.toarray()\n        return ret\n    else:\n        return np.dot(a, b)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _joint_log_likelihood(self, X):\n        check_is_fitted(self, \"classes_\")\n\n        X = check_array(X, accept_sparse='csr')\n        X_bin = self._transform_data(X)\n\n        n_classes, n_features = self.feature_log_prob_.shape\n        n_samples, n_features_X = X_bin.shape\n\n        if n_features_X != n_features:\n            raise ValueError(\n                \"Expected input with %d features, got %d instead\" %\n                (n_features, n_features_X))\n\n        # see chapter 4.1 of http://www.cs.columbia.edu/~mcollins/em.pdf\n        # implementation as in Formula 4.\n\n        jll = safe_sparse_dot(X_bin, self.feature_log_prob_.T)\n        jll += self.class_log_prior_\n\n        return jll", "response": "Calculate the posterior log probability of the samples X"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform classification on an array of test vectors X and return the predicted target values for X.", "response": "def predict(self, X):\n        \"\"\"\n        Perform classification on an array of test vectors X.\n\n        Parameters\n        ----------\n        X : array-like, shape = [n_samples, n_features]\n\n        Returns\n        -------\n        C : array, shape = [n_samples]\n            Predicted target values for X\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n        return self.classes_[np.argmax(jll, axis=1)]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npredicting the log - probability of the test vector X.", "response": "def predict_log_proba(self, X):\n        \"\"\"\n        Return log-probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like, shape = [n_samples, n_features]\n\n        Returns\n        -------\n        C : array-like, shape = [n_samples, n_classes]\n            Returns the log-probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute `classes_`.\n        \"\"\"\n        jll = self._joint_log_likelihood(X)\n\n        # normalize by P(x) = P(f_1, ..., f_n)\n        log_prob_x = logsumexp(jll, axis=1)  # return shape = (2,)\n\n        return jll - np.atleast_2d(log_prob_x).T"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits the data for each column separately.", "response": "def _fit_data(self, X):\n        \"\"\"Binarize the data for each column separately.\n\n        Parameters\n        ----------\n        X : array-like, shape = [n_samples, n_features]\n\n        Returns\n        -------\n        X_transformed : array-like\n            Returns the data where in each columns the labels are\n            binarized.\n\n        \"\"\"\n\n        if self.binarize is not None:\n            X = binarize(X, threshold=self.binarize)\n\n        for i in range(X.shape[1]):\n\n            # initialise binarizer and save\n            binarizer = LabelBinarizer()\n\n            # fit the data to the binarizer\n            binarizer.fit(X[:, i])\n            self._binarizers.append(binarizer)\n\n        return self._transform_data(X)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _count(self, X, Y):\n\n        self.feature_count_ += safe_sparse_dot(Y.T, X)\n        self.class_count_ += Y.sum(axis=0)", "response": "Count and smooth feature occurrences."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_feature_log_prob(self, alpha):\n        smoothed_fc = self.feature_count_ + alpha\n        smoothed_cc = self.class_count_ + alpha * 2\n\n        self.feature_log_prob_ = (np.log(smoothed_fc) -\n                                  np.log(smoothed_cc.reshape(-1, 1)))", "response": "Apply smoothing to raw counts and recompute log probabilities"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit(self, X, y, sample_weight=None):\n        X, y = check_X_y(X, y, 'csr')\n\n        # Transform data with a label binarizer. Each column will get\n        # transformed into a N columns (for each distinct value a column). For\n        # a situation with 0 and 1 outcome values, the result given two\n        # columns.\n        X_bin = self._fit_data(X)\n        _, n_features = X_bin.shape\n\n        # prepare Y\n        labelbin = LabelBinarizer()\n        Y = labelbin.fit_transform(y)\n        self.classes_ = labelbin.classes_\n        if Y.shape[1] == 1:\n            Y = np.concatenate((1 - Y, Y), axis=1)\n\n        # LabelBinarizer().fit_transform() returns arrays with dtype=np.int64.\n        # We convert it to np.float64 to support sample_weight consistently;\n        # this means we also don't have to cast X to floating point\n        Y = Y.astype(np.float64)\n        if sample_weight is not None:\n            sample_weight = np.atleast_2d(sample_weight)\n            Y *= check_array(sample_weight).T\n\n        class_prior = self.class_prior\n\n        # Count raw events from data before updating the class log prior\n        # and feature log probas\n        n_effective_classes = Y.shape[1]\n        self.class_count_ = np.zeros(n_effective_classes, dtype=np.float64)\n        self.feature_count_ = np.zeros((n_effective_classes, n_features),\n                                       dtype=np.float64)\n        self._count(X_bin, Y)\n        alpha = self._check_alpha()\n        self._update_feature_log_prob(alpha)\n        self._update_class_log_prior(class_prior=class_prior)\n\n        return self", "response": "Fit Naive Bayes classifier according to X y and return a new object containing the classifier s class probabilities and feature log probabilities."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitialising parameters for unsupervised learning.", "response": "def _init_parameters_random(self, X_bin):\n        \"\"\"Initialise parameters for unsupervised learning.\n\n        \"\"\"\n\n        _, n_features = X_bin.shape\n\n        # The parameter class_log_prior_ has shape (2,). The values represent\n        # 'match' and 'non-match'.\n        rand_vals = np.random.rand(2)\n        class_prior = rand_vals / np.sum(rand_vals)\n\n        # make empty array of feature log probs\n        # dimensions 2xn_features\n        feature_prob = np.zeros((2, n_features))\n\n        feat_i = 0\n\n        for i, bin in enumerate(self._binarizers):\n\n            bin_len = bin.classes_.shape[0]\n\n            rand_vals_0 = np.random.rand(bin_len)\n            feature_prob[0, feat_i:feat_i + bin_len] = \\\n                rand_vals_0 / np.sum(rand_vals_0)\n\n            rand_vals_1 = np.random.rand(bin_len)\n            feature_prob[1, feat_i:feat_i + bin_len] = \\\n                rand_vals_1 / np.sum(rand_vals_1)\n\n            feat_i += bin_len\n\n        return np.log(class_prior), np.log(feature_prob)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialise parameters for unsupervised learning.", "response": "def _init_parameters_jaro(self, X_bin):\n        \"\"\"Initialise parameters for unsupervised learning.\n\n        \"\"\"\n\n        _, n_features = X_bin.shape\n\n        class_prior = [.9, .1]\n        feature_prob = np.zeros((2, n_features))\n\n        for i, bin in enumerate(self._binarizers):\n\n            if bin.classes_.shape[0] != 2:\n                raise ValueError(\"Only binary labels are allowed for \"\n                                 \"'jaro'method. \"\n                                 \"Column {} has {} different labels.\".format(\n                                     i, bin.classes_.shape[0]))\n\n            # TODO: ensure classes are [0, 1] (not [1, 0])\n            # TODO: check with bin.y_type_\n\n            feature_prob[0, :] = np.tile([.9, .1], int(n_features / 2))\n            feature_prob[1, :] = np.tile([.1, .9], int(n_features / 2))\n\n        return np.log(class_prior), np.log(feature_prob)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits the ECM classifier according to X.", "response": "def fit(self, X):\n        \"\"\"Fit ECM classifier according to X\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n            Training vectors, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        \"\"\"\n        X = check_array(X, accept_sparse='csr')\n\n        # count frequencies of elements in vector space\n        # based on https://stackoverflow.com/a/33235665\n        # faster than numpy.unique\n        X_unique, X_freq = np.unique(X, axis=0, return_counts=True)\n        X_freq = np.atleast_2d(X_freq)\n\n        # Transform data with a label binarizer. Each column will get\n        # transformed into a N columns (for each distinct value a column). For\n        # a situation with 0 and 1 outcome values, the result given two\n        # columns.\n        X_unique_bin = self._fit_data(X_unique)\n        _, n_features = X_unique_bin.shape\n\n        # initialise parameters\n        self.classes_ = np.array([0, 1])\n\n        if is_string_like(self.init) and self.init == 'random':\n            self.class_log_prior_, self.feature_log_prob_ = \\\n                self._init_parameters_random(X_unique_bin)\n        elif is_string_like(self.init) and self.init == 'jaro':\n            self.class_log_prior_, self.feature_log_prob_ = \\\n                self._init_parameters_jaro(X_unique_bin)\n        else:\n            raise ValueError(\"'{}' is not a valid value for \"\n                             \"argument 'init'\".format(self.init))\n\n        iteration = 0\n        stop_iteration = False\n\n        self._log_class_log_prior = np.atleast_2d(self.class_log_prior_)\n        self._log_feature_log_prob = np.atleast_3d(self.feature_log_prob_)\n\n        while iteration < self.max_iter and not stop_iteration:\n\n            # expectation step\n            g = self.predict_proba(X_unique)\n            g_freq = g * X_freq.T\n            g_freq_sum = g_freq.sum(axis=0)\n\n            # maximisation step\n            class_log_prior_ = np.log(g_freq_sum) - np.log(X.shape[0])  # p\n            feature_log_prob_ = np.log(safe_sparse_dot(g_freq.T, X_unique_bin))\n            feature_log_prob_ -= np.log(np.atleast_2d(g_freq_sum).T)\n\n            # Stop iterating when the class prior and feature probs are close\n            # to the values in the to previous iteration (parameters starting\n            # with 'self').\n            class_log_prior_close = np.allclose(\n                class_log_prior_, self.class_log_prior_, atol=self.atol)\n            feature_log_prob_close = np.allclose(\n                feature_log_prob_, self.feature_log_prob_, atol=self.atol)\n            if (class_log_prior_close and feature_log_prob_close):\n                stop_iteration = True\n            if np.all(np.isnan(feature_log_prob_)):\n                stop_iteration = True\n\n            # Update the class prior and feature probs.\n            self.class_log_prior_ = class_log_prior_\n            self.feature_log_prob_ = feature_log_prob_\n\n            # create logs\n            self._log_class_log_prior = np.concatenate(\n                [self._log_class_log_prior,\n                 np.atleast_2d(self.class_log_prior_)]\n            )\n            self._log_feature_log_prob = np.concatenate(\n                [self._log_feature_log_prob,\n                 np.atleast_3d(self.feature_log_prob_)], axis=2\n            )\n            # Increment counter\n            iteration += 1\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the sorting key values as a series", "response": "def _get_sorting_key_values(self, array1, array2):\n        \"\"\"return the sorting key values as a series\"\"\"\n\n        concat_arrays = numpy.concatenate([array1, array2])\n        unique_values = numpy.unique(concat_arrays)\n\n        return numpy.sort(unique_values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute(self, links):\n\n        try:\n            import networkx as nx\n        except ImportError():\n            raise Exception(\"'networkx' module is needed for this operation\")\n\n        G = nx.Graph()\n        G.add_edges_from(links.values)\n        connected_components = nx.connected_component_subgraphs(G)\n\n        links_result = [pd.MultiIndex.from_tuples(subgraph.edges())\n                        for subgraph in connected_components]\n\n        return links_result", "response": "Compute the connected components of a set of links."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _prob_match(self, features):\n\n        # compute the probabilities\n        probs = self.kernel.predict_proba(features)\n\n        # get the position of match probabilities\n        classes = list(self.kernel.classes_)\n        match_class_position = classes.index(1)\n\n        return probs[:, match_class_position]", "response": "Compute the match probabilities for a set of features."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _predict(self, features):\n\n        from sklearn.exceptions import NotFittedError\n\n        try:\n            prediction = self.kernel.predict_classes(features)[:, 0]\n        except NotFittedError:\n            raise NotFittedError(\n                \"{} is not fitted yet. Call 'fit' with appropriate \"\n                \"arguments before using this method.\".format(\n                    type(self).__name__\n                )\n            )\n\n        return prediction", "response": "Predict matches and non - matches for a set of features."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _febrl_links(df):\n\n    index = df.index.to_series()\n    keys = index.str.extract(r'rec-(\\d+)', expand=True)[0]\n\n    index_int = numpy.arange(len(df))\n\n    df_helper = pandas.DataFrame({\n        'key': keys,\n        'index': index_int\n    })\n\n    # merge the two frame and make MultiIndex.\n    pairs_df = df_helper.merge(\n        df_helper, on='key'\n    )[['index_x', 'index_y']]\n    pairs_df = pairs_df[pairs_df['index_x'] > pairs_df['index_y']]\n\n    return pandas.MultiIndex(\n        levels=[df.index.values, df.index.values],\n        labels=[pairs_df['index_x'].values, pairs_df['index_y'].values],\n        names=[None, None],\n        verify_integrity=False\n    )", "response": "Get the links of a FEBRL dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the FEBRL 1 dataset.", "response": "def load_febrl1(return_links=False):\n    \"\"\"Load the FEBRL 1 dataset.\n\n    The Freely Extensible Biomedical Record Linkage (Febrl) package is\n    distributed with a dataset generator and four datasets generated\n    with the generator. This function returns the first Febrl dataset\n    as a :class:`pandas.DataFrame`.\n\n            *\"This data set contains 1000 records (500 original and\n            500 duplicates, with exactly one duplicate per original\n            record.\"*\n\n    Parameters\n    ----------\n    return_links: bool\n        When True, the function returns also the true links.\n\n    Returns\n    -------\n    pandas.DataFrame\n        A :class:`pandas.DataFrame` with Febrl dataset1.csv. When\n        return_links is True, the function returns also the true\n        links. The true links are all links in the lower triangular\n        part of the matrix.\n\n    \"\"\"\n\n    df = _febrl_load_data('dataset1.csv')\n\n    if return_links:\n        links = _febrl_links(df)\n        return df, links\n    else:\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_febrl2(return_links=False):\n\n    df = _febrl_load_data('dataset2.csv')\n\n    if return_links:\n        links = _febrl_links(df)\n        return df, links\n    else:\n        return df", "response": "Loads the FEBRL 2 dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the FEBRL 3 dataset.", "response": "def load_febrl3(return_links=False):\n    \"\"\"Load the FEBRL 3 dataset.\n\n    The Freely Extensible Biomedical Record Linkage (Febrl) package is\n    distributed with a dataset generator and four datasets generated\n    with the generator. This function returns the third Febrl dataset\n    as a :class:`pandas.DataFrame`.\n\n            *\"This data set contains 5000 records (2000 originals and\n            3000 duplicates), with a maximum of 5 duplicates based on\n            one original record (and a Zipf distribution of duplicate\n            records). Distribution of duplicates:\n            168 originals records have 5 duplicate records\n            161 originals records have 4 duplicate records\n            212 originals records have 3 duplicate records\n            256 originals records have 2 duplicate records\n            368 originals records have 1 duplicate record\n            1835 originals records have no duplicate record\"*\n\n    Parameters\n    ----------\n    return_links: bool\n        When True, the function returns also the true links.\n\n    Returns\n    -------\n    pandas.DataFrame\n        A :class:`pandas.DataFrame` with Febrl dataset3.csv. When\n        return_links is True, the function returns also the true\n        links. The true links are all links in the lower triangular\n        part of the matrix.\n\n    \"\"\"\n\n    df = _febrl_load_data('dataset3.csv')\n\n    if return_links:\n        links = _febrl_links(df)\n        return df, links\n    else:\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the FEBRL 4 datasets.", "response": "def load_febrl4(return_links=False):\n    \"\"\"Load the FEBRL 4 datasets.\n\n    The Freely Extensible Biomedical Record Linkage (Febrl) package is\n    distributed with a dataset generator and four datasets generated\n    with the generator. This function returns the fourth Febrl dataset\n    as a :class:`pandas.DataFrame`.\n\n            *\"Generated as one data set with 10000 records (5000\n            originals and 5000  duplicates, with one duplicate per\n            original), the originals have been split from the\n            duplicates, into dataset4a.csv (containing the 5000\n            original records) and dataset4b.csv (containing the\n            5000 duplicate records) These two data sets can be\n            used for testing linkage procedures.\"*\n\n    Parameters\n    ----------\n    return_links: bool\n        When True, the function returns also the true links.\n\n    Returns\n    -------\n    (pandas.DataFrame, pandas.DataFrame)\n        A :class:`pandas.DataFrame` with Febrl dataset4a.csv and a pandas\n        dataframe with Febrl dataset4b.csv. When return_links is True,\n        the function returns also the true links.\n\n    \"\"\"\n\n    df_a = _febrl_load_data('dataset4a.csv')\n    df_b = _febrl_load_data('dataset4b.csv')\n\n    if return_links:\n        links = pandas.MultiIndex.from_arrays([\n            [\"rec-{}-org\".format(i) for i in range(0, 5000)],\n            [\"rec-{}-dup-0\".format(i) for i in range(0, 5000)]]\n        )\n        return df_a, df_b, links\n    else:\n        return df_a, df_b"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the Krebsregister dataset.", "response": "def load_krebsregister(block=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n                       missing_values=None, shuffle=True):\n    \"\"\"Load the Krebsregister dataset.\n\n    This dataset of comparison patterns was obtained in a\n    epidemiological cancer study in Germany. The comparison patterns\n    were created by the Institute for Medical Biostatistics,\n    Epidemiology and Informatics (IMBEI) and the University Medical\n    Center of Johannes Gutenberg University (Mainz, Germany). The\n    dataset is available for research online.\n\n    \"The records represent individual data including first and\n    family name, sex, date of birth and postal code, which were\n    collected through iterative insertions in the course of\n    several years. The comparison patterns in this data set are\n    based on a sample of 100.000 records dating from 2005 to 2008.\n    Data pairs were classified as \"match\" or \"non-match\" during\n    an extensive manual review where several documentarists were\n    involved.  The resulting classification formed the basis for\n    assessing the quality of the registry's own record linkage\n    procedure.\n\n    In order to limit the amount of patterns a blocking procedure\n    was applied, which selects only record pairs that meet\n    specific agreement conditions. The results of the following\n    six blocking iterations were merged together:\n\n    - Phonetic equality of first name and family name, equality of\n      date of birth.\n    - Phonetic equality of first name, equality of day of birth.\n    - Phonetic equality of first name, equality of month of birth.\n    - Phonetic equality of first name, equality of year of birth.\n    - Equality of complete date of birth.\n    - Phonetic equality of family name, equality of sex.\n\n    This procedure resulted in 5.749.132 record pairs, of which\n    20.931 are matches. The data set is split into 10 blocks of\n    (approximately) equal size and ratio of matches to\n    non-matches.\"\n\n    Parameters\n    ----------\n    block : int, list\n        An integer or a list with integers between 1 and 10. The\n        blocks are the blocks explained in the description.\n    missing_values : object, int, float\n        The value of the missing values. Default NaN.\n    shuffle : bool\n        Shuffle the record pairs. Default True.\n\n    Returns\n    -------\n    (pandas.DataFrame, pandas.MultiIndex)\n        A pandas.DataFrame with comparison vectors and a\n        pandas.MultiIndex with the indices of the matches.\n\n    \"\"\"\n\n    # If the data is not found, download it.\n    for i in range(1, 11):\n\n        filepath = os.path.join(os.path.dirname(__file__),\n                                'krebsregister', 'block_{}.zip'.format(i))\n\n        if not os.path.exists(filepath):\n            _download_krebsregister()\n            break\n\n    if isinstance(block, (list, tuple)):\n\n        data = pandas.concat([_krebsregister_block(bl) for bl in block])\n    else:\n\n        data = _krebsregister_block(block)\n\n    if shuffle:\n        data = data.sample(frac=1, random_state=535)\n\n    match_index = data.index[data['is_match']]\n    del data['is_match']\n\n    if pandas.notnull(missing_values):\n        data.fillna(missing_values, inplace=True)\n\n    return data, match_index"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert names or strings into phonetic codes.", "response": "def phonetic(s, method, concat=True, encoding='utf-8', decode_error='strict'):\n    \"\"\"Convert names or strings into phonetic codes.\n\n    The implemented algorithms are `soundex\n    <https://en.wikipedia.org/wiki/Soundex>`_, `nysiis\n    <https://en.wikipedia.org/wiki/New_York_State_Identification_and_\n    Intelligence_System>`_, `metaphone\n    <https://en.wikipedia.org/wiki/Metaphone>`_ or  `match_rating\n    <https://en.wikipedia.org/wiki/Match_rating_approach>`_.\n\n    Parameters\n    ----------\n    s : pandas.Series\n        A pandas.Series with string values (often names) to encode.\n    method: str\n        The algorithm that is used to phonetically encode the values.\n        The possible options are \"soundex\", \"nysiis\", \"metaphone\" or\n        \"match_rating\".\n    concat: bool, optional\n        Remove whitespace before phonetic encoding.\n    encoding: str, optional\n        If bytes are given, this encoding is used to decode. Default\n        is 'utf-8'.\n    decode_error: {'strict', 'ignore', 'replace'}, optional\n        Instruction on what to do if a byte Series is given that\n        contains characters not of the given `encoding`. By default,\n        it is 'strict', meaning that a UnicodeDecodeError will be\n        raised. Other values are 'ignore' and 'replace'.\n\n    Returns\n    -------\n    pandas.Series\n        A Series with phonetic encoded values.\n\n    \"\"\"\n\n    # encoding\n    if sys.version_info[0] == 2:\n        s = s.apply(\n            lambda x: x.decode(encoding, decode_error)\n            if type(x) == bytes else x)\n\n    if concat:\n        s = s.str.replace(r\"[\\-\\_\\s]\", \"\")\n\n    for alg in _phonetic_algorithms:\n        if method in alg['argument_names']:\n            phonetic_callback = alg['callback']\n            break\n    else:\n        raise ValueError(\"The algorithm '{}' is not known.\".format(method))\n\n    return s.str.upper().apply(\n        lambda x: phonetic_callback(x) if pandas.notnull(x) else np.nan\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a block index.", "response": "def block(self, *args, **kwargs):\n        \"\"\"Add a block index.\n\n        Shortcut of :class:`recordlinkage.index.Block`::\n\n            from recordlinkage.index import Block\n\n            indexer = recordlinkage.Index()\n            indexer.add(Block())\n\n        \"\"\"\n        indexer = Block(*args, **kwargs)\n        self.add(indexer)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a Sorted Neighbourhood Index. Shortcut of recordlinkage. index. SortedNeighbourhood ::", "response": "def sortedneighbourhood(self, *args, **kwargs):\n        \"\"\"Add a Sorted Neighbourhood Index.\n\n        Shortcut of :class:`recordlinkage.index.SortedNeighbourhood`::\n\n            from recordlinkage.index import SortedNeighbourhood\n\n            indexer = recordlinkage.Index()\n            indexer.add(SortedNeighbourhood())\n\n        \"\"\"\n        indexer = SortedNeighbourhood(*args, **kwargs)\n        self.add(indexer)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random(self, *args, **kwargs):\n        indexer = Random()\n        self.add(indexer)\n\n        return self", "response": "Add a random index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an exact attribute to the set.", "response": "def exact(self, *args, **kwargs):\n        \"\"\"Compare attributes of pairs exactly.\n\n        Shortcut of :class:`recordlinkage.compare.Exact`::\n\n            from recordlinkage.compare import Exact\n\n            indexer = recordlinkage.Compare()\n            indexer.add(Exact())\n\n        \"\"\"\n        compare = Exact(*args, **kwargs)\n        self.add(compare)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new attribute to the set with the string algorithm.", "response": "def string(self, *args, **kwargs):\n        \"\"\"Compare attributes of pairs with string algorithm.\n\n        Shortcut of :class:`recordlinkage.compare.String`::\n\n            from recordlinkage.compare import String\n\n            indexer = recordlinkage.Compare()\n            indexer.add(String())\n\n        \"\"\"\n        compare = String(*args, **kwargs)\n        self.add(compare)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef numeric(self, *args, **kwargs):\n        compare = Numeric(*args, **kwargs)\n        self.add(compare)\n\n        return self", "response": "Add a numeric attribute to the set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef geo(self, *args, **kwargs):\n        compare = Geographic(*args, **kwargs)\n        self.add(compare)\n\n        return self", "response": "Add a geographic attribute to the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef date(self, *args, **kwargs):\n        compare = Date(*args, **kwargs)\n        self.add(compare)\n\n        return self", "response": "Add a date to the set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the reduction ratio of a candidate record set.", "response": "def reduction_ratio(links_pred, *total):\n    \"\"\"Compute the reduction ratio.\n\n    The reduction ratio is 1 minus the ratio candidate matches and the maximum\n    number of pairs possible.\n\n    Parameters\n    ----------\n    links_pred: int, pandas.MultiIndex\n        The number of candidate record pairs or the pandas.MultiIndex with\n        record pairs.\n    *total: pandas.DataFrame object(s)\n        The DataFrames are used to compute the full index size with the\n        full_index_size function.\n\n    Returns\n    -------\n    float\n        The reduction ratio.\n\n    \"\"\"\n\n    n_max = full_index_size(*total)\n\n    if isinstance(links_pred, pandas.MultiIndex):\n        links_pred = len(links_pred)\n\n    if links_pred > n_max:\n        raise ValueError(\"n has to be smaller of equal n_max\")\n\n    return 1 - links_pred / n_max"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the maximum number of record pairs possible.", "response": "def max_pairs(shape):\n    \"\"\"[DEPRECATED] Compute the maximum number of record pairs possible.\"\"\"\n\n    if not isinstance(shape, (tuple, list)):\n        x = get_length(shape)\n        n = int(x * (x - 1) / 2)\n\n    elif (isinstance(shape, (tuple, list)) and len(shape) == 1):\n        x = get_length(shape[0])\n        n = int(x * (x - 1) / 2)\n\n    else:\n        n = numpy.prod([get_length(xi) for xi in shape])\n\n    return n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the number of records in a full index.", "response": "def full_index_size(*args):\n    \"\"\"Compute the number of records in a full index.\n\n    Compute the number of records in a full index without building the index\n    itself. The result is the maximum number of record pairs possible. This\n    function is especially useful in measures like the `reduction_ratio`.\n\n    Deduplication: Given a DataFrame A with length N, the full index size is\n    N*(N-1)/2. Linking: Given a DataFrame A with length N and a DataFrame B\n    with length M, the full index size is N*M.\n\n    Parameters\n    ----------\n    *args: int, pandas.MultiIndex, pandas.Series, pandas.DataFrame\n        A pandas object or a int representing the length of a dataset to link.\n        When there is one argument, it is assumed that the record linkage is\n        a deduplication process.\n\n    Examples\n    --------\n\n    Use integers:\n    >>> full_index_size(10)  # deduplication: 45 pairs\n    >>> full_index_size(10, 10)  # linking: 100 pairs\n\n    or pandas objects\n    >>> full_index_size(DF)  # deduplication: len(DF)*(len(DF)-1)/2 pairs\n    >>> full_index_size(DF, DF)  # linking: len(DF)*len(DF) pairs\n\n    \"\"\"\n\n    # check if a list or tuple is passed as argument\n    if len(args) == 1 and isinstance(args[0], (list, tuple)):\n        args = tuple(args[0])\n\n    if len(args) == 1:\n        n = get_length(args[0])\n        size = int(n * (n - 1) / 2)\n    else:\n        size = numpy.prod([get_length(arg) for arg in args])\n\n    return size"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef true_positives(links_true, links_pred):\n\n    links_true = _get_multiindex(links_true)\n    links_pred = _get_multiindex(links_pred)\n\n    return len(links_true & links_pred)", "response": "Count the number of true positives in a node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncounting the number of true negatives.", "response": "def true_negatives(links_true, links_pred, total):\n    \"\"\"Count the number of True Negatives.\n\n    Returns the number of correctly predicted non-links, also called the\n    number of True Negatives (TN).\n\n    Parameters\n    ----------\n    links_true: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The true (or actual) links.\n    links_pred: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The predicted links.\n    total: int, pandas.MultiIndex\n        The count of all record pairs (both links and non-links). When the\n        argument is a pandas.MultiIndex, the length of the index is used.\n\n    Returns\n    -------\n    int\n        The number of correctly predicted non-links.\n\n    \"\"\"\n\n    links_true = _get_multiindex(links_true)\n    links_pred = _get_multiindex(links_pred)\n\n    if isinstance(total, pandas.MultiIndex):\n        total = len(total)\n\n    return int(total) - len(links_true | links_pred)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncount the number of false positives in a true non - links.", "response": "def false_positives(links_true, links_pred):\n    \"\"\"Count the number of False Positives.\n\n    Returns the number of incorrect predictions of true non-links. (true non-\n    links, but predicted as links). This value is known as the number of False\n    Positives (FP).\n\n    Parameters\n    ----------\n    links_true: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The true (or actual) links.\n    links_pred: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The predicted links.\n\n    Returns\n    -------\n    int\n        The number of false positives.\n\n    \"\"\"\n\n    links_true = _get_multiindex(links_true)\n    links_pred = _get_multiindex(links_pred)\n\n    return len(links_pred.difference(links_true))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncount the number of false negatives.", "response": "def false_negatives(links_true, links_pred):\n    \"\"\"Count the number of False Negatives.\n\n    Returns the number of incorrect predictions of true links. (true links,\n    but predicted as non-links). This value is known as the number of False\n    Negatives (FN).\n\n    Parameters\n    ----------\n    links_true: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The true (or actual) links.\n    links_pred: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The predicted links.\n\n    Returns\n    -------\n    int\n        The number of false negatives.\n\n    \"\"\"\n\n    links_true = _get_multiindex(links_true)\n    links_pred = _get_multiindex(links_pred)\n\n    return len(links_true.difference(links_pred))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef confusion_matrix(links_true, links_pred, total=None):\n\n    links_true = _get_multiindex(links_true)\n    links_pred = _get_multiindex(links_pred)\n\n    tp = true_positives(links_true, links_pred)\n    fp = false_positives(links_true, links_pred)\n    fn = false_negatives(links_true, links_pred)\n\n    if total is None:\n        tn = numpy.nan\n    else:\n        tn = true_negatives(links_true, links_pred, total)\n\n    return numpy.array([[tp, fn], [fp, tn]])", "response": "Compute the confusion matrix for a single node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the precision of a node in a node set.", "response": "def precision(links_true, links_pred=None):\n    \"\"\"precision(links_true, links_pred)\n\n    Compute the precision.\n\n    The precision is given by TP/(TP+FP).\n\n    Parameters\n    ----------\n    links_true: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The true (or actual) collection of links.\n    links_pred: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The predicted collection of links.\n\n    Returns\n    -------\n    float\n        The precision\n    \"\"\"\n\n    if _isconfusionmatrix(links_true):\n\n        confusion_matrix = links_true\n\n        v = confusion_matrix[0, 0] \\\n            / (confusion_matrix[0, 0] + confusion_matrix[1, 0])\n    else:\n\n        tp = true_positives(links_true, links_pred)\n        fp = false_positives(links_true, links_pred)\n        v = tp / (tp + fp)\n\n    return float(v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the recall of a single node.", "response": "def recall(links_true, links_pred=None):\n    \"\"\"recall(links_true, links_pred)\n\n    Compute the recall/sensitivity.\n\n    The recall is given by TP/(TP+FN).\n\n    Parameters\n    ----------\n    links_true: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The true (or actual) collection of links.\n    links_pred: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The predicted collection of links.\n\n    Returns\n    -------\n    float\n        The recall\n    \"\"\"\n\n    if _isconfusionmatrix(links_true):\n\n        confusion_matrix = links_true\n\n        v = confusion_matrix[0, 0] \\\n            / (confusion_matrix[0, 0] + confusion_matrix[0, 1])\n    else:\n\n        tp = true_positives(links_true, links_pred)\n        fn = false_negatives(links_true, links_pred)\n        v = tp / (tp + fn)\n\n    return float(v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the accuracy of a single record pair.", "response": "def accuracy(links_true, links_pred=None, total=None):\n    \"\"\"accuracy(links_true, links_pred, total)\n\n    Compute the accuracy.\n\n    The accuracy is given by (TP+TN)/(TP+FP+TN+FN).\n\n    Parameters\n    ----------\n    links_true: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The true (or actual) collection of links.\n    links_pred: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The predicted collection of links.\n    total: int, pandas.MultiIndex\n        The count of all record pairs (both links and non-links). When the\n        argument is a pandas.MultiIndex, the length of the index is used.\n\n    Returns\n    -------\n    float\n        The accuracy\n    \"\"\"\n\n    if _isconfusionmatrix(links_true):\n\n        confusion_matrix = links_true\n\n        v = (confusion_matrix[0, 0] + confusion_matrix[1, 1]) \\\n            / numpy.sum(confusion_matrix)\n    else:\n\n        tp = true_positives(links_true, links_pred)\n        tn = true_negatives(links_true, links_pred, total)\n\n        v = (tp + tn) / total\n\n    return float(v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the specificity of a single record pair.", "response": "def specificity(links_true, links_pred=None, total=None):\n    \"\"\"specificity(links_true, links_pred, total)\n\n    Compute the specificity.\n\n    The specificity is given by TN/(FP+TN).\n\n    Parameters\n    ----------\n    links_true: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The true (or actual) collection of links.\n    links_pred: pandas.MultiIndex, pandas.DataFrame, pandas.Series\n        The predicted collection of links.\n    total: int, pandas.MultiIndex\n        The count of all record pairs (both links and non-links). When the\n        argument is a pandas.MultiIndex, the length of the index is used.\n\n    Returns\n    -------\n    float\n        The specificity\n\n    \"\"\"\n\n    if _isconfusionmatrix(links_true):\n\n        confusion_matrix = links_true\n\n        v = confusion_matrix[1, 1] / \\\n            (confusion_matrix[1, 0] + confusion_matrix[1, 1])\n    else:\n\n        fp = false_positives(links_true, links_pred)\n        tn = true_negatives(links_true, links_pred, total)\n        v = tn / (fp + tn)\n\n    return float(v)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fscore(links_true, links_pred=None):\n\n    prec = precision(links_true, links_pred)\n    rec = recall(links_true, links_pred)\n\n    return float(2 * prec * rec / (prec + rec))", "response": "Compute the F - score of a set of links."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute continuous random values for each record pair.", "response": "def compute(self, pairs, x=None, x_link=None):\n        \"\"\"Return continuous random values for each record pair.\n\n        Parameters\n        ----------\n        pairs : pandas.MultiIndex\n            A pandas MultiIndex with the record pairs to compare. The indices\n            in the MultiIndex are indices of the DataFrame(s) to link.\n        x : pandas.DataFrame\n            The DataFrame to link. If `x_link` is given, the comparing is a\n            linking problem. If `x_link` is not given, the problem is one of\n            deduplication.\n        x_link : pandas.DataFrame, optional\n            The second DataFrame.\n\n        Returns\n        -------\n        pandas.Series, pandas.DataFrame, numpy.ndarray\n            The result of comparing record pairs (the features). Can be\n            a tuple with multiple pandas.Series, pandas.DataFrame,\n            numpy.ndarray objects.\n        \"\"\"\n\n        df_empty = pd.DataFrame(index=pairs)\n        return self._compute(\n            tuple([df_empty]),\n            tuple([df_empty])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parallel_compare_helper(class_obj, pairs, x, x_link=None):\n    return class_obj._compute(pairs, x, x_link)", "response": "Internal function to overcome pickling problem in python2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chunk_pandas(frame_or_series, chunksize=None):\n    if not isinstance(chunksize, int):\n        raise ValueError('argument chunksize needs to be integer type')\n\n    bins = np.arange(0, len(frame_or_series), step=chunksize)\n\n    for b in bins:\n\n        yield frame_or_series[b:b + chunksize]", "response": "Chunk a frame into smaller equal parts."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a model to the index algorithm list.", "response": "def add(self, model):\n        \"\"\"Add a index method.\n\n        This method is used to add index algorithms. If multiple algorithms\n        are added, the union of the record pairs from the algorithm is taken.\n\n        Parameters\n        ----------\n        model : list, class\n            A (list of) index algorithm(s) from\n            :mod:`recordlinkage.index`.\n        \"\"\"\n        if isinstance(model, list):\n            self.algorithms = self.algorithms + model\n        else:\n            self.algorithms.append(model)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index(self, x, x_link=None):\n        if not self.algorithms:\n            raise ValueError(\"No algorithms given.\")\n\n        # start timing\n        start_time = time.time()\n\n        pairs = None\n        for cl_alg in self.algorithms:\n            pairs_i = cl_alg.index(x, x_link)\n\n            if pairs is None:\n                pairs = pairs_i\n            else:\n                pairs = pairs.union(pairs_i)\n\n        if x_link is not None:\n            n_max = max_pairs((x, x_link))\n        else:\n            n_max = max_pairs(x)\n\n        # store the number of pairs\n        n = pairs.shape[0]\n        eta = time.time() - start_time\n        rr = 1 - n / n_max\n        i_max = '?' if self._i_max is None else self._i_max\n\n        self._eta.append(eta)\n        self._n.append(n)\n        self._n_max.append(n_max)\n\n        # log\n        logging.info(\"indexing [{:d}/{}] - time: {:.2f}s - pairs: {:d}/{:d} - \"\n                     \"rr: {:0.5f}\".format(self._i, i_max, eta, n, n_max, rr))\n\n        # log total\n        if self._output_log_total:\n\n            n_total = np.sum(self._n)\n            n_max_total = np.sum(self._n_max)\n            rr_avg = 1 - n_total / n_max_total\n            eta_total = np.sum(self._eta)\n\n            logging.info(\"indexing [{:d}/{}] - time: {:.2f}s - \"\n                         \"pairs_total: {:d}/{:d} - rr_total: {:0.5f}\".format(\n                             self._i, i_max, eta_total,\n                             n_total, n_max_total, rr_avg))\n\n        self._i += 1\n\n        return pairs", "response": "Make an index of record pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding an index for deduplicating a dataset.", "response": "def _dedup_index(self, df_a):\n        \"\"\"Build an index for deduplicating a dataset.\n\n        Parameters\n        ----------\n        df_a : (tuple of) pandas.Series\n            The data of the DataFrame to build the index with.\n\n        Returns\n        -------\n        pandas.MultiIndex\n            A pandas.MultiIndex with record pairs. Each record pair\n            contains the index values of two records. The records are\n            sampled from the lower triangular part of the matrix.\n        \"\"\"\n        pairs = self._link_index(df_a, df_a)\n\n        # Remove all pairs not in the lower triangular part of the matrix.\n        # This part can be inproved by not comparing the level values, but the\n        # level itself.\n        pairs = pairs[pairs.labels[0] > pairs.labels[1]]\n\n        return pairs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef index(self, x, x_link=None):\n        if x is None:  # error\n            raise ValueError(\"provide at least one dataframe\")\n        elif x_link is not None:  # linking (two arg)\n            x = (x, x_link)\n        elif isinstance(x, (list, tuple)):  # dedup or linking (single arg)\n            x = tuple(x)\n        else:  # dedup (single arg)\n            x = (x,)\n\n        if self.verify_integrity:\n\n            for df in x:\n                self._verify_integrety(df)\n\n        # linking\n        if not self._deduplication(x):\n\n            pairs = self._link_index(*x)\n            names = self._make_index_names(x[0].index.name, x[1].index.name)\n\n        # deduplication\n        else:\n\n            pairs = self._dedup_index(*x)\n            names = self._make_index_names(x[0].index.name, x[0].index.name)\n\n        pairs.rename(names, inplace=True)\n\n        return pairs", "response": "Make an index of record pairs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the vectorized version of the record pairs.", "response": "def _compute_vectorized(self, *args):\n        \"\"\"Compare attributes (vectorized)\n\n        Parameters\n        ----------\n        *args : pandas.Series\n            pandas.Series' as arguments.\n\n        Returns\n        -------\n        pandas.Series, pandas.DataFrame, numpy.ndarray\n            The result of comparing record pairs (the features). Can be\n            a tuple with multiple pandas.Series, pandas.DataFrame,\n            numpy.ndarray objects.\n\n        \"\"\"\n        if self._f_compare_vectorized:\n            return self._f_compare_vectorized(\n                *(args + self.args), **self.kwargs)\n        else:\n            raise NotImplementedError()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompares the data on the left and right.", "response": "def _compute(self, left_on, right_on):\n        \"\"\"Compare the data on the left and right.\n\n        :meth:`BaseCompareFeature._compute` and\n        :meth:`BaseCompareFeature.compute` differ on the accepted\n        arguments. `_compute` accepts indexed data while `compute`\n        accepts the record pairs and the DataFrame's.\n\n        Parameters\n        ----------\n        left_on : (tuple of) pandas.Series\n            Data to compare with `right_on`\n        right_on : (tuple of) pandas.Series\n            Data to compare with `left_on`\n\n        Returns\n        -------\n        pandas.Series, pandas.DataFrame, numpy.ndarray\n            The result of comparing record pairs (the features). Can be\n            a tuple with multiple pandas.Series, pandas.DataFrame,\n            numpy.ndarray objects.\n        \"\"\"\n        result = self._compute_vectorized(*tuple(left_on + right_on))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute(self, pairs, x, x_link=None):\n        if not is_pandas_2d_multiindex(pairs):\n            raise ValueError(\n                \"expected pandas.MultiIndex with record pair indices \"\n                \"as first argument\"\n            )\n\n        if not isinstance(x, pandas.DataFrame):\n            raise ValueError(\"expected pandas.DataFrame as second argument\")\n\n        if x_link is not None and not isinstance(x_link, pandas.DataFrame):\n            raise ValueError(\"expected pandas.DataFrame as third argument\")\n\n        labels_left = listify(self.labels_left, [])\n        labels_right = listify(self.labels_right, [])\n\n        if x_link is None:\n            df_a = frame_indexing(x[labels_left + labels_right], pairs, 0)\n            data1 = tuple([df_a[lbl] for lbl in listify(self.labels_left)])\n            data2 = tuple([df_a[lbl] for lbl in listify(self.labels_right)])\n        else:\n            df_a = frame_indexing(x[labels_left], pairs, 0)\n            data1 = tuple([df_a[lbl] for lbl in listify(self.labels_left)])\n            df_b = frame_indexing(x_link[labels_right], pairs, 1)\n            data2 = tuple([df_b[lbl] for lbl in listify(self.labels_right)])\n\n        results = self._compute(data1, data2)\n\n        return results", "response": "Compute the record pairs of each record pair."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the similarity between two recordlinkage entries.", "response": "def compare_vectorized(self, comp_func, labels_left, labels_right,\n                           *args, **kwargs):\n        \"\"\"Compute the similarity between values with a callable.\n\n        This method initialises the comparing of values with a custom\n        function/callable. The function/callable should accept\n        numpy.ndarray's.\n\n        Example\n        -------\n\n        >>> comp = recordlinkage.Compare()\n        >>> comp.compare_vectorized(custom_callable, 'first_name', 'name')\n        >>> comp.compare(PAIRS, DATAFRAME1, DATAFRAME2)\n\n        Parameters\n        ----------\n        comp_func : function\n            A comparison function. This function can be a built-in function\n            or a user defined comparison function. The function should accept\n            numpy.ndarray's as first two arguments.\n        labels_left : label, pandas.Series, pandas.DataFrame\n            The labels, Series or DataFrame to compare.\n        labels_right : label, pandas.Series, pandas.DataFrame\n            The labels, Series or DataFrame to compare.\n        *args :\n            Additional arguments to pass to callable comp_func.\n        **kwargs :\n            Additional keyword arguments to pass to callable comp_func.\n            (keyword 'label' is reserved.)\n        label : (list of) label(s)\n            The name of the feature and the name of the column. IMPORTANT:\n            This argument is a keyword argument and can not be part of the\n            arguments of comp_func.\n        \"\"\"\n        label = kwargs.pop('label', None)\n\n        if isinstance(labels_left, tuple):\n            labels_left = list(labels_left)\n\n        if isinstance(labels_right, tuple):\n            labels_right = list(labels_right)\n\n        feature = BaseCompareFeature(\n            labels_left, labels_right, args, kwargs, label=label)\n        feature._f_compare_vectorized = comp_func\n\n        self.add(feature)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all labels of the left dataframe.", "response": "def _get_labels_left(self, validate=None):\n        \"\"\"Get all labels of the left dataframe.\"\"\"\n\n        labels = []\n\n        for compare_func in self.features:\n\n            labels = labels + listify(compare_func.labels_left)\n\n        # check requested labels (for better error messages)\n        if not is_label_dataframe(labels, validate):\n            error_msg = \"label is not found in the dataframe\"\n            raise KeyError(error_msg)\n\n        return unique(labels)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_labels_right(self, validate=None):\n        labels = []\n\n        for compare_func in self.features:\n\n            labels = labels + listify(compare_func.labels_right)\n\n        # check requested labels (for better error messages)\n        if not is_label_dataframe(labels, validate):\n            error_msg = \"label is not found in the dataframe\"\n            raise KeyError(error_msg)\n\n        return unique(labels)", "response": "Get all labels of the right dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _union(self, objs, index=None, column_i=0):\n        feat_conc = []\n\n        for feat, label in objs:\n\n            # result is tuple of results\n            if isinstance(feat, tuple):\n                if label is None:\n                    label = [None] * len(feat)\n\n                partial_result = self._union(\n                    zip(feat, label), column_i=column_i)\n                feat_conc.append(partial_result)\n                column_i = column_i + partial_result.shape[1]\n\n            # result is pandas.Series.\n            elif isinstance(feat, pandas.Series):\n                feat.reset_index(drop=True, inplace=True)\n                if label is None:\n                    label = column_i\n                feat.rename(label, inplace=True)\n                feat_conc.append(feat)\n                column_i = column_i + 1\n\n            # result is pandas.DataFrame\n            elif isinstance(feat, pandas.DataFrame):\n                feat.reset_index(drop=True, inplace=True)\n                if label is None:\n                    label = np.arange(column_i, column_i + feat.shape[1])\n                feat.columns = label\n                feat_conc.append(feat)\n                column_i = column_i + feat.shape[1]\n\n            # result is numpy 1d array\n            elif is_numpy_like(feat) and len(feat.shape) == 1:\n                if label is None:\n                    label = column_i\n                f = pandas.Series(feat, name=label, copy=False)\n\n                feat_conc.append(f)\n                column_i = column_i + 1\n\n            # result is numpy 2d array\n            elif is_numpy_like(feat) and len(feat.shape) == 2:\n                if label is None:\n                    label = np.arange(column_i, column_i + feat.shape[1])\n                feat_df = pandas.DataFrame(feat, columns=label, copy=False)\n                if label is None:\n                    feat_df.columns = [None for _ in range(feat_df.shape[1])]\n                feat_conc.append(feat_df)\n                column_i = column_i + feat.shape[1]\n\n            # other results are not (yet) supported\n            else:\n                raise ValueError(\"expected numpy.ndarray or \"\n                                 \"pandas object to be returned, \"\n                                 \"got '{}'\".format(feat.__class__.__name__))\n\n        result = pandas.concat(feat_conc, axis=1, copy=False)\n        if index is not None:\n            result.set_index(index, inplace=True)\n\n        return result", "response": "This function creates a union of the features."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute(self, pairs, x, x_link=None):\n        if not isinstance(pairs, pandas.MultiIndex):\n            raise ValueError(\n                \"expected pandas.MultiIndex with record pair indices \"\n                \"as first argument\"\n            )\n\n        if not isinstance(x, pandas.DataFrame):\n            raise ValueError(\"expected pandas.DataFrame as second argument\")\n\n        if x_link is not None and not isinstance(x_link, pandas.DataFrame):\n            raise ValueError(\"expected pandas.DataFrame as third argument\")\n\n        if self.n_jobs == 1:\n            results = self._compute(pairs, x, x_link)\n        elif self.n_jobs > 1:\n            results = self._compute_parallel(\n                pairs, x, x_link, n_jobs=self.n_jobs)\n        else:\n            raise ValueError(\"number of jobs should be positive integer\")\n\n        return results", "response": "Compare the records of each record pair with the records of each feature vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit(self, comparison_vectors, match_index=None):\n        logging.info(\"Classification - start training {}\".format(\n            self.__class__.__name__)\n        )\n\n        self._initialise_classifier(comparison_vectors)\n\n        # start timing\n        start_time = time.time()\n\n        if isinstance(match_index, (pandas.MultiIndex, pandas.Index)):\n\n            try:\n                y = pandas.Series(0, index=comparison_vectors.index)\n                y.loc[match_index & comparison_vectors.index] = 1\n            except pandas.IndexError as err:\n\n                # The are no matches. So training is not possible.\n                if len(match_index & comparison_vectors.index) == 0:\n                    raise LearningError(\n                        \"both matches and non-matches needed in the\" +\n                        \"trainingsdata, only non-matches found\"\n                    )\n                else:\n                    raise err\n\n            self._fit(comparison_vectors.values, y.values)\n\n        elif match_index is None:\n            self._fit(comparison_vectors.values)\n        else:\n            raise ValueError(\n                \"'match_index' has incorrect type '{}'\".format(\n                    type(match_index)\n                )\n            )\n\n        # log timing\n        logf_time = \"Classification - training computation time: ~{:.2f}s\"\n        logging.info(logf_time.format(time.time() - start_time))", "response": "Train the classifier with the given comparison vectors."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit_predict(self, comparison_vectors, match_index=None):\n        self.fit(comparison_vectors, match_index)\n        result = self.predict(comparison_vectors)\n\n        return result", "response": "Train the classifier and predict the recordlinkage."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npredicts the class of the record pairs based on their comparison vectors into matches non - matches and possible matches.", "response": "def predict(self, comparison_vectors):\n        \"\"\"Predict the class of the record pairs.\n\n        Classify a set of record pairs based on their comparison vectors into\n        matches, non-matches and possible matches. The classifier has to be\n        trained to call this method.\n\n        Parameters\n        ----------\n        comparison_vectors : pandas.DataFrame\n            Dataframe with comparison vectors.\n        return_type : str\n            Deprecated. Use recordlinkage.options instead. Use the option\n            `recordlinkage.set_option('classification.return_type', 'index')`\n            instead.\n\n        Returns\n        -------\n        pandas.Series\n            A pandas Series with the labels 1 (for the matches) and 0 (for the\n            non-matches).\n\n        \"\"\"\n        logging.info(\"Classification - predict matches and non-matches\")\n\n        # make the predicition\n        prediction = self._predict(comparison_vectors.values)\n        self._post_predict(prediction)\n\n        # format and return the result\n        return self._return_result(prediction, comparison_vectors)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the probabilities for each record pair.", "response": "def prob(self, comparison_vectors, return_type=None):\n        \"\"\"Compute the probabilities for each record pair.\n\n        For each pair of records, estimate the probability of being a match.\n\n        Parameters\n        ----------\n        comparison_vectors : pandas.DataFrame\n            The dataframe with comparison vectors.\n        return_type : str\n            Deprecated. (default 'series')\n\n        Returns\n        -------\n        pandas.Series or numpy.ndarray\n            The probability of being a match for each record pair.\n\n        \"\"\"\n        if return_type is not None:\n            warnings.warn(\"The argument 'return_type' is removed. \"\n                          \"Default value is now 'series'.\",\n                          VisibleDeprecationWarning, stacklevel=2)\n\n        logging.info(\"Classification - compute probabilities\")\n\n        prob_match = self._prob_match(comparison_vectors.values)\n        return pandas.Series(prob_match, index=comparison_vectors.index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _return_result(self, result, comparison_vectors=None):\n        return_type = cf.get_option('classification.return_type')\n\n        if type(result) != np.ndarray:\n            raise ValueError(\"numpy.ndarray expected.\")\n\n        # return the pandas.MultiIndex\n        if return_type == 'index':\n            return comparison_vectors.index[result.astype(bool)]\n\n        # return a pandas.Series\n        elif return_type == 'series':\n            return pandas.Series(\n                result,\n                index=comparison_vectors.index,\n                name='classification')\n\n        # return a numpy.ndarray\n        elif return_type == 'array':\n            return result\n\n        # return_type not known\n        else:\n            raise ValueError(\n                \"return_type {} unknown. Choose 'index', 'series' or \"\n                \"'array'\".format(return_type))", "response": "Return the result of the classification."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a set of binary comparison vectors for the given number of matching record pairs.", "response": "def binary_vectors(n, n_match, m=[0.9] * 8, u=[0.1] * 8,\n                   random_state=None, return_links=False, dtype=np.int8):\n    \"\"\"Generate random binary comparison vectors.\n\n    This function is used to generate random comparison vectors. The\n    result of each comparison is a binary value (0 or 1).\n\n    Parameters\n    ----------\n    n : int\n        The total number of comparison vectors.\n    n_match : int\n        The number of matching record pairs.\n    m : list, default [0.9] * 8, optional\n        A list of m probabilities of each partially identifying\n        variable. The m probability is the probability that an\n        identifier in matching record pairs agrees.\n    u : list, default [0.9] * 8, optional\n        A list of u probabilities of each partially identifying\n        variable. The u probability is the probability that an\n        identifier in non-matching record pairs agrees.\n    random_state : int or numpy.random.RandomState, optional\n        Seed for the random number generator with an integer or numpy\n        RandomState object.\n    return_links: bool\n        When True, the function returns also the true links.\n    dtype: numpy.dtype\n        The dtype of each column in the returned DataFrame.\n\n    Returns\n    -------\n    pandas.DataFrame\n        A dataframe with comparison vectors.\n\n\n    \"\"\"\n\n    if len(m) != len(u):\n        raise ValueError(\"the length of 'm' is not equal the length of 'u'\")\n\n    if n_match >= n or n_match < 0:\n        raise ValueError(\"the number of matches is bounded by [0, n]\")\n\n    # set the random seed\n    np.random.seed(random_state)\n\n    matches = []\n    nonmatches = []\n\n    sample_set = np.array([0, 1], dtype=dtype)\n\n    for i, _ in enumerate(m):\n\n        p_mi = [1 - m[i], m[i]]\n        p_ui = [1 - u[i], u[i]]\n\n        comp_mi = np.random.choice(sample_set, (n_match, 1), p=p_mi)\n        comp_ui = np.random.choice(sample_set, (n - n_match, 1), p=p_ui)\n\n        nonmatches.append(comp_ui)\n        matches.append(comp_mi)\n\n    match_block = np.concatenate(matches, axis=1)\n    nonmatch_block = np.concatenate(nonmatches, axis=1)\n\n    data_np = np.concatenate((match_block, nonmatch_block), axis=0)\n    index_np = np.random.randint(1001, 1001 + n * 2, (n, 2))\n\n    data_col_names = ['c_%s' % (i + 1) for i in range(len(m))]\n    data_mi = pd.MultiIndex.from_arrays([index_np[:, 0], index_np[:, 1]])\n    data_df = pd.DataFrame(data_np, index=data_mi, columns=data_col_names)\n\n    features = data_df.sample(frac=1, random_state=random_state)\n\n    if return_links:\n        links = data_mi[:n_match]\n        return features, links\n    else:\n        return features"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the position of the match class.", "response": "def _match_class_pos(self):\n        \"\"\"Return the position of the match class.\"\"\"\n        # TODO: add notfitted warnings\n        if self.kernel.classes_.shape[0] != 2:\n            raise ValueError(\"Number of classes is {}, expected 2.\".format(\n                self.kernel.classes_.shape[0]))\n\n        # # get the position of match probabilities\n        # classes = list(self.kernel.classes_)\n        # return classes.index(1)\n\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the position of the non - match class.", "response": "def _nonmatch_class_pos(self):\n        \"\"\"Return the position of the non-match class.\"\"\"\n        # TODO: add notfitted warnings\n        if self.kernel.classes_.shape[0] != 2:\n            raise ValueError(\"Number of classes is {}, expected 2.\".format(\n                self.kernel.classes_.shape[0]))\n\n        # # get the position of match probabilities\n        # classes = list(self.kernel.classes_)\n        # return classes.index(0)\n\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log_m_probs(self):\n        m = self.kernel.feature_log_prob_[self._match_class_pos()]\n        return self._prob_inverse_transform(m)", "response": "Log probability P ( x_i == 1 | Match class"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log_u_probs(self):\n        u = self.kernel.feature_log_prob_[self._nonmatch_class_pos()]\n        return self._prob_inverse_transform(u)", "response": "Log probability P ( x_i == 1 | Non - match ) as described in the FS framework."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_weights(self):\n        m = self.kernel.feature_log_prob_[self._match_class_pos()]\n        u = self.kernel.feature_log_prob_[self._nonmatch_class_pos()]\n\n        return self._prob_inverse_transform(m - u)", "response": "Log weights as described in the FS framework."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef u_probs(self):\n        log_u = self.kernel.feature_log_prob_[self._nonmatch_class_pos()]\n\n        return self._prob_inverse_transform(numpy.exp(log_u))", "response": "Probability P ( x_i == 1 |Non - match ) as described in the FS framework."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef weights(self):\n        m = self.kernel.feature_log_prob_[self._match_class_pos()]\n        u = self.kernel.feature_log_prob_[self._nonmatch_class_pos()]\n\n        return self._prob_inverse_transform(numpy.exp(m - u))", "response": "Weights as described in the FS framework."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the centers of the clusters.", "response": "def _initialise_classifier(self, comparison_vectors):\n        \"\"\"Set the centers of the clusters.\"\"\"\n\n        # Set the start point of the classifier.\n        self.kernel.init = numpy.array(\n            [[0.05] * len(list(comparison_vectors)),\n             [0.95] * len(list(comparison_vectors))])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if label existance", "response": "def is_label_dataframe(label, df):\n    \"\"\"check column label existance\"\"\"\n\n    setdiff = set(label) - set(df.columns.tolist())\n\n    if len(setdiff) == 0:\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a list of the argument if it is not a list.", "response": "def listify(x, none_value=[]):\n    \"\"\"Make a list of the argument if it is not a list.\"\"\"\n\n    if isinstance(x, list):\n        return x\n    elif isinstance(x, tuple):\n        return list(x)\n    elif x is None:\n        return none_value\n    else:\n        return [x]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplicates MultiIndex. to_frame which is used in pandas 0. 21.", "response": "def multi_index_to_frame(index):\n    \"\"\"\n    Replicates MultiIndex.to_frame, which was introduced in pandas 0.21,\n    for the sake of backwards compatibility.\n    \"\"\"\n    return pandas.DataFrame(index.tolist(), index=index, columns=index.names)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef index_split(index, chunks):\n\n    Ntotal = index.shape[0]\n    Nsections = int(chunks)\n    if Nsections <= 0:\n        raise ValueError('number sections must be larger than 0.')\n    Neach_section, extras = divmod(Ntotal, Nsections)\n    section_sizes = ([0] + extras * [Neach_section + 1] +\n                     (Nsections - extras) * [Neach_section])\n    div_points = numpy.array(section_sizes).cumsum()\n\n    sub_ind = []\n    for i in range(Nsections):\n        st = div_points[i]\n        end = div_points[i + 1]\n        sub_ind.append(index[st:end])\n\n    return sub_ind", "response": "Function to split pandas. Index and pandas. MultiIndex objects into chunks."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nindexes dataframe based on one level of MultiIndex.", "response": "def frame_indexing(frame, multi_index, level_i, indexing_type='label'):\n    \"\"\"Index dataframe based on one level of MultiIndex.\n\n    Arguments\n    ---------\n    frame : pandas.DataFrame\n        The datafrme to select records from.\n    multi_index : pandas.MultiIndex\n        A pandas multiindex were one fo the levels is used to sample the\n        dataframe with.\n    level_i : int, str\n        The level of the multiIndex to index on.\n    indexing_type : str\n        The type of indexing. The value can be 'label' or 'position'.\n        Default 'label'.\n\n    \"\"\"\n\n    if indexing_type == \"label\":\n        data = frame.loc[multi_index.get_level_values(level_i)]\n        data.index = multi_index\n    elif indexing_type == \"position\":\n        data = frame.iloc[multi_index.get_level_values(level_i)]\n        data.index = multi_index\n    else:\n        raise ValueError(\"indexing_type needs to be 'label' or 'position'\")\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fillna(series_or_arr, missing_value=0.0):\n\n    if pandas.notnull(missing_value):\n        if isinstance(series_or_arr, (numpy.ndarray)):\n            series_or_arr[numpy.isnan(series_or_arr)] = missing_value\n        else:\n            series_or_arr.fillna(missing_value, inplace=True)\n\n    return series_or_arr", "response": "Fill missing values in pandas objects and numpy arrays."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_related_model(field):\n    model = None\n\n    if hasattr(field, 'related_model') and field.related_model:   #  pragma: no cover\n        model = field.related_model\n    # Django<1.8 doesn't have the related_model API, so we need to use rel,\n    # which was removed in Django 2.0\n    elif hasattr(field, 'rel') and field.rel:  # pragma: no cover\n        model = field.rel.to\n\n    return model", "response": "Gets the related model from a related field"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a pivot table from the current model.", "response": "def to_pivot_table(self, fieldnames=(), verbose=True,\n                       values=None, rows=None, cols=None,\n                       aggfunc='mean', fill_value=None, margins=False,\n                       dropna=True, coerce_float=True):\n        \"\"\"\n        A convenience method for creating a spread sheet style pivot table\n        as a DataFrame\n        Parameters\n        ----------\n        fieldnames:  The model field names(columns) to utilise in creating\n                     the DataFrame. You can span a relationships in the usual\n                     Django ORM way by using the foreign key field name\n                     separated by double underscores and refer to a field\n                     in a related model.\n\n        values:  The field to use to calculate the values to aggregate.\n\n        rows:  The list of field names to group on\n               Keys to group on the x-axis of the pivot table\n\n        cols:  The list of column names or arrays to group on\n               Keys to group on the y-axis of the pivot table\n\n        aggfunc:  How to arregate the values. By default this would be\n                  ``numpy.mean``. A list of aggregates functions can be passed\n                  In this case the resulting pivot table will have\n                  hierarchical columns whose top level are the function names\n                  (inferred from the function objects themselves)\n\n        fill_value:  A scalar value to replace the missing values with\n\n        margins:  Boolean, default False Add all row / columns\n                  (e.g. for subtotal / grand totals)\n\n        dropna:  Boolean, default True.\n                 Do not include columns whose entries are all NaN\n\n        verbose: If this is ``True`` then populate the DataFrame with the\n                 human readable versions for foreign key fields else use the\n                 actual values set in the model\n\n        coerce_float:   Attempt to convert values to non-string, non-numeric\n                        objects (like decimal.Decimal) to floating point.\n        \"\"\"\n        df = self.to_dataframe(fieldnames, verbose=verbose,\n                               coerce_float=coerce_float)\n\n        return df.pivot_table(values=values, fill_value=fill_value, index=rows,\n                              columns=cols, aggfunc=aggfunc, margins=margins,\n                              dropna=dropna)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_timeseries(self, fieldnames=(), verbose=True,\n                      index=None, storage='wide',\n                      values=None, pivot_columns=None, freq=None,\n                      coerce_float=True, rs_kwargs=None):\n        \"\"\"\n        A convenience method for creating a time series DataFrame i.e the\n        DataFrame index will be an instance of  DateTime or PeriodIndex\n\n        Parameters\n        ----------\n\n        fieldnames:  The model field names(columns) to utilise in creating\n                     the DataFrame. You can span a relationships in the usual\n                     Django ORM way by using the foreign key field name\n                     separated by double underscores and refer to a field\n                     in a related model.\n\n        index:  specify the field to use  for the index. If the index\n                field is not in fieldnames it will be appended. This\n                is mandatory for timeseries.\n\n        storage:  Specify if the queryset uses the\n                  ``wide`` format\n\n                  date       |  col1| col2| col3|\n                  -----------|------|-----|-----|\n                  2001-01-01-| 100.5| 23.3|  2.2|\n                  2001-02-01-| 106.3| 17.0|  4.6|\n                  2001-03-01-| 111.7| 11.1|  0.7|\n\n                  or the `long` format.\n\n                  date       |values| names|\n                  -----------|------|------|\n                  2001-01-01-| 100.5|  col1|\n                  2001-02-01-| 106.3|  col1|\n                  2001-03-01-| 111.7|  col1|\n                  2001-01-01-|  23.3|  col2|\n                  2001-02-01-|  17.0|  col2|\n                  2001-01-01-|  23.3|  col2|\n                  2001-02-01-|   2.2|  col3|\n                  2001-03-01-|   4.6|  col3|\n                  2001-03-01-|   0.7|  col3|\n\n\n        pivot_columns:  Required once the you specify `long` format\n                       storage. This could either be a list or string\n                       identifying the field name or combination of field.\n                       If the pivot_column is a single column then the\n                       unique values in this column become a new columns in\n                       the DataFrame If the pivot column is a list the values\n                       in these columns are concatenated (using the '-'\n                       as a separator) and these values are used for the new\n                       timeseries columns\n\n        values:  Also required if you utilize the `long` storage the\n                 values column name is use for populating new frame values\n\n        freq:  The offset string or object representing a target conversion\n\n        rs_kwargs:  A dictonary of keyword arguments based on the\n                    ``pandas.DataFrame.resample`` method\n\n        verbose:  If  this is ``True`` then populate the DataFrame with the\n                  human readable versions of any foreign key fields else use\n                  the primary keys values else use the actual values set\n                  in the model.\n\n        coerce_float:   Attempt to convert values to non-string, non-numeric\n                        objects (like decimal.Decimal) to floating point.\n        \"\"\"\n        assert index is not None, 'You must supply an index field'\n        assert storage in ('wide', 'long'), 'storage must be wide or long'\n        if rs_kwargs is None:\n            rs_kwargs = {}\n\n        if storage == 'wide':\n            df = self.to_dataframe(fieldnames, verbose=verbose, index=index,\n                                   coerce_float=coerce_float, datetime_index=True)\n        else:\n            df = self.to_dataframe(fieldnames, verbose=verbose,\n                                   coerce_float=coerce_float, datetime_index=True)\n            assert values is not None, 'You must specify a values field'\n            assert pivot_columns is not None, 'You must specify pivot_columns'\n\n            if isinstance(pivot_columns, (tuple, list)):\n                df['combined_keys'] = ''\n                for c in pivot_columns:\n                    df['combined_keys'] += df[c].str.upper() + '.'\n\n                df['combined_keys'] += values.lower()\n\n                df = df.pivot(index=index,\n                              columns='combined_keys',\n                              values=values)\n            else:\n                df = df.pivot(index=index,\n                              columns=pivot_columns,\n                              values=values)\n\n        if freq is not None:\n            df = df.resample(freq, **rs_kwargs)\n\n        return df", "response": "This method creates a time series DataFrame from the current instance of the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_dataframe(self, fieldnames=(), verbose=True, index=None,\n                     coerce_float=False, datetime_index=False):\n        \"\"\"\n        Returns a DataFrame from the queryset\n\n        Paramaters\n        -----------\n\n        fieldnames:  The model field names(columns) to utilise in creating\n                     the DataFrame. You can span a relationships in the usual\n                     Django ORM way by using the foreign key field name\n                     separated by double underscores and refer to a field\n                     in a related model.\n\n\n        index:  specify the field to use  for the index. If the index\n                field is not in fieldnames it will be appended. This\n                is mandatory for timeseries.\n\n        verbose: If  this is ``True`` then populate the DataFrame with the\n                 human readable versions for foreign key fields else\n                 use the actual values set in the model\n\n        coerce_float:   Attempt to convert values to non-string, non-numeric\n                        objects (like decimal.Decimal) to floating point.\n\n        datetime_index: specify whether index should be converted to a\n                        DateTimeIndex.\n        \"\"\"\n\n        return read_frame(self, fieldnames=fieldnames, verbose=verbose,\n                          index_col=index, coerce_float=coerce_float,\n                          datetime_index=datetime_index)", "response": "Returns a DataFrame from the queryset"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a DataFrame from a QuerySet and returns it as a DataFrame.", "response": "def read_frame(qs, fieldnames=(), index_col=None, coerce_float=False,\n               verbose=True, datetime_index=False):\n    \"\"\"\n    Returns a dataframe from a QuerySet\n\n    Optionally specify the field names/columns to utilize and\n    a field as the index\n\n    Parameters\n    ----------\n\n    qs: The Django QuerySet.\n    fieldnames: The model field names to use in creating the frame.\n         You can span a relationship in the usual Django way\n         by using  double underscores to specify a related field\n         in another model\n         You can span a relationship in the usual Django way\n         by using  double underscores to specify a related field\n         in another model\n\n    index_col: specify the field to use  for the index. If the index\n               field is not in the field list it will be appended\n\n    coerce_float : boolean, default False\n        Attempt to convert values to non-string, non-numeric data (like\n        decimal.Decimal) to floating point, useful for SQL result sets\n\n    verbose:  boolean If  this is ``True`` then populate the DataFrame with the\n                human readable versions of any foreign key fields else use\n                the primary keys values.\n                The human readable version of the foreign key field is\n                defined in the ``__unicode__`` or ``__str__``\n                methods of the related class definition\n\n    datetime_index: specify whether index should be converted to a\n                    DateTimeIndex.\n    \"\"\"\n\n    if fieldnames:\n        fieldnames = pd.unique(fieldnames)\n        if index_col is not None and index_col not in fieldnames:\n            # Add it to the field names if not already there\n            fieldnames = tuple(fieldnames) + (index_col,)\n        fields = to_fields(qs, fieldnames)\n    elif is_values_queryset(qs):\n        if django.VERSION < (1, 9):  # pragma: no cover\n            annotation_field_names = list(qs.query.annotation_select)\n\n            if annotation_field_names is None:\n                annotation_field_names = []\n\n            extra_field_names = qs.extra_names\n            if extra_field_names is None:\n                extra_field_names = []\n\n            select_field_names = qs.field_names\n\n        else:  # pragma: no cover\n            annotation_field_names = list(qs.query.annotation_select)\n            extra_field_names = list(qs.query.extra_select)\n            select_field_names = list(qs.query.values_select)\n\n        fieldnames = select_field_names + annotation_field_names + \\\n            extra_field_names\n        fields = [None if '__' in f else qs.model._meta.get_field(f)\n                  for f in select_field_names] + \\\n            [None] * (len(annotation_field_names) + len(extra_field_names))\n\n        uniq_fields = set()\n        fieldnames, fields = zip(\n            *(f for f in zip(fieldnames, fields)\n              if f[0] not in uniq_fields and not uniq_fields.add(f[0])))\n    else:\n        fields = qs.model._meta.fields\n        fieldnames = [f.name for f in fields]\n        fieldnames += list(qs.query.annotation_select.keys())\n\n    if is_values_queryset(qs):\n        recs = list(qs)\n    else:\n        recs = list(qs.values_list(*fieldnames))\n\n    df = pd.DataFrame.from_records(recs, columns=fieldnames,\n                                   coerce_float=coerce_float)\n\n    if verbose:\n        update_with_verbose(df, fieldnames, fields)\n\n    if index_col is not None:\n        df.set_index(index_col, inplace=True)\n\n    if datetime_index:\n        df.index = pd.to_datetime(df.index, errors=\"ignore\")\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the height if the binary tree is balanced.", "response": "def _is_balanced(root):\n    \"\"\"Return the height if the binary tree is balanced, -1 otherwise.\n\n    :param root: Root node of the binary tree.\n    :type root: binarytree.Node | None\n    :return: Height if the binary tree is balanced, -1 otherwise.\n    :rtype: int\n    \"\"\"\n    if root is None:\n        return 0\n    left = _is_balanced(root.left)\n    if left < 0:\n        return -1\n    right = _is_balanced(root.right)\n    if right < 0:\n        return -1\n    return -1 if abs(left - right) > 1 else max(left, right) + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the binary tree is a BST.", "response": "def _is_bst(root, min_value=float('-inf'), max_value=float('inf')):\n    \"\"\"Check if the binary tree is a BST (binary search tree).\n\n    :param root: Root node of the binary tree.\n    :type root: binarytree.Node | None\n    :param min_value: Minimum node value seen.\n    :type min_value: int | float\n    :param max_value: Maximum node value seen.\n    :type max_value: int | float\n    :return: True if the binary tree is a BST, False otherwise.\n    :rtype: bool\n    \"\"\"\n    if root is None:\n        return True\n    return (\n        min_value < root.value < max_value and\n        _is_bst(root.left, min_value, root.value) and\n        _is_bst(root.right, root.value, max_value)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _generate_perfect_bst(height):\n    max_node_count = 2 ** (height + 1) - 1\n    node_values = list(range(max_node_count))\n    return _build_bst_from_sorted_values(node_values)", "response": "Generate a perfect BST."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a random leaf count for building binary trees.", "response": "def _generate_random_leaf_count(height):\n    \"\"\"Return a random leaf count for building binary trees.\n\n    :param height: Height of the binary tree.\n    :type height: int\n    :return: Random leaf count.\n    :rtype: int\n    \"\"\"\n    max_leaf_count = 2 ** height\n    half_leaf_count = max_leaf_count // 2\n\n    # A very naive way of mimicking normal distribution\n    roll_1 = random.randint(0, half_leaf_count)\n    roll_2 = random.randint(0, max_leaf_count - half_leaf_count)\n    return roll_1 + roll_2 or half_leaf_count"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generate_random_node_values(height):\n    max_node_count = 2 ** (height + 1) - 1\n    node_values = list(range(max_node_count))\n    random.shuffle(node_values)\n    return node_values", "response": "Generate random node values for building binary trees."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_tree_string(root, curr_index, index=False, delimiter='-'):\n    if root is None:\n        return [], 0, 0, 0\n\n    line1 = []\n    line2 = []\n    if index:\n        node_repr = '{}{}{}'.format(curr_index, delimiter, root.value)\n    else:\n        node_repr = str(root.value)\n\n    new_root_width = gap_size = len(node_repr)\n\n    # Get the left and right sub-boxes, their widths, and root repr positions\n    l_box, l_box_width, l_root_start, l_root_end = \\\n        _build_tree_string(root.left, 2 * curr_index + 1, index, delimiter)\n    r_box, r_box_width, r_root_start, r_root_end = \\\n        _build_tree_string(root.right, 2 * curr_index + 2, index, delimiter)\n\n    # Draw the branch connecting the current root node to the left sub-box\n    # Pad the line with whitespaces where necessary\n    if l_box_width > 0:\n        l_root = (l_root_start + l_root_end) // 2 + 1\n        line1.append(' ' * (l_root + 1))\n        line1.append('_' * (l_box_width - l_root))\n        line2.append(' ' * l_root + '/')\n        line2.append(' ' * (l_box_width - l_root))\n        new_root_start = l_box_width + 1\n        gap_size += 1\n    else:\n        new_root_start = 0\n\n    # Draw the representation of the current root node\n    line1.append(node_repr)\n    line2.append(' ' * new_root_width)\n\n    # Draw the branch connecting the current root node to the right sub-box\n    # Pad the line with whitespaces where necessary\n    if r_box_width > 0:\n        r_root = (r_root_start + r_root_end) // 2\n        line1.append('_' * r_root)\n        line1.append(' ' * (r_box_width - r_root + 1))\n        line2.append(' ' * r_root + '\\\\')\n        line2.append(' ' * (r_box_width - r_root))\n        gap_size += 1\n    new_root_end = new_root_start + new_root_width - 1\n\n    # Combine the left and right sub-boxes with the branches drawn above\n    gap = ' ' * gap_size\n    new_box = [''.join(line1), ''.join(line2)]\n    for i in range(max(len(l_box), len(r_box))):\n        l_line = l_box[i] if i < len(l_box) else ' ' * l_box_width\n        r_line = r_box[i] if i < len(r_box) else ' ' * r_box_width\n        new_box.append(l_line + gap + r_line)\n\n    # Return the new box, its width and its root repr positions\n    return new_box, len(new_box[0]), new_root_start, new_root_end", "response": "Recursively walks the binary tree and builds a pretty - print string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninspect the binary tree and return its properties.", "response": "def _get_tree_properties(root):\n    \"\"\"Inspect the binary tree and return its properties (e.g. height).\n\n    :param root: Root node of the binary tree.\n    :rtype: binarytree.Node\n    :return: Binary tree properties.\n    :rtype: dict\n    \"\"\"\n    is_descending = True\n    is_ascending = True\n    min_node_value = root.value\n    max_node_value = root.value\n    size = 0\n    leaf_count = 0\n    min_leaf_depth = 0\n    max_leaf_depth = -1\n    is_strict = True\n    is_complete = True\n    current_nodes = [root]\n    non_full_node_seen = False\n\n    while len(current_nodes) > 0:\n        max_leaf_depth += 1\n        next_nodes = []\n\n        for node in current_nodes:\n            size += 1\n            value = node.value\n            min_node_value = min(value, min_node_value)\n            max_node_value = max(value, max_node_value)\n\n            # Node is a leaf.\n            if node.left is None and node.right is None:\n                if min_leaf_depth == 0:\n                    min_leaf_depth = max_leaf_depth\n                leaf_count += 1\n\n            if node.left is not None:\n                if node.left.value > value:\n                    is_descending = False\n                elif node.left.value < value:\n                    is_ascending = False\n                next_nodes.append(node.left)\n                is_complete = not non_full_node_seen\n            else:\n                non_full_node_seen = True\n\n            if node.right is not None:\n                if node.right.value > value:\n                    is_descending = False\n                elif node.right.value < value:\n                    is_ascending = False\n                next_nodes.append(node.right)\n                is_complete = not non_full_node_seen\n            else:\n                non_full_node_seen = True\n\n            # If we see a node with only one child, it is not strict\n            is_strict &= (node.left is None) == (node.right is None)\n\n        current_nodes = next_nodes\n\n    return {\n        'height': max_leaf_depth,\n        'size': size,\n        'is_max_heap': is_complete and is_descending,\n        'is_min_heap': is_complete and is_ascending,\n        'is_perfect': leaf_count == 2 ** max_leaf_depth,\n        'is_strict': is_strict,\n        'is_complete': is_complete,\n        'leaf_count': leaf_count,\n        'min_node_value': min_node_value,\n        'max_node_value': max_node_value,\n        'min_leaf_depth': min_leaf_depth,\n        'max_leaf_depth': max_leaf_depth,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a binary tree from a list representation.", "response": "def build(values):\n    \"\"\"Build a tree from `list representation`_ and return its root node.\n\n    .. _list representation:\n        https://en.wikipedia.org/wiki/Binary_tree#Arrays\n\n    :param values: List representation of the binary tree, which is a list of\n        node values in breadth-first order starting from the root (current\n        node). If a node is at index i, its left child is always at 2i + 1,\n        right child at 2i + 2, and parent at floor((i - 1) / 2). None indicates\n        absence of a node at that index. See example below for an illustration.\n    :type values: [int | float | None]\n    :return: Root node of the binary tree.\n    :rtype: binarytree.Node\n    :raise binarytree.exceptions.NodeNotFoundError: If the list representation\n        is malformed (e.g. a parent node is missing).\n\n    **Example**:\n\n    .. doctest::\n\n        >>> from binarytree import build\n        >>>\n        >>> root = build([1, 2, 3, None, 4])\n        >>>\n        >>> print(root)\n        <BLANKLINE>\n          __1\n         /   \\\\\n        2     3\n         \\\\\n          4\n        <BLANKLINE>\n\n    .. doctest::\n\n        >>> from binarytree import build\n        >>>\n        >>> root = build([None, 2, 3])  # doctest: +IGNORE_EXCEPTION_DETAIL\n        Traceback (most recent call last):\n         ...\n        NodeNotFoundError: parent node missing at index 0\n    \"\"\"\n    nodes = [None if v is None else Node(v) for v in values]\n\n    for index in range(1, len(nodes)):\n        node = nodes[index]\n        if node is not None:\n            parent_index = (index - 1) // 2\n            parent = nodes[parent_index]\n            if parent is None:\n                raise NodeNotFoundError(\n                    'parent node missing at index {}'.format(parent_index))\n            setattr(parent, 'left' if index % 2 else 'right', node)\n\n    return nodes[0] if nodes else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tree(height=3, is_perfect=False):\n    _validate_tree_height(height)\n    values = _generate_random_node_values(height)\n    if is_perfect:\n        return build(values)\n\n    leaf_count = _generate_random_leaf_count(height)\n    root = Node(values.pop(0))\n    leaves = set()\n\n    for value in values:\n        node = root\n        depth = 0\n        inserted = False\n\n        while depth < height and not inserted:\n            attr = random.choice(('left', 'right'))\n            if getattr(node, attr) is None:\n                setattr(node, attr, Node(value))\n                inserted = True\n            node = getattr(node, attr)\n            depth += 1\n\n        if inserted and depth == height:\n            leaves.add(node)\n        if len(leaves) == leaf_count:\n            break\n\n    return root", "response": "Generate a random binary tree and return its root node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bst(height=3, is_perfect=False):\n    _validate_tree_height(height)\n    if is_perfect:\n        return _generate_perfect_bst(height)\n\n    values = _generate_random_node_values(height)\n    leaf_count = _generate_random_leaf_count(height)\n\n    root = Node(values.pop(0))\n    leaves = set()\n\n    for value in values:\n        node = root\n        depth = 0\n        inserted = False\n\n        while depth < height and not inserted:\n            attr = 'left' if node.value > value else 'right'\n            if getattr(node, attr) is None:\n                setattr(node, attr, Node(value))\n                inserted = True\n            node = getattr(node, attr)\n            depth += 1\n\n        if inserted and depth == height:\n            leaves.add(node)\n        if len(leaves) == leaf_count:\n            break\n\n    return root", "response": "Generate a random BST and return its root node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef heap(height=3, is_max=True, is_perfect=False):\n    _validate_tree_height(height)\n    values = _generate_random_node_values(height)\n\n    if not is_perfect:\n        # Randomly cut some of the leaf nodes away\n        random_cut = random.randint(2 ** height, len(values))\n        values = values[:random_cut]\n\n    if is_max:\n        negated = [-v for v in values]\n        heapq.heapify(negated)\n        return build([-v for v in negated])\n    else:\n        heapq.heapify(values)\n        return build(values)", "response": "Generate a random heap and return its root node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(self):\n        has_more_nodes = True\n        visited = set()\n        to_visit = [self]\n        index = 0\n\n        while has_more_nodes:\n            has_more_nodes = False\n            next_nodes = []\n\n            for node in to_visit:\n                if node is None:\n                    next_nodes.extend((None, None))\n                else:\n                    if node in visited:\n                        raise NodeReferenceError(\n                            'cyclic node reference at index {}'.format(index))\n                    if not isinstance(node, Node):\n                        raise NodeTypeError(\n                            'invalid node instance at index {}'.format(index))\n                    if not isinstance(node.value, numbers.Number):\n                        raise NodeValueError(\n                            'invalid node value at index {}'.format(index))\n                    if node.left is not None or node.right is not None:\n                        has_more_nodes = True\n                    visited.add(node)\n                    next_nodes.extend((node.left, node.right))\n                index += 1\n\n            to_visit = next_nodes", "response": "Check if the binary tree is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef values(self):\n        current_nodes = [self]\n        has_more_nodes = True\n        values = []\n\n        while has_more_nodes:\n            has_more_nodes = False\n            next_nodes = []\n            for node in current_nodes:\n                if node is None:\n                    values.append(None)\n                    next_nodes.extend((None, None))\n                    continue\n\n                if node.left is not None or node.right is not None:\n                    has_more_nodes = True\n\n                values.append(node.value)\n                next_nodes.extend((node.left, node.right))\n\n            current_nodes = next_nodes\n\n        # Get rid of trailing None's\n        while values and values[-1] is None:\n            values.pop()\n\n        return values", "response": "Return the list representation of the binary tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef leaves(self):\n        current_nodes = [self]\n        leaves = []\n\n        while len(current_nodes) > 0:\n            next_nodes = []\n            for node in current_nodes:\n                if node.left is None and node.right is None:\n                    leaves.append(node)\n                    continue\n                if node.left is not None:\n                    next_nodes.append(node.left)\n                if node.right is not None:\n                    next_nodes.append(node.right)\n            current_nodes = next_nodes\n        return leaves", "response": "Return the leaves of the binary tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the properties of the binary tree.", "response": "def properties(self):\n        \"\"\"Return various properties of the binary tree.\n\n        :return: Binary tree properties.\n        :rtype: dict\n\n        **Example**:\n\n        .. doctest::\n\n            >>> from binarytree import Node\n            >>>\n            >>> root = Node(1)\n            >>> root.left = Node(2)\n            >>> root.right = Node(3)\n            >>> root.left.left = Node(4)\n            >>> root.left.right = Node(5)\n            >>> props = root.properties\n            >>>\n            >>> props['height']         # equivalent to root.height\n            2\n            >>> props['size']           # equivalent to root.size\n            5\n            >>> props['max_leaf_depth'] # equivalent to root.max_leaf_depth\n            2\n            >>> props['min_leaf_depth'] # equivalent to root.min_leaf_depth\n            1\n            >>> props['max_node_value'] # equivalent to root.max_node_value\n            5\n            >>> props['min_node_value'] # equivalent to root.min_node_value\n            1\n            >>> props['leaf_count']     # equivalent to root.leaf_count\n            3\n            >>> props['is_balanced']    # equivalent to root.is_balanced\n            True\n            >>> props['is_bst']         # equivalent to root.is_bst\n            False\n            >>> props['is_complete']    # equivalent to root.is_complete\n            True\n            >>> props['is_max_heap']    # equivalent to root.is_max_heap\n            False\n            >>> props['is_min_heap']    # equivalent to root.is_min_heap\n            True\n            >>> props['is_perfect']     # equivalent to root.is_perfect\n            False\n            >>> props['is_strict']      # equivalent to root.is_strict\n            True\n        \"\"\"\n        properties = _get_tree_properties(self)\n        properties.update({\n            'is_bst': _is_bst(self),\n            'is_balanced': _is_balanced(self) >= 0\n        })\n        return properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inorder(self):\n        node_stack = []\n        result = []\n        node = self\n\n        while True:\n            if node is not None:\n                node_stack.append(node)\n                node = node.left\n            elif len(node_stack) > 0:\n                node = node_stack.pop()\n                result.append(node)\n                node = node.right\n            else:\n                break\n\n        return result", "response": "Return the nodes in the binary tree using in - order traversal."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the nodes in the binary tree using a pre - order traversal.", "response": "def preorder(self):\n        \"\"\"Return the nodes in the binary tree using pre-order_ traversal.\n\n        A pre-order_ traversal visits root, left subtree, then right subtree.\n\n        .. _pre-order: https://en.wikipedia.org/wiki/Tree_traversal\n\n        :return: List of nodes.\n        :rtype: [binarytree.Node]\n\n        **Example**:\n\n        .. doctest::\n\n            >>> from binarytree import Node\n            >>>\n            >>> root = Node(1)\n            >>> root.left = Node(2)\n            >>> root.right = Node(3)\n            >>> root.left.left = Node(4)\n            >>> root.left.right = Node(5)\n            >>>\n            >>> print(root)\n            <BLANKLINE>\n                __1\n               /   \\\\\n              2     3\n             / \\\\\n            4   5\n            <BLANKLINE>\n            >>> root.preorder\n            [Node(1), Node(2), Node(4), Node(5), Node(3)]\n        \"\"\"\n        node_stack = [self]\n        result = []\n\n        while len(node_stack) > 0:\n            node = node_stack.pop()\n            result.append(node)\n\n            if node.right is not None:\n                node_stack.append(node.right)\n            if node.left is not None:\n                node_stack.append(node.left)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the nodes in the binary tree using post - order traversal.", "response": "def postorder(self):\n        \"\"\"Return the nodes in the binary tree using post-order_ traversal.\n\n        A post-order_ traversal visits left subtree, right subtree, then root.\n\n        .. _post-order: https://en.wikipedia.org/wiki/Tree_traversal\n\n        :return: List of nodes.\n        :rtype: [binarytree.Node]\n\n        **Example**:\n\n        .. doctest::\n\n            >>> from binarytree import Node\n            >>>\n            >>> root = Node(1)\n            >>> root.left = Node(2)\n            >>> root.right = Node(3)\n            >>> root.left.left = Node(4)\n            >>> root.left.right = Node(5)\n            >>>\n            >>> print(root)\n            <BLANKLINE>\n                __1\n               /   \\\\\n              2     3\n             / \\\\\n            4   5\n            <BLANKLINE>\n            >>> root.postorder\n            [Node(4), Node(5), Node(2), Node(3), Node(1)]\n        \"\"\"\n        node_stack = []\n        result = []\n        node = self\n\n        while True:\n            while node is not None:\n                if node.right is not None:\n                    node_stack.append(node.right)\n                node_stack.append(node)\n                node = node.left\n\n            node = node_stack.pop()\n            if (node.right is not None and\n                    len(node_stack) > 0 and\n                    node_stack[-1] is node.right):\n                node_stack.pop()\n                node_stack.append(node)\n                node = node.right\n            else:\n                result.append(node)\n                node = None\n\n            if len(node_stack) == 0:\n                break\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef levelorder(self):\n        current_nodes = [self]\n        result = []\n\n        while len(current_nodes) > 0:\n            next_nodes = []\n            for node in current_nodes:\n                result.append(node)\n                if node.left is not None:\n                    next_nodes.append(node.left)\n                if node.right is not None:\n                    next_nodes.append(node.right)\n            current_nodes = next_nodes\n\n        return result", "response": "Return the nodes in the binary tree using level - order_ traversal."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a specified invitation backend", "response": "def invitation_backend(backend=None, namespace=None):\n    # type: (Optional[Text], Optional[Text]) -> BaseBackend\n    \"\"\"\n    Returns a specified invitation backend\n\n    Args:\n        backend: dotted path to the invitation backend class\n        namespace: URL namespace to use\n\n    Returns:\n        an instance of an InvitationBackend\n\n    \"\"\"\n    backend = backend or ORGS_INVITATION_BACKEND\n    class_module, class_name = backend.rsplit(\".\", 1)\n    mod = import_module(class_module)\n    return getattr(mod, class_name)(namespace=namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a specified registration backend", "response": "def registration_backend(backend=None, namespace=None):\n    # type: (Optional[Text], Optional[Text]) -> BaseBackend\n    \"\"\"\n    Returns a specified registration backend\n\n    Args:\n        backend: dotted path to the registration backend class\n        namespace: URL namespace to use\n\n    Returns:\n        an instance of an RegistrationBackend\n\n    \"\"\"\n    backend = backend or ORGS_REGISTRATION_BACKEND\n    class_module, class_name = backend.rsplit(\".\", 1)\n    mod = import_module(class_module)\n    return getattr(mod, class_name)(namespace=namespace)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a registration ModelForm for the given organization model.", "response": "def org_registration_form(org_model):\n    \"\"\"\n    Generates a registration ModelForm for the given organization model class\n    \"\"\"\n\n    class OrganizationRegistrationForm(forms.ModelForm):\n        \"\"\"Form class for creating new organizations owned by new users.\"\"\"\n        email = forms.EmailField()\n\n        class Meta:\n            model = org_model\n            exclude = (\"is_active\", \"users\")\n\n        def save(self, *args, **kwargs):\n            self.instance.is_active = False\n            super(OrganizationRegistrationForm, self).save(*args, **kwargs)\n\n    return OrganizationRegistrationForm"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the user to the database.", "response": "def save(self, **kwargs):\n        \"\"\"\n        Create the organization, then get the user, then make the owner.\n        \"\"\"\n        is_active = True\n        try:\n            user = get_user_model().objects.get(email=self.cleaned_data[\"email\"])\n        except get_user_model().DoesNotExist:\n            user = invitation_backend().invite_by_email(\n                self.cleaned_data[\"email\"],\n                **{\n                    \"domain\": get_current_site(self.request),\n                    \"organization\": self.cleaned_data[\"name\"],\n                    \"sender\": self.request.user,\n                    \"created\": True,\n                }\n            )\n            is_active = False\n        return create_organization(\n            user,\n            self.cleaned_data[\"name\"],\n            self.cleaned_data[\"slug\"],\n            is_active=is_active,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninviting a user by email to another user", "response": "def invite_by_email(self, email, user, organization, **kwargs):\n        # type: (Text, AbstractUser, AbstractBaseOrganization) -> OrganizationInvitationBase\n        \"\"\"\n        Primary interface method by which one user invites another to join\n\n        Args:\n            email:\n            request:\n            **kwargs:\n\n        Returns:\n            an invitation instance\n\n        Raises:\n            MultipleObjectsReturned if multiple matching users are found\n\n        \"\"\"\n        try:\n            invitee = self.user_model.objects.get(email__iexact=email)\n        except self.user_model.DoesNotExist:\n            invitee = None\n\n        # TODO allow sending just the OrganizationUser instance\n        user_invitation = self.invitation_model.objects.create(\n            invitee=invitee,\n            invitee_identifier=email.lower(),\n            invited_by=user,\n            organization=organization,\n        )\n        self.send_invitation(user_invitation)\n        return user_invitation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_invitation(self, invitation, **kwargs):\n        # type: (OrganizationInvitationBase) -> bool\n        \"\"\"\n        Sends an invitation message for a specific invitation.\n\n        This could be overridden to do other things, such as sending a confirmation\n        email to the sender.\n\n        Args:\n            invitation:\n\n        Returns:\n\n        \"\"\"\n        return self.email_message(\n            invitation.invitee_identifier,\n            self.invitation_subject,\n            self.invitation_body,\n            invitation.invited_by,\n            **kwargs\n        ).send()", "response": "Sends an invitation message for a specific organization invitation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an invitation email message.", "response": "def email_message(\n        self,\n        recipient,  # type: Text\n        subject_template,  # type: Text\n        body_template,  # type: Text\n        sender=None,  # type: Optional[AbstractUser]\n        message_class=EmailMessage,\n        **kwargs\n    ):\n        \"\"\"\n        Returns an invitation email message. This can be easily overridden.\n        For instance, to send an HTML message, use the EmailMultiAlternatives message_class\n        and attach the additional conent.\n        \"\"\"\n        from_email = \"%s %s <%s>\" % (\n            sender.first_name,\n            sender.last_name,\n            email.utils.parseaddr(settings.DEFAULT_FROM_EMAIL)[1],\n        )\n        reply_to = \"%s %s <%s>\" % (sender.first_name, sender.last_name, sender.email)\n\n        headers = {\"Reply-To\": reply_to}\n        kwargs.update({\"sender\": sender, \"recipient\": recipient})\n\n        subject_template = loader.get_template(subject_template)\n        body_template = loader.get_template(body_template)\n\n        subject = subject_template.render(\n            kwargs\n        ).strip()  # Remove stray newline characters\n\n        body = body_template.render(kwargs)\n\n        return message_class(subject, body, from_email, [recipient], headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the organization model of the given module.", "response": "def update_org(cls, module):\n        \"\"\"\n        Adds the `users` field to the organization model\n        \"\"\"\n        try:\n            cls.module_registry[module][\"OrgModel\"]._meta.get_field(\"users\")\n        except FieldDoesNotExist:\n            cls.module_registry[module][\"OrgModel\"].add_to_class(\n                \"users\",\n                models.ManyToManyField(\n                    USER_MODEL,\n                    through=cls.module_registry[module][\"OrgUserModel\"].__name__,\n                    related_name=\"%(app_label)s_%(class)s\",\n                ),\n            )\n\n        cls.module_registry[module][\"OrgModel\"].invitation_model = cls.module_registry[\n            module\n        ][\n            \"OrgInviteModel\"\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_org_users(cls, module):\n        try:\n            cls.module_registry[module][\"OrgUserModel\"]._meta.get_field(\"user\")\n        except FieldDoesNotExist:\n            cls.module_registry[module][\"OrgUserModel\"].add_to_class(\n                \"user\",\n                models.ForeignKey(\n                    USER_MODEL,\n                    related_name=\"%(app_label)s_%(class)s\",\n                    on_delete=models.CASCADE,\n                ),\n            )\n        try:\n            cls.module_registry[module][\"OrgUserModel\"]._meta.get_field(\"organization\")\n        except FieldDoesNotExist:\n            cls.module_registry[module][\"OrgUserModel\"].add_to_class(\n                \"organization\",\n                models.ForeignKey(\n                    cls.module_registry[module][\"OrgModel\"],\n                    related_name=\"organization_users\",\n                    on_delete=models.CASCADE,\n                ),\n            )", "response": "Adds the user field to the organization user model and the link to the specific organization model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_org_owner(cls, module):\n        try:\n            cls.module_registry[module][\"OrgOwnerModel\"]._meta.get_field(\n                \"organization_user\"\n            )\n        except FieldDoesNotExist:\n            cls.module_registry[module][\"OrgOwnerModel\"].add_to_class(\n                \"organization_user\",\n                models.OneToOneField(\n                    cls.module_registry[module][\"OrgUserModel\"],\n                    on_delete=models.CASCADE,\n                ),\n            )\n        try:\n            cls.module_registry[module][\"OrgOwnerModel\"]._meta.get_field(\"organization\")\n        except FieldDoesNotExist:\n            cls.module_registry[module][\"OrgOwnerModel\"].add_to_class(\n                \"organization\",\n                models.OneToOneField(\n                    cls.module_registry[module][\"OrgModel\"],\n                    related_name=\"owner\",\n                    on_delete=models.CASCADE,\n                ),\n            )", "response": "Updates the organization and organization user for the owner."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_org_invite(cls, module):\n        try:\n            cls.module_registry[module][\"OrgInviteModel\"]._meta.get_field(\"invited_by\")\n        except FieldDoesNotExist:\n            cls.module_registry[module][\"OrgInviteModel\"].add_to_class(\n                \"invited_by\",\n                models.ForeignKey(\n                    USER_MODEL,\n                    related_name=\"%(app_label)s_%(class)s_sent_invitations\",\n                    on_delete=models.CASCADE,\n                ),\n            )\n        try:\n            cls.module_registry[module][\"OrgInviteModel\"]._meta.get_field(\"invitee\")\n        except FieldDoesNotExist:\n            cls.module_registry[module][\"OrgInviteModel\"].add_to_class(\n                \"invitee\",\n                models.ForeignKey(\n                    USER_MODEL,\n                    null=True,\n                    blank=True,\n                    related_name=\"%(app_label)s_%(class)s_invitations\",\n                    on_delete=models.CASCADE,\n                ),\n            )\n        try:\n            cls.module_registry[module][\"OrgInviteModel\"]._meta.get_field(\n                \"organization\"\n            )\n        except FieldDoesNotExist:\n            cls.module_registry[module][\"OrgInviteModel\"].add_to_class(\n                \"organization\",\n                models.ForeignKey(\n                    cls.module_registry[module][\"OrgModel\"],\n                    related_name=\"organization_invites\",\n                    on_delete=models.CASCADE,\n                ),\n            )", "response": "Updates the org invite related fields in the user and organization relations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_relation_name(self):\n        return \"{0}_{1}\".format(\n            self._meta.app_label.lower(), self.__class__.__name__.lower()\n        )", "response": "Returns the string name of the related name to the user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef name(self):\n        if hasattr(self.user, \"get_full_name\"):\n            return self.user.get_full_name()\n        return \"{0}\".format(self.user)", "response": "Returns the connected user s full name or string representation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef activate(self, user):\n        org_user = self.organization.add_user(user, **self.activation_kwargs())\n        self.invitee = user\n        self.save()\n        return org_user", "response": "Activates the user and saves the instance holding the user s invitee value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_object(self):\n        if hasattr(self, \"organization_user\"):\n            return self.organization_user\n        organization_pk = self.kwargs.get(\"organization_pk\", None)\n        user_pk = self.kwargs.get(\"user_pk\", None)\n        self.organization_user = get_object_or_404(\n            self.get_user_model().objects.select_related(),\n            user__pk=user_pk,\n            organization__pk=organization_pk,\n        )\n        return self.organization_user", "response": "Returns the OrganizationUser object based on the primary keys for both the organization and the user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_token(self, user, token):\n        # Parse the token\n        try:\n            ts_b36, hash = token.split(\"-\")\n        except ValueError:\n            return False\n\n        try:\n            ts = base36_to_int(ts_b36)\n        except ValueError:\n            return False\n\n        # Check that the timestamp/uid has not been tampered with\n        if not constant_time_compare(self._make_token_with_timestamp(user, ts), token):\n            return False\n\n        # Check the timestamp is within limit\n        if (self._num_days(self._today()) - ts) > REGISTRATION_TIMEOUT_DAYS:\n            return False\n\n        return True", "response": "Check that a password reset token is correct for a given user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_organization(\n    user,\n    name,\n    slug=None,\n    is_active=None,\n    org_defaults=None,\n    org_user_defaults=None,\n    **kwargs\n):\n    \"\"\"\n    Returns a new organization, also creating an initial organization user who\n    is the owner.\n\n    The specific models can be specified if a custom organization app is used.\n    The simplest way would be to use a partial.\n\n    >>> from organizations.utils import create_organization\n    >>> from myapp.models import Account\n    >>> from functools import partial\n    >>> create_account = partial(create_organization, model=Account)\n\n    \"\"\"\n    org_model = kwargs.pop(\"model\", None) or kwargs.pop(\n        \"org_model\", None\n    ) or default_org_model()\n    kwargs.pop(\"org_user_model\", None)  # Discard deprecated argument\n\n    org_owner_model = org_model.owner.related.related_model\n    try:\n        # Django 1.9\n        org_user_model = org_model.organization_users.rel.related_model\n    except AttributeError:\n        # Django 1.8\n        org_user_model = org_model.organization_users.related.related_model\n\n    if org_defaults is None:\n        org_defaults = {}\n    if org_user_defaults is None:\n        if \"is_admin\" in model_field_names(org_user_model):\n            org_user_defaults = {\"is_admin\": True}\n        else:\n            org_user_defaults = {}\n\n    if slug is not None:\n        org_defaults.update({\"slug\": slug})\n    if is_active is not None:\n        org_defaults.update({\"is_active\": is_active})\n\n    org_defaults.update({\"name\": name})\n    organization = org_model.objects.create(**org_defaults)\n\n    org_user_defaults.update({\"organization\": organization, \"user\": user})\n    new_user = org_user_model.objects.create(**org_user_defaults)\n\n    org_owner_model.objects.create(\n        organization=organization, organization_user=new_user\n    )\n    return organization", "response": "Create an organization user who\n    is the owner."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the specified attribute for the specified model field on the model class.", "response": "def model_field_attr(model, model_field, attr):\n    \"\"\"\n    Returns the specified attribute for the specified field on the model class.\n    \"\"\"\n    fields = dict([(field.name, field) for field in model._meta.fields])\n    return getattr(fields[model_field], attr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the form for registering or inviting a user", "response": "def get_form(self, **kwargs):\n        \"\"\"Returns the form for registering or inviting a user\"\"\"\n        if not hasattr(self, \"form_class\"):\n            raise AttributeError(_(\"You must define a form_class\"))\n        return self.form_class(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef activate_organizations(self, user):\n        try:\n            relation_name = self.org_model().user_relation_name\n        except TypeError:\n            # No org_model specified, raises a TypeError because NoneType is\n            # not callable. This the most sensible default:\n            relation_name = \"organizations_organization\"\n        organization_set = getattr(user, relation_name)\n        for org in organization_set.filter(is_active=False):\n            org.is_active = True\n            org.save()", "response": "Activates the related organizations for the user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef activate_view(self, request, user_id, token):\n        try:\n            user = self.user_model.objects.get(id=user_id, is_active=False)\n        except self.user_model.DoesNotExist:\n            raise Http404(_(\"Your URL may have expired.\"))\n\n        if not RegistrationTokenGenerator().check_token(user, token):\n            raise Http404(_(\"Your URL may have expired.\"))\n        form = self.get_form(\n            data=request.POST or None, files=request.FILES or None, instance=user\n        )\n        if form.is_valid():\n            form.instance.is_active = True\n            user = form.save()\n            user.set_password(form.cleaned_data[\"password\"])\n            user.save()\n            self.activate_organizations(user)\n            user = authenticate(\n                username=form.cleaned_data[\"username\"],\n                password=form.cleaned_data[\"password\"],\n            )\n            login(request, user)\n            return redirect(self.get_success_url())\n        return render(request, self.registration_form_template, {\"form\": form})", "response": "View function that activates the given User by setting is_active to True if the provided information is verified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a reminder email to the specified user", "response": "def send_reminder(self, user, sender=None, **kwargs):\n        \"\"\"Sends a reminder email to the specified user\"\"\"\n        if user.is_active:\n            return False\n        token = RegistrationTokenGenerator().make_token(user)\n        kwargs.update({\"token\": token})\n        self.email_message(\n            user, self.reminder_subject, self.reminder_body, sender, **kwargs\n        ).send()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef email_message(\n        self,\n        user,\n        subject_template,\n        body_template,\n        sender=None,\n        message_class=EmailMessage,\n        **kwargs\n    ):\n        \"\"\"\n        Returns an email message for a new user. This can be easily overridden.\n        For instance, to send an HTML message, use the EmailMultiAlternatives message_class\n        and attach the additional conent.\n        \"\"\"\n        if sender:\n            try:\n                display_name = sender.get_full_name()\n            except (AttributeError, TypeError):\n                display_name = sender.get_username()\n            from_email = \"%s <%s>\" % (\n                display_name, email.utils.parseaddr(settings.DEFAULT_FROM_EMAIL)[1]\n            )\n            reply_to = \"%s <%s>\" % (display_name, sender.email)\n        else:\n            from_email = settings.DEFAULT_FROM_EMAIL\n            reply_to = from_email\n\n        headers = {\"Reply-To\": reply_to}\n        kwargs.update({\"sender\": sender, \"user\": user})\n\n        subject_template = loader.get_template(subject_template)\n        body_template = loader.get_template(body_template)\n        subject = subject_template.render(\n            kwargs\n        ).strip()  # Remove stray newline characters\n        body = body_template.render(kwargs)\n        return message_class(subject, body, from_email, [user.email], headers=headers)", "response": "Returns an email message for a new user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_by_email(self, email, sender=None, request=None, **kwargs):\n        try:\n            user = self.user_model.objects.get(email=email)\n        except self.user_model.DoesNotExist:\n            user = self.user_model.objects.create(\n                username=self.get_username(),\n                email=email,\n                password=self.user_model.objects.make_random_password(),\n            )\n            user.is_active = False\n            user.save()\n        self.send_activation(user, sender, **kwargs)\n        return user", "response": "Registers a new user by email."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending an activation email to the user", "response": "def send_activation(self, user, sender=None, **kwargs):\n        \"\"\"\n        Invites a user to join the site\n        \"\"\"\n        if user.is_active:\n            return False\n        token = self.get_token(user)\n        kwargs.update({\"token\": token})\n        self.email_message(\n            user, self.activation_subject, self.activation_body, sender, **kwargs\n        ).send()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the user account and organization and user account creation process", "response": "def create_view(self, request):\n        \"\"\"\n        Initiates the organization and user account creation process\n        \"\"\"\n        try:\n            if request.user.is_authenticated():\n                return redirect(\"organization_add\")\n        except TypeError:\n            if request.user.is_authenticated:\n                return redirect(\"organization_add\")\n        form = org_registration_form(self.org_model)(request.POST or None)\n        if form.is_valid():\n            try:\n                user = self.user_model.objects.get(email=form.cleaned_data[\"email\"])\n            except self.user_model.DoesNotExist:\n                user = self.user_model.objects.create(\n                    username=self.get_username(),\n                    email=form.cleaned_data[\"email\"],\n                    password=self.user_model.objects.make_random_password(),\n                )\n                user.is_active = False\n                user.save()\n            else:\n                return redirect(\"organization_add\")\n            organization = create_organization(\n                user,\n                form.cleaned_data[\"name\"],\n                form.cleaned_data[\"slug\"],\n                is_active=False,\n            )\n            return render(\n                request,\n                self.activation_success_template,\n                {\"user\": user, \"organization\": organization},\n            )\n        return render(request, self.registration_form_template, {\"form\": form})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef invite_by_email(self, email, sender=None, request=None, **kwargs):\n        try:\n            user = self.user_model.objects.get(email=email)\n        except self.user_model.DoesNotExist:\n            # TODO break out user creation process\n            if \"username\" in inspect.getargspec(\n                self.user_model.objects.create_user\n            ).args:\n                user = self.user_model.objects.create(\n                    username=self.get_username(),\n                    email=email,\n                    password=self.user_model.objects.make_random_password(),\n                )\n            else:\n                user = self.user_model.objects.create(\n                    email=email, password=self.user_model.objects.make_random_password()\n                )\n            user.is_active = False\n            user.save()\n        self.send_invitation(user, sender, **kwargs)\n        return user", "response": "Creates an inactive user with the information we know and then sends an invitation email for that user to complete registration."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_notification(self, user, sender=None, **kwargs):\n        if not user.is_active:\n            return False\n        self.email_message(\n            user, self.notification_subject, self.notification_body, sender, **kwargs\n        ).send()\n        return True", "response": "Send a notification email to the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a new user and returns the org user object.", "response": "def add_user(self, user, is_admin=False):\n        \"\"\"\n        Adds a new user and if the first user makes the user an admin and\n        the owner.\n        \"\"\"\n        users_count = self.users.all().count()\n        if users_count == 0:\n            is_admin = True\n        # TODO get specific org user?\n        org_user = self._org_user_model.objects.create(\n            user=user, organization=self, is_admin=is_admin\n        )\n        if users_count == 0:\n            # TODO get specific org user?\n            self._org_owner_model.objects.create(\n                organization=self, organization_user=org_user\n            )\n\n        # User added signal\n        user_added.send(sender=self, user=user)\n        return org_user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_user(self, user):\n        org_user = self._org_user_model.objects.get(user=user, organization=self)\n        org_user.delete()\n\n        # User removed signal\n        user_removed.send(sender=self, user=user)", "response": "Removes a user from an organization."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_or_add_user(self, user, **kwargs):\n        is_admin = kwargs.pop(\"is_admin\", False)\n        users_count = self.users.all().count()\n        if users_count == 0:\n            is_admin = True\n\n        org_user, created = self._org_user_model.objects.get_or_create(\n            organization=self, user=user, defaults={\"is_admin\": is_admin}\n        )\n        if users_count == 0:\n            self._org_owner_model.objects.create(\n                organization=self, organization_user=org_user\n            )\n        if created:\n            # User added signal\n            user_added.send(sender=self, user=user)\n        return org_user, created", "response": "Gets or creates a user instance from the organization and returns the org_user and created flag."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef change_owner(self, new_owner):\n        old_owner = self.owner.organization_user\n        self.owner.organization_user = new_owner\n        self.owner.save()\n\n        # Owner changed signal\n        owner_changed.send(sender=self, old=old_owner, new=new_owner)", "response": "Changes ownership of an organization."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_admin(self, user):\n        return True if self.organization_users.filter(\n            user=user, is_admin=True\n        ) else False", "response": "Returns True if user is an admin in the organization otherwise False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes the user from the organization.", "response": "def delete(self, using=None):\n        \"\"\"\n        If the organization user is also the owner, this should not be deleted\n        unless it's part of a cascade from the Organization.\n\n        If there is no owner then the deletion should proceed.\n        \"\"\"\n        from organizations.exceptions import OwnershipRequired\n\n        try:\n            if self.organization.owner.organization_user.pk == self.pk:\n                raise OwnershipRequired(\n                    _(\n                        \"Cannot delete organization owner \"\n                        \"before organization or transferring ownership.\"\n                    )\n                )\n        # TODO This line presumes that OrgOwner model can't be modified\n        except self._org_owner_model.DoesNotExist:\n            pass\n        super(AbstractBaseOrganizationUser, self).delete(using=using)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self, *args, **kwargs):\n        from organizations.exceptions import OrganizationMismatch\n\n        if self.organization_user.organization.pk != self.organization.pk:\n            raise OrganizationMismatch\n        else:\n            super(AbstractBaseOrganizationOwner, self).save(*args, **kwargs)", "response": "This method is used to save the chosen\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n\n    parser = argparse.ArgumentParser(description='Convert ULog to KML')\n    parser.add_argument('filename', metavar='file.ulg', help='ULog input file')\n\n    parser.add_argument('-o', '--output', dest='output_filename',\n                        help=\"output filename\", default='track.kml')\n    parser.add_argument('--topic', dest='topic_name',\n                        help=\"topic name with position data (default=vehicle_gps_position)\",\n                        default='vehicle_gps_position')\n    parser.add_argument('--camera-trigger', dest='camera_trigger',\n                        help=\"Camera trigger topic name (e.g. camera_capture)\",\n                        default=None)\n\n    args = parser.parse_args()\n\n    convert_ulog2kml(args.filename, args.output_filename,\n                     position_topic_name=args.topic_name,\n                     camera_trigger_topic_name=args.camera_trigger)", "response": "Command line interface for the convert_ulog2kml function"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefault colors for flight mode to color conversion", "response": "def _kml_default_colors(x):\n    \"\"\" flight mode to color conversion \"\"\"\n    x = max([x, 0])\n    colors_arr = [simplekml.Color.red, simplekml.Color.green, simplekml.Color.blue,\n                  simplekml.Color.violet, simplekml.Color.yellow, simplekml.Color.orange,\n                  simplekml.Color.burlywood, simplekml.Color.azure, simplekml.Color.lightblue,\n                  simplekml.Color.lawngreen, simplekml.Color.indianred, simplekml.Color.hotpink]\n    return colors_arr[x]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_ulog2kml(ulog_file_name, output_file_name, position_topic_name=\n                     'vehicle_gps_position', colors=_kml_default_colors, altitude_offset=0,\n                     minimum_interval_s=0.1, style=None, camera_trigger_topic_name=None):\n    \"\"\"\n    Coverts and ULog file to a CSV file.\n\n    :param ulog_file_name: The ULog filename to open and read\n    :param output_file_name: KML Output file name\n    :param position_topic_name: either name of a topic (must have 'lon', 'lat' &\n           'alt' fields), or a list of topic names\n    :param colors: lambda function with flight mode (int) (or -1) as input and\n           returns a color (eg 'fffff8f0') (or list of lambda functions if\n           multiple position_topic_name's)\n    :param altitude_offset: add this offset to the altitude [m]\n    :param minimum_interval_s: minimum time difference between two datapoints\n           (drop if more points)\n    :param style: dictionary with rendering options:\n                  'extrude': Bool\n                  'line_width': int\n    :param camera_trigger_topic_name: name of the camera trigger topic (must\n                                      have 'lon', 'lat' & 'seq')\n\n    :return: None\n    \"\"\"\n\n    default_style = {\n        'extrude': False,\n        'line_width': 3\n        }\n\n    used_style = default_style\n    if style is not None:\n        for key in style:\n            used_style[key] = style[key]\n\n\n    if not isinstance(position_topic_name, list):\n        position_topic_name = [position_topic_name]\n        colors = [colors]\n\n    kml = simplekml.Kml()\n    load_topic_names = position_topic_name + ['vehicle_status']\n    if camera_trigger_topic_name is not None:\n        load_topic_names.append(camera_trigger_topic_name)\n    ulog = ULog(ulog_file_name, load_topic_names)\n\n    # get flight modes\n    try:\n        cur_dataset = ulog.get_dataset('vehicle_status')\n        flight_mode_changes = cur_dataset.list_value_changes('nav_state')\n        flight_mode_changes.append((ulog.last_timestamp, -1))\n    except (KeyError, IndexError) as error:\n        flight_mode_changes = []\n\n    # add the graphs\n    for topic, cur_colors in zip(position_topic_name, colors):\n        _kml_add_position_data(kml, ulog, topic, cur_colors, used_style,\n                               altitude_offset, minimum_interval_s, flight_mode_changes)\n\n    # camera triggers\n    _kml_add_camera_triggers(kml, ulog, camera_trigger_topic_name, altitude_offset)\n\n    kml.save(output_file_name)", "response": "Converts a ULog file to a KML file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _kml_add_camera_triggers(kml, ulog, camera_trigger_topic_name, altitude_offset):\n\n    data = ulog.data_list\n    topic_instance = 0\n\n    cur_dataset = [elem for elem in data\n                   if elem.name == camera_trigger_topic_name and elem.multi_id == topic_instance]\n    if len(cur_dataset) > 0:\n        cur_dataset = cur_dataset[0]\n\n        pos_lon = cur_dataset.data['lon']\n        pos_lat = cur_dataset.data['lat']\n        pos_alt = cur_dataset.data['alt']\n        sequence = cur_dataset.data['seq']\n\n        for i in range(len(pos_lon)):\n            pnt = kml.newpoint(name='Camera Trigger '+str(sequence[i]))\n            pnt.coords = [(pos_lon[i], pos_lat[i], pos_alt[i] + altitude_offset)]", "response": "Add camera triggers to the KML map."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dataset(self, name, multi_instance=0):\n        return [elem for elem in self._data_list\n                if elem.name == name and elem.multi_id == multi_instance][0]", "response": "get a specific dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_message_info_multiple(self, msg_info):\n        if msg_info.key in self._msg_info_multiple_dict:\n            if msg_info.is_continued:\n                self._msg_info_multiple_dict[msg_info.key][-1].append(msg_info.value)\n            else:\n                self._msg_info_multiple_dict[msg_info.key].append([msg_info.value])\n        else:\n            self._msg_info_multiple_dict[msg_info.key] = [[msg_info.value]]", "response": "add a message info multiple to self. _msg_info_multiple_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading and parse an ULog file into memory", "response": "def _load_file(self, log_file, message_name_filter_list):\n        \"\"\" load and parse an ULog file into memory \"\"\"\n        if isinstance(log_file, str):\n            self._file_handle = open(log_file, \"rb\")\n        else:\n            self._file_handle = log_file\n\n        # parse the whole file\n        self._read_file_header()\n        self._last_timestamp = self._start_timestamp\n        self._read_file_definitions()\n\n        if self.has_data_appended and len(self._appended_offsets) > 0:\n            if self._debug:\n                print('This file has data appended')\n            for offset in self._appended_offsets:\n                self._read_file_data(message_name_filter_list, read_until=offset)\n                self._file_handle.seek(offset)\n\n        # read the whole file, or the rest if data appended\n        self._read_file_data(message_name_filter_list)\n\n        self._file_handle.close()\n        del self._file_handle"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the file data section", "response": "def _read_file_data(self, message_name_filter_list, read_until=None):\n        \"\"\"\n        read the file data section\n        :param read_until: an optional file offset: if set, parse only up to\n                           this offset (smaller than)\n        \"\"\"\n\n        if read_until is None:\n            read_until = 1 << 50 # make it larger than any possible log file\n\n        try:\n            # pre-init reusable objects\n            header = self._MessageHeader()\n            msg_data = self._MessageData()\n\n            while True:\n                data = self._file_handle.read(3)\n                header.initialize(data)\n                data = self._file_handle.read(header.msg_size)\n                if len(data) < header.msg_size:\n                    break # less data than expected. File is most likely cut\n\n                if self._file_handle.tell() > read_until:\n                    if self._debug:\n                        print('read until offset=%i done, current pos=%i' %\n                              (read_until, self._file_handle.tell()))\n                    break\n\n                if header.msg_type == self.MSG_TYPE_INFO:\n                    msg_info = self._MessageInfo(data, header)\n                    self._msg_info_dict[msg_info.key] = msg_info.value\n                elif header.msg_type == self.MSG_TYPE_INFO_MULTIPLE:\n                    msg_info = self._MessageInfo(data, header, is_info_multiple=True)\n                    self._add_message_info_multiple(msg_info)\n                elif header.msg_type == self.MSG_TYPE_PARAMETER:\n                    msg_info = self._MessageInfo(data, header)\n                    self._changed_parameters.append((self._last_timestamp,\n                                                     msg_info.key, msg_info.value))\n                elif header.msg_type == self.MSG_TYPE_ADD_LOGGED_MSG:\n                    msg_add_logged = self._MessageAddLogged(data, header,\n                                                            self._message_formats)\n                    if (message_name_filter_list is None or\n                            msg_add_logged.message_name in message_name_filter_list):\n                        self._subscriptions[msg_add_logged.msg_id] = msg_add_logged\n                    else:\n                        self._filtered_message_ids.add(msg_add_logged.msg_id)\n                elif header.msg_type == self.MSG_TYPE_LOGGING:\n                    msg_logging = self.MessageLogging(data, header)\n                    self._logged_messages.append(msg_logging)\n                elif header.msg_type == self.MSG_TYPE_DATA:\n                    msg_data.initialize(data, header, self._subscriptions, self)\n                    if msg_data.timestamp != 0 and msg_data.timestamp > self._last_timestamp:\n                        self._last_timestamp = msg_data.timestamp\n                elif header.msg_type == self.MSG_TYPE_DROPOUT:\n                    msg_dropout = self.MessageDropout(data, header,\n                                                      self._last_timestamp)\n                    self._dropouts.append(msg_dropout)\n                else:\n                    if self._debug:\n                        print('_read_file_data: unknown message type: %i (%s)' %\n                              (header.msg_type, chr(header.msg_type)))\n                        file_position = self._file_handle.tell()\n                        print('file position: %i (0x%x) msg size: %i' % (\n                            file_position, file_position, header.msg_size))\n\n                    if self._check_file_corruption(header):\n                        # seek back to advance only by a single byte instead of\n                        # skipping the message\n                        self._file_handle.seek(-2-header.msg_size, 1)\n\n        except struct.error:\n            pass #we read past the end of the file\n\n        # convert into final representation\n        while self._subscriptions:\n            _, value = self._subscriptions.popitem()\n            if len(value.buffer) > 0: # only add if we have data\n                data_item = ULog.Data(value)\n                self._data_list.append(data_item)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks for file corruption based on an unknown message type in the header", "response": "def _check_file_corruption(self, header):\n        \"\"\" check for file corruption based on an unknown message type in the header \"\"\"\n        # We need to handle 2 cases:\n        # - corrupt file (we do our best to read the rest of the file)\n        # - new ULog message type got added (we just want to skip the message)\n        if header.msg_type == 0 or header.msg_size == 0 or header.msg_size > 10000:\n            if not self._file_corrupt and self._debug:\n                print('File corruption detected')\n            self._file_corrupt = True\n\n        return self._file_corrupt"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_version_info(self, key_name='ver_sw_release'):\n        if key_name in self._msg_info_dict:\n            val = self._msg_info_dict[key_name]\n            return ((val >> 24) & 0xff, (val >> 16) & 0xff, (val >> 8) & 0xff, val & 0xff)\n        return None", "response": "get the version information as tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets version information in the form v1. 2. 3 RC", "response": "def get_version_info_str(self, key_name='ver_sw_release'):\n        \"\"\"\n        get version information in the form 'v1.2.3 (RC)', or None if version\n        tag either not found or it's a development version\n        \"\"\"\n        version = self.get_version_info(key_name)\n        if not version is None and version[3] >= 64:\n            type_str = ''\n            if version[3] < 128: type_str = ' (alpha)'\n            elif version[3] < 192: type_str = ' (beta)'\n            elif version[3] < 255: type_str = ' (RC)'\n            return 'v{}.{}.{}{}'.format(version[0], version[1], version[2], type_str)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n\n    parser = argparse.ArgumentParser(description='Convert ULog to CSV')\n    parser.add_argument('filename', metavar='file.ulg', help='ULog input file')\n\n    parser.add_argument(\n        '-m', '--messages', dest='messages',\n        help=(\"Only consider given messages. Must be a comma-separated list of\"\n              \" names, like 'sensor_combined,vehicle_gps_position'\"))\n    parser.add_argument('-d', '--delimiter', dest='delimiter', action='store',\n                        help=\"Use delimiter in CSV (default is ',')\", default=',')\n\n\n    parser.add_argument('-o', '--output', dest='output', action='store',\n                        help='Output directory (default is same as input file)',\n                        metavar='DIR')\n\n    args = parser.parse_args()\n\n    if args.output and not os.path.isdir(args.output):\n        print('Creating output directory {:}'.format(args.output))\n        os.mkdir(args.output)\n\n    convert_ulog2csv(args.filename, args.messages, args.output, args.delimiter)", "response": "Command line interface for the convert_ulog2csv function"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_ulog2csv(ulog_file_name, messages, output, delimiter):\n\n    msg_filter = messages.split(',') if messages else None\n\n    ulog = ULog(ulog_file_name, msg_filter)\n    data = ulog.data_list\n\n    output_file_prefix = ulog_file_name\n    # strip '.ulg'\n    if output_file_prefix.lower().endswith('.ulg'):\n        output_file_prefix = output_file_prefix[:-4]\n\n    # write to different output path?\n    if output:\n        base_name = os.path.basename(output_file_prefix)\n        output_file_prefix = os.path.join(output, base_name)\n\n    for d in data:\n        fmt = '{0}_{1}_{2}.csv'\n        output_file_name = fmt.format(output_file_prefix, d.name, d.multi_id)\n        fmt = 'Writing {0} ({1} data points)'\n        # print(fmt.format(output_file_name, len(d.data['timestamp'])))\n        with open(output_file_name, 'w') as csvfile:\n\n            # use same field order as in the log, except for the timestamp\n            data_keys = [f.field_name for f in d.field_data]\n            data_keys.remove('timestamp')\n            data_keys.insert(0, 'timestamp')  # we want timestamp at first position\n\n            # we don't use np.savetxt, because we have multiple arrays with\n            # potentially different data types. However the following is quite\n            # slow...\n\n            # write the header\n            csvfile.write(delimiter.join(data_keys) + '\\n')\n\n            # write the data\n            last_elem = len(data_keys)-1\n            for i in range(len(d.data['timestamp'])):\n                for k in range(len(data_keys)):\n                    csvfile.write(str(d.data[data_keys[k]][i]))\n                    if k != last_elem:\n                        csvfile.write(delimiter)\n                csvfile.write('\\n')", "response": "Convert a ULog file to a CSV file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show_info(ulog, verbose):\n    m1, s1 = divmod(int(ulog.start_timestamp/1e6), 60)\n    h1, m1 = divmod(m1, 60)\n    m2, s2 = divmod(int((ulog.last_timestamp - ulog.start_timestamp)/1e6), 60)\n    h2, m2 = divmod(m2, 60)\n    print(\"Logging start time: {:d}:{:02d}:{:02d}, duration: {:d}:{:02d}:{:02d}\".format(\n        h1, m1, s1, h2, m2, s2))\n\n    dropout_durations = [dropout.duration for dropout in ulog.dropouts]\n    if len(dropout_durations) == 0:\n        print(\"No Dropouts\")\n    else:\n        print(\"Dropouts: count: {:}, total duration: {:.1f} s, max: {:} ms, mean: {:} ms\"\n              .format(len(dropout_durations), sum(dropout_durations)/1000.,\n                      max(dropout_durations),\n                      int(sum(dropout_durations)/len(dropout_durations))))\n\n    version = ulog.get_version_info_str()\n    if not version is None:\n        print('SW Version: {}'.format(version))\n\n    print(\"Info Messages:\")\n    for k in sorted(ulog.msg_info_dict):\n        if not k.startswith('perf_') or verbose:\n            print(\" {0}: {1}\".format(k, ulog.msg_info_dict[k]))\n\n\n    if len(ulog.msg_info_multiple_dict) > 0:\n        if verbose:\n            print(\"Info Multiple Messages:\")\n            for k in sorted(ulog.msg_info_multiple_dict):\n                print(\" {0}: {1}\".format(k, ulog.msg_info_multiple_dict[k]))\n        else:\n            print(\"Info Multiple Messages: {}\".format(\n                \", \".join([\"[{}: {}]\".format(k, len(ulog.msg_info_multiple_dict[k])) for k in\n                           sorted(ulog.msg_info_multiple_dict)])))\n\n\n\n    print(\"\")\n    print(\"{:<41} {:7}, {:10}\".format(\"Name (multi id, message size in bytes)\",\n                                      \"number of data points\", \"total bytes\"))\n\n    data_list_sorted = sorted(ulog.data_list, key=lambda d: d.name + str(d.multi_id))\n    for d in data_list_sorted:\n        message_size = sum([ULog.get_field_size(f.type_str) for f in d.field_data])\n        num_data_points = len(d.data['timestamp'])\n        name_id = \"{:} ({:}, {:})\".format(d.name, d.multi_id, message_size)\n        print(\" {:<40} {:7d} {:10d}\".format(name_id, num_data_points,\n                                            message_size * num_data_points))", "response": "Show general information from an ULog"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n\n    parser = argparse.ArgumentParser(description='Display logged messages from an ULog file')\n    parser.add_argument('filename', metavar='file.ulg', help='ULog input file')\n\n\n    args = parser.parse_args()\n    ulog_file_name = args.filename\n\n    msg_filter = [] # we don't need the data messages\n    ulog = ULog(ulog_file_name, msg_filter)\n\n\n    for m in ulog.logged_messages:\n        m1, s1 = divmod(int(m.timestamp/1e6), 60)\n        h1, m1 = divmod(m1, 60)\n        print(\"{:d}:{:02d}:{:02d} {:}: {:}\".format(\n            h1, m1, s1, m.log_level_str(), m.message))", "response": "This function is the main entry point for the ULog command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n\n    parser = argparse.ArgumentParser(description='Extract parameters from an ULog file')\n    parser.add_argument('filename', metavar='file.ulg', help='ULog input file')\n\n    parser.add_argument('-d', '--delimiter', dest='delimiter', action='store',\n                        help='Use delimiter in CSV (default is \\',\\')', default=',')\n\n    parser.add_argument('-i', '--initial', dest='initial', action='store_true',\n                        help='Only extract initial parameters', default=False)\n\n    parser.add_argument('-o', '--octave', dest='octave', action='store_true',\n                        help='Use Octave format', default=False)\n\n    parser.add_argument('-t', '--timestamps', dest='timestamps', action='store_true',\n                        help='Extract changed parameters with timestamps', default=False)\n\n    parser.add_argument('output_filename', metavar='params.txt',\n                        type=argparse.FileType('w'), nargs='?',\n                        help='Output filename (default=stdout)', default=sys.stdout)\n\n    args = parser.parse_args()\n    ulog_file_name = args.filename\n\n    message_filter = []\n    if not args.initial: message_filter = None\n\n    ulog = ULog(ulog_file_name, message_filter)\n\n    param_keys = sorted(ulog.initial_parameters.keys())\n    delimiter = args.delimiter\n    output_file = args.output_filename\n\n    if not args.octave:\n        for param_key in param_keys:\n            output_file.write(param_key)\n            if args.initial:\n                output_file.write(delimiter)\n                output_file.write(str(ulog.initial_parameters[param_key]))\n                output_file.write('\\n')\n            elif args.timestamps:\n                output_file.write(delimiter)\n                output_file.write(str(ulog.initial_parameters[param_key]))\n                for t, name, value in ulog.changed_parameters:\n                    if name == param_key:\n                        output_file.write(delimiter)\n                        output_file.write(str(value))\n\n                output_file.write('\\n')\n                output_file.write(\"timestamp\")\n                output_file.write(delimiter)\n                output_file.write('0')\n                for t, name, value in ulog.changed_parameters:\n                    if name == param_key:\n                        output_file.write(delimiter)\n                        output_file.write(str(t))\n\n                output_file.write('\\n')\n            else:\n                for t, name, value in ulog.changed_parameters:\n                    if name == param_key:\n                        output_file.write(delimiter)\n                        output_file.write(str(value))\n\n                output_file.write('\\n')\n\n    else:\n\n        for param_key in param_keys:\n            output_file.write('# name ')\n            output_file.write(param_key)\n            values = [ulog.initial_parameters[param_key]]\n\n            if not args.initial:\n                for t, name, value in ulog.changed_parameters:\n                    if name == param_key:\n                        values += [value]\n\n            if len(values) > 1:\n                output_file.write('\\n# type: matrix\\n')\n                output_file.write('# rows: 1\\n')\n                output_file.write('# columns: ')\n                output_file.write(str(len(values)) + '\\n')\n                for value in values:\n                    output_file.write(str(value) + ' ')\n\n            else:\n                output_file.write('\\n# type: scalar\\n')\n                output_file.write(str(values[0]))\n\n            output_file.write('\\n')", "response": "This function is the main function of the ULog command line interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the configured estimator as string from initial parameters", "response": "def get_estimator(self):\n        \"\"\"return the configured estimator as string from initial parameters\"\"\"\n\n        mav_type = self._ulog.initial_parameters.get('MAV_TYPE', None)\n        if mav_type == 1: # fixed wing always uses EKF2\n            return 'EKF2'\n\n        mc_est_group = self._ulog.initial_parameters.get('SYS_MC_EST_GROUP', None)\n        return {0: 'INAV',\n                1: 'LPE',\n                2: 'EKF2',\n                3: 'IEKF'}.get(mc_est_group, 'unknown ({})'.format(mc_est_group))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_roll_pitch_yaw(self):\n\n        self._add_roll_pitch_yaw_to_message('vehicle_attitude')\n        self._add_roll_pitch_yaw_to_message('vehicle_vision_attitude')\n        self._add_roll_pitch_yaw_to_message('vehicle_attitude_groundtruth')\n        self._add_roll_pitch_yaw_to_message('vehicle_attitude_setpoint', '_d')", "response": "add roll pitch yaw to the base log file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_configured_rc_input_names(self, channel):\n        ret_val = []\n        for key in self._ulog.initial_parameters:\n            param_val = self._ulog.initial_parameters[key]\n            if key.startswith('RC_MAP_') and param_val == channel + 1:\n                ret_val.append(key[7:].capitalize())\n\n        if len(ret_val) > 0:\n            return ret_val\n        return None", "response": "find all RC mappings to a given channel and return their names"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __main(draft, directory, project_name, project_version, project_date, answer_yes):\n    directory = os.path.abspath(directory)\n    config = load_config(directory)\n    to_err = draft\n\n    click.echo(\"Loading template...\", err=to_err)\n    if config[\"template\"] is None:\n        template = pkg_resources.resource_string(\n            __name__, \"templates/template.rst\"\n        ).decode(\"utf8\")\n    else:\n        with open(config[\"template\"], \"rb\") as tmpl:\n            template = tmpl.read().decode(\"utf8\")\n\n    click.echo(\"Finding news fragments...\", err=to_err)\n\n    definitions = config[\"types\"]\n\n    if config.get(\"directory\"):\n        base_directory = os.path.abspath(config[\"directory\"])\n        fragment_directory = None\n    else:\n        base_directory = os.path.abspath(\n            os.path.join(directory, config[\"package_dir\"], config[\"package\"])\n        )\n        fragment_directory = \"newsfragments\"\n\n    fragments, fragment_filenames = find_fragments(\n        base_directory, config[\"sections\"], fragment_directory, definitions\n    )\n\n    click.echo(\"Rendering news fragments...\", err=to_err)\n    fragments = split_fragments(fragments, definitions)\n    rendered = render_fragments(\n        # The 0th underline is used for the top line\n        template,\n        config[\"issue_format\"],\n        fragments,\n        definitions,\n        config[\"underlines\"][1:],\n        config[\"wrap\"],\n    )\n\n    if project_version is None:\n        project_version = get_version(\n            os.path.join(directory, config[\"package_dir\"]), config[\"package\"]\n        )\n\n    if project_name is None:\n        package = config.get(\"package\")\n        if package:\n            project_name = get_project_name(\n                os.path.abspath(os.path.join(directory, config[\"package_dir\"])), package\n            )\n        else:\n            # Can't determine a project_name, but maybe it is not needed.\n            project_name = \"\"\n\n    if project_date is None:\n        project_date = _get_date()\n\n    top_line = config[\"title_format\"].format(\n        name=project_name, version=project_version, project_date=project_date\n    )\n    top_line += u\"\\n\" + (config[\"underlines\"][0] * len(top_line)) + u\"\\n\"\n\n    if draft:\n        click.echo(\n            \"Draft only -- nothing has been written.\\n\"\n            \"What is seen below is what would be written.\\n\",\n            err=to_err,\n        )\n        click.echo(\"%s\\n%s\" % (top_line, rendered))\n    else:\n        click.echo(\"Writing to newsfile...\", err=to_err)\n        start_line = config[\"start_line\"]\n        append_to_newsfile(\n            directory, config[\"filename\"], start_line, top_line, rendered\n        )\n\n        click.echo(\"Staging newsfile...\", err=to_err)\n        stage_newsfile(directory, config[\"filename\"])\n\n        click.echo(\"Removing news fragments...\", err=to_err)\n        remove_files(fragment_filenames, answer_yes)\n\n        click.echo(\"Done!\", err=to_err)", "response": "Main entry point for the news page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding all the fragments in a single section.", "response": "def find_fragments(base_directory, sections, fragment_directory, definitions):\n    \"\"\"\n    Sections are a dictonary of section names to paths.\n    \"\"\"\n    content = OrderedDict()\n    fragment_filenames = []\n\n    for key, val in sections.items():\n\n        if fragment_directory is not None:\n            section_dir = os.path.join(base_directory, val, fragment_directory)\n        else:\n            section_dir = os.path.join(base_directory, val)\n\n        files = os.listdir(section_dir)\n\n        file_content = {}\n\n        for basename in files:\n            parts = basename.split(u\".\")\n\n            counter = 0\n            if len(parts) == 1:\n                continue\n            else:\n                ticket, category = parts[:2]\n\n            # If there is a number after the category then use it as a counter,\n            # otherwise ignore it.\n            # This means 1.feature.1 and 1.feature do not conflict but\n            # 1.feature.rst and 1.feature do.\n            if len(parts) > 2:\n                try:\n                    counter = int(parts[2])\n                except ValueError:\n                    pass\n\n            if category not in definitions:\n                continue\n\n            full_filename = os.path.join(section_dir, basename)\n            fragment_filenames.append(full_filename)\n            with open(full_filename, \"rb\") as f:\n                data = f.read().decode(\"utf8\", \"replace\")\n\n            if (ticket, category, counter) in file_content:\n                raise ValueError(\n                    \"multiple files for {}.{} in {}\".format(\n                        ticket, category, section_dir\n                    )\n                )\n            file_content[ticket, category, counter] = data\n\n        content[key] = file_content\n\n    return content, fragment_filenames"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef indent(text, prefix):\n    # Based on Python 3's textwrap.indent\n    def prefixed_lines():\n        for line in text.splitlines(True):\n            yield (prefix + line if line.strip() else line)\n    return u\"\".join(prefixed_lines())", "response": "Indent text with prefix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender the fragments into a news file.", "response": "def render_fragments(template, issue_format, fragments, definitions, underlines, wrap):\n    \"\"\"\n    Render the fragments into a news file.\n    \"\"\"\n\n    jinja_template = Template(template, trim_blocks=True)\n\n    data = OrderedDict()\n\n    for section_name, section_value in fragments.items():\n\n        data[section_name] = OrderedDict()\n\n        for category_name, category_value in section_value.items():\n            # Suppose we start with an ordering like this:\n            #\n            # - Fix the thing (#7, #123, #2)\n            # - Fix the other thing (#1)\n\n            # First we sort the issues inside each line:\n            #\n            # - Fix the thing (#2, #7, #123)\n            # - Fix the other thing (#1)\n            entries = []\n            for text, issues in category_value.items():\n                entries.append((text, sorted(issues, key=issue_key)))\n\n            # Then we sort the lines:\n            #\n            # - Fix the other thing (#1)\n            # - Fix the thing (#2, #7, #123)\n            entries.sort(key=entry_key)\n\n            # Then we put these nicely sorted entries back in an ordered dict\n            # for the template, after formatting each issue number\n            categories = OrderedDict()\n            for text, issues in entries:\n                rendered = [render_issue(issue_format, i) for i in issues]\n                categories[text] = rendered\n\n            data[section_name][category_name] = categories\n\n    done = []\n\n    res = jinja_template.render(\n        sections=data, definitions=definitions, underlines=underlines\n    )\n\n    for line in res.split(u\"\\n\"):\n        if wrap:\n            done.append(\n                textwrap.fill(\n                    line,\n                    width=79,\n                    subsequent_indent=u\"  \",\n                    break_long_words=False,\n                    break_on_hyphens=False,\n                )\n            )\n        else:\n            done.append(line)\n\n    return u\"\\n\".join(done).rstrip() + u\"\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a Bland - Altman plot for the given set of measurements.", "response": "def plot_blandaltman(x, y, agreement=1.96, confidence=.95, figsize=(5, 4),\n                     dpi=100, ax=None):\n    \"\"\"\n    Generate a Bland-Altman plot to compare two sets of measurements.\n\n    Parameters\n    ----------\n    x, y : np.array or list\n        First and second measurements.\n    agreement : float\n        Multiple of the standard deviation to plot limit of agreement bounds.\n        The defaults is 1.96.\n    confidence : float\n        If not ``None``, plot the specified percentage confidence interval on\n        the mean and limits of agreement.\n    figsize : tuple\n        Figsize in inches\n    dpi : int\n        Resolution of the figure in dots per inches.\n    ax : matplotlib axes\n        Axis on which to draw the plot\n\n    Returns\n    -------\n    ax : Matplotlib Axes instance\n        Returns the Axes object with the plot for further tweaking.\n\n    Notes\n    -----\n    Bland-Altman plots are extensively used to evaluate the agreement among two\n    different instruments or two measurements techniques. Bland-Altman plots\n    allow identification of any systematic difference between the measurements\n    (i.e., fixed bias) or possible outliers. The mean difference is the\n    estimated bias, and the SD of the differences measures the random\n    fluctuations around this mean. If the mean value of the difference differs\n    significantly from 0 on the basis of a 1-sample t-test, this indicates\n    the presence of fixed bias. If there is a consistent bias, it can be\n    adjusted for by subtracting the mean difference from the new method.\n    It is common to compute 95% limits of agreement for each comparison\n    (average difference \u00b1 1.96 standard deviation of the difference), which\n    tells us how far apart measurements by 2 methods were more likely to be\n    for most individuals. If the differences within mean \u00b1 1.96 SD are not\n    clinically important, the two methods may be used interchangeably.\n    The 95% limits of agreement can be unreliable estimates of the population\n    parameters especially for small sample sizes so, when comparing methods\n    or assessing repeatability, it is important to calculate confidence\n    intervals for 95% limits of agreement.\n\n    The code is an adaptation of the Python package PyCompare by\n    Jake TM Pearce. All credits goes to the original author. The present\n    implementation is a simplified version; please refer to the original\n    package for more advanced functionalities.\n\n    References\n    ----------\n    .. [1] Bland, J. M., & Altman, D. (1986). Statistical methods for assessing\n           agreement between two methods of clinical measurement. The lancet,\n           327(8476), 307-310.\n\n    .. [2] https://github.com/jaketmp/pyCompare\n\n    .. [3] https://en.wikipedia.org/wiki/Bland%E2%80%93Altman_plot\n\n    Examples\n    --------\n\n    Bland-Altman plot\n\n    .. plot::\n\n        >>> import numpy as np\n        >>> import pingouin as pg\n        >>> np.random.seed(123)\n        >>> mean, cov = [10, 11], [[1, 0.8], [0.8, 1]]\n        >>> x, y = np.random.multivariate_normal(mean, cov, 30).T\n        >>> ax = pg.plot_blandaltman(x, y)\n    \"\"\"\n    # Safety check\n    x = np.asarray(x)\n    y = np.asarray(y)\n    assert x.ndim == 1 and y.ndim == 1\n    assert x.size == y.size\n    n = x.size\n    mean = np.vstack((x, y)).mean(0)\n    diff = x - y\n    md = diff.mean()\n    sd = diff.std(axis=0, ddof=1)\n\n    # Confidence intervals\n    if confidence is not None:\n        assert 0 < confidence < 1\n        ci = dict()\n        ci['mean'] = stats.norm.interval(confidence, loc=md,\n                                         scale=sd / np.sqrt(n))\n        seLoA = ((1 / n) + (agreement**2 / (2 * (n - 1)))) * (sd**2)\n        loARange = np.sqrt(seLoA) * stats.t.ppf((1 - confidence) / 2, n - 1)\n        ci['upperLoA'] = ((md + agreement * sd) + loARange,\n                          (md + agreement * sd) - loARange)\n        ci['lowerLoA'] = ((md - agreement * sd) + loARange,\n                          (md - agreement * sd) - loARange)\n\n    # Start the plot\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize, dpi=dpi)\n\n    # Plot the mean diff, limits of agreement and scatter\n    ax.axhline(md, color='#6495ED', linestyle='--')\n    ax.axhline(md + agreement * sd, color='coral', linestyle='--')\n    ax.axhline(md - agreement * sd, color='coral', linestyle='--')\n    ax.scatter(mean, diff, alpha=0.5)\n\n    loa_range = (md + (agreement * sd)) - (md - agreement * sd)\n    offset = (loa_range / 100.0) * 1.5\n\n    trans = transforms.blended_transform_factory(ax.transAxes, ax.transData)\n\n    ax.text(0.98, md + offset, 'Mean', ha=\"right\", va=\"bottom\",\n            transform=trans)\n    ax.text(0.98, md - offset, '%.2f' % md, ha=\"right\", va=\"top\",\n            transform=trans)\n\n    ax.text(0.98, md + (agreement * sd) + offset, '+%.2f SD' % agreement,\n            ha=\"right\", va=\"bottom\", transform=trans)\n    ax.text(0.98, md + (agreement * sd) - offset,\n            '%.2f' % (md + agreement * sd), ha=\"right\", va=\"top\",\n            transform=trans)\n\n    ax.text(0.98, md - (agreement * sd) - offset, '-%.2f SD' % agreement,\n            ha=\"right\", va=\"top\", transform=trans)\n    ax.text(0.98, md - (agreement * sd) + offset,\n            '%.2f' % (md - agreement * sd), ha=\"right\", va=\"bottom\",\n            transform=trans)\n\n    if confidence is not None:\n        ax.axhspan(ci['mean'][0], ci['mean'][1],\n                   facecolor='#6495ED', alpha=0.2)\n\n        ax.axhspan(ci['upperLoA'][0], ci['upperLoA'][1],\n                   facecolor='coral', alpha=0.2)\n\n        ax.axhspan(ci['lowerLoA'][0], ci['lowerLoA'][1],\n                   facecolor='coral', alpha=0.2)\n\n    # Labels and title\n    ax.set_ylabel('Difference between methods')\n    ax.set_xlabel('Mean of methods')\n    ax.set_title('Bland-Altman plot')\n\n    # Despine and trim\n    sns.despine(trim=True, ax=ax)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots the bootstrapped 95% confidence intervals and distribution of a robust Skipped correlation.", "response": "def plot_skipped_corr(x, y, xlabel=None, ylabel=None, n_boot=2000, seed=None):\n\n    \"\"\"Plot the bootstrapped 95% confidence intervals and distribution\n    of a robust Skipped correlation.\n\n    Parameters\n    ----------\n    x, y : 1D-arrays or list\n        Samples\n    xlabel, ylabel : str\n        Axes labels\n    n_boot : int\n        Number of bootstrap iterations for the computation of the\n        confidence intervals\n    seed : int\n        Random seed generator for the bootstrap confidence intervals.\n\n    Returns\n    --------\n    fig : matplotlib Figure instance\n        Matplotlib Figure. To get the individual axes, use fig.axes.\n\n    Notes\n    -----\n    This function is inspired by the Matlab Robust Correlation Toolbox (Pernet,\n    Wilcox and Rousselet, 2012). It uses the skipped correlation to determine\n    the outliers. Note that this function requires the scikit-learn package.\n\n    References\n    ----------\n    .. [1] Pernet, C.R., Wilcox, R., Rousselet, G.A., 2012. Robust correlation\n           analyses: false positive and power validation using a new open\n           source matlab toolbox. Front. Psychol. 3, 606.\n           https://doi.org/10.3389/fpsyg.2012.00606\n\n    Examples\n    --------\n\n    Plot a robust Skipped correlation with bootstrapped confidence intervals\n\n    .. plot::\n\n        >>> import numpy as np\n        >>> import pingouin as pg\n        >>> np.random.seed(123)\n        >>> mean, cov, n = [170, 70], [[20, 10], [10, 20]], 30\n        >>> x, y = np.random.multivariate_normal(mean, cov, n).T\n        >>> # Introduce two outliers\n        >>> x[10], y[10] = 160, 100\n        >>> x[8], y[8] = 165, 90\n        >>> fig = pg.plot_skipped_corr(x, y, xlabel='Height', ylabel='Weight')\n    \"\"\"\n    from pingouin.correlation import skipped\n    from scipy.stats import pearsonr\n    from pingouin.effsize import compute_bootci\n\n    # Safety check\n    x = np.asarray(x)\n    y = np.asarray(y)\n    assert x.size == y.size\n\n    # Skipped Spearman / Pearson correlations\n    r, p, outliers = skipped(x, y, method='spearman')\n    r_pearson, _ = pearsonr(x[~outliers], y[~outliers])\n\n    # Bootstrapped skipped Spearman distribution & CI\n    spearman_ci, spearman_dist = compute_bootci(\n        x=x[~outliers], y=y[~outliers], func='spearman',\n        n_boot=n_boot, return_dist=True, seed=seed)\n\n    # Bootstrapped skipped Pearson distribution & CI\n    pearson_ci, pearson_dist = compute_bootci(\n        x=x[~outliers], y=y[~outliers], func='pearson',\n        n_boot=n_boot, return_dist=True, seed=seed)\n\n    # START THE PLOT\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4.2))\n    # plt.subplots_adjust(wspace=0.3)\n    sns.despine()\n\n    # Scatter plot and regression lines\n    sns.regplot(x[~outliers], y[~outliers], ax=ax1, color='darkcyan')\n    ax1.scatter(x[outliers], y[outliers], color='indianred', label='outliers')\n    ax1.scatter(x[~outliers], y[~outliers], color='seagreen', label='good')\n\n    # Labels\n    xlabel = 'x' if xlabel is None else xlabel\n    ylabel = 'y' if ylabel is None else ylabel\n    ax1.set_xlabel(xlabel)\n    ax1.set_ylabel(ylabel)\n    ax1.set_title('Outliers (n={})'.format(sum(outliers)), y=1.05)\n\n    # Spearman distribution\n    sns.distplot(spearman_dist, kde=True, ax=ax2, color='darkcyan')\n    for i in spearman_ci:\n        ax2.axvline(x=i, color='coral', lw=2)\n    ax2.axvline(x=0, color='k', ls='--', lw=1.5)\n    ax2.set_ylabel('Density of bootstrap samples')\n    ax2.set_xlabel('Correlation coefficient')\n    ax2.set_title(\n        'Skipped Spearman r = {}\\n95% CI = [{}, {}]'.format(r.round(2),\n                                                            spearman_ci[0],\n                                                            spearman_ci[1]),\n        y=1.05)\n\n    # Pearson dististribution\n    sns.distplot(pearson_dist, kde=True, ax=ax3, color='steelblue')\n    for i in pearson_ci:\n        ax3.axvline(x=i, color='coral', lw=2)\n    ax3.axvline(x=0, color='k', ls='--', lw=1.5)\n    ax3.set_xlabel('Correlation coefficient')\n    ax3.set_title(\n        'Skipped Pearson r = {}\\n95% CI = [{}, {}]'.format(r_pearson.round(2),\n                                                           pearson_ci[0],\n                                                           pearson_ci[1]),\n        y=1.05)\n\n    # Optimize layout\n    plt.tight_layout()\n\n    return fig"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ppoints(n, a=0.5):\n    a = 3 / 8 if n <= 10 else 0.5\n    return (np.arange(n) + 1 - a) / (n + 1 - 2 * a)", "response": "Returns the probability distribution at which the inverse of the log - likelihood of the given number of points generated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef qqplot(x, dist='norm', sparams=(), confidence=.95, figsize=(5, 4),\n           ax=None):\n    \"\"\"Quantile-Quantile plot.\n\n    Parameters\n    ----------\n    x : array_like\n        Sample data.\n    dist : str or stats.distributions instance, optional\n        Distribution or distribution function name. The default is 'norm' for a\n        normal probability plot. Objects that look enough like a\n        `scipy.stats.distributions` instance (i.e. they have a ``ppf`` method)\n        are also accepted.\n    sparams : tuple, optional\n        Distribution-specific shape parameters (shape parameters, location,\n        and scale). See :py:func:`scipy.stats.probplot` for more details.\n    confidence : float\n        Confidence level (.95 = 95%) for point-wise confidence envelope.\n        Pass False for no envelope.\n    figsize : tuple\n        Figsize in inches\n    ax : matplotlib axes\n        Axis on which to draw the plot\n\n    Returns\n    -------\n    ax : Matplotlib Axes instance\n        Returns the Axes object with the plot for further tweaking.\n\n    Notes\n    -----\n    This function returns a scatter plot of the quantile of the sample data `x`\n    against the theoretical quantiles of the distribution given in `dist`\n    (default = 'norm').\n\n    The points plotted in a Q\u2013Q plot are always non-decreasing when viewed\n    from left to right. If the two distributions being compared are identical,\n    the Q\u2013Q plot follows the 45\u00b0 line y = x. If the two distributions agree\n    after linearly transforming the values in one of the distributions,\n    then the Q\u2013Q plot follows some line, but not necessarily the line y = x.\n    If the general trend of the Q\u2013Q plot is flatter than the line y = x,\n    the distribution plotted on the horizontal axis is more dispersed than\n    the distribution plotted on the vertical axis. Conversely, if the general\n    trend of the Q\u2013Q plot is steeper than the line y = x, the distribution\n    plotted on the vertical axis is more dispersed than the distribution\n    plotted on the horizontal axis. Q\u2013Q plots are often arced, or \"S\" shaped,\n    indicating that one of the distributions is more skewed than the other,\n    or that one of the distributions has heavier tails than the other.\n\n    In addition, the function also plots a best-fit line (linear regression)\n    for the data and annotates the plot with the coefficient of\n    determination :math:`R^2`. Note that the intercept and slope of the\n    linear regression between the quantiles gives a measure of the relative\n    location and relative scale of the samples.\n\n    References\n    ----------\n    .. [1] https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot\n\n    .. [2] https://github.com/cran/car/blob/master/R/qqPlot.R\n\n    .. [3] Fox, J. (2008), Applied Regression Analysis and Generalized Linear\n           Models, 2nd Ed., Sage Publications, Inc.\n\n    Examples\n    --------\n\n    Q-Q plot using a normal theoretical distribution:\n\n    .. plot::\n\n        >>> import numpy as np\n        >>> import pingouin as pg\n        >>> np.random.seed(123)\n        >>> x = np.random.normal(size=50)\n        >>> ax = pg.qqplot(x, dist='norm')\n\n    Two Q-Q plots using two separate axes:\n\n    .. plot::\n\n        >>> import numpy as np\n        >>> import pingouin as pg\n        >>> import matplotlib.pyplot as plt\n        >>> np.random.seed(123)\n        >>> x = np.random.normal(size=50)\n        >>> x_exp = np.random.exponential(size=50)\n        >>> fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4))\n        >>> ax1 = pg.qqplot(x, dist='norm', ax=ax1, confidence=False)\n        >>> ax2 = pg.qqplot(x_exp, dist='expon', ax=ax2)\n\n    Using custom location / scale parameters as well as another Seaborn style\n\n    .. plot::\n\n        >>> import numpy as np\n        >>> import seaborn as sns\n        >>> import pingouin as pg\n        >>> import matplotlib.pyplot as plt\n        >>> np.random.seed(123)\n        >>> x = np.random.normal(size=50)\n        >>> mean, std = 0, 0.8\n        >>> sns.set_style('darkgrid')\n        >>> ax = pg.qqplot(x, dist='norm', sparams=(mean, std))\n    \"\"\"\n    if isinstance(dist, str):\n        dist = getattr(stats, dist)\n\n    x = np.asarray(x)\n    x = x[~np.isnan(x)]  # NaN are automatically removed\n\n    # Extract quantiles and regression\n    quantiles = stats.probplot(x, sparams=sparams, dist=dist, fit=False)\n    theor, observed = quantiles[0], quantiles[1]\n\n    fit_params = dist.fit(x)\n    loc = fit_params[-2]\n    scale = fit_params[-1]\n    shape = fit_params[0] if len(fit_params) == 3 else None\n\n    # Observed values to observed quantiles\n    if loc != 0 and scale != 1:\n        observed = (np.sort(observed) - fit_params[-2]) / fit_params[-1]\n\n    # Linear regression\n    slope, intercept, r, _, _ = stats.linregress(theor, observed)\n\n    # Start the plot\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.plot(theor, observed, 'bo')\n\n    stats.morestats._add_axis_labels_title(ax,\n                                           xlabel='Theoretical quantiles',\n                                           ylabel='Ordered quantiles',\n                                           title='Q-Q Plot')\n\n    # Add diagonal line\n    end_pts = [ax.get_xlim(), ax.get_ylim()]\n    end_pts[0] = min(end_pts[0])\n    end_pts[1] = max(end_pts[1])\n    ax.plot(end_pts, end_pts, color='slategrey', lw=1.5)\n    ax.set_xlim(end_pts)\n    ax.set_ylim(end_pts)\n\n    # Add regression line and annotate R2\n    fit_val = slope * theor + intercept\n    ax.plot(theor, fit_val, 'r-', lw=2)\n    posx = end_pts[0] + 0.60 * (end_pts[1] - end_pts[0])\n    posy = end_pts[0] + 0.10 * (end_pts[1] - end_pts[0])\n    ax.text(posx, posy, \"$R^2=%.3f$\" % r**2)\n\n    if confidence is not False:\n        # Confidence envelope\n        n = x.size\n        P = _ppoints(n)\n        crit = stats.norm.ppf(1 - (1 - confidence) / 2)\n        pdf = dist.pdf(theor) if shape is None else dist.pdf(theor, shape)\n        se = (slope / pdf) * np.sqrt(P * (1 - P) / n)\n        upper = fit_val + crit * se\n        lower = fit_val - crit * se\n        ax.plot(theor, upper, 'r--', lw=1.25)\n        ax.plot(theor, lower, 'r--', lw=1.25)\n\n    return ax", "response": "Returns a scatter plot of the quantile of the sample data x against theoretical quantiles of the distribution given in dist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting a paired plot of the specified data.", "response": "def plot_paired(data=None, dv=None, within=None, subject=None, order=None,\n                boxplot=True, figsize=(4, 4), dpi=100, ax=None,\n                colors=['green', 'grey', 'indianred'],\n                pointplot_kwargs={'scale': .6, 'markers': '.'},\n                boxplot_kwargs={'color': 'lightslategrey', 'width': .2}):\n    \"\"\"\n    Paired plot.\n\n    Parameters\n    ----------\n    data : pandas DataFrame\n        Long-format dataFrame.\n    dv : string\n        Name of column containing the dependant variable.\n    within : string\n        Name of column containing the within-subject factor. Note that\n        ``within`` must have exactly two within-subject levels\n        (= two unique values).\n    subject : string\n        Name of column containing the subject identifier.\n    order : list of str\n        List of values in ``within`` that define the order of elements on the\n        x-axis of the plot. If None, uses alphabetical order.\n    boxplot : boolean\n        If True, add a boxplot to the paired lines using the\n        :py:func:`seaborn.boxplot` function.\n    figsize : tuple\n        Figsize in inches\n    dpi : int\n        Resolution of the figure in dots per inches.\n    ax : matplotlib axes\n        Axis on which to draw the plot.\n    colors : list of str\n        Line colors names. Default is green when value increases from A to B,\n        indianred when value decreases from A to B and grey when the value is\n        the same in both measurements.\n    pointplot_kwargs : dict\n        Dictionnary of optional arguments that are passed to the\n        :py:func:`seaborn.pointplot` function.\n    boxplot_kwargs : dict\n        Dictionnary of optional arguments that are passed to the\n        :py:func:`seaborn.boxplot` function.\n\n    Returns\n    -------\n    ax : Matplotlib Axes instance\n        Returns the Axes object with the plot for further tweaking.\n\n    Notes\n    -----\n    Data must be a long-format pandas DataFrame.\n\n    Examples\n    --------\n\n    Default paired plot:\n\n    .. plot::\n\n        >>> from pingouin import read_dataset\n        >>> df = read_dataset('mixed_anova')\n        >>> df = df.query(\"Group == 'Meditation' and Subject > 40\")\n        >>> df = df.query(\"Time == 'August' or Time == 'June'\")\n        >>> import pingouin as pg\n        >>> ax = pg.plot_paired(data=df, dv='Scores', within='Time',\n        ...                     subject='Subject', dpi=150)\n\n    Paired plot on an existing axis (no boxplot and uniform color):\n\n    .. plot::\n\n        >>> from pingouin import read_dataset\n        >>> df = read_dataset('mixed_anova').query(\"Time != 'January'\")\n        >>> import pingouin as pg\n        >>> import matplotlib.pyplot as plt\n        >>> fig, ax1 = plt.subplots(1, 1, figsize=(5, 4))\n        >>> pg.plot_paired(data=df[df['Group'] == 'Meditation'],\n        ...                dv='Scores', within='Time', subject='Subject',\n        ...                ax=ax1, boxplot=False,\n        ...                colors=['grey', 'grey', 'grey'])  # doctest: +SKIP\n    \"\"\"\n    from pingouin.utils import _check_dataframe, remove_rm_na\n\n    # Validate args\n    _check_dataframe(data=data, dv=dv, within=within, subject=subject,\n                     effects='within')\n\n    # Remove NaN values\n    data = remove_rm_na(dv=dv, within=within, subject=subject, data=data)\n\n    # Extract subjects\n    subj = data[subject].unique()\n\n    # Extract within-subject level (alphabetical order)\n    x_cat = np.unique(data[within])\n    assert len(x_cat) == 2, 'Within must have exactly two unique levels.'\n\n    if order is None:\n        order = x_cat\n    else:\n        assert len(order) == 2, 'Order must have exactly two elements.'\n\n    # Start the plot\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize, dpi=dpi)\n\n    for idx, s in enumerate(subj):\n        tmp = data.loc[data[subject] == s, [dv, within, subject]]\n        x_val = tmp[tmp[within] == order[0]][dv].values[0]\n        y_val = tmp[tmp[within] == order[1]][dv].values[0]\n        if x_val < y_val:\n            color = colors[0]\n        elif x_val > y_val:\n            color = colors[2]\n        elif x_val == y_val:\n            color = colors[1]\n\n        # Plot individual lines using Seaborn\n        sns.pointplot(data=tmp, x=within, y=dv, order=order, color=color,\n                      ax=ax, **pointplot_kwargs)\n\n    if boxplot:\n        sns.boxplot(data=data, x=within, y=dv, order=order, ax=ax,\n                    **boxplot_kwargs)\n\n    # Despine and trim\n    sns.despine(trim=True, ax=ax)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshift plot. The shift plot is described in Rousselet, Pernet and Wilcox (2017). Parameters ---------- x, y : array_like First and second set of observations. x and y must be independent. n_boot : int Number of bootstrap iterations. The higher, the better, the slower. percentiles: array_like Sequence of percentiles to compute, which must be between 0 and 100 inclusive. Default set to [10, 20, 30, 40, 50, 60, 70, 80, 90]. ci: float Confidence level (0.95 = 95%). seed : int or None Random seed for generating bootstrap samples, can be integer or None (default). show_median: boolean If True, show the median with black lines. Defaut set to True. violin: boolean If True, plot the density of X and Y distributions. Defaut set to True. Returns ------- fig : matplotlib Figure instance Matplotlib Figure. To get the individual axes, use fig.axes. Notes ----- This function will estimate the bootstrap CI for the percentile difference between X (fixed) and Y (resampled). If N is small, the CI of X -> Y and Y -> X can vary. References ---------- .. [1] Rousselet, G. A., Pernet, C. R. and Wilcox, R. R. (2017). Beyond differences in means: robust graphical methods to compare two groups in neuroscience. Eur J Neurosci, 46: 1738-1748. doi:10.1111/ejn.13610 Examples -------- Default shift plot .. plot:: >>> import numpy as np >>> import pingouin as pg >>> np.random.seed(42) >>> x = np.random.normal(5.5, 2, 50) >>> y = np.random.normal(6, 1.5, 50) >>> fig = pg.plot_shift(x, y) With different options .. plot:: >>> import numpy as np >>> import pingouin as pg >>> np.random.seed(42) >>> x = np.random.normal(5.5, 2, 50) >>> y = np.random.normal(6, 1.5, 50) >>> fig = pg.plot_shift(x, y, n_boot=2000, percentiles=[5, 55, 95], ... show_median=False, seed=456, violin=False)", "response": "def plot_shift(x, y, n_boot=1000, percentiles=np.arange(10, 100, 10),\n               ci=0.95, seed=None, show_median=True, violin=True):\n    \"\"\"Shift plot.\n\n    The shift plot is described in Rousselet, Pernet and Wilcox (2017).\n\n    Parameters\n    ----------\n    x, y : array_like\n        First and second set of observations. x and y must be independent.\n    n_boot : int\n        Number of bootstrap iterations. The higher, the better, the slower.\n    percentiles: array_like\n        Sequence of percentiles to compute, which must be between 0 and 100\n        inclusive. Default set to [10, 20, 30, 40, 50, 60, 70, 80, 90].\n    ci: float\n        Confidence level (0.95 = 95%).\n    seed : int or None\n        Random seed for generating bootstrap samples, can be integer or\n        None (default).\n    show_median: boolean\n        If True, show the median with black lines. Defaut set to True.\n    violin: boolean\n        If True, plot the density of X and Y distributions.\n        Defaut set to True.\n\n    Returns\n    -------\n    fig : matplotlib Figure instance\n        Matplotlib Figure. To get the individual axes, use fig.axes.\n\n    Notes\n    -----\n    This function will estimate the bootstrap CI for the percentile difference\n    between X (fixed) and Y (resampled). If N is small, the CI of X -> Y and\n    Y -> X can vary.\n\n    References\n    ----------\n    .. [1] Rousselet, G. A., Pernet, C. R. and Wilcox, R. R. (2017). Beyond\n           differences in means: robust graphical methods to compare two groups\n           in neuroscience. Eur J Neurosci, 46: 1738-1748.\n           doi:10.1111/ejn.13610\n\n    Examples\n    --------\n    Default shift plot\n\n    .. plot::\n\n        >>> import numpy as np\n        >>> import pingouin as pg\n        >>> np.random.seed(42)\n        >>> x = np.random.normal(5.5, 2, 50)\n        >>> y = np.random.normal(6, 1.5, 50)\n        >>> fig = pg.plot_shift(x, y)\n\n    With different options\n\n    .. plot::\n\n        >>> import numpy as np\n        >>> import pingouin as pg\n        >>> np.random.seed(42)\n        >>> x = np.random.normal(5.5, 2, 50)\n        >>> y = np.random.normal(6, 1.5, 50)\n        >>> fig = pg.plot_shift(x, y, n_boot=2000, percentiles=[5, 55, 95],\n        ...                     show_median=False, seed=456, violin=False)\n    \"\"\"\n    # Safety check\n    x = np.asarray(x)\n    y = np.asarray(y)\n    percentiles = np.asarray(percentiles)\n    assert x.ndim == 1, 'x must be 1D.'\n    assert y.ndim == 1, 'y must be 1D.'\n    nx, ny = x.size, y.size\n    assert nx >= 10, 'x must have at least 10 samples.'\n    assert ny >= 10, 'y must have at least 10 samples.'\n    assert 0 < ci < 1, 'ci must be between 0 and 1.'\n\n    x_per = np.percentile(x, percentiles)\n    y_per = np.percentile(y, percentiles)\n\n    # Compute bootstrap CI\n    rng = np.random.RandomState(seed)\n    bootsam = rng.choice(y, size=(n_boot, ny), replace=True)\n    bootstat = np.swapaxes(np.percentile(bootsam, percentiles, axis=1), 1, 0)\n    bootstat -= x_per\n\n    # Find upper and lower confidence interval for each quantiles\n    ci *= 100\n    upper = np.percentile(bootstat, ci + (100 - ci) / 2, axis=0)\n    lower = np.percentile(bootstat, (100 - ci) / 2, axis=0)\n    median_per = np.median(bootstat, axis=0)\n\n    # Create long-format dataFrame for use with Seaborn\n    data = pd.DataFrame({'value': np.concatenate([x, y]),\n                         'variable': ['X'] * nx + ['Y'] * ny})\n\n    #############################\n    # Plots X and Y distributions\n    #############################\n    fig = plt.figure(figsize=(8, 5))\n    ax1 = plt.subplot2grid((3, 3), (0, 0), rowspan=2, colspan=3)\n\n    # Boxplot X & Y\n    def adjacent_values(vals, q1, q3):\n        upper_adjacent_value = q3 + (q3 - q1) * 1.5\n        upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n\n        lower_adjacent_value = q1 - (q3 - q1) * 1.5\n        lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n        return lower_adjacent_value, upper_adjacent_value\n\n    for dis, pos in zip([x, y], [1.2, -0.2]):\n        qrt1, medians, qrt3 = np.percentile(dis, [25, 50, 75])\n        whiskers = adjacent_values(np.sort(dis), qrt1, qrt3)\n        ax1.plot(medians, pos, marker='o', color='white', zorder=10)\n        ax1.hlines(pos, qrt1, qrt3, color='k',\n                   linestyle='-', lw=7, zorder=9)\n        ax1.hlines(pos, whiskers[0], whiskers[1],\n                   color='k', linestyle='-', lw=2, zorder=9)\n\n    ax1 = sns.stripplot(data=data, x='value', y='variable',\n                        orient='h', order=['Y', 'X'],\n                        palette=['#88bedc', '#cfcfcf'])\n\n    if violin:\n\n        vl = plt.violinplot([y, x], showextrema=False, vert=False, widths=1)\n\n        # Upper plot\n        paths = vl['bodies'][0].get_paths()[0]\n        paths.vertices[:, 1][paths.vertices[:, 1] >= 1] = 1\n        paths.vertices[:, 1] = paths.vertices[:, 1] - 1.2\n        vl['bodies'][0].set_edgecolor('k')\n        vl['bodies'][0].set_facecolor('#88bedc')\n        vl['bodies'][0].set_alpha(0.8)\n\n        # Lower plot\n        paths = vl['bodies'][1].get_paths()[0]\n        paths.vertices[:, 1][paths.vertices[:, 1] <= 2] = 2\n        paths.vertices[:, 1] = paths.vertices[:, 1] - 0.8\n        vl['bodies'][1].set_edgecolor('k')\n        vl['bodies'][1].set_facecolor('#cfcfcf')\n        vl['bodies'][1].set_alpha(0.8)\n\n        # Rescale ylim\n        ax1.set_ylim(2, -1)\n\n    for i in range(len(percentiles)):\n        # Connection between quantiles\n        if upper[i] < 0:\n            col = '#4c72b0'\n        elif lower[i] > 0:\n            col = '#c34e52'\n        else:\n            col = 'darkgray'\n        plt.plot([y_per[i], x_per[i]], [0.2, 0.8],\n                 marker='o', color=col, zorder=10)\n        # X quantiles\n        plt.plot([x_per[i], x_per[i]], [0.8, 1.2], 'k--', zorder=9)\n        # Y quantiles\n        plt.plot([y_per[i], y_per[i]], [-0.2, 0.2], 'k--', zorder=9)\n\n    if show_median:\n        # X median\n        plt.plot([x_per[4], x_per[4]], [0.8, 1.2], 'k-')\n        # Y median\n        plt.plot([y_per[4], y_per[4]], [-0.2, 0.2], 'k-')\n\n    plt.xlabel('Scores (a.u.)', size=20)\n    ax1.set_yticklabels(['Y', 'X'], size=20)\n    ax1.set_ylabel('')\n\n    #######################\n    # Plots quantiles shift\n    #######################\n    ax2 = plt.subplot2grid((3, 3), (2, 0), rowspan=1, colspan=3)\n    for i, per in enumerate(x_per):\n        if upper[i] < 0:\n            col = '#4c72b0'\n        elif lower[i] > 0:\n            col = '#c34e52'\n        else:\n            col = 'darkgray'\n        plt.plot([per, per], [upper[i], lower[i]], lw=3, color=col, zorder=10)\n        plt.plot(per, median_per[i], marker='o', ms=10, color=col, zorder=10)\n\n    plt.axhline(y=0, ls='--', lw=2, color='gray')\n\n    ax2.set_xlabel('X quantiles', size=20)\n    ax2.set_ylabel('Y - X quantiles \\n differences (a.u.)', size=10)\n    sns.despine()\n    plt.tight_layout()\n\n    return fig"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rm_anova(data=None, dv=None, within=None, subject=None, correction='auto',\n             detailed=False, export_filename=None):\n    \"\"\"One-way and two-way repeated measures ANOVA.\n\n    Parameters\n    ----------\n    data : pandas DataFrame\n        DataFrame. Note that this function can also directly be used as a\n        :py:class:`pandas.DataFrame` method, in which case this argument is no\n        longer needed.\n        Both wide and long-format dataframe are supported for one-way repeated\n        measures ANOVA. However, ``data`` must be in long format for two-way\n        repeated measures.\n    dv : string\n        Name of column containing the dependant variable (only required if\n        ``data`` is in long format).\n    within : string\n        Name of column containing the within factor (only required if ``data``\n        is in long format).\n        If ``within`` is a single string, then compute a one-way repeated\n        measures ANOVA, if ``within`` is a list with two strings,\n        compute a two-way repeated measures ANOVA.\n    subject : string\n        Name of column containing the subject identifier (only required if\n        ``data`` is in long format).\n    correction : string or boolean\n        If True, also return the Greenhouse-Geisser corrected p-value.\n        If 'auto' (default), compute Mauchly's test of sphericity to determine\n        whether the p-values needs to be corrected\n        (see :py:func:`pingouin.sphericity`).\n    detailed : boolean\n        If True, return a full ANOVA table.\n    export_filename : string\n        Filename (without extension) for the output file.\n        If None, do not export the table.\n        By default, the file will be created in the current python console\n        directory. To change that, specify the filename with full path.\n\n    Returns\n    -------\n    aov : DataFrame\n        ANOVA summary ::\n\n        'Source' : Name of the within-group factor\n        'ddof1' : Degrees of freedom (numerator)\n        'ddof2' : Degrees of freedom (denominator)\n        'F' : F-value\n        'p-unc' : Uncorrected p-value\n        'np2' : Partial eta-square effect size\n        'eps' : Greenhouse-Geisser epsilon factor (= index of sphericity)\n        'p-GG-corr' : Greenhouse-Geisser corrected p-value\n        'W-spher' : Sphericity test statistic\n        'p-spher' : p-value of the sphericity test\n        'sphericity' : sphericity of the data (boolean)\n\n    See Also\n    --------\n    anova : One-way and two-way ANOVA\n    mixed_anova : Two way mixed ANOVA\n    friedman : Non-parametric one-way repeated measures ANOVA\n\n    Notes\n    -----\n    Data can be in wide or long format for one-way repeated measures ANOVA but\n    *must* be in long format for two-way repeated measures ANOVA.\n\n    In one-way repeated-measures ANOVA, the total variance (sums of squares)\n    is divided into three components\n\n    .. math:: SS_{total} = SS_{treatment} + (SS_{subjects} + SS_{error})\n\n    with\n\n    .. math:: SS_{total} = \\\\sum_i^r \\\\sum_j^n (Y_{ij} - \\\\overline{Y})^2\n    .. math:: SS_{treatment} = \\\\sum_i^r n_i(\\\\overline{Y_i} - \\\\overline{Y})^2\n    .. math:: SS_{subjects} = r\\\\sum (\\\\overline{Y}_s - \\\\overline{Y})^2\n    .. math:: SS_{error} = SS_{total} - SS_{treatment} - SS_{subjects}\n\n    where :math:`i=1,...,r; j=1,...,n_i`, :math:`r` is the number of\n    conditions, :math:`n_i` the number of observations for each condition,\n    :math:`\\\\overline{Y}` the grand mean of the data, :math:`\\\\overline{Y_i}`\n    the mean of the :math:`i^{th}` condition and :math:`\\\\overline{Y}_{subj}`\n    the mean of the :math:`s^{th}` subject.\n\n    The F-statistics is then defined as:\n\n    .. math::\n\n        F^* = \\\\frac{MS_{treatment}}{MS_{error}} =\n        \\\\frac{\\\\frac{SS_{treatment}}\n        {r-1}}{\\\\frac{SS_{error}}{(n - 1)(r - 1)}}\n\n    and the p-value can be calculated using a F-distribution with\n    :math:`v_{treatment} = r - 1` and\n    :math:`v_{error} = (n - 1)(r - 1)` degrees of freedom.\n\n    The effect size reported in Pingouin is the partial eta-square, which is\n    equivalent to eta-square for one-way repeated measures ANOVA.\n\n    .. math:: \\\\eta_p^2 = \\\\frac{SS_{treatment}}{SS_{treatment} + SS_{error}}\n\n    Results have been tested against R and JASP. Note however that if the\n    dataset contains one or more other within subject factors, an automatic\n    collapsing to the mean is applied on the dependant variable (same behavior\n    as the ezANOVA R package). As such, results can differ from those of JASP.\n\n    Similarly, in two-way repeated measures ANOVA, Pingouin uses the lower\n    bound epsilon factor for the interaction, which is more conservative than\n    the Greenhouse-Geisser epsilon factor used in R or JASP. Therefore, the\n    corrected p-values of the interaction term will be slightly higher in\n    Pingouin. If you can, always double-check your results.\n\n    Missing values are automatically removed (listwise deletion) using the\n    :py:func:`pingouin.remove_rm_na` function. This could drastically decrease\n    the power of the ANOVA if many missing values are present. In that case,\n    it might be better to use linear mixed effects models.\n\n    References\n    ----------\n    .. [1] Bakeman, R. (2005). Recommended effect size statistics for\n           repeated measures designs. Behavior research methods, 37(3),\n           379-384.\n\n    .. [2] Richardson, J. T. (2011). Eta squared and partial eta squared as\n           measures of effect size in educational research. Educational\n           Research Review, 6(2), 135-147.\n\n    .. [3] https://en.wikipedia.org/wiki/Repeated_measures_design\n\n    Examples\n    --------\n    One-way repeated measures ANOVA using a wide-format dataset\n\n    >>> import pingouin as pg\n    >>> data = pg.read_dataset('rm_anova_wide')\n    >>> pg.rm_anova(data)\n       Source  ddof1  ddof2      F     p-unc    np2    eps\n    0  Within      3     24  5.201  0.006557  0.394  0.694\n\n    One-way repeated-measures ANOVA using a long-format dataset\n\n    >>> df = pg.read_dataset('rm_anova')\n    >>> aov = pg.rm_anova(dv='DesireToKill', within='Disgustingness',\n    ...                   subject='Subject', data=df, detailed=True)\n    >>> print(aov)\n               Source       SS  DF      MS       F        p-unc    np2 eps\n    0  Disgustingness   27.485   1  27.485  12.044  0.000793016  0.116   1\n    1           Error  209.952  92   2.282       -            -      -   -\n\n    Two-way repeated-measures ANOVA\n\n    >>> aov = pg.rm_anova(dv='DesireToKill',\n    ...                   within=['Disgustingness', 'Frighteningness'],\n    ...                   subject='Subject', data=df)\n\n    As a :py:class:`pandas.DataFrame` method\n\n    >>> df.rm_anova(dv='DesireToKill', within='Disgustingness',\n    ...             subject='Subject',  detailed=True)\n               Source       SS  DF      MS       F        p-unc    np2 eps\n    0  Disgustingness   27.485   1  27.485  12.044  0.000793016  0.116   1\n    1           Error  209.952  92   2.282       -            -      -   -\n    \"\"\"\n    if isinstance(within, list):\n        if len(within) == 2:\n            return rm_anova2(dv=dv, within=within, data=data, subject=subject,\n                             export_filename=export_filename)\n        elif len(within) == 1:\n            within = within[0]\n\n    # Check data format\n    if all([v is None for v in [dv, within, subject]]):\n        # Convert from wide to long format\n        assert isinstance(data, pd.DataFrame)\n        data = data._get_numeric_data().dropna()\n        assert data.shape[0] > 2, 'Data must have at least 3 rows.'\n        assert data.shape[1] > 1, 'Data must contain at least two columns.'\n        data['Subj'] = np.arange(data.shape[0])\n        data = data.melt(id_vars='Subj', var_name='Within', value_name='DV')\n        subject, within, dv = 'Subj', 'Within', 'DV'\n\n    # Check dataframe\n    _check_dataframe(dv=dv, within=within, data=data, subject=subject,\n                     effects='within')\n\n    # Collapse to the mean\n    data = data.groupby([subject, within]).mean().reset_index()\n\n    # Remove NaN\n    if data[dv].isnull().any():\n        data = remove_rm_na(dv=dv, within=within, subject=subject,\n                            data=data[[subject, within, dv]])\n    assert not data[within].isnull().any(), 'Cannot have NaN in `within`.'\n    assert not data[subject].isnull().any(), 'Cannot have NaN in `subject`.'\n\n    # Groupby\n    grp_with = data.groupby(within)[dv]\n    rm = list(data[within].unique())\n    n_rm = len(rm)\n    n_obs = int(data.groupby(within)[dv].count().max())\n    grandmean = data[dv].mean()\n\n    # Calculate sums of squares\n    sstime = ((grp_with.mean() - grandmean)**2 * grp_with.count()).sum()\n    sswithin = grp_with.apply(lambda x: (x - x.mean())**2).sum()\n    grp_subj = data.groupby(subject)[dv]\n    sssubj = n_rm * np.sum((grp_subj.mean() - grandmean)**2)\n    sserror = sswithin - sssubj\n\n    # Calculate degrees of freedom\n    ddof1 = n_rm - 1\n    ddof2 = ddof1 * (n_obs - 1)\n\n    # Calculate F and p-values\n    mserror = sserror / (ddof2 / ddof1)\n    fval = sstime / mserror\n    p_unc = f(ddof1, ddof2).sf(fval)\n\n    # Calculating partial eta-square\n    # Similar to (fval * ddof1) / (fval * ddof1 + ddof2)\n    np2 = sstime / (sstime + sserror)\n\n    # Reshape and remove NAN for sphericity estimation and correction\n    data_pivot = data.pivot(index=subject, columns=within, values=dv).dropna()\n\n    # Compute sphericity using Mauchly test\n    # Sphericity assumption only applies if there are more than 2 levels\n    if correction == 'auto' or (correction is True and n_rm >= 3):\n        spher, W_spher, chi_sq_spher, ddof_spher, \\\n            p_spher = sphericity(data_pivot, alpha=.05)\n        if correction == 'auto':\n            correction = True if not spher else False\n    else:\n        correction = False\n\n    # Compute epsilon adjustement factor\n    eps = epsilon(data_pivot, correction='gg')\n\n    # If required, apply Greenhouse-Geisser correction for sphericity\n    if correction:\n        corr_ddof1, corr_ddof2 = [np.maximum(d * eps, 1.) for d in\n                                  (ddof1, ddof2)]\n        p_corr = f(corr_ddof1, corr_ddof2).sf(fval)\n\n    # Create output dataframe\n    if not detailed:\n        aov = pd.DataFrame({'Source': within,\n                            'ddof1': ddof1,\n                            'ddof2': ddof2,\n                            'F': fval,\n                            'p-unc': p_unc,\n                            'np2': np2,\n                            'eps': eps,\n                            }, index=[0])\n        if correction:\n            aov['p-GG-corr'] = p_corr\n            aov['W-spher'] = W_spher\n            aov['p-spher'] = p_spher\n            aov['sphericity'] = spher\n\n        col_order = ['Source', 'ddof1', 'ddof2', 'F', 'p-unc',\n                     'p-GG-corr', 'np2', 'eps', 'sphericity', 'W-spher',\n                     'p-spher']\n    else:\n        aov = pd.DataFrame({'Source': [within, 'Error'],\n                            'SS': np.round([sstime, sserror], 3),\n                            'DF': [ddof1, ddof2],\n                            'MS': np.round([sstime / ddof1, sserror / ddof2],\n                                           3),\n                            'F': [fval, np.nan],\n                            'p-unc': [p_unc, np.nan],\n                            'np2': [np2, np.nan],\n                            'eps': [eps, np.nan]\n                            })\n        if correction:\n            aov['p-GG-corr'] = [p_corr, np.nan]\n            aov['W-spher'] = [W_spher, np.nan]\n            aov['p-spher'] = [p_spher, np.nan]\n            aov['sphericity'] = [spher, np.nan]\n\n        col_order = ['Source', 'SS', 'DF', 'MS', 'F', 'p-unc', 'p-GG-corr',\n                     'np2', 'eps', 'sphericity', 'W-spher', 'p-spher']\n\n    # Round\n    aov[['F', 'eps', 'np2']] = aov[['F', 'eps', 'np2']].round(3)\n\n    # Replace NaN\n    aov = aov.fillna('-')\n\n    aov = aov.reindex(columns=col_order)\n    aov.dropna(how='all', axis=1, inplace=True)\n    # Export to .csv\n    if export_filename is not None:\n        _export_table(aov, export_filename)\n    return aov", "response": "This function creates an ANOVA table from a dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rm_anova2(dv=None, within=None, subject=None, data=None,\n              export_filename=None):\n    \"\"\"Two-way repeated measures ANOVA.\n\n    This is an internal function. The main call to this function should be done\n    by the :py:func:`pingouin.rm_anova` function.\n\n    Parameters\n    ----------\n    dv : string\n        Name of column containing the dependant variable.\n    within : list\n        Names of column containing the two within factor\n        (e.g. ['Time', 'Treatment'])\n    subject : string\n        Name of column containing the subject identifier.\n    data : pandas DataFrame\n        DataFrame\n    export_filename : string\n        Filename (without extension) for the output file.\n        If None, do not export the table.\n        By default, the file will be created in the current python console\n        directory. To change that, specify the filename with full path.\n\n    Returns\n    -------\n    aov : DataFrame\n        ANOVA summary ::\n\n        'Source' : Name of the within-group factors\n        'ddof1' : Degrees of freedom (numerator)\n        'ddof2' : Degrees of freedom (denominator)\n        'F' : F-value\n        'p-unc' : Uncorrected p-value\n        'np2' : Partial eta-square effect size\n        'eps' : Greenhouse-Geisser epsilon factor (= index of sphericity)\n        'p-GG-corr' : Greenhouse-Geisser corrected p-value\n    \"\"\"\n    a, b = within\n\n    # Validate the dataframe\n    _check_dataframe(dv=dv, within=within, data=data, subject=subject,\n                     effects='within')\n\n    # Remove NaN\n    if data[[subject, a, b, dv]].isnull().any().any():\n        data = remove_rm_na(dv=dv, subject=subject, within=[a, b],\n                            data=data[[subject, a, b, dv]])\n\n    # Collapse to the mean (that this is also done in remove_rm_na)\n    data = data.groupby([subject, a, b]).mean().reset_index()\n\n    assert not data[a].isnull().any(), 'Cannot have NaN in %s' % a\n    assert not data[b].isnull().any(), 'Cannot have NaN in %s' % b\n    assert not data[subject].isnull().any(), 'Cannot have NaN in %s' % subject\n\n    # Group sizes and grandmean\n    n_a = data[a].nunique()\n    n_b = data[b].nunique()\n    n_s = data[subject].nunique()\n    mu = data[dv].mean()\n\n    # Groupby means\n    grp_s = data.groupby(subject)[dv].mean()\n    grp_a = data.groupby([a])[dv].mean()\n    grp_b = data.groupby([b])[dv].mean()\n    grp_ab = data.groupby([a, b])[dv].mean()\n    grp_as = data.groupby([a, subject])[dv].mean()\n    grp_bs = data.groupby([b, subject])[dv].mean()\n\n    # Sums of squares\n    ss_tot = np.sum((data[dv] - mu)**2)\n    ss_s = (n_a * n_b) * np.sum((grp_s - mu)**2)\n    ss_a = (n_b * n_s) * np.sum((grp_a - mu)**2)\n    ss_b = (n_a * n_s) * np.sum((grp_b - mu)**2)\n    ss_ab_er = n_s * np.sum((grp_ab - mu)**2)\n    ss_ab = ss_ab_er - ss_a - ss_b\n    ss_as_er = n_b * np.sum((grp_as - mu)**2)\n    ss_as = ss_as_er - ss_s - ss_a\n    ss_bs_er = n_a * np.sum((grp_bs - mu)**2)\n    ss_bs = ss_bs_er - ss_s - ss_b\n    ss_abs = ss_tot - ss_a - ss_b - ss_s - ss_ab - ss_as - ss_bs\n\n    # DOF\n    df_a = n_a - 1\n    df_b = n_b - 1\n    df_s = n_s - 1\n    df_ab_er = n_a * n_b - 1\n    df_ab = df_ab_er - df_a - df_b\n    df_as_er = n_a * n_s - 1\n    df_as = df_as_er - df_s - df_a\n    df_bs_er = n_b * n_s - 1\n    df_bs = df_bs_er - df_s - df_b\n    df_tot = n_a * n_b * n_s - 1\n    df_abs = df_tot - df_a - df_b - df_s - df_ab - df_as - df_bs\n\n    # Mean squares\n    ms_a = ss_a / df_a\n    ms_b = ss_b / df_b\n    ms_ab = ss_ab / df_ab\n    ms_as = ss_as / df_as\n    ms_bs = ss_bs / df_bs\n    ms_abs = ss_abs / df_abs\n\n    # F-values\n    f_a = ms_a / ms_as\n    f_b = ms_b / ms_bs\n    f_ab = ms_ab / ms_abs\n\n    # P-values\n    p_a = f(df_a, df_as).sf(f_a)\n    p_b = f(df_b, df_bs).sf(f_b)\n    p_ab = f(df_ab, df_abs).sf(f_ab)\n\n    # Partial eta-square\n    eta_a = (f_a * df_a) / (f_a * df_a + df_as)\n    eta_b = (f_b * df_b) / (f_b * df_b + df_bs)\n    eta_ab = (f_ab * df_ab) / (f_ab * df_ab + df_abs)\n\n    # Epsilon\n    piv_a = data.pivot_table(index=subject, columns=a, values=dv)\n    piv_b = data.pivot_table(index=subject, columns=b, values=dv)\n    piv_ab = data.pivot_table(index=subject, columns=[a, b], values=dv)\n    eps_a = epsilon(piv_a, correction='gg')\n    eps_b = epsilon(piv_b, correction='gg')\n    # For the interaction term we use the lower bound epsilon factor\n    # (same behavior as described on real-statistics.com)\n    # TODO: understand how the Greenhouse-Geisser epsilon is computed for\n    # the interaction term.\n    eps_ab = epsilon(piv_ab, correction='lb')\n\n    # Greenhouse-Geisser correction\n    df_a_c, df_as_c = [np.maximum(d * eps_a, 1.) for d in (df_a, df_as)]\n    df_b_c, df_bs_c = [np.maximum(d * eps_b, 1.) for d in (df_b, df_bs)]\n    df_ab_c, df_abs_c = [np.maximum(d * eps_ab, 1.) for d in (df_ab, df_abs)]\n    p_a_corr = f(df_a_c, df_as_c).sf(f_a)\n    p_b_corr = f(df_b_c, df_bs_c).sf(f_b)\n    p_ab_corr = f(df_ab_c, df_abs_c).sf(f_ab)\n\n    # Create dataframe\n    aov = pd.DataFrame({'Source': [a, b, a + ' * ' + b],\n                        'SS': [ss_a, ss_b, ss_ab],\n                        'ddof1': [df_a, df_b, df_ab],\n                        'ddof2': [df_as, df_bs, df_abs],\n                        'MS': [ms_a, ms_b, ms_ab],\n                        'F': [f_a, f_b, f_ab],\n                        'p-unc': [p_a, p_b, p_ab],\n                        'p-GG-corr': [p_a_corr, p_b_corr, p_ab_corr],\n                        'np2': [eta_a, eta_b, eta_ab],\n                        'eps': [eps_a, eps_b, eps_ab],\n                        })\n\n    col_order = ['Source', 'SS', 'ddof1', 'ddof2', 'MS', 'F', 'p-unc',\n                 'p-GG-corr', 'np2', 'eps']\n\n    # Round\n    aov[['SS', 'MS', 'F', 'eps', 'np2']] = aov[['SS', 'MS', 'F', 'eps',\n                                                'np2']].round(3)\n\n    aov = aov.reindex(columns=col_order)\n    # Export to .csv\n    if export_filename is not None:\n        _export_table(aov, export_filename)\n    return aov", "response": "This function is an internal function that removes NaNs from the dataframe and returns the ANOVA summary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef anova(dv=None, between=None, data=None, detailed=False,\n          export_filename=None):\n    \"\"\"One-way and two-way ANOVA.\n\n    Parameters\n    ----------\n    dv : string\n        Name of column in ``data`` containing the dependent variable.\n    between : string or list with two elements\n        Name of column(s) in ``data`` containing the between-subject factor(s).\n        If ``between`` is a single string, a one-way ANOVA is computed.\n        If ``between`` is a list with two elements\n        (e.g. ['Factor1', 'Factor2']), a two-way ANOVA is computed.\n    data : pandas DataFrame\n        DataFrame. Note that this function can also directly be used as a\n        Pandas method, in which case this argument is no longer needed.\n    detailed : boolean\n        If True, return a detailed ANOVA table\n        (default True for two-way ANOVA).\n    export_filename : string\n        Filename (without extension) for the output file.\n        If None, do not export the table.\n        By default, the file will be created in the current python console\n        directory. To change that, specify the filename with full path.\n\n    Returns\n    -------\n    aov : DataFrame\n        ANOVA summary ::\n\n        'Source' : Factor names\n        'SS' : Sums of squares\n        'DF' : Degrees of freedom\n        'MS' : Mean squares\n        'F' : F-values\n        'p-unc' : uncorrected p-values\n        'np2' : Partial eta-square effect sizes\n\n    See Also\n    --------\n    rm_anova : One-way and two-way repeated measures ANOVA\n    mixed_anova : Two way mixed ANOVA\n    welch_anova : One-way Welch ANOVA\n    kruskal : Non-parametric one-way ANOVA\n\n    Notes\n    -----\n    The classic ANOVA is very powerful when the groups are normally distributed\n    and have equal variances. However, when the groups have unequal variances,\n    it is best to use the Welch ANOVA (`welch_anova`) that better controls for\n    type I error (Liu 2015). The homogeneity of variances can be measured with\n    the `homoscedasticity` function.\n\n    The main idea of ANOVA is to partition the variance (sums of squares)\n    into several components. For example, in one-way ANOVA:\n\n    .. math:: SS_{total} = SS_{treatment} + SS_{error}\n    .. math:: SS_{total} = \\\\sum_i \\\\sum_j (Y_{ij} - \\\\overline{Y})^2\n    .. math:: SS_{treatment} = \\\\sum_i n_i (\\\\overline{Y_i} - \\\\overline{Y})^2\n    .. math:: SS_{error} = \\\\sum_i \\\\sum_j (Y_{ij} - \\\\overline{Y}_i)^2\n\n    where :math:`i=1,...,r; j=1,...,n_i`, :math:`r` is the number of groups,\n    and :math:`n_i` the number of observations for the :math:`i` th group.\n\n    The F-statistics is then defined as:\n\n    .. math::\n\n        F^* = \\\\frac{MS_{treatment}}{MS_{error}} = \\\\frac{SS_{treatment}\n        / (r - 1)}{SS_{error} / (n_t - r)}\n\n    and the p-value can be calculated using a F-distribution with\n    :math:`r-1, n_t-1` degrees of freedom.\n\n    When the groups are balanced and have equal variances, the optimal post-hoc\n    test is the Tukey-HSD test (:py:func:`pingouin.pairwise_tukey`).\n    If the groups have unequal variances, the Games-Howell test is more\n    adequate (:py:func:`pingouin.pairwise_gameshowell`).\n\n    The effect size reported in Pingouin is the partial eta-square.\n    However, one should keep in mind that for one-way ANOVA\n    partial eta-square is the same as eta-square and generalized eta-square.\n    For more details, see Bakeman 2005; Richardson 2011.\n\n    .. math:: \\\\eta_p^2 = \\\\frac{SS_{treatment}}{SS_{treatment} + SS_{error}}\n\n    Note that missing values are automatically removed. Results have been\n    tested against R, Matlab and JASP.\n\n    **Important**\n\n    Versions of Pingouin below 0.2.5 gave wrong results for **unbalanced\n    two-way ANOVA**. This issue has been resolved in Pingouin>=0.2.5. In such\n    cases, a type II ANOVA is calculated via an internal call to the\n    statsmodels package. This latter package is therefore required for two-way\n    ANOVA with unequal sample sizes.\n\n    References\n    ----------\n    .. [1] Liu, Hangcheng. \"Comparing Welch's ANOVA, a Kruskal-Wallis test and\n           traditional ANOVA in case of Heterogeneity of Variance.\" (2015).\n\n    .. [2] Bakeman, Roger. \"Recommended effect size statistics for repeated\n           measures designs.\" Behavior research methods 37.3 (2005): 379-384.\n\n    .. [3] Richardson, John TE. \"Eta squared and partial eta squared as\n           measures of effect size in educational research.\" Educational\n           Research Review 6.2 (2011): 135-147.\n\n    Examples\n    --------\n    One-way ANOVA\n\n    >>> import pingouin as pg\n    >>> df = pg.read_dataset('anova')\n    >>> aov = pg.anova(dv='Pain threshold', between='Hair color', data=df,\n    ...             detailed=True)\n    >>> aov\n           Source        SS  DF       MS      F       p-unc    np2\n    0  Hair color  1360.726   3  453.575  6.791  0.00411423  0.576\n    1      Within  1001.800  15   66.787      -           -      -\n\n    Note that this function can also directly be used as a Pandas method\n\n    >>> df.anova(dv='Pain threshold', between='Hair color', detailed=True)\n           Source        SS  DF       MS      F       p-unc    np2\n    0  Hair color  1360.726   3  453.575  6.791  0.00411423  0.576\n    1      Within  1001.800  15   66.787      -           -      -\n\n    Two-way ANOVA with balanced design\n\n    >>> data = pg.read_dataset('anova2')\n    >>> data.anova(dv=\"Yield\", between=[\"Blend\", \"Crop\"]).round(3)\n             Source        SS  DF        MS      F  p-unc    np2\n    0         Blend     2.042   1     2.042  0.004  0.952  0.000\n    1          Crop  2736.583   2  1368.292  2.525  0.108  0.219\n    2  Blend * Crop  2360.083   2  1180.042  2.178  0.142  0.195\n    3      residual  9753.250  18   541.847    NaN    NaN    NaN\n\n    Two-way ANOVA with unbalanced design (requires statsmodels)\n\n    >>> data = pg.read_dataset('anova2_unbalanced')\n    >>> data.anova(dv=\"Scores\", between=[\"Diet\", \"Exercise\"]).round(3)\n                Source       SS   DF       MS      F  p-unc    np2\n    0             Diet  390.625  1.0  390.625  7.423  0.034  0.553\n    1         Exercise  180.625  1.0  180.625  3.432  0.113  0.364\n    2  Diet * Exercise   15.625  1.0   15.625  0.297  0.605  0.047\n    3         residual  315.750  6.0   52.625    NaN    NaN    NaN\n    \"\"\"\n    if isinstance(between, list):\n        if len(between) == 2:\n            return anova2(dv=dv, between=between, data=data,\n                          export_filename=export_filename)\n        elif len(between) == 1:\n            between = between[0]\n\n    # Check data\n    _check_dataframe(dv=dv, between=between, data=data, effects='between')\n\n    # Drop missing values\n    data = data[[dv, between]].dropna()\n\n    # Reset index (avoid duplicate axis error)\n    data = data.reset_index(drop=True)\n\n    groups = list(data[between].unique())\n    n_groups = len(groups)\n    N = data[dv].size\n\n    # Calculate sums of squares\n    grp = data.groupby(between)[dv]\n    # Between effect\n    ssbetween = ((grp.mean() - data[dv].mean())**2 * grp.count()).sum()\n    # Within effect (= error between)\n    #  = (grp.var(ddof=0) * grp.count()).sum()\n    sserror = grp.apply(lambda x: (x - x.mean())**2).sum()\n\n    # Calculate DOF, MS, F and p-values\n    ddof1 = n_groups - 1\n    ddof2 = N - n_groups\n    msbetween = ssbetween / ddof1\n    mserror = sserror / ddof2\n    fval = msbetween / mserror\n    p_unc = f(ddof1, ddof2).sf(fval)\n\n    # Calculating partial eta-square\n    # Similar to (fval * ddof1) / (fval * ddof1 + ddof2)\n    np2 = ssbetween / (ssbetween + sserror)\n\n    # Create output dataframe\n    if not detailed:\n        aov = pd.DataFrame({'Source': between,\n                            'ddof1': ddof1,\n                            'ddof2': ddof2,\n                            'F': fval,\n                            'p-unc': p_unc,\n                            'np2': np2\n                            }, index=[0])\n\n        col_order = ['Source', 'ddof1', 'ddof2', 'F', 'p-unc', 'np2']\n    else:\n        aov = pd.DataFrame({'Source': [between, 'Within'],\n                            'SS': np.round([ssbetween, sserror], 3),\n                            'DF': [ddof1, ddof2],\n                            'MS': np.round([msbetween, mserror], 3),\n                            'F': [fval, np.nan],\n                            'p-unc': [p_unc, np.nan],\n                            'np2': [np2, np.nan]\n                            })\n        col_order = ['Source', 'SS', 'DF', 'MS', 'F', 'p-unc', 'np2']\n\n    # Round\n    aov[['F', 'np2']] = aov[['F', 'np2']].round(3)\n\n    # Replace NaN\n    aov = aov.fillna('-')\n\n    aov = aov.reindex(columns=col_order)\n    aov.dropna(how='all', axis=1, inplace=True)\n    # Export to .csv\n    if export_filename is not None:\n        _export_table(aov, export_filename)\n    return aov", "response": "One - way ANOVA."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef anova2(dv=None, between=None, data=None, export_filename=None):\n    # Validate the dataframe\n    _check_dataframe(dv=dv, between=between, data=data, effects='between')\n\n    fac1, fac2 = between\n\n    # Drop missing values\n    data = data[[dv, fac1, fac2]].dropna()\n\n    # Reset index (avoid duplicate axis error)\n    data = data.reset_index(drop=True)\n\n    grp_both = data.groupby(between)[dv]\n    ng1, ng2 = data[fac1].nunique(), data[fac2].nunique()\n\n    if grp_both.count().nunique() == 1:\n        # BALANCED DESIGN\n        aov_fac1 = anova(data=data, dv=dv, between=fac1, detailed=True)\n        aov_fac2 = anova(data=data, dv=dv, between=fac2, detailed=True)\n        # Sums of squares\n        ss_fac1 = aov_fac1.loc[0, 'SS']\n        ss_fac2 = aov_fac2.loc[0, 'SS']\n        ss_tot = ((data[dv] - data[dv].mean())**2).sum()\n        ss_resid = np.sum(grp_both.apply(lambda x: (x - x.mean())**2))\n        ss_inter = ss_tot - (ss_resid + ss_fac1 + ss_fac2)\n        # Degrees of freedom\n        df_fac1 = aov_fac1.loc[0, 'DF']\n        df_fac2 = aov_fac2.loc[0, 'DF']\n        df_inter = (ng1 - 1) * (ng2 - 1)\n        df_resid = data[dv].size - (ng1 * ng2)\n    else:\n        # UNBALANCED DESIGN\n        import statsmodels.api as sm\n        from statsmodels.formula.api import ols\n        warnings.warn(\"Groups are unbalanced. Type II ANOVA will be computed \"\n                      \"using statsmodels\")\n        formula = \"%s ~ C(%s) * C(%s)\" % (dv, fac1, fac2)\n        lm = ols(formula, data=data).fit()\n        sts = sm.stats.anova_lm(lm, typ=2)\n        # Sums of squares\n        ss_fac1 = sts.iloc[0, 0]\n        ss_fac2 = sts.iloc[1, 0]\n        ss_inter = sts.iloc[2, 0]\n        ss_resid = sts.iloc[3, 0]\n        # Degrees of freedom\n        df_fac1 = sts.iloc[0, 1]\n        df_fac2 = sts.iloc[1, 1]\n        df_inter = sts.iloc[2, 1]\n        df_resid = sts.iloc[3, 1]\n\n    # Mean squares\n    ms_fac1 = ss_fac1 / df_fac1\n    ms_fac2 = ss_fac2 / df_fac2\n    ms_inter = ss_inter / df_inter\n    ms_resid = ss_resid / df_resid\n\n    # F-values\n    fval_fac1 = ms_fac1 / ms_resid\n    fval_fac2 = ms_fac2 / ms_resid\n    fval_inter = ms_inter / ms_resid\n\n    # P-values\n    pval_fac1 = f(df_fac1, df_resid).sf(fval_fac1)\n    pval_fac2 = f(df_fac2, df_resid).sf(fval_fac2)\n    pval_inter = f(df_inter, df_resid).sf(fval_inter)\n\n    # Partial eta-square\n    np2_fac1 = ss_fac1 / (ss_fac1 + ss_resid)\n    np2_fac2 = ss_fac2 / (ss_fac2 + ss_resid)\n    np2_inter = ss_inter / (ss_inter + ss_resid)\n\n    # Create output dataframe\n    aov = pd.DataFrame({'Source': [fac1, fac2, fac1 + ' * ' + fac2,\n                                   'residual'],\n                        'SS': np.round([ss_fac1, ss_fac2, ss_inter,\n                                        ss_resid], 3),\n                        'DF': [df_fac1, df_fac2, df_inter, df_resid],\n                        'MS': np.round([ms_fac1, ms_fac2, ms_inter,\n                                        ms_resid], 3),\n                        'F': [fval_fac1, fval_fac2, fval_inter, np.nan],\n                        'p-unc': [pval_fac1, pval_fac2, pval_inter, np.nan],\n                        'np2': [np2_fac1, np2_fac2, np2_inter, np.nan]\n                        })\n    col_order = ['Source', 'SS', 'DF', 'MS', 'F', 'p-unc', 'np2']\n\n    aov = aov.reindex(columns=col_order)\n    aov.dropna(how='all', axis=1, inplace=True)\n    # Export to .csv\n    if export_filename is not None:\n        _export_table(aov, export_filename)\n    return aov", "response": "Two - way ANOVA."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mixed_anova(dv=None, within=None, subject=None, between=None, data=None,\n                correction='auto', export_filename=None):\n    \"\"\"Mixed-design (split-plot) ANOVA.\n\n    Parameters\n    ----------\n    dv : string\n        Name of column containing the dependant variable.\n    within : string\n        Name of column containing the within factor.\n    subject : string\n        Name of column containing the subject identifier.\n    between : string\n        Name of column containing the between factor.\n    data : pandas DataFrame\n        DataFrame. Note that this function can also directly be used as a\n        Pandas method, in which case this argument is no longer needed.\n    correction : string or boolean\n        If True, return Greenhouse-Geisser corrected p-value.\n        If 'auto' (default), compute Mauchly's test of sphericity to determine\n        whether the p-values needs to be corrected.\n    export_filename : string\n        Filename (without extension) for the output file.\n        If None, do not export the table.\n        By default, the file will be created in the current python console\n        directory. To change that, specify the filename with full path.\n\n    Returns\n    -------\n    aov : DataFrame\n        ANOVA summary ::\n\n        'Source' : Names of the factor considered\n        'ddof1' : Degrees of freedom (numerator)\n        'ddof2' : Degrees of freedom (denominator)\n        'F' : F-values\n        'p-unc' : Uncorrected p-values\n        'np2' : Partial eta-square effect sizes\n        'eps' : Greenhouse-Geisser epsilon factor ( = index of sphericity)\n        'p-GG-corr' : Greenhouse-Geisser corrected p-values\n        'W-spher' : Sphericity test statistic\n        'p-spher' : p-value of the sphericity test\n        'sphericity' : sphericity of the data (boolean)\n\n    See Also\n    --------\n    anova : One-way and two-way ANOVA\n    rm_anova : One-way and two-way repeated measures ANOVA\n\n    Notes\n    -----\n    Results have been tested against R and JASP.\n\n    Missing values are automatically removed (listwise deletion) using the\n    :py:func:`pingouin.remove_rm_na` function. This could drastically decrease\n    the power of the ANOVA if many missing values are present. In that case,\n    it might be better to use linear mixed effects models.\n\n    If the between-subject groups are unbalanced (=  unequal sample sizes), a\n    type II ANOVA will be computed.\n\n    Examples\n    --------\n    Compute a two-way mixed model ANOVA.\n\n    >>> from pingouin import mixed_anova, read_dataset\n    >>> df = read_dataset('mixed_anova')\n    >>> aov = mixed_anova(dv='Scores', between='Group',\n    ...                   within='Time', subject='Subject', data=df)\n    >>> aov\n            Source     SS  DF1  DF2     MS      F     p-unc    np2    eps\n    0        Group  5.460    1   58  5.460  5.052  0.028420  0.080      -\n    1         Time  7.628    2  116  3.814  4.027  0.020373  0.065  0.999\n    2  Interaction  5.168    2  116  2.584  2.728  0.069530  0.045      -\n    \"\"\"\n    # Check data\n    _check_dataframe(dv=dv, within=within, between=between, data=data,\n                     subject=subject, effects='interaction')\n\n    # Collapse to the mean\n    data = data.groupby([subject, within, between]).mean().reset_index()\n\n    # Remove NaN\n    if data[dv].isnull().any():\n        data = remove_rm_na(dv=dv, within=within, subject=subject,\n                            data=data[[subject, within, between, dv]])\n\n    # SUMS OF SQUARES\n    grandmean = data[dv].mean()\n    # Extract main effects of time and between\n    mtime = rm_anova(dv=dv, within=within, subject=subject, data=data,\n                     correction=correction, detailed=True)\n    mbetw = anova(dv=dv, between=between, data=data, detailed=True)\n    # Extract SS total, residuals and interactions\n    grp = data.groupby([between, within])[dv]\n    sstotal = grp.apply(lambda x: (x - grandmean)**2).sum()\n    # sst = residuals within + residuals between\n    sst = grp.apply(lambda x: (x - x.mean())**2).sum()\n    # Interaction\n    ssinter = sstotal - (sst + mtime.loc[0, 'SS'] + mbetw.loc[0, 'SS'])\n    sswg = mtime.loc[1, 'SS'] - ssinter\n    sseb = sstotal - (mtime.loc[0, 'SS'] + mbetw.loc[0, 'SS'] + sswg + ssinter)\n\n    # DEGREES OF FREEDOM\n    n_obs = data.groupby(within)[dv].count().max()\n    dftime = mtime.loc[0, 'DF']\n    dfbetween = mbetw.loc[0, 'DF']\n    dfeb = n_obs - data.groupby(between)[dv].count().count()\n    dfwg = dftime * dfeb\n    dfinter = mtime.loc[0, 'DF'] * mbetw.loc[0, 'DF']\n\n    # MEAN SQUARES\n    mseb = sseb / dfeb\n    mswg = sswg / dfwg\n    msinter = ssinter / dfinter\n\n    # F VALUES\n    fbetween = mbetw.loc[0, 'MS'] / mseb\n    ftime = mtime.loc[0, 'MS'] / mswg\n    finter = msinter / mswg\n\n    # P-values\n    pbetween = f(dfbetween, dfeb).sf(fbetween)\n    ptime = f(dftime, dfwg).sf(ftime)\n    pinter = f(dfinter, dfwg).sf(finter)\n\n    # Effects sizes\n    npsq_between = fbetween * dfbetween / (fbetween * dfbetween + dfeb)\n    npsq_time = ftime * dftime / (ftime * dftime + dfwg)\n    npsq_inter = ssinter / (ssinter + sswg)\n\n    # Stats table\n    aov = pd.concat([mbetw.drop(1), mtime.drop(1)], sort=False,\n                    ignore_index=True)\n    # Update values\n    aov.rename(columns={'DF': 'DF1'}, inplace=True)\n    aov.loc[0, 'F'], aov.loc[1, 'F'] = fbetween, ftime\n    aov.loc[0, 'p-unc'], aov.loc[1, 'p-unc'] = pbetween, ptime\n    aov.loc[0, 'np2'], aov.loc[1, 'np2'] = npsq_between, npsq_time\n    aov = aov.append({'Source': 'Interaction',\n                      'SS': ssinter,\n                      'DF1': dfinter,\n                      'MS': msinter,\n                      'F': finter,\n                      'p-unc': pinter,\n                      'np2': npsq_inter,\n                      }, ignore_index=True)\n\n    aov['SS'] = aov['SS'].round(3)\n    aov['MS'] = aov['MS'].round(3)\n    aov['DF2'] = [dfeb, dfwg, dfwg]\n    aov['eps'] = [np.nan, mtime.loc[0, 'eps'], np.nan]\n    col_order = ['Source', 'SS', 'DF1', 'DF2', 'MS', 'F', 'p-unc',\n                 'p-GG-corr', 'np2', 'eps', 'sphericity', 'W-spher',\n                 'p-spher']\n\n    # Replace NaN\n    aov = aov.fillna('-')\n\n    aov = aov.reindex(columns=col_order)\n    aov.dropna(how='all', axis=1, inplace=True)\n\n    # Round\n    aov[['F', 'eps', 'np2']] = aov[['F', 'eps', 'np2']].round(3)\n\n    # Export to .csv\n    if export_filename is not None:\n        _export_table(aov, export_filename)\n    return aov", "response": "Mixed - design ANOVA."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ancovan(dv=None, covar=None, between=None, data=None,\n            export_filename=None):\n    \"\"\"ANCOVA with n covariates.\n\n    This is an internal function. The main call to this function should be done\n    by the :py:func:`pingouin.ancova` function.\n\n    Parameters\n    ----------\n    dv : string\n        Name of column containing the dependant variable.\n    covar : string\n        Name(s) of columns containing the covariates.\n    between : string\n        Name of column containing the between factor.\n    data : pandas DataFrame\n        DataFrame\n    export_filename : string\n        Filename (without extension) for the output file.\n        If None, do not export the table.\n        By default, the file will be created in the current python console\n        directory. To change that, specify the filename with full path.\n\n    Returns\n    -------\n    aov : DataFrame\n        ANCOVA summary ::\n\n        'Source' : Names of the factor considered\n        'SS' : Sums of squares\n        'DF' : Degrees of freedom\n        'F' : F-values\n        'p-unc' : Uncorrected p-values\n    \"\"\"\n    # Check that stasmodels is installed\n    from pingouin.utils import _is_statsmodels_installed\n    _is_statsmodels_installed(raise_error=True)\n    from statsmodels.api import stats\n    from statsmodels.formula.api import ols\n\n    # Check that covariates are numeric ('float', 'int')\n    assert all([data[covar[i]].dtype.kind in 'fi' for i in range(len(covar))])\n\n    # Fit ANCOVA model\n    formula = dv + ' ~ C(' + between + ')'\n    for c in covar:\n        formula += ' + ' + c\n    model = ols(formula, data=data).fit()\n    aov = stats.anova_lm(model, typ=2).reset_index()\n\n    aov.rename(columns={'index': 'Source', 'sum_sq': 'SS',\n                        'df': 'DF', 'PR(>F)': 'p-unc'}, inplace=True)\n\n    aov.loc[0, 'Source'] = between\n\n    aov['DF'] = aov['DF'].astype(int)\n    aov[['SS', 'F']] = aov[['SS', 'F']].round(3)\n\n    # Export to .csv\n    if export_filename is not None:\n        _export_table(aov, export_filename)\n\n    return aov", "response": "AnCOVA with n covariates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the ANOVA dataset.", "response": "def read_dataset(dname):\n    \"\"\"Read example datasets.\n\n    Parameters\n    ----------\n    dname : string\n        Name of dataset to read (without extension).\n        Must be a valid dataset present in pingouin.datasets\n\n    Returns\n    -------\n    data : pd.DataFrame\n        Dataset\n\n    Examples\n    --------\n    Load the ANOVA dataset\n\n    >>> from pingouin import read_dataset\n    >>> df = read_dataset('anova')\n    \"\"\"\n    # Check extension\n    d, ext = op.splitext(dname)\n    if ext.lower() == '.csv':\n        dname = d\n    # Check that dataset exist\n    if dname not in dts['dataset'].values:\n        raise ValueError('Dataset does not exist. Valid datasets names are',\n                         dts['dataset'].values)\n    # Load dataset\n    return pd.read_csv(op.join(ddir, dname + '.csv'), sep=',')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _perm_pval(bootstat, estimate, tail='two-sided'):\n    assert tail in ['two-sided', 'upper', 'lower'], 'Wrong tail argument.'\n    assert isinstance(estimate, (int, float))\n    bootstat = np.asarray(bootstat)\n    assert bootstat.ndim == 1, 'bootstat must be a 1D array.'\n    n_boot = bootstat.size\n    assert n_boot >= 1, 'bootstat must have at least one value.'\n    if tail == 'upper':\n        p = np.greater_equal(bootstat, estimate).sum() / n_boot\n    elif tail == 'lower':\n        p = np.less_equal(bootstat, estimate).sum() / n_boot\n    else:\n        p = np.greater_equal(np.fabs(bootstat), abs(estimate)).sum() / n_boot\n    return p", "response": "Compute p - values from a permutation test."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexports DataFrame to. csv", "response": "def _export_table(table, fname):\n    \"\"\"Export DataFrame to .csv\"\"\"\n    import os.path as op\n    extension = op.splitext(fname.lower())[1]\n    if extension == '':\n        fname = fname + '.csv'\n    table.to_csv(fname, index=None, sep=',', encoding='utf-8',\n                 float_format='%.4f', decimal='.')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving NaN in a single array.", "response": "def _remove_na_single(x, axis='rows'):\n    \"\"\"Remove NaN in a single array.\n    This is an internal Pingouin function.\n    \"\"\"\n    if x.ndim == 1:\n        # 1D arrays\n        x_mask = ~np.isnan(x)\n    else:\n        # 2D arrays\n        ax = 1 if axis == 'rows' else 0\n        x_mask = ~np.any(np.isnan(x), axis=ax)\n    # Check if missing values are present\n    if ~x_mask.all():\n        ax = 0 if axis == 'rows' else 1\n        ax = 0 if x.ndim == 1 else ax\n        x = x.compress(x_mask, axis=ax)\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove missing values along a given axis in one or more numpy arrays.", "response": "def remove_na(x, y=None, paired=False, axis='rows'):\n    \"\"\"Remove missing values along a given axis in one or more (paired) numpy\n    arrays.\n\n    Parameters\n    ----------\n    x, y : 1D or 2D arrays\n        Data. ``x`` and ``y`` must have the same number of dimensions.\n        ``y`` can be None to only remove missing values in ``x``.\n    paired : bool\n        Indicates if the measurements are paired or not.\n    axis : str\n        Axis or axes along which missing values are removed.\n        Can be 'rows' or 'columns'. This has no effect if ``x`` and ``y`` are\n        one-dimensional arrays.\n\n    Returns\n    -------\n    x, y : np.ndarray\n        Data without missing values\n\n    Examples\n    --------\n    Single 1D array\n\n    >>> import numpy as np\n    >>> from pingouin import remove_na\n    >>> x = [6.4, 3.2, 4.5, np.nan]\n    >>> remove_na(x)\n    array([6.4, 3.2, 4.5])\n\n    With two paired 1D arrays\n\n    >>> y = [2.3, np.nan, 5.2, 4.6]\n    >>> remove_na(x, y, paired=True)\n    (array([6.4, 4.5]), array([2.3, 5.2]))\n\n    With two independent 2D arrays\n\n    >>> x = np.array([[4, 2], [4, np.nan], [7, 6]])\n    >>> y = np.array([[6, np.nan], [3, 2], [2, 2]])\n    >>> x_no_nan, y_no_nan = remove_na(x, y, paired=False)\n    \"\"\"\n    # Safety checks\n    x = np.asarray(x)\n    assert x.size > 1, 'x must have more than one element.'\n    assert axis in ['rows', 'columns'], 'axis must be rows or columns.'\n\n    if y is None:\n        return _remove_na_single(x, axis=axis)\n    elif isinstance(y, (int, float, str)):\n        return _remove_na_single(x, axis=axis), y\n    elif isinstance(y, (list, np.ndarray)):\n        y = np.asarray(y)\n        # Make sure that we just pass-through if y have only 1 element\n        if y.size == 1:\n            return _remove_na_single(x, axis=axis), y\n        if x.ndim != y.ndim or paired is False:\n            # x and y do not have the same dimension\n            x_no_nan = _remove_na_single(x, axis=axis)\n            y_no_nan = _remove_na_single(y, axis=axis)\n            return x_no_nan, y_no_nan\n\n    # At this point, we assume that x and y are paired and have same dimensions\n    if x.ndim == 1:\n        # 1D arrays\n        x_mask = ~np.isnan(x)\n        y_mask = ~np.isnan(y)\n    else:\n        # 2D arrays\n        ax = 1 if axis == 'rows' else 0\n        x_mask = ~np.any(np.isnan(x), axis=ax)\n        y_mask = ~np.any(np.isnan(y), axis=ax)\n\n    # Check if missing values are present\n    if ~x_mask.all() or ~y_mask.all():\n        ax = 0 if axis == 'rows' else 1\n        ax = 0 if x.ndim == 1 else ax\n        both = np.logical_and(x_mask, y_mask)\n        x = x.compress(both, axis=ax)\n        y = y.compress(both, axis=ax)\n    return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_rm_na(dv=None, within=None, subject=None, data=None,\n                 aggregate='mean'):\n    \"\"\"Remove missing values in long-format repeated-measures dataframe.\n\n    Parameters\n    ----------\n    dv : string or list\n        Dependent variable(s), from which the missing values should be removed.\n        If ``dv`` is not specified, all the columns in the dataframe are\n        considered. ``dv`` must be numeric.\n    within : string or list\n        Within-subject factor(s).\n    subject : string\n        Subject identifier.\n    data : dataframe\n        Long-format dataframe.\n    aggregate : string\n        Aggregation method if there are more within-factors in the data than\n        specified in the ``within`` argument. Can be `mean`, `median`, `sum`,\n        `first`, `last`, or any other function accepted by\n        :py:meth:`pandas.DataFrame.groupby`.\n\n    Returns\n    -------\n    data : dataframe\n        Dataframe without the missing values.\n\n    Notes\n    -----\n    If multiple factors are specified, the missing values are removed on the\n    last factor, so the order of ``within`` is important.\n\n    In addition, if there are more within-factors in the data than specified in\n    the ``within`` argument, data will be aggregated using the function\n    specified in ``aggregate``. Note that in the default case (aggregation\n    using the mean), all the non-numeric column(s) will be dropped.\n    \"\"\"\n    # Safety checks\n    assert isinstance(aggregate, str), 'aggregate must be a str.'\n    assert isinstance(within, (str, list)), 'within must be str or list.'\n    assert isinstance(subject, str), 'subject must be a string.'\n    assert isinstance(data, pd.DataFrame), 'Data must be a DataFrame.'\n\n    idx_cols = _flatten_list([subject, within])\n    all_cols = data.columns\n\n    if data[idx_cols].isnull().any().any():\n        raise ValueError(\"NaN are present in the within-factors or in the \"\n                         \"subject column. Please remove them manually.\")\n\n    # Check if more within-factors are present and if so, aggregate\n    if (data.groupby(idx_cols).count() > 1).any().any():\n        # Make sure that we keep the non-numeric columns when aggregating\n        # This is disabled by default to avoid any confusion.\n        # all_others = all_cols.difference(idx_cols)\n        # all_num = data[all_others].select_dtypes(include='number').columns\n        # agg = {c: aggregate if c in all_num else 'first' for c in all_others}\n        data = data.groupby(idx_cols).agg(aggregate)\n    else:\n        # Set subject + within factors as index.\n        # Sorting is done to avoid performance warning when dropping.\n        data = data.set_index(idx_cols).sort_index()\n\n    # Find index with missing values\n    if dv is None:\n        iloc_nan = data.isnull().values.nonzero()[0]\n    else:\n        iloc_nan = data[dv].isnull().values.nonzero()[0]\n\n    # Drop the last within level\n    idx_nan = data.index[iloc_nan].droplevel(-1)\n\n    # Drop and re-order\n    data = data.drop(idx_nan).reset_index(drop=False)\n    return data.reindex(columns=all_cols).dropna(how='all', axis=1)", "response": "Removes missing values from long - format repeated - measures dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nflattens an arbitrarily nested list into a new list.", "response": "def _flatten_list(x):\n    \"\"\"Flatten an arbitrarily nested list into a new list.\n\n    This can be useful to select pandas DataFrame columns.\n\n    From https://stackoverflow.com/a/16176969/10581531\n\n    Examples\n    --------\n    >>> from pingouin.utils import _flatten_list\n    >>> x = ['X1', ['M1', 'M2'], 'Y1', ['Y2']]\n    >>> _flatten_list(x)\n    ['X1', 'M1', 'M2', 'Y1', 'Y2']\n\n    >>> x = ['Xaa', 'Xbb', 'Xcc']\n    >>> _flatten_list(x)\n    ['Xaa', 'Xbb', 'Xcc']\n    \"\"\"\n    result = []\n    # Remove None\n    x = list(filter(None.__ne__, x))\n    for el in x:\n        x_is_iter = isinstance(x, collections.Iterable)\n        if x_is_iter and not isinstance(el, (str, tuple)):\n            result.extend(_flatten_list(el))\n        else:\n            result.append(el)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that the data is a pandas dataframe.", "response": "def _check_dataframe(dv=None, between=None, within=None, subject=None,\n                     effects=None, data=None):\n    \"\"\"Check dataframe\"\"\"\n    # Check that data is a dataframe\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError('Data must be a pandas dataframe.')\n    # Check that both dv and data are provided.\n    if any(v is None for v in [dv, data]):\n        raise ValueError('DV and data must be specified')\n    # Check that dv is a numeric variable\n    if data[dv].dtype.kind not in 'fi':\n        raise ValueError('DV must be numeric.')\n    # Check that effects is provided\n    if effects not in ['within', 'between', 'interaction', 'all']:\n        raise ValueError('Effects must be: within, between, interaction, all')\n    # Check that within is a string or a list (rm_anova2)\n    if effects == 'within' and not isinstance(within, (str, list)):\n        raise ValueError('within must be a string or a list.')\n    # Check that subject identifier is provided in rm_anova and friedman.\n    if effects == 'within' and subject is None:\n        raise ValueError('subject must be specified when effects=within')\n    # Check that between is a string or a list (anova2)\n    if effects == 'between' and not isinstance(between, (str,\n                                                         list)):\n        raise ValueError('between must be a string or a list.')\n    # Check that both between and within are present for interaction\n    if effects == 'interaction':\n        for input in [within, between]:\n            if not isinstance(input, (str, list)):\n                raise ValueError('within and between must be specified when '\n                                 'effects=interaction')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat BF10 to floating point or scientific notation.", "response": "def _format_bf(bf, precision=3, trim='0'):\n    \"\"\"Format BF10 to floating point or scientific notation.\n    \"\"\"\n    if bf >= 1e4 or bf <= 1e-4:\n        out = np.format_float_scientific(bf, precision=precision, trim=trim)\n    else:\n        out = np.format_float_positional(bf, precision=precision, trim=trim)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bayesfactor_pearson(r, n):\n    from scipy.special import gamma\n\n    # Function to be integrated\n    def fun(g, r, n):\n        return np.exp(((n - 2) / 2) * np.log(1 + g) + (-(n - 1) / 2)\n                      * np.log(1 + (1 - r**2) * g) + (-3 / 2)\n                      * np.log(g) + - n / (2 * g))\n\n    # JZS Bayes factor calculation\n    integr = quad(fun, 0, np.inf, args=(r, n))[0]\n    bf10 = np.sqrt((n / 2)) / gamma(1 / 2) * integr\n    return _format_bf(bf10)", "response": "This function calculates the JZS Bayes Factor of a Pearson correlation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normality(*args, alpha=.05):\n    from scipy.stats import shapiro\n    k = len(args)\n    p = np.zeros(k)\n    normal = np.zeros(k, 'bool')\n    for j in range(k):\n        _, p[j] = shapiro(args[j])\n        normal[j] = True if p[j] > alpha else False\n\n    if k == 1:\n        normal = bool(normal)\n        p = float(p)\n\n    return normal, np.round(p, 3)", "response": "Test for univariate normality test."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef homoscedasticity(*args, alpha=.05):\n    from scipy.stats import levene, bartlett\n    k = len(args)\n    if k < 2:\n        raise ValueError(\"Must enter at least two input sample vectors.\")\n\n    # Test normality of data\n    normal, _ = normality(*args)\n    if np.count_nonzero(normal) != normal.size:\n        # print('Data are not normally distributed. Using Levene test.')\n        _, p = levene(*args)\n    else:\n        _, p = bartlett(*args)\n\n    equal_var = True if p > alpha else False\n    return equal_var, np.round(p, 3)", "response": "Test the homogeneity of variances."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the epsilon adjustement factor for repeated measurements.", "response": "def epsilon(data, correction='gg'):\n    \"\"\"Epsilon adjustement factor for repeated measures.\n\n    Parameters\n    ----------\n    data : pd.DataFrame\n        DataFrame containing the repeated measurements.\n        ``data`` must be in wide-format. To convert from wide to long format,\n        use the :py:func:`pandas.pivot_table` function.\n    correction : string\n        Specify the epsilon version ::\n\n            'gg' : Greenhouse-Geisser\n            'hf' : Huynh-Feldt\n            'lb' : Lower bound\n\n    Returns\n    -------\n    eps : float\n        Epsilon adjustement factor.\n\n    Notes\n    -----\n    The **lower bound** for epsilon is:\n\n    .. math:: lb = \\\\frac{1}{k - 1}\n\n    where :math:`k` is the number of groups (= data.shape[1]).\n\n    The **Greenhouse-Geisser epsilon** is given by:\n\n    .. math::\n\n        \\\\epsilon_{GG} = \\\\frac{k^2(\\\\overline{diag(S)} - \\\\overline{S})^2}\n        {(k-1)(\\\\sum_{i=1}^{k}\\\\sum_{j=1}^{k}s_{ij}^2 - 2k\\\\sum_{j=1}^{k}\n        \\\\overline{s_i}^2 + k^2\\\\overline{S}^2)}\n\n    where :math:`S` is the covariance matrix, :math:`\\\\overline{S}` the\n    grandmean of S and :math:`\\\\overline{diag(S)}` the mean of all the elements\n    on the diagonal of S (i.e. mean of the variances).\n\n    The **Huynh-Feldt epsilon** is given by:\n\n    .. math::\n\n        \\\\epsilon_{HF} = \\\\frac{n(k-1)\\\\epsilon_{GG}-2}{(k-1)\n        (n-1-(k-1)\\\\epsilon_{GG})}\n\n    where :math:`n` is the number of subjects.\n\n    References\n    ----------\n    .. [1] http://www.real-statistics.com/anova-repeated-measures/sphericity/\n\n    Examples\n    --------\n\n    >>> import pandas as pd\n    >>> from pingouin import epsilon\n    >>> data = pd.DataFrame({'A': [2.2, 3.1, 4.3, 4.1, 7.2],\n    ...                      'B': [1.1, 2.5, 4.1, 5.2, 6.4],\n    ...                      'C': [8.2, 4.5, 3.4, 6.2, 7.2]})\n    >>> epsilon(data, correction='gg')\n    0.5587754577585018\n\n    >>> epsilon(data, correction='hf')\n    0.6223448311539781\n\n    >>> epsilon(data, correction='lb')\n    0.5\n    \"\"\"\n    # Covariance matrix\n    S = data.cov()\n    n = data.shape[0]\n    k = data.shape[1]\n\n    # Lower bound\n    if correction == 'lb':\n        if S.columns.nlevels == 1:\n            return 1 / (k - 1)\n        elif S.columns.nlevels == 2:\n            ka = S.columns.levels[0].size\n            kb = S.columns.levels[1].size\n            return 1 / ((ka - 1) * (kb - 1))\n\n    # Compute GGEpsilon\n    # - Method 1\n    mean_var = np.diag(S).mean()\n    S_mean = S.mean().mean()\n    ss_mat = (S**2).sum().sum()\n    ss_rows = (S.mean(1)**2).sum().sum()\n    num = (k * (mean_var - S_mean))**2\n    den = (k - 1) * (ss_mat - 2 * k * ss_rows + k**2 * S_mean**2)\n    eps = np.min([num / den, 1])\n    # - Method 2\n    # S_pop = S - S.mean(0)[:, None] - S.mean(1)[None, :] + S.mean()\n    # eig = np.linalg.eigvalsh(S_pop)[1:]\n    # V = eig.sum()**2 / np.sum(eig**2)\n    # eps = V / (k - 1)\n\n    # Huynh-Feldt\n    if correction == 'hf':\n        num = n * (k - 1) * eps - 2\n        den = (k - 1) * (n - 1 - (k - 1) * eps)\n        eps = np.min([num / den, 1])\n    return eps"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_esci(stat=None, nx=None, ny=None, paired=False, eftype='cohen',\n                 confidence=.95, decimals=2):\n    \"\"\"Parametric confidence intervals around a Cohen d or a\n    correlation coefficient.\n\n    Parameters\n    ----------\n    stat : float\n        Original effect size. Must be either a correlation coefficient or a\n        Cohen-type effect size (Cohen d or Hedges g).\n    nx, ny : int\n        Length of vector x and y.\n    paired : bool\n        Indicates if the effect size was estimated from a paired sample.\n        This is only relevant for cohen or hedges effect size.\n    eftype : string\n        Effect size type. Must be 'r' (correlation) or 'cohen'\n        (Cohen d or Hedges g).\n    confidence : float\n        Confidence level (0.95 = 95%)\n    decimals : int\n        Number of rounded decimals.\n\n    Returns\n    -------\n    ci : array\n        Desired converted effect size\n\n    Notes\n    -----\n    To compute the parametric confidence interval around a\n    **Pearson r correlation** coefficient, one must first apply a\n    Fisher's r-to-z transformation:\n\n    .. math:: z = 0.5 \\\\cdot \\\\ln \\\\frac{1 + r}{1 - r} = \\\\text{arctanh}(r)\n\n    and compute the standard deviation:\n\n    .. math:: se = \\\\frac{1}{\\\\sqrt{n - 3}}\n\n    where :math:`n` is the sample size.\n\n    The lower and upper confidence intervals - *in z-space* - are then\n    given by:\n\n    .. math:: ci_z = z \\\\pm crit \\\\cdot se\n\n    where :math:`crit` is the critical value of the nomal distribution\n    corresponding to the desired confidence level (e.g. 1.96 in case of a 95%\n    confidence interval).\n\n    These confidence intervals can then be easily converted back to *r-space*:\n\n    .. math::\n\n        ci_r = \\\\frac{\\\\exp(2 \\\\cdot ci_z) - 1}{\\\\exp(2 \\\\cdot ci_z) + 1} =\n        \\\\text{tanh}(ci_z)\n\n    A formula for calculating the confidence interval for a\n    **Cohen d effect size** is given by Hedges and Olkin (1985, p86).\n    If the effect size estimate from the sample is :math:`d`, then it is\n    normally distributed, with standard deviation:\n\n    .. math::\n\n        se = \\\\sqrt{\\\\frac{n_x + n_y}{n_x \\\\cdot n_y} +\n        \\\\frac{d^2}{2 (n_x + n_y)}}\n\n    where :math:`n_x` and :math:`n_y` are the sample sizes of the two groups.\n\n    In one-sample test or paired test, this becomes:\n\n    .. math::\n\n        se = \\\\sqrt{\\\\frac{1}{n_x} + \\\\frac{d^2}{2 \\\\cdot n_x}}\n\n    The lower and upper confidence intervals are then given by:\n\n    .. math:: ci_d = d \\\\pm crit \\\\cdot se\n\n    where :math:`crit` is the critical value of the nomal distribution\n    corresponding to the desired confidence level (e.g. 1.96 in case of a 95%\n    confidence interval).\n\n    References\n    ----------\n    .. [1] https://en.wikipedia.org/wiki/Fisher_transformation\n\n    .. [2] Hedges, L., and Ingram Olkin. \"Statistical models for\n           meta-analysis.\" (1985).\n\n    .. [3] http://www.leeds.ac.uk/educol/documents/00002182.htm\n\n    Examples\n    --------\n    1. Confidence interval of a Pearson correlation coefficient\n\n    >>> import pingouin as pg\n    >>> x = [3, 4, 6, 7, 5, 6, 7, 3, 5, 4, 2]\n    >>> y = [4, 6, 6, 7, 6, 5, 5, 2, 3, 4, 1]\n    >>> nx, ny = len(x), len(y)\n    >>> stat = np.corrcoef(x, y)[0][1]\n    >>> ci = pg.compute_esci(stat=stat, nx=nx, ny=ny, eftype='r')\n    >>> print(stat, ci)\n    0.7468280049029223 [0.27 0.93]\n\n    2. Confidence interval of a Cohen d\n\n    >>> import pingouin as pg\n    >>> x = [3, 4, 6, 7, 5, 6, 7, 3, 5, 4, 2]\n    >>> y = [4, 6, 6, 7, 6, 5, 5, 2, 3, 4, 1]\n    >>> nx, ny = len(x), len(y)\n    >>> stat = pg.compute_effsize(x, y, eftype='cohen')\n    >>> ci = pg.compute_esci(stat=stat, nx=nx, ny=ny, eftype='cohen')\n    >>> print(stat, ci)\n    0.1537753990658328 [-0.68  0.99]\n    \"\"\"\n    from scipy.stats import norm\n    # Safety check\n    assert eftype.lower() in['r', 'pearson', 'spearman', 'cohen',\n                             'd', 'g', 'hedges']\n    assert stat is not None and nx is not None\n    assert isinstance(confidence, float)\n    assert 0 < confidence < 1\n\n    # Note that we are using a normal dist and not a T dist:\n    # from scipy.stats import t\n    # crit = np.abs(t.ppf((1 - confidence) / 2), dof)\n    crit = np.abs(norm.ppf((1 - confidence) / 2))\n\n    if eftype.lower() in ['r', 'pearson', 'spearman']:\n        # Standardize correlation coefficient\n        z = np.arctanh(stat)\n        se = 1 / np.sqrt(nx - 3)\n        ci_z = np.array([z - crit * se, z + crit * se])\n        # Transform back to r\n        ci = np.tanh(ci_z)\n    else:\n        if ny == 1 or paired:\n            # One sample or paired\n            se = np.sqrt(1 / nx + stat**2 / (2 * nx))\n        else:\n            # Two-sample test\n            se = np.sqrt(((nx + ny) / (nx * ny)) + (stat**2) / (2 * (nx + ny)))\n        ci = np.array([stat - crit * se, stat + crit * se])\n    return np.round(ci, decimals)", "response": "Compute the parametric confidence intervals around a Cohen - type effect size or Hedges g."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbootstraps confidence intervals of univariate and bivariate functions. Parameters ---------- x : 1D-array or list First sample. Required for both bivariate and univariate functions. y : 1D-array, list, or None Second sample. Required only for bivariate functions. func : str or custom function Function to compute the bootstrapped statistic. Accepted string values are:: 'pearson': Pearson correlation (bivariate, requires x and y) 'spearman': Spearman correlation (bivariate) 'cohen': Cohen d effect size (bivariate) 'hedges': Hedges g effect size (bivariate) 'mean': Mean (univariate, requires only x) 'std': Standard deviation (univariate) 'var': Variance (univariate) method : str Method to compute the confidence intervals:: 'norm': Normal approximation with bootstrapped bias and standard error 'per': basic percentile method 'cper': Bias corrected percentile method (default) paired : boolean Indicates whether x and y are paired or not. Only useful when computing bivariate Cohen d or Hedges g bootstrapped confidence intervals. confidence : float Confidence level (0.95 = 95%) n_boot : int Number of bootstrap iterations. The higher, the better, the slower. decimals : int Number of rounded decimals. seed : int or None Random seed for generating bootstrap samples. return_dist : boolean If True, return the confidence intervals and the bootstrapped distribution (e.g. for plotting purposes). Returns ------- ci : array Desired converted effect size Notes ----- Results have been tested against the *bootci* Matlab function. References ---------- .. [1] https://www.mathworks.com/help/stats/bootci.html .. [2] DiCiccio, T. J., & Efron, B. (1996). Bootstrap confidence intervals. Statistical science, 189-212. .. [3] Davison, A. C., & Hinkley, D. V. (1997). Bootstrap methods and their application (Vol. 1). Cambridge university press. Examples -------- 1. Bootstrapped 95% confidence interval of a Pearson correlation >>> import pingouin as pg >>> x = [3, 4, 6, 7, 5, 6, 7, 3, 5, 4, 2] >>> y = [4, 6, 6, 7, 6, 5, 5, 2, 3, 4, 1] >>> stat = np.corrcoef(x, y)[0][1] >>> ci = pg.compute_bootci(x, y, func='pearson', seed=42) >>> print(stat, ci) 0.7468280049029223 [0.27 0.93] 2. Bootstrapped 95% confidence interval of a Cohen d >>> stat = pg.compute_effsize(x, y, eftype='cohen') >>> ci = pg.compute_bootci(x, y, func='cohen', seed=42, decimals=3) >>> print(stat, ci) 0.1537753990658328 [-0.327 0.562] 3. Bootstrapped confidence interval of a standard deviation (univariate) >>> import numpy as np >>> stat = np.std(x, ddof=1) >>> ci = pg.compute_bootci(x, func='std', seed=123) >>> print(stat, ci) 1.6787441193290351 [1.21 2.16] 4. Bootstrapped confidence interval using a custom function >>> stat = np.sum(np.exp(x) / np.exp(y)) >>> ci = pg.compute_bootci(x, y, func=lambda x, y: np.sum(np.exp(x) ... / np.exp(y)), n_boot=10000, seed=123) >>> print(stat, ci) 26.80405184881793 [12.76 45.15] 5. Get the bootstrapped distribution around a Pearson correlation >>> ci, bstat = pg.compute_bootci(x, y, return_dist=True) >>> print(bstat.size) 2000", "response": "def compute_bootci(x, y=None, func='pearson', method='cper', paired=False,\n                   confidence=.95, n_boot=2000, decimals=2, seed=None,\n                   return_dist=False):\n    \"\"\"Bootstrapped confidence intervals of univariate and bivariate functions.\n\n    Parameters\n    ----------\n    x : 1D-array or list\n        First sample. Required for both bivariate and univariate functions.\n    y : 1D-array, list, or None\n        Second sample. Required only for bivariate functions.\n    func : str or custom function\n        Function to compute the bootstrapped statistic.\n        Accepted string values are::\n\n        'pearson': Pearson correlation (bivariate, requires x and y)\n        'spearman': Spearman correlation (bivariate)\n        'cohen': Cohen d effect size (bivariate)\n        'hedges': Hedges g effect size (bivariate)\n        'mean': Mean (univariate, requires only x)\n        'std': Standard deviation (univariate)\n        'var': Variance (univariate)\n    method : str\n        Method to compute the confidence intervals::\n\n        'norm': Normal approximation with bootstrapped bias and standard error\n        'per': basic percentile method\n        'cper': Bias corrected percentile method (default)\n    paired : boolean\n        Indicates whether x and y are paired or not. Only useful when computing\n        bivariate Cohen d or Hedges g bootstrapped confidence intervals.\n    confidence : float\n        Confidence level (0.95 = 95%)\n    n_boot : int\n        Number of bootstrap iterations. The higher, the better, the slower.\n    decimals : int\n        Number of rounded decimals.\n    seed : int or None\n        Random seed for generating bootstrap samples.\n    return_dist : boolean\n        If True, return the confidence intervals and the bootstrapped\n        distribution  (e.g. for plotting purposes).\n\n    Returns\n    -------\n    ci : array\n        Desired converted effect size\n\n    Notes\n    -----\n    Results have been tested against the *bootci* Matlab function.\n\n    References\n    ----------\n    .. [1] https://www.mathworks.com/help/stats/bootci.html\n\n    .. [2] DiCiccio, T. J., & Efron, B. (1996). Bootstrap confidence intervals.\n           Statistical science, 189-212.\n\n    .. [3] Davison, A. C., & Hinkley, D. V. (1997). Bootstrap methods and their\n           application (Vol. 1). Cambridge university press.\n\n    Examples\n    --------\n    1. Bootstrapped 95% confidence interval of a Pearson correlation\n\n    >>> import pingouin as pg\n    >>> x = [3, 4, 6, 7, 5, 6, 7, 3, 5, 4, 2]\n    >>> y = [4, 6, 6, 7, 6, 5, 5, 2, 3, 4, 1]\n    >>> stat = np.corrcoef(x, y)[0][1]\n    >>> ci = pg.compute_bootci(x, y, func='pearson', seed=42)\n    >>> print(stat, ci)\n    0.7468280049029223 [0.27 0.93]\n\n    2. Bootstrapped 95% confidence interval of a Cohen d\n\n    >>> stat = pg.compute_effsize(x, y, eftype='cohen')\n    >>> ci = pg.compute_bootci(x, y, func='cohen', seed=42, decimals=3)\n    >>> print(stat, ci)\n    0.1537753990658328 [-0.327  0.562]\n\n    3. Bootstrapped confidence interval of a standard deviation (univariate)\n\n    >>> import numpy as np\n    >>> stat = np.std(x, ddof=1)\n    >>> ci = pg.compute_bootci(x, func='std', seed=123)\n    >>> print(stat, ci)\n    1.6787441193290351 [1.21 2.16]\n\n    4. Bootstrapped confidence interval using a custom function\n\n    >>> stat = np.sum(np.exp(x) / np.exp(y))\n    >>> ci = pg.compute_bootci(x, y, func=lambda x, y: np.sum(np.exp(x)\n    ...                           / np.exp(y)), n_boot=10000, seed=123)\n    >>> print(stat, ci)\n    26.80405184881793 [12.76 45.15]\n\n    5. Get the bootstrapped distribution around a Pearson correlation\n\n    >>> ci, bstat = pg.compute_bootci(x, y, return_dist=True)\n    >>> print(bstat.size)\n    2000\n    \"\"\"\n    from inspect import isfunction\n    from scipy.stats import norm\n\n    x = np.asarray(x)\n    n = x.size\n    assert x.ndim == 1\n    assert n > 1\n\n    if y is not None:\n        y = np.asarray(y)\n        ny = y.size\n        assert y.ndim == 1\n        assert ny > 1\n        n = min(n, ny)\n\n    assert isinstance(confidence, float)\n    assert 0 < confidence < 1\n    assert method in ['norm', 'normal', 'percentile', 'per', 'cpercentile',\n                      'cper']\n    assert isfunction(func) or isinstance(func, str)\n\n    if isinstance(func, str):\n        func_str = '%s' % func\n        if func == 'pearson':\n\n            def func(x, y):\n                return np.corrcoef(x, y)[0][1]\n\n        elif func == 'spearman':\n            from scipy.stats import spearmanr\n\n            def func(x, y):\n                spr, _ = spearmanr(x, y)\n                return spr\n\n        elif func in ['cohen', 'hedges']:\n            from pingouin.effsize import compute_effsize\n\n            def func(x, y):\n                return compute_effsize(x, y, paired=paired, eftype=func_str)\n\n        elif func == 'mean':\n\n            def func(x):\n                return np.mean(x)\n\n        elif func == 'std':\n\n            def func(x):\n                return np.std(x, ddof=1)\n\n        elif func == 'var':\n\n            def func(x):\n                return np.var(x, ddof=1)\n        else:\n            raise ValueError('Function string not recognized.')\n\n    # Bootstrap\n    rng = np.random.RandomState(seed)  # Random seed\n    bootsam = rng.choice(np.arange(n), size=(n, n_boot), replace=True)\n    bootstat = np.empty(n_boot)\n\n    if y is not None:\n        reference = func(x, y)\n        for i in range(n_boot):\n            # Note that here we use a bootstrapping procedure with replacement\n            # of all the pairs (Xi, Yi). This is NOT suited for\n            # hypothesis testing such as p-value estimation). Instead, for the\n            # latter, one must only shuffle the Y values while keeping the X\n            # values constant, i.e.:\n            # >>> bootsam = rng.random_sample((n_boot, n)).argsort(axis=1)\n            # >>> for i in range(n_boot):\n            # >>>   bootstat[i] = func(x, y[bootsam[i, :]])\n            bootstat[i] = func(x[bootsam[:, i]], y[bootsam[:, i]])\n    else:\n        reference = func(x)\n        for i in range(n_boot):\n            bootstat[i] = func(x[bootsam[:, i]])\n\n    # CONFIDENCE INTERVALS\n    alpha = 1 - confidence\n    dist_sorted = np.sort(bootstat)\n\n    if method in ['norm', 'normal']:\n        # Normal approximation\n        za = norm.ppf(alpha / 2)\n        se = np.std(bootstat, ddof=1)\n\n        bias = np.mean(bootstat - reference)\n        ll = reference - bias + se * za\n        ul = reference - bias - se * za\n        ci = [ll, ul]\n    elif method in ['percentile', 'per']:\n        # Uncorrected percentile\n        pct_ll = int(n_boot * (alpha / 2))\n        pct_ul = int(n_boot * (1 - alpha / 2))\n        ci = [dist_sorted[pct_ll], dist_sorted[pct_ul]]\n    else:\n        # Corrected percentile bootstrap\n        # Compute bias-correction constant z0\n        z_0 = norm.ppf(np.mean(bootstat < reference) +\n                       np.mean(bootstat == reference) / 2)\n        z_alpha = norm.ppf(alpha / 2)\n        pct_ul = 100 * norm.cdf(2 * z_0 - z_alpha)\n        pct_ll = 100 * norm.cdf(2 * z_0 + z_alpha)\n        ll = np.percentile(bootstat, pct_ll)\n        ul = np.percentile(bootstat, pct_ul)\n        ci = [ll, ul]\n\n    ci = np.round(ci, decimals)\n    if return_dist:\n        return ci, bootstat\n    else:\n        return ci"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert an effect size between two set of observations.", "response": "def convert_effsize(ef, input_type, output_type, nx=None, ny=None):\n    \"\"\"Conversion between effect sizes.\n\n    Parameters\n    ----------\n    ef : float\n        Original effect size\n    input_type : string\n        Effect size type of ef. Must be 'r' or 'd'.\n    output_type : string\n        Desired effect size type.\n        Available methods are ::\n\n        'none' : no effect size\n        'cohen' : Unbiased Cohen d\n        'hedges' : Hedges g\n        'glass': Glass delta\n        'eta-square' : Eta-square\n        'odds-ratio' : Odds ratio\n        'AUC' : Area Under the Curve\n    nx, ny : int, optional\n        Length of vector x and y.\n        nx and ny are required to convert to Hedges g\n\n    Returns\n    -------\n    ef : float\n        Desired converted effect size\n\n    See Also\n    --------\n    compute_effsize : Calculate effect size between two set of observations.\n    compute_effsize_from_t : Convert a T-statistic to an effect size.\n\n    Notes\n    -----\n    The formula to convert **r** to **d** is given in ref [1]:\n\n    .. math:: d = \\\\frac{2r}{\\\\sqrt{1 - r^2}}\n\n    The formula to convert **d** to **r** is given in ref [2]:\n\n    .. math::\n\n        r = \\\\frac{d}{\\\\sqrt{d^2 + \\\\frac{(n_x + n_y)^2 - 2(n_x + n_y)}\n        {n_xn_y}}}\n\n    The formula to convert **d** to :math:`\\\\eta^2` is given in ref [3]:\n\n    .. math:: \\\\eta^2 = \\\\frac{(0.5 * d)^2}{1 + (0.5 * d)^2}\n\n    The formula to convert **d** to an odds-ratio is given in ref [4]:\n\n    .. math:: OR = e(\\\\frac{d * \\\\pi}{\\\\sqrt{3}})\n\n    The formula to convert **d** to area under the curve is given in ref [5]:\n\n    .. math:: AUC = \\\\mathcal{N}_{cdf}(\\\\frac{d}{\\\\sqrt{2}})\n\n    References\n    ----------\n    .. [1] Rosenthal, Robert. \"Parametric measures of effect size.\"\n       The handbook of research synthesis 621 (1994): 231-244.\n\n    .. [2] McGrath, Robert E., and Gregory J. Meyer. \"When effect sizes\n       disagree: the case of r and d.\" Psychological methods 11.4 (2006): 386.\n\n    .. [3] Cohen, Jacob. \"Statistical power analysis for the behavioral\n       sciences. 2nd.\" (1988).\n\n    .. [4] Borenstein, Michael, et al. \"Effect sizes for continuous data.\"\n       The handbook of research synthesis and meta-analysis 2 (2009): 221-235.\n\n    .. [5] Ruscio, John. \"A probability-based measure of effect size:\n       Robustness to base rates and other factors.\" Psychological methods 1\n       3.1 (2008): 19.\n\n    Examples\n    --------\n    1. Convert from Cohen d to eta-square\n\n    >>> from pingouin import convert_effsize\n    >>> d = .45\n    >>> eta = convert_effsize(d, 'cohen', 'eta-square')\n    >>> print(eta)\n    0.048185603807257595\n\n    2. Convert from Cohen d to Hegdes g (requires the sample sizes of each\n       group)\n\n    >>> d = .45\n    >>> g = convert_effsize(d, 'cohen', 'hedges', nx=10, ny=10)\n    >>> print(g)\n    0.4309859154929578\n\n    3. Convert Pearson r to Cohen d\n\n    >>> r = 0.40\n    >>> d = convert_effsize(r, 'r', 'cohen')\n    >>> print(d)\n    0.8728715609439696\n\n    4. Reverse operation: convert Cohen d to Pearson r\n\n    >>> d = 0.873\n    >>> r = convert_effsize(d, 'cohen', 'r')\n    >>> print(r)\n    0.40004943911648533\n    \"\"\"\n    it = input_type.lower()\n    ot = output_type.lower()\n\n    # Check input and output type\n    for input in [it, ot]:\n        if not _check_eftype(input):\n            err = \"Could not interpret input '{}'\".format(input)\n            raise ValueError(err)\n    if it not in ['r', 'cohen']:\n        raise ValueError(\"Input type must be 'r' or 'cohen'\")\n\n    if it == ot:\n        return ef\n\n    d = (2 * ef) / np.sqrt(1 - ef**2) if it == 'r' else ef  # Rosenthal 1994\n\n    # Then convert to the desired output type\n    if ot == 'cohen':\n        return d\n    elif ot == 'hedges':\n        if all(v is not None for v in [nx, ny]):\n            return d * (1 - (3 / (4 * (nx + ny) - 9)))\n        else:\n            # If shapes of x and y are not known, return cohen's d\n            warnings.warn(\"You need to pass nx and ny arguments to compute \"\n                          \"Hedges g. Returning Cohen's d instead\")\n            return d\n    elif ot == 'glass':\n        warnings.warn(\"Returning original effect size instead of Glass \"\n                      \"because variance is not known.\")\n        return ef\n    elif ot == 'r':\n        # McGrath and Meyer 2006\n        if all(v is not None for v in [nx, ny]):\n            a = ((nx + ny)**2 - 2 * (nx + ny)) / (nx * ny)\n        else:\n            a = 4\n        return d / np.sqrt(d**2 + a)\n    elif ot == 'eta-square':\n        # Cohen 1988\n        return (d / 2)**2 / (1 + (d / 2)**2)\n    elif ot == 'odds-ratio':\n        # Borenstein et al. 2009\n        return np.exp(d * np.pi / np.sqrt(3))\n    elif ot in ['auc', 'cles']:\n        # Ruscio 2008\n        from scipy.stats import norm\n        return norm.cdf(d / np.sqrt(2))\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_effsize(x, y, paired=False, eftype='cohen'):\n    # Check arguments\n    if not _check_eftype(eftype):\n        err = \"Could not interpret input '{}'\".format(eftype)\n        raise ValueError(err)\n\n    x = np.asarray(x)\n    y = np.asarray(y)\n\n    if x.size != y.size and paired:\n        warnings.warn(\"x and y have unequal sizes. Switching to \"\n                      \"paired == False.\")\n        paired = False\n\n    # Remove rows with missing values\n    x, y = remove_na(x, y, paired=paired)\n    nx, ny = x.size, y.size\n\n    if ny == 1:\n        # Case 1: One-sample Test\n        d = (x.mean() - y) / x.std(ddof=1)\n        return d\n    if eftype.lower() == 'glass':\n        # Find group with lowest variance\n        sd_control = np.min([x.std(ddof=1), y.std(ddof=1)])\n        d = (x.mean() - y.mean()) / sd_control\n        return d\n    elif eftype.lower() == 'r':\n        # Return correlation coefficient (useful for CI bootstrapping)\n        from scipy.stats import pearsonr\n        r, _ = pearsonr(x, y)\n        return r\n    elif eftype.lower() == 'cles':\n        # Compute exact CLES\n        diff = x[:, None] - y\n        return max((diff < 0).sum(), (diff > 0).sum()) / diff.size\n    else:\n        # Test equality of variance of data with a stringent threshold\n        # equal_var, p = homoscedasticity(x, y, alpha=.001)\n        # if not equal_var:\n        #     print('Unequal variances (p<.001). You should report',\n        #           'Glass delta instead.')\n\n        # Compute unbiased Cohen's d effect size\n        if not paired:\n            # https://en.wikipedia.org/wiki/Effect_size\n            dof = nx + ny - 2\n            poolsd = np.sqrt(((nx - 1) * x.var(ddof=1)\n                              + (ny - 1) * y.var(ddof=1)) / dof)\n            d = (x.mean() - y.mean()) / poolsd\n        else:\n            # Report Cohen d-avg (Cumming 2012; Lakens 2013)\n            d = (x.mean() - y.mean()) / (.5 * (x.std(ddof=1)\n                                               + y.std(ddof=1)))\n        return convert_effsize(d, 'cohen', eftype, nx=nx, ny=ny)", "response": "Compute the effect size between two sets of observations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_effsize_from_t(tval, nx=None, ny=None, N=None, eftype='cohen'):\n    if not _check_eftype(eftype):\n        err = \"Could not interpret input '{}'\".format(eftype)\n        raise ValueError(err)\n\n    if not isinstance(tval, float):\n        err = \"T-value must be float\"\n        raise ValueError(err)\n\n    # Compute Cohen d (Lakens, 2013)\n    if nx is not None and ny is not None:\n        d = tval * np.sqrt(1 / nx + 1 / ny)\n    elif N is not None:\n        d = 2 * tval / np.sqrt(N)\n    else:\n        raise ValueError('You must specify either nx + ny, or just N')\n    return convert_effsize(d, 'cohen', eftype, nx=nx, ny=ny)", "response": "Compute effect size from a T - value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef skipped(x, y, method='spearman'):\n    # Check that sklearn is installed\n    from pingouin.utils import _is_sklearn_installed\n    _is_sklearn_installed(raise_error=True)\n    from scipy.stats import chi2\n    from sklearn.covariance import MinCovDet\n    X = np.column_stack((x, y))\n    nrows, ncols = X.shape\n    gval = np.sqrt(chi2.ppf(0.975, 2))\n\n    # Compute center and distance to center\n    center = MinCovDet(random_state=42).fit(X).location_\n    B = X - center\n    B2 = B**2\n    bot = B2.sum(axis=1)\n\n    # Loop over rows\n    dis = np.zeros(shape=(nrows, nrows))\n    for i in np.arange(nrows):\n        if bot[i] != 0:\n            dis[i, :] = np.linalg.norm(B * B2[i, :] / bot[i], axis=1)\n\n    # Detect outliers\n    def idealf(x):\n        \"\"\"Compute the ideal fourths IQR (Wilcox 2012).\n        \"\"\"\n        n = len(x)\n        j = int(np.floor(n / 4 + 5 / 12))\n        y = np.sort(x)\n        g = (n / 4) - j + (5 / 12)\n        low = (1 - g) * y[j - 1] + g * y[j]\n        k = n - j + 1\n        up = (1 - g) * y[k - 1] + g * y[k - 2]\n        return up - low\n\n    # One can either use the MAD or the IQR (see Wilcox 2012)\n    # MAD = mad(dis, axis=1)\n    iqr = np.apply_along_axis(idealf, 1, dis)\n    thresh = (np.median(dis, axis=1) + gval * iqr)\n    outliers = np.apply_along_axis(np.greater, 0, dis, thresh).any(axis=0)\n\n    # Compute correlation on remaining data\n    if method == 'spearman':\n        r, pval = spearmanr(X[~outliers, 0], X[~outliers, 1])\n    else:\n        r, pval = pearsonr(X[~outliers, 0], X[~outliers, 1])\n    return r, pval, outliers", "response": "Returns the skipped correlation coefficient for the given observations x and y."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbootstraps Mahalanobis distances for each row in a and average across all the bootstraps.", "response": "def bsmahal(a, b, n_boot=200):\n    \"\"\"\n    Bootstraps Mahalanobis distances for Shepherd's pi correlation.\n\n    Parameters\n    ----------\n    a : ndarray (shape=(n, 2))\n        Data\n    b : ndarray (shape=(n, 2))\n        Data\n    n_boot : int\n        Number of bootstrap samples to calculate.\n\n    Returns\n    -------\n    m : ndarray (shape=(n,))\n        Mahalanobis distance for each row in a, averaged across all the\n        bootstrap resamples.\n    \"\"\"\n    n, m = b.shape\n    MD = np.zeros((n, n_boot))\n    nr = np.arange(n)\n    xB = np.random.choice(nr, size=(n_boot, n), replace=True)\n\n    # Bootstrap the MD\n    for i in np.arange(n_boot):\n        s1 = b[xB[i, :], 0]\n        s2 = b[xB[i, :], 1]\n        X = np.column_stack((s1, s2))\n        mu = X.mean(0)\n        _, R = np.linalg.qr(X - mu)\n        sol = np.linalg.solve(R.T, (a - mu).T)\n        MD[:, i] = np.sum(sol**2, 0) * (n - 1)\n\n    # Average across all bootstraps\n    return MD.mean(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shepherd(x, y, n_boot=200):\n    from scipy.stats import spearmanr\n\n    X = np.column_stack((x, y))\n\n    # Bootstrapping on Mahalanobis distance\n    m = bsmahal(X, X, n_boot)\n\n    # Determine outliers\n    outliers = (m >= 6)\n\n    # Compute correlation\n    r, pval = spearmanr(x[~outliers], y[~outliers])\n\n    # (optional) double the p-value to achieve a nominal false alarm rate\n    # pval *= 2\n    # pval = 1 if pval > 1 else pval\n\n    return r, pval, outliers", "response": "Shepherd s Pi correlation coefficient equivalent to Spearman s rho after outliers\n    removal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef percbend(x, y, beta=.2):\n    from scipy.stats import t\n    X = np.column_stack((x, y))\n    nx = X.shape[0]\n    M = np.tile(np.median(X, axis=0), nx).reshape(X.shape)\n    W = np.sort(np.abs(X - M), axis=0)\n    m = int((1 - beta) * nx)\n    omega = W[m - 1, :]\n    P = (X - M) / omega\n    P[np.isinf(P)] = 0\n    P[np.isnan(P)] = 0\n\n    # Loop over columns\n    a = np.zeros((2, nx))\n    for c in [0, 1]:\n        psi = P[:, c]\n        i1 = np.where(psi < -1)[0].size\n        i2 = np.where(psi > 1)[0].size\n        s = X[:, c].copy()\n        s[np.where(psi < -1)[0]] = 0\n        s[np.where(psi > 1)[0]] = 0\n        pbos = (np.sum(s) + omega[c] * (i2 - i1)) / (s.size - i1 - i2)\n        a[c] = (X[:, c] - pbos) / omega[c]\n\n    # Bend\n    a[a <= -1] = -1\n    a[a >= 1] = 1\n\n    # Get r, tval and pval\n    a, b = a\n    r = (a * b).sum() / np.sqrt((a**2).sum() * (b**2).sum())\n    tval = r * np.sqrt((nx - 2) / (1 - r**2))\n    pval = 2 * t.sf(abs(tval), nx - 2)\n    return r, pval", "response": "This function calculates the percentage bend correlation coefficient for a set of observations x and y."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the correlation between two variables.", "response": "def corr(x, y, tail='two-sided', method='pearson'):\n    \"\"\"(Robust) correlation between two variables.\n\n    Parameters\n    ----------\n    x, y : array_like\n        First and second set of observations. x and y must be independent.\n    tail : string\n        Specify whether to return 'one-sided' or 'two-sided' p-value.\n    method : string\n        Specify which method to use for the computation of the correlation\n        coefficient. Available methods are ::\n\n        'pearson' : Pearson product-moment correlation\n        'spearman' : Spearman rank-order correlation\n        'kendall' : Kendall\u2019s tau (ordinal data)\n        'percbend' : percentage bend correlation (robust)\n        'shepherd' : Shepherd's pi correlation (robust Spearman)\n        'skipped' : skipped correlation (robust Spearman, requires sklearn)\n\n    Returns\n    -------\n    stats : pandas DataFrame\n        Test summary ::\n\n        'n' : Sample size (after NaN removal)\n        'outliers' : number of outliers (only for 'shepherd' or 'skipped')\n        'r' : Correlation coefficient\n        'CI95' : 95% parametric confidence intervals\n        'r2' : R-squared\n        'adj_r2' : Adjusted R-squared\n        'p-val' : one or two tailed p-value\n        'BF10' : Bayes Factor of the alternative hypothesis (Pearson only)\n        'power' : achieved power of the test (= 1 - type II error).\n\n    See also\n    --------\n    pairwise_corr : Pairwise correlation between columns of a pandas DataFrame\n    partial_corr : Partial correlation\n\n    Notes\n    -----\n    The Pearson correlation coefficient measures the linear relationship\n    between two datasets. Strictly speaking, Pearson's correlation requires\n    that each dataset be normally distributed. Correlations of -1 or +1 imply\n    an exact linear relationship.\n\n    The Spearman correlation is a nonparametric measure of the monotonicity of\n    the relationship between two datasets. Unlike the Pearson correlation,\n    the Spearman correlation does not assume that both datasets are normally\n    distributed. Correlations of -1 or +1 imply an exact monotonic\n    relationship.\n\n    Kendall\u2019s tau is a measure of the correspondence between two rankings.\n    Values close to 1 indicate strong agreement, values close to -1 indicate\n    strong disagreement.\n\n    The percentage bend correlation [1]_ is a robust method that\n    protects against univariate outliers.\n\n    The Shepherd's pi [2]_ and skipped [3]_, [4]_ correlations are both robust\n    methods that returns the Spearman's rho after bivariate outliers removal.\n    Note that the skipped correlation requires that the scikit-learn\n    package is installed (for computing the minimum covariance determinant).\n\n    Please note that rows with NaN are automatically removed.\n\n    If method='pearson', The JZS Bayes Factor is approximated using the\n    :py:func:`pingouin.bayesfactor_pearson` function.\n\n    References\n    ----------\n    .. [1] Wilcox, R.R., 1994. The percentage bend correlation coefficient.\n       Psychometrika 59, 601\u2013616. https://doi.org/10.1007/BF02294395\n\n    .. [2] Schwarzkopf, D.S., De Haas, B., Rees, G., 2012. Better ways to\n       improve standards in brain-behavior correlation analysis. Front.\n       Hum. Neurosci. 6, 200. https://doi.org/10.3389/fnhum.2012.00200\n\n    .. [3] Rousselet, G.A., Pernet, C.R., 2012. Improving standards in\n       brain-behavior correlation analyses. Front. Hum. Neurosci. 6, 119.\n       https://doi.org/10.3389/fnhum.2012.00119\n\n    .. [4] Pernet, C.R., Wilcox, R., Rousselet, G.A., 2012. Robust correlation\n       analyses: false positive and power validation using a new open\n       source matlab toolbox. Front. Psychol. 3, 606.\n       https://doi.org/10.3389/fpsyg.2012.00606\n\n    Examples\n    --------\n    1. Pearson correlation\n\n    >>> import numpy as np\n    >>> # Generate random correlated samples\n    >>> np.random.seed(123)\n    >>> mean, cov = [4, 6], [(1, .5), (.5, 1)]\n    >>> x, y = np.random.multivariate_normal(mean, cov, 30).T\n    >>> # Compute Pearson correlation\n    >>> from pingouin import corr\n    >>> corr(x, y)\n              n      r         CI95%     r2  adj_r2     p-val   BF10  power\n    pearson  30  0.491  [0.16, 0.72]  0.242   0.185  0.005813  6.135  0.809\n\n    2. Pearson correlation with two outliers\n\n    >>> x[3], y[5] = 12, -8\n    >>> corr(x, y)\n              n      r          CI95%     r2  adj_r2     p-val  BF10  power\n    pearson  30  0.147  [-0.23, 0.48]  0.022  -0.051  0.439148  0.19  0.121\n\n    3. Spearman correlation\n\n    >>> corr(x, y, method=\"spearman\")\n               n      r         CI95%     r2  adj_r2     p-val  power\n    spearman  30  0.401  [0.05, 0.67]  0.161   0.099  0.028034   0.61\n\n    4. Percentage bend correlation (robust)\n\n    >>> corr(x, y, method='percbend')\n               n      r         CI95%     r2  adj_r2     p-val  power\n    percbend  30  0.389  [0.03, 0.66]  0.151   0.089  0.033508  0.581\n\n    5. Shepherd's pi correlation (robust)\n\n    >>> corr(x, y, method='shepherd')\n               n  outliers      r         CI95%     r2  adj_r2     p-val  power\n    shepherd  30         2  0.437  [0.09, 0.69]  0.191   0.131  0.020128  0.694\n\n    6. Skipped spearman correlation (robust)\n\n    >>> corr(x, y, method='skipped')\n              n  outliers      r         CI95%     r2  adj_r2     p-val  power\n    skipped  30         2  0.437  [0.09, 0.69]  0.191   0.131  0.020128  0.694\n\n    7. One-tailed Spearman correlation\n\n    >>> corr(x, y, tail=\"one-sided\", method='spearman')\n               n      r         CI95%     r2  adj_r2     p-val  power\n    spearman  30  0.401  [0.05, 0.67]  0.161   0.099  0.014017  0.726\n\n    8. Using columns of a pandas dataframe\n\n    >>> import pandas as pd\n    >>> data = pd.DataFrame({'x': x, 'y': y})\n    >>> corr(data['x'], data['y'])\n              n      r          CI95%     r2  adj_r2     p-val  BF10  power\n    pearson  30  0.147  [-0.23, 0.48]  0.022  -0.051  0.439148  0.19  0.121\n    \"\"\"\n    x = np.asarray(x)\n    y = np.asarray(y)\n\n    # Check size\n    if x.size != y.size:\n        raise ValueError('x and y must have the same length.')\n\n    # Remove NA\n    x, y = remove_na(x, y, paired=True)\n    nx = x.size\n\n    # Compute correlation coefficient\n    if method == 'pearson':\n        r, pval = pearsonr(x, y)\n    elif method == 'spearman':\n        r, pval = spearmanr(x, y)\n    elif method == 'kendall':\n        r, pval = kendalltau(x, y)\n    elif method == 'percbend':\n        r, pval = percbend(x, y)\n    elif method == 'shepherd':\n        r, pval, outliers = shepherd(x, y)\n    elif method == 'skipped':\n        r, pval, outliers = skipped(x, y, method='spearman')\n    else:\n        raise ValueError('Method not recognized.')\n\n    assert not np.isnan(r), 'Correlation returned NaN. Check your data.'\n\n    # Compute r2 and adj_r2\n    r2 = r**2\n    adj_r2 = 1 - (((1 - r2) * (nx - 1)) / (nx - 3))\n\n    # Compute the parametric 95% confidence interval and power\n    if r2 < 1:\n        ci = compute_esci(stat=r, nx=nx, ny=nx, eftype='r')\n        pr = round(power_corr(r=r, n=nx, power=None, alpha=0.05, tail=tail), 3)\n    else:\n        ci = [1., 1.]\n        pr = np.inf\n\n    # Create dictionnary\n    stats = {'n': nx,\n             'r': round(r, 3),\n             'r2': round(r2, 3),\n             'adj_r2': round(adj_r2, 3),\n             'CI95%': [ci],\n             'p-val': pval if tail == 'two-sided' else .5 * pval,\n             'power': pr\n             }\n\n    if method in ['shepherd', 'skipped']:\n        stats['outliers'] = sum(outliers)\n\n    # Compute the BF10 for Pearson correlation only\n    if method == 'pearson' and nx < 1000:\n        if r2 < 1:\n            stats['BF10'] = bayesfactor_pearson(r, nx)\n        else:\n            stats['BF10'] = str(np.inf)\n\n    # Convert to DataFrame\n    stats = pd.DataFrame.from_records(stats, index=[method])\n\n    # Define order\n    col_keep = ['n', 'outliers', 'r', 'CI95%', 'r2', 'adj_r2', 'p-val',\n                'BF10', 'power']\n    col_order = [k for k in col_keep if k in stats.keys().tolist()]\n    return stats[col_order]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rm_corr(data=None, x=None, y=None, subject=None, tail='two-sided'):\n    from pingouin import ancova, power_corr\n    # Safety checks\n    assert isinstance(data, pd.DataFrame), 'Data must be a DataFrame'\n    assert x in data, 'The %s column is not in data.' % x\n    assert y in data, 'The %s column is not in data.' % y\n    assert subject in data, 'The %s column is not in data.' % subject\n    if data[subject].nunique() < 3:\n        raise ValueError('rm_corr requires at least 3 unique subjects.')\n    # Remove missing values\n    data = data[[x, y, subject]].dropna(axis=0)\n\n    # Using PINGOUIN\n    aov, bw = ancova(dv=y, covar=x, between=subject, data=data,\n                     return_bw=True)\n    sign = np.sign(bw)\n    dof = int(aov.loc[2, 'DF'])\n    n = dof + 2\n    ssfactor = aov.loc[1, 'SS']\n    sserror = aov.loc[2, 'SS']\n    rm = sign * np.sqrt(ssfactor / (ssfactor + sserror))\n    pval = aov.loc[1, 'p-unc']\n    pval *= 0.5 if tail == 'one-sided' else 1\n    ci = compute_esci(stat=rm, nx=n, eftype='pearson').tolist()\n    pwr = power_corr(r=rm, n=n, tail=tail)\n    # Convert to Dataframe\n    stats = pd.DataFrame({\"r\": round(rm, 3), \"dof\": int(dof),\n                          \"pval\": pval, \"CI95%\": str(ci),\n                          \"power\": round(pwr, 3)}, index=[\"rm_corr\"])\n    return stats", "response": "Returns a new record set that is a set of non - independence measures that are used to compute the common within - individual association between two variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _dcorr(y, n2, A, dcov2_xx):\n    # Pairwise Euclidean distances\n    b = squareform(pdist(y, metric='euclidean'))\n    # Double centering\n    B = b - b.mean(axis=0)[None, :] - b.mean(axis=1)[:, None] + b.mean()\n    # Compute squared distance covariances\n    dcov2_yy = np.vdot(B, B) / n2\n    dcov2_xy = np.vdot(A, B) / n2\n    return np.sqrt(dcov2_xy) / np.sqrt(np.sqrt(dcov2_xx) * np.sqrt(dcov2_yy))", "response": "Helper function for distance correlation bootstrapping."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the distance correlation between two arrays.", "response": "def distance_corr(x, y, tail='upper', n_boot=1000, seed=None):\n    \"\"\"Distance correlation between two arrays.\n\n    Statistical significance (p-value) is evaluated with a permutation test.\n\n    Parameters\n    ----------\n    x, y : np.ndarray\n        1D or 2D input arrays, shape (n_samples, n_features).\n        x and y must have the same number of samples and must not\n        contain missing values.\n    tail : str\n        Tail for p-value ::\n\n        'upper' : one-sided (upper tail)\n        'lower' : one-sided (lower tail)\n        'two-sided' : two-sided\n\n    n_boot : int or None\n        Number of bootstrap to perform.\n        If None, no bootstrapping is performed and the function\n        only returns the distance correlation (no p-value).\n        Default is 1000 (thus giving a precision of 0.001).\n    seed : int or None\n        Random state seed.\n\n    Returns\n    -------\n    dcor : float\n        Sample distance correlation (range from 0 to 1).\n    pval : float\n        P-value\n\n    Notes\n    -----\n    From Wikipedia:\n\n    *Distance correlation is a measure of dependence between two paired\n    random vectors of arbitrary, not necessarily equal, dimension. The\n    distance correlation coefficient is zero if and only if the random vectors\n    are independent. Thus, distance correlation measures both linear and\n    nonlinear association between two random variables or random vectors.\n    This is in contrast to Pearson's correlation, which can only detect\n    linear association between two random variables.*\n\n    The distance correlation of two random variables is obtained by\n    dividing their distance covariance by the product of their distance\n    standard deviations:\n\n    .. math::\n\n        \\\\text{dCor}(X, Y) = \\\\frac{\\\\text{dCov}(X, Y)}\n        {\\\\sqrt{\\\\text{dVar}(X) \\\\cdot \\\\text{dVar}(Y)}}\n\n    where :math:`\\\\text{dCov}(X, Y)` is the square root of the arithmetic\n    average of the product of the double-centered pairwise Euclidean distance\n    matrices.\n\n    Note that by contrast to Pearson's correlation, the distance correlation\n    cannot be negative, i.e :math:`0 \\\\leq \\\\text{dCor} \\\\leq 1`.\n\n    Results have been tested against the 'energy' R package. To be consistent\n    with this latter, only the one-sided p-value is computed, i.e. the upper\n    tail of the T-statistic.\n\n    References\n    ----------\n    .. [1] https://en.wikipedia.org/wiki/Distance_correlation\n\n    .. [2] Sz\u00e9kely, G. J., Rizzo, M. L., & Bakirov, N. K. (2007).\n           Measuring and testing dependence by correlation of distances.\n           The annals of statistics, 35(6), 2769-2794.\n\n    .. [3] https://gist.github.com/satra/aa3d19a12b74e9ab7941\n\n    .. [4] https://gist.github.com/wladston/c931b1495184fbb99bec\n\n    .. [5] https://cran.r-project.org/web/packages/energy/energy.pdf\n\n    Examples\n    --------\n    1. With two 1D vectors\n\n    >>> from pingouin import distance_corr\n    >>> a = [1, 2, 3, 4, 5]\n    >>> b = [1, 2, 9, 4, 4]\n    >>> distance_corr(a, b, seed=9)\n    (0.7626762424168667, 0.312)\n\n    2. With two 2D arrays and no p-value\n\n    >>> import numpy as np\n    >>> np.random.seed(123)\n    >>> from pingouin import distance_corr\n    >>> a = np.random.random((10, 10))\n    >>> b = np.random.random((10, 10))\n    >>> distance_corr(a, b, n_boot=None)\n    0.8799633012275321\n    \"\"\"\n    assert tail in ['upper', 'lower', 'two-sided'], 'Wrong tail argument.'\n    x = np.asarray(x)\n    y = np.asarray(y)\n    # Check for NaN values\n    if any([np.isnan(np.min(x)), np.isnan(np.min(y))]):\n        raise ValueError('Input arrays must not contain NaN values.')\n    if x.ndim == 1:\n        x = x[:, None]\n    if y.ndim == 1:\n        y = y[:, None]\n    assert x.shape[0] == y.shape[0], 'x and y must have same number of samples'\n\n    # Extract number of samples\n    n = x.shape[0]\n    n2 = n**2\n\n    # Process first array to avoid redundancy when performing bootstrap\n    a = squareform(pdist(x, metric='euclidean'))\n    A = a - a.mean(axis=0)[None, :] - a.mean(axis=1)[:, None] + a.mean()\n    dcov2_xx = np.vdot(A, A) / n2\n\n    # Process second array and compute final distance correlation\n    dcor = _dcorr(y, n2, A, dcov2_xx)\n\n    # Compute one-sided p-value using a bootstrap procedure\n    if n_boot is not None and n_boot > 1:\n        # Define random seed and permutation\n        rng = np.random.RandomState(seed)\n        bootsam = rng.random_sample((n_boot, n)).argsort(axis=1)\n        bootstat = np.empty(n_boot)\n        for i in range(n_boot):\n            bootstat[i] = _dcorr(y[bootsam[i, :]], n2, A, dcov2_xx)\n\n        pval = _perm_pval(bootstat, dcor, tail=tail)\n        return dcor, pval\n    else:\n        return dcor"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logistic_regression(X, y, coef_only=False, alpha=0.05,\n                        as_dataframe=True, remove_na=False, **kwargs):\n    \"\"\"(Multiple) Binary logistic regression.\n\n    Parameters\n    ----------\n    X : np.array or list\n        Predictor(s). Shape = (n_samples, n_features) or (n_samples,).\n    y : np.array or list\n        Dependent variable. Shape = (n_samples).\n        Must be binary.\n    coef_only : bool\n        If True, return only the regression coefficients.\n    alpha : float\n        Alpha value used for the confidence intervals.\n        CI = [alpha / 2 ; 1 - alpha / 2]\n    as_dataframe : bool\n        If True, returns a pandas DataFrame. If False, returns a dictionnary.\n    remove_na : bool\n        If True, apply a listwise deletion of missing values (i.e. the entire\n        row is removed).\n    **kwargs : optional\n        Optional arguments passed to sklearn.linear_model.LogisticRegression.\n\n    Returns\n    -------\n    stats : dataframe or dict\n        Logistic regression summary::\n\n        'names' : name of variable(s) in the model (e.g. x1, x2...)\n        'coef' : regression coefficients\n        'se' : standard error\n        'z' : z-scores\n        'pval' : two-tailed p-values\n        'CI[2.5%]' : lower confidence interval\n        'CI[97.5%]' : upper confidence interval\n\n    Notes\n    -----\n    This is a wrapper around the\n    :py:class:`sklearn.linear_model.LogisticRegression` class.\n\n    Results have been compared against statsmodels and JASP.\n\n    Note that the first coefficient is always the constant term (intercept) of\n    the model.\n\n    This function will not run if NaN values are either present in the target\n    or predictors variables. Please remove them before runing the function.\n\n    Adapted from a code found at\n    https://gist.github.com/rspeare/77061e6e317896be29c6de9a85db301d\n\n    Examples\n    --------\n    1. Simple binary logistic regression\n\n    >>> import numpy as np\n    >>> from pingouin import logistic_regression\n    >>> np.random.seed(123)\n    >>> x = np.random.normal(size=30)\n    >>> y = np.random.randint(0, 2, size=30)\n    >>> lom = logistic_regression(x, y)\n    >>> lom.round(2)\n           names  coef    se     z  pval  CI[2.5%]  CI[97.5%]\n    0  Intercept -0.27  0.37 -0.73  0.46     -0.99       0.45\n    1         x1  0.06  0.32  0.19  0.85     -0.56       0.68\n\n    2. Multiple binary logistic regression\n\n    >>> np.random.seed(42)\n    >>> z = np.random.normal(size=30)\n    >>> X = np.column_stack((x, z))\n    >>> lom = logistic_regression(X, y)\n    >>> print(lom['coef'].values)\n    [-0.34933805 -0.0226106  -0.39453532]\n\n    3. Using a Pandas DataFrame\n\n    >>> import pandas as pd\n    >>> df = pd.DataFrame({'x': x, 'y': y, 'z': z})\n    >>> lom = logistic_regression(df[['x', 'z']], df['y'])\n    >>> print(lom['coef'].values)\n    [-0.34933805 -0.0226106  -0.39453532]\n\n    4. Return only the coefficients\n\n    >>> logistic_regression(X, y, coef_only=True)\n    array([-0.34933805, -0.0226106 , -0.39453532])\n\n    4. Passing custom parameters to sklearn\n\n    >>> lom = logistic_regression(X, y, solver='sag', max_iter=10000)\n    >>> print(lom['coef'].values)\n    [-0.34941889 -0.02261911 -0.39451064]\n    \"\"\"\n    # Check that sklearn is installed\n    from pingouin.utils import _is_sklearn_installed\n    _is_sklearn_installed(raise_error=True)\n    from sklearn.linear_model import LogisticRegression\n\n    # Extract names if X is a Dataframe or Series\n    if isinstance(X, pd.DataFrame):\n        names = X.keys().tolist()\n    elif isinstance(X, pd.Series):\n        names = [X.name]\n    else:\n        names = []\n\n    assert 0 < alpha < 1\n    assert y.ndim == 1, 'y must be one-dimensional.'\n\n    # Convert to numpy array\n    X = np.asarray(X)\n    y = np.asarray(y)\n\n    # Add axis if only one-dimensional array\n    if X.ndim == 1:\n        X = X[..., np.newaxis]\n\n    # Check for NaN /  Inf\n    if remove_na:\n        X, y = rm_na(X, y[..., np.newaxis], paired=True, axis='rows')\n        y = np.squeeze(y)\n    y_gd = np.isfinite(y).all()\n    X_gd = np.isfinite(X).all()\n    assert y_gd, 'Target variable contains NaN or Inf. Please remove them.'\n    assert X_gd, 'Predictors contains NaN or Inf. Please remove them.'\n\n    # Check that X and y have same length\n    assert y.shape[0] == X.shape[0], 'X and y must have same number of samples'\n\n    # Check that y is binary\n    if np.unique(y).size != 2:\n        raise ValueError('Dependent variable must be binary.')\n\n    if not names:\n        names = ['x' + str(i + 1) for i in range(X.shape[1])]\n\n    # Add intercept in names\n    names.insert(0, \"Intercept\")\n\n    # Initialize and fit\n    if 'solver' not in kwargs:\n        kwargs['solver'] = 'lbfgs'\n    if 'multi_class' not in kwargs:\n        kwargs['multi_class'] = 'auto'\n    lom = LogisticRegression(**kwargs)\n    lom.fit(X, y)\n    coef = np.append(lom.intercept_, lom.coef_)\n    if coef_only:\n        return coef\n\n    # Design matrix -- add intercept\n    X_design = np.column_stack((np.ones(X.shape[0]), X))\n    n, p = X_design.shape\n\n    # Fisher Information Matrix\n    denom = (2 * (1 + np.cosh(lom.decision_function(X))))\n    denom = np.tile(denom, (p, 1)).T\n    fim = np.dot((X_design / denom).T, X_design)\n    crao = np.linalg.inv(fim)\n\n    # Standard error and Z-scores\n    se = np.sqrt(np.diag(crao))\n    z_scores = coef / se\n\n    # Two-tailed p-values\n    pval = np.array([2 * norm.sf(abs(z)) for z in z_scores])\n\n    # Confidence intervals\n    crit = norm.ppf(1 - alpha / 2)\n    ll = coef - crit * se\n    ul = coef + crit * se\n\n    # Rename CI\n    ll_name = 'CI[%.1f%%]' % (100 * alpha / 2)\n    ul_name = 'CI[%.1f%%]' % (100 * (1 - alpha / 2))\n\n    # Create dict\n    stats = {'names': names, 'coef': coef, 'se': se, 'z': z_scores,\n             'pval': pval, ll_name: ll, ul_name: ul}\n    if as_dataframe:\n        return pd.DataFrame.from_dict(stats)\n    else:\n        return stats", "response": "(Multiple) Binary logistic regression.\n\n    Parameters\n    ----------\n    X : np.array or list\n        Predictor(s). Shape = (n_samples, n_features) or (n_samples,).\n    y : np.array or list\n        Dependent variable. Shape = (n_samples).\n        Must be binary.\n    coef_only : bool\n        If True, return only the regression coefficients.\n    alpha : float\n        Alpha value used for the confidence intervals.\n        CI = [alpha / 2 ; 1 - alpha / 2]\n    as_dataframe : bool\n        If True, returns a pandas DataFrame. If False, returns a dictionnary.\n    remove_na : bool\n        If True, apply a listwise deletion of missing values (i.e. the entire\n        row is removed).\n    **kwargs : optional\n        Optional arguments passed to sklearn.linear_model.LogisticRegression.\n\n    Returns\n    -------\n    stats : dataframe or dict\n        Logistic regression summary::\n\n        'names' : name of variable(s) in the model (e.g. x1, x2...)\n        'coef' : regression coefficients\n        'se' : standard error\n        'z' : z-scores\n        'pval' : two-tailed p-values\n        'CI[2.5%]' : lower confidence interval\n        'CI[97.5%]' : upper confidence interval\n\n    Notes\n    -----\n    This is a wrapper around the\n    :py:class:`sklearn.linear_model.LogisticRegression` class.\n\n    Results have been compared against statsmodels and JASP.\n\n    Note that the first coefficient is always the constant term (intercept) of\n    the model.\n\n    This function will not run if NaN values are either present in the target\n    or predictors variables. Please remove them before runing the function.\n\n    Adapted from a code found at\n    https://gist.github.com/rspeare/77061e6e317896be29c6de9a85db301d\n\n    Examples\n    --------\n    1. Simple binary logistic regression\n\n    >>> import numpy as np\n    >>> from pingouin import logistic_regression\n    >>> np.random.seed(123)\n    >>> x = np.random.normal(size=30)\n    >>> y = np.random.randint(0, 2, size=30)\n    >>> lom = logistic_regression(x, y)\n    >>> lom.round(2)\n           names  coef    se     z  pval  CI[2.5%]  CI[97.5%]\n    0  Intercept -0.27  0.37 -0.73  0.46     -0.99       0.45\n    1         x1  0.06  0.32  0.19  0.85     -0.56       0.68\n\n    2. Multiple binary logistic regression\n\n    >>> np.random.seed(42)\n    >>> z = np.random.normal(size=30)\n    >>> X = np.column_stack((x, z))\n    >>> lom = logistic_regression(X, y)\n    >>> print(lom['coef'].values)\n    [-0.34933805 -0.0226106  -0.39453532]\n\n    3. Using a Pandas DataFrame\n\n    >>> import pandas as pd\n    >>> df = pd.DataFrame({'x': x, 'y': y, 'z': z})\n    >>> lom = logistic_regression(df[['x', 'z']], df['y'])\n    >>> print(lom['coef'].values)\n    [-0.34933805 -0.0226106  -0.39453532]\n\n    4. Return only the coefficients\n\n    >>> logistic_regression(X, y, coef_only=True)\n    array([-0.34933805, -0.0226106 , -0.39453532])\n\n    4. Passing custom parameters to sklearn\n\n    >>> lom = logistic_regression(X, y, solver='sag', max_iter=10000)\n    >>> print(lom['coef'].values)\n    [-0.34941889 -0.02261911 -0.39451064]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npoints estimate based on bootstrap sample.", "response": "def _point_estimate(X_val, XM_val, M_val, y_val, idx, n_mediator,\n                    mtype='linear'):\n    \"\"\"Point estimate of indirect effect based on bootstrap sample.\"\"\"\n    # Mediator(s) model (M(j) ~ X + covar)\n    beta_m = []\n    for j in range(n_mediator):\n        if mtype == 'linear':\n            beta_m.append(linear_regression(X_val[idx], M_val[idx, j],\n                                            coef_only=True)[1])\n        else:\n            beta_m.append(logistic_regression(X_val[idx], M_val[idx, j],\n                                              coef_only=True)[1])\n\n    # Full model (Y ~ X + M + covar)\n    beta_y = linear_regression(XM_val[idx], y_val[idx],\n                               coef_only=True)[2:(2 + n_mediator)]\n\n    # Point estimate\n    return beta_m * beta_y"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the bias corrected confidence interval estimate for a single bootstrap sample.", "response": "def _bca(ab_estimates, sample_point, n_boot, alpha=0.05):\n    \"\"\"Get (1 - alpha) * 100 bias-corrected confidence interval estimate\n\n    Note that this is similar to the \"cper\" module implemented in\n    :py:func:`pingouin.compute_bootci`.\n\n    Parameters\n    ----------\n    ab_estimates : 1d array-like\n        Array with bootstrap estimates for each sample.\n    sample_point : float\n        Indirect effect point estimate based on full sample.\n    n_boot : int\n        Number of bootstrap samples\n    alpha : float\n        Alpha for confidence interval\n\n    Returns\n    -------\n    CI : 1d array-like\n        Lower limit and upper limit bias-corrected confidence interval\n        estimates.\n    \"\"\"\n    # Bias of bootstrap estimates\n    z0 = norm.ppf(np.sum(ab_estimates < sample_point) / n_boot)\n\n    # Adjusted intervals\n    adjusted_ll = norm.cdf(2 * z0 + norm.ppf(alpha / 2)) * 100\n    adjusted_ul = norm.cdf(2 * z0 + norm.ppf(1 - alpha / 2)) * 100\n    ll = np.percentile(ab_estimates, q=adjusted_ll)\n    ul = np.percentile(ab_estimates, q=adjusted_ul)\n    return np.array([ll, ul])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes p - value from bootstrap distribution.", "response": "def _pval_from_bootci(boot, estimate):\n    \"\"\"Compute p-value from bootstrap distribution.\n    Similar to the pval function in the R package mediation.\n    Note that this is less accurate than a permutation test because the\n    bootstrap distribution is not conditioned on a true null hypothesis.\n    \"\"\"\n    if estimate == 0:\n        out = 1\n    else:\n        out = 2 * min(sum(boot > 0), sum(boot < 0)) / len(boot)\n    return min(out, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mediation_analysis(data=None, x=None, m=None, y=None, covar=None,\n                       alpha=0.05, n_boot=500, seed=None, return_dist=False):\n    \"\"\"Mediation analysis using a bias-correct non-parametric bootstrap method.\n\n    Parameters\n    ----------\n    data : pd.DataFrame\n        Dataframe.\n    x : str\n        Column name in data containing the predictor variable.\n        The predictor variable must be continuous.\n    m : str or list of str\n        Column name(s) in data containing the mediator variable(s).\n        The mediator(s) can be continuous or binary (e.g. 0 or 1).\n        This function supports multiple parallel mediators.\n    y : str\n        Column name in data containing the outcome variable.\n        The outcome variable must be continuous.\n    covar : None, str, or list\n        Covariate(s). If not None, the specified covariate(s) will be included\n        in all regressions.\n    alpha : float\n        Significance threshold. Used to determine the confidence interval,\n        CI = [ alpha / 2 ; 1 -  alpha / 2]\n    n_boot : int\n        Number of bootstrap iterations for confidence intervals and p-values\n        estimation. The greater, the slower.\n    seed : int or None\n        Random state seed.\n    return_dist : bool\n        If True, the function also returns the indirect bootstrapped beta\n        samples (size = n_boot). Can be plotted for instance using\n        :py:func:`seaborn.distplot()` or :py:func:`seaborn.kdeplot()`\n        functions.\n\n    Returns\n    -------\n    stats : pd.DataFrame\n        Mediation summary::\n\n        'path' : regression model\n        'coef' : regression estimates\n        'se' : standard error\n        'CI[2.5%]' : lower confidence interval\n        'CI[97.5%]' : upper confidence interval\n        'pval' : two-sided p-values\n        'sig' : statistical significance\n\n    Notes\n    -----\n    Mediation analysis is a \"statistical procedure to test\n    whether the effect of an independent variable X on a dependent variable\n    Y (i.e., X \u2192 Y) is at least partly explained by a chain of effects of the\n    independent variable on an intervening mediator variable M and of the\n    intervening variable on the dependent variable (i.e., X \u2192 M \u2192 Y)\"\n    (from Fiedler et al. 2011).\n\n    The **indirect effect** (also referred to as average causal mediation\n    effect or ACME) of X on Y through mediator M quantifies the estimated\n    difference in Y resulting from a one-unit change in X through a sequence of\n    causal steps in which X affects M, which in turn affects Y.\n    It is considered significant if the specified confidence interval does not\n    include 0. The path 'X --> Y' is the sum of both the indirect and direct\n    effect. It is sometimes referred to as total effect. For more details,\n    please refer to Fiedler et al 2011 or Hayes and Rockwood 2017.\n\n    A linear regression is used if the mediator variable is continuous and a\n    logistic regression if the mediator variable is dichotomous (binary). Note\n    that this function also supports parallel multiple mediators: \"in such\n    models, mediators may be and often are correlated, but nothing in the\n    model allows one mediator to causally influence another.\"\n    (Hayes and Rockwood 2017)\n\n    This function wll only work well if the outcome variable is continuous.\n    It does not support binary or ordinal outcome variable. For more\n    advanced mediation models, please refer to the `lavaan` or `mediation` R\n    packages, or the PROCESS macro for SPSS.\n\n    The two-sided p-value of the indirect effect is computed using the\n    bootstrap distribution, as in the mediation R package. However, the p-value\n    should be interpreted with caution since it is a) not constructed\n    conditioned on a true null hypothesis (see Hayes and Rockwood 2017) and b)\n    varies depending on the number of bootstrap samples and the random seed.\n\n    Note that rows with NaN are automatically removed.\n\n    Results have been tested against the R mediation package and this tutorial\n    https://data.library.virginia.edu/introduction-to-mediation-analysis/\n\n    References\n    ----------\n    .. [1] Baron, R. M. & Kenny, D. A. The moderator\u2013mediator variable\n           distinction in social psychological research: Conceptual, strategic,\n           and statistical considerations. J. Pers. Soc. Psychol. 51, 1173\u20131182\n           (1986).\n\n    .. [2] Fiedler, K., Schott, M. & Meiser, T. What mediation analysis can\n           (not) do. J. Exp. Soc. Psychol. 47, 1231\u20131236 (2011).\n\n    .. [3] Hayes, A. F. & Rockwood, N. J. Regression-based statistical\n           mediation and moderation analysis in clinical research:\n           Observations, recommendations, and implementation. Behav. Res.\n           Ther. 98, 39\u201357 (2017).\n\n    .. [4] https://cran.r-project.org/web/packages/mediation/mediation.pdf\n\n    .. [5] http://lavaan.ugent.be/tutorial/mediation.html\n\n    .. [6] https://github.com/rmill040/pymediation\n\n    Examples\n    --------\n    1. Simple mediation analysis\n\n    >>> from pingouin import mediation_analysis, read_dataset\n    >>> df = read_dataset('mediation')\n    >>> mediation_analysis(data=df, x='X', m='M', y='Y', alpha=0.05, seed=42)\n           path    coef      se          pval  CI[2.5%]  CI[97.5%]  sig\n    0     M ~ X  0.5610  0.0945  4.391362e-08    0.3735     0.7485  Yes\n    1     Y ~ M  0.6542  0.0858  1.612674e-11    0.4838     0.8245  Yes\n    2     Total  0.3961  0.1112  5.671128e-04    0.1755     0.6167  Yes\n    3    Direct  0.0396  0.1096  7.187429e-01   -0.1780     0.2572   No\n    4  Indirect  0.3565  0.0833  0.000000e+00    0.2198     0.5377  Yes\n\n    2. Return the indirect bootstrapped beta coefficients\n\n    >>> stats, dist = mediation_analysis(data=df, x='X', m='M', y='Y',\n    ...                                  return_dist=True)\n    >>> print(dist.shape)\n    (500,)\n\n    3. Mediation analysis with a binary mediator variable\n\n    >>> mediation_analysis(data=df, x='X', m='Mbin', y='Y', seed=42)\n           path    coef      se      pval  CI[2.5%]  CI[97.5%]  sig\n    0  Mbin ~ X -0.0205  0.1159  0.859392   -0.2476     0.2066   No\n    1  Y ~ Mbin -0.1354  0.4118  0.743076   -0.9525     0.6818   No\n    2     Total  0.3961  0.1112  0.000567    0.1755     0.6167  Yes\n    3    Direct  0.3956  0.1117  0.000614    0.1739     0.6173  Yes\n    4  Indirect  0.0023  0.0495  0.960000   -0.0715     0.1441   No\n\n    4. Mediation analysis with covariates\n\n    >>> mediation_analysis(data=df, x='X', m='M', y='Y',\n    ...                    covar=['Mbin', 'Ybin'], seed=42)\n           path    coef      se          pval  CI[2.5%]  CI[97.5%]  sig\n    0     M ~ X  0.5594  0.0968  9.394635e-08    0.3672     0.7516  Yes\n    1     Y ~ M  0.6660  0.0861  1.017261e-11    0.4951     0.8368  Yes\n    2     Total  0.4204  0.1129  3.324252e-04    0.1962     0.6446  Yes\n    3    Direct  0.0645  0.1104  5.608583e-01   -0.1548     0.2837   No\n    4  Indirect  0.3559  0.0865  0.000000e+00    0.2093     0.5530  Yes\n\n    5. Mediation analysis with multiple parallel mediators\n\n    >>> mediation_analysis(data=df, x='X', m=['M', 'Mbin'], y='Y', seed=42)\n                path    coef      se          pval  CI[2.5%]  CI[97.5%]  sig\n    0          M ~ X  0.5610  0.0945  4.391362e-08    0.3735     0.7485  Yes\n    1       Mbin ~ X -0.0051  0.0290  8.592408e-01   -0.0626     0.0523   No\n    2          Y ~ M  0.6537  0.0863  2.118163e-11    0.4824     0.8250  Yes\n    3       Y ~ Mbin -0.0640  0.3282  8.456998e-01   -0.7154     0.5873   No\n    4          Total  0.3961  0.1112  5.671128e-04    0.1755     0.6167  Yes\n    5         Direct  0.0395  0.1102  7.206301e-01   -0.1792     0.2583   No\n    6     Indirect M  0.3563  0.0845  0.000000e+00    0.2148     0.5385  Yes\n    7  Indirect Mbin  0.0003  0.0097  9.520000e-01   -0.0172     0.0252   No\n    \"\"\"\n    # Sanity check\n    assert isinstance(x, str), 'y must be a string.'\n    assert isinstance(y, str), 'y must be a string.'\n    assert isinstance(m, (list, str)), 'Mediator(s) must be a list or string.'\n    assert isinstance(covar, (type(None), str, list))\n    if isinstance(m, str):\n        m = [m]\n    n_mediator = len(m)\n    assert isinstance(data, pd.DataFrame), 'Data must be a DataFrame.'\n    # Check for duplicates\n    assert n_mediator == len(set(m)), 'Cannot have duplicates mediators.'\n    if isinstance(covar, str):\n        covar = [covar]\n    if isinstance(covar, list):\n        assert len(covar) == len(set(covar)), 'Cannot have duplicates covar.'\n        assert set(m).isdisjoint(covar), 'Mediator cannot be in covar.'\n    # Check that columns are in dataframe\n    columns = _fl([x, m, y, covar])\n    keys = data.columns\n    assert all([c in keys for c in columns]), 'Column(s) are not in DataFrame.'\n    # Check that columns are numeric\n    err_msg = \"Columns must be numeric or boolean.\"\n    assert all([data[c].dtype.kind in 'bfi' for c in columns]), err_msg\n\n    # Drop rows with NAN Values\n    data = data[columns].dropna()\n    n = data.shape[0]\n    assert n > 5, 'DataFrame must have at least 5 samples (rows).'\n\n    # Check if mediator is binary\n    mtype = 'logistic' if all(data[m].nunique() == 2) else 'linear'\n\n    # Name of CI\n    ll_name = 'CI[%.1f%%]' % (100 * alpha / 2)\n    ul_name = 'CI[%.1f%%]' % (100 * (1 - alpha / 2))\n\n    # Compute regressions\n    cols = ['names', 'coef', 'se', 'pval', ll_name, ul_name]\n\n    # For speed, we pass np.array instead of pandas DataFrame\n    X_val = data[_fl([x, covar])].values  # X + covar as predictors\n    XM_val = data[_fl([x, m, covar])].values  # X + M + covar as predictors\n    M_val = data[m].values  # M as target (no covariates)\n    y_val = data[y].values  # y as target (no covariates)\n\n    # M(j) ~ X + covar\n    sxm = {}\n    for idx, j in enumerate(m):\n        if mtype == 'linear':\n            sxm[j] = linear_regression(X_val, M_val[:, idx],\n                                       alpha=alpha).loc[[1], cols]\n        else:\n            sxm[j] = logistic_regression(X_val, M_val[:, idx],\n                                         alpha=alpha).loc[[1], cols]\n        sxm[j].loc[1, 'names'] = '%s ~ X' % j\n    sxm = pd.concat(sxm, ignore_index=True)\n\n    # Y ~ M + covar\n    smy = linear_regression(data[_fl([m, covar])], y_val,\n                            alpha=alpha).loc[1:n_mediator, cols]\n\n    # Average Total Effects (Y ~ X + covar)\n    sxy = linear_regression(X_val, y_val, alpha=alpha).loc[[1], cols]\n\n    # Average Direct Effects (Y ~ X + M + covar)\n    direct = linear_regression(XM_val, y_val, alpha=alpha).loc[[1], cols]\n\n    # Rename paths\n    smy['names'] = smy['names'].apply(lambda x: 'Y ~ %s' % x)\n    direct.loc[1, 'names'] = 'Direct'\n    sxy.loc[1, 'names'] = 'Total'\n\n    # Concatenate and create sig column\n    stats = pd.concat((sxm, smy, sxy, direct), ignore_index=True)\n    stats['sig'] = np.where(stats['pval'] < alpha, 'Yes', 'No')\n\n    # Bootstrap confidence intervals\n    rng = np.random.RandomState(seed)\n    idx = rng.choice(np.arange(n), replace=True, size=(n_boot, n))\n    ab_estimates = np.zeros(shape=(n_boot, n_mediator))\n    for i in range(n_boot):\n        ab_estimates[i, :] = _point_estimate(X_val, XM_val, M_val, y_val,\n                                             idx[i, :], n_mediator, mtype)\n\n    ab = _point_estimate(X_val, XM_val, M_val, y_val, np.arange(n),\n                         n_mediator, mtype)\n    indirect = {'names': m, 'coef': ab, 'se': ab_estimates.std(ddof=1, axis=0),\n                'pval': [], ll_name: [], ul_name: [], 'sig': []}\n\n    for j in range(n_mediator):\n        ci_j = _bca(ab_estimates[:, j], indirect['coef'][j],\n                    alpha=alpha, n_boot=n_boot)\n        indirect[ll_name].append(min(ci_j))\n        indirect[ul_name].append(max(ci_j))\n        # Bootstrapped p-value of indirect effect\n        # Note that this is less accurate than a permutation test because the\n        # bootstrap distribution is not conditioned on a true null hypothesis.\n        # For more details see Hayes and Rockwood 2017\n        indirect['pval'].append(_pval_from_bootci(ab_estimates[:, j],\n                                indirect['coef'][j]))\n        indirect['sig'].append('Yes' if indirect['pval'][j] < alpha else 'No')\n\n    # Create output dataframe\n    indirect = pd.DataFrame.from_dict(indirect)\n    if n_mediator == 1:\n        indirect['names'] = 'Indirect'\n    else:\n        indirect['names'] = indirect['names'].apply(lambda x:\n                                                    'Indirect %s' % x)\n    stats = stats.append(indirect, ignore_index=True)\n    stats = stats.rename(columns={'names': 'path'})\n\n    # Round\n    col_to_round = ['coef', 'se', ll_name, ul_name]\n    stats[col_to_round] = stats[col_to_round].round(4)\n\n    if return_dist:\n        return stats, np.squeeze(ab_estimates)\n    else:\n        return stats", "response": "This function performs a bias - corrected non - parametric bootstrap method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _anova(self, dv=None, between=None, detailed=False, export_filename=None):\n    aov = anova(data=self, dv=dv, between=between, detailed=detailed,\n                export_filename=export_filename)\n    return aov", "response": "Return one - way and two - way ANOVA."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns one - way Welch ANOVA.", "response": "def _welch_anova(self, dv=None, between=None, export_filename=None):\n    \"\"\"Return one-way Welch ANOVA.\"\"\"\n    aov = welch_anova(data=self, dv=dv, between=between,\n                      export_filename=export_filename)\n    return aov"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _mixed_anova(self, dv=None, between=None, within=None, subject=None,\n                 correction=False, export_filename=None):\n    \"\"\"Two-way mixed ANOVA.\"\"\"\n    aov = mixed_anova(data=self, dv=dv, between=between, within=within,\n                      subject=subject, correction=correction,\n                      export_filename=export_filename)\n    return aov", "response": "Two - way mixed ANOVA."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _partial_corr(self, x=None, y=None, covar=None, x_covar=None, y_covar=None,\n                  tail='two-sided', method='pearson'):\n    \"\"\"Partial and semi-partial correlation.\"\"\"\n    stats = partial_corr(data=self, x=x, y=y, covar=covar, x_covar=x_covar,\n                         y_covar=y_covar, tail=tail, method=method)\n    return stats", "response": "Partial and semi - partial correlation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pcorr(self):\n    V = self.cov()  # Covariance matrix\n    Vi = np.linalg.pinv(V)  # Inverse covariance matrix\n    D = np.diag(np.sqrt(1 / np.diag(Vi)))\n    pcor = -1 * (D @ Vi @ D)  # Partial correlation matrix\n    pcor[np.diag_indices_from(pcor)] = 1\n    return pd.DataFrame(pcor, index=V.index, columns=V.columns)", "response": "Calculates the partial correlation matrix for each pair of variables in a given set of variables."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wilcoxon(x, y, tail='two-sided'):\n    from scipy.stats import wilcoxon\n    x = np.asarray(x)\n    y = np.asarray(y)\n\n    # Remove NA\n    x, y = remove_na(x, y, paired=True)\n\n    # Compute test\n    wval, pval = wilcoxon(x, y, zero_method='wilcox', correction=False)\n    pval *= .5 if tail == 'one-sided' else pval\n\n    # Effect size 1: common language effect size (McGraw and Wong 1992)\n    diff = x[:, None] - y\n    cles = max((diff < 0).sum(), (diff > 0).sum()) / diff.size\n\n    # Effect size 2: matched-pairs rank biserial correlation (Kerby 2014)\n    rank = np.arange(x.size, 0, -1)\n    rsum = rank.sum()\n    fav = rank[np.sign(y - x) > 0].sum()\n    unfav = rank[np.sign(y - x) < 0].sum()\n    rbc = fav / rsum - unfav / rsum\n\n    # Fill output DataFrame\n    stats = pd.DataFrame({}, index=['Wilcoxon'])\n    stats['W-val'] = round(wval, 3)\n    stats['p-val'] = pval\n    stats['RBC'] = round(rbc, 3)\n    stats['CLES'] = round(cles, 3)\n\n    col_order = ['W-val', 'p-val', 'RBC', 'CLES']\n    stats = stats.reindex(columns=col_order)\n    return stats", "response": "Wilcoxon signed - rank test."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cochran(dv=None, within=None, subject=None, data=None,\n            export_filename=None):\n    \"\"\"Cochran Q test. Special case of the Friedman test when the dependant\n    variable is binary.\n\n    Parameters\n    ----------\n    dv : string\n        Name of column containing the binary dependant variable.\n    within : string\n        Name of column containing the within-subject factor.\n    subject : string\n        Name of column containing the subject identifier.\n    data : pandas DataFrame\n        DataFrame\n    export_filename : string\n        Filename (without extension) for the output file.\n        If None, do not export the table.\n        By default, the file will be created in the current python console\n        directory. To change that, specify the filename with full path.\n\n    Returns\n    -------\n    stats : DataFrame\n        Test summary ::\n\n        'Q' : The Cochran Q statistic\n        'p-unc' : Uncorrected p-value\n        'dof' : degrees of freedom\n\n    Notes\n    -----\n    The Cochran Q Test is a non-parametric test for ANOVA with repeated\n    measures where the dependent variable is binary.\n\n    Data are expected to be in long-format. NaN are automatically removed\n    from the data.\n\n    The Q statistics is defined as:\n\n    .. math:: Q = \\\\frac{(r-1)(r\\\\sum_j^rx_j^2-N^2)}{rN-\\\\sum_i^nx_i^2}\n\n    where :math:`N` is the total sum of all observations, :math:`j=1,...,r`\n    where :math:`r` is the number of repeated measures, :math:`i=1,...,n` where\n    :math:`n` is the number of observations per condition.\n\n    The p-value is then approximated using a chi-square distribution with\n    :math:`r-1` degrees of freedom:\n\n    .. math:: Q \\\\sim \\\\chi^2(r-1)\n\n    References\n    ----------\n\n    .. [1] Cochran, W.G., 1950. The comparison of percentages in matched\n       samples. Biometrika 37, 256\u2013266.\n       https://doi.org/10.1093/biomet/37.3-4.256\n\n    Examples\n    --------\n    Compute the Cochran Q test for repeated measurements.\n\n    >>> from pingouin import cochran, read_dataset\n    >>> df = read_dataset('cochran')\n    >>> cochran(dv='Energetic', within='Time', subject='Subject', data=df)\n            Source  dof      Q     p-unc\n    cochran   Time    2  6.706  0.034981\n    \"\"\"\n    from scipy.stats import chi2\n\n    # Check data\n    _check_dataframe(dv=dv, within=within, data=data, subject=subject,\n                     effects='within')\n\n    # Remove NaN\n    if data[dv].isnull().any():\n        data = remove_rm_na(dv=dv, within=within, subject=subject,\n                            data=data[[subject, within, dv]])\n\n    # Groupby and extract size\n    grp = data.groupby(within)[dv]\n    grp_s = data.groupby(subject)[dv]\n    k = data[within].nunique()\n    dof = k - 1\n    # n = grp.count().unique()[0]\n\n    # Q statistic and p-value\n    q = (dof * (k * np.sum(grp.sum()**2) - grp.sum().sum()**2)) / \\\n        (k * grp.sum().sum() - np.sum(grp_s.sum()**2))\n    p_unc = chi2.sf(q, dof)\n\n    # Create output dataframe\n    stats = pd.DataFrame({'Source': within,\n                          'dof': dof,\n                          'Q': np.round(q, 3),\n                          'p-unc': p_unc,\n                          }, index=['cochran'])\n\n    # Export to .csv\n    if export_filename is not None:\n        _export_table(stats, export_filename)\n    return stats", "response": "This function returns a test that is a cochran test for the dependent variable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _isnumber(string):\n    if not _isconvertible(float, string):\n        return False\n    elif isinstance(string, (_text_type, _binary_type)) and (\n            math.isinf(float(string)) or math.isnan(float(string))):\n        return string.lower() in ['inf', '-inf', 'nan']\n    return True", "response": "Return True if string is a number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntruing or False is a boolean", "response": "def _isbool(string):\n    \"\"\"\n    >>> _isbool(True)\n    True\n    >>> _isbool(\"False\")\n    True\n    >>> _isbool(1)\n    False\n    \"\"\"\n    return isinstance(string, _bool_type) or\\\n        (isinstance(string, (_binary_type, _text_type))\n         and\n         string in (\"True\", \"False\"))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _type(string, has_invisible=True, numparse=True):\n\n    if has_invisible and \\\n       (isinstance(string, _text_type) or isinstance(string, _binary_type)):\n        string = _strip_invisible(string)\n\n    if string is None:\n        return _none_type\n    elif hasattr(string, \"isoformat\"):  # datetime.datetime, date, and time\n        return _text_type\n    elif _isbool(string):\n        return _bool_type\n    elif _isint(string) and numparse:\n        return int\n    elif _isint(string, _long_type) and numparse:\n        return int\n    elif _isnumber(string) and numparse:\n        return float\n    elif isinstance(string, _binary_type):\n        return _binary_type\n    else:\n        return _text_type", "response": "Returns the most generic type of the string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _multiline_width(multiline_s, line_width_fn=len):\n    return max(map(line_width_fn, re.split(\"[\\r\\n]\", multiline_s)))", "response": "Visible width of a potentially multiline content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _choose_width_fn(has_invisible, enable_widechars, is_multiline):\n    if has_invisible:\n        line_width_fn = _visible_width\n    elif enable_widechars:  # optional wide-character support if available\n        line_width_fn = wcwidth.wcswidth\n    else:\n        line_width_fn = len\n    if is_multiline:\n        def width_fn(s): return _multiline_width(s, line_width_fn)\n    else:\n        width_fn = line_width_fn\n    return width_fn", "response": "Return a function to calculate visible cell width."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _align_column(strings, alignment, minwidth=0,\n                  has_invisible=True, enable_widechars=False, is_multiline=False):\n    \"\"\"[string] -> [padded_string]\"\"\"\n    strings, padfn = _align_column_choose_padfn(\n        strings, alignment, has_invisible)\n    width_fn = _choose_width_fn(has_invisible, enable_widechars, is_multiline)\n\n    s_widths = list(map(width_fn, strings))\n    maxwidth = max(max(s_widths), minwidth)\n    # TODO: refactor column alignment in single-line and multiline modes\n    if is_multiline:\n        if not enable_widechars and not has_invisible:\n            padded_strings = [\n                \"\\n\".join([padfn(maxwidth, s) for s in ms.splitlines()])\n                for ms in strings]\n        else:\n            # enable wide-character width corrections\n            s_lens = [max((len(s) for s in re.split(\"[\\r\\n]\", ms)))\n                      for ms in strings]\n            visible_widths = [maxwidth - (w - l)\n                              for w, l in zip(s_widths, s_lens)]\n            # wcswidth and _visible_width don't count invisible characters;\n            # padfn doesn't need to apply another correction\n            padded_strings = [\"\\n\".join([padfn(w, s) for s in (ms.splitlines() or ms)])\n                              for ms, w in zip(strings, visible_widths)]\n    else:  # single-line cell values\n        if not enable_widechars and not has_invisible:\n            padded_strings = [padfn(maxwidth, s) for s in strings]\n        else:\n            # enable wide-character width corrections\n            s_lens = list(map(len, strings))\n            visible_widths = [maxwidth - (w - l)\n                              for w, l in zip(s_widths, s_lens)]\n            # wcswidth and _visible_width don't count invisible characters;\n            # padfn doesn't need to apply another correction\n            padded_strings = [\n                padfn(\n                    w, s) for s, w in zip(\n                    strings, visible_widths)]\n    return padded_strings", "response": "Aligns a list of strings in a single - line or multiline column."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _column_type(strings, has_invisible=True, numparse=True):\n    types = [_type(s, has_invisible, numparse) for s in strings]\n    return reduce(_more_generic, types, _bool_type)", "response": "The least generic type all column values are convertible to."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npads string header to width chars given known visible_width of the header.", "response": "def _align_header(header, alignment, width, visible_width, is_multiline=False,\n                  width_fn=None):\n    \"Pad string header to width chars given known visible_width of the header.\"\n    if is_multiline:\n        header_lines = re.split(_multiline_codes, header)\n        padded_lines = [_align_header(h, alignment, width, width_fn(h))\n                        for h in header_lines]\n        return \"\\n\".join(padded_lines)\n    # else: not multiline\n    ninvisible = len(header) - visible_width\n    width += ninvisible\n    if alignment == \"left\":\n        return _padright(width, header)\n    elif alignment == \"center\":\n        return _padboth(width, header)\n    elif not alignment:\n        return \"{0}\".format(header)\n    else:\n        return _padleft(width, header)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prepend_row_index(rows, index):\n    if index is None or index is False:\n        return rows\n    if len(index) != len(rows):\n        print('index=', index)\n        print('rows=', rows)\n        raise ValueError('index must be as long as the number of data rows')\n    rows = [[v] + list(row) for v, row in zip(index, rows)]\n    return rows", "response": "Add a left - most index column."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnormalize a tabular data type to a list of lists dicts and pandas. DataFrame.", "response": "def _normalize_tabular_data(tabular_data, headers, showindex=\"default\"):\n    \"\"\"Transform a supported data type to a list of lists,\n    and a list of headers.\n\n    Supported tabular data types:\n\n    * list-of-lists or another iterable of iterables\n\n    * list of named tuples (usually used with headers=\"keys\")\n\n    * list of dicts (usually used with headers=\"keys\")\n\n    * list of OrderedDicts (usually used with headers=\"keys\")\n\n    * 2D NumPy arrays\n\n    * NumPy record arrays (usually used with headers=\"keys\")\n\n    * dict of iterables (usually used with headers=\"keys\")\n\n    * pandas.DataFrame (usually used with headers=\"keys\")\n\n    The first row can be used as headers if headers=\"firstrow\",\n    column indices can be used as headers if headers=\"keys\".\n\n    If showindex=\"default\", show row indices of the pandas.DataFrame.\n    If showindex=\"always\", show row indices for all types of data.\n    If showindex=\"never\", don't show row indices for all types of data.\n    If showindex is an iterable, show its values as row indices.\n\n    \"\"\"\n\n    try:\n        bool(headers)\n        is_headers2bool_broken = False\n    except ValueError:  # numpy.ndarray, pandas.core.index.Index, ...\n        is_headers2bool_broken = True\n        headers = list(headers)\n\n    index = None\n    if hasattr(tabular_data, \"keys\") and hasattr(tabular_data, \"values\"):\n        # dict-like and pandas.DataFrame?\n        if hasattr(tabular_data.values, \"__call__\"):\n            # likely a conventional dict\n            keys = tabular_data.keys()\n            # columns have to be transposed\n            rows = list(izip_longest(*tabular_data.values()))\n        elif hasattr(tabular_data, \"index\"):\n            # values is a property, has .index => it's likely a\n            # pandas.DataFrame (pandas 0.11.0)\n            keys = list(tabular_data)\n            if tabular_data.index.name is not None:\n                if isinstance(tabular_data.index.name, list):\n                    keys[:0] = tabular_data.index.name\n                else:\n                    keys[:0] = [tabular_data.index.name]\n            vals = tabular_data.values  # values matrix doesn't need to be transposed\n            # for DataFrames add an index per default\n            index = list(tabular_data.index)\n            rows = [list(row) for row in vals]\n        else:\n            raise ValueError(\n                \"tabular data doesn't appear to be a dict or a DataFrame\")\n\n        if headers == \"keys\":\n            headers = list(map(_text_type, keys))  # headers should be strings\n\n    else:  # it's a usual an iterable of iterables, or a NumPy array\n        rows = list(tabular_data)\n\n        if (headers == \"keys\" and not rows):\n            # an empty table (issue #81)\n            headers = []\n        elif (headers == \"keys\" and\n              hasattr(tabular_data, \"dtype\") and\n              getattr(tabular_data.dtype, \"names\")):\n            # numpy record array\n            headers = tabular_data.dtype.names\n        elif (headers == \"keys\"\n              and len(rows) > 0\n              and isinstance(rows[0], tuple)\n              and hasattr(rows[0], \"_fields\")):\n            # namedtuple\n            headers = list(map(_text_type, rows[0]._fields))\n        elif (len(rows) > 0\n              and isinstance(rows[0], dict)):\n            # dict or OrderedDict\n            uniq_keys = set()  # implements hashed lookup\n            keys = []  # storage for set\n            if headers == \"firstrow\":\n                firstdict = rows[0] if len(rows) > 0 else {}\n                keys.extend(firstdict.keys())\n                uniq_keys.update(keys)\n                rows = rows[1:]\n            for row in rows:\n                for k in row.keys():\n                    # Save unique items in input order\n                    if k not in uniq_keys:\n                        keys.append(k)\n                        uniq_keys.add(k)\n            if headers == 'keys':\n                headers = keys\n            elif isinstance(headers, dict):\n                # a dict of headers for a list of dicts\n                headers = [headers.get(k, k) for k in keys]\n                headers = list(map(_text_type, headers))\n            elif headers == \"firstrow\":\n                if len(rows) > 0:\n                    headers = [firstdict.get(k, k) for k in keys]\n                    headers = list(map(_text_type, headers))\n                else:\n                    headers = []\n            elif headers:\n                raise ValueError(\n                    'headers for a list of dicts is not a dict or a keyword')\n            rows = [[row.get(k) for k in keys] for row in rows]\n\n        elif (headers == \"keys\"\n              and hasattr(tabular_data, \"description\")\n              and hasattr(tabular_data, \"fetchone\")\n              and hasattr(tabular_data, \"rowcount\")):\n            # Python Database API cursor object (PEP 0249)\n            # print tabulate(cursor, headers='keys')\n            headers = [column[0] for column in tabular_data.description]\n\n        elif headers == \"keys\" and len(rows) > 0:\n            # keys are column indices\n            headers = list(map(_text_type, range(len(rows[0]))))\n\n    # take headers from the first row if necessary\n    if headers == \"firstrow\" and len(rows) > 0:\n        if index is not None:\n            headers = [index[0]] + list(rows[0])\n            index = index[1:]\n        else:\n            headers = rows[0]\n        headers = list(map(_text_type, headers))  # headers should be strings\n        rows = rows[1:]\n\n    headers = list(map(_text_type, headers))\n    rows = list(map(list, rows))\n\n    # add or remove an index column\n    showindex_is_a_str = type(showindex) in [_text_type, _binary_type]\n    if showindex == \"default\" and index is not None:\n        rows = _prepend_row_index(rows, index)\n    elif isinstance(showindex, Iterable) and not showindex_is_a_str:\n        rows = _prepend_row_index(rows, list(showindex))\n    elif showindex == \"always\" or (_bool(showindex) and not showindex_is_a_str):\n        if index is None:\n            index = list(range(len(rows)))\n        rows = _prepend_row_index(rows, index)\n    elif showindex == \"never\" or (not _bool(showindex) and not showindex_is_a_str):\n        pass\n\n    # pad with empty headers for initial columns if necessary\n    if headers and len(rows) > 0:\n        nhs = len(headers)\n        ncols = len(rows[0])\n        if nhs < ncols:\n            headers = [\"\"] * (ncols - nhs) + headers\n\n    return rows, headers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tabulate(tabular_data, headers=(), tablefmt=\"simple\",\n             floatfmt=_DEFAULT_FLOATFMT, numalign=\"decimal\", stralign=\"left\",\n             missingval=_DEFAULT_MISSINGVAL, showindex=\"default\",\n             disable_numparse=False):\n    \"\"\"Format a fixed width table for pretty printing.\n    \"\"\"\n    if tabular_data is None:\n        tabular_data = []\n    list_of_lists, headers = _normalize_tabular_data(\n        tabular_data, headers, showindex=showindex)\n\n    # empty values in the first column of RST tables should be escaped (issue #82)\n    # \"\" should be escaped as \"\\\\ \" or \"..\"\n    if tablefmt == 'rst':\n        list_of_lists, headers = _rst_escape_first_column(\n            list_of_lists, headers)\n\n    # optimization: look for ANSI control codes once,\n    # enable smart width functions only if a control code is found\n    plain_text = '\\t'.join(['\\t'.join(map(_text_type, headers))] +\n                           ['\\t'.join(map(_text_type, row)) for row in list_of_lists])\n\n    has_invisible = re.search(_invisible_codes, plain_text)\n    enable_widechars = wcwidth is not None and WIDE_CHARS_MODE\n    if tablefmt in multiline_formats and _is_multiline(plain_text):\n        tablefmt = multiline_formats.get(tablefmt, tablefmt)\n        is_multiline = True\n    else:\n        is_multiline = False\n    width_fn = _choose_width_fn(has_invisible, enable_widechars, is_multiline)\n\n    # format rows and columns, convert numeric values to strings\n    cols = list(izip_longest(*list_of_lists))\n    numparses = _expand_numparse(disable_numparse, len(cols))\n    coltypes = [_column_type(col, numparse=np) for col, np in\n                zip(cols, numparses)]\n    if isinstance(floatfmt, basestring):  # old version\n        # just duplicate the string to use in each column\n        float_formats = len(cols) * [floatfmt]\n    else:  # if floatfmt is list, tuple etc we have one per column\n        float_formats = list(floatfmt)\n        if len(float_formats) < len(cols):\n            float_formats.extend(\n                (len(cols) - len(float_formats)) * [_DEFAULT_FLOATFMT])\n    if isinstance(missingval, basestring):\n        missing_vals = len(cols) * [missingval]\n    else:\n        missing_vals = list(missingval)\n        if len(missing_vals) < len(cols):\n            missing_vals.extend(\n                (len(cols) - len(missing_vals)) * [_DEFAULT_MISSINGVAL])\n    cols = [[_format(v, ct, fl_fmt, miss_v, has_invisible) for v in c]\n            for c, ct, fl_fmt, miss_v in zip(cols, coltypes, float_formats, missing_vals)]\n\n    # align columns\n    aligns = [numalign if ct in [int, float] else stralign for ct in coltypes]\n    minwidths = [\n        width_fn(h) + MIN_PADDING for h in headers] if headers else [0] * len(cols)\n    cols = [_align_column(c, a, minw, has_invisible, enable_widechars, is_multiline)\n            for c, a, minw in zip(cols, aligns, minwidths)]\n\n    if headers:\n        # align headers and add headers\n        t_cols = cols or [['']] * len(headers)\n        t_aligns = aligns or [stralign] * len(headers)\n        minwidths = [max(minw, max(width_fn(cl) for cl in c))\n                     for minw, c in zip(minwidths, t_cols)]\n        headers = [_align_header(h, a, minw, width_fn(h), is_multiline, width_fn)\n                   for h, a, minw in zip(headers, t_aligns, minwidths)]\n        rows = list(zip(*cols))\n    else:\n        minwidths = [max(width_fn(cl) for cl in c) for c in cols]\n        rows = list(zip(*cols))\n\n    if not isinstance(tablefmt, TableFormat):\n        tablefmt = _table_formats.get(tablefmt, _table_formats[\"simple\"])\n\n    return _format_table(tablefmt, headers, rows,\n                         minwidths, aligns, is_multiline)", "response": "Format a table of data into a fixed width table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpand disable_numparse to column_count.", "response": "def _expand_numparse(disable_numparse, column_count):\n    \"\"\"\n    Return a list of bools of length `column_count` which indicates whether\n    number parsing should be used on each column.\n    If `disable_numparse` is a list of indices, each of those indices are False,\n    and everything else is True.\n    If `disable_numparse` is a bool, then the returned list is all the same.\n    \"\"\"\n    if isinstance(disable_numparse, Iterable):\n        numparses = [True] * column_count\n        for index in disable_numparse:\n            numparses[index] = False\n        return numparses\n    else:\n        return [not disable_numparse] * column_count"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pairwise_tukey(dv=None, between=None, data=None, alpha=.05,\n                   tail='two-sided', effsize='hedges'):\n    '''Pairwise Tukey-HSD post-hoc test.\n\n    Parameters\n    ----------\n    dv : string\n        Name of column containing the dependant variable.\n    between: string\n        Name of column containing the between factor.\n    data : pandas DataFrame\n        DataFrame\n    alpha : float\n        Significance level\n    tail : string\n        Indicates whether to return the 'two-sided' or 'one-sided' p-values\n    effsize : string or None\n        Effect size type. Available methods are ::\n\n        'none' : no effect size\n        'cohen' : Unbiased Cohen d\n        'hedges' : Hedges g\n        'glass': Glass delta\n        'eta-square' : Eta-square\n        'odds-ratio' : Odds ratio\n        'AUC' : Area Under the Curve\n\n    Returns\n    -------\n    stats : DataFrame\n        Stats summary ::\n\n        'A' : Name of first measurement\n        'B' : Name of second measurement\n        'mean(A)' : Mean of first measurement\n        'mean(B)' : Mean of second measurement\n        'diff' : Mean difference\n        'SE' : Standard error\n        'tail' : indicate whether the p-values are one-sided or two-sided\n        'T' : T-values\n        'p-tukey' : Tukey-HSD corrected p-values\n        'efsize' : effect sizes\n        'eftype' : type of effect size\n\n    Notes\n    -----\n    Tukey HSD post-hoc is best for balanced one-way ANOVA.\n    It has been proven to be conservative for one-way ANOVA with unequal\n    sample sizes. However, it is not robust if the groups have unequal\n    variances, in which case the Games-Howell test is more adequate.\n    Tukey HSD is not valid for repeated measures ANOVA.\n\n    Note that when the sample sizes are unequal, this function actually\n    performs the Tukey-Kramer test (which allows for unequal sample sizes).\n\n    The T-values are defined as:\n\n    .. math::\n\n        t = \\\\frac{\\\\overline{x}_i - \\\\overline{x}_j}\n        {\\\\sqrt{2 \\\\cdot MS_w / n}}\n\n    where :math:`\\\\overline{x}_i` and :math:`\\\\overline{x}_j` are the means of\n    the first and second group, respectively, :math:`MS_w` the mean squares of\n    the error (computed using ANOVA) and :math:`n` the sample size.\n\n    If the sample sizes are unequal, the Tukey-Kramer procedure is\n    automatically used:\n\n    .. math::\n\n        t = \\\\frac{\\\\overline{x}_i - \\\\overline{x}_j}{\\\\sqrt{\\\\frac{MS_w}{n_i}\n        + \\\\frac{MS_w}{n_j}}}\n\n    where :math:`n_i` and :math:`n_j` are the sample sizes of the first and\n    second group, respectively.\n\n    The p-values are then approximated using the Studentized range distribution\n    :math:`Q(\\\\sqrt2*|t_i|, r, N - r)` where :math:`r` is the total number of\n    groups and :math:`N` is the total sample size.\n\n    Note that the p-values might be slightly different than those obtained\n    using R or Matlab since the studentized range approximation is done using\n    the Gleason (1999) algorithm, which is more efficient and accurate than\n    the algorithms used in Matlab or R.\n\n    References\n    ----------\n    .. [1] Tukey, John W. \"Comparing individual means in the analysis of\n           variance.\" Biometrics (1949): 99-114.\n\n    .. [2] Gleason, John R. \"An accurate, non-iterative approximation for\n           studentized range quantiles.\" Computational statistics & data\n           analysis 31.2 (1999): 147-158.\n\n    Examples\n    --------\n    Pairwise Tukey post-hocs on the pain threshold dataset.\n\n    >>> from pingouin import pairwise_tukey, read_dataset\n    >>> df = read_dataset('anova')\n    >>> pt = pairwise_tukey(dv='Pain threshold', between='Hair color', data=df)\n    '''\n    from pingouin.external.qsturng import psturng\n\n    # First compute the ANOVA\n    aov = anova(dv=dv, data=data, between=between, detailed=True)\n    df = aov.loc[1, 'DF']\n    ng = aov.loc[0, 'DF'] + 1\n    grp = data.groupby(between)[dv]\n    n = grp.count().values\n    gmeans = grp.mean().values\n    gvar = aov.loc[1, 'MS'] / n\n\n    # Pairwise combinations\n    g1, g2 = np.array(list(combinations(np.arange(ng), 2))).T\n    mn = gmeans[g1] - gmeans[g2]\n    se = np.sqrt(gvar[g1] + gvar[g2])\n    tval = mn / se\n\n    # Critical values and p-values\n    # from pingouin.external.qsturng import qsturng\n    # crit = qsturng(1 - alpha, ng, df) / np.sqrt(2)\n    pval = psturng(np.sqrt(2) * np.abs(tval), ng, df)\n    pval *= 0.5 if tail == 'one-sided' else 1\n\n    # Uncorrected p-values\n    # from scipy.stats import t\n    # punc = t.sf(np.abs(tval), n[g1].size + n[g2].size - 2) * 2\n\n    # Effect size\n    d = tval * np.sqrt(1 / n[g1] + 1 / n[g2])\n    ef = convert_effsize(d, 'cohen', effsize, n[g1], n[g2])\n\n    # Create dataframe\n    # Careful: pd.unique does NOT sort whereas numpy does\n    stats = pd.DataFrame({\n                         'A': np.unique(data[between])[g1],\n                         'B': np.unique(data[between])[g2],\n                         'mean(A)': gmeans[g1],\n                         'mean(B)': gmeans[g2],\n                         'diff': mn,\n                         'SE': np.round(se, 3),\n                         'tail': tail,\n                         'T': np.round(tval, 3),\n                         # 'alpha': alpha,\n                         # 'crit': np.round(crit, 3),\n                         'p-tukey': pval,\n                         'efsize': np.round(ef, 3),\n                         'eftype': effsize,\n                         })\n    return stats", "response": "Pairwise Tukey - HSD test."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new p - value of the pairwise correlation between columns of a pandas dataframe.", "response": "def pairwise_corr(data, columns=None, covar=None, tail='two-sided',\n                  method='pearson', padjust='none', export_filename=None):\n    '''Pairwise (partial) correlations between columns of a pandas dataframe.\n\n    Parameters\n    ----------\n    data : pandas DataFrame\n        DataFrame. Note that this function can also directly be used as a\n        Pandas method, in which case this argument is no longer needed.\n    columns : list or str\n        Column names in data ::\n\n        '[\"a\", \"b\", \"c\"]' : combination between columns a, b, and c\n        '[\"a\"]' : product between a and all the other numeric columns\n        '[[\"a\"], [\"b\", \"c\"]]' : product between [\"a\"] and [\"b\", \"c\"]\n        '[[\"a\", \"d\"], [\"b\", \"c\"]]' : product between [\"a\", \"d\"] and [\"b\", \"c\"]\n        '[[\"a\", \"d\"], None]' : product between [\"a\", \"d\"] and all other columns\n\n        Note that if column is not specified, then the function will return the\n        pairwise correlation between the combination of all the numeric columns\n        in data. See the examples section for more details on this.\n    covar : None, string or list\n        Covariate(s) for partial correlation. Must be one or more columns\n        in data. Use a list if there are more than one covariate. If\n        ``covar`` is not None, a partial correlation will be computed using\n        :py:func:`pingouin.partial_corr` function.\n    tail : string\n        Indicates whether to return the 'two-sided' or 'one-sided' p-values\n    method : string\n        Specify which method to use for the computation of the correlation\n        coefficient. Available methods are ::\n\n        'pearson' : Pearson product-moment correlation\n        'spearman' : Spearman rank-order correlation\n        'kendall' : Kendall\u2019s tau (ordinal data)\n        'percbend' : percentage bend correlation (robust)\n        'shepherd' : Shepherd's pi correlation (robust Spearman)\n    padjust : string\n        Method used for testing and adjustment of pvalues.\n        Available methods are ::\n\n        'none' : no correction\n        'bonferroni' : one-step Bonferroni correction\n        'holm' : step-down method using Bonferroni adjustments\n        'fdr_bh' : Benjamini/Hochberg FDR correction\n        'fdr_by' : Benjamini/Yekutieli FDR correction\n    export_filename : string\n        Filename (without extension) for the output file.\n        If None, do not export the table.\n        By default, the file will be created in the current python console\n        directory. To change that, specify the filename with full path.\n\n    Returns\n    -------\n    stats : DataFrame\n        Stats summary ::\n\n        'X' : Name(s) of first columns\n        'Y' : Name(s) of second columns\n        'method' : method used to compute the correlation\n        'covar' : List of specified covariate(s) (only for partial correlation)\n        'tail' : indicates whether the p-values are one-sided or two-sided\n        'n' : Sample size (after NaN removal)\n        'r' : Correlation coefficients\n        'CI95' : 95% parametric confidence intervals\n        'r2' : R-squared values\n        'adj_r2' : Adjusted R-squared values\n        'z' : Standardized correlation coefficients\n        'p-unc' : uncorrected one or two tailed p-values\n        'p-corr' : corrected one or two tailed p-values\n        'p-adjust' : Correction method\n\n    Notes\n    -----\n    Please refer to the :py:func:`pingouin.corr()` function for a description\n    of the different methods. NaN are automatically removed from the data.\n\n    This function is more flexible and gives a much more detailed\n    output than the :py:func:`pandas.DataFrame.corr()` method (i.e. p-values,\n    confidence interval, Bayes Factor..). This comes however at\n    an increased computational cost. While this should not be discernible for\n    dataframe with less than 10,000 rows and/or less than 20 columns, this\n    function can be slow for very large dataset. For speed purpose, the Bayes\n    Factor is only computed when the sample size is less than 1000\n    (and method='pearson').\n\n    This function also works with two-dimensional multi-index columns. In this\n    case, columns must be list(s) of tuple(s). See the Jupyter notebook\n    for more details:\n    https://github.com/raphaelvallat/pingouin/blob/master/notebooks/04_Correlations.ipynb\n\n    If ``covar`` is specified, this function will compute the pairwise partial\n    correlation between the variables. If you are only interested in computing\n    the partial correlation matrix (i.e. the raw pairwise partial correlation\n    coefficient matrix, without the p-values, sample sizes, etc), a better\n    alternative is to use the :py:func:`pingouin.pcorr` function (see\n    example 7).\n\n    Examples\n    --------\n    1. One-tailed spearman correlation corrected for multiple comparisons\n\n    >>> from pingouin import pairwise_corr, read_dataset\n    >>> data = read_dataset('pairwise_corr').iloc[:, 1:]\n    >>> pairwise_corr(data, method='spearman', tail='two-sided',\n    ...               padjust='bonf')  # doctest: +SKIP\n\n    2. Robust two-sided correlation with uncorrected p-values\n\n    >>> pcor = pairwise_corr(data, columns=['Openness', 'Extraversion',\n    ...                                     'Neuroticism'], method='percbend')\n\n    3. One-versus-all pairwise correlations\n\n    >>> pairwise_corr(data, columns=['Neuroticism'])  # doctest: +SKIP\n\n    4. Pairwise correlations between two lists of columns (cartesian product)\n\n    >>> columns = [['Neuroticism', 'Extraversion'], ['Openness']]\n    >>> pairwise_corr(data, columns)   # doctest: +SKIP\n\n    5. As a Pandas method\n\n    >>> pcor = data.pairwise_corr(covar='Neuroticism', method='spearman')\n\n    6. Pairwise partial correlation\n\n    >>> pcor = pairwise_corr(data, covar='Neuroticism')  # One covariate\n    >>> pcor = pairwise_corr(data, covar=['Neuroticism', 'Openness'])  # Two\n\n    7. Pairwise partial correlation matrix (only the r-values)\n\n    >>> data[['Neuroticism', 'Openness', 'Extraversion']].pcorr()\n                  Neuroticism  Openness  Extraversion\n    Neuroticism      1.000000  0.092097     -0.360421\n    Openness         0.092097  1.000000      0.281312\n    Extraversion    -0.360421  0.281312      1.000000\n    '''\n    from pingouin.correlation import corr, partial_corr\n\n    if tail not in ['one-sided', 'two-sided']:\n        raise ValueError('Tail not recognized')\n\n    # Keep only numeric columns\n    data = data._get_numeric_data()\n    # Remove columns with constant value and/or NaN\n    data = data.loc[:, data.nunique(dropna=True) >= 2]\n    # Extract columns names\n    keys = data.columns.tolist()\n\n    # First ensure that columns is a list\n    if isinstance(columns, (str, tuple)):\n        columns = [columns]\n\n    def traverse(o, tree_types=(list, tuple)):\n        \"\"\"Helper function to flatten nested lists.\n        From https://stackoverflow.com/a/6340578\n        \"\"\"\n        if isinstance(o, tree_types):\n            for value in o:\n                for subvalue in traverse(value, tree_types):\n                    yield subvalue\n        else:\n            yield o\n\n    # Check if columns index has multiple levels\n    if isinstance(data.columns, pd.core.index.MultiIndex):\n        multi_index = True\n        if columns is not None:\n            # Simple List with one element: [('L0', 'L1')]\n            # Simple list with >= 2 elements: [('L0', 'L1'), ('L0', 'L2')]\n            # Nested lists: [[('L0', 'L1')], ...] or [..., [('L0', 'L1')]]\n            col_flatten = list(traverse(columns, tree_types=list))\n            assert all(isinstance(c, (tuple, type(None))) for c in col_flatten)\n    else:\n        multi_index = False\n\n    # Then define combinations / products between columns\n    if columns is None:\n        # Case A: column is not defined --> corr between all numeric columns\n        combs = list(combinations(keys, 2))\n    else:\n        # Case B: column is specified\n        if isinstance(columns[0], list):\n            group1 = [e for e in columns[0] if e in keys]\n            # Assert that column is two-dimensional\n            if len(columns) == 1:\n                columns.append(None)\n            if isinstance(columns[1], list) and len(columns[1]):\n                # B1: [['a', 'b'], ['c', 'd']]\n                group2 = [e for e in columns[1] if e in keys]\n            else:\n                # B2: [['a', 'b']], [['a', 'b'], None] or [['a', 'b'], 'all']\n                group2 = [e for e in keys if e not in group1]\n            combs = list(product(group1, group2))\n        else:\n            # Column is a simple list\n            if len(columns) == 1:\n                # Case B3: one-versus-all, e.g. ['a'] or 'a'\n                # Check that this column exist\n                if columns[0] not in keys:\n                    msg = ('\"%s\" is not in data or is not numeric.'\n                           % columns[0])\n                    raise ValueError(msg)\n                others = [e for e in keys if e != columns[0]]\n                combs = list(product(columns, others))\n            else:\n                # Combinations between all specified columns ['a', 'b', 'c']\n                # Make sure that we keep numeric columns\n                columns = [c for c in columns if c in keys]\n                if len(columns) == 1:\n                    # If only one-column is left, equivalent to ['a']\n                    others = [e for e in keys if e != columns[0]]\n                    combs = list(product(columns, others))\n                else:\n                    # combinations between ['a', 'b', 'c']\n                    combs = list(combinations(columns, 2))\n\n    combs = np.array(combs)\n    if len(combs) == 0:\n        raise ValueError(\"No column combination found. Please make sure that \"\n                         \"the specified columns exist in the dataframe, are \"\n                         \"numeric, and contains at least two unique values.\")\n\n    # Initialize empty dataframe\n    if multi_index:\n        X = list(zip(combs[:, 0, 0], combs[:, 0, 1]))\n        Y = list(zip(combs[:, 1, 0], combs[:, 1, 1]))\n    else:\n        X = combs[:, 0]\n        Y = combs[:, 1]\n    stats = pd.DataFrame({'X': X, 'Y': Y, 'method': method, 'tail': tail},\n                         index=range(len(combs)),\n                         columns=['X', 'Y', 'method', 'tail', 'n', 'outliers',\n                                  'r', 'CI95%', 'r2', 'adj_r2', 'p-val',\n                                  'BF10', 'power'])\n\n    # Now we check if covariates are present\n    if covar is not None:\n        assert isinstance(covar, (str, list)), 'covar must be list or string.'\n        if isinstance(covar, str):\n            covar = [covar]\n        # Check that columns exist and are numeric\n        assert all([c in keys for c in covar]), 'covar not in data or not num.'\n        # And we make sure that X or Y does not contain covar\n        stats = stats[~stats[['X', 'Y']].isin(covar).any(1)]\n        stats = stats.reset_index(drop=True)\n        if stats.shape[0] == 0:\n            raise ValueError(\"No column combination found. Please make sure \"\n                             \"that the specified columns and covar exist in \"\n                             \"the dataframe, are numeric, and contains at \"\n                             \"least two unique values.\")\n\n    # Compute pairwise correlations and fill dataframe\n    dvs = ['n', 'r', 'CI95%', 'r2', 'adj_r2', 'p-val', 'power']\n    dvs_out = dvs + ['outliers']\n    dvs_bf10 = dvs + ['BF10']\n    for i in range(stats.shape[0]):\n        col1, col2 = stats.loc[i, 'X'], stats.loc[i, 'Y']\n        if covar is None:\n            cor_st = corr(data[col1].values, data[col2].values, tail=tail,\n                          method=method)\n        else:\n            cor_st = partial_corr(data=data, x=col1, y=col2, covar=covar,\n                                  tail=tail, method=method)\n        cor_st_keys = cor_st.columns.tolist()\n        if 'BF10' in cor_st_keys:\n            stats.loc[i, dvs_bf10] = cor_st[dvs_bf10].values\n        elif 'outliers' in cor_st_keys:\n            stats.loc[i, dvs_out] = cor_st[dvs_out].values\n        else:\n            stats.loc[i, dvs] = cor_st[dvs].values\n\n    # Force conversion to numeric\n    stats = stats.astype({'r': float, 'r2': float, 'adj_r2': float,\n                          'n': int, 'p-val': float, 'outliers': float,\n                          'power': float})\n\n    # Multiple comparisons\n    stats = stats.rename(columns={'p-val': 'p-unc'})\n    padjust = None if stats['p-unc'].size <= 1 else padjust\n    if padjust is not None:\n        if padjust.lower() != 'none':\n            reject, stats['p-corr'] = multicomp(stats['p-unc'].values,\n                                                method=padjust)\n            stats['p-adjust'] = padjust\n    else:\n        stats['p-corr'] = None\n        stats['p-adjust'] = None\n\n    # Standardize correlation coefficients (Fisher z-transformation)\n    stats['z'] = np.round(np.arctanh(stats['r'].values), 3)\n\n    col_order = ['X', 'Y', 'method', 'tail', 'n', 'outliers', 'r', 'CI95%',\n                 'r2', 'adj_r2', 'z', 'p-unc', 'p-corr', 'p-adjust',\n                 'BF10', 'power']\n\n    # Reorder columns and remove empty ones\n    stats = stats.reindex(columns=col_order)\n    stats = stats.dropna(how='all', axis=1)\n\n    # Add covariates names if present\n    if covar is not None:\n        stats.insert(loc=3, column='covar', value=str(covar))\n\n    if export_filename is not None:\n        _export_table(stats, export_filename)\n    return stats"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef circ_axial(alpha, n):\n    alpha = np.array(alpha)\n    return np.remainder(alpha * n, 2 * np.pi)", "response": "Transforms n - axial data to a common scale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef circ_corrcc(x, y, tail='two-sided'):\n    from scipy.stats import norm\n    x = np.asarray(x)\n    y = np.asarray(y)\n\n    # Check size\n    if x.size != y.size:\n        raise ValueError('x and y must have the same length.')\n\n    # Remove NA\n    x, y = remove_na(x, y, paired=True)\n    n = x.size\n\n    # Compute correlation coefficient\n    x_sin = np.sin(x - circmean(x))\n    y_sin = np.sin(y - circmean(y))\n    # Similar to np.corrcoef(x_sin, y_sin)[0][1]\n    r = np.sum(x_sin * y_sin) / np.sqrt(np.sum(x_sin**2) * np.sum(y_sin**2))\n\n    # Compute T- and p-values\n    tval = np.sqrt((n * (x_sin**2).mean() * (y_sin**2).mean())\n                   / np.mean(x_sin**2 * y_sin**2)) * r\n\n    # Approximately distributed as a standard normal\n    pval = 2 * norm.sf(abs(tval))\n    pval = pval / 2 if tail == 'one-sided' else pval\n    return np.round(r, 3), pval", "response": "Computes the correlation coefficient between two circular variables."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef circ_corrcl(x, y, tail='two-sided'):\n    from scipy.stats import pearsonr, chi2\n    x = np.asarray(x)\n    y = np.asarray(y)\n\n    # Check size\n    if x.size != y.size:\n        raise ValueError('x and y must have the same length.')\n\n    # Remove NA\n    x, y = remove_na(x, y, paired=True)\n    n = x.size\n\n    # Compute correlation coefficent for sin and cos independently\n    rxs = pearsonr(y, np.sin(x))[0]\n    rxc = pearsonr(y, np.cos(x))[0]\n    rcs = pearsonr(np.sin(x), np.cos(x))[0]\n\n    # Compute angular-linear correlation (equ. 27.47)\n    r = np.sqrt((rxc**2 + rxs**2 - 2 * rxc * rxs * rcs) / (1 - rcs**2))\n\n    # Compute p-value\n    pval = chi2.sf(n * r**2, 2)\n    pval = pval / 2 if tail == 'one-sided' else pval\n    return np.round(r, 3), pval", "response": "Computes the correlation coefficient between two circular variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmeans direction for circular data.", "response": "def circ_mean(alpha, w=None, axis=0):\n    \"\"\"Mean direction for circular data.\n\n    Parameters\n    ----------\n    alpha : array\n        Sample of angles in radians\n    w : array\n        Number of incidences in case of binned angle data\n    axis : int\n        Compute along this dimension\n\n    Returns\n    -------\n    mu : float\n        Mean direction\n\n    Examples\n    --------\n    Mean resultant vector of circular data\n\n    >>> from pingouin import circ_mean\n    >>> alpha = [0.785, 1.570, 3.141, 0.839, 5.934]\n    >>> circ_mean(alpha)\n    1.012962445838065\n    \"\"\"\n    alpha = np.array(alpha)\n    if isinstance(w, (list, np.ndarray)):\n        w = np.array(w)\n        if alpha.shape != w.shape:\n            raise ValueError(\"w must have the same shape as alpha.\")\n    else:\n        w = np.ones_like(alpha)\n    return np.angle(np.multiply(w, np.exp(1j * alpha)).sum(axis=axis))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmeaning resultant vector length for circular data. Parameters ---------- alpha : array Sample of angles in radians w : array Number of incidences in case of binned angle data d : float Spacing (in radians) of bin centers for binned data. If supplied, a correction factor is used to correct for bias in the estimation of r. axis : int Compute along this dimension Returns ------- r : float Mean resultant length Notes ----- The length of the mean resultant vector is a crucial quantity for the measurement of circular spread or hypothesis testing in directional statistics. The closer it is to one, the more concentrated the data sample is around the mean direction (Berens 2009). Examples -------- Mean resultant vector length of circular data >>> from pingouin import circ_r >>> x = [0.785, 1.570, 3.141, 0.839, 5.934] >>> circ_r(x) 0.49723034495605356", "response": "def circ_r(alpha, w=None, d=None, axis=0):\n    \"\"\"Mean resultant vector length for circular data.\n\n    Parameters\n    ----------\n    alpha : array\n        Sample of angles in radians\n    w : array\n        Number of incidences in case of binned angle data\n    d : float\n        Spacing (in radians) of bin centers for binned data. If supplied,\n        a correction factor is used to correct for bias in the estimation\n        of r.\n    axis : int\n        Compute along this dimension\n\n    Returns\n    -------\n    r : float\n        Mean resultant length\n\n    Notes\n    -----\n    The length of the mean resultant vector is a crucial quantity for the\n    measurement of circular spread or hypothesis testing in directional\n    statistics. The closer it is to one, the more concentrated the data\n    sample is around the mean direction (Berens 2009).\n\n    Examples\n    --------\n    Mean resultant vector length of circular data\n\n    >>> from pingouin import circ_r\n    >>> x = [0.785, 1.570, 3.141, 0.839, 5.934]\n    >>> circ_r(x)\n    0.49723034495605356\n    \"\"\"\n    alpha = np.array(alpha)\n    w = np.array(w) if w is not None else np.ones(alpha.shape)\n    if alpha.size is not w.size:\n        raise ValueError(\"Input dimensions do not match\")\n\n    # Compute weighted sum of cos and sin of angles:\n    r = np.multiply(w, np.exp(1j * alpha)).sum(axis=axis)\n\n    # Obtain length:\n    r = np.abs(r) / w.sum(axis=axis)\n\n    # For data with known spacing, apply correction factor\n    if d is not None:\n        c = d / 2 / np.sin(d / 2)\n        r = c * r\n\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef circ_rayleigh(alpha, w=None, d=None):\n    alpha = np.array(alpha)\n    if w is None:\n        r = circ_r(alpha)\n        n = len(alpha)\n    else:\n        if len(alpha) is not len(w):\n            raise ValueError(\"Input dimensions do not match\")\n        r = circ_r(alpha, w, d)\n        n = np.sum(w)\n\n    # Compute Rayleigh's statistic\n    R = n * r\n    z = (R**2) / n\n\n    # Compute p value using approxation in Zar (1999), p. 617\n    pval = np.exp(np.sqrt(1 + 4 * n + 4 * (n**2 - R**2)) - (1 + 2 * n))\n\n    return np.round(z, 3), pval", "response": "Simple Rayleigh test for non - uniformity of circular data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bonf(pvals, alpha=0.05):\n    pvals = np.asarray(pvals)\n    num_nan = np.isnan(pvals).sum()\n    pvals_corrected = pvals * (float(pvals.size) - num_nan)\n    pvals_corrected = np.clip(pvals_corrected, None, 1)\n    with np.errstate(invalid='ignore'):\n        reject = np.less(pvals_corrected, alpha)\n    return reject, pvals_corrected", "response": "P - values correction with Bonferroni method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef multicomp(pvals, alpha=0.05, method='holm'):\n    if not isinstance(pvals, (list, np.ndarray)):\n        err = \"pvals must be a list or a np.ndarray\"\n        raise ValueError(err)\n\n    if method.lower() in ['b', 'bonf', 'bonferroni']:\n        reject, pvals_corrected = bonf(pvals, alpha=alpha)\n    elif method.lower() in ['h', 'holm']:\n        reject, pvals_corrected = holm(pvals, alpha=alpha)\n    elif method.lower() in ['fdr', 'fdr_bh']:\n        reject, pvals_corrected = fdr(pvals, alpha=alpha, method='fdr_bh')\n    elif method.lower() in ['fdr_by']:\n        reject, pvals_corrected = fdr(pvals, alpha=alpha, method='fdr_by')\n    elif method.lower() == 'none':\n        pvals_corrected = pvals\n        with np.errstate(invalid='ignore'):\n            reject = np.less(pvals_corrected, alpha)\n    else:\n        raise ValueError('Multiple comparison method not recognized')\n    return reject, pvals_corrected", "response": "This function is used to apply multiple comparison to a single hypothesis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef intraclass_corr(data=None, groups=None, raters=None, scores=None, ci=.95):\n    from pingouin import anova\n\n    # Check dataframe\n    if any(v is None for v in [data, groups, raters, scores]):\n        raise ValueError('Data, groups, raters and scores must be specified')\n    assert isinstance(data, pd.DataFrame), 'Data must be a pandas dataframe.'\n    # Check that scores is a numeric variable\n    assert data[scores].dtype.kind in 'fi', 'Scores must be numeric.'\n    # Check that data are fully balanced\n    if data.groupby(raters)[scores].count().nunique() > 1:\n        raise ValueError('Data must be balanced.')\n\n    # Extract sizes\n    k = data[raters].nunique()\n    # n = data[groups].nunique()\n\n    # ANOVA and ICC\n    aov = anova(dv=scores, data=data, between=groups, detailed=True)\n    icc = (aov.loc[0, 'MS'] - aov.loc[1, 'MS']) / \\\n          (aov.loc[0, 'MS'] + (k - 1) * aov.loc[1, 'MS'])\n\n    # Confidence interval\n    alpha = 1 - ci\n    df_num, df_den = aov.loc[0, 'DF'], aov.loc[1, 'DF']\n    f_lower = aov.loc[0, 'F'] / f.isf(alpha / 2, df_num, df_den)\n    f_upper = aov.loc[0, 'F'] * f.isf(alpha / 2, df_den, df_num)\n    lower = (f_lower - 1) / (f_lower + k - 1)\n    upper = (f_upper - 1) / (f_upper + k - 1)\n\n    return round(icc, 6), np.round([lower, upper], 3)", "response": "Intra-class correlation coefficient.\n\n    Parameters\n    ----------\n    data : pd.DataFrame\n        Dataframe containing the variables\n    groups : string\n        Name of column in data containing the groups.\n    raters : string\n        Name of column in data containing the raters (scorers).\n    scores : string\n        Name of column in data containing the scores (ratings).\n    ci : float\n        Confidence interval\n\n    Returns\n    -------\n    icc : float\n        Intraclass correlation coefficient\n    ci : list\n        Lower and upper confidence intervals\n\n    Notes\n    -----\n    The intraclass correlation (ICC) assesses the reliability of ratings by\n    comparing the variability of different ratings of the same subject to the\n    total variation across all ratings and all subjects. The ratings are\n    quantitative (e.g. Likert scale).\n\n    Inspired from:\n    http://www.real-statistics.com/reliability/intraclass-correlation/\n\n    Examples\n    --------\n    ICC of wine quality assessed by 4 judges.\n\n    >>> import pingouin as pg\n    >>> data = pg.read_dataset('icc')\n    >>> pg.intraclass_corr(data=data, groups='Wine', raters='Judge',\n    ...                    scores='Scores', ci=.95)\n    (0.727526, array([0.434, 0.927]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _phi( p ):\n    # this function is faster than using scipy.stats.norm.isf(p)\n    # but the permissity of the license isn't explicitly listed.\n    # using scipy.stats.norm.isf(p) is an acceptable alternative\n\n    \"\"\"\n    Modified from the author's original perl code (original comments follow below)\n    by dfield@yahoo-inc.com.  May 3, 2004.\n\n    Lower tail quantile for standard normal distribution function.\n\n    This function returns an approximation of the inverse cumulative\n    standard normal distribution function.  I.e., given P, it returns\n    an approximation to the X satisfying P = Pr{Z <= X} where Z is a\n    random variable from the standard normal distribution.\n\n    The algorithm uses a minimax approximation by rational functions\n    and the result has a relative error whose absolute value is less\n    than 1.15e-9.\n\n    Author:      Peter John Acklam\n    Time-stamp:  2000-07-19 18:26:14\n    E-mail:      pjacklam@online.no\n    WWW URL:     http://home.online.no/~pjacklam\n    \"\"\"\n\n    if p <= 0 or p >= 1:\n        # The original perl code exits here, we'll throw an exception instead\n        raise ValueError( \"Argument to ltqnorm %f must be in open interval (0,1)\" % p )\n\n    # Coefficients in rational approximations.\n    a = (-3.969683028665376e+01,  2.209460984245205e+02, \\\n         -2.759285104469687e+02,  1.383577518672690e+02, \\\n         -3.066479806614716e+01,  2.506628277459239e+00)\n    b = (-5.447609879822406e+01,  1.615858368580409e+02, \\\n         -1.556989798598866e+02,  6.680131188771972e+01, \\\n         -1.328068155288572e+01 )\n    c = (-7.784894002430293e-03, -3.223964580411365e-01, \\\n         -2.400758277161838e+00, -2.549732539343734e+00, \\\n          4.374664141464968e+00,  2.938163982698783e+00)\n    d = ( 7.784695709041462e-03,  3.224671290700398e-01, \\\n          2.445134137142996e+00,  3.754408661907416e+00)\n\n    # Define break-points.\n    plow  = 0.02425\n    phigh = 1 - plow\n\n    # Rational approximation for lower region:\n    if p < plow:\n        q  = math.sqrt(-2*math.log(p))\n        return -(((((c[0]*q+c[1])*q+c[2])*q+c[3])*q+c[4])*q+c[5]) / \\\n                 ((((d[0]*q+d[1])*q+d[2])*q+d[3])*q+1)\n\n    # Rational approximation for upper region:\n    if phigh < p:\n        q  = math.sqrt(-2*math.log(1-p))\n        return (((((c[0]*q+c[1])*q+c[2])*q+c[3])*q+c[4])*q+c[5]) / \\\n                ((((d[0]*q+d[1])*q+d[2])*q+d[3])*q+1)\n\n    # Rational approximation for central region:\n    q = p - 0.5\n    r = q*q\n    return -(((((a[0]*r+a[1])*r+a[2])*r+a[3])*r+a[4])*r+a[5])*q / \\\n           (((((b[0]*r+b[1])*r+b[2])*r+b[3])*r+b[4])*r+1)", "response": "This function is used to calculate the inverse cumulative version of the random variable from the standard normal distribution function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating f - hat for the coefficients in a probability p sample mean difference r and degrees of freedom v.", "response": "def _func(a, p, r, v):\n    \"\"\"\n    calculates f-hat for the coefficients in a, probability p,\n    sample mean difference r, and degrees of freedom v.\n    \"\"\"\n    # eq. 2.3\n    f = a[0]*math.log(r-1.) + \\\n        a[1]*math.log(r-1.)**2 + \\\n        a[2]*math.log(r-1.)**3 + \\\n        a[3]*math.log(r-1.)**4\n\n    # eq. 2.7 and 2.8 corrections\n    if r == 3:\n        f += -0.002 / (1. + 12. * _phi(p)**2)\n\n        if v <= 4.364:\n            f += 1./517. - 1./(312.*(v,1e38)[np.isinf(v)])\n        else:\n            f += 1./(191.*(v,1e38)[np.isinf(v)])\n\n    return -f"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _interpolate_p(p, r, v):\n\n    # interpolate p (v should be in table)\n    # if .5 < p < .75 use linear interpolation in q\n    # if p > .75 use quadratic interpolation in log(y + r/v)\n    # by -1. / (1. + 1.5 * _phi((1. + p)/2.))\n\n    # find the 3 closest v values\n    p0, p1, p2 = _select_ps(p)\n    try:\n        y0 = _func(A[(p0, v)], p0, r, v) + 1.\n    except:\n        print(p,r,v)\n    y1 = _func(A[(p1, v)], p1, r, v) + 1.\n    y2 = _func(A[(p2, v)], p2, r, v) + 1.\n\n    y_log0 = math.log(y0 + float(r)/float(v))\n    y_log1 = math.log(y1 + float(r)/float(v))\n    y_log2 = math.log(y2 + float(r)/float(v))\n\n    # If p < .85 apply only the ordinate transformation\n    # if p > .85 apply the ordinate and the abcissa transformation\n    # In both cases apply quadratic interpolation\n    if p > .85:\n        p_t  = _ptransform(p)\n        p0_t = _ptransform(p0)\n        p1_t = _ptransform(p1)\n        p2_t = _ptransform(p2)\n\n        # calculate derivatives for quadratic interpolation\n        d2 = 2*((y_log2-y_log1)/(p2_t-p1_t) - \\\n                (y_log1-y_log0)/(p1_t-p0_t))/(p2_t-p0_t)\n        if (p2+p0)>=(p1+p1):\n            d1 = (y_log2-y_log1)/(p2_t-p1_t) - 0.5*d2*(p2_t-p1_t)\n        else:\n            d1 = (y_log1-y_log0)/(p1_t-p0_t) + 0.5*d2*(p1_t-p0_t)\n        d0 = y_log1\n\n        # interpolate value\n        y_log = (d2/2.) * (p_t-p1_t)**2. + d1 * (p_t-p1_t) + d0\n\n        # transform back to y\n        y = math.exp(y_log) - float(r)/float(v)\n\n    elif p > .5:\n        # calculate derivatives for quadratic interpolation\n        d2 = 2*((y_log2-y_log1)/(p2-p1) - \\\n                (y_log1-y_log0)/(p1-p0))/(p2-p0)\n        if (p2+p0)>=(p1+p1):\n            d1 = (y_log2-y_log1)/(p2-p1) - 0.5*d2*(p2-p1)\n        else:\n            d1 = (y_log1-y_log0)/(p1-p0) + 0.5*d2*(p1-p0)\n        d0 = y_log1\n\n        # interpolate values\n        y_log = (d2/2.) * (p-p1)**2. + d1 * (p-p1) + d0\n\n        # transform back to y\n        y = math.exp(y_log) - float(r)/float(v)\n\n    else:\n        # linear interpolation in q and p\n        q0 = math.sqrt(2) * -y0 * \\\n             scipy.stats.t.isf((1.+p0)/2., max(v, 1e38))\n        q1 = math.sqrt(2) * -y1 * \\\n             scipy.stats.t.isf((1.+p1)/2., max(v, 1e38))\n\n        d1 = (q1-q0)/(p1-p0)\n        d0 = q0\n\n        # interpolate values\n        q = d1 * (p-p0) + d0\n\n        # transform back to y\n        y = -q / (math.sqrt(2) * \\\n                  scipy.stats.t.isf((1.+p)/2., max(v, 1e38)))\n\n    return y", "response": "interpolates p based on the values in the A table for the given scalar value of r and the scalar value of v."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the points to use for interpolating v", "response": "def _select_vs(v, p):\n    # This one is is about 30 times faster than\n    # the generic algorithm it is replacing.\n    \"\"\"returns the points to use for interpolating v\"\"\"\n\n    if v >= 120.:\n        return 60, 120, inf\n    elif v >= 60.:\n        return 40, 60, 120\n    elif v >= 40.:\n        return 30, 40, 60\n    elif v >= 30.:\n        return 24, 30, 40\n    elif v >= 24.:\n        return 20, 24, 30\n    elif v >= 19.5:\n        return 19, 20, 24\n\n    if p >= .9:\n        if v < 2.5:\n            return 1, 2, 3\n    else:\n        if v < 3.5:\n            return 2, 3, 4\n\n    vi = int(round(v))\n    return vi - 1, vi, vi + 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninterpolates v based on the values in the A table for the given scalar value of r and the values in the third parameter of the A table for the given p and third parameter of the A table for the given r and the values in the third parameter of the A table for the given r.", "response": "def _interpolate_v(p, r, v):\n\n    \"\"\"\n    interpolates v based on the values in the A table for the\n    scalar value of r and th\n    \"\"\"\n    # interpolate v (p should be in table)\n    # ordinate: y**2\n    # abcissa:  1./v\n\n    # find the 3 closest v values\n    # only p >= .9 have table values for 1 degree of freedom.\n    # The boolean is used to index the tuple and append 1 when\n    # p >= .9\n    v0, v1, v2 = _select_vs(v, p)\n\n    # y = f - 1.\n    y0_sq = (_func(A[(p,v0)], p, r, v0) + 1.)**2.\n    y1_sq = (_func(A[(p,v1)], p, r, v1) + 1.)**2.\n    y2_sq = (_func(A[(p,v2)], p, r, v2) + 1.)**2.\n\n    # if v2 is inf set to a big number so interpolation\n    # calculations will work\n    if v2 > 1e38: v2 = 1e38\n\n    # transform v\n    v_, v0_, v1_, v2_ = 1./v, 1./v0, 1./v1, 1./v2\n\n    # calculate derivatives for quadratic interpolation\n    d2 = 2.*((y2_sq-y1_sq)/(v2_-v1_) - \\\n             (y0_sq-y1_sq)/(v0_-v1_)) / (v2_-v0_)\n    if (v2_ + v0_) >= (v1_ + v1_):\n        d1 = (y2_sq-y1_sq) / (v2_-v1_) - 0.5*d2*(v2_-v1_)\n    else:\n        d1 = (y1_sq-y0_sq) / (v1_-v0_) + 0.5*d2*(v1_-v0_)\n    d0 = y1_sq\n\n    # calculate y\n    y = math.sqrt((d2/2.)*(v_-v1_)**2. + d1*(v_-v1_)+ d0)\n\n    return y"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef qsturng(p, r, v):\n\n    if all(map(_isfloat, [p, r, v])):\n        return _qsturng(p, r, v)\n    return _vqsturng(p, r, v)", "response": "Approximates the quantile p for a studentized range\n       distribution having v degrees of freedom and r samples\nATTRIBS for probability r."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef psturng(q, r, v):\n    if all(map(_isfloat, [q, r, v])):\n        return _psturng(q, r, v)\n    return _vpsturng(q, r, v)", "response": "Evaluates the probability from 0 to q for a studentized\n       range having v degrees of freedom and r samples."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nevaluate the power of an ANOVA and return the result.", "response": "def power_anova(eta=None, k=None, n=None, power=None, alpha=0.05):\n    \"\"\"\n    Evaluate power, sample size, effect size or\n    significance level of a one-way balanced ANOVA.\n\n    Parameters\n    ----------\n    eta : float\n        ANOVA effect size (eta-square == :math:`\\\\eta^2`).\n    k : int\n        Number of groups\n    n : int\n        Sample size per group. Groups are assumed to be balanced\n        (i.e. same sample size).\n    power : float\n        Test power (= 1 - type II error).\n    alpha : float\n        Significance level (type I error probability).\n        The default is 0.05.\n\n    Notes\n    -----\n    Exactly ONE of the parameters ``eta``, ``k``, ``n``, ``power`` and\n    ``alpha`` must be passed as None, and that parameter is determined from\n    the others.\n\n    Notice that ``alpha`` has a default value of 0.05 so None must be\n    explicitly passed if you want to compute it.\n\n    This function is a mere Python translation of the original `pwr.anova.test`\n    function implemented in the `pwr` package. All credit goes to the author,\n    Stephane Champely.\n\n    Statistical power is the likelihood that a study will\n    detect an effect when there is an effect there to be detected.\n    A high statistical power means that there is a low probability of\n    concluding that there is no effect when there is one.\n    Statistical power is mainly affected by the effect size and the sample\n    size.\n\n    For one-way ANOVA, eta-square is the same as partial eta-square. It can be\n    evaluated from the f-value and degrees of freedom of the ANOVA using\n    the following formula:\n\n    .. math::\n        \\\\eta^2 = \\\\frac{v_1 F^*}{v_1 F^* + v_2}\n\n    Using :math:`\\\\eta^2` and the total sample size :math:`N`, the\n    non-centrality parameter is defined by:\n\n    .. math:: \\\\delta = N * \\\\frac{\\\\eta^2}{1 - \\\\eta^2}\n\n    Then the critical value of the non-central F-distribution is computed using\n    the percentile point function of the F-distribution with:\n\n    .. math:: q = 1 - alpha\n    .. math:: v_1 = k - 1\n    .. math:: v_2 = N - k\n\n    where :math:`k` is the number of groups.\n\n    Finally, the power of the ANOVA is calculated using the survival function\n    of the non-central F-distribution using the previously computed critical\n    value, non-centrality parameter, and degrees of freedom.\n\n    :py:func:`scipy.optimize.brenth` is used to solve power equations for other\n    variables (i.e. sample size, effect size, or significance level). If the\n    solving fails, a nan value is returned.\n\n    Results have been tested against GPower and the R pwr package.\n\n    References\n    ----------\n\n    .. [1] Cohen, J. (1988). Statistical power analysis for the behavioral\n           sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.\n\n    .. [2] https://cran.r-project.org/web/packages/pwr/pwr.pdf\n\n    Examples\n    --------\n    1. Compute achieved power\n\n    >>> from pingouin import power_anova\n    >>> print('power: %.4f' % power_anova(eta=0.1, k=3, n=20))\n    power: 0.6082\n\n    2. Compute required number of groups\n\n    >>> print('k: %.4f' % power_anova(eta=0.1, n=20, power=0.80))\n    k: 6.0944\n\n    3. Compute required sample size\n\n    >>> print('n: %.4f' % power_anova(eta=0.1, k=3, power=0.80))\n    n: 29.9255\n\n    4. Compute achieved effect size\n\n    >>> print('eta: %.4f' % power_anova(n=20, k=4, power=0.80, alpha=0.05))\n    eta: 0.1255\n\n    5. Compute achieved alpha (significance)\n\n    >>> print('alpha: %.4f' % power_anova(eta=0.1, n=20, k=4, power=0.80,\n    ...                                   alpha=None))\n    alpha: 0.1085\n    \"\"\"\n    # Check the number of arguments that are None\n    n_none = sum([v is None for v in [eta, k, n, power, alpha]])\n    if n_none != 1:\n        err = 'Exactly one of eta, k, n, power, and alpha must be None.'\n        raise ValueError(err)\n\n    # Safety checks\n    if eta is not None:\n        eta = abs(eta)\n        f_sq = eta / (1 - eta)\n    if alpha is not None:\n        assert 0 < alpha <= 1\n    if power is not None:\n        assert 0 < power <= 1\n\n    def func(f_sq, k, n, power, alpha):\n        nc = (n * k) * f_sq\n        dof1 = k - 1\n        dof2 = (n * k) - k\n        fcrit = stats.f.ppf(1 - alpha, dof1, dof2)\n        return stats.ncf.sf(fcrit, dof1, dof2, nc)\n\n    # Evaluate missing variable\n    if power is None:\n        # Compute achieved power\n        return func(f_sq, k, n, power, alpha)\n\n    elif k is None:\n        # Compute required number of groups\n\n        def _eval_k(k, eta, n, power, alpha):\n            return func(f_sq, k, n, power, alpha) - power\n\n        try:\n            return brenth(_eval_k, 2, 100, args=(f_sq, n, power, alpha))\n        except ValueError:  # pragma: no cover\n            return np.nan\n\n    elif n is None:\n        # Compute required sample size\n\n        def _eval_n(n, f_sq, k, power, alpha):\n            return func(f_sq, k, n, power, alpha) - power\n\n        try:\n            return brenth(_eval_n, 2, 1e+07, args=(f_sq, k, power, alpha))\n        except ValueError:  # pragma: no cover\n            return np.nan\n\n    elif eta is None:\n        # Compute achieved eta\n\n        def _eval_eta(f_sq, k, n, power, alpha):\n            return func(f_sq, k, n, power, alpha) - power\n\n        try:\n            f_sq = brenth(_eval_eta, 1e-10, 1 - 1e-10, args=(k, n, power,\n                                                             alpha))\n            return f_sq / (f_sq + 1)  # Return eta-square\n        except ValueError:  # pragma: no cover\n            return np.nan\n\n    else:\n        # Compute achieved alpha\n\n        def _eval_alpha(alpha, f_sq, k, n, power):\n            return func(f_sq, k, n, power, alpha) - power\n\n        try:\n            return brenth(_eval_alpha, 1e-10, 1 - 1e-10, args=(f_sq, k, n,\n                                                               power))\n        except ValueError:  # pragma: no cover\n            return np.nan"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate achieved power given r n and alpha.", "response": "def power_corr(r=None, n=None, power=None, alpha=0.05, tail='two-sided'):\n    \"\"\"\n    Evaluate power, sample size, correlation coefficient or\n    significance level of a correlation test.\n\n    Parameters\n    ----------\n    r : float\n        Correlation coefficient.\n    n : int\n        Number of observations (sample size).\n    power : float\n        Test power (= 1 - type II error).\n    alpha : float\n        Significance level (type I error probability).\n        The default is 0.05.\n    tail : str\n        Indicates whether the test is \"two-sided\" or \"one-sided\".\n\n    Notes\n    -----\n    Exactly ONE of the parameters ``r``, ``n``, ``power`` and ``alpha`` must\n    be passed as None, and that parameter is determined from the others.\n\n    Notice that ``alpha`` has a default value of 0.05 so None must be\n    explicitly passed if you want to compute it.\n\n    :py:func:`scipy.optimize.brenth` is used to solve power equations for other\n    variables (i.e. sample size, effect size, or significance level). If the\n    solving fails, a nan value is returned.\n\n    This function is a mere Python translation of the original `pwr.r.test`\n    function implemented in the `pwr` R package.\n    All credit goes to the author, Stephane Champely.\n\n    References\n    ----------\n\n    .. [1] Cohen, J. (1988). Statistical power analysis for the behavioral\n           sciences (2nd ed.). Hillsdale,NJ: Lawrence Erlbaum.\n\n    .. [2] https://cran.r-project.org/web/packages/pwr/pwr.pdf\n\n    Examples\n    --------\n    1. Compute achieved power given ``r``, ``n`` and ``alpha``\n\n    >>> from pingouin import power_corr\n    >>> print('power: %.4f' % power_corr(r=0.5, n=20))\n    power: 0.6379\n\n    2. Compute required sample size given ``r``, ``power`` and ``alpha``\n\n    >>> print('n: %.4f' % power_corr(r=0.5, power=0.80,\n    ...                                tail='one-sided'))\n    n: 22.6091\n\n    3. Compute achieved ``r`` given ``n``, ``power`` and ``alpha`` level\n\n    >>> print('r: %.4f' % power_corr(n=20, power=0.80, alpha=0.05))\n    r: 0.5822\n\n    4. Compute achieved alpha level given ``r``, ``n`` and ``power``\n\n    >>> print('alpha: %.4f' % power_corr(r=0.5, n=20, power=0.80,\n    ...                                    alpha=None))\n    alpha: 0.1377\n    \"\"\"\n    # Check the number of arguments that are None\n    n_none = sum([v is None for v in [r, n, power, alpha]])\n    if n_none != 1:\n        raise ValueError('Exactly one of n, r, power, and alpha must be None')\n\n    # Safety checks\n    if r is not None:\n        assert -1 <= r <= 1\n        r = abs(r)\n    if alpha is not None:\n        assert 0 < alpha <= 1\n    if power is not None:\n        assert 0 < power <= 1\n    if n is not None:\n        assert n > 4\n\n    # Define main function\n    if tail == 'two-sided':\n\n        def func(r, n, power, alpha):\n            dof = n - 2\n            ttt = stats.t.ppf(1 - alpha / 2, dof)\n            rc = np.sqrt(ttt**2 / (ttt**2 + dof))\n            zr = np.arctanh(r) + r / (2 * (n - 1))\n            zrc = np.arctanh(rc)\n            power = stats.norm.cdf((zr - zrc) * np.sqrt(n - 3)) + \\\n                stats.norm.cdf((-zr - zrc) * np.sqrt(n - 3))\n            return power\n\n    else:\n\n        def func(r, n, power, alpha):\n            dof = n - 2\n            ttt = stats.t.ppf(1 - alpha, dof)\n            rc = np.sqrt(ttt**2 / (ttt**2 + dof))\n            zr = np.arctanh(r) + r / (2 * (n - 1))\n            zrc = np.arctanh(rc)\n            power = stats.norm.cdf((zr - zrc) * np.sqrt(n - 3))\n            return power\n\n    # Evaluate missing variable\n    if power is None and n is not None and r is not None:\n        # Compute achieved power given r, n and alpha\n        return func(r, n, power=None, alpha=alpha)\n\n    elif n is None and power is not None and r is not None:\n        # Compute required sample size given r, power and alpha\n\n        def _eval_n(n, r, power, alpha):\n            return func(r, n, power, alpha) - power\n\n        try:\n            return brenth(_eval_n, 4 + 1e-10, 1e+09, args=(r, power, alpha))\n        except ValueError:  # pragma: no cover\n            return np.nan\n\n    elif r is None and power is not None and n is not None:\n        # Compute achieved r given sample size, power and alpha level\n\n        def _eval_r(r, n, power, alpha):\n            return func(r, n, power, alpha) - power\n\n        try:\n            return brenth(_eval_r, 1e-10, 1 - 1e-10, args=(n, power, alpha))\n        except ValueError:  # pragma: no cover\n            return np.nan\n\n    else:\n        # Compute achieved alpha (significance) level given r, n and power\n\n        def _eval_alpha(alpha, r, n, power):\n            return func(r, n, power, alpha) - power\n\n        try:\n            return brenth(_eval_alpha, 1e-10, 1 - 1e-10, args=(r, n, power))\n        except ValueError:  # pragma: no cover\n            return np.nan"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting consuming the stream.", "response": "def consume(self, timeout=None, loop=None):\n        \"\"\"Start consuming the stream\n\n        :param timeout: int: if it's given then it stops consumer after given\n        number of seconds\n        \"\"\"\n        if self._consumer_fn is None:\n            raise ValueError('Consumer function is not defined yet')\n\n        logger.info('Start consuming the stream')\n\n        @asyncio.coroutine\n        def worker(conn_url):\n            extra_headers = {\n                'Connection': 'upgrade',\n                'Upgrade': 'websocket',\n                'Sec-Websocket-Version': 13,\n            }\n\n            ws = yield from websockets.connect(\n                conn_url, extra_headers=extra_headers)\n\n            if ws is None:\n                raise RuntimeError(\"Couldn't connect to the '%s'\" % conn_url)\n\n            try:\n                while True:\n                    message = yield from ws.recv()\n                    yield from self._consumer_fn(message)\n            finally:\n                yield from ws.close()\n\n        if loop is None:\n            loop = asyncio.new_event_loop()\n\n        asyncio.set_event_loop(loop)\n        try:\n            task = worker(conn_url=self._conn_url)\n            if timeout:\n                logger.info('Running task with timeout %s sec', timeout)\n                loop.run_until_complete(\n                    asyncio.wait_for(task, timeout=timeout))\n            else:\n                loop.run_until_complete(task)\n        except asyncio.TimeoutError:\n            logger.info('Timeout is reached. Closing the loop')\n            loop.close()\n        except KeyboardInterrupt:\n            logger.info('Closing the loop')\n            loop.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_rule(self, value, tag):\n        resp = requests.post(url=self.REQUEST_URL.format(**self._params),\n                             json={'rule': {'value': value, 'tag': tag}})\n        return resp.json()", "response": "Add a new rule to the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a rule by tag", "response": "def remove_rule(self, tag):\n        \"\"\"Remove a rule by tag\n\n        \"\"\"\n        resp = requests.delete(url=self.REQUEST_URL.format(**self._params),\n                               json={'tag': tag})\n        return resp.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncoercing iterable values to val1 val2 valN", "response": "def stringify_values(data):\n    \"\"\"Coerce iterable values to 'val1,val2,valN'\n\n    Example:\n        fields=['nickname', 'city', 'can_see_all_posts']\n        --> fields='nickname,city,can_see_all_posts'\n\n    :param data: dict\n    :return: converted values dict\n    \"\"\"\n    if not isinstance(data, dict):\n        raise ValueError('Data must be dict. %r is passed' % data)\n\n    values_dict = {}\n    for key, value in data.items():\n        items = []\n        if isinstance(value, six.string_types):\n            items.append(value)\n        elif isinstance(value, Iterable):\n            for v in value:\n                # Convert to str int values\n                if isinstance(v, int):\n                    v = str(v)\n                try:\n                    item = six.u(v)\n                except TypeError:\n                    item = v\n                items.append(item)\n            value = ','.join(items)\n        values_dict[key] = value\n    return values_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_url_query_params(url, fragment=True):\n    parsed_url = urlparse(url)\n    if fragment:\n        url_query = parse_qsl(parsed_url.fragment)\n    else:\n        url_query = parse_qsl(parsed_url.query)\n    # login_response_url_query can have multiple key\n    url_query = dict(url_query)\n    return url_query", "response": "Parse url query params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the action url from the html.", "response": "def parse_form_action_url(html, parser=None):\n    \"\"\"Parse <form action=\"(.+)\"> url\n\n    :param html: str: raw html text\n    :param parser: bs4.BeautifulSoup: html parser\n    :return: url str: for example: /login.php?act=security_check&to=&hash=12346\n    \"\"\"\n    if parser is None:\n        parser = bs4.BeautifulSoup(html, 'html.parser')\n\n    forms = parser.find_all('form')\n    if not forms:\n        raise VkParseError('Action form is not found in the html \\n%s' % html)\n    if len(forms) > 1:\n        raise VkParseError('Find more than 1 forms to handle:\\n%s', forms)\n    form = forms[0]\n    return form.get('action')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_masked_phone_number(html, parser=None):\n    if parser is None:\n        parser = bs4.BeautifulSoup(html, 'html.parser')\n\n    fields = parser.find_all('span', {'class': 'field_prefix'})\n    if not fields:\n        raise VkParseError(\n            'No <span class=\"field_prefix\">...</span> in the \\n%s' % html)\n\n    result = []\n    for f in fields:\n        value = f.get_text().replace(six.u('\\xa0'), '')\n        result.append(value)\n    return tuple(result)", "response": "Get masked phone number from security check html."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_html_warnings(html, parser=None):\n    if parser is None:\n        parser = bs4.BeautifulSoup(html, 'html.parser')\n\n    # Check warnings\n    warnings = parser.find_all('div', {'class': 'service_msg_warning'})\n    if warnings:\n        raise VkPageWarningsError('; '.join([w.get_text() for w in warnings]))\n    return True", "response": "Check if html has any warnings"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndoes vk login :param http_session: vk_requests.utils.VerboseHTTPSession: http session", "response": "def do_login(self, http_session):\n        \"\"\"Do vk login\n\n        :param http_session: vk_requests.utils.VerboseHTTPSession: http session\n        \"\"\"\n\n        response = http_session.get(self.LOGIN_URL)\n        action_url = parse_form_action_url(response.text)\n\n        # Stop login it action url is not found\n        if not action_url:\n            logger.debug(response.text)\n            raise VkParseError(\"Can't parse form action url\")\n\n        login_form_data = {'email': self._login, 'pass': self._password}\n        login_response = http_session.post(action_url, login_form_data)\n        logger.debug('Cookies: %s', http_session.cookies)\n\n        response_url_query = parse_url_query_params(\n            login_response.url, fragment=False)\n\n        logger.debug('response_url_query: %s', response_url_query)\n        act = response_url_query.get('act')\n\n        # Check response url query params firstly\n        if 'sid' in response_url_query:\n            self.require_auth_captcha(\n                response=login_response,\n                query_params=response_url_query,\n                login_form_data=login_form_data,\n                http_session=http_session)\n\n        elif act == 'authcheck':\n            self.require_2fa(html=login_response.text,\n                             http_session=http_session)\n\n        elif act == 'security_check':\n            self.require_phone_number(html=login_response.text,\n                                      session=http_session)\n\n        session_cookies = ('remixsid' in http_session.cookies,\n                           'remixsid6' in http_session.cookies)\n        if any(session_cookies):\n            logger.info('VK session is established')\n            return True\n        else:\n            message = 'Authorization error: incorrect password or ' \\\n                      'authentication code'\n            logger.error(message)\n            raise VkAuthError(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_direct_authorization(self, session):\n        logger.info('Doing direct authorization, app_id=%s', self.app_id)\n        auth_data = {\n            'client_id': self.app_id,\n            'client_secret': self._client_secret,\n            'username': self._login,\n            'password': self._password,\n            'grant_type': 'password',\n            '2fa_supported': self._two_fa_supported,\n            'scope': self.scope,\n            'v': self.api_version\n        }\n        response = session.post(url=self.DIRECT_AUTHORIZE_URL,\n                                data=stringify_values(auth_data))\n        try:\n            response_json = response.json()\n        except ValueError:  # not JSON in response\n            error_message = 'OAuth2 grant access error'\n            logger.error(response.text)\n            raise VkAuthError(error_message)\n        else:\n            if 'access_token' in response_json:\n                return response_json\n\n            if response_json['error'] == 'need_validation':\n                return self.direct_auth_require_2fa(session, auth_data)\n            elif response_json['error'] == 'need_captcha':\n                return self.direct_auth_require_captcha(session, response_json, auth_data)\n            else:\n                error_message = 'VK error: [{}] {}'.format(\n                    response_json['error'], response_json['error_description'])\n                raise VkAuthError(error_message)", "response": "Direct authorization for the current user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves auth captcha case", "response": "def require_auth_captcha(self, response, query_params,\n                             login_form_data, http_session):\n        \"\"\"Resolve auth captcha case\n\n        :param response: http response\n        :param query_params: dict: response query params, for example:\n        {'s': '0', 'email': 'my@email', 'dif': '1', 'role': 'fast', 'sid': '1'}\n\n        :param login_form_data: dict\n        :param http_session: requests.Session\n        :return: :raise VkAuthError:\n        \"\"\"\n        logger.info('Captcha is needed. Query params: %s', query_params)\n        form_text = response.text\n\n        action_url = parse_form_action_url(form_text)\n        logger.debug('form action url: %s', action_url)\n        if not action_url:\n            raise VkAuthError('Cannot find form action url')\n\n        captcha_sid, captcha_url = parse_captcha_html(\n            html=response.text, response_url=response.url)\n        logger.info('Captcha url %s', captcha_url)\n\n        login_form_data['captcha_sid'] = captcha_sid\n        login_form_data['captcha_key'] = self.get_captcha_key(captcha_url)\n\n        response = http_session.post(action_url, login_form_data)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_access_token(self):\n        if self._service_token:\n            logger.info('Use service token: %s',\n                        5 * '*' + self._service_token[50:])\n            return self._service_token\n\n        if not all([self.app_id, self._login, self._password]):\n            raise ValueError(\n                'app_id=%s, login=%s password=%s (masked) must be given'\n                % (self.app_id, self._login,\n                   '*' * len(self._password) if self._password else 'None'))\n\n        logger.info(\"Getting access token for user '%s'\" % self._login)\n        with self.http_session as s:\n            if self._client_secret:\n                url_query_params = self.do_direct_authorization(session=s)\n            else:\n                self.do_login(http_session=s)\n                url_query_params = self.do_implicit_flow_authorization(session=s)\n            logger.debug('url_query_params: %s', url_query_params)\n\n        if 'access_token' in url_query_params:\n            logger.info('Access token has been gotten')\n            return url_query_params['access_token']\n        else:\n            raise VkAuthError('OAuth2 authorization error. Url params: %s'\n                              % url_query_params)", "response": "Get access token using app_id login and password OR service token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread CAPTCHA key from user input", "response": "def get_captcha_key(self, captcha_image_url):\n        \"\"\"Read CAPTCHA key from user input\"\"\"\n\n        if self.interactive:\n            print('Open CAPTCHA image url in your browser and enter it below: ',\n                  captcha_image_url)\n            captcha_key = raw_input('Enter CAPTCHA key: ')\n            return captcha_key\n        else:\n            raise VkAuthError(\n                'Captcha is required. Use interactive mode to enter it '\n                'manually')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake API request helper function", "response": "def make_request(self, request, captcha_response=None):\n        \"\"\"Make api request helper function\n\n        :param request: vk_requests.api.Request instance\n        :param captcha_response: None or dict, e.g {'sid': <sid>, 'key': <key>}\n        :return: dict: json decoded http response\n        \"\"\"\n        logger.debug('Prepare API Method request %r', request)\n        response = self._send_api_request(request=request,\n                                          captcha_response=captcha_response)\n        response.raise_for_status()\n        response_or_error = json.loads(response.text)\n        logger.debug('response: %s', response_or_error)\n\n        if 'error' in response_or_error:\n            error_data = response_or_error['error']\n            vk_error = VkAPIError(error_data)\n\n            if vk_error.is_captcha_needed():\n                captcha_key = self.get_captcha_key(vk_error.captcha_img_url)\n                if not captcha_key:\n                    raise vk_error\n\n                # Retry http request with captcha info attached\n                captcha_response = {\n                    'sid': vk_error.captcha_sid,\n                    'key': captcha_key,\n                }\n                return self.make_request(\n                    request, captcha_response=captcha_response)\n\n            elif vk_error.is_access_token_incorrect():\n                logger.info(\n                    'Authorization failed. Access token will be dropped')\n                self._access_token = None\n                return self.make_request(request)\n\n            else:\n                raise vk_error\n        elif 'execute_errors' in response_or_error:\n            # can take place while running .execute vk method\n            # See more: https://vk.com/dev/execute\n            raise VkAPIError(response_or_error['execute_errors'][0])\n        elif 'response' in response_or_error:\n            return response_or_error['response']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _send_api_request(self, request, captcha_response=None):\n        url = self.API_URL + request.method_name\n\n        # Prepare request arguments\n        method_kwargs = {'v': self.api_version}\n\n        # Shape up the request data\n        for values in (request.method_args,):\n            method_kwargs.update(stringify_values(values))\n\n        if self.is_token_required() or self._service_token:\n            # Auth api call if access_token hadn't been gotten earlier\n            method_kwargs['access_token'] = self.access_token\n\n        if captcha_response:\n            method_kwargs['captcha_sid'] = captcha_response['sid']\n            method_kwargs['captcha_key'] = captcha_response['key']\n\n        http_params = dict(url=url,\n                           data=method_kwargs,\n                           **request.http_params)\n        logger.debug('send_api_request:http_params: %s', http_params)\n        response = self.http_session.post(**http_params)\n        return response", "response": "Prepare and send the HTTP API request to the VK API."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_api(app_id=None, login=None, password=None, phone_number=None,\n               scope='offline', api_version='5.92', http_params=None,\n               interactive=False, service_token=None, client_secret=None,\n               two_fa_supported=False, two_fa_force_sms=False):\n    \"\"\"Factory method to explicitly create API with app_id, login, password\n    and phone_number parameters.\n\n    If the app_id, login, password are not passed, then token-free session\n    will be created automatically\n\n    :param app_id: int: vk application id, more info: https://vk.com/dev/main\n    :param login: str: vk login\n    :param password: str: vk password\n    :param phone_number: str: phone number with country code (+71234568990)\n    :param scope: str or list of str: vk session scope\n    :param api_version: str: vk api version, check https://vk.com/dev/versions\n    :param interactive: bool: flag which indicates to use InteractiveVKSession\n    :param service_token: str: new way of querying vk api, instead of getting\n    oauth token\n    :param http_params: dict: requests http parameters passed along\n    :param client_secret: str: secure application key for Direct Authorization,\n    more info: https://vk.com/dev/auth_direct\n    :param two_fa_supported: bool: enable two-factor authentication for Direct Authorization,\n    more info: https://vk.com/dev/auth_direct\n    :param two_fa_force_sms: bool: force SMS two-factor authentication for Direct Authorization\n    if two_fa_supported is True, more info: https://vk.com/dev/auth_direct\n    :return: api instance\n    :rtype : vk_requests.api.API\n    \"\"\"\n    session = VKSession(app_id=app_id,\n                        user_login=login,\n                        user_password=password,\n                        phone_number=phone_number,\n                        scope=scope,\n                        service_token=service_token,\n                        api_version=api_version,\n                        interactive=interactive,\n                        client_secret=client_secret,\n                        two_fa_supported = two_fa_supported,\n                        two_fa_force_sms=two_fa_force_sms)\n    return API(session=session, http_params=http_params)", "response": "Create API instance with user_id login password and phone_number parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url(self, host):\n        path = '/'.join(str(v) for v in self._path)\n        return 'coaps://{}:5684/{}'.format(host, path)", "response": "Generate url for coap client."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _merge(self, a, b):\n        for k, v in a.items():\n            if isinstance(v, dict):\n                item = b.setdefault(k, {})\n                self._merge(v, item)\n            elif isinstance(v, list):\n                item = b.setdefault(k, [{}])\n                if len(v) == 1 and isinstance(v[0], dict):\n                    self._merge(v[0], item[0])\n                else:\n                    b[k] = v\n            else:\n                b[k] = v\n        return b", "response": "Merges a into b."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncombine the data for this command with another command.", "response": "def combine_data(self, command2):\n        \"\"\"Combines the data for this command with another.\"\"\"\n        if command2 is None:\n            return\n        self._data = self._merge(command2._data, self._data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads JSON data from a file and return as list or dict.", "response": "def load_json(filename: str) -> Union[List, Dict]:\n    \"\"\"Load JSON data from a file and return as dict or list.\n\n    Defaults to returning empty dict if file is not found.\n    \"\"\"\n    try:\n        with open(filename, encoding='utf-8') as fdesc:\n            return json.loads(fdesc.read())\n    except FileNotFoundError:\n        # This is not a fatal error\n        _LOGGER.debug('JSON file not found: %s', filename)\n    except ValueError as error:\n        _LOGGER.exception('Could not parse JSON content: %s', filename)\n        raise PytradfriError(error)\n    except OSError as error:\n        _LOGGER.exception('JSON file reading failed: %s', filename)\n        raise PytradfriError(error)\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving JSON data to a file.", "response": "def save_json(filename: str, config: Union[List, Dict]):\n    \"\"\"Save JSON data to a file.\n\n    Returns True on success.\n    \"\"\"\n    try:\n        data = json.dumps(config, sort_keys=True, indent=4)\n        with open(filename, 'w', encoding='utf-8') as fdesc:\n            fdesc.write(data)\n            return True\n    except TypeError as error:\n        _LOGGER.exception('Failed to serialize to JSON: %s',\n                          filename)\n        raise PytradfriError(error)\n    except OSError as error:\n        _LOGGER.exception('Saving JSON file failed: %s',\n                          filename)\n        raise PytradfriError(error)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_selected_keys(self, selection):\n        return [k for k, b in self._lookup.items() if b & selection]", "response": "Return a list of keys for the given selection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of values for the given selection.", "response": "def get_selected_values(self, selection):\n        \"\"\"Return a list of values for the given selection.\"\"\"\n        return [v for b, v in self._choices if b & selection]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_output(output, parse_json=True):\n    output = output.strip()\n    _LOGGER.debug('Received: %s', output)\n\n    if not output:\n        return None\n\n    elif 'decrypt_verify' in output:\n        raise RequestError(\n            'Please compile coap-client without debug output. See '\n            'instructions at '\n            'https://github.com/ggravlingen/pytradfri#installation')\n\n    elif output.startswith(CLIENT_ERROR_PREFIX):\n        raise ClientError(output)\n\n    elif output.startswith(SERVER_ERROR_PREFIX):\n        raise ServerError(output)\n\n    elif not parse_json:\n        return output\n\n    return json.loads(output)", "response": "Process output from coap - client."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretry API call when a timeout occurs.", "response": "def retry_timeout(api, retries=3):\n    \"\"\"Retry API call when a timeout occurs.\"\"\"\n    @wraps(api)\n    def retry_api(*args, **kwargs):\n        \"\"\"Retrying API.\"\"\"\n        for i in range(1, retries + 1):\n            try:\n                return api(*args, **kwargs)\n            except RequestTimeout:\n                if i == retries:\n                    raise\n\n    return retry_api"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef request(self, api_commands, *, timeout=None):\n        if not isinstance(api_commands, list):\n            return self._execute(api_commands, timeout=timeout)\n\n        command_results = []\n\n        for api_command in api_commands:\n            result = self._execute(api_command, timeout=timeout)\n            command_results.append(result)\n\n        return command_results", "response": "Make a request. Timeout is in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates and set a psk from the security key.", "response": "def generate_psk(self, security_key):\n        \"\"\"\n        Generate and set a psk from the security key.\n        \"\"\"\n        if not self._psk:\n            # Backup the real identity.\n            existing_psk_id = self._psk_id\n\n            # Set the default identity and security key for generation.\n            self._psk_id = 'Client_identity'\n            self._psk = security_key\n\n            # Ask the Gateway to generate the psk for the identity.\n            self._psk = self.request(Gateway().generate_psk(existing_psk_id))\n\n            # Restore the real identity.\n            self._psk_id = existing_psk_id\n\n        return self._psk"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the time the task starts.", "response": "def task_start_time(self):\n        \"\"\"Return the time the task starts.\n\n        Time is set according to iso8601.\n        \"\"\"\n        return datetime.time(\n            self.task_start_parameters[\n                ATTR_SMART_TASK_TRIGGER_TIME_START_HOUR],\n            self.task_start_parameters[\n                ATTR_SMART_TASK_TRIGGER_TIME_START_MIN])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tasks(self):\n        return [StartActionItem(\n            self._task,\n            i,\n            self.state,\n            self.path,\n            self.raw) for i in range(len(self.raw))]", "response": "Return the list of task objects of the task control."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_dimmer_start_time(self, hour, minute):\n        #  This is to calculate the difference between local time\n        #  and the time in the gateway\n        d1 = self._gateway.get_gateway_info().current_time\n        d2 = dt.utcnow()\n        diff = d1 - d2\n        newtime = dt(100, 1, 1, hour, minute, 00) - diff\n\n        command = {\n            ATTR_SMART_TASK_TRIGGER_TIME_INTERVAL:\n                [{\n                    ATTR_SMART_TASK_TRIGGER_TIME_START_HOUR: newtime.hour,\n                    ATTR_SMART_TASK_TRIGGER_TIME_START_MIN: newtime.minute\n                }]\n            }\n        return self._task.set_values(command)", "response": "Set start time for task in iso8601."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns state of start action task.", "response": "def devices(self):\n        \"\"\"Return state of start action task.\"\"\"\n        return [StartActionItem(\n            self.start_action,\n            i,\n            self.state,\n            self.path,\n            self.raw) for i in range(\n                len(self.raw[ROOT_START_ACTION]))]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning state of start action task.", "response": "def devices_dict(self):\n        \"\"\"Return state of start action task.\"\"\"\n        json_list = {}\n        z = 0\n        for x in self._raw[ROOT_START_ACTION]:\n            if z != self.index:\n                json_list.update(x)\n            z = z + 1\n        return json_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef item_controller(self):\n        return StartActionItemController(\n            self,\n            self.raw,\n            self.state,\n            self.path,\n            self.devices_dict)", "response": "Method to control a task."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_dimmer(self, dimmer):\n        command = {\n            ATTR_START_ACTION: {\n                    ATTR_DEVICE_STATE: self.state,\n                    ROOT_START_ACTION: [{\n                        ATTR_ID: self.raw[ATTR_ID],\n                        ATTR_LIGHT_DIMMER: dimmer,\n                        ATTR_TRANSITION_TIME: self.raw[ATTR_TRANSITION_TIME]\n                    }, self.devices_dict]\n                }\n            }\n        return self.set_values(command)", "response": "Set final dimmer value for task."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_transition_time(self, transition_time):\n        command = {\n            ATTR_START_ACTION: {\n                    ATTR_DEVICE_STATE: self.state,\n                    ROOT_START_ACTION: [{\n                        ATTR_ID: self.raw[ATTR_ID],\n                        ATTR_LIGHT_DIMMER: self.raw[ATTR_LIGHT_DIMMER],\n                        ATTR_TRANSITION_TIME: transition_time * 10 * 60\n                    }, self.devices_dict]\n                }\n            }\n        return self.set_values(command)", "response": "Set time for light transition."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nobserve resource and call callback when updated.", "response": "def observe(self, callback, err_callback, duration=60):\n        \"\"\"Observe resource and call callback when updated.\"\"\"\n        def observe_callback(value):\n            \"\"\"\n            Called when end point is updated.\n\n            Returns a Command.\n            \"\"\"\n            self.raw = value\n            callback(self)\n\n        return Command('get', self.path, process_result=observe_callback,\n                       err_callback=err_callback,\n                       observe=True,\n                       observe_duration=duration)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the group. Returns a Command.", "response": "def update(self):\n        \"\"\"\n        Update the group.\n\n        Returns a Command.\n        \"\"\"\n        def process_result(result):\n            self.raw = result\n        return Command('get', self.path, process_result=process_result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_psk(self, identity):\n        def process_result(result):\n            return result[ATTR_PSK]\n\n        return Command('post', [ROOT_GATEWAY, ATTR_AUTH], {\n            ATTR_IDENTITY: identity\n        }, process_result=process_result)", "response": "Generates the PRE_SHARED_KEY from the gateway."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all available endpoints on the gateway.", "response": "def get_endpoints(self):\n        \"\"\"\n        Return all available endpoints on the gateway.\n\n        Returns a Command.\n        \"\"\"\n        def process_result(result):\n            return [line.split(';')[0][2:-1] for line in result.split(',')]\n\n        return Command('get', ['.well-known', 'core'], parse_json=False,\n                       process_result=process_result)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the devices linked to the gateway.", "response": "def get_devices(self):\n        \"\"\"\n        Return the devices linked to the gateway.\n\n        Returns a Command.\n        \"\"\"\n        def process_result(result):\n            return [self.get_device(dev) for dev in result]\n\n        return Command('get', [ROOT_DEVICES], process_result=process_result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a specific device.", "response": "def get_device(self, device_id):\n        \"\"\"\n        Return specified device.\n\n        Returns a Command.\n        \"\"\"\n        def process_result(result):\n            return Device(result)\n\n        return Command('get', [ROOT_DEVICES, device_id],\n                       process_result=process_result)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_groups(self):\n        def process_result(result):\n            return [self.get_group(group) for group in result]\n\n        return Command('get', [ROOT_GROUPS], process_result=process_result)", "response": "Returns the groups linked to the gateway."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a specific group.", "response": "def get_group(self, group_id):\n        \"\"\"\n        Return specified group.\n\n        Returns a Command.\n        \"\"\"\n        def process_result(result):\n            return Group(self, result)\n\n        return Command('get', [ROOT_GROUPS, group_id],\n                       process_result=process_result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_gateway_info(self):\n        def process_result(result):\n            return GatewayInfo(result)\n\n        return Command('get',\n                       [ROOT_GATEWAY, ATTR_GATEWAY_INFO],\n                       process_result=process_result)", "response": "Return the gateway info."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_moods(self):\n        mood_parent = self._get_mood_parent()\n\n        def process_result(result):\n            return [self.get_mood(mood, mood_parent=mood_parent) for mood in\n                    result]\n\n        return Command('get', [ROOT_MOODS, mood_parent],\n                       process_result=process_result)", "response": "Returns a Command that returns the moods defined on the gateway."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a mood from the API.", "response": "def get_mood(self, mood_id, *, mood_parent=None):\n        \"\"\"\n        Return a mood.\n\n        Returns a Command.\n        \"\"\"\n        if mood_parent is None:\n            mood_parent = self._get_mood_parent()\n\n        def process_result(result):\n            return Mood(result, mood_parent)\n\n        return Command('get', [ROOT_MOODS, mood_parent, mood_id],\n                       mood_parent, process_result=process_result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_smart_tasks(self):\n        def process_result(result):\n            return [self.get_smart_task(task) for task in result]\n\n        return Command('get', [ROOT_SMART_TASKS],\n                       process_result=process_result)", "response": "Returns the list of smart tasks linked to the gateway."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning specified transition. Returns a Command.", "response": "def get_smart_task(self, task_id):\n        \"\"\"\n        Return specified transition.\n\n        Returns a Command.\n        \"\"\"\n        def process_result(result):\n            return SmartTask(self, result)\n\n        return Command('get', [ROOT_SMART_TASKS, task_id],\n                       process_result=process_result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstrings representation of current power source.", "response": "def power_source_str(self):\n        \"\"\"String representation of current power source.\"\"\"\n        if DeviceInfo.ATTR_POWER_SOURCE not in self.raw:\n            return None\n        return DeviceInfo.VALUE_POWER_SOURCES.get(self.power_source, 'Unknown')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of light objects of the light control.", "response": "def lights(self):\n        \"\"\"Return light objects of the light control.\"\"\"\n        return [Light(self._device, i) for i in range(len(self.raw))]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the state of a light.", "response": "def set_state(self, state, *, index=0):\n        \"\"\"Set state of a light.\"\"\"\n        return self.set_values({\n            ATTR_DEVICE_STATE: int(state)\n        }, index=index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_dimmer(self, dimmer, *, index=0, transition_time=None):\n        self._value_validate(dimmer, RANGE_BRIGHTNESS, \"Dimmer\")\n\n        values = {\n            ATTR_LIGHT_DIMMER: dimmer\n        }\n\n        if transition_time is not None:\n            values[ATTR_TRANSITION_TIME] = transition_time\n\n        return self.set_values(values, index=index)", "response": "Set dimmer value of a light."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_color_temp(self, color_temp, *, index=0, transition_time=None):\n        self._value_validate(color_temp, RANGE_MIREDS, \"Color temperature\")\n\n        values = {\n            ATTR_LIGHT_MIREDS: color_temp\n        }\n\n        if transition_time is not None:\n            values[ATTR_TRANSITION_TIME] = transition_time\n\n        return self.set_values(values, index=index)", "response": "Set color temperature a light."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the hex color of the light.", "response": "def set_hex_color(self, color, *, index=0, transition_time=None):\n        \"\"\"Set hex color of the light.\"\"\"\n        values = {\n            ATTR_LIGHT_COLOR_HEX: color,\n        }\n\n        if transition_time is not None:\n            values[ATTR_TRANSITION_TIME] = transition_time\n\n        return self.set_values(values, index=index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets xy color of the light.", "response": "def set_xy_color(self, color_x, color_y, *, index=0, transition_time=None):\n        \"\"\"Set xy color of the light.\"\"\"\n        self._value_validate(color_x, RANGE_X, \"X color\")\n        self._value_validate(color_y, RANGE_Y, \"Y color\")\n\n        values = {\n            ATTR_LIGHT_COLOR_X: color_x,\n            ATTR_LIGHT_COLOR_Y: color_y\n        }\n\n        if transition_time is not None:\n            values[ATTR_TRANSITION_TIME] = transition_time\n\n        return self.set_values(values, index=index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_hsb(self, hue, saturation, brightness=None, *, index=0,\n                transition_time=None):\n        \"\"\"Set HSB color settings of the light.\"\"\"\n        self._value_validate(hue, RANGE_HUE, \"Hue\")\n        self._value_validate(saturation, RANGE_SATURATION, \"Saturation\")\n\n        values = {\n            ATTR_LIGHT_COLOR_SATURATION: saturation,\n            ATTR_LIGHT_COLOR_HUE: hue\n        }\n\n        if brightness is not None:\n            values[ATTR_LIGHT_DIMMER] = brightness\n            self._value_validate(brightness, RANGE_BRIGHTNESS, \"Brightness\")\n\n        if transition_time is not None:\n            values[ATTR_TRANSITION_TIME] = transition_time\n\n        return self.set_values(values, index=index)", "response": "Set HSB color settings of the light."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _value_validate(self, value, rnge, identifier=\"Given\"):\n        if value is not None and (value < rnge[0] or value > rnge[1]):\n            raise ValueError('%s value must be between %d and %d.'\n                             % (identifier, rnge[0], rnge[1]))", "response": "Validate that a value is within a given range."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_values(self, values, *, index=0):\n        assert len(self.raw) == 1, \\\n            'Only devices with 1 light supported'\n\n        return Command('put', self._device.path, {\n            ATTR_LIGHT_CONTROL: [\n                values\n            ]\n        })", "response": "Set values on light control."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sockets(self):\n        return [Socket(self._device, i) for i in range(len(self.raw))]", "response": "Return a list of socket objects of the socket control."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the response from the server.", "response": "def _process_output(res, parse_json=True):\n    \"\"\"Process output.\"\"\"\n    res_payload = res.payload.decode('utf-8')\n    output = res_payload.strip()\n\n    _LOGGER.debug('Status: %s, Received: %s', res.code, output)\n\n    if not output:\n        return None\n\n    if not res.code.is_successful():\n        if 128 <= res.code < 160:\n            raise ClientError(output)\n        elif 160 <= res.code < 192:\n            raise ServerError(output)\n\n    if not parse_json:\n        return output\n\n    return json.loads(output)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def _get_protocol(self):\n        if self._protocol is None:\n            self._protocol = asyncio.Task(Context.create_client_context(\n                loop=self._loop))\n        return (await self._protocol)", "response": "Get the protocol for the request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset the protocol if an error occurs.", "response": "async def _reset_protocol(self, exc=None):\n        \"\"\"Reset the protocol if an error occurs.\"\"\"\n        # Be responsible and clean up.\n        protocol = await self._get_protocol()\n        await protocol.shutdown()\n        self._protocol = None\n        # Let any observers know the protocol has been shutdown.\n        for ob_error in self._observations_err_callbacks:\n            ob_error(exc)\n        self._observations_err_callbacks.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def _get_response(self, msg):\n        try:\n            protocol = await self._get_protocol()\n            pr = protocol.request(msg)\n            r = await pr.response\n            return pr, r\n        except ConstructionRenderableError as e:\n            raise ClientError(\"There was an error with the request.\", e)\n        except RequestTimedOut as e:\n            await self._reset_protocol(e)\n            raise RequestTimeout('Request timed out.', e)\n        except (OSError, socket.gaierror, Error) as e:\n            # aiocoap sometimes raises an OSError/socket.gaierror too.\n            # aiocoap issue #124\n            await self._reset_protocol(e)\n            raise ServerError(\"There was an error with the request.\", e)\n        except asyncio.CancelledError as e:\n            await self._reset_protocol(e)\n            raise e", "response": "Perform the request get the response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def generate_psk(self, security_key):\n        if not self._psk:\n            PatchedDTLSSecurityStore.IDENTITY = 'Client_identity'.encode(\n                'utf-8')\n            PatchedDTLSSecurityStore.KEY = security_key.encode('utf-8')\n\n            command = Gateway().generate_psk(self._psk_id)\n            self._psk = await self.request(command)\n\n            PatchedDTLSSecurityStore.IDENTITY = self._psk_id.encode('utf-8')\n            PatchedDTLSSecurityStore.KEY = self._psk.encode('utf-8')\n\n            # aiocoap has now cached our psk, so it must be reset.\n            # We also no longer need the protocol, so this will clean that up.\n            await self._reset_protocol()\n\n        return self._psk", "response": "Generate and set a psk from the security key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of member ID s for this group.", "response": "def member_ids(self):\n        \"\"\"Members of this group.\"\"\"\n        info = self.raw.get(ATTR_MEMBERS, {})\n\n        if not info or ROOT_DEVICES2 not in info:\n            return []\n\n        return info[ROOT_DEVICES2].get(ATTR_ID, [])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_dimmer(self, dimmer, transition_time=None):\n        values = {\n            ATTR_LIGHT_DIMMER: dimmer,\n        }\n        if transition_time is not None:\n            values[ATTR_TRANSITION_TIME] = transition_time\n        return self.set_values(values)", "response": "Set the dimmer value of a group."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_gateway():\n    print(\"Printing information about the Gateway\")\n    data = api(gateway.get_gateway_info()).raw\n    print(jsonify(data))", "response": "Print gateway info as JSON"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints all devices as JSON", "response": "def print_all_devices():\n    \"\"\"Print all devices as JSON\"\"\"\n    print(\"Printing information about all devices paired to the Gateway\")\n    if len(devices) == 0:\n        exit(bold(\"No devices paired\"))\n\n    container = []\n    for dev in devices:\n        container.append(dev.raw)\n    print(jsonify(container))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint all lamp devices as JSON", "response": "def print_lamps():\n    \"\"\"Print all lamp devices as JSON\"\"\"\n    print(\"Printing information about all lamps paired to the Gateway\")\n    lights = [dev for dev in devices if dev.has_light_control]\n    if len(lights) == 0:\n        exit(bold(\"No lamps paired\"))\n\n    container = []\n    for l in lights:\n        container.append(l.raw)\n    print(jsonify(container))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_smart_tasks():\n    print(\"Printing information about smart tasks\")\n    tasks = api(gateway.get_smart_tasks())\n    if len(tasks) == 0:\n        exit(bold(\"No smart tasks defined\"))\n\n    container = []\n    for task in tasks:\n        container.append(api(task).task_control.raw)\n    print(jsonify(container))", "response": "Print smart tasks as JSON"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_groups():\n    print(\"Printing information about all groups defined in the Gateway\")\n    groups = api(gateway.get_groups())\n    if len(groups) == 0:\n        exit(bold(\"No groups defined\"))\n\n    container = []\n    for group in groups:\n        container.append(api(group).raw)\n    print(jsonify(container))", "response": "Print all groups as JSON"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef LoadGDAL(filename, no_data=None):\n  if not GDAL_AVAILABLE:\n    raise Exception(\"richdem.LoadGDAL() requires GDAL.\")\n\n  allowed_types = {gdal.GDT_Byte,gdal.GDT_Int16,gdal.GDT_Int32,gdal.GDT_UInt16,gdal.GDT_UInt32,gdal.GDT_Float32,gdal.GDT_Float64}\n\n  #Read in data\n  src_ds  = gdal.Open(filename)\n  srcband = src_ds.GetRasterBand(1)\n\n  if no_data is None:\n    no_data = srcband.GetNoDataValue()\n    if no_data is None:\n      raise Exception(\"The source data did not have a NoData value. Please use the no_data argument to specify one. If should not be equal to any of the actual data values. If you are using all possible data values, then the situation is pretty hopeless - sorry.\")\n\n  srcdata = rdarray(srcband.ReadAsArray(), no_data=no_data)\n\n  # raster_srs = osr.SpatialReference()\n  # raster_srs.ImportFromWkt(raster.GetProjectionRef())\n\n  if not srcband.DataType in allowed_types:\n    raise Exception(\"This datatype is not supported. Please file a bug report on RichDEM.\")\n\n  srcdata.projection   = src_ds.GetProjectionRef()\n  srcdata.geotransform = src_ds.GetGeoTransform()\n\n  srcdata.metadata = dict()\n  for k,v in src_ds.GetMetadata().items():\n    srcdata.metadata[k] = v\n\n  _AddAnalysis(srcdata, \"LoadGDAL(filename={0}, no_data={1})\".format(filename, no_data))\n\n  return srcdata", "response": "Reads a GDAL file and returns a RichDEM array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SaveGDAL(filename, rda):\n  if type(rda) is not rdarray:\n    raise Exception(\"A richdem.rdarray or numpy.ndarray is required!\")\n\n  if not GDAL_AVAILABLE:\n    raise Exception(\"richdem.SaveGDAL() requires GDAL.\")\n\n  driver    = gdal.GetDriverByName('GTiff')\n  data_type = gdal.GDT_Float32 #TODO\n  data_set  = driver.Create(filename, xsize=rda.shape[1], ysize=rda.shape[0], bands=1, eType=data_type)\n  data_set.SetGeoTransform(rda.geotransform)\n  data_set.SetProjection(rda.projection)\n  band = data_set.GetRasterBand(1)\n  band.SetNoDataValue(rda.no_data)\n  band.WriteArray(np.array(rda))\n  for k,v in rda.metadata.items():\n    data_set.SetMetadataItem(str(k),str(v))", "response": "Save a GDAL file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfills all depressions in a DEM.", "response": "def FillDepressions(\n  dem,\n  epsilon  = False,\n  in_place = False,\n  topology = 'D8'\n):\n  \"\"\"Fills all depressions in a DEM.\n\n     Args:\n         dem     (rdarray): An elevation model\n         epsilon (float):   If True, an epsilon gradient is imposed to all flat regions.\n                            This ensures that there is always a local gradient.\n         in_place (bool):   If True, the DEM is modified in place and there is\n                            no return; otherwise, a new, altered DEM is returned.                                     \n         topology (string): A topology indicator\n\n     Returns:\n         DEM without depressions.\n  \"\"\"\n  if type(dem) is not rdarray:\n    raise Exception(\"A richdem.rdarray or numpy.ndarray is required!\")\n\n  if topology not in ['D8','D4']:\n    raise Exception(\"Unknown topology!\")\n\n  if not in_place:\n    dem = dem.copy()\n\n  _AddAnalysis(dem, \"FillDepressions(dem, epsilon={0})\".format(epsilon))\n\n  demw = dem.wrap()\n\n  if epsilon:\n    if topology=='D8':\n      _richdem.rdPFepsilonD8(demw)\n    elif topology=='D4':\n      _richdem.rdPFepsilonD4(demw)\n  else:\n    if topology=='D8':\n      _richdem.rdFillDepressionsD8(demw)\n    elif topology=='D4':\n      _richdem.rdFillDepressionsD4(demw)\n\n  dem.copyFromWrapped(demw)\n\n  if not in_place:\n    return dem"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef BreachDepressions(\n  dem,\n  in_place = False,\n  topology = 'D8'\n):\n  \"\"\"Breaches all depressions in a DEM.\n\n     Args:\n         dem     (rdarray): An elevation model\n         in_place (bool):   If True, the DEM is modified in place and there is\n                            no return; otherwise, a new, altered DEM is returned.                                     \n         topology (string): A topology indicator\n\n     Returns:\n         DEM without depressions.\n  \"\"\"\n  if type(dem) is not rdarray:\n    raise Exception(\"A richdem.rdarray or numpy.ndarray is required!\")\n\n  if topology not in ['D8','D4']:\n    raise Exception(\"Unknown topology!\")\n\n  if not in_place:\n    dem = dem.copy()\n\n  _AddAnalysis(dem, \"BreachDepressions(dem)\")\n\n  demw = dem.wrap()\n\n  if topology=='D8':\n    _richdem.rdBreachDepressionsD8(demw)\n  elif topology=='D4':\n    _richdem.rdBreachDepressionsD4(demw)\n\n  dem.copyFromWrapped(demw)\n\n  if not in_place:\n    return dem", "response": "Breaches all depressions in a DEM."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattempt to resolve flats by imposing a local gradient of the elevation model Shipment.", "response": "def ResolveFlats(\n  dem,\n  in_place = False\n):\n  \"\"\"Attempts to resolve flats by imposing a local gradient\n\n     Args:\n         dem          (rdarray):   An elevation model\n         in_place (bool):   If True, the DEM is modified in place and there is\n                            no return; otherwise, a new, altered DEM is returned.         \n\n     Returns:\n         DEM modified such that all flats drain.\n  \"\"\"\n  if type(dem) is not rdarray:\n    raise Exception(\"A richdem.rdarray or numpy.ndarray is required!\")\n\n  if not in_place:\n    dem = dem.copy()\n\n  _AddAnalysis(dem, \"ResolveFlats(dem, in_place={in_place})\".format(in_place=in_place))\n\n  demw = dem.wrap()\n\n  _richdem.rdResolveFlatsEpsilon(demw)\n\n  dem.copyFromWrapped(demw)\n\n  if not in_place:\n    return dem"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FlowAccumulation(\n  dem,\n  method   = None,\n  exponent = None,\n  weights  = None,\n  in_place = False\n):\n  \"\"\"Calculates flow accumulation. A variety of methods are available.\n\n     Args:\n         dem      (rdarray): An elevation model\n         method   (str):     Flow accumulation method to use. (See below.)\n         exponent (float):   Some methods require an exponent; refer to the \n                             relevant publications for details.\n         weights  (rdarray): Flow accumulation weights to use. This is the\n                             amount of flow generated by each cell. If this is\n                             not provided, each cell will generate 1 unit of\n                             flow.\n         in_place (bool):    If True, then `weights` is modified in place. An\n                             accumulation matrix is always returned, but it will\n                             just be a view of the modified data if `in_place` \n                             is True.\n\n     =================== ============================== ===========================\n     Method              Note                           Reference\n     =================== ============================== ===========================\n     Tarboton            Alias for Dinf.                `Taroboton (1997)              doi: 10.1029/96WR03137             <http://dx.doi.org/10.1029/96WR03137>`_\n     Dinf                Alias for Tarboton.            `Taroboton (1997)              doi: 10.1029/96WR03137             <http://dx.doi.org/10.1029/96WR03137>`_\n     Quinn               Holmgren with exponent=1.      `Quinn et al. (1991)           doi: 10.1002/hyp.3360050106        <http://dx.doi.org/10.1002/hyp.3360050106>`_\n     Holmgren(E)         Generalization of Quinn.       `Holmgren (1994)               doi: 10.1002/hyp.3360080405        <http://dx.doi.org/10.1002/hyp.3360080405>`_\n     Freeman(E)          TODO                           `Freeman (1991)                doi: 10.1016/0098-3004(91)90048-I  <http://dx.doi.org/10.1016/0098-3004(91)90048-I>`_\n     FairfieldLeymarieD8 Alias for Rho8.                `Fairfield and Leymarie (1991) doi: 10.1029/90WR02658             <http://dx.doi.org/10.1029/90WR02658>`_\n     FairfieldLeymarieD4 Alias for Rho4.                `Fairfield and Leymarie (1991) doi: 10.1029/90WR02658             <http://dx.doi.org/10.1029/90WR02658>`_\n     Rho8                Alias for FairfieldLeymarieD8. `Fairfield and Leymarie (1991) doi: 10.1029/90WR02658             <http://dx.doi.org/10.1029/90WR02658>`_\n     Rho4                Alias for FairfieldLeymarieD4. `Fairfield and Leymarie (1991) doi: 10.1029/90WR02658             <http://dx.doi.org/10.1029/90WR02658>`_\n     OCallaghanD8        Alias for D8.                  `O'Callaghan and Mark (1984)   doi: 10.1016/S0734-189X(84)80011-0 <http://dx.doi.org/10.1016/S0734-189X(84)80011-0>`_\n     OCallaghanD4        Alias for D8.                  `O'Callaghan and Mark (1984)   doi: 10.1016/S0734-189X(84)80011-0 <http://dx.doi.org/10.1016/S0734-189X(84)80011-0>`_\n     D8                  Alias for OCallaghanD8.        `O'Callaghan and Mark (1984)   doi: 10.1016/S0734-189X(84)80011-0 <http://dx.doi.org/10.1016/S0734-189X(84)80011-0>`_\n     D4                  Alias for OCallaghanD4.        `O'Callaghan and Mark (1984)   doi: 10.1016/S0734-189X(84)80011-0 <http://dx.doi.org/10.1016/S0734-189X(84)80011-0>`_\n     =================== ============================== ===========================\n\n     **Methods marked (E) require the exponent argument.**\n\n     Returns:\n         A flow accumulation according to the desired method. If `weights` was\n         provided and `in_place` was True, then this matrix is a view of the\n         modified data.\n  \"\"\"\n  if type(dem) is not rdarray:\n    raise Exception(\"A richdem.rdarray or numpy.ndarray is required!\")\n\n  facc_methods = {\n    \"Tarboton\":            _richdem.FA_Tarboton,\n    \"Dinf\":                _richdem.FA_Tarboton,\n    \"Quinn\":               _richdem.FA_Quinn,\n    \"FairfieldLeymarieD8\": _richdem.FA_FairfieldLeymarieD8,\n    \"FairfieldLeymarieD4\": _richdem.FA_FairfieldLeymarieD4,\n    \"Rho8\":                _richdem.FA_Rho8,\n    \"Rho4\":                _richdem.FA_Rho4,\n    \"OCallaghanD8\":        _richdem.FA_OCallaghanD8,\n    \"OCallaghanD4\":        _richdem.FA_OCallaghanD4,\n    \"D8\":                  _richdem.FA_D8,\n    \"D4\":                  _richdem.FA_D4\n  }\n\n  facc_methods_exponent = {\n    \"Freeman\":           _richdem.FA_Freeman,\n    \"Holmgren\":          _richdem.FA_Holmgren\n  }\n\n  if   weights is not None and     in_place:\n    accum = rdarray(weights, no_data=-1)\n  elif weights is not None and not in_place:\n    accum = rdarray(weights, copy=True, meta_obj=dem, no_data=-1)\n  elif weights is None:\n    accum = rdarray(np.ones(shape=dem.shape, dtype='float64'), meta_obj=dem, no_data=-1)\n  else:\n    raise Exception(\"Execution should never reach this point!\")\n\n  if accum.dtype!='float64':\n    raise Exception(\"Accumulation array must be of type 'float64'!\")\n\n  accumw = accum.wrap()\n\n  _AddAnalysis(accum, \"FlowAccumulation(dem, method={method}, exponent={exponent}, weights={weights}, in_place={in_place})\".format(\n    method   = method,\n    exponent = exponent,\n    weights  = 'None' if weights is None else 'weights',\n    in_place = in_place\n  ))\n\n  if method in facc_methods:\n    facc_methods[method](dem.wrap(),accumw)\n  elif method in facc_methods_exponent:\n    if exponent is None:\n      raise Exception('FlowAccumulation method \"'+method+'\" requires an exponent!')\n    facc_methods_exponent[method](dem.wrap(),accumw,exponent)\n  else:\n    raise Exception(\"Invalid FlowAccumulation method. Valid methods are: \" + ', '.join(list(facc_methods.keys()) + list(facc_methods_exponent.keys()) ))\n\n  accum.copyFromWrapped(accumw)\n\n  return accum", "response": "Calculates flow accumulation for a single elevation model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating flow accumulation from flow proportions.", "response": "def FlowAccumFromProps(\n  props,\n  weights  = None,\n  in_place = False\n):\n  \"\"\"Calculates flow accumulation from flow proportions.\n\n     Args:\n         props    (rdarray): An elevation model\n         weights  (rdarray): Flow accumulation weights to use. This is the\n                             amount of flow generated by each cell. If this is\n                             not provided, each cell will generate 1 unit of\n                             flow.\n         in_place (bool):    If True, then `weights` is modified in place. An\n                             accumulation matrix is always returned, but it will\n                             just be a view of the modified data if `in_place` \n                             is True.\n\n     Returns:\n         A flow accumulation array. If `weights` was provided and `in_place` was\n         True, then this matrix is a view of the modified data.\n  \"\"\"\n  if type(props) is not rd3array:\n    raise Exception(\"A richdem.rd3array or numpy.ndarray is required!\")\n\n  if   weights is not None and     in_place:\n    accum = rdarray(weights, no_data=-1)\n  elif weights is not None and not in_place:\n    accum = rdarray(weights, copy=True, meta_obj=props, no_data=-1)\n  elif weights is None:\n    accum = rdarray(np.ones(shape=props.shape[0:2], dtype='float64'), meta_obj=props, no_data=-1)\n  else:\n    raise Exception(\"Execution should never reach this point!\")\n\n  if accum.dtype!='float64':\n    raise Exception(\"Accumulation array must be of type 'float64'!\")\n\n  accumw = accum.wrap()\n\n  _AddAnalysis(accum, \"FlowAccumFromProps(dem, weights={weights}, in_place={in_place})\".format(\n    weights  = 'None' if weights is None else 'weights',\n    in_place = in_place\n  ))\n\n  _richdem.FlowAccumulation(props.wrap(),accumw)\n\n  accum.copyFromWrapped(accumw)\n\n  return accum"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef FlowProportions(\n  dem,\n  method   = None,\n  exponent = None\n):\n  \"\"\"Calculates flow proportions. A variety of methods are available.\n\n     Args:\n         dem      (rdarray): An elevation model\n         method   (str):     Flow accumulation method to use. (See below.)\n         exponent (float):   Some methods require an exponent; refer to the \n                             relevant publications for details.\n\n     =================== ============================== ===========================\n     Method              Note                           Reference\n     =================== ============================== ===========================\n     Tarboton            Alias for Dinf.                `Taroboton (1997)              doi: 10.1029/96WR03137             <http://dx.doi.org/10.1029/96WR03137>`_\n     Dinf                Alias for Tarboton.            `Taroboton (1997)              doi: 10.1029/96WR03137             <http://dx.doi.org/10.1029/96WR03137>`_\n     Quinn               Holmgren with exponent=1.      `Quinn et al. (1991)           doi: 10.1002/hyp.3360050106        <http://dx.doi.org/10.1002/hyp.3360050106>`_\n     Holmgren(E)         Generalization of Quinn.       `Holmgren (1994)               doi: 10.1002/hyp.3360080405        <http://dx.doi.org/10.1002/hyp.3360080405>`_\n     Freeman(E)          TODO                           `Freeman (1991)                doi: 10.1016/0098-3004(91)90048-I  <http://dx.doi.org/10.1016/0098-3004(91)90048-I>`_\n     FairfieldLeymarieD8 Alias for Rho8.                `Fairfield and Leymarie (1991) doi: 10.1029/90WR02658             <http://dx.doi.org/10.1029/90WR02658>`_\n     FairfieldLeymarieD4 Alias for Rho4.                `Fairfield and Leymarie (1991) doi: 10.1029/90WR02658             <http://dx.doi.org/10.1029/90WR02658>`_\n     Rho8                Alias for FairfieldLeymarieD8. `Fairfield and Leymarie (1991) doi: 10.1029/90WR02658             <http://dx.doi.org/10.1029/90WR02658>`_\n     Rho4                Alias for FairfieldLeymarieD4. `Fairfield and Leymarie (1991) doi: 10.1029/90WR02658             <http://dx.doi.org/10.1029/90WR02658>`_\n     OCallaghanD8        Alias for D8.                  `O'Callaghan and Mark (1984)   doi: 10.1016/S0734-189X(84)80011-0 <http://dx.doi.org/10.1016/S0734-189X(84)80011-0>`_\n     OCallaghanD4        Alias for D8.                  `O'Callaghan and Mark (1984)   doi: 10.1016/S0734-189X(84)80011-0 <http://dx.doi.org/10.1016/S0734-189X(84)80011-0>`_\n     D8                  Alias for OCallaghanD8.        `O'Callaghan and Mark (1984)   doi: 10.1016/S0734-189X(84)80011-0 <http://dx.doi.org/10.1016/S0734-189X(84)80011-0>`_\n     D4                  Alias for OCallaghanD4.        `O'Callaghan and Mark (1984)   doi: 10.1016/S0734-189X(84)80011-0 <http://dx.doi.org/10.1016/S0734-189X(84)80011-0>`_\n     =================== ============================== ===========================\n\n     **Methods marked (E) require the exponent argument.**\n\n     Returns:\n         A flow proportion according to the desired method.\n  \"\"\"\n  if type(dem) is not rdarray:\n    raise Exception(\"A richdem.rdarray or numpy.ndarray is required!\")\n\n  fprop_methods = {\n    \"Tarboton\":            _richdem.FM_Tarboton,\n    \"Dinf\":                _richdem.FM_Tarboton,\n    \"Quinn\":               _richdem.FM_Quinn,\n    \"FairfieldLeymarieD8\": _richdem.FM_FairfieldLeymarieD8,\n    \"FairfieldLeymarieD4\": _richdem.FM_FairfieldLeymarieD4,\n    \"Rho8\":                _richdem.FM_Rho8,\n    \"Rho4\":                _richdem.FM_Rho4,\n    \"OCallaghanD8\":        _richdem.FM_OCallaghanD8,\n    \"OCallaghanD4\":        _richdem.FM_OCallaghanD4,\n    \"D8\":                  _richdem.FM_D8,\n    \"D4\":                  _richdem.FM_D4\n  }\n\n  fprop_methods_exponent = {\n    \"Freeman\":           _richdem.FM_Freeman,\n    \"Holmgren\":          _richdem.FM_Holmgren\n  }\n\n  fprops  = rd3array(np.zeros(shape=dem.shape+(9,), dtype='float32'), meta_obj=dem, no_data=-2)\n  fpropsw = fprops.wrap()\n\n  _AddAnalysis(fprops, \"FlowProportions(dem, method={method}, exponent={exponent})\".format(\n    method   = method,\n    exponent = exponent,\n  ))\n\n  if method in fprop_methods:\n    fprop_methods[method](dem.wrap(),fpropsw)\n  elif method in fprop_methods_exponent:\n    if exponent is None:\n      raise Exception('FlowProportions method \"'+method+'\" requires an exponent!')\n    fprop_methods_exponent[method](dem.wrap(),fpropsw,exponent)\n  else:\n    raise Exception(\"Invalid FlowProportions method. Valid methods are: \" + ', '.join(list(fprop_methods.keys()) + list(fprop_methods_exponent.keys()) ))\n\n  fprops.copyFromWrapped(fpropsw)\n\n  return fprops", "response": "Calculates flow proportions for a given elevation model."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the terrain attributes for the specified elevation model and attribute.", "response": "def TerrainAttribute(\n  dem,\n  attrib,\n  zscale = 1.0\n):\n  \"\"\"Calculates terrain attributes. A variety of methods are available.\n\n     Args:\n         dem    (rdarray):  An elevation model\n         attrib (str):      Terrain attribute to calculate. (See below.)\n         zscale (float):    How much to scale the z-axis by prior to calculation\n\n     ======================= =========\n     Method                  Reference\n     ======================= =========\n     slope_riserun           `Horn (1981)                   doi: 10.1109/PROC.1981.11918 <http://dx.doi.org/10.1109/PROC.1981.11918>`_ \n     slope_percentage        `Horn (1981)                   doi: 10.1109/PROC.1981.11918 <http://dx.doi.org/10.1109/PROC.1981.11918>`_ \n     slope_degrees           `Horn (1981)                   doi: 10.1109/PROC.1981.11918 <http://dx.doi.org/10.1109/PROC.1981.11918>`_ \n     slope_radians           `Horn (1981)                   doi: 10.1109/PROC.1981.11918 <http://dx.doi.org/10.1109/PROC.1981.11918>`_ \n     aspect                  `Horn (1981)                   doi: 10.1109/PROC.1981.11918 <http://dx.doi.org/10.1109/PROC.1981.11918>`_ \n     curvature               `Zevenbergen and Thorne (1987) doi: 10.1002/esp.3290120107  <http://dx.doi.org/10.1002/esp.3290120107>`_ \n     planform_curvature      `Zevenbergen and Thorne (1987) doi: 10.1002/esp.3290120107  <http://dx.doi.org/10.1002/esp.3290120107>`_ \n     profile_curvature       `Zevenbergen and Thorne (1987) doi: 10.1002/esp.3290120107  <http://dx.doi.org/10.1002/esp.3290120107>`_ \n     ======================= =========\n\n     Returns:\n         A raster of the indicated terrain attributes.\n  \"\"\"\n  if type(dem) is not rdarray:\n    raise Exception(\"A richdem.rdarray or numpy.ndarray is required!\")\n\n  terrain_attribs = {\n    #\"spi\":                _richdem.TA_SPI,\n    #\"cti\":                _richdem.TA_CTI,\n    \"slope_riserun\":      _richdem.TA_slope_riserun,\n    \"slope_percentage\":   _richdem.TA_slope_percentage,\n    \"slope_degrees\":      _richdem.TA_slope_degrees,\n    \"slope_radians\":      _richdem.TA_slope_radians,\n    \"aspect\":             _richdem.TA_aspect,\n    \"curvature\":          _richdem.TA_curvature,\n    \"planform_curvature\": _richdem.TA_planform_curvature,\n    \"profile_curvature\":  _richdem.TA_profile_curvature,\n  }\n\n  if not attrib in terrain_attribs:\n    raise Exception(\"Invalid TerrainAttributes attribute. Valid attributes are: \" + ', '.join(terrain_attribs.keys()))\n\n  result  = rdarray(np.zeros(shape=dem.shape, dtype='float32'), meta_obj=dem, no_data=-9999)\n  resultw = result.wrap()\n\n  _AddAnalysis(result, \"TerrainAttribute(dem, attrib={0}, zscale={1})\".format(attrib,zscale))\n\n  terrain_attribs[attrib](dem.wrap(),resultw,zscale)\n\n  result.copyFromWrapped(resultw)\n\n  return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _join(*args):\n    return delimiter.join(filter(lambda s: s != '', map(lambda s: s.lstrip(delimiter), args)))", "response": "Join S3 bucket args together."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize(self):\n        self.bookstore_settings = BookstoreSettings(config=self.config)\n        self.session = aiobotocore.get_session()", "response": "Initialize a helper to get bookstore settings and session information quickly"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def put(self, path=''):\n        self.log.info(\"Attempt publishing to %s\", path)\n\n        if path == '' or path == '/':\n            raise web.HTTPError(400, \"Must provide a path for publishing\")\n\n        model = self.get_json_body()\n        if model:\n            await self._publish(model, path.lstrip('/'))\n        else:\n            raise web.HTTPError(400, \"Cannot publish an empty model\")", "response": "Publish a notebook on a given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def _publish(self, model, path):\n        if model['type'] != 'notebook':\n            raise web.HTTPError(400, \"bookstore only publishes notebooks\")\n        content = model['content']\n\n        full_s3_path = s3_path(\n            self.bookstore_settings.s3_bucket, self.bookstore_settings.published_prefix, path\n        )\n        file_key = s3_key(self.bookstore_settings.published_prefix, path)\n\n        self.log.info(\n            \"Publishing to %s\",\n            s3_display_path(\n                self.bookstore_settings.s3_bucket, self.bookstore_settings.published_prefix, path\n            ),\n        )\n\n        async with self.session.create_client(\n            's3',\n            aws_secret_access_key=self.bookstore_settings.s3_secret_access_key,\n            aws_access_key_id=self.bookstore_settings.s3_access_key_id,\n            endpoint_url=self.bookstore_settings.s3_endpoint_url,\n            region_name=self.bookstore_settings.s3_region_name,\n        ) as client:\n            self.log.info(\"Processing published write of %s\", path)\n            obj = await client.put_object(\n                Bucket=self.bookstore_settings.s3_bucket, Key=file_key, Body=json.dumps(content)\n            )\n            self.log.info(\"Done with published write of %s\", path)\n\n        self.set_status(201)\n\n        resp_content = {\"s3path\": full_s3_path}\n\n        if 'VersionId' in obj:\n            resp_content[\"versionID\"] = obj['VersionId']\n\n        resp_str = json.dumps(resp_content)\n        self.finish(resp_str)", "response": "Publish a notebook to the path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_bookstore(settings: BookstoreSettings):\n    general_settings = [settings.s3_bucket != \"\", settings.s3_endpoint_url != \"\"]\n    archive_settings = [settings.workspace_prefix != \"\"]\n    published_settings = [settings.published_prefix != \"\"]\n\n    validation_checks = {\n        \"bookstore_valid\": all(general_settings),\n        \"archive_valid\": all(archive_settings),\n        \"publish_valid\": all(published_settings),\n    }\n    return validation_checks", "response": "Validate bookstore configuration settings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_auth(self):\n        self.token = self.nb_record.token\n        first = requests.get(f\"{self.url}/login\")\n        self.xsrf_token = first.cookies.get(\"_xsrf\", \"\")", "response": "Sets up token access for authorizing requests to notebook server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_request_sessions(self):\n        self.req_session = requests.Session()\n        self.req_session.headers.update(self.headers)", "response": "Sets up a requests. Session object for sharing headers across API requests."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def archive(self, record: ArchiveRecord):\n        async with self.path_lock_ready:\n            lock = self.path_locks.get(record.filepath)\n\n            if lock is None:\n                lock = Lock()\n                self.path_locks[record.filepath] = lock\n\n        # Skip writes when a given path is already locked\n        if lock.locked():\n            self.log.info(\"Skipping archive of %s\", record.filepath)\n            return\n\n        async with lock:\n            try:\n                async with self.session.create_client(\n                    's3',\n                    aws_secret_access_key=self.settings.s3_secret_access_key,\n                    aws_access_key_id=self.settings.s3_access_key_id,\n                    endpoint_url=self.settings.s3_endpoint_url,\n                    region_name=self.settings.s3_region_name,\n                ) as client:\n                    self.log.info(\"Processing storage write of %s\", record.filepath)\n                    file_key = s3_key(self.settings.workspace_prefix, record.filepath)\n                    await client.put_object(\n                        Bucket=self.settings.s3_bucket, Key=file_key, Body=record.content\n                    )\n                    self.log.info(\"Done with storage write of %s\", record.filepath)\n            except Exception as e:\n                self.log.error(\n                    'Error while archiving file: %s %s', record.filepath, e, exc_info=True\n                )", "response": "Process a record to write to storage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend request to store notebook to S3. This hook offloads the storage request to the event loop. When the event loop is available for execution of the request, the storage of the notebook will be done and the write to storage occurs. Parameters ---------- model : str The type of file path : str The storage location", "response": "def run_pre_save_hook(self, model, path, **kwargs):\n        \"\"\"Send request to store notebook to S3.\n\n        This hook offloads the storage request to the event loop.\n        When the event loop is available for execution of the request, the\n        storage of the notebook will be done and the write to storage occurs.\n\n        Parameters\n        ----------\n        model : str\n            The type of file\n        path : str\n            The storage location\n        \"\"\"\n        if model[\"type\"] != \"notebook\":\n            return\n\n        content = json.dumps(model[\"content\"])\n\n        loop = ioloop.IOLoop.current()\n\n        # Offload archival and schedule write to storage with the current event loop\n        loop.spawn_callback(\n            self.archive,\n            ArchiveRecord(\n                content=content, filepath=path, queued_time=ioloop.IOLoop.current().time()\n            ),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a dict with params", "response": "def build_checkout_params(self, **kwargs):\n        \"\"\" build a dict with params \"\"\"\n        params = kwargs or {}\n        if self.sender:\n            params['senderName'] = self.sender.get('name')\n            params['senderAreaCode'] = self.sender.get('area_code')\n            params['senderPhone'] = self.sender.get('phone')\n            params['senderEmail'] = is_valid_email(self.sender.get('email'))\n            params['senderCPF'] = is_valid_cpf(self.sender.get('cpf'))\n            params['senderCNPJ'] = is_valid_cnpj(self.sender.get('cnpj'))\n            params['senderBornDate'] = self.sender.get('born_date')\n            params['senderHash'] = self.sender.get('hash')\n\n        if self.config.USE_SHIPPING:\n            if self.shipping:\n                params['shippingType'] = self.shipping.get('type')\n                params['shippingAddressStreet'] = self.shipping.get('street')\n                params['shippingAddressNumber'] = self.shipping.get('number')\n                params['shippingAddressComplement'] = self.shipping.get(\n                    'complement')\n                params['shippingAddressDistrict'] = self.shipping.get(\n                    'district')\n                params['shippingAddressPostalCode'] = self.shipping.get(\n                    'postal_code')\n                params['shippingAddressCity'] = self.shipping.get('city')\n                params['shippingAddressState'] = self.shipping.get('state')\n                params['shippingAddressCountry'] = self.shipping.get('country',\n                                                                     'BRA')\n                if self.shipping.get('cost'):\n                    params['shippingCost'] = self.shipping.get('cost')\n        else:\n            params['shippingAddressRequired'] = 'false'\n\n        if self.extra_amount:\n            params['extraAmount'] = self.extra_amount\n\n        params['reference'] = self.reference\n        params['receiverEmail'] = self.data['email']\n\n        if self.redirect_url:\n            params['redirectURL'] = self.redirect_url\n\n        if self.notification_url:\n            params['notificationURL'] = self.notification_url\n\n        if self.abandon_url:\n            params['abandonURL'] = self.abandon_url\n\n        for i, item in enumerate(self.items, 1):\n            params['itemId%s' % i] = item.get('id')\n            params['itemDescription%s' % i] = item.get('description')\n            params['itemAmount%s' % i] = item.get('amount')\n            params['itemQuantity%s' % i] = item.get('quantity')\n            params['itemWeight%s' % i] = item.get('weight')\n            params['itemShippingCost%s' % i] = item.get('shipping_cost')\n\n        if self.payment:\n\n            params['paymentMethod'] = self.payment.get('method')\n            params['paymentMode'] = self.payment.get('mode')\n\n        if self.credit_card:\n            params['billingAddressCountry'] = 'BRA'\n\n            credit_card_keys_map = [\n                ('creditCardToken', 'credit_card_token'),\n                ('installmentQuantity', 'installment_quantity'),\n                ('installmentValue', 'installment_value'),\n                ('noInterestInstallmentQuantity',\n                 'no_interest_installment_quantity'),\n                ('creditCardHolderName', 'card_holder_name'),\n                ('creditCardHolderCPF', 'card_holder_cpf'),\n                ('creditCardHolderBirthDate', 'card_holder_birth_date'),\n                ('creditCardHolderAreaCode', 'card_holder_area_code'),\n                ('creditCardHolderPhone', 'card_holder_phone'),\n                ('billingAddressStreet', 'billing_address_street'),\n                ('billingAddressNumber', 'billing_address_number'),\n                ('billingAddressComplement', 'billing_address_complement'),\n                ('billingAddressDistrict', 'billing_address_district'),\n                ('billingAddressPostalCode', 'billing_address_postal_code'),\n                ('billingAddressCity', 'billing_address_city'),\n                ('billingAddressState', 'billing_address_state'),\n            ]\n\n            for key_to_set, key_to_get in credit_card_keys_map:\n                params[key_to_set] = self.credit_card.get(key_to_get)\n\n        if self.pre_approval:\n\n            params['preApprovalCharge'] = self.pre_approval.get('charge')\n            params['preApprovalName'] = self.pre_approval.get('name')\n            params['preApprovalDetails'] = self.pre_approval.get('details')\n            params['preApprovalAmountPerPayment'] = self.pre_approval.get(\n                'amount_per_payment')\n            params['preApprovalMaxAmountPerPayment'] = self.pre_approval.get(\n                'max_amount_per_payment')\n            params['preApprovalPeriod'] = self.pre_approval.get('period')\n            params['preApprovalMaxPaymentsPerPeriod'] = self.pre_approval.get(\n                'max_payments_per_period')\n            params['preApprovalMaxAmountPerPeriod'] = self.pre_approval.get(\n                'max_amount_per_period')\n            params['preApprovalInitialDate'] = self.pre_approval.get(\n                'initial_date')\n            params['preApprovalFinalDate'] = self.pre_approval.get(\n                'final_date')\n            params['preApprovalMaxTotalAmount'] = self.pre_approval.get(\n                'max_total_amount')\n\n        self.data.update(params)\n        self.clean_none_params()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a dict with params that are required for the pre - approval payment", "response": "def build_pre_approval_payment_params(self, **kwargs):\n        \"\"\" build a dict with params \"\"\"\n\n        params = kwargs or {}\n\n        params['reference'] = self.reference\n        params['preApprovalCode'] = self.code\n\n        for i, item in enumerate(self.items, 1):\n            params['itemId%s' % i] = item.get('id')\n            params['itemDescription%s' % i] = item.get('description')\n            params['itemAmount%s' % i] = item.get('amount')\n            params['itemQuantity%s' % i] = item.get('quantity')\n            params['itemWeight%s' % i] = item.get('weight')\n            params['itemShippingCost%s' % i] = item.get('shipping_cost')\n\n        self.data.update(params)\n        self.clean_none_params()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, url):\n        return requests.get(url, params=self.data, headers=self.config.HEADERS)", "response": "do a get transaction"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post(self, url):\n        return requests.post(url, data=self.data, headers=self.config.HEADERS)", "response": "do a post request"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef checkout(self, transparent=False, **kwargs):\n        self.data['currency'] = self.config.CURRENCY\n        self.build_checkout_params(**kwargs)\n        if transparent:\n            response = self.post(url=self.config.TRANSPARENT_CHECKOUT_URL)\n        else:\n            response = self.post(url=self.config.CHECKOUT_URL)\n        return PagSeguroCheckoutResponse(response.content, config=self.config)", "response": "create a pagseguro checkout"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck a notification by its code", "response": "def check_notification(self, code):\n        \"\"\" check a notification by its code \"\"\"\n        response = self.get(url=self.config.NOTIFICATION_URL % code)\n        return PagSeguroNotificationResponse(response.content, self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_pre_approval_notification(self, code):\n        response = self.get(\n            url=self.config.PRE_APPROVAL_NOTIFICATION_URL % code)\n        return PagSeguroPreApprovalNotificationResponse(\n            response.content, self.config)", "response": "check a pre approval notification by its code"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pre_approval_ask_payment(self, **kwargs):\n        self.build_pre_approval_payment_params(**kwargs)\n        response = self.post(url=self.config.PRE_APPROVAL_PAYMENT_URL)\n        return PagSeguroPreApprovalPayment(response.content, self.config)", "response": "ask form a subscribe payment"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pre_approval_cancel(self, code):\n        response = self.get(url=self.config.PRE_APPROVAL_CANCEL_URL % code)\n        return PagSeguroPreApprovalCancel(response.content, self.config)", "response": "cancel a pre - approval"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks a transaction by its code", "response": "def check_transaction(self, code):\n        \"\"\" check a transaction by its code \"\"\"\n        response = self.get(url=self.config.TRANSACTION_URL % code)\n        return PagSeguroNotificationResponse(response.content, self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query_transactions(self, initial_date, final_date,\n                           page=None,\n                           max_results=None):\n        \"\"\" query transaction by date range \"\"\"\n        last_page = False\n        results = []\n        while last_page is False:\n            search_result = self._consume_query_transactions(\n                initial_date, final_date, page, max_results)\n            results.extend(search_result.transactions)\n            if search_result.current_page is None or \\\n               search_result.total_pages is None or \\\n               search_result.current_page == search_result.total_pages:\n                last_page = True\n            else:\n                page = search_result.current_page + 1\n\n        return results", "response": "query transaction by date range"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_pre_approvals(self, initial_date, final_date, page=None,\n                            max_results=None):\n        \"\"\" query pre-approvals by date range \"\"\"\n        last_page = False\n        results = []\n        while last_page is False:\n            search_result = self._consume_query_pre_approvals(\n                initial_date, final_date, page, max_results)\n            results.extend(search_result.pre_approvals)\n            if search_result.current_page is None or \\\n               search_result.total_pages is None or \\\n               search_result.current_page == search_result.total_pages:\n                last_page = True\n            else:\n                page = search_result.current_page + 1\n\n        return results", "response": "query pre - approvals by date range"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new item to the cart", "response": "def add_to_cart(item_id):\n    \"\"\" Cart with Product \"\"\"\n    cart = Cart(session['cart'])\n    if cart.change_item(item_id, 'add'):\n        session['cart'] = cart.to_dict()\n    return list_products()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the object to a dict.", "response": "def to_dict(self):\n        \"\"\" Attribute values to dict \"\"\"\n\n        return {\n            \"total\": self.total,\n            \"subtotal\": self.subtotal,\n            \"items\": self.items,\n            \"extra_amount\": self.extra_amount\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef change_item(self, item_id, operation):\n\n        product = Products().get_one(item_id)\n        if product:\n            if operation == 'add':\n                self.items.append(product)\n            elif operation == 'remove':\n                cart_p = [x for x in self.items if x['id'] == product['id']]\n                self.items.remove(cart_p[0])\n            self.update()\n            return True\n        else:\n            return False", "response": "Change items in cart"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the internal state of the items in the cart.", "response": "def update(self):\n        \"\"\" Remove items in cart \"\"\"\n\n        subtotal = float(0)\n        total = float(0)\n        for product in self.items:\n            subtotal += float(product[\"price\"])\n        if subtotal > 0:\n            total = subtotal + self.extra_amount\n        self.subtotal = subtotal\n        self.total = total"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_connection(self, url):\n        u = urlparse(url)\n\n        if u.netloc.find('@') > -1 and (u.scheme == 'bolt' or u.scheme == 'bolt+routing'):\n            credentials, hostname = u.netloc.rsplit('@', 1)\n            username, password, = credentials.split(':')\n        else:\n            raise ValueError(\"Expecting url format: bolt://user:password@localhost:7687\"\n                             \" got {0}\".format(url))\n\n        self.driver = GraphDatabase.driver(u.scheme + '://' + hostname,\n                                           auth=basic_auth(username, password),\n                                           encrypted=config.ENCRYPTED_CONNECTION,\n                                           max_pool_size=config.MAX_POOL_SIZE)\n        self.url = url\n        self._pid = os.getpid()\n        self._active_transaction = None", "response": "Sets the connection URL to the address a Neo4j server is set up at\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef begin(self, access_mode=None):\n        if self._active_transaction:\n            raise SystemError(\"Transaction in progress\")\n        self._active_transaction = self.driver.session(access_mode=access_mode).begin_transaction()", "response": "Begins a new transaction"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _object_resolution(self, result_list):\n        \n        # Object resolution occurs in-place\n        for a_result_item in enumerate(result_list):\n            for a_result_attribute in enumerate(a_result_item[1]):                    \n                try:\n                    # Primitive types should remain primitive types, \n                    #  Nodes to be resolved to native objects\n                    resolved_object = a_result_attribute[1]\n                    \n                    if type(a_result_attribute[1]) is Node:\n                        resolved_object = self._NODE_CLASS_REGISTRY[frozenset(a_result_attribute[1].labels)].inflate(\n                            a_result_attribute[1])\n                        \n                    if type(a_result_attribute[1]) is list:\n                        resolved_object = self._object_resolution([a_result_attribute[1]])                    \n                    \n                    result_list[a_result_item[0]][a_result_attribute[0]] = resolved_object\n                    \n                except KeyError:\n                    # Not being able to match the label set of a node with a known object results \n                    # in a KeyError in the internal dictionary used for resolution. If it is impossible \n                    # to match, then raise an exception with more details about the error.\n                    raise ModelDefinitionMismatch(a_result_attribute[1], self._NODE_CLASS_REGISTRY)\n                    \n        return result_list", "response": "Perform in place automatic object resolution on a list of results."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a Cypher query on the database and returns a list of results and their headers.", "response": "def cypher_query(self, query, params=None, handle_unique=True, retry_on_session_expire=False, resolve_objects=False):\n        \"\"\"\n        Runs a query on the database and returns a list of results and their headers.\n        \n        :param query: A CYPHER query\n        :type: str\n        :param params: Dictionary of parameters\n        :type: dict\n        :param handle_unique: Whether or not to raise UniqueProperty exception on Cypher's ConstraintValidation errors\n        :type: bool\n        :param retry_on_session_expire: Whether or not to attempt the same query again if the transaction has expired\n        :type: bool        \n        :param resolve_objects: Whether to attempt to resolve the returned nodes to data model objects automatically\n        :type: bool\n        \"\"\"\n        \n        if self._pid != os.getpid():\n            self.set_connection(self.url)\n\n        if self._active_transaction:\n            session = self._active_transaction\n        else:\n            session = self.driver.session()\n\n        try:\n            # Retrieve the data\n            start = time.time()\n            response = session.run(query, params)\n            results, meta = [list(r.values()) for r in response], response.keys()\n            end = time.time()\n            \n            if resolve_objects:\n                # Do any automatic resolution required\n                results = self._object_resolution(results)\n                \n        except CypherError as ce:\n            if ce.code == u'Neo.ClientError.Schema.ConstraintValidationFailed':\n                if 'already exists with label' in ce.message and handle_unique:\n                    raise UniqueProperty(ce.message)\n\n                raise ConstraintValidationFailed(ce.message)\n            else:\n                exc_info = sys.exc_info()\n                if sys.version_info >= (3, 0):\n                    raise exc_info[1].with_traceback(exc_info[2])\n                else:\n                    raise exc_info[1]\n        except SessionError:\n            if retry_on_session_expire:\n                self.set_connection(self.url)\n                return self.cypher_query(query=query,\n                                         params=params,\n                                         handle_unique=handle_unique,\n                                         retry_on_session_expire=False)\n            raise\n\n        if os.environ.get('NEOMODEL_CYPHER_DEBUG', False):\n            logger.debug(\"query: \" + query + \"\\nparams: \" + repr(params) + \"\\ntook: {:.2g}s\\n\".format(end - start))\n\n        return results, meta"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a relationship matching string.", "response": "def _rel_helper(lhs, rhs, ident=None, relation_type=None, direction=None, relation_properties=None, **kwargs):\n    \"\"\"\n    Generate a relationship matching string, with specified parameters.\n    Examples:\n    relation_direction = OUTGOING: (lhs)-[relation_ident:relation_type]->(rhs)\n    relation_direction = INCOMING: (lhs)<-[relation_ident:relation_type]-(rhs)\n    relation_direction = EITHER: (lhs)-[relation_ident:relation_type]-(rhs)\n\n    :param lhs: The left hand statement.\n    :type lhs: str\n    :param rhs: The right hand statement.\n    :type rhs: str\n    :param ident: A specific identity to name the relationship, or None.\n    :type ident: str\n    :param relation_type: None for all direct rels, * for all of any length, or a name of an explicit rel.\n    :type relation_type: str\n    :param direction: None or EITHER for all OUTGOING,INCOMING,EITHER. Otherwise OUTGOING or INCOMING.\n    :param relation_properties: dictionary of relationship properties to match\n    :returns: string\n    \"\"\"\n\n    if direction == OUTGOING:\n        stmt = '-{0}->'\n    elif direction == INCOMING:\n        stmt = '<-{0}-'\n    else:\n        stmt = '-{0}-'\n\n    rel_props = ''\n\n    if relation_properties:\n        rel_props = ' {{{0}}}'.format(', '.join(\n            ['{0}: {1}'.format(key, value) for key, value in relation_properties.items()]))\n\n    # direct, relation_type=None is unspecified, relation_type\n    if relation_type is None:\n        stmt = stmt.format('')\n    # all(\"*\" wildcard) relation_type\n    elif relation_type == '*':\n        stmt = stmt.format('[*]')\n    else:\n        # explicit relation_type\n        stmt = stmt.format('[{0}:`{1}`{2}]'.format(ident if ident else '', relation_type, rel_props))\n\n    return \"({0}){1}({2})\".format(lhs, stmt, rhs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef install_traversals(cls, node_set):\n    rels = cls.defined_properties(rels=True, aliases=False, properties=False)\n\n    for key, value in rels.items():\n        if hasattr(node_set, key):\n            raise ValueError(\"Can't install traversal '{0}' exists on NodeSet\".format(key))\n\n        rel = getattr(cls, key)\n        rel._lookup_node_class()\n\n        traversal = Traversal(source=node_set, name=key, definition=rel.definition)\n        setattr(node_set, key, traversal)", "response": "Install Traversal objects for each node class defined in the StructuredNode class on a NodeSet instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_filter_args(cls, kwargs):\n\n    output = {}\n\n    for key, value in kwargs.items():\n        if '__' in key:\n            prop, operator = key.rsplit('__')\n            operator = OPERATOR_TABLE[operator]\n        else:\n            prop = key\n            operator = '='\n\n        if prop not in cls.defined_properties(rels=False):\n            raise ValueError(\"No such property {0} on {1}\".format(prop, cls.__name__))\n\n        property_obj = getattr(cls, prop)\n        if isinstance(property_obj, AliasProperty):\n            prop = property_obj.aliased_to()\n            deflated_value = getattr(cls, prop).deflate(value)\n        else:\n            # handle special operators\n            if operator == _SPECIAL_OPERATOR_IN:\n                if not isinstance(value, tuple) and not isinstance(value, list):\n                    raise ValueError('Value must be a tuple or list for IN operation {0}={1}'.format(key, value))\n                deflated_value = [property_obj.deflate(v) for v in value]\n            elif operator == _SPECIAL_OPERATOR_ISNULL:\n                if not isinstance(value, bool):\n                    raise ValueError('Value must be a bool for isnull operation on {0}'.format(key))\n                operator = 'IS NULL' if value else 'IS NOT NULL'\n                deflated_value = None\n            elif operator in _REGEX_OPERATOR_TABLE.values():\n                deflated_value = property_obj.deflate(value)\n                if not isinstance(deflated_value, basestring):\n                    raise ValueError('Must be a string value for {0}'.format(key))\n                if operator in _STRING_REGEX_OPERATOR_TABLE.values():\n                    deflated_value = re.escape(deflated_value)\n                deflated_value = operator.format(deflated_value)\n                operator = _SPECIAL_OPERATOR_REGEX\n            else:\n                deflated_value = property_obj.deflate(value)\n\n        # map property to correct property name in the database\n        db_property = cls.defined_properties(rels=False)[prop].db_property or prop\n\n        output[db_property] = (operator, deflated_value)\n\n    return output", "response": "process filter parameters and return a list of cyphers that can be used to generate the filter statement"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloops through has parameters check they correspond to class rels defined return a tuple of the match and dont_match", "response": "def process_has_args(cls, kwargs):\n    \"\"\"\n    loop through has parameters check they correspond to class rels defined\n    \"\"\"\n    rel_definitions = cls.defined_properties(properties=False, rels=True, aliases=False)\n\n    match, dont_match = {}, {}\n\n    for key, value in kwargs.items():\n        if key not in rel_definitions:\n            raise ValueError(\"No such relation {0} defined on a {1}\".format(key, cls.__name__))\n\n        rhs_ident = key\n\n        rel_definitions[key]._lookup_node_class()\n\n        if value is True:\n            match[rhs_ident] = rel_definitions[key].definition\n        elif value is False:\n            dont_match[rhs_ident] = rel_definitions[key].definition\n        elif isinstance(value, NodeSet):\n            raise NotImplementedError(\"Not implemented yet\")\n        else:\n            raise ValueError(\"Expecting True / False / NodeSet got: \" + repr(value))\n\n    return match, dont_match"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a traversal from a node to a set of nodes", "response": "def build_traversal(self, traversal):\n        \"\"\"\n        traverse a relationship from a node to a set of nodes\n        \"\"\"\n        # build source\n        rhs_label = ':' + traversal.target_class.__label__\n\n        # build source\n        lhs_ident = self.build_source(traversal.source)\n        rhs_ident = traversal.name + rhs_label\n        self._ast['return'] = traversal.name\n        self._ast['result_class'] = traversal.target_class\n\n        rel_ident = self.create_ident()\n        stmt = _rel_helper(lhs=lhs_ident, rhs=rhs_ident, ident=rel_ident, **traversal.definition)\n        self._ast['match'].append(stmt)\n\n        if traversal.filters:\n            self.build_where_stmt(rel_ident, traversal.filters)\n\n        return traversal.name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_label(self, ident, cls):\n        ident_w_label = ident + ':' + cls.__label__\n        self._ast['match'].append('({0})'.format(ident_w_label))\n        self._ast['return'] = ident\n        self._ast['result_class'] = cls\n        return ident", "response": "build a label for the match nodes by a label"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds additional matches for the node_set", "response": "def build_additional_match(self, ident, node_set):\n        \"\"\"\n            handle additional matches supplied by 'has()' calls\n        \"\"\"\n        source_ident = ident\n\n        for key, value in node_set.must_match.items():\n            if isinstance(value, dict):\n                label = ':' + value['node_class'].__label__\n                stmt = _rel_helper(lhs=source_ident, rhs=label, ident='', **value)\n                self._ast['where'].append(stmt)\n            else:\n                raise ValueError(\"Expecting dict got: \" + repr(value))\n\n        for key, val in node_set.dont_match.items():\n            if isinstance(val, dict):\n                label = ':' + val['node_class'].__label__\n                stmt = _rel_helper(lhs=source_ident, rhs=label, ident='', **val)\n                self._ast['where'].append('NOT ' + stmt)\n            else:\n                raise ValueError(\"Expecting dict got: \" + repr(val))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a where statement from some filters", "response": "def build_where_stmt(self, ident, filters, q_filters=None, source_class=None):\n        \"\"\"\n        construct a where statement from some filters\n        \"\"\"\n        if q_filters is not None:\n            stmts = self._parse_q_filters(ident, q_filters, source_class)\n            if stmts:\n                self._ast['where'].append(stmts)\n        else:\n            stmts = []\n            for row in filters:\n                negate = False\n\n                # pre-process NOT cases as they are nested dicts\n                if '__NOT__' in row and len(row) == 1:\n                    negate = True\n                    row = row['__NOT__']\n\n                for prop, op_and_val in row.items():\n                    op, val = op_and_val\n                    if op in _UNARY_OPERATORS:\n                        # unary operators do not have a parameter\n                        statement = '{0} {1}.{2} {3}'.format('NOT' if negate else '', ident, prop, op)\n                    else:\n                        place_holder = self._register_place_holder(ident + '_' + prop)\n                        statement = '{0} {1}.{2} {3} {{{4}}}'.format('NOT' if negate else '', ident, prop, op, place_holder)\n                        self._query_params[place_holder] = val\n                    stmts.append(statement)\n\n            self._ast['where'].append(' AND '.join(stmts))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef all(self, lazy=False):\n        return self.query_cls(self).build_ast()._execute(lazy)", "response": "Returns all nodes belonging to the set\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, lazy=False, **kwargs):\n        result = self._get(limit=2, lazy=lazy, **kwargs)\n        if len(result) > 1:\n            raise MultipleNodesReturned(repr(kwargs))\n        elif not result:\n            raise self.source_class.DoesNotExist(repr(kwargs))\n        else:\n            return result[0]", "response": "Retrieve one node from the set matching the supplied parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the first node in the set matching the supplied parameters.", "response": "def first(self, **kwargs):\n        \"\"\"\n        Retrieve the first node from the set matching supplied parameters\n\n        :param kwargs: same syntax as `filter()`\n        :return: node\n        \"\"\"\n        result = result = self._get(limit=1, **kwargs)\n        if result:\n            return result[0]\n        else:\n            raise self.source_class.DoesNotExist(repr(kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter(self, *args, **kwargs):\n        if args or kwargs:\n            self.q_filters = Q(self.q_filters & Q(*args, **kwargs))\n        return self", "response": "Apply filters to the existing nodes in the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exclude(self, *args, **kwargs):\n        if args or kwargs:\n            self.q_filters = Q(self.q_filters & ~Q(*args, **kwargs))\n        return self", "response": "Exclude nodes from the NodeSet via filters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new ordering property to the query.", "response": "def order_by(self, *props):\n        \"\"\"\n        Order by properties. Prepend with minus to do descending. Pass None to\n        remove ordering.\n        \"\"\"\n        should_remove = len(props) == 1 and props[0] is None\n        if not hasattr(self, '_order_by') or should_remove:\n            self._order_by = []\n            if should_remove:\n                return self\n        if '?' in props:\n            self._order_by.append('?')\n        else:\n            for prop in props:\n                prop = prop.strip()\n                if prop.startswith('-'):\n                    prop = prop[1:]\n                    desc = True\n                else:\n                    desc = False\n\n                if prop not in self.source_class.defined_properties(rels=False):\n                    raise ValueError(\"No such property {0} on {1}\".format(\n                        prop, self.source_class.__name__))\n\n                property_obj = getattr(self.source_class, prop)\n                if isinstance(property_obj, AliasProperty):\n                    prop = property_obj.aliased_to()\n\n                self._order_by.append(prop + (' DESC' if desc else ''))\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntraversing relationships with properties matching the given parameters.", "response": "def match(self, **kwargs):\n        \"\"\"\n        Traverse relationships with properties matching the given parameters.\n\n            e.g: `.match(price__lt=10)`\n\n        :param kwargs: see `NodeSet.filter()` for syntax\n        :return: self\n        \"\"\"\n        if kwargs:\n            if self.definition.get('model') is None:\n                raise ValueError(\"match() with filter only available on relationships with a model\")\n            output = process_filter_args(self.definition['model'], kwargs)\n            if output:\n                self.filters.append(output)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inflate(self, value):\n        if not isinstance(value,neo4j.types.spatial.Point):\n            raise TypeError('Invalid datatype to inflate. Expected POINT datatype, received {}'.format(type(value)))\n\n        try:\n            value_point_crs = SRID_TO_CRS[value.srid]\n        except KeyError:\n            raise ValueError('Invalid SRID to inflate. '\n                             'Expected one of {}, received {}'.format(SRID_TO_CRS.keys(), value.srid))\n\n        if self._crs != value_point_crs:\n            raise ValueError('Invalid CRS. '\n                             'Expected POINT defined over {}, received {}'.format(self._crs, value_point_crs))\n        # cartesian\n        if value.srid == 7203:\n            return NeomodelPoint(x=value.x, y=value.y)\n        # cartesian-3d\n        elif value.srid == 9157:\n            return NeomodelPoint(x=value.x, y=value.y, z=value.z)\n        # wgs-84\n        elif value.srid == 4326:\n            return NeomodelPoint(longitude=value.longitude, latitude=value.latitude)\n        # wgs-83-3d\n        elif value.srid == 4979:\n            return NeomodelPoint(longitude=value.longitude, latitude=value.latitude, height=value.height)", "response": "Handles the marshalling from Neo4J POINT to NeomodelPoint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle the marshalling from NeomodelPoint to Neo4J POINT", "response": "def deflate(self, value):\n        \"\"\"\n        Handles the marshalling from NeomodelPoint to Neo4J POINT\n\n        :param value: The point that was assigned as value to a property in the model\n        :type value: NeomodelPoint\n        :return: Neo4J POINT\n        \"\"\"\n        if not isinstance(value, NeomodelPoint):\n            raise TypeError('Invalid datatype to deflate. Expected NeomodelPoint, received {}'.format(type(value)))\n\n        if not value.crs == self._crs:\n            raise ValueError('Invalid CRS. '\n                             'Expected NeomodelPoint defined over {}, '\n                             'received NeomodelPoint defined over {}'.format(self._crs, value.crs))\n\n        if value.crs == 'cartesian-3d':\n            return neo4j.types.spatial.CartesianPoint((value.x, value.y,  value.z))\n        elif value.crs == 'cartesian':\n            return neo4j.types.spatial.CartesianPoint((value.x,value.y))\n        elif value.crs == 'wgs-84':\n            return neo4j.types.spatial.WGS84Point((value.longitude, value.latitude))\n        elif value.crs == 'wgs-84-3d':\n            return neo4j.types.spatial.WGS84Point((value.longitude, value.latitude, value.height))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new instance of cls with the given children and connector.", "response": "def _new_instance(cls, children=None, connector=None, negated=False):\n        \"\"\"\n        Create a new instance of this class when new Nodes (or subclasses) are\n        needed in the internal code in this class. Normally, it just shadows\n        __init__(). However, subclasses with an __init__ signature that aren't\n        an extension of Node.__init__ might need to implement this method to\n        allow a Node to create a new instance of them (if they have any extra\n        setting up to do).\n        \"\"\"\n        obj = QBase(children, connector, negated)\n        obj.__class__ = cls\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, data, conn_type, squash=True):\n        if data in self.children:\n            return data\n        if not squash:\n            self.children.append(data)\n            return data\n        if self.connector == conn_type:\n            # We can reuse self.children to append or squash the node other.\n            if (isinstance(data, QBase) and not data.negated and\n                    (data.connector == conn_type or len(data) == 1)):\n                # We can squash the other node's children directly into this\n                # node. We are just doing (AB)(CD) == (ABCD) here, with the\n                # addition that if the length of the other node is 1 the\n                # connector doesn't matter. However, for the len(self) == 1\n                # case we don't want to do the squashing, as it would alter\n                # self.connector.\n                self.children.extend(data.children)\n                return self\n            else:\n                # We could use perhaps additional logic here to see if some\n                # children could be used for pushdown here.\n                self.children.append(data)\n                return data\n        else:\n            obj = self._new_instance(self.children, self.connector,\n                                     self.negated)\n            self.connector = conn_type\n            self.children = [obj, data]\n            return data", "response": "Adds the given data to the tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck for valid node i. e correct class and is saved", "response": "def _check_node(self, obj):\n        \"\"\"check for valid node i.e correct class and is saved\"\"\"\n        if not issubclass(type(obj), self.definition['node_class']):\n            raise ValueError(\"Expected node of class \" + self.definition['node_class'].__name__)\n        if not hasattr(obj, 'id'):\n            raise ValueError(\"Can't perform operation on unsaved node \" + repr(obj))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconnects a node to a new node.", "response": "def connect(self, node, properties=None):\n        \"\"\"\n        Connect a node\n\n        :param node:\n        :param properties: for the new relationship\n        :type: dict\n        :return:\n        \"\"\"\n        self._check_node(node)\n\n        if not self.definition['model'] and properties:\n            raise NotImplementedError(\n                \"Relationship properties without using a relationship model \"\n                \"is no longer supported.\"\n            )\n\n        params = {}\n        rel_model = self.definition['model']\n        rp = None  # rel_properties\n\n        if rel_model:\n            rp = {}\n            # need to generate defaults etc to create fake instance\n            tmp = rel_model(**properties) if properties else rel_model()\n            # build params and place holders to pass to rel_helper\n            for p, v in rel_model.deflate(tmp.__properties__).items():\n                rp[p] = '{' + p + '}'\n                params[p] = v\n\n            if hasattr(tmp, 'pre_save'):\n                tmp.pre_save()\n\n        new_rel = _rel_helper(lhs='us', rhs='them', ident='r', relation_properties=rp, **self.definition)\n        q = \"MATCH (them), (us) WHERE id(them)={them} and id(us)={self} \" \\\n            \"CREATE UNIQUE\" + new_rel\n\n        params['them'] = node.id\n\n        if not rel_model:\n            self.source.cypher(q, params)\n            return True\n\n        rel_ = self.source.cypher(q + \" RETURN r\", params)[0][0][0]\n        rel_instance = self._set_start_end_cls(rel_model.inflate(rel_), node)\n\n        if hasattr(rel_instance, 'post_save'):\n            rel_instance.post_save()\n\n        return rel_instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces a node with a new node.", "response": "def replace(self, node, properties=None):\n        \"\"\"\n        Disconnect all existing nodes and connect the supplied node\n\n        :param node:\n        :param properties: for the new relationship\n        :type: dict\n        :return:\n        \"\"\"\n        self.disconnect_all()\n        self.connect(node, properties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef relationship(self, node):\n        self._check_node(node)\n        my_rel = _rel_helper(lhs='us', rhs='them', ident='r', **self.definition)\n        q = \"MATCH \" + my_rel + \" WHERE id(them)={them} and id(us)={self} RETURN r LIMIT 1\"\n        rels = self.source.cypher(q, {'them': node.id})[0]\n        if not rels:\n            return\n\n        rel_model = self.definition.get('model') or StructuredRel\n\n        return self._set_start_end_cls(rel_model.inflate(rels[0][0]), node)", "response": "Retrieve the relationship object for this first relationship between self and node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reconnect(self, old_node, new_node):\n\n        self._check_node(old_node)\n        self._check_node(new_node)\n        if old_node.id == new_node.id:\n            return\n        old_rel = _rel_helper(lhs='us', rhs='old', ident='r', **self.definition)\n\n        # get list of properties on the existing rel\n        result, meta = self.source.cypher(\n            \"MATCH (us), (old) WHERE id(us)={self} and id(old)={old} \"\n            \"MATCH \" + old_rel + \" RETURN r\", {'old': old_node.id})\n        if result:\n            node_properties = _get_node_properties(result[0][0])\n            existing_properties = node_properties.keys()\n        else:\n            raise NotConnected('reconnect', self.source, old_node)\n\n        # remove old relationship and create new one\n        new_rel = _rel_helper(lhs='us', rhs='new', ident='r2', **self.definition)\n        q = \"MATCH (us), (old), (new) \" \\\n            \"WHERE id(us)={self} and id(old)={old} and id(new)={new} \" \\\n            \"MATCH \" + old_rel\n        q += \" CREATE UNIQUE\" + new_rel\n\n        # copy over properties if we have\n        for p in existing_properties:\n            q += \" SET r2.{0} = r.{1}\".format(p, p)\n        q += \" WITH r DELETE r\"\n\n        self.source.cypher(q, {'old': old_node.id, 'new': new_node.id})", "response": "Disconnect old_node and connect new_node copying over any properties on the original relationship and create new one."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisconnect a node from the cache.", "response": "def disconnect(self, node):\n        \"\"\"\n        Disconnect a node\n\n        :param node:\n        :return:\n        \"\"\"\n        rel = _rel_helper(lhs='a', rhs='b', ident='r', **self.definition)\n        q = \"MATCH (a), (b) WHERE id(a)={self} and id(b)={them} \" \\\n            \"MATCH \" + rel + \" DELETE r\"\n        self.source.cypher(q, {'them': node.id})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disconnect_all(self):\n        rhs = 'b:' + self.definition['node_class'].__label__\n        rel = _rel_helper(lhs='a', rhs=rhs, ident='r', **self.definition)\n        q = 'MATCH (a) WHERE id(a)={self} MATCH ' + rel + ' DELETE r'\n        self.source.cypher(q)", "response": "Disconnect all nodes from the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the associated node.", "response": "def single(self):\n        \"\"\"\n        Return the associated node.\n\n        :return: node\n        \"\"\"\n        nodes = super(ZeroOrOne, self).all()\n        if len(nodes) == 1:\n            return nodes[0]\n        if len(nodes) > 1:\n            raise CardinalityViolation(self, len(nodes))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to a node.", "response": "def connect(self, node, properties=None):\n        \"\"\"\n        Connect to a node.\n\n        :param node:\n        :type: StructuredNode\n        :param properties: relationship properties\n        :type: dict\n        :return: True / rel instance\n        \"\"\"\n        if len(self):\n            raise AttemptedCardinalityViolation(\n                    \"Node already has {0} can't connect more\".format(self))\n        else:\n            return super(ZeroOrOne, self).connect(node, properties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef single(self):\n        nodes = super(OneOrMore, self).all()\n        if nodes:\n            return nodes[0]\n        raise CardinalityViolation(self, 'none')", "response": "Fetch one of the related nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disconnect(self, node):\n        if super(OneOrMore, self).__len__() < 2:\n            raise AttemptedCardinalityViolation(\"One or more expected\")\n        return super(OneOrMore, self).disconnect(node)", "response": "Disconnects a node from the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the associated node.", "response": "def single(self):\n        \"\"\"\n        Return the associated node.\n\n        :return: node\n        \"\"\"\n        nodes = super(One, self).all()\n        if nodes:\n            if len(nodes) == 1:\n                return nodes[0]\n            else:\n                raise CardinalityViolation(self, len(nodes))\n        else:\n            raise CardinalityViolation(self, 'none')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconnect a node to a node.", "response": "def connect(self, node, properties=None):\n        \"\"\"\n        Connect a node\n\n        :param node:\n        :param properties: relationship properties\n        :return: True / rel instance\n        \"\"\"\n        if not hasattr(self.source, 'id'):\n            raise ValueError(\"Node has not been saved cannot connect!\")\n        if len(self):\n            raise AttemptedCardinalityViolation(\n                \"Node already has one relationship\"\n            )\n        else:\n            return super(One, self).connect(node, properties)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef drop_constraints(quiet=True, stdout=None):\n\n    results, meta = db.cypher_query(\"CALL db.constraints()\")\n    pattern = re.compile(':(.*) \\).*\\.(\\w*)')\n    for constraint in results:\n        db.cypher_query('DROP ' + constraint[0])\n        match = pattern.search(constraint[0])\n        stdout.write(''' - Droping unique constraint and index on label {0} with property {1}.\\n'''.format(\n            match.group(1), match.group(2)))\n    stdout.write(\"\\n\")", "response": "Discover and drop all unique constraints."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndiscovering and drop all indexes.", "response": "def drop_indexes(quiet=True, stdout=None):\n    \"\"\"\n    Discover and drop all indexes.\n\n    :type: bool\n    :return: None\n    \"\"\"\n\n    results, meta = db.cypher_query(\"CALL db.indexes()\")\n    pattern = re.compile(':(.*)\\((.*)\\)')\n    for index in results:\n        db.cypher_query('DROP ' + index[0])\n        match = pattern.search(index[0])\n        stdout.write(' - Dropping index on label {0} with property {1}.\\n'.format(\n            match.group(1), match.group(2)))\n    stdout.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls functions for dropping constraints and indexes.", "response": "def remove_all_labels(stdout=None):\n    \"\"\"\n    Calls functions for dropping constraints and indexes.\n\n    :param stdout: output stream\n    :return: None\n    \"\"\"\n\n    if not stdout:\n        stdout = sys.stdout\n\n    stdout.write(\"Droping constraints...\\n\")\n    drop_constraints(quiet=False, stdout=stdout)\n\n    stdout.write('Droping indexes...\\n')\n    drop_indexes(quiet=False, stdout=stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install_labels(cls, quiet=True, stdout=None):\n\n    if not hasattr(cls, '__label__'):\n        if not quiet:\n            stdout.write(' ! Skipping class {0}.{1} is abstract\\n'.format(cls.__module__, cls.__name__))\n        return\n\n    for name, property in cls.defined_properties(aliases=False, rels=False).items():\n        db_property = property.db_property or name\n        if property.index:\n            if not quiet:\n                stdout.write(' + Creating index {0} on label {1} for class {2}.{3}\\n'.format(\n                    name, cls.__label__, cls.__module__, cls.__name__))\n\n            db.cypher_query(\"CREATE INDEX on :{0}({1}); \".format(\n                cls.__label__, db_property))\n\n        elif property.unique_index:\n            if not quiet:\n                stdout.write(' + Creating unique constraint for {0} on label {1} for class {2}.{3}\\n'.format(\n                    name, cls.__label__, cls.__module__, cls.__name__))\n\n            db.cypher_query(\"CREATE CONSTRAINT \"\n                            \"on (n:{0}) ASSERT n.{1} IS UNIQUE; \".format(\n                cls.__label__, db_property))", "response": "Setup labels for a given class"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndiscovers all subclasses of StructuredNode and install labels on each.", "response": "def install_all_labels(stdout=None):\n    \"\"\"\n    Discover all subclasses of StructuredNode in your application and execute install_labels on each.\n    Note: code most be loaded (imported) in order for a class to be discovered.\n\n    :param stdout: output stream\n    :return: None\n    \"\"\"\n\n    if not stdout:\n        stdout = sys.stdout\n\n    def subsub(kls):  # recursively return all subclasses\n        return kls.__subclasses__() + [g for s in kls.__subclasses__() for g in subsub(s)]\n\n    stdout.write(\"Setting up indexes and constraints...\\n\\n\")\n\n    i = 0\n    for cls in subsub(StructuredNode):\n        stdout.write('Found {0}.{1}\\n'.format(cls.__module__, cls.__name__))\n        install_labels(cls, quiet=False, stdout=stdout)\n        i += 1\n\n    if i:\n        stdout.write('\\n')\n\n    stdout.write('Finished {0} classes.\\n'.format(i))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_merge_query(cls, merge_params, update_existing=False, lazy=False, relationship=None):\n        query_params = dict(merge_params=merge_params)\n        n_merge = \"n:{0} {{{1}}}\".format(\n            \":\".join(cls.inherited_labels()),\n            \", \".join(\"{0}: params.create.{0}\".format(getattr(cls, p).db_property or p) for p in cls.__required_properties__))\n        if relationship is None:\n            # create \"simple\" unwind query\n            query = \"UNWIND {{merge_params}} as params\\n MERGE ({0})\\n \".format(n_merge)\n        else:\n            # validate relationship\n            if not isinstance(relationship.source, StructuredNode):\n                raise ValueError(\"relationship source [{0}] is not a StructuredNode\".format(repr(relationship.source)))\n            relation_type = relationship.definition.get('relation_type')\n            if not relation_type:\n                raise ValueError('No relation_type is specified on provided relationship')\n\n            from .match import _rel_helper\n\n            query_params[\"source_id\"] = relationship.source.id\n            query = \"MATCH (source:{0}) WHERE ID(source) = {{source_id}}\\n \".format(relationship.source.__label__)\n            query += \"WITH source\\n UNWIND {merge_params} as params \\n \"\n            query += \"MERGE \"\n            query += _rel_helper(lhs='source', rhs=n_merge, ident=None,\n                                 relation_type=relation_type, direction=relationship.definition['direction'])\n\n        query += \"ON CREATE SET n = params.create\\n \"\n        # if update_existing, write properties on match as well\n        if update_existing is True:\n            query += \"ON MATCH SET n += params.update\\n\"\n\n        # close query\n        if lazy:\n            query += \"RETURN id(n)\"\n        else:\n            query += \"RETURN n\"\n\n        return query, query_params", "response": "Build a MERGE query for the specified class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new instance of the given class with the given properties.", "response": "def create(cls, *props, **kwargs):\n        \"\"\"\n        Call to CREATE with parameters map. A new instance will be created and saved.\n\n        :param props: dict of properties to create the nodes.\n        :type props: tuple\n        :param lazy: False by default, specify True to get nodes with id only without the parameters.\n        :type: bool\n        :rtype: list\n        \"\"\"\n\n        if 'streaming' in kwargs:\n            warnings.warn('streaming is not supported by bolt, please remove the kwarg',\n                          category=DeprecationWarning, stacklevel=1)\n\n        lazy = kwargs.get('lazy', False)\n        # create mapped query\n        query = \"CREATE (n:{0} {{create_params}})\".format(':'.join(cls.inherited_labels()))\n\n        # close query\n        if lazy:\n            query += \" RETURN id(n)\"\n        else:\n            query += \" RETURN n\"\n\n        results = []\n        for item in [cls.deflate(p, obj=_UnsavedNode(), skip_empty=True) for p in props]:\n            node, _ = db.cypher_query(query, {'create_params': item})\n            results.extend(node[0])\n\n        nodes = [cls.inflate(node) for node in results]\n\n        if not lazy and hasattr(cls, 'post_create'):\n            for node in nodes:\n                node.post_create()\n\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates or update a new instance of the class with the specified properties.", "response": "def create_or_update(cls, *props, **kwargs):\n        \"\"\"\n        Call to MERGE with parameters map. A new instance will be created and saved if does not already exists,\n        this is an atomic operation. If an instance already exists all optional properties specified will be updated.\n\n        Note that the post_create hook isn't called after create_or_update\n\n        :param props: List of dict arguments to get or create the entities with.\n        :type props: tuple\n        :param relationship: Optional, relationship to get/create on when new entity is created.\n        :param lazy: False by default, specify True to get nodes with id only without the parameters.\n        :rtype: list\n        \"\"\"\n        lazy = kwargs.get('lazy', False)\n        relationship = kwargs.get('relationship')\n\n        # build merge query, make sure to update only explicitly specified properties\n        create_or_update_params = []\n        for specified, deflated in [(p, cls.deflate(p, skip_empty=True)) for p in props]:\n            create_or_update_params.append({\"create\": deflated,\n                                            \"update\": dict((k, v) for k, v in deflated.items() if k in specified)})\n        query, params = cls._build_merge_query(create_or_update_params, update_existing=True, relationship=relationship,\n                                               lazy=lazy)\n\n        if 'streaming' in kwargs:\n            warnings.warn('streaming is not supported by bolt, please remove the kwarg',\n                          category=DeprecationWarning, stacklevel=1)\n\n        # fetch and build instance for each result\n        results = db.cypher_query(query, params)\n        return [cls.inflate(r[0]) for r in results[0]]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cypher(self, query, params=None):\n        self._pre_action_check('cypher')\n        params = params or {}\n        params.update({'self': self.id})\n        return db.cypher_query(query, params)", "response": "Execute a cypher query with the param self pre - populated with the nodes neo4j id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n        self._pre_action_check('delete')\n        self.cypher(\"MATCH (self) WHERE id(self)={self} \"\n                    \"OPTIONAL MATCH (self)-[r]-()\"\n                    \" DELETE r, self\")\n        delattr(self, 'id')\n        self.deleted = True\n        return True", "response": "Delete a node and its relationships"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets or create a new node with the given properties.", "response": "def get_or_create(cls, *props, **kwargs):\n        \"\"\"\n        Call to MERGE with parameters map. A new instance will be created and saved if does not already exists,\n        this is an atomic operation.\n        Parameters must contain all required properties, any non required properties with defaults will be generated.\n\n        Note that the post_create hook isn't called after get_or_create\n\n        :param props: dict of properties to get or create the entities with.\n        :type props: tuple\n        :param relationship: Optional, relationship to get/create on when new entity is created.\n        :param lazy: False by default, specify True to get nodes with id only without the parameters.\n        :rtype: list\n        \"\"\"\n        lazy = kwargs.get('lazy', False)\n        relationship = kwargs.get('relationship')\n\n        # build merge query\n        get_or_create_params = [{\"create\": cls.deflate(p, skip_empty=True)} for p in props]\n        query, params = cls._build_merge_query(get_or_create_params, relationship=relationship, lazy=lazy)\n\n        if 'streaming' in kwargs:\n            warnings.warn('streaming is not supported by bolt, please remove the kwarg',\n                          category=DeprecationWarning, stacklevel=1)\n\n        # fetch and build instance for each result\n        results = db.cypher_query(query, params)\n        return [cls.inflate(r[0]) for r in results[0]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninflate a raw neo4j_driver node to a neomodel node", "response": "def inflate(cls, node):\n        \"\"\"\n        Inflate a raw neo4j_driver node to a neomodel node\n        :param node:\n        :return: node object\n        \"\"\"\n        # support lazy loading\n        if isinstance(node, int):\n            snode = cls()\n            snode.id = node\n        else:\n            node_properties = _get_node_properties(node)\n            props = {}\n            for key, prop in cls.__all_properties__:\n                # map property name from database to object property\n                db_property = prop.db_property or key\n\n                if db_property in node_properties:\n                    props[key] = prop.inflate(node_properties[db_property], node)\n                elif prop.has_default:\n                    props[key] = prop.default_value()\n                else:\n                    props[key] = None\n\n            snode = cls(**props)\n            snode.id = node.id\n\n        return snode"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns list of labels from nodes class hierarchy.", "response": "def inherited_labels(cls):\n        \"\"\"\n        Return list of labels from nodes class hierarchy.\n\n        :return: list\n        \"\"\"\n        return [scls.__label__ for scls in cls.mro()\n                if hasattr(scls, '__label__') and not hasattr(\n                scls, '__abstract_node__')]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refresh(self):\n        self._pre_action_check('refresh')\n        if hasattr(self, 'id'):\n            request = self.cypher(\"MATCH (n) WHERE id(n)={self}\"\n                                            \" RETURN n\")[0]\n            if not request or not request[0]:\n                raise self.__class__.DoesNotExist(\"Can't refresh non existent node\")\n            node = self.inflate(request[0][0])\n            for key, val in node.__properties__.items():\n                setattr(self, key, val)\n        else:\n            raise ValueError(\"Can't refresh unsaved node\")", "response": "Reload the node from neo4j"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self):\n\n        # create or update instance node\n        if hasattr(self, 'id'):\n            # update\n            params = self.deflate(self.__properties__, self)\n            query = \"MATCH (n) WHERE id(n)={self} \\n\"\n            query += \"\\n\".join([\"SET n.{0} = {{{1}}}\".format(key, key) + \"\\n\"\n                                for key in params.keys()])\n            for label in self.inherited_labels():\n                query += \"SET n:`{0}`\\n\".format(label)\n            self.cypher(query, params)\n        elif hasattr(self, 'deleted') and self.deleted:\n            raise ValueError(\"{0}.save() attempted on deleted node\".format(\n                self.__class__.__name__))\n        else:  # create\n            self.id = self.create(self.__properties__)[0].id\n        return self", "response": "Save the node to neo4j or raise an exception"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a default value for the current locale.", "response": "def default_value(self):\n        \"\"\"\n        Generate a default value\n\n        :return: the value\n        \"\"\"\n        if self.has_default:\n            if hasattr(self.default, '__call__'):\n                return self.default()\n            else:\n                return self.default\n        else:\n            raise Exception(\"No default value specified\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self):\n        props = self.deflate(self.__properties__)\n        query = \"MATCH ()-[r]->() WHERE id(r)={self} \"\n        for key in props:\n            query += \" SET r.{0} = {{{1}}}\".format(key, key)\n        props['self'] = self.id\n\n        db.cypher_query(query, props)\n\n        return self", "response": "Save the relationship between this object and another object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget start node in the database.", "response": "def start_node(self):\n        \"\"\"\n        Get start node\n\n        :return: StructuredNode\n        \"\"\"\n        return db.cypher_query(\"MATCH (aNode) \"\n                               \"WHERE id(aNode)={nodeid} \"\n                               \"RETURN aNode\".format(nodeid=self._start_node_id),\n                               resolve_objects = True)[0][0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the end node of the node.", "response": "def end_node(self):\n        \"\"\"\n        Get end node\n\n        :return: StructuredNode\n        \"\"\"\n        return db.cypher_query(\"MATCH (aNode) \"\n                               \"WHERE id(aNode)={nodeid} \"\n                               \"RETURN aNode\".format(nodeid=self._end_node_id),\n                               resolve_objects = True)[0][0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inflate(cls, rel):\n        props = {}\n        for key, prop in cls.defined_properties(aliases=False, rels=False).items():\n            if key in rel:\n                props[key] = prop.inflate(rel[key], obj=rel)\n            elif prop.has_default:\n                props[key] = prop.default_value()\n            else:\n                props[key] = None\n        srel = cls(**props)\n        srel._start_node_id = rel.start_node.id\n        srel._end_node_id = rel.end_node.id\n        srel.id = rel.id\n        return srel", "response": "Inflate a neo4j_driver relationship object to a neomodel object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_JSON(self, JSON_string):\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        # Check if server returned errors: this check overcomes the lack of use\n        # of HTTP error status codes by the OWM API but it's supposed to be\n        # deprecated as soon as the API implements a correct HTTP mechanism for\n        # communicating errors to the clients. In addition, in this specific\n        # case the OWM API responses are the very same either when no results\n        # are found for a station and when the station does not exist!\n        measurements = {}\n        try:\n            if 'cod' in d:\n                if d['cod'] != \"200\":\n                    raise api_response_error.APIResponseError(\n                                              \"OWM API: error - response payload: \" + str(d), d['cod'])\n            if str(d['cnt']) == \"0\":\n                return None\n            else:\n                for item in d['list']:\n                    if 'temp' not in item:\n                        temp = None\n                    elif isinstance(item['temp'], dict):\n                        temp = item['temp']['v']\n                    else:\n                        temp = item['temp']\n                    if 'humidity' not in item:\n                        hum = None\n                    elif isinstance(item['humidity'], dict):\n                        hum = item['humidity']['v']\n                    else:\n                        hum = item['humidity']\n                    if 'pressure' not in item:\n                        pres = None\n                    elif isinstance(item['pressure'], dict):\n                        pres = item['pressure']['v']\n                    else:\n                        pres = item['pressure']\n                    if 'rain' in item and isinstance(item['rain']['today'],\n                                                     dict):\n                        rain = item['rain']['today']['v']\n                    else:\n                        rain = None\n                    if 'wind' in item and isinstance(item['wind']['speed'],\n                                                     dict):\n                        wind = item['wind']['speed']['v']\n                    else:\n                        wind = None\n                    measurements[item['dt']] = {\"temperature\": temp,\n                                                \"humidity\": hum,\n                                                \"pressure\": pres,\n                                                \"rain\": rain,\n                                                \"wind\": wind\n                                                }\n        except KeyError:\n            raise parse_response_error.ParseResponseError(__name__ + \\\n                                     ': impossible to read JSON data')\n        current_time = round(time.time())\n        return stationhistory.StationHistory(None, None, current_time,\n                                             measurements)", "response": "Parses a JSON string containing a station history object and returns a new instance of the class that is used to store the data in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninvoke the CO Index endpoint :param params_dict: dict of parameters :returns: a string containing raw JSON data :raises: *ValueError*, *APICallError*", "response": "def get_coi(self, params_dict):\n        \"\"\"\n        Invokes the CO Index endpoint\n\n        :param params_dict: dict of parameters\n        :returns: a string containing raw JSON data\n        :raises: *ValueError*, *APICallError*\n\n        \"\"\"\n        lat = str(params_dict['lat'])\n        lon = str(params_dict['lon'])\n        start = params_dict['start']\n        interval = params_dict['interval']\n\n        # build request URL\n        if start is None:\n            timeref = 'current'\n        else:\n            if interval is None:\n                timeref = self._trim_to(timeformatutils.to_date(start), 'year')\n            else:\n                timeref = self._trim_to(timeformatutils.to_date(start), interval)\n\n        fixed_url = '%s/%s,%s/%s.json' % (CO_INDEX_URL, lat, lon, timeref)\n        uri = http_client.HttpClient.to_url(fixed_url, self._API_key, None)\n        _, json_data = self._client.cacheable_get_json(uri)\n        return json_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_XML(self, xml_declaration=True, xmlns=True):\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         NO2INDEX_XMLNS_PREFIX,\n                                         NO2INDEX_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)", "response": "Dumps object fields to an XML - formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping the object data to a fully traversable DOM representation of the object.", "response": "def _to_DOM(self):\n        \"\"\"\n        Dumps object data to a fully traversable DOM representation of the\n        object.\n\n        :returns: a ``xml.etree.Element`` object\n\n        \"\"\"\n        root_node = ET.Element(\"no2index\")\n        reference_time_node = ET.SubElement(root_node, \"reference_time\")\n        reference_time_node.text = str(self._reference_time)\n        reception_time_node = ET.SubElement(root_node, \"reception_time\")\n        reception_time_node.text = str(self._reception_time)\n        interval_node = ET.SubElement(root_node, \"interval\")\n        interval_node.text = str(self._interval)\n        no2_samples_node = ET.SubElement(root_node, \"no2_samples\")\n        for smpl in self._no2_samples:\n            s = smpl.copy()\n            # turn values to 12 decimal digits-formatted strings\n            s['label'] = s['label']\n            s['value'] = '{:.12e}'.format(s['value'])\n            s['precision'] = '{:.12e}'.format(s['precision'])\n            xmlutils.create_DOM_node_from_dict(s, \"no2_sample\",\n                                               no2_samples_node)\n        root_node.append(self._location._to_DOM())\n        return root_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef items(cls):\n        return [\n            cls.TRUE_COLOR,\n            cls.FALSE_COLOR,\n            cls.NDVI,\n            cls.EVI\n        ]", "response": "Return a list of all values for this enum\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef items(cls):\n        return [\n            cls.GREEN,\n            cls.BLACK_AND_WHITE,\n            cls.CONTRAST_SHIFTED,\n            cls.CONTRAST_CONTINUOUS\n        ]", "response": "Return a list of all values for this enum."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a dictionary representing the attributes of a trigger entity.", "response": "def parse_dict(self, data_dict):\n        \"\"\"\n        Parses a dictionary representing the attributes of a `pyowm.alertapi30.trigger.Trigger` entity\n        :param data_dict: dict\n        :return: `pyowm.alertapi30.trigger.Trigger`\n        \"\"\"\n        assert isinstance(data_dict, dict)\n        string_repr = json.dumps(data_dict)\n        return self.parse_JSON(string_repr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_JSON(self, JSON_string):\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        try:\n            # trigger id\n            trigger_id = d.get('_id', None)\n\n            # start timestamp\n            start_dict = d['time_period']['start']\n            expr = start_dict['expression']\n            if expr != 'after':\n                raise ValueError('Invalid time expression: \"%s\" on start timestamp. Only: \"after\" is supported' % expr)\n            start = start_dict['amount']\n\n            # end timestamp\n            end_dict = d['time_period']['end']\n            expr = end_dict['expression']\n            if expr != 'after':\n                raise ValueError('Invalid time expression: \"%s\" on end timestamp. Only: \"after\" is supported' % expr)\n            end = end_dict['amount']\n\n            # conditions\n            conditions = [Condition.from_dict(c) for c in d['conditions']]\n\n            # alerts\n            alerts_dict = d['alerts']\n            alerts = list()\n            for key in alerts_dict:\n                alert_id = key\n                alert_data = alerts_dict[alert_id]\n                alert_last_update = alert_data['last_update']\n                alert_met_conds = [\n                    dict(current_value=c['current_value']['min'], condition=Condition.from_dict(c['condition']))\n                        for c in alert_data['conditions']\n                ]\n                alert_coords = alert_data['coordinates']\n                alert = Alert(alert_id, trigger_id, alert_met_conds, alert_coords, last_update=alert_last_update)\n                alerts.append(alert)\n\n            # area\n            area_list = d['area']\n            area = [GeometryBuilder.build(a_dict) for a_dict in area_list]\n\n            # alert channels\n            alert_channels = None  # defaulting\n\n        except ValueError as e:\n            raise parse_response_error.ParseResponseError('Impossible to parse JSON: %s' % e)\n        except KeyError as e:\n            raise parse_response_error.ParseResponseError('Impossible to parse JSON: %s' % e)\n\n        return Trigger(start, end, conditions, area=area, alerts=alerts, alert_channels=alert_channels, id=trigger_id)", "response": "Parses a JSON string containing a trigger and returns a pyowm. alertapi30. trigger. Trigger instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_JSON(self, JSON_string):\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        try:\n            alert_id = d['_id']\n            t = d['last_update'].split('.')[0].replace('T', ' ') + '+00'\n            alert_last_update = timeformatutils._ISO8601_to_UNIXtime(t)\n            alert_trigger_id = d['triggerId']\n            alert_met_conds = [\n                dict(current_value=c['current_value']['min'], condition=Condition.from_dict(c['condition']))\n                    for c in d['conditions']\n            ]\n            alert_coords = d['coordinates']\n            return Alert(alert_id, alert_trigger_id, alert_met_conds, alert_coords, last_update=alert_last_update)\n\n        except ValueError as e:\n            raise parse_response_error.ParseResponseError('Impossible to parse JSON: %s' % e)\n        except KeyError as e:\n            raise parse_response_error.ParseResponseError('Impossible to parse JSON: %s' % e)", "response": "Parses a raw JSON string containing a alert and returns a new alert object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a new data node to the front list.", "response": "def add(self, data):\n        \"\"\"\n        Adds a new data node to the front list. The provided data will be\n        encapsulated into a new instance of LinkedListNode class and linked\n        list pointers will be updated, as well as list's size.\n\n        :param data: the data to be inserted in the new list node\n        :type data: object\n\n        \"\"\"\n        node = LinkedListNode(data, None)\n        if self._size == 0:\n            self._first_node = node\n            self._last_node = node\n        else:\n            second_node = self._first_node\n            self._first_node = node\n            self._first_node.update_next(second_node)\n        self._size += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self, data):\n        current_node = self._first_node\n        deleted = False\n\n        if self._size == 0:\n            return\n\n        if data == current_node.data():\n            # case 1: the list has only one item\n            if current_node.next() is None:\n                self._first_node = LinkedListNode(None, None)\n                self._last_node = self._first_node\n                self._size = 0\n                return\n            # case 2: the list has more than one item\n            current_node = current_node.next()\n            self._first_node = current_node\n            self._size -= 1\n            return\n\n        while True:\n            if current_node is None:\n                deleted = False\n                break\n            # Check next element's data\n            next_node = current_node.next()\n            if next_node is not None:\n                if data == next_node.data():\n                    next_next_node = next_node.next()\n                    current_node.update_next(next_next_node)\n                    next_node = None\n                    deleted = True\n                    break\n            current_node = current_node.next()\n        if deleted:\n            self._size -= 1", "response": "Removes a data node from the list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the provided data is stored in at least one node of the list.", "response": "def contains(self, data):\n        \"\"\"\n        Checks if the provided data is stored in at least one node of the list.\n\n        :param data: the seeked data\n        :type data: object\n        :returns: a boolean\n\n        \"\"\"\n        for item in self:\n            if item.data() == data:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef index_of(self, data):\n        current_node = self._first_node\n        pos = 0\n        while current_node:\n            if current_node.data() == data:\n                return pos\n            else:\n                current_node = current_node.next()\n                pos += 1\n        return -1", "response": "Returns the index of the first occurrence of the data in the node in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop(self):\n        popped = False\n        result = None\n        current_node = self._first_node\n        while not popped:\n            next_node = current_node.next()\n            next_next_node = next_node.next()\n            if not next_next_node:\n                self._last_node = current_node\n                self._last_node.update_next(None)\n                self._size -= 1\n                result = next_node.data()\n                popped = True\n            current_node = next_node\n        return result", "response": "Removes the last node from the list and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a weather object out of a dictionary.", "response": "def weather_from_dictionary(d):\n    \"\"\"\n    Builds a *Weather* object out of a data dictionary. Only certain\n    properties of the dictionary are used: if these properties are not\n    found or cannot be read, an error is issued.\n\n    :param d: a data dictionary\n    :type d: dict\n    :returns: a *Weather* instance\n    :raises: *KeyError* if it is impossible to find or read the data\n        needed to build the instance\n\n    \"\"\"\n    # -- times\n    if 'dt' in d:\n        reference_time = d['dt']\n    elif 'dt' in d['last']:\n        reference_time = d['last']['dt']\n    if 'sys' in d and 'sunset' in d['sys']:\n        sunset_time = d['sys']['sunset']\n    else:\n        sunset_time = 0\n    if 'sys' in d and 'sunrise' in d['sys']:\n        sunrise_time = d['sys']['sunrise']\n    else:\n        sunrise_time = 0\n    # -- calc\n    if 'calc' in d:\n        if 'dewpoint' in d['calc']:\n            dewpoint = d['calc']['dewpoint']\n        else:\n            dewpoint = None\n        if 'humidex' in d['calc']:\n            humidex = d['calc']['humidex']\n        else:\n            humidex = None\n        if 'heatindex' in d['calc']:\n            heat_index = d['calc']['heatindex']\n        else:\n            heat_index = None\n    elif 'last' in d:\n        if 'calc' in d['last']:\n            if 'dewpoint' in d['last']['calc']:\n                dewpoint = d['last']['calc']['dewpoint']\n            else:\n                dewpoint = None\n            if 'humidex' in d['last']['calc']:\n                humidex = d['last']['calc']['humidex']\n            else:\n                humidex = None\n            if 'heatindex' in d['last']['calc']:\n                heat_index = d['last']['calc']['heatindex']\n            else:\n                heat_index = None\n    else:\n        dewpoint = None\n        humidex = None\n        heat_index = None\n    # -- visibility\n    if 'visibility' in d:\n        if isinstance(d['visibility'], int):\n            visibility_distance = d['visibility']\n        elif 'distance' in d['visibility']:\n            visibility_distance = d['visibility']['distance']\n        else:\n            visibility_distance = None\n    elif 'last' in d and 'visibility' in d['last']:\n        if isinstance(d['last']['visibility'], int):\n            visibility_distance = d['last']['visibility']\n        elif 'distance' in d['last']['visibility']:\n            visibility_distance = d['last']['visibility']['distance']\n        else:\n            visibility_distance = None\n    else:\n        visibility_distance = None\n    # -- clouds\n    if 'clouds' in d:\n        if isinstance(d['clouds'], int) or isinstance(d['clouds'], float):\n            clouds = d['clouds']\n        elif 'all' in d['clouds']:\n            clouds = d['clouds']['all']\n        else:\n            clouds = 0\n    else:\n        clouds = 0\n    # -- rain\n    if 'rain' in d:\n        if isinstance(d['rain'], int) or isinstance(d['rain'], float):\n            rain = {'all': d['rain']}\n        else:\n            if d['rain'] is not None:\n                rain = d['rain'].copy()\n            else:\n                rain = dict()\n    else:\n        rain = dict()\n    # -- wind\n    if 'wind' in d and d['wind'] is not None:\n        wind = d['wind'].copy()\n    elif 'last' in d:\n        if 'wind' in d['last'] and d['last']['wind'] is not None:\n            wind = d['last']['wind'].copy()\n        else:\n            wind = dict()\n    else:\n        wind = dict()\n        if 'speed' in d:\n            wind['speed'] = d['speed']\n        if 'deg' in d:\n            wind['deg'] = d['deg']\n    # -- humidity\n    if 'humidity' in d:\n        humidity = d['humidity']\n    elif 'main' in d and 'humidity' in d['main']:\n        humidity = d['main']['humidity']\n    elif 'last' in d and 'main' in d['last'] and 'humidity' in d['last']['main']:\n        humidity = d['last']['main']['humidity']\n    else:\n        humidity = 0\n    # -- snow\n    if 'snow' in d:\n        if isinstance(d['snow'], int) or isinstance(d['snow'], float):\n            snow = {'all': d['snow']}\n        else:\n            if d['snow'] is not None:\n                snow = d['snow'].copy()\n            else:\n                snow = dict()\n    else:\n        snow = dict()\n    # -- pressure\n    if 'pressure' in d:\n        atm_press = d['pressure']\n    elif 'main' in d and 'pressure' in d['main']:\n        atm_press = d['main']['pressure']\n    elif 'last' in d:\n        if 'main' in d['last']:\n            atm_press = d['last']['main']['pressure']\n    else:\n        atm_press = None\n    if 'main' in d and 'sea_level' in d['main']:\n        sea_level_press = d['main']['sea_level']\n    else:\n        sea_level_press = None\n    pressure = {'press': atm_press, 'sea_level': sea_level_press}\n    # -- temperature\n    if 'temp' in d:\n        if d['temp'] is not None:\n            temperature = d['temp'].copy()\n        else:\n            temperature = dict()\n    elif 'main' in d and 'temp' in d['main']:\n        temp = d['main']['temp']\n        if 'temp_kf' in d['main']:\n            temp_kf = d['main']['temp_kf']\n        else:\n            temp_kf = None\n        if 'temp_max' in d['main']:\n            temp_max = d['main']['temp_max']\n        else:\n            temp_max = None\n        if 'temp_min' in d['main']:\n            temp_min = d['main']['temp_min']\n        else:\n            temp_min = None\n        temperature = {'temp': temp,\n                       'temp_kf': temp_kf,\n                       'temp_max': temp_max,\n                       'temp_min': temp_min\n                       }\n    elif 'last' in d:\n        if 'main' in d['last']:\n            temperature = dict(temp=d['last']['main']['temp'])\n    else:\n        temperature = dict()\n    # -- weather status info\n    if 'weather' in d:\n        status = d['weather'][0]['main']\n        detailed_status = d['weather'][0]['description']\n        weather_code = d['weather'][0]['id']\n        weather_icon_name = d['weather'][0]['icon']\n    else:\n        status = ''\n        detailed_status = ''\n        weather_code = 0\n        weather_icon_name = ''\n\n    return Weather(reference_time, sunset_time, sunrise_time, clouds,\n                rain, snow, wind, humidity, pressure, temperature,\n                status, detailed_status, weather_code, weather_icon_name,\n                visibility_distance, dewpoint, humidex, heat_index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sunset_time(self, timeformat='unix'):\n        if self._sunset_time is None:\n            return None\n        return timeformatutils.timeformat(self._sunset_time, timeformat)", "response": "Returns the GMT time of sunset entry in the specified format"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the GMT time of sunrise entry in the specified format", "response": "def get_sunrise_time(self, timeformat='unix'):\n        \"\"\"Returns the GMT time of sunrise\n\n        :param timeformat: the format for the time value. May be:\n            '*unix*' (default) for UNIX time or '*iso*' for ISO8601-formatted\n            string in the format ``YYYY-MM-DD HH:MM:SS+00``\n        :type timeformat: str\n        :returns: an int or a str or None\n        :raises: ValueError\n\n        \"\"\"\n        if self._sunrise_time is None:\n            return None\n        return timeformatutils.timeformat(self._sunrise_time, timeformat)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_wind(self, unit='meters_sec'):\n        if unit == 'meters_sec':\n            return self._wind\n        elif unit == 'miles_hour':\n            wind_dict = {k: self._wind[k] for k in self._wind if self._wind[k] is not None}\n            return temputils.metric_wind_dict_to_imperial(wind_dict)\n        else:\n            raise ValueError(\"Invalid value for target wind conversion unit\")", "response": "Returns a dict containing wind info for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dict with temperature info.", "response": "def get_temperature(self, unit='kelvin'):\n        \"\"\"Returns a dict with temperature info\n\n        :param unit: the unit of measure for the temperature values. May be:\n            '*kelvin*' (default), '*celsius*' or '*fahrenheit*'\n        :type unit: str\n        :returns: a dict containing temperature values.\n        :raises: ValueError when unknown temperature units are provided\n\n        \"\"\"\n        # This is due to the fact that the OWM Weather API responses are mixing\n        # absolute temperatures and temperature deltas together\n        to_be_converted = dict()\n        not_to_be_converted = dict()\n        for label, temp in self._temperature.items():\n            if temp is None or temp < 0:\n                not_to_be_converted[label] = temp\n            else:\n                to_be_converted[label] = temp\n        converted = temputils.kelvin_dict_to(to_be_converted, unit)\n        return dict(list(converted.items()) + \\\n                    list(not_to_be_converted.items()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps the object fields into a JSON formatted string", "response": "def to_JSON(self):\n        \"\"\"Dumps object fields into a JSON formatted string\n\n        :returns: the JSON string\n\n        \"\"\"\n        return json.dumps({'reference_time': self._reference_time,\n                           'sunset_time': self._sunset_time,\n                           'sunrise_time': self._sunrise_time,\n                           'clouds': self._clouds,\n                           'rain': self._rain,\n                           'snow': self._snow,\n                           'wind': self._wind,\n                           'humidity': self._humidity,\n                           'pressure': self._pressure,\n                           'temperature': self._temperature,\n                           'status': self._status,\n                           'detailed_status': self._detailed_status,\n                           'weather_code': self._weather_code,\n                           'weather_icon_name': self._weather_icon_name,\n                           'visibility_distance': self._visibility_distance,\n                           'dewpoint': self._dewpoint,\n                           'humidex': self._humidex,\n                           'heat_index': self._heat_index})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_XML(self, xml_declaration=True, xmlns=True):\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         WEATHER_XMLNS_PREFIX,\n                                         WEATHER_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration). \\\n            encode('utf-8')", "response": "Dumps the object fields to an XML - formatted string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump the object data to a fully traversable DOM representation of the object.", "response": "def _to_DOM(self):\n        \"\"\"\n        Dumps object data to a fully traversable DOM representation of the\n        object.\n\n        :returns: a ``xml.etree.Element`` object\n\n        \"\"\"\n        root_node = ET.Element(\"weather\")\n        status_node = ET.SubElement(root_node, \"status\")\n        status_node.text = self._status\n        weather_code_node = ET.SubElement(root_node, \"weather_code\")\n        weather_code_node.text = str(self._weather_code)\n        xmlutils.create_DOM_node_from_dict(self._rain, \"rain\", root_node)\n        xmlutils.create_DOM_node_from_dict(self._snow, \"snow\", root_node)\n        xmlutils.create_DOM_node_from_dict(self._pressure, \"pressure\",\n                                             root_node)\n        node_sunrise_time = ET.SubElement(root_node, \"sunrise_time\")\n        node_sunrise_time.text = str(self._sunrise_time) if self._sunrise_time is not None else 'null'\n        weather_icon_name_node = ET.SubElement(root_node, \"weather_icon_name\")\n        weather_icon_name_node.text = self._weather_icon_name\n        clouds_node = ET.SubElement(root_node, \"clouds\")\n        clouds_node.text = str(self._clouds)\n        xmlutils.create_DOM_node_from_dict(self._temperature,\n                                                \"temperature\", root_node)\n        detailed_status_node = ET.SubElement(root_node, \"detailed_status\")\n        detailed_status_node.text = self._detailed_status\n        reference_time_node = ET.SubElement(root_node, \"reference_time\")\n        reference_time_node.text = str(self._reference_time)\n        sunset_time_node = ET.SubElement(root_node, \"sunset_time\")\n        sunset_time_node.text = str(self._sunset_time) if self._sunset_time is not None else 'null'\n        humidity_node = ET.SubElement(root_node, \"humidity\")\n        humidity_node.text = str(self._humidity)\n        xmlutils.create_DOM_node_from_dict(self._wind, \"wind\", root_node)\n        visibility_distance_node = ET.SubElement(root_node, \"visibility_distance\")\n        visibility_distance_node.text = str(self._visibility_distance)\n        dewpoint_node = ET.SubElement(root_node, \"dewpoint\")\n        dewpoint_node.text = str(self._dewpoint)\n        humidex_node = ET.SubElement(root_node, \"humidex\")\n        humidex_node.text = str(self._humidex)\n        heat_index_node = ET.SubElement(root_node, \"heat_index\")\n        heat_index_node.text = str(self._heat_index)\n        return root_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the UTC time of creation of this station", "response": "def creation_time(self, timeformat='unix'):\n        \"\"\"Returns the UTC time of creation of this station\n\n        :param timeformat: the format for the time value. May be:\n            '*unix*' (default) for UNIX time, '*iso*' for ISO8601-formatted\n            string in the format ``YYYY-MM-DD HH:MM:SS+00`` or `date` for\n            a ``datetime.datetime`` object\n        :type timeformat: str\n        :returns: an int or a str or a ``datetime.datetime`` object or None\n        :raises: ValueError\n\n        \"\"\"\n        if self.created_at is None:\n            return None\n        return timeformatutils.timeformat(self.created_at, timeformat)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the UTC time of the last update on this station s metadata .", "response": "def last_update_time(self, timeformat='unix'):\n        \"\"\"Returns the UTC time of the last update on this station's metadata\n\n        :param timeformat: the format for the time value. May be:\n            '*unix*' (default) for UNIX time, '*iso*' for ISO8601-formatted\n            string in the format ``YYYY-MM-DD HH:MM:SS+00`` or `date` for\n            a ``datetime.datetime`` object\n        :type timeformat: str\n        :returns: an int or a str or a ``datetime.datetime`` object or None\n        :raises: ValueError\n\n        \"\"\"\n        if self.updated_at is None:\n            return None\n        return timeformatutils.timeformat(self.updated_at, timeformat)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_JSON(self):\n        return json.dumps({'id': self.id,\n                           'external_id': self.external_id,\n                           'name': self.name,\n                           'created_at': timeformatutils.to_ISO8601(self.created_at),\n                           'updated_at': timeformatutils.to_ISO8601(self.updated_at),\n                           'lat': self.lat,\n                           'lon': self.lon,\n                           'alt': self.alt if self.alt is not None else 'None',\n                           'rank': self.rank})", "response": "Dumps the object fields into a JSON formatted string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping the object fields to an XML - formatted string.", "response": "def to_XML(self, xml_declaration=True, xmlns=True):\n        \"\"\"\n        Dumps object fields to an XML-formatted string. The 'xml_declaration'\n        switch  enables printing of a leading standard XML line containing XML\n        version and encoding. The 'xmlns' switch enables printing of qualified\n        XMLNS prefixes.\n\n        :param XML_declaration: if ``True`` (default) prints a leading XML\n            declaration line\n        :type XML_declaration: bool\n        :param xmlns: if ``True`` (default) prints full XMLNS prefixes\n        :type xmlns: bool\n        :returns: an XML-formatted string\n\n        \"\"\"\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         STATION_XMLNS_PREFIX,\n                                         STATION_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping the object data to a fully traversable DOM representation of the object.", "response": "def _to_DOM(self):\n        \"\"\"\n        Dumps object data to a fully traversable DOM representation of the\n        object.\n\n        :returns: a ``xml.etree.Element`` object\n\n        \"\"\"\n        root_node = ET.Element('station')\n        created_at_node = ET.SubElement(root_node, \"created_at\")\n        created_at_node.text = \\\n            timeformatutils.to_ISO8601(self.created_at)if self.created_at is not None else 'null'\n        updated_at_node = ET.SubElement(root_node, \"updated_at\")\n        updated_at_node.text = \\\n            timeformatutils.to_ISO8601(self.updated_at)if self.updated_at is not None else 'null'\n        station_id_node = ET.SubElement(root_node, 'id')\n        station_id_node.text = str(self.id)\n        station_id_node = ET.SubElement(root_node, 'external_id')\n        station_id_node.text = str(self.external_id)\n        station_name_node = ET.SubElement(root_node, 'name')\n        station_name_node.text = str(self.name) if self.name is not None else 'null'\n        lat_node = ET.SubElement(root_node, 'lat')\n        lat_node.text = str(self.lat)\n        lon_node = ET.SubElement(root_node, 'lon')\n        lon_node.text = str(self.lon)\n        alt_node = ET.SubElement(root_node, 'alt')\n        alt_node.text = str(self.alt) if self.alt is not None else 'null'\n        rank_node = ET.SubElement(root_node, 'rank')\n        rank_node.text = str(self.rank) if self.rank is not None else 'null'\n\n        return root_node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_JSON(self):\n        return json.dumps({\"station_ID\": self._station_ID,\n                            \"interval\": self._interval,\n                            \"reception_time\": self._reception_time,\n                            \"measurements\": self._measurements\n                           })", "response": "Dumps the object fields into a JSON formatted string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_XML(self, xml_declaration=True, xmlns=True):\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         STATION_HISTORY_XMLNS_PREFIX,\n                                         STATION_HISTORY_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)", "response": "Dumps the object fields to an XML - formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndump the object data to a fully traversable DOM representation of the object.", "response": "def _to_DOM(self):\n        \"\"\"\n        Dumps object data to a fully traversable DOM representation of the\n        object.\n\n        :returns: a ``xml.etree.Element`` object\n\n        \"\"\"\n        root_node = ET.Element(\"station_history\")\n        station_id_node = ET.SubElement(root_node, \"station_id\")\n        station_id_node.text = str(self._station_ID)\n        interval_node = ET.SubElement(root_node, \"interval\")\n        interval_node.text = self._interval\n        reception_time_node = ET.SubElement(root_node, \"reception_time\")\n        reception_time_node.text = str(self._reception_time)\n        measurements_node = ET.SubElement(root_node, \"measurements\")\n        for m in self._measurements:\n            d = self._measurements[m].copy()\n            d['reference_time'] = m\n            xmlutils.create_DOM_node_from_dict(d, \"measurement\",\n                                               measurements_node)\n        return root_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_JSON(self, JSON_string):\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        # Check if server returned errors: this check overcomes the lack of use\n        # of HTTP error status codes by the OWM API 2.5. This mechanism is\n        # supposed to be deprecated as soon as the API fully adopts HTTP for\n        # conveying errors to the clients\n        if 'message' in d and 'cod' in d:\n            if d['cod'] == \"404\":\n                print(\"OWM API: data not found - response payload: \" + \\\n                    json.dumps(d))\n                return None\n            elif d['cod'] != \"200\":\n                raise api_response_error.APIResponseError(\n                                      \"OWM API: error - response payload: \" + json.dumps(d), d['cod'])\n        # Handle the case when no results are found\n        if 'cnt' in d and d['cnt'] == \"0\":\n            return []\n        else:\n            if 'list' in d:\n                try:\n                    return [weather.weather_from_dictionary(item) \\\n                            for item in d['list']]\n                except KeyError:\n                    raise parse_response_error.ParseResponseError(\n                              ''.join([__name__, ': impossible to read ' \\\n                                              'weather info from JSON data'])\n                          )\n            else:\n                raise parse_response_error.ParseResponseError(\n                              ''.join([__name__, ': impossible to read ' \\\n                                              'weather list from JSON data'])\n                      )", "response": "Parses a JSON string containing a list of weather instances."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tomorrow(hour=None, minute=None):\n    if hour is None:\n        hour = datetime.now().hour\n    if minute is None:\n        minute = datetime.now().minute\n    tomorrow_date = date.today() + timedelta(days=1)\n    return datetime(tomorrow_date.year, tomorrow_date.month, tomorrow_date.day,\n                    hour, minute, 0)", "response": "Returns the datetime object corresponding to tomorrow."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the datetime object corresponding to yesterday.", "response": "def yesterday(hour=None, minute=None):\n    \"\"\"\n    Gives the ``datetime.datetime`` object corresponding to yesterday. The\n    default value for optional parameters is the current value of hour and\n    minute. I.e: when called without specifying values for parameters, the\n    resulting object will refer to the time = now - 24 hours; when called with\n    only hour specified, the resulting object will refer to yesterday at the\n    specified hour and at the current minute.\n\n    :param hour: the hour for yesterday, in the format *0-23* (defaults to\n        ``None``)\n    :type hour: int\n    :param minute: the minute for yesterday, in the format *0-59* (defaults to\n        ``None``)\n    :type minute: int\n    :returns: a ``datetime.datetime`` object\n    :raises: *ValueError* when hour or minute have bad values\n    \"\"\"\n    if hour is None:\n        hour = datetime.now().hour\n    if minute is None:\n        minute = datetime.now().minute\n    yesterday_date = date.today() + timedelta(days=-1)\n    return datetime(yesterday_date.year, yesterday_date.month,\n                    yesterday_date.day, hour, minute, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef millis_offset_between_epochs(reference_epoch, target_epoch):\n    assert isinstance(reference_epoch, int)\n    assert isinstance(target_epoch, int)\n    return (target_epoch - reference_epoch)*1000", "response": "Calculates the millis offset between two epochs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bounding_polygon(self):\n        lon_left, lat_bottom, lon_right, lat_top = Tile.tile_coords_to_bbox(self.x, self.y, self.zoom)\n        print(lon_left, lat_bottom, lon_right, lat_top)\n        return Polygon([[[lon_left, lat_top],\n                       [lon_right, lat_top],\n                       [lon_right, lat_bottom],\n                       [lon_left, lat_bottom],\n                       [lon_left, lat_top]]])", "response": "Returns the bounding box polygon for this tile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the coordinates of the tile containing the specified geopoint at the specified zoom level.", "response": "def tile_coords_for_point(cls, geopoint, zoom):\n        \"\"\"\n        Returns the coordinates of the tile containing the specified geopoint at the specified zoom level\n\n        :param geopoint: the input geopoint instance\n        :type geopoint: `pywom.utils.geo.Point`\n        :param zoom: zoom level\n        :type zoom: int\n        :return: a tuple (x, y) containing the tile-coordinates\n        \"\"\"\n        return Tile.geoocoords_to_tile_coords(geopoint.lon, geopoint.lat, zoom)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the tile numbers corresponding to the specified geocoordinates at the specified zoom level.", "response": "def geoocoords_to_tile_coords(cls, lon, lat, zoom):\n        \"\"\"\n        Calculates the tile numbers corresponding to the specified geocoordinates at the specified zoom level\n        Coordinates shall be provided in degrees and using the Mercator Projection (http://en.wikipedia.org/wiki/Mercator_projection)\n\n        :param lon: longitude\n        :type lon: int or float\n        :param lat: latitude\n        :type lat: int or float\n        :param zoom: zoom level\n        :type zoom: int\n        :return: a tuple (x, y) containing the tile-coordinates\n        \"\"\"\n        n = 2.0 ** zoom\n        x = int((lon + 180.0) / 360.0 * n)\n        y = int((1.0 - math.log(math.tan(math.radians(lat)) + (1 / math.cos(math.radians(lat)))) / math.pi) / 2.0 * n)\n        return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the lon lat coordinates of the bounding box corresponding to specific tile coordinates.", "response": "def tile_coords_to_bbox(cls, x, y, zoom):\n        \"\"\"\n        Calculates the lon/lat estrema of the bounding box corresponding to specific tile coordinates. Output coodinates\n        are in degrees and in the Mercator Projection (http://en.wikipedia.org/wiki/Mercator_projection)\n\n        :param x: the x tile coordinates\n        :param y: the y tile coordinates\n        :param zoom: the zoom level\n        :return: tuple with (lon_left, lat_bottom, lon_right, lat_top)\n        \"\"\"\n        def tile_to_geocoords(x, y, zoom):\n            n = 2. ** zoom\n            lon = x / n * 360. - 180.\n            lat = math.degrees(math.atan(math.sinh(math.pi * (1 - 2 * y / n))))\n            return lat, lon\n        north_west_corner =  tile_to_geocoords(x, y, zoom)\n        south_east_corner = tile_to_geocoords(x+1, y+1, zoom)\n        return north_west_corner[1], south_east_corner[0], south_east_corner[1], north_west_corner[0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tile(self, x, y, zoom):\n        status, data = self.http_client.get_png(\n            ROOT_TILE_URL % self.map_layer + '/%s/%s/%s.png' % (zoom, x, y),\n            params={'appid': self.API_key})\n        img = Image(data, ImageTypeEnum.PNG)\n        return Tile(x, y, zoom, self.map_layer, img)", "response": "Retrieves the tile with the specified coordinates and zoom level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a raw JSON string containing a station object.", "response": "def parse_JSON(self, JSON_string):\n        \"\"\"\n        Parses a *pyowm.stationsapi30.station.Station* instance out of raw JSON\n        data.\n\n        :param JSON_string: a raw JSON string\n        :type JSON_string: str\n        :return: a *pyowm.stationsapi30.station.Station** instance or ``None``\n            if no data is available\n        :raises: *ParseResponseError* if it is impossible to find or parse the\n            data needed to build the result\n\n        \"\"\"\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        try:\n            id = d.get('ID', None) or d.get('id', None)\n            external_id = d.get('external_id', None)\n            lon = d.get('longitude', None)\n            lat = d.get('latitude', None)\n            alt = d.get('altitude', None)\n        except KeyError as e:\n            raise parse_response_error.ParseResponseError('Impossible to parse JSON: %s' % e)\n        name = d.get('name', None)\n        rank = d.get('rank', None)\n        created_at = d.get('created_at', None)\n        updated_at = d.get('updated_at', None)\n        return Station(id, created_at, updated_at, external_id, name, lon, lat,\n                       alt, rank)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_JSON(self):\n        last = None\n        if self._last_weather:\n            last = self._last_weather.to_JSON()\n        return json.dumps({'name': self._name,\n                           'station_ID': self._station_ID,\n                           'station_type': self._station_type,\n                           'status': self._status,\n                           'lat': self._lat,\n                           'lon': self._lon,\n                           'distance': self._distance,\n                           'weather': json.loads(last),\n                           })", "response": "Dumps object fields into a JSON formatted string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndump the object fields to an XML - formatted string.", "response": "def to_XML(self, xml_declaration=True, xmlns=True):\n        \"\"\"\n        Dumps object fields to an XML-formatted string. The 'xml_declaration'\n        switch  enables printing of a leading standard XML line containing XML\n        version and encoding. The 'xmlns' switch enables printing of qualified\n        XMLNS prefixes.\n\n        :param XML_declaration: if ``True`` (default) prints a leading XML\n            declaration line\n        :type XML_declaration: bool\n        :param xmlns: if ``True`` (default) prints full XMLNS prefixes\n        :type xmlns: bool\n        :returns: an XML-formatted string\n\n        \"\"\"\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         LIST_STATION_XMLNS_PREFIX,\n                                         LIST_STATION_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _to_DOM(self):\n        last_weather = None\n        if (self._last_weather\n                and isinstance(self._last_weather, weather.Weather)):\n            last_weather = self._last_weather._to_DOM()\n\n        root_node = ET.Element('station')\n        station_name_node = ET.SubElement(root_node, 'name')\n        station_name_node.text = str(self._name)\n        station_id_node = ET.SubElement(root_node, 'station_id')\n        station_id_node.text = str(self._station_ID)\n        station_type_node = ET.SubElement(root_node, 'station_type')\n        station_type_node.text = str(self._station_type)\n        status_node = ET.SubElement(root_node, 'status')\n        status_node.text = str(self._status)\n        coords_node = ET.SubElement(root_node, 'coords')\n        lat_node = ET.SubElement(coords_node, 'lat')\n        lat_node.text = str(self._lat)\n        lon_node = ET.SubElement(coords_node, 'lon')\n        lon_node.text = str(self._lon)\n        distance_node = ET.SubElement(root_node, 'distance')\n        distance_node.text = str(self._distance)\n        root_node.append(last_weather)\n        return root_node", "response": "Dumps object data to a fully traversable DOM representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_trigger(self,  start, end, conditions, area, alert_channels=None):\n        assert start is not None\n        assert end is not None\n\n        # prepare time period\n        unix_start = timeformatutils.to_UNIXtime(start)\n        unix_end = timeformatutils.to_UNIXtime(end)\n        unix_current = timeutils.now(timeformat='unix')\n        if unix_start >= unix_end:\n            raise ValueError(\"The start timestamp must precede the end timestamp\")\n        delta_millis_start = timeutils.millis_offset_between_epochs(unix_current, unix_start)\n        delta_millis_end = timeutils.millis_offset_between_epochs(unix_current, unix_end)\n        the_time_period = {\n            \"start\": {\n                \"expression\": \"after\",\n                \"amount\": delta_millis_start\n            },\n            \"end\": {\n                \"expression\": \"after\",\n                \"amount\": delta_millis_end\n            }\n        }\n\n        assert conditions is not None\n        if len(conditions) == 0:\n            raise ValueError('A trigger must contain at least one condition: you provided none')\n        the_conditions = [dict(name=c.weather_param, expression=c.operator, amount=c.amount) for c in conditions]\n\n        assert area is not None\n        if len(area) == 0:\n            raise ValueError('The area for a trigger must contain at least one geoJSON type: you provided none')\n        the_area = [a.as_dict() for a in area]\n\n        # >>> for the moment, no specific handling for alert channels\n\n        status, payload = self.http_client.post(\n            TRIGGERS_URI,\n            params={'appid': self.API_key},\n            data=dict(time_period=the_time_period, conditions=the_conditions, area=the_area),\n            headers={'Content-Type': 'application/json'})\n        return self.trigger_parser.parse_dict(payload)", "response": "Creates a new trigger on the Alert API with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving all of the user s triggers that are set on the Weather Alert API.", "response": "def get_triggers(self):\n        \"\"\"\n        Retrieves all of the user's triggers that are set on the Weather Alert API.\n\n        :returns: list of `pyowm.alertapi30.trigger.Trigger` objects\n\n        \"\"\"\n        status, data = self.http_client.get_json(\n            TRIGGERS_URI,\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})\n        return [self.trigger_parser.parse_dict(item) for item in data]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_trigger(self, trigger_id):\n        assert isinstance(trigger_id, str), \"Value must be a string\"\n        status, data = self.http_client.get_json(\n            NAMED_TRIGGER_URI % trigger_id,\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})\n        return self.trigger_parser.parse_dict(data)", "response": "Retrieves the named trigger from the Weather Alert API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the local record with the data from the specified trigger object.", "response": "def update_trigger(self, trigger):\n        \"\"\"\n        Updates on the Alert API the trigger record having the ID of the specified Trigger object: the remote record is\n        updated with data from the local Trigger object.\n\n        :param trigger: the Trigger with updated data\n        :type trigger: `pyowm.alertapi30.trigger.Trigger`\n        :return: ``None`` if update is successful, an error otherwise\n        \"\"\"\n        assert trigger is not None\n        assert isinstance(trigger.id, str), \"Value must be a string\"\n        the_time_period = {\n            \"start\": {\n                \"expression\": \"after\",\n                \"amount\": trigger.start_after_millis\n            },\n            \"end\": {\n                \"expression\": \"after\",\n                \"amount\": trigger.end_after_millis\n            }\n        }\n        the_conditions = [dict(name=c.weather_param, expression=c.operator, amount=c.amount) for c in trigger.conditions]\n        the_area = [a.as_dict() for a in trigger.area]\n\n        status, _ = self.http_client.put(\n            NAMED_TRIGGER_URI % trigger.id,\n            params={'appid': self.API_key},\n            data=dict(time_period=the_time_period, conditions=the_conditions, area=the_area),\n            headers={'Content-Type': 'application/json'})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_trigger(self, trigger):\n        assert trigger is not None\n        assert isinstance(trigger.id, str), \"Value must be a string\"\n        status, _ = self.http_client.delete(\n            NAMED_TRIGGER_URI % trigger.id,\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})", "response": "Deletes the provided alert record identified by the ID of the provided trigger and along with all related alerts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_alerts_for(self, trigger):\n        assert trigger is not None\n        assert isinstance(trigger.id, str), \"Value must be a string\"\n        status, data = self.http_client.get_json(\n            ALERTS_URI % trigger.id,\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})\n        return [self.alert_parser.parse_dict(item) for item in data]", "response": "Retrieves all of the alerts that were fired for the specified trigger."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the alert record for the specified ID and belongs to the specified trigger.", "response": "def get_alert(self, alert_id, trigger):\n        \"\"\"\n        Retrieves info about the alert record on the Alert API that has the specified ID and belongs to the specified\n        parent Trigger object\n        :param trigger: the parent trigger\n        :type trigger: `pyowm.alertapi30.trigger.Trigger`\n        :param alert_id: the ID of the alert\n        :type alert_id `pyowm.alertapi30.alert.Alert`\n        :return: an `pyowm.alertapi30.alert.Alert` instance\n        \"\"\"\n        assert trigger is not None\n        assert alert_id is not None\n        assert isinstance(alert_id, str), \"Value must be a string\"\n        assert isinstance(trigger.id, str), \"Value must be a string\"\n        status, data = self.http_client.get_json(\n            NAMED_ALERT_URI % (trigger.id, alert_id),\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})\n        return self.alert_parser.parse_dict(data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete all of the alerts that were fired for the specified trigger.", "response": "def delete_all_alerts_for(self, trigger):\n        \"\"\"\n        Deletes all of the alert that were fired for the specified Trigger\n        :param trigger: the trigger whose alerts are to be cleared\n        :type trigger: `pyowm.alertapi30.trigger.Trigger`\n        :return: `None` if deletion is successful, an exception otherwise\n        \"\"\"\n        assert trigger is not None\n        assert isinstance(trigger.id, str), \"Value must be a string\"\n        status, _ = self.http_client.delete(\n            ALERTS_URI % trigger.id,\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_alert(self, alert):\n        assert alert is not None\n        assert isinstance(alert.id, str), \"Value must be a string\"\n        assert isinstance(alert.trigger_id, str), \"Value must be a string\"\n        status, _ = self.http_client.delete(\n            NAMED_ALERT_URI % (alert.trigger_id, alert.id),\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})", "response": "Delete the specified alert from the Alert API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_JSON(self, JSON_string):\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        try:\n            # -- reference time\n            reference_time = d['date']\n\n            # -- reception time (now)\n            reception_time = timeutils.now('unix')\n\n            # -- location\n            lon = float(d['lon'])\n            lat = float(d['lat'])\n            place = location.Location(None, lon, lat, None)\n\n            # -- UV intensity\n            uv_intensity = float(d['value'])\n\n        except KeyError:\n            raise parse_response_error.ParseResponseError(\n                      ''.join([__name__, ': impossible to parse UV Index']))\n\n        return uvindex.UVIndex(reference_time, place, uv_intensity,\n                               reception_time)", "response": "Parses a raw JSON string containing UV index information."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a list of UVIndex instances out of a raw JSON string.", "response": "def parse_JSON(self, JSON_string):\n        \"\"\"\n        Parses a list of *UVIndex* instances out of raw JSON data. Only certain\n        properties of the data are used: if these properties are not found or\n        cannot be parsed, an error is issued.\n\n        :param JSON_string: a raw JSON string\n        :type JSON_string: str\n        :returns: a list of *UVIndex* instances or an empty list if no data is\n            available\n        :raises: *ParseResponseError* if it is impossible to find or parse the\n            data needed to build the result, *APIResponseError* if the JSON\n            string embeds an HTTP status error\n\n        \"\"\"\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        uvindex_parser = UVIndexParser()\n        return [uvindex_parser.parse_JSON(json.dumps(item)) for item in d]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve all of the user s stations registered on the Stations API.", "response": "def get_stations(self):\n        \"\"\"\n        Retrieves all of the user's stations registered on the Stations API.\n\n        :returns: list of *pyowm.stationsapi30.station.Station* objects\n\n        \"\"\"\n\n        status, data = self.http_client.get_json(\n            STATIONS_URI,\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})\n        return [self.stations_parser.parse_dict(item) for item in data]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_station(self, id):\n        status, data = self.http_client.get_json(\n            NAMED_STATION_URI % str(id),\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})\n        return self.stations_parser.parse_dict(data)", "response": "Retrieves a named station from the Stations API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_station(self, external_id, name, lat, lon, alt=None):\n        assert external_id is not None\n        assert name is not None\n        assert lon is not None\n        assert lat is not None\n        if lon < -180.0 or lon > 180.0:\n            raise ValueError(\"'lon' value must be between -180 and 180\")\n        if lat < -90.0 or lat > 90.0:\n            raise ValueError(\"'lat' value must be between -90 and 90\")\n        if alt is not None:\n            if alt < 0.0:\n                raise ValueError(\"'alt' value must not be negative\")\n        status, payload = self.http_client.post(\n            STATIONS_URI,\n            params={'appid': self.API_key},\n            data=dict(external_id=external_id, name=name, lat=lat,\n                      lon=lon, alt=alt),\n            headers={'Content-Type': 'application/json'})\n        return self.stations_parser.parse_dict(payload)", "response": "Create a new station on the Station API with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_station(self, station):\n        assert station.id is not None\n        status, _ = self.http_client.put(\n            NAMED_STATION_URI % str(station.id),\n            params={'appid': self.API_key},\n            data=dict(external_id=station.external_id, name=station.name,\n                      lat=station.lat, lon=station.lon, alt=station.alt),\n            headers={'Content-Type': 'application/json'})", "response": "Updates the Station API record identified by the ID of the provided station object with all of its fields\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_station(self, station):\n        assert station.id is not None\n        status, _ = self.http_client.delete(\n            NAMED_STATION_URI % str(station.id),\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})", "response": "Deletes the provided station and all related measurements of the provided station."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_measurement(self, measurement):\n        assert measurement is not None\n        assert measurement.station_id is not None\n        status, _ = self.http_client.post(\n            MEASUREMENTS_URI,\n            params={'appid': self.API_key},\n            data=[self._structure_dict(measurement)],\n            headers={'Content-Type': 'application/json'})", "response": "Posts the provided Measurement object s data to the Station API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_measurements(self, list_of_measurements):\n        assert list_of_measurements is not None\n        assert all([m.station_id is not None for m in list_of_measurements])\n        msmts = [self._structure_dict(m) for m in list_of_measurements]\n        status, _ = self.http_client.post(\n            MEASUREMENTS_URI,\n            params={'appid': self.API_key},\n            data=msmts,\n            headers={'Content-Type': 'application/json'})", "response": "Sends the list of Measurement objects to the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_measurements(self, station_id, aggregated_on, from_timestamp,\n                         to_timestamp, limit=100):\n        \"\"\"\n        Reads measurements of a specified station recorded in the specified time\n        window and aggregated on minute, hour or day. Optionally, the number of\n        resulting measurements can be limited.\n\n        :param station_id: unique station identifier\n        :type station_id: str\n        :param aggregated_on: aggregation time-frame for this measurement\n        :type aggregated_on: string between 'm','h' and 'd'\n        :param from_timestamp: Unix timestamp corresponding to the beginning of\n          the time window\n        :type from_timestamp: int\n        :param to_timestamp: Unix timestamp corresponding to the end of the\n          time window\n        :type to_timestamp: int\n        :param limit: max number of items to be returned. Defaults to 100\n        :type limit: int\n        :returns: list of *pyowm.stationsapi30.measurement.AggregatedMeasurement*\n          objects\n        \"\"\"\n        assert station_id is not None\n        assert aggregated_on is not None\n        assert from_timestamp is not None\n        assert from_timestamp > 0\n        assert to_timestamp is not None\n        assert to_timestamp > 0\n        if to_timestamp < from_timestamp:\n            raise ValueError(\"End timestamp can't be earlier than begin timestamp\")\n        assert isinstance(limit, int)\n        assert limit >= 0\n        query = {'appid': self.API_key,\n                 'station_id': station_id,\n                 'type': aggregated_on,\n                 'from': from_timestamp,\n                 'to': to_timestamp,\n                 'limit': limit}\n        status, data = self.http_client.get_json(\n            MEASUREMENTS_URI,\n            params=query,\n            headers={'Content-Type': 'application/json'})\n        return [self.aggregated_measurements_parser.parse_dict(item) for item in data]", "response": "Reads measurements of a specified station in the specified time - frame window and aggregated on minute or day."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending the Measurement objects contained in the provided Buffer instance to the Stations API.", "response": "def send_buffer(self, buffer):\n        \"\"\"\n        Posts to the Stations API data about the Measurement objects contained\n        into the provided Buffer instance.\n\n        :param buffer: the *pyowm.stationsapi30.buffer.Buffer* instance whose\n          measurements are to be posted\n        :type buffer: *pyowm.stationsapi30.buffer.Buffer* instance\n        :returns: `None` if creation is successful, an exception otherwise\n        \"\"\"\n        assert buffer is not None\n        msmts = [self._structure_dict(m) for m in buffer.measurements]\n        status, _ = self.http_client.post(\n            MEASUREMENTS_URI,\n            params={'appid': self.API_key},\n            data=msmts,\n            headers={'Content-Type': 'application/json'})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping dict data to an xml. etree. Element object and attaches it to the specified parent node.", "response": "def create_DOM_node_from_dict(d, name, parent_node):\n    \"\"\"\n    Dumps dict data to an ``xml.etree.ElementTree.SubElement`` DOM subtree\n    object and attaches it to the specified DOM parent node. The created\n    subtree object is named after the specified name. If the supplied dict is\n    ``None`` no DOM node is created for it as well as no DOM subnodes are\n    generated  for eventual ``None`` values found inside the dict\n\n    :param d: the input dictionary\n    :type d: dict\n    :param name: the name for the DOM subtree to be created\n    :type name: str\n    :param parent_node: the parent DOM node the newly created subtree must be\n        attached to\n    :type parent_node: ``xml.etree.ElementTree.Element`` or derivative objects\n    :returns: ``xml.etree.ElementTree.SubElementTree`` object\n\n    \"\"\"\n    if d is not None:\n        root_dict_node = ET.SubElement(parent_node, name)\n        for key, value in d.items():\n            if value is not None:\n                node = ET.SubElement(root_dict_node, key)\n                node.text = str(value)\n        return root_dict_node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DOM_node_to_XML(tree, xml_declaration=True):\n    result = ET.tostring(tree, encoding='utf8', method='xml').decode('utf-8')\n    if not xml_declaration:\n        result = result.split(\"<?xml version='1.0' encoding='utf8'?>\\n\")[1]\n    return result", "response": "Print a DOM tree to its Unicode representation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nannotates the provided DOM tree with XMLNS attributes and adds XMLNSPREFIX to the tags of the tree nodes.", "response": "def annotate_with_XMLNS(tree, prefix, URI):\n    \"\"\"\n    Annotates the provided DOM tree with XMLNS attributes and adds XMLNS\n    prefixes to the tags of the tree nodes.\n\n    :param tree: the input DOM tree\n    :type tree: an ``xml.etree.ElementTree.ElementTree`` or\n        ``xml.etree.ElementTree.Element`` object\n    :param prefix: XMLNS prefix for tree nodes' tags\n    :type prefix: str\n    :param URI: the URI for the XMLNS definition file\n    :type URI: str\n\n    \"\"\"\n    if not ET.iselement(tree):\n        tree = tree.getroot()\n    tree.attrib['xmlns:' + prefix] = URI\n    iterator = tree.iter()\n    next(iterator)  # Don't add XMLNS prefix to the root node\n    for e in iterator:\n        e.tag = prefix + \":\" + e.tag"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the search results having the specified image type", "response": "def with_img_type(self, image_type):\n        \"\"\"\n        Returns the search results having the specified image type\n\n        :param image_type: the desired image type (valid values are provided by the\n            `pyowm.commons.enums.ImageTypeEnum` enum)\n        :type image_type: `pyowm.commons.databoxes.ImageType` instance\n        :returns: a list of `pyowm.agroapi10.imagery.MetaImage` instances\n\n        \"\"\"\n        assert isinstance(image_type, ImageType)\n        return list(filter(lambda x: x.image_type == image_type, self.metaimages))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef with_preset(self, preset):\n        assert isinstance(preset, str)\n        return list(filter(lambda x: x.preset == preset, self.metaimages))", "response": "Returns the seach results having the specified preset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef with_img_type_and_preset(self, image_type, preset):\n        assert isinstance(image_type, ImageType)\n        assert isinstance(preset, str)\n        return list(filter(lambda x: x.image_type == image_type and x.preset == preset, self.metaimages))", "response": "Returns the search results having both the specified image type and preset"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef status_for(self, code):\n        is_in = lambda start, end, n: True if start <= n <= end else False\n        for status in self._code_ranges_dict:\n            for _range in self._code_ranges_dict[status]:\n                if is_in(_range['start'],_range['end'],code):\n                    return status\n        return None", "response": "Returns the status string for the specified weather status code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a raw JSON string containing the object representation of an aggregated measurement.", "response": "def parse_JSON(self, JSON_string):\n        \"\"\"\n        Parses a *pyowm.stationsapi30.measurement.AggregatedMeasurement*\n        instance out of raw JSON data.\n\n        :param JSON_string: a raw JSON string\n        :type JSON_string: str\n        :return: a *pyowm.stationsapi30.measurement.AggregatedMeasurement*\n          instance or ``None`` if no data is available\n        :raises: *ParseResponseError* if it is impossible to find or parse the\n            data needed to build the result\n\n        \"\"\"\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        station_id = d.get('station_id', None)\n        ts = d.get('date', None)\n        if ts is not None:\n            ts = int(ts)\n        aggregated_on = d.get('type', None)\n        temp = d.get('temp', dict())\n        humidity = d.get('humidity', dict())\n        wind = d.get('wind', dict())\n        pressure = d.get('pressure', dict())\n        precipitation = d.get('precipitation', dict())\n        return AggregatedMeasurement(station_id, ts, aggregated_on, temp=temp,\n            humidity=humidity, wind=wind,\n            pressure=pressure, precipitation=precipitation)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef creation_time(self, timeformat='unix'):\n        if self.timestamp is None:\n            return None\n        return timeformatutils.timeformat(self.timestamp, timeformat)", "response": "Returns the UTC time of creation of this aggregated measurement\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_dict(self):\n        return {'station_id': self.station_id,\n                'timestamp': self.timestamp,\n                'aggregated_on': self.aggregated_on,\n                'temp': self.temp,\n                'humidity': self.humidity,\n                'wind': self.wind,\n                'pressure': self.pressure,\n                'precipitation': self.precipitation}", "response": "Dumps the object fields into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self):\n        return {\n            'station_id': self.station_id,\n            'timestamp': self.timestamp,\n            'temperature': self.temperature,\n            'wind_speed': self.wind_speed,\n            'wind_gust': self.wind_gust,\n            'wind_deg': self.wind_deg,\n            'pressure': self.pressure,\n            'humidity': self.humidity,\n            'rain_1h': self.rain_1h,\n            'rain_6h': self.rain_6h,\n            'rain_24h': self.rain_24h,\n            'snow_1h': self.snow_1h,\n            'snow_6h': self.snow_6h,\n            'snow_24h': self.snow_24h,\n            'dew_point': self.dew_point,\n            'humidex': self.humidex,\n            'heat_index': self.heat_index,\n            'visibility_distance': self.visibility_distance,\n            'visibility_prefix': self.visibility_prefix,\n            'clouds_distance': self.clouds_distance,\n            'clouds_condition': self.clouds_condition,\n            'clouds_cumulus': self.clouds_cumulus,\n            'weather_precipitation': self.weather_precipitation,\n            'weather_descriptor': self.weather_descriptor,\n            'weather_intensity': self.weather_intensity,\n            'weather_proximity': self.weather_proximity,\n            'weather_obscuration': self.weather_obscuration,\n            'weather_other': self.weather_other}", "response": "Dumps object fields into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a Location object out of a dictionary containing the properties of the notange system and the geographical coordinates of the current system.", "response": "def location_from_dictionary(d):\n    \"\"\"\n    Builds a *Location* object out of a data dictionary. Only certain\n    properties of the dictionary are used: if these properties are not\n    found or cannot be read, an error is issued.\n\n    :param d: a data dictionary\n    :type d: dict\n    :returns: a *Location* instance\n    :raises: *KeyError* if it is impossible to find or read the data\n        needed to build the instance\n\n    \"\"\"\n    country = None\n    if 'sys' in d and 'country' in d['sys']:\n        country = d['sys']['country']\n    if 'city' in d:\n        data = d['city']\n    else:\n        data = d\n    if 'name' in data:\n        name = data['name']\n    else:\n        name = None\n    if 'id' in data:\n        ID = int(data['id'])\n    else:\n        ID = None\n    if 'coord' in data:\n        lon = data['coord'].get('lon', 0.0)\n        lat = data['coord'].get('lat', 0.0)\n    elif 'coord' in data['station']:\n        if 'lon' in data['station']['coord']:\n            lon = data['station']['coord'].get('lon', 0.0)\n        elif 'lng' in data['station']['coord']:\n            lon = data['station']['coord'].get('lng', 0.0)\n        else:\n            lon = 0.0\n        lat = data['station']['coord'].get('lat', 0.0)\n    else:\n        raise KeyError(\"Impossible to read geographical coordinates from JSON\")\n    if 'country' in data:\n        country = data['country']\n    return Location(name, lon, lat, ID, country)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_geopoint(self):\n        if self._lon is None or self._lat is None:\n            return None\n        return geo.Point(self._lon, self._lat)", "response": "Returns the geoJSON compliant representation of this location"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping the object fields into a JSON formatted string", "response": "def to_JSON(self):\n        \"\"\"Dumps object fields into a JSON formatted string\n\n        :returns:  the JSON string\n\n        \"\"\"\n        return json.dumps({'name': self._name,\n                         'coordinates': {'lon': self._lon,\n                                         'lat': self._lat\n                                        },\n                         'ID': self._ID,\n                         'country': self._country})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_XML(self, xml_declaration=True, xmlns=True):\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         LOCATION_XMLNS_PREFIX,\n                                         LOCATION_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)", "response": "Dumps the object fields to an XML - formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping the object data to a fully traversable DOM representation of the object.", "response": "def _to_DOM(self):\n        \"\"\"\n        Dumps object data to a fully traversable DOM representation of the\n        object.\n\n        :returns: a ``xml.etree.Element`` object\n\n        \"\"\"\n        root_node = ET.Element(\"location\")\n        name_node = ET.SubElement(root_node, \"name\")\n        name_node.text = self._name\n        coords_node = ET.SubElement(root_node, \"coordinates\")\n        lon_node = ET.SubElement(coords_node, \"lon\")\n        lon_node.text = str(self._lon)\n        lat_node = ET.SubElement(coords_node, \"lat\")\n        lat_node.text = str(self._lat)\n        id_node = ET.SubElement(root_node, \"ID\")\n        id_node.text = str(self._ID)\n        country_node = ET.SubElement(root_node, \"country\")\n        country_node.text = self._country\n        return root_node"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a JSON string containing a station and returns a new instance of the class that is used to store the data in the object.", "response": "def parse_JSON(self, JSON_string):\n        \"\"\"\n        Parses a *Station* instance out of raw JSON data. Only certain\n        properties of the data are used: if these properties are not found or\n        cannot be parsed, an error is issued.\n\n        :param JSON_string: a raw JSON string\n        :type JSON_string: str\n        :returns: a *Station* instance or ``None`` if no data is available\n        :raises: *ParseResponseError* if it is impossible to find or parse the\n            data needed to build the result, *APIResponseError* if the JSON\n            string embeds an HTTP status error\n\n        \"\"\"\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        try:\n            name = d['station']['name']\n            station_ID = d['station']['id']\n            station_type = d['station']['type']\n            status = d['station']['status']\n            lat = d['station']['coord']['lat']\n            if 'lon' in d['station']['coord']:\n                lon = d['station']['coord']['lon']\n            elif 'lng' in d['station']['coord']:\n                lon = d['station']['coord']['lng']\n            else:\n                lon = None\n            if 'distance' in d:\n                distance = d['distance']\n            else:\n                distance = None\n        \n        except KeyError as e:\n            error_msg = ''.join((__name__, ': unable to read JSON data', ))\n            raise parse_response_error.ParseResponseError(error_msg)\n        else:\n            if 'last' in d:\n                last_weather = weather.weather_from_dictionary(d['last'])\n            else:\n                last_weather = None\n\n        return station.Station(name, station_ID, station_type, status, lat, lon,\n                               distance, last_weather)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, request_url):\n        try:\n            cached_item = self._table[request_url]\n            cur_time = timeutils.now('unix')\n            if cur_time - cached_item['insertion_time'] > self._item_lifetime:\n                # Cache item has expired\n                self._clean_item(request_url)\n                return None\n            cached_item['insertion_time'] = cur_time  # Update insertion time\n            self._promote(request_url)\n            return cached_item['data']\n        except:\n            return None", "response": "Returns the JSON string which represents the OWM web\n            API response to the request identified by the URL. If the request has not yet been identified by the URL None is returned."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value of the response_json in the cache.", "response": "def set(self, request_url, response_json):\n        \"\"\"\n        Checks if the maximum size of the cache has been reached and in case\n        discards the least recently used item from 'usage_recency' and 'table';\n        then adds the response_json to be cached to the 'table' dict using as\n        a lookup key the request_url of the request that generated the value;\n        finally adds it at the front of 'usage_recency'\n\n        :param request_url: the request URL that uniquely identifies the\n            request whose response is to be cached\n        :type request_url: str\n        :param response_json: the response JSON to be cached\n        :type response_json: str\n\n        \"\"\"\n        if self.size() == self._max_size:\n            popped = self._usage_recency.pop()\n            del self._table[popped]\n        current_time = timeutils.now('unix')\n        if request_url not in self._table:\n            self._table[request_url] = {'data': response_json,\n                                        'insertion_time': current_time}\n            self._usage_recency.add(request_url)\n        else:\n            self._table[request_url]['insertion_time'] = current_time\n            self._promote(request_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves the cache item specified by request_url to the front of the usage_recency list", "response": "def _promote(self, request_url):\n        \"\"\"\n        Moves the cache item specified by request_url to the front of the\n        'usage_recency' list\n        \"\"\"\n        self._usage_recency.remove(request_url)\n        self._usage_recency.add(request_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _clean_item(self, request_url):\n        del self._table[request_url]\n        self._usage_recency.remove(request_url)", "response": "Removes the specified item from the cache s datastructures\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef append(self, measurement):\n        assert isinstance(measurement, Measurement)\n        assert measurement.station_id == self.station_id\n        self.measurements.append(measurement)", "response": "Appends the specified Measurement object to the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_from_dict(self, the_dict):\n        m = Measurement.from_dict(the_dict)\n        self.append(m)", "response": "Creates a Measurement object from the supplied dict and appends it to the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new measurement object from the supplied JSON string and appends it to the buffer.", "response": "def append_from_json(self, json_string):\n        \"\"\"\n        Creates a ``measurement.Measurement`` object from the supplied JSON string\n        and then appends it to the buffer\n        :param json_string: the JSON formatted string\n\n        \"\"\"\n        a_dict = json.loads(json_string)\n        self.append_from_dict(a_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsorts the measurements of this buffer in reverse chronological order", "response": "def sort_reverse_chronologically(self):\n        \"\"\"\n        Sorts the measurements of this buffer in reverse chronological order\n\n        \"\"\"\n        self.measurements.sort(key=lambda m: m.timestamp, reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the soil surface temperature in the specified unit", "response": "def surface_temp(self, unit='kelvin'):\n        \"\"\"Returns the soil surface temperature\n\n        :param unit: the unit of measure for the temperature value. May be:\n            '*kelvin*' (default), '*celsius*' or '*fahrenheit*'\n        :type unit: str\n        :returns: a float\n        :raises: ValueError when unknown temperature units are provided\n\n        \"\"\"\n        if unit == 'kelvin':\n            return self._surface_temp\n        if unit == 'celsius':\n            return temputils.kelvin_to_celsius(self._surface_temp)\n        if unit == 'fahrenheit':\n            return temputils.kelvin_to_fahrenheit(self._surface_temp)\n        else:\n            raise ValueError('Wrong temperature unit')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ten_cm_temp(self, unit='kelvin'):\n        if unit == 'kelvin':\n            return self._ten_cm_temp\n        if unit == 'celsius':\n            return temputils.kelvin_to_celsius(self._ten_cm_temp)\n        if unit == 'fahrenheit':\n            return temputils.kelvin_to_fahrenheit(self._ten_cm_temp)\n        else:\n            raise ValueError('Wrong temperature unit')", "response": "Returns the soil temperature measured 10 cm below surface\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the given value is a feasible decimal latitude.", "response": "def assert_is_lat(val):\n    \"\"\"\n    Checks it the given value is a feasible decimal latitude\n\n    :param val: value to be checked\n    :type val: int of float\n    :returns:  `None`\n    :raises: *ValueError* if value is out of latitude boundaries, *AssertionError* if type is wrong\n\n    \"\"\"\n    assert type(val) is float or type(val) is int, \"Value must be a number\"\n    if val < -90.0 or val > 90.0:\n        raise ValueError(\"Latitude value must be between -90 and 90\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assert_is_lon(val):\n    assert type(val) is float or type(val) is int, \"Value must be a number\"\n    if val < -180.0 or val > 180.0:\n        raise ValueError(\"Longitude value must be between -180 and 180\")", "response": "Checks that the given value is a feasible decimal longitude."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bounding_square_polygon(self, inscribed_circle_radius_km=10.0):\n        assert isinstance(inscribed_circle_radius_km, int) or isinstance(inscribed_circle_radius_km, float)\n        assert inscribed_circle_radius_km > 0., 'Radius must be greater than zero'\n\n        # turn metric distance to radians on the approximated local sphere\n        rad_distance = float(inscribed_circle_radius_km) / EARTH_RADIUS_KM\n\n        # calculating min/max lat for bounding box\n        bb_min_lat_deg = self.lat * math.pi/180. - rad_distance\n        bb_max_lat_deg = self.lat * math.pi/180. + rad_distance\n\n        # now checking for poles...\n        if bb_min_lat_deg > math.radians(-90) and bb_max_lat_deg < math.radians(90):  # no poles in the bounding box\n            delta_lon = math.asin(math.sin(rad_distance) / math.cos(math.radians(self.lat)))\n\n            bb_min_lon_deg = math.radians(self.lon) - delta_lon\n            if bb_min_lon_deg < math.radians(-180):\n                bb_min_lon_deg += 2 * math.pi\n\n            bb_max_lon_deg = math.radians(self.lon) + delta_lon\n            if bb_max_lon_deg > math.radians(180):\n                bb_max_lon_deg -= 2 * math.pi\n        else:   # a pole is contained in the bounding box\n            bb_min_lat_deg = max(bb_min_lat_deg, math.radians(-90))\n            bb_max_lat_deg = min(bb_max_lat_deg, math.radians(90))\n            bb_min_lon_deg = math.radians(-180)\n            bb_max_lon_deg = math.radians(180)\n\n        # turn back from radians to decimal\n        bb_min_lat = bb_min_lat_deg * 180./math.pi\n        bb_max_lat = bb_max_lat_deg * 180./math.pi\n        bb_min_lon = bb_min_lon_deg * 180./math.pi\n        bb_max_lon = bb_max_lon_deg * 180./math.pi\n\n        return Polygon([[\n            [bb_min_lon, bb_max_lat],\n            [bb_max_lon, bb_max_lat],\n            [bb_max_lon, bb_min_lat],\n            [bb_min_lon, bb_min_lat],\n            [bb_min_lon, bb_max_lat]\n        ]])", "response": "Returns a square polygon that circumscribes the circle with this geopoint and the specified radius in kilometers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a MultiPoint from an iterable of pyowm. utils. geo. Point objects.", "response": "def from_points(cls, iterable_of_points):\n        \"\"\"\n        Creates a MultiPoint from an iterable collection of `pyowm.utils.geo.Point` instances\n        :param iterable_of_points: iterable whose items are `pyowm.utils.geo.Point` instances\n        :type iterable_of_points: iterable\n        :return: a *MultiPoint* instance\n        \"\"\"\n        return MultiPoint([(p.lon, p.lat) for p in iterable_of_points])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef points(self):\n        feature = geojson.Feature(geometry=self._geom)\n        points_coords = list(geojson.utils.coords(feature))\n        return [Point(p[0], p[1]) for p in points_coords]", "response": "Returns the list of Point instances representing the points of the polygon"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_points(cls, list_of_lists):\n        result = []\n        for l in list_of_lists:\n            curve = []\n            for point in l:\n                curve.append((point.lon, point.lat))\n            result.append(curve)\n        return Polygon(result)", "response": "Creates a Polygon instance out of a list of lists each sublist being populated with\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_dict(self, the_dict):\n        geom = geojson.loads(json.dumps(the_dict))\n        result = MultiPolygon([\n            [[[0, 0], [0, 0]]],\n            [[[1, 1], [1, 1]]]\n        ])\n        result._geom = geom\n        return result", "response": "Builds a MultiPolygon instance out of a geoJSON compliant dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build(cls, the_dict):\n        assert isinstance(the_dict, dict), 'Geometry must be a dict'\n        geom_type = the_dict.get('type', None)\n        if geom_type == 'Point':\n            return Point.from_dict(the_dict)\n        elif geom_type == 'MultiPoint':\n            return MultiPoint.from_dict(the_dict)\n        elif geom_type == 'Polygon':\n            return Polygon.from_dict(the_dict)\n        elif geom_type == 'MultiPolygon':\n            return MultiPolygon.from_dict(the_dict)\n        else:\n            raise ValueError('Unable to build a GeoType object: unrecognized geometry type')", "response": "Builds a GeoType object based on the geoJSON compliant dict containing the geometry type and the dictionary containing the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a raw JSON string into a list of *Observation* instances.", "response": "def parse_JSON(self, JSON_string):\n        \"\"\"\n        Parses a list of *Observation* instances out of raw JSON data. Only\n        certain properties of the data are used: if these properties are not\n        found or cannot be parsed, an error is issued.\n\n        :param JSON_string: a raw JSON string\n        :type JSON_string: str\n        :returns: a list of *Observation* instances or ``None`` if no data is\n            available\n        :raises: *ParseResponseError* if it is impossible to find or parse the\n            data needed to build the result, *APIResponseError* if the OWM API\n            returns a HTTP status error\n\n        \"\"\"\n        if JSON_string is None:\n            raise ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        observation_parser = ObservationParser()\n        if 'cod' in d:\n            # Check if server returned errors: this check overcomes the lack of use\n            # of HTTP error status codes by the OWM API 2.5. This mechanism is\n            # supposed to be deprecated as soon as the API fully adopts HTTP for\n            # conveying errors to the clients\n            if d['cod'] == \"200\" or d['cod'] == 200:\n                pass\n            else:\n                if d['cod'] == \"404\" or d['cod'] == 404:\n                    print(\"OWM API: data not found - response payload: \" + json.dumps(d))\n                    return None\n                else:\n                    raise APIResponseError(\"OWM API: error - response payload: \" + json.dumps(d), str(d['cod']))\n\n        # Handle the case when no results are found\n        if 'count' in d and d['count'] == \"0\":\n            return []\n        if 'cnt' in d and d['cnt'] == 0:\n            return []\n        if 'list' in d:\n            return [observation_parser.parse_JSON(json.dumps(item)) \\\n                    for item in d['list']]\n\n        # no way out..\n        raise ParseResponseError(''.join([__name__,\n                                ': impossible to read JSON data']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps the object fields to an XML - formatted string.", "response": "def to_XML(self, xml_declaration=True, xmlns=True):\n        \"\"\"\n        Dumps object fields to an XML-formatted string. The 'xml_declaration'\n        switch  enables printing of a leading standard XML line containing XML\n        version and encoding. The 'xmlns' switch enables printing of qualified\n        XMLNS prefixes.\n\n        :param XML_declaration: if ``True`` (default) prints a leading XML\n            declaration line\n        :type XML_declaration: bool\n        :param xmlns: if ``True`` (default) prints full XMLNS prefixes\n        :type xmlns: bool\n        :returns: an XML-formatted string\n\n        \"\"\"\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         OZONE_XMLNS_PREFIX,\n                                         OZONE_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _to_DOM(self):\n        root_node = ET.Element(\"ozone\")\n        reference_time_node = ET.SubElement(root_node, \"reference_time\")\n        reference_time_node.text = str(self._reference_time)\n        reception_time_node = ET.SubElement(root_node, \"reception_time\")\n        reception_time_node.text = str(self._reception_time)\n        interval_node = ET.SubElement(root_node, \"interval\")\n        interval_node.text = str(self._interval)\n        value_node = ET.SubElement(root_node, \"value\")\n        value_node.text = str(self.du_value)\n        root_node.append(self._location._to_DOM())\n        return root_node", "response": "Dumps the object data to a fully traversable DOM representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_JSON(self, JSON_string):\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        try:\n            # -- reference time (strip away Z and T on ISO8601 format)\n            t = d['time'].replace('Z', '+00').replace('T', ' ')\n            reference_time = timeformatutils._ISO8601_to_UNIXtime(t)\n\n            # -- reception time (now)\n            reception_time = timeutils.now('unix')\n\n            # -- location\n            lon = float(d['location']['longitude'])\n            lat = float(d['location']['latitude'])\n            place = location.Location(None, lon, lat, None)\n\n            # -- CO samples\n            co_samples = d['data']\n\n        except KeyError:\n            raise parse_response_error.ParseResponseError(\n                      ''.join([__name__, ': impossible to parse COIndex']))\n\n        return coindex.COIndex(reference_time, place, None, co_samples,\n                               reception_time)", "response": "Parses a JSON string containing a COIndex instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_JSON(self, JSON_string):\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        try:\n            # -- reference time (strip away Z and T on ISO8601 format)\n            t = d['time'].replace('Z', '+00').replace('T', ' ')\n            reference_time = timeformatutils._ISO8601_to_UNIXtime(t)\n\n            # -- reception time (now)\n            reception_time = timeutils.now('unix')\n\n            # -- location\n            lon = float(d['location']['longitude'])\n            lat = float(d['location']['latitude'])\n            place = location.Location(None, lon, lat, None)\n\n            # -- CO samples\n            no2_samples = [dict(label=key,\n                                precision=d['data'][key]['precision'],\n                                value=d['data'][key]['value']) for key in d['data']]\n\n        except KeyError:\n            raise parse_response_error.ParseResponseError(\n                      ''.join([__name__, ': impossible to parse NO2Index']))\n\n        return no2index.NO2Index(reference_time, place, None, no2_samples,\n                                 reception_time)", "response": "Parses a JSON string containing NO2Index data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a raw JSON string containing the ozone information.", "response": "def parse_JSON(self, JSON_string):\n        \"\"\"\n        Parses an *Ozone* instance out of raw JSON data. Only certain\n        properties of the data are used: if these properties are not found or\n        cannot be parsed, an error is issued.\n\n        :param JSON_string: a raw JSON string\n        :type JSON_string: str\n        :returns: an *Ozone* instance or ``None`` if no data is available\n        :raises: *ParseResponseError* if it is impossible to find or parse the\n            data needed to build the result, *APIResponseError* if the JSON\n            string embeds an HTTP status error\n\n        \"\"\"\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        try:\n            # -- reference time (strip away Z and T on ISO8601 format)\n            ref_t = d['time'].replace('Z', '+00').replace('T', ' ')\n            reference_time = timeformatutils._ISO8601_to_UNIXtime(ref_t)\n\n            # -- reception time (now)\n            reception_time = timeutils.now('unix')\n\n            # -- location\n            lon = float(d['location']['longitude'])\n            lat = float(d['location']['latitude'])\n            place = location.Location(None, lon, lat, None)\n\n            # -- ozone Dobson Units value\n            du = d['data']\n            if du is not None:\n                du_value = float(du)\n            else:\n                raise ValueError('No information about Ozon Dobson Units')\n\n        except KeyError:\n            raise parse_response_error.ParseResponseError(\n                      ''.join([__name__, ': impossible to parse UV Index']))\n\n        return ozone.Ozone(reference_time, place, None, du_value, reception_time)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deprecated(will_be=None, on_version=None, name=None):\n    def outer_function(function):\n        if name is None:\n            _name = function.__name__\n        else:\n            _name = name\n        warning_msg = '\"%s\" is deprecated.' % _name\n        if will_be is not None and on_version is not None:\n            warning_msg += \" It will be %s on version %s\" % (\n                will_be,\n                '.'.join(map(str, on_version)))\n\n        @wraps(function)\n        def inner_function(*args, **kwargs):\n            warnings.warn(warning_msg,\n                          category=DeprecationWarning,\n                          stacklevel=2)\n            return function(*args, **kwargs)\n\n        return inner_function\n\n    return outer_function", "response": "A function decorator that warns about deprecation upon function invocation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_polygon(self, geopolygon, name=None):\n        assert geopolygon is not None\n        assert isinstance(geopolygon, GeoPolygon)\n        data = dict()\n        data['geo_json'] = {\n            \"type\": \"Feature\",\n            \"properties\": {},\n            \"geometry\": geopolygon.as_dict()\n        }\n        if name is not None:\n            data['name'] = name\n        status, payload = self.http_client.post(\n            POLYGONS_URI,\n            params={'appid': self.API_key},\n            data=data,\n            headers={'Content-Type': 'application/json'})\n        return Polygon.from_dict(payload)", "response": "Create a new polygon on the Agro API with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_polygons(self):\n\n        status, data = self.http_client.get_json(\n            POLYGONS_URI,\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})\n        return [Polygon.from_dict(item) for item in data]", "response": "Retrieves all of the user s polygons registered on the Agro API."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_polygon(self, polygon_id):\n        status, data = self.http_client.get_json(\n            NAMED_POLYGON_URI % str(polygon_id),\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})\n        return Polygon.from_dict(data)", "response": "Retrieves a named polygon from the Agro API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the mnemonic name of the provided polygon object.", "response": "def update_polygon(self, polygon):\n        \"\"\"\n        Updates on the Agro API the Polygon identified by the ID of the provided polygon object.\n        Currently this only changes the mnemonic name of the remote polygon\n\n        :param polygon: the `pyowm.agro10.polygon.Polygon` object to be updated\n        :type polygon: `pyowm.agro10.polygon.Polygon` instance\n        :returns: `None` if update is successful, an exception otherwise\n        \"\"\"\n        assert polygon.id is not None\n        status, _ = self.http_client.put(\n            NAMED_POLYGON_URI % str(polygon.id),\n            params={'appid': self.API_key},\n            data=dict(name=polygon.name),\n            headers={'Content-Type': 'application/json'})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_polygon(self, polygon):\n        assert polygon.id is not None\n        status, _ = self.http_client.delete(\n            NAMED_POLYGON_URI % str(polygon.id),\n            params={'appid': self.API_key},\n            headers={'Content-Type': 'application/json'})", "response": "Deletes the provided polygon object from the Agro API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef soil_data(self, polygon):\n        assert polygon is not None\n        assert isinstance(polygon, Polygon)\n        polyd = polygon.id\n        status, data = self.http_client.get_json(\n            SOIL_URI,\n            params={'appid': self.API_key,\n                    'polyid': polyd},\n            headers={'Content-Type': 'application/json'})\n        the_dict = dict()\n        the_dict['reference_time'] = data['dt']\n        the_dict['surface_temp'] = data['t0']\n        the_dict['ten_cm_temp'] = data['t10']\n        the_dict['moisture'] = data['moisture']\n        the_dict['polygon_id'] = polyd\n        return Soil.from_dict(the_dict)", "response": "Retrieves the latest soil data on the specified polygon"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_satellite_imagery(self, polygon_id, acquired_from, acquired_to, img_type=None, preset=None,\n                                 min_resolution=None, max_resolution=None, acquired_by=None, min_cloud_coverage=None,\n                                 max_cloud_coverage=None, min_valid_data_coverage=None, max_valid_data_coverage=None):\n        \"\"\"\n        Searches on the Agro API the metadata for all available satellite images that contain the specified polygon and\n        acquired during the specified time interval; and optionally matching the specified set of filters:\n        - image type (eg. GeoTIF)\n        - image preset (eg. false color, NDVI, ...)\n        - min/max acquisition resolution\n        - acquiring satellite\n        - min/max cloud coverage on acquired scene\n        - min/max valid data coverage on acquired scene\n\n        :param polygon_id: the ID of the reference polygon\n        :type polygon_id: str\n        :param acquired_from: lower edge of acquisition interval, UNIX timestamp\n        :type acquired_from: int\n        :param acquired_to: upper edge of acquisition interval, UNIX timestamp\n        :type acquired_to: int\n        :param img_type: the desired file format type of the images. Allowed values are given by `pyowm.commons.enums.ImageTypeEnum`\n        :type img_type: `pyowm.commons.databoxes.ImageType`\n        :param preset: the desired preset of the images. Allowed values are given by `pyowm.agroapi10.enums.PresetEnum`\n        :type preset: str\n        :param min_resolution: minimum resolution for images, px/meters\n        :type min_resolution: int\n        :param max_resolution: maximum resolution for images, px/meters\n        :type max_resolution: int\n        :param acquired_by: short symbol of the satellite that acquired the image (eg. \"l8\")\n        :type acquired_by: str\n        :param min_cloud_coverage: minimum cloud coverage percentage on acquired images\n        :type min_cloud_coverage: int\n        :param max_cloud_coverage: maximum cloud coverage percentage on acquired images\n        :type max_cloud_coverage: int\n        :param min_valid_data_coverage: minimum valid data coverage percentage on acquired images\n        :type min_valid_data_coverage: int\n        :param max_valid_data_coverage: maximum valid data coverage percentage on acquired images\n        :type max_valid_data_coverage: int\n        :return: a list of `pyowm.agro10.imagery.MetaImage` subtypes instances\n        \"\"\"\n        assert polygon_id is not None\n        assert acquired_from is not None\n        assert acquired_to is not None\n        assert acquired_from <= acquired_to, 'Start timestamp of acquisition window must come before its end'\n        if min_resolution is not None:\n            assert min_resolution > 0, 'Minimum resolution must be positive'\n        if max_resolution is not None:\n            assert max_resolution > 0, 'Maximum resolution must be positive'\n        if min_resolution is not None and max_resolution is not None:\n            assert min_resolution <= max_resolution, 'Mininum resolution must be lower than maximum resolution'\n        if min_cloud_coverage is not None:\n            assert min_cloud_coverage >= 0, 'Minimum cloud coverage must be non negative'\n        if max_cloud_coverage is not None:\n            assert max_cloud_coverage >= 0, 'Maximum cloud coverage must be non negative'\n        if min_cloud_coverage is not None and max_cloud_coverage is not None:\n            assert min_cloud_coverage <= max_cloud_coverage, 'Minimum cloud coverage must be lower than maximum cloud coverage'\n        if min_valid_data_coverage is not None:\n            assert min_valid_data_coverage >= 0, 'Minimum valid data coverage must be non negative'\n        if max_valid_data_coverage is not None:\n            assert max_valid_data_coverage >= 0, 'Maximum valid data coverage must be non negative'\n        if min_valid_data_coverage is not None and max_valid_data_coverage is not None:\n            assert min_valid_data_coverage <= max_valid_data_coverage, 'Minimum valid data coverage must be lower than maximum valid data coverage'\n\n        # prepare params\n        params = dict(appid=self.API_key, polyid=polygon_id, start=acquired_from, end=acquired_to)\n        if min_resolution is not None:\n            params['resolution_min'] = min_resolution\n        if max_resolution is not None:\n            params['resolution_max'] = max_resolution\n        if acquired_by is not None:\n            params['type'] = acquired_by\n        if min_cloud_coverage is not None:\n            params['clouds_min'] = min_cloud_coverage\n        if max_cloud_coverage is not None:\n            params['clouds_max'] = max_cloud_coverage\n        if min_valid_data_coverage is not None:\n            params['coverage_min'] = min_valid_data_coverage\n        if max_valid_data_coverage is not None:\n            params['coverage_max'] = max_valid_data_coverage\n\n        # call API\n        status, data = self.http_client.get_json(SATELLITE_IMAGERY_SEARCH_URI, params=params)\n\n        result_set = SatelliteImagerySearchResultSet(polygon_id, data, timeutils.now(timeformat='unix'))\n\n        # further filter by img_type and/or preset (if specified)\n        if img_type is not None and preset is not None:\n            return result_set.with_img_type_and_preset(img_type, preset)\n        elif img_type is not None:\n            return result_set.with_img_type(img_type)\n        elif preset is not None:\n            return result_set.with_preset(preset)\n        else:\n            return result_set.all()", "response": "Search the Agro API for available satellite images that contain the specified polygon and optionally matching the filters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_satellite_image(self, metaimage, x=None, y=None, zoom=None, palette=None):\n        if palette is not None:\n            assert isinstance(palette, str)\n            params = dict(paletteid=palette)\n        else:\n            palette = PaletteEnum.GREEN\n            params = dict()\n        # polygon PNG\n        if isinstance(metaimage, MetaPNGImage):\n            prepared_url = metaimage.url\n            status, data = self.http_client.get_png(\n                prepared_url, params=params)\n            img = Image(data, metaimage.image_type)\n            return SatelliteImage(metaimage, img, downloaded_on=timeutils.now(timeformat='unix'), palette=palette)\n        # GeoTIF\n        elif isinstance(metaimage, MetaGeoTiffImage):\n            prepared_url = metaimage.url\n            status, data = self.http_client.get_geotiff(\n                prepared_url, params=params)\n            img = Image(data, metaimage.image_type)\n            return SatelliteImage(metaimage, img, downloaded_on=timeutils.now(timeformat='unix'), palette=palette)\n        # tile PNG\n        elif isinstance(metaimage, MetaTile):\n            assert x is not None\n            assert y is not None\n            assert zoom is not None\n            prepared_url = self._fill_url(metaimage.url, x, y, zoom)\n            status, data = self.http_client.get_png(\n                prepared_url, params=params)\n            img = Image(data, metaimage.image_type)\n            tile = Tile(x, y, zoom, None, img)\n            return SatelliteImage(metaimage, tile, downloaded_on=timeutils.now(timeformat='unix'), palette=palette)\n        else:\n            raise ValueError(\"Cannot download: unsupported MetaImage subtype\")", "response": "Downloads the satellite image described by the provided metadata."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves statistics for the satellite image described by the provided metadata.", "response": "def stats_for_satellite_image(self, metaimage):\n        \"\"\"\n        Retrieves statistics for the satellite image described by the provided metadata.\n        This is currently only supported 'EVI' and 'NDVI' presets\n\n        :param metaimage: the satellite image's metadata, in the form of a `MetaImage` subtype instance\n        :type metaimage: a `pyowm.agroapi10.imagery.MetaImage` subtype\n        :return: dict\n        \"\"\"\n        if metaimage.preset != PresetEnum.EVI and metaimage.preset != PresetEnum.NDVI:\n            raise ValueError(\"Unsupported image preset: should be EVI or NDVI\")\n        if metaimage.stats_url is None:\n            raise ValueError(\"URL for image statistics is not defined\")\n        status, data = self.http_client.get_json(metaimage.stats_url, params={})\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps the object fields into a JSON formatted string", "response": "def to_JSON(self):\n        \"\"\"Dumps object fields into a JSON formatted string\n\n        :returns:  the JSON string\n\n        \"\"\"\n        return json.dumps({\"reference_time\": self._reference_time,\n                           \"location\": json.loads(self._location.to_JSON()),\n                           \"value\": self._value,\n                           \"reception_time\": self._reception_time,\n                           })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping the object fields to an XML - formatted string.", "response": "def to_XML(self, xml_declaration=True, xmlns=True):\n        \"\"\"\n        Dumps object fields to an XML-formatted string. The 'xml_declaration'\n        switch  enables printing of a leading standard XML line containing XML\n        version and encoding. The 'xmlns' switch enables printing of qualified\n        XMLNS prefixes.\n\n        :param XML_declaration: if ``True`` (default) prints a leading XML\n            declaration line\n        :type XML_declaration: bool\n        :param xmlns: if ``True`` (default) prints full XMLNS prefixes\n        :type xmlns: bool\n        :returns: an XML-formatted string\n\n        \"\"\"\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         UVINDEX_XMLNS_PREFIX,\n                                         UVINDEX_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _to_DOM(self):\n        root_node = ET.Element(\"uvindex\")\n        reference_time_node = ET.SubElement(root_node, \"reference_time\")\n        reference_time_node.text = str(self._reference_time)\n        reception_time_node = ET.SubElement(root_node, \"reception_time\")\n        reception_time_node.text = str(self._reception_time)\n        value_node = ET.SubElement(root_node, \"value\")\n        value_node.text = str(self._value)\n        root_node.append(self._location._to_DOM())\n        return root_node", "response": "Dumps the object data to a fully traversable DOM representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_API_online(self):\n        params = {'q': 'London,GB'}\n        uri = http_client.HttpClient.to_url(OBSERVATION_URL,\n                                            self._API_key,\n                                            self._subscription_type)\n        try:\n            _1, _2 = self._wapi.cacheable_get_json(uri, params=params)\n            return True\n        except api_call_error.APICallTimeoutError:\n            return False", "response": "Returns True if the OWM Weather API is currently online."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef weather_at_place(self, name):\n\n        assert isinstance(name, str), \"Value must be a string\"\n        encoded_name = name\n        params = {'q': encoded_name, 'lang': self._language}\n        uri = http_client.HttpClient.to_url(OBSERVATION_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['observation'].parse_JSON(json_data)", "response": "Queries the OWM Weather API for the currently observed weather at the specified toponym."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries the OWM Weather API for the currently observed weather at the specified geographic coordinates.", "response": "def weather_at_coords(self, lat, lon):\n        \"\"\"\n        Queries the OWM Weather API for the currently observed weather at the\n        specified geographic (eg: 51.503614, -0.107331).\n\n        :param lat: the location's latitude, must be between -90.0 and 90.0\n        :type lat: int/float\n        :param lon: the location's longitude, must be between -180.0 and 180.0\n        :type lon: int/float\n        :returns: an *Observation* instance or ``None`` if no weather data is\n            available\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed or *APICallException* when OWM Weather API can not be\n            reached\n        \"\"\"\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        params = {'lon': lon, 'lat': lat, 'lang': self._language}\n        uri = http_client.HttpClient.to_url(OBSERVATION_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['observation'].parse_JSON(json_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries the OWM Weather API for the currently observed weather at the specified zip code and country code.", "response": "def weather_at_zip_code(self, zipcode, country):\n        \"\"\"\n        Queries the OWM Weather API for the currently observed weather at the\n        specified zip code and country code (eg: 2037, au).\n        \n        :param zip: the location's zip or postcode\n        :type zip: string\n        :param country: the location's country code\n        :type country: string\n        :returns: an *Observation* instance or ``None`` if no weather data is\n            available\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed or *APICallException* when OWM Weather API can not be\n            reached\n        \"\"\"\n        assert isinstance(zipcode, str), \"Value must be a string\"\n        assert isinstance(country, str), \"Value must be a string\"\n        encoded_zip = zipcode\n        encoded_country = country\n        zip_param = encoded_zip + ',' + encoded_country\n        params = {'zip': zip_param, 'lang': self._language}\n        uri = http_client.HttpClient.to_url(OBSERVATION_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['observation'].parse_JSON(json_data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the OWM Weather API for the currently observed weather at the specified city ID.", "response": "def weather_at_id(self, id):\n        \"\"\"\n        Queries the OWM Weather API for the currently observed weather at the\n        specified city ID (eg: 5128581)\n\n        :param id: the location's city ID\n        :type id: int\n        :returns: an *Observation* instance or ``None`` if no weather data is\n            available\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed or *APICallException* when OWM Weather API can not be\n            reached\n        \"\"\"\n        assert type(id) is int, \"'id' must be an int\"\n        if id < 0:\n            raise ValueError(\"'id' value must be greater than 0\")\n        params = {'id': id, 'lang': self._language}\n        uri = http_client.HttpClient.to_url(OBSERVATION_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['observation'].parse_JSON(json_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef weather_at_ids(self, ids_list):\n        assert type(ids_list) is list, \"'ids_list' must be a list of integers\"\n        for id in ids_list:\n            assert type(id) is int, \"'ids_list' must be a list of integers\"\n            if id < 0:\n                raise ValueError(\"id values in 'ids_list' must be greater \"\n                                 \"than 0\")\n        params = {'id': ','.join(list(map(str, ids_list))), 'lang': self._language}\n        uri = http_client.HttpClient.to_url(GROUP_OBSERVATIONS_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['observation_list'].parse_JSON(json_data)", "response": "Queries the OWM Weather API for the currently observed weathers at the specified city IDs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the OWM Weather API for the currently observed weather at all the locations specified by pattern.", "response": "def weather_at_places(self, pattern, searchtype, limit=None):\n        \"\"\"\n        Queries the OWM Weather API for the currently observed weather in all the\n        locations whose name is matching the specified text search parameters.\n        A twofold search can be issued: *'accurate'* (exact matching) and\n        *'like'* (matches names that are similar to the supplied pattern).\n\n        :param pattern: the string pattern (not a regex) to be searched for the\n            toponym\n        :type pattern: str\n        :param searchtype: the search mode to be used, must be *'accurate'* for\n          an exact matching or *'like'* for a likelihood matching\n        :type: searchtype: str\n        :param limit: the maximum number of *Observation* items in the returned\n            list (default is ``None``, which stands for any number of items)\n        :param limit: int or ``None``\n        :returns: a list of *Observation* objects or ``None`` if no weather\n            data is available\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed, *APICallException* when OWM Weather API can not be\n            reached, *ValueError* when bad value is supplied for the search\n            type or the maximum number of items retrieved\n        \"\"\"\n        assert isinstance(pattern, str), \"'pattern' must be a str\"\n        assert isinstance(searchtype, str), \"'searchtype' must be a str\"\n        if searchtype != \"accurate\" and searchtype != \"like\":\n            raise ValueError(\"'searchtype' value must be 'accurate' or 'like'\")\n        if limit is not None:\n            assert isinstance(limit, int), \"'limit' must be an int or None\"\n            if limit < 1:\n                raise ValueError(\"'limit' must be None or greater than zero\")\n        params = {'q': pattern, 'type': searchtype, 'lang': self._language}\n        if limit is not None:\n            # fix for OWM 2.5 API bug!\n            params['cnt'] = limit - 1\n        uri = http_client.HttpClient.to_url(FIND_OBSERVATIONS_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['observation_list'].parse_JSON(json_data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef weather_at_station(self, station_id):\n        assert type(station_id) is int, \"'station_id' must be an int\"\n        if station_id < 0:\n            raise ValueError(\"'station_id' value must be greater than 0\")\n        params = {'id': station_id, 'lang': self._language}\n        uri = http_client.HttpClient.to_url(STATION_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['observation'].parse_JSON(json_data)", "response": "Queries the OWM Weather API for the weather currently observed by a specific meteostation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries the OWM Weather API for the weather currently observed by the given meteostations within the bounding box.", "response": "def weather_at_stations_in_bbox(self, lat_top_left, lon_top_left,\n                                    lat_bottom_right, lon_bottom_right,\n                                    cluster=False, limit=None):\n        \"\"\"\n        Queries the OWM Weather API for the weather currently observed by\n        meteostations inside the bounding box of latitude/longitude coords.\n\n        :param lat_top_left: latitude for top-left of bounding box, must be\n            between -90.0 and 90.0\n        :type lat_top_left: int/float\n        :param lon_top_left: longitude for top-left of bounding box\n            must be between -180.0 and 180.0\n        :type lon_top_left: int/float\n        :param lat_bottom_right: latitude for bottom-right of bounding box, must\n            be between -90.0 and 90.0\n        :type lat_bottom_right: int/float\n        :param lon_bottom_right: longitude for bottom-right of bounding box,\n            must be between -180.0 and 180.0\n        :type lon_bottom_right: int/float\n        :param cluster: use server clustering of points\n        :type cluster: bool\n        :param limit: the maximum number of *Observation* items in the returned\n            list (default is ``None``, which stands for any number of items)\n        :param limit: int or ``None``\n        :returns: a list of *Observation* objects or ``None`` if no weather\n            data is available\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed, *APICallException* when OWM Weather API can not be\n            reached, *ValueError* when coordinates values are out of bounds or\n            negative values are provided for limit\n        \"\"\"\n        assert type(cluster) is bool, \"'cluster' must be a bool\"\n        assert type(limit) in (int, type(None)), \\\n                \"'limit' must be an int or None\"\n        geo.assert_is_lon(lon_top_left)\n        geo.assert_is_lon(lon_bottom_right)\n        geo.assert_is_lat(lat_top_left)\n        geo.assert_is_lat(lat_bottom_right)\n        if limit is not None and limit < 1:\n            raise ValueError(\"'limit' must be None or greater than zero\")\n        params = {'bbox': ','.join([str(lon_top_left),\n                                    str(lat_top_left),\n                                    str(lon_bottom_right),\n                                    str(lat_bottom_right)]),\n                  'cluster': 'yes' if cluster else 'no',}\n        if limit is not None:\n            params['cnt'] = limit\n        uri = http_client.HttpClient.to_url(BBOX_STATION_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['observation_list'].parse_JSON(json_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries the OWM Weather API for the weather currently observed by the specified location.", "response": "def weather_at_places_in_bbox(self, lon_left, lat_bottom, lon_right, lat_top,\n                                  zoom=10, cluster=False):\n        \"\"\"\n        Queries the OWM Weather API for the weather currently observed by\n        meteostations inside the bounding box of latitude/longitude coords.\n\n        :param lat_top: latitude for top margin of bounding box, must be\n            between -90.0 and 90.0\n        :type lat_top: int/float\n        :param lon_left: longitude for left margin of bounding box\n            must be between -180.0 and 180.0\n        :type lon_left: int/float\n        :param lat_bottom: latitude for the bottom margin of bounding box, must\n            be between -90.0 and 90.0\n        :type lat_bottom: int/float\n        :param lon_right: longitude for the right margin of bounding box,\n            must be between -180.0 and 180.0\n        :type lon_right: int/float\n        :param zoom: zoom level (defaults to: 10)\n        :type zoom: int\n        :param cluster: use server clustering of points\n        :type cluster: bool\n        :returns: a list of *Observation* objects or ``None`` if no weather\n            data is available\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed, *APICallException* when OWM Weather API can not be\n            reached, *ValueError* when coordinates values are out of bounds or\n            negative values are provided for limit\n        \"\"\"\n        geo.assert_is_lon(lon_left)\n        geo.assert_is_lon(lon_right)\n        geo.assert_is_lat(lat_bottom)\n        geo.assert_is_lat(lat_top)\n        assert type(zoom) is int, \"'zoom' must be an int\"\n        if zoom <= 0:\n            raise ValueError(\"'zoom' must greater than zero\")\n        assert type(cluster) is bool, \"'cluster' must be a bool\"\n        params = {'bbox': ','.join([str(lon_left),\n                                    str(lat_bottom),\n                                    str(lon_right),\n                                    str(lat_top),\n                                    str(zoom)]),\n                  'cluster': 'yes' if cluster else 'no'}\n        uri = http_client.HttpClient.to_url(BBOX_CITY_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['observation_list'].parse_JSON(json_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries the OWM Weather API for three hours weather forecast for the specified location.", "response": "def three_hours_forecast(self, name):\n        \"\"\"\n        Queries the OWM Weather API for three hours weather forecast for the\n        specified location (eg: \"London,uk\"). A *Forecaster* object is\n        returned, containing a *Forecast* instance covering a global streak of\n        five days: this instance encapsulates *Weather* objects, with a time\n        interval of three hours one from each other\n\n        :param name: the location's toponym\n        :type name: str or unicode\n        :returns: a *Forecaster* instance or ``None`` if forecast data is not\n            available for the specified location\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed, *APICallException* when OWM Weather API can not be\n            reached\n        \"\"\"\n        assert isinstance(name, str), \"Value must be a string\"\n        encoded_name = name\n        params = {'q': encoded_name, 'lang': self._language}\n        uri = http_client.HttpClient.to_url(THREE_HOURS_FORECAST_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        forecast = self._parsers['forecast'].parse_JSON(json_data)\n        if forecast is not None:\n            forecast.set_interval(\"3h\")\n            return forecaster.Forecaster(forecast)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef three_hours_forecast_at_coords(self, lat, lon):\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        params = {'lon': lon, 'lat': lat, 'lang': self._language}\n        uri = http_client.HttpClient.to_url(THREE_HOURS_FORECAST_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        forecast = self._parsers['forecast'].parse_JSON(json_data)\n        if forecast is not None:\n            forecast.set_interval(\"3h\")\n            return forecaster.Forecaster(forecast)\n        else:\n            return None", "response": "Queries the OWM Weather API for the three hours weather forecast at the specified geographic coordinate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying the OWM Weather API for the three hours weather forecast at the specified location ID.", "response": "def three_hours_forecast_at_id(self, id):\n        \"\"\"\n        Queries the OWM Weather API for three hours weather forecast for the\n        specified city ID (eg: 5128581). A *Forecaster* object is returned,\n        containing a *Forecast* instance covering a global streak of\n        five days: this instance encapsulates *Weather* objects, with a time\n        interval of three hours one from each other\n\n        :param id: the location's city ID\n        :type id: int\n        :returns: a *Forecaster* instance or ``None`` if forecast data is not\n            available for the specified location\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed, *APICallException* when OWM Weather API can not be\n            reached\n        \"\"\"\n        assert type(id) is int, \"'id' must be an int\"\n        if id < 0:\n            raise ValueError(\"'id' value must be greater than 0\")\n        params = {'id': id, 'lang': self._language}\n        uri = http_client.HttpClient.to_url(THREE_HOURS_FORECAST_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        forecast = self._parsers['forecast'].parse_JSON(json_data)\n        if forecast is not None:\n            forecast.set_interval(\"3h\")\n            return forecaster.Forecaster(forecast)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef daily_forecast(self, name, limit=None):\n        assert isinstance(name, str), \"Value must be a string\"\n        encoded_name = name\n        if limit is not None:\n            assert isinstance(limit, int), \"'limit' must be an int or None\"\n            if limit < 1:\n                raise ValueError(\"'limit' must be None or greater than zero\")\n        params = {'q': encoded_name, 'lang': self._language}\n        if limit is not None:\n            params['cnt'] = limit\n        uri = http_client.HttpClient.to_url(DAILY_FORECAST_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        forecast = self._parsers['forecast'].parse_JSON(json_data)\n        if forecast is not None:\n            forecast.set_interval(\"daily\")\n            return forecaster.Forecaster(forecast)\n        else:\n            return None", "response": "Queries the OWM Weather API for a daily weather forecast for the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef daily_forecast_at_coords(self, lat, lon, limit=None):\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        if limit is not None:\n            assert isinstance(limit, int), \"'limit' must be an int or None\"\n            if limit < 1:\n                raise ValueError(\"'limit' must be None or greater than zero\")\n        params = {'lon': lon, 'lat': lat, 'lang': self._language}\n        if limit is not None:\n            params['cnt'] = limit\n        uri = http_client.HttpClient.to_url(DAILY_FORECAST_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        forecast = self._parsers['forecast'].parse_JSON(json_data)\n        if forecast is not None:\n            forecast.set_interval(\"daily\")\n            return forecaster.Forecaster(forecast)\n        else:\n            return None", "response": "Queries the daily weather forecast API for the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef weather_history_at_place(self, name, start=None, end=None):\n        assert isinstance(name, str), \"Value must be a string\"\n        encoded_name = name\n        params = {'q': encoded_name, 'lang': self._language}\n        if start is None and end is None:\n            pass\n        elif start is not None and end is not None:\n            unix_start = timeformatutils.to_UNIXtime(start)\n            unix_end = timeformatutils.to_UNIXtime(end)\n            if unix_start >= unix_end:\n                raise ValueError(\"Error: the start time boundary must \" \\\n                                 \"precede the end time!\")\n            current_time = time()\n            if unix_start > current_time:\n                raise ValueError(\"Error: the start time boundary must \" \\\n                                 \"precede the current time!\")\n            params['start'] = str(unix_start)\n            params['end'] = str(unix_end)\n        else:\n            raise ValueError(\"Error: one of the time boundaries is None, \" \\\n                             \"while the other is not!\")\n        uri = http_client.HttpClient.to_url(CITY_WEATHER_HISTORY_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['weather_history'].parse_JSON(json_data)", "response": "Queries the OWM Weather API for weather history at a specific location."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the OWM Weather API for weather history at the specified location.", "response": "def weather_history_at_coords(self, lat, lon, start=None, end=None):\n        \"\"\"\n        Queries the OWM Weather API for weather history for the specified at the\n        specified geographic (eg: 51.503614, -0.107331). A list of *Weather*\n        objects is returned. It is possible to query for weather history in a\n        closed time period, whose boundaries can be passed as optional\n        parameters.\n\n        :param lat: the location's latitude, must be between -90.0 and 90.0\n        :type lat: int/float\n        :param lon: the location's longitude, must be between -180.0 and 180.0\n        :type lon: int/float\n        :param start: the object conveying the time value for the start query\n            boundary (defaults to ``None``)\n        :type start: int, ``datetime.datetime`` or ISO8601-formatted\n            string\n        :param end: the object conveying the time value for the end query\n            boundary (defaults to ``None``)\n        :type end: int, ``datetime.datetime`` or ISO8601-formatted string\n        :returns: a list of *Weather* instances or ``None`` if history data is\n            not available for the specified location\n\n        \"\"\"\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        params = {'lon': lon, 'lat': lat, 'lang': self._language}\n        if start is not None:\n            unix_start = timeformatutils.to_UNIXtime(start)\n\n            current_time = time()\n            if unix_start > current_time:\n                raise ValueError(\"Error: the start time boundary must \"\n                                 \"precede the current time!\")\n            params['start'] = str(unix_start)\n        else:\n            unix_start = None\n\n        if end is not None:\n            unix_end = timeformatutils.to_UNIXtime(end)\n            params['end'] = str(unix_end)\n        else:\n            unix_end = None\n\n        if unix_start is not None and unix_end is not None:\n            if unix_start >= unix_end:\n                raise ValueError(\"Error: the start time boundary must \"\n                                 \"precede the end time!\")\n        uri = http_client.HttpClient.to_url(CITY_WEATHER_HISTORY_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['weather_history'].parse_JSON(json_data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef weather_history_at_id(self, id, start=None, end=None):\n        assert type(id) is int, \"'id' must be an int\"\n        if id < 0:\n            raise ValueError(\"'id' value must be greater than 0\")\n        params = {'id': id, 'lang': self._language}\n        if start is None and end is None:\n            pass\n        elif start is not None and end is not None:\n            unix_start = timeformatutils.to_UNIXtime(start)\n            unix_end = timeformatutils.to_UNIXtime(end)\n            if unix_start >= unix_end:\n                raise ValueError(\"Error: the start time boundary must \" \\\n                                 \"precede the end time!\")\n            current_time = time()\n            if unix_start > current_time:\n                raise ValueError(\"Error: the start time boundary must \" \\\n                                 \"precede the current time!\")\n            params['start'] = str(unix_start)\n            params['end'] = str(unix_end)\n        else:\n            raise ValueError(\"Error: one of the time boundaries is None, \" \\\n                             \"while the other is not!\")\n        uri = http_client.HttpClient.to_url(CITY_WEATHER_HISTORY_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['weather_history'].parse_JSON(json_data)", "response": "Queries the OWM Weather API for weather history at the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef station_at_coords(self, lat, lon, limit=None):\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        if limit is not None:\n            assert isinstance(limit, int), \"'limit' must be int or None\"\n            if limit < 1:\n                raise ValueError(\"'limit' must be None or greater than zero\")\n        params = {'lat': lat, 'lon': lon}\n        if limit is not None:\n            params['cnt'] = limit\n        uri = http_client.HttpClient.to_url(FIND_STATION_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        return self._parsers['station_list'].parse_JSON(json_data)", "response": "Queries the OWM Weather API for weather stations nearest to the specified geographic coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nquerying the OWM Weather API for the historical weather data measurements for the specified station ID and returns a StationHistory instance.", "response": "def station_tick_history(self, station_ID, limit=None):\n        \"\"\"\n        Queries the OWM Weather API for historic weather data measurements for the\n        specified meteostation (eg: 2865), sampled once a minute (tick).\n        A *StationHistory* object instance is returned, encapsulating the\n        measurements: the total number of data points can be limited using the\n        appropriate parameter\n\n        :param station_ID: the numeric ID of the meteostation\n        :type station_ID: int\n        :param limit: the maximum number of data points the result shall\n            contain (default is ``None``, which stands for any number of data\n            points)\n        :type limit: int or ``None``\n        :returns: a *StationHistory* instance or ``None`` if data is not\n            available for the specified meteostation\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed, *APICallException* when OWM Weather API can not be\n            reached, *ValueError* if the limit value is negative\n\n        \"\"\"\n        assert isinstance(station_ID, int), \"'station_ID' must be int\"\n        if limit is not None:\n            assert isinstance(limit, int), \"'limit' must be an int or None\"\n            if limit < 1:\n                raise ValueError(\"'limit' must be None or greater than zero\")\n        station_history = self._retrieve_station_history(station_ID, limit,\n                                                         \"tick\")\n        if station_history is not None:\n            return historian.Historian(station_history)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _retrieve_station_history(self, station_ID, limit, interval):\n        params = {'id': station_ID, 'type': interval, 'lang': self._language}\n        if limit is not None:\n            params['cnt'] = limit\n        uri = http_client.HttpClient.to_url(STATION_WEATHER_HISTORY_URL,\n                                            self._API_key,\n                                            self._subscription_type,\n                                            self._use_ssl)\n        _, json_data = self._wapi.cacheable_get_json(uri, params=params)\n        station_history = \\\n            self._parsers['station_history'].parse_JSON(json_data)\n        if station_history is not None:\n            station_history.set_station_ID(station_ID)\n            station_history.set_interval(interval)\n        return station_history", "response": "Helper method for station_X_history functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uvindex_around_coords(self, lat, lon):\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        params = {'lon': lon, 'lat': lat}\n        json_data = self._uvapi.get_uvi(params)\n        uvindex = self._parsers['uvindex'].parse_JSON(json_data)\n        return uvindex", "response": "Queries the OWM Weather API for Ultra Violet value sampled in the provided geocoordinates and in the specified time\n        interval."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uvindex_forecast_around_coords(self, lat, lon):\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        params = {'lon': lon, 'lat': lat}\n        json_data = self._uvapi.get_uvi_forecast(params)\n        uvindex_list = self._parsers['uvindex_list'].parse_JSON(json_data)\n        return uvindex_list", "response": "Queries the OWM Weather API for forecast Ultra Violet values in the next 8\n        days in the surroundings of the provided geocoordinates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uvindex_history_around_coords(self, lat, lon, start, end=None):\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        assert start is not None\n        start = timeformatutils.timeformat(start, 'unix')\n        if end is None:\n            end = timeutils.now(timeformat='unix')\n        else:\n            end = timeformatutils.timeformat(end, 'unix')\n        params = {'lon': lon, 'lat': lat, 'start': start, 'end': end}\n        json_data = self._uvapi.get_uvi_history(params)\n        uvindex_list = self._parsers['uvindex_list'].parse_JSON(json_data)\n        return uvindex_list", "response": "Queries the OWM Weather API for UV index historical values in the specified geocoordinates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef coindex_around_coords(self, lat, lon, start=None, interval=None):\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        params = {'lon': lon, 'lat': lat, 'start': start, 'interval': interval}\n        json_data = self._pollapi.get_coi(params)\n        coindex = self._parsers['coindex'].parse_JSON(json_data)\n        if interval is None:\n            interval = 'year'\n        coindex._interval = interval\n        return coindex", "response": "Queries the OWM Weather API for the values sampled in the provided geocoordinates and in the specified time window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ozone_around_coords(self, lat, lon, start=None, interval=None):\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        params = {'lon': lon, 'lat': lat, 'start': start, 'interval': interval}\n        json_data = self._pollapi.get_o3(params)\n        ozone = self._parsers['ozone'].parse_JSON(json_data)\n        if interval is None:\n            interval = 'year'\n            ozone._interval = interval\n        return ozone", "response": "Queries the OWM Weather API for the Ozone value in Dobson Units sampled in the provided geocoordinates and returns an instance of Location object representing the UV intensity value of the Ozone value at the specified location."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef no2index_around_coords(self, lat, lon, start=None, interval=None):\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        params = {'lon': lon, 'lat': lat, 'start': start, 'interval': interval}\n        json_data = self._pollapi.get_no2(params)\n        no2index = self._parsers['no2index'].parse_JSON(json_data)\n        if interval is None:\n            interval = 'year'\n        no2index._interval = interval\n        return no2index", "response": "Queries the NO2 index API for NO2 samples sampled in the provided geocoordinates and in the specified time window."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nquery the OWM Weather API for SO2 samples sampled in the provided geocoordinates and returns a list of location objects representing the list of SO2 samples sampled in the specified time window.", "response": "def so2index_around_coords(self, lat, lon, start=None, interval=None):\n        \"\"\"\n        Queries the OWM Weather API for Sulphur Dioxide values sampled in the\n        surroundings of the provided geocoordinates and in the specified time\n        interval.\n        A *SO2Index* object instance is returned, encapsulating a\n        *Location* object and the list of SO2 samples\n        If `start` is not provided, the latest available SO2 samples are\n        retrieved\n        If `start` is provided but `interval` is not, then `interval` defaults\n        to the maximum extent, which is: `year`\n\n        :param lat: the location's latitude, must be between -90.0 and 90.0\n        :type lat: int/float\n        :param lon: the location's longitude, must be between -180.0 and 180.0\n        :type lon: int/float\n        :param start: the object conveying the start value of the search time\n            window start (defaults to ``None``). If not provided, the latest\n            available SO2 samples value are retrieved\n        :type start: int, ``datetime.datetime`` or ISO8601-formatted\n            string\n        :param interval: the length of the search time window starting at\n           `start` (defaults to ``None``). If not provided, 'year' is used\n        :type interval: str among: 'minute', 'hour', 'day', 'month, 'year'\n        :return: a *SO2Index* instance or ``None`` if data is not available\n        :raises: *ParseResponseException* when OWM Weather API responses' data\n            cannot be parsed, *APICallException* when OWM Weather API can not be\n            reached, *ValueError* for wrong input values\n        \"\"\"\n        geo.assert_is_lon(lon)\n        geo.assert_is_lat(lat)\n        params = {'lon': lon, 'lat': lat, 'start': start, 'interval': interval}\n        json_data = self._pollapi.get_so2(params)\n        so2index = self._parsers['so2index'].parse_JSON(json_data)\n        if interval is None:\n            interval = 'year'\n        so2index._interval = interval\n        return so2index"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kelvin_dict_to(d, target_temperature_unit):\n    if target_temperature_unit == 'kelvin':\n        return d\n    elif target_temperature_unit == 'celsius':\n        return {key: kelvin_to_celsius(d[key]) for key in d}\n    elif target_temperature_unit == 'fahrenheit':\n        return {key: kelvin_to_fahrenheit(d[key]) for key in d}\n    else:\n        raise ValueError(\"Invalid value for target temperature conversion \\\n                         unit\")", "response": "Converts all the values in a dictionary from Kelvin temperatures to the specified temperature format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a numeric temperature from Kelvin degrees to Celsius degrees", "response": "def kelvin_to_celsius(kelvintemp):\n    \"\"\"\n    Converts a numeric temperature from Kelvin degrees to Celsius degrees\n\n    :param kelvintemp: the Kelvin temperature\n    :type kelvintemp: int/long/float\n    :returns: the float Celsius temperature\n    :raises: *TypeError* when bad argument types are provided\n\n    \"\"\"\n    if kelvintemp < 0:\n        raise ValueError(__name__ + \\\n                         \": negative temperature values not allowed\")\n    celsiustemp = kelvintemp - KELVIN_OFFSET\n    return float(\"{0:.2f}\".format(celsiustemp))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kelvin_to_fahrenheit(kelvintemp):\n    if kelvintemp < 0:\n        raise ValueError(__name__ + \\\n                         \": negative temperature values not allowed\")\n    fahrenheittemp = (kelvintemp - KELVIN_OFFSET) * \\\n        FAHRENHEIT_DEGREE_SCALE + FAHRENHEIT_OFFSET\n    return float(\"{0:.2f}\".format(fahrenheittemp))", "response": "Converts a numeric temperature from Kelvin degrees to Fahrenheit degrees\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert all the wind values in a dict from meters to hours.", "response": "def metric_wind_dict_to_imperial(d):\n    \"\"\"\n    Converts all the wind values in a dict from meters/sec (metric measurement \n    system) to miles/hour (imperial measurement system)\n    .\n\n    :param d: the dictionary containing metric values\n    :type d: dict\n    :returns: a dict with the same keys as the input dict and values converted\n        to miles/hour\n\n    \"\"\"\n    result = dict()\n    for key, value in d.items():\n        if key != 'deg': # do not convert wind degree\n            result[key] = value * MILES_PER_HOUR_FOR_ONE_METER_PER_SEC\n        else:\n            result[key] = value\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a global OWM instance that represents the desired OWM Weather API version.", "response": "def OWM(API_key=constants.DEFAULT_API_KEY, version=constants.LATEST_OWM_API_VERSION,\n        config_module=None, language=None, subscription_type=None, use_ssl=None):\n    \"\"\"\n    A parametrized factory method returning a global OWM instance that\n    represents the desired OWM Weather API version (or the currently supported one\n    if no version number is specified)\n\n    :param API_key: the OWM Weather API key (defaults to a test value)\n    :type API_key: str\n    :param version: the OWM Weather API version. Defaults to ``None``, which means\n        use the latest web API version\n    :type version: str\n    :param config_module: the Python path of the configuration module you want\n        to provide for instantiating the library. Defaults to ``None``, which\n        means use the default configuration values for the web API version\n        support you are currently requesting. Please be aware that malformed\n        user-defined configuration modules can lead to unwanted behaviour!\n    :type config_module: str (eg: 'mypackage.mysubpackage.myconfigmodule')\n    :param language: the language in which you want text results to be returned.\n          It's a two-characters string, eg: \"en\", \"ru\", \"it\". Defaults to:\n          ``None``, which means use the default language.\n    :type language: str\n    :param subscription_type: the type of OWM Weather API subscription to be wrapped.\n           Can be 'free' (free subscription) or 'pro' (paid subscription),\n           Defaults to: 'free'\n    :type subscription_type: str\n    :param use_ssl: whether API calls should be made via SSL or not.\n           Defaults to: False\n    :type use_ssl: bool\n    :returns: an instance of a proper *OWM* subclass\n    :raises: *ValueError* when unsupported OWM API versions are provided\n    \"\"\"\n    if version == '2.5':\n        if config_module is None:\n            config_module = \"pyowm.weatherapi25.configuration25\"\n        cfg_module = __import__(config_module,  fromlist=[''])\n        from pyowm.weatherapi25.owm25 import OWM25\n        if language is None:\n            language = cfg_module.language\n        if subscription_type is None:\n            subscription_type = cfg_module.API_SUBSCRIPTION_TYPE\n            if subscription_type not in ['free', 'pro']:\n                subscription_type = 'free'\n        if use_ssl is None:\n            use_ssl = cfg_module.USE_SSL\n        return OWM25(cfg_module.parsers, API_key, cfg_module.cache,\n                     language, subscription_type, use_ssl)\n    raise ValueError(\"Unsupported OWM Weather API version\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing an observation from a raw JSON string.", "response": "def parse_JSON(self, JSON_string):\n        \"\"\"\n        Parses an *Observation* instance out of raw JSON data. Only certain\n        properties of the data are used: if these properties are not found or\n        cannot be parsed, an error is issued.\n\n        :param JSON_string: a raw JSON string\n        :type JSON_string: str\n        :returns: an *Observation* instance or ``None`` if no data is available\n        :raises: *ParseResponseError* if it is impossible to find or parse the\n            data needed to build the result, *APIResponseError* if the JSON\n            string embeds an HTTP status error\n\n        \"\"\"\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = loads(JSON_string)\n        # Check if server returned errors: this check overcomes the lack of use\n        # of HTTP error status codes by the OWM API 2.5. This mechanism is\n        # supposed to be deprecated as soon as the API fully adopts HTTP for\n        # conveying errors to the clients\n        if 'message' in d and 'cod' in d:\n            if d['cod'] == \"404\":\n                print(\"OWM API: observation data not available - response \" \\\n                    \"payload: \" + dumps(d))\n                return None\n            else:\n                raise api_response_error.APIResponseError(\n                                      \"OWM API: error - response payload: \" + dumps(d), d['cod'])\n        try:\n            place = location.location_from_dictionary(d)\n        except KeyError:\n            raise parse_response_error.ParseResponseError(\n                                      ''.join([__name__, ': impossible to ' \\\n                                       'read location info from JSON data']))\n        try:\n            w = weather.weather_from_dictionary(d)\n        except KeyError:\n            raise parse_response_error.ParseResponseError(\n                                      ''.join([__name__, ': impossible to ' \\\n                                       'read weather info from JSON data']))\n        current_time = int(round(time()))\n        return observation.Observation(current_time, place, w)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_JSON(self):\n        return json.dumps({\"reference_time\": self._reference_time,\n                           \"location\": json.loads(self._location.to_JSON()),\n                           \"interval\": self._interval,\n                           \"co_samples\": self._co_samples,\n                           \"reception_time\": self._reception_time,\n                           })", "response": "Dumps the object fields into a JSON formatted string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump the object fields to an XML - formatted string.", "response": "def to_XML(self, xml_declaration=True, xmlns=True):\n        \"\"\"\n        Dumps object fields to an XML-formatted string. The 'xml_declaration'\n        switch  enables printing of a leading standard XML line containing XML\n        version and encoding. The 'xmlns' switch enables printing of qualified\n        XMLNS prefixes.\n\n        :param XML_declaration: if ``True`` (default) prints a leading XML\n            declaration line\n        :type XML_declaration: bool\n        :param xmlns: if ``True`` (default) prints full XMLNS prefixes\n        :type xmlns: bool\n        :returns: an XML-formatted string\n\n        \"\"\"\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         COINDEX_XMLNS_PREFIX,\n                                         COINDEX_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_JSON(self, JSON_string):\n        if JSON_string is None:\n            raise ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        station_parser = StationParser()\n        return [station_parser.parse_JSON(json.dumps(item)) for item in d]", "response": "Parses a list of stations out of a raw JSON string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef id_for(self, city_name):\n        line = self._lookup_line_by_city_name(city_name)\n        return int(line.split(\",\")[1]) if line is not None else None", "response": "Returns the long ID corresponding to the first city found that matches\n        the provided city name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ids_for(self, city_name, country=None, matching='nocase'):\n        if not city_name:\n            return []\n        if matching not in self.MATCHINGS:\n            raise ValueError(\"Unknown type of matching: \"\n                             \"allowed values are %s\" % \", \".join(self.MATCHINGS))\n        if country is not None and len(country) != 2:\n            raise ValueError(\"Country must be a 2-char string\")\n        splits = self._filter_matching_lines(city_name, country, matching)\n        return [(int(item[1]), item[0], item[4]) for item in splits]", "response": "Returns a list of tuples corresponding to the int IDs and relative toponyms and 2 - chars country of the cities of the given city name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef location_for(self, city_name):\n        line = self._lookup_line_by_city_name(city_name)\n        if line is None:\n            return None\n        tokens = line.split(\",\")\n        return Location(tokens[0], float(tokens[3]), float(tokens[2]),\n                        int(tokens[1]), tokens[4])", "response": "Returns a Location object corresponding to the first city found\n        that matches the provided city name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef locations_for(self, city_name, country=None, matching='nocase'):\n        if not city_name:\n            return []\n        if matching not in self.MATCHINGS:\n            raise ValueError(\"Unknown type of matching: \"\n                             \"allowed values are %s\" % \", \".join(self.MATCHINGS))\n        if country is not None and len(country) != 2:\n            raise ValueError(\"Country must be a 2-char string\")\n        splits = self._filter_matching_lines(city_name, country, matching)\n        return [Location(item[0], float(item[3]), float(item[2]),\n                         int(item[1]), item[4]) for item in splits]", "response": "Returns a list of Location objects corresponding to the given city name and country."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of geopoints corresponding to the provided city name and country.", "response": "def geopoints_for(self, city_name, country=None, matching='nocase'):\n        \"\"\"\n        Returns a list of ``pyowm.utils.geo.Point`` objects corresponding to\n        the int IDs and relative toponyms and 2-chars country of the cities\n        matching the provided city name.\n        The rule for identifying matchings is according to the provided\n        `matching` parameter value.\n        If `country` is provided, the search is restricted to the cities of\n        the specified country.\n        :param country: two character str representing the country where to\n        search for the city. Defaults to `None`, which means: search in all\n        countries.\n        :param matching: str among `exact` (literal, case-sensitive matching),\n        `nocase` (literal, case-insensitive matching) and `like` (matches cities\n        whose name contains as a substring the string fed to the function, no\n        matter the case). Defaults to `nocase`.\n        :raises ValueError if the value for `matching` is unknown\n        :return: list of `pyowm.utils.geo.Point` objects\n        \"\"\"\n        locations = self.locations_for(city_name, country, matching=matching)\n        return [loc.to_geopoint() for loc in locations]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an iterable whose items are the lists of split tokens of every text line matched against the provided city_name country and matching style.", "response": "def _filter_matching_lines(self, city_name, country, matching):\n        \"\"\"\n        Returns an iterable whose items are the lists of split tokens of every\n        text line matched against the city ID files according to the provided\n        combination of city_name, country and matching style\n        :param city_name: str\n        :param country: str or `None`\n        :param matching: str\n        :return: list of lists\n        \"\"\"\n        result = list()\n\n        # find the right file to scan and extract its lines. Upon \"like\"\n        # matchings, just read all files\n        if matching == 'like':\n            lines = [l.strip() for l in self._get_all_lines()]\n        else:\n            filename = self._assess_subfile_from(city_name)\n            lines = [l.strip() for l in self._get_lines(filename)]\n\n        # look for toponyms matching the specified city_name and according to\n        # the specified matching style\n        for line in lines:\n            tokens = line.split(\",\")\n            # sometimes city names have an inner comma...\n            if len(tokens) == 6:\n                tokens = [tokens[0]+','+tokens[1], tokens[2], tokens[3],\n                          tokens[4], tokens[5]]\n            # check country\n            if country is not None:\n                if tokens[4] != country:\n                    continue\n\n            # check city_name\n            if self._city_name_matches(city_name, tokens[0], matching):\n                result.append(tokens)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the first matching line in a list of lines.", "response": "def _match_line(self, city_name, lines):\n        \"\"\"\n        The lookup is case insensitive and returns the first matching line,\n        stripped.\n        :param city_name: str\n        :param lines: list of str\n        :return: str\n        \"\"\"\n        for line in lines:\n            toponym = line.split(',')[0]\n            if toponym.lower() == city_name.lower():\n                return line.strip()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the alert with the specified ID or None if no such alert exists.", "response": "def get_alert(self, alert_id):\n        \"\"\"\n        Returns the `Alert` of this `Trigger` having the specified ID\n        :param alert_id: str, the ID of the alert\n        :return: `Alert` instance\n        \"\"\"\n        for alert in self.alerts:\n            if alert.id == alert_id:\n                return alert\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all the alerts that have been fired since the specified timestamp.", "response": "def get_alerts_since(self, timestamp):\n        \"\"\"\n        Returns all the `Alert` objects of this `Trigger` that were fired since the specified timestamp.\n        :param timestamp: time object representing the point in time since when alerts have to be fetched\n        :type timestamp: int, ``datetime.datetime`` or ISO8601-formatted string\n        :return: list of `Alert` instances\n        \"\"\"\n        unix_timestamp = timeformatutils.to_UNIXtime(timestamp)\n        result = []\n        for alert in self.alerts:\n            if alert.last_update >= unix_timestamp:\n                result.append(alert)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the alerts that refer to the specified weather parameter.", "response": "def get_alerts_on(self, weather_param):\n        \"\"\"\n        Returns all the `Alert` objects of this `Trigger` that refer to the specified weather parameter (eg. 'temp',\n        'pressure', etc.). The allowed weather params are the ones enumerated by class\n        `pyowm.alertapi30.enums.WeatherParametersEnum`\n        :param weather_param: str, values in `pyowm.alertapi30.enums.WeatherParametersEnum`\n        :return: list of `Alert` instances\n        \"\"\"\n        result = []\n        for alert in self.alerts:\n            for met_condition in alert.met_conditions:\n                if met_condition['condition'].weather_param == weather_param:\n                    result.append(alert)\n                    break\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef when_starts(self, timeformat='unix'):\n        start_coverage = min([item.get_reference_time() \\\n                              for item in self._forecast])\n        return timeformatutils.timeformat(start_coverage, timeformat)", "response": "Returns the GMT time of the start of the forecast coverage which is\n        the time of the most ancient weather item in the forecast"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the GMT time of the end of the forecast coverage", "response": "def when_ends(self, timeformat='unix'):\n        \"\"\"\n        Returns the GMT time of the end of the forecast coverage, which is the\n        time of the most recent *Weather* item in the forecast\n\n        :param timeformat: the format for the time value. May be:\n            '*unix*' (default) for UNIX time\n            '*iso*' for ISO8601-formatted string in the format ``YYYY-MM-DD HH:MM:SS+00``\n            '*date* for ``datetime.datetime`` object instance\n        :type timeformat: str\n        :returns: a long or a str\n        :raises: *ValueError* when invalid time format values are provided\n\n        \"\"\"\n        end_coverage = max([item.get_reference_time() \\\n                            for item in self._forecast])\n        return timeformatutils.timeformat(end_coverage, timeformat)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _will_be(self, timeobject, weather_condition):\n        time_value = timeformatutils.to_UNIXtime(timeobject)\n        closest_weather = weatherutils.find_closest_weather(\n                                        self._forecast.get_weathers(),\n                                        time_value)\n        return weatherutils.status_is(closest_weather, weather_condition,\n                                      weather_code_registry)", "response": "Tells if at the specified weather condition will occur at the specified time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the most hot version of the weather in the forecast with the highest maxCOOKIE.", "response": "def most_hot(self):\n        \"\"\"\n        Returns the *Weather* object in the forecast having the highest max\n        temperature. The temperature is retrieved using the\n        ``get_temperature['temp_max']`` call; was 'temp_max' key missing for\n        every *Weather* instance in the forecast, ``None`` would be returned.\n\n        :returns: a *Weather* object or ``None`` if no item in the forecast is\n            eligible\n        \"\"\"\n        maxtemp = -270.0  # No one would survive that...\n        hottest = None\n        for weather in self._forecast.get_weathers():\n            d = weather.get_temperature()\n            if 'temp_max' in d:\n                if d['temp_max'] > maxtemp:\n                    maxtemp = d['temp_max']\n                    hottest = weather\n        return hottest"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef most_cold(self):\n        mintemp = 1000.0  # No one would survive that...\n        coldest = None\n        for weather in self._forecast.get_weathers():\n            d = weather.get_temperature()\n            if 'temp_min' in d:\n                if d['temp_min'] < mintemp:\n                    mintemp = d['temp_min']\n                    coldest = weather\n        return coldest", "response": "Returns the most cold weather in the forecast with the lowest min\n        temperature."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef most_humid(self):\n        max_humidity = 0\n        most_humid = None\n        for weather in self._forecast.get_weathers():\n            h = weather.get_humidity()\n            if h > max_humidity:\n                max_humidity = h\n                most_humid = weather\n        return most_humid", "response": "Returns the most humid object in the forecast."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the most rainy weather in the forecast with the highest precipitation volume.", "response": "def most_rainy(self):\n        \"\"\"\n        Returns the *Weather* object in the forecast having the highest\n        precipitation volume. The rain amount is retrieved via the\n        ``get_rain['all']`` call; was the 'all' key missing for every *Weather*\n        instance in the forecast,``None`` would be returned.\n\n        :returns: a *Weather* object or ``None`` if no item in the forecast is\n            eligible\n        \"\"\"\n        max_rain = 0\n        most_rainy = None\n        for weather in self._forecast.get_weathers():\n            d = weather.get_rain()\n            if 'all' in d:\n                if d['all'] > max_rain:\n                    max_rain = d['all']\n                    most_rainy = weather\n        return most_rainy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the most snowy weather in the forecast with the highest snow volume.", "response": "def most_snowy(self):\n        \"\"\"\n        Returns the *Weather* object in the forecast having the highest\n        snow volume. The snow amount is retrieved via the ``get_snow['all']``\n        call; was the 'all' key missing for every *Weather* instance in the\n        forecast, ``None`` would be returned.\n\n        :returns: a *Weather* object or ``None`` if no item in the forecast is\n            eligible\n        \"\"\"\n        max_snow = 0\n        most_snowy = None\n        for weather in self._forecast.get_weathers():\n            d = weather.get_snow()\n            if 'all' in d:\n                if d['all'] > max_snow:\n                    max_snow = d['all']\n                    most_snowy = weather\n        return most_snowy"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the most windy weather in the forecast with the highest wind speed.", "response": "def most_windy(self):\n        \"\"\"\n        Returns the *Weather* object in the forecast having the highest\n        wind speed. The snow amount is retrieved via the ``get_wind['speed']``\n        call; was the 'speed' key missing for every *Weather* instance in the\n        forecast, ``None`` would be returned.\n\n        :returns: a *Weather* object or ``None`` if no item in the forecast is\n            eligible\n        \"\"\"\n        max_wind_speed = 0\n        most_windy = None\n        for weather in self._forecast.get_weathers():\n            d = weather.get_wind()\n            if 'speed' in d:\n                if d['speed'] > max_wind_speed:\n                    max_wind_speed = d['speed']\n                    most_windy = weather\n        return most_windy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef status_is(weather, status, weather_code_registry):\n    weather_status = weather_code_registry. \\\n        status_for(weather.get_weather_code()).lower()\n    return weather_status == status", "response": "Checks if the weather status code of a weather object corresponds to the detailed status indicated."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef any_status_is(weather_list, status, weather_code_registry):\n    for weather in weather_list:\n        if status_is(weather, status, weather_code_registry):\n            return True\n    return False", "response": "Checks if the status code of any weather object in the provided list corresponds to the detailed status indicated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter_by_status(weather_list, status, weather_code_registry):\n    result = []\n    for weather in weather_list:\n        if status_is(weather, status, weather_code_registry):\n            result.append(weather)\n    return result", "response": "Filters out from the provided list of weather objects a sublist of items\n    having a status corresponding to the provided one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_in_coverage(unixtime, weathers_list):\n    if not weathers_list:\n        return False\n    else:\n        min_of_coverage = min([weather.get_reference_time() \\\n                               for weather in weathers_list])\n        max_of_coverage = max([weather.get_reference_time() \\\n                               for weather in weathers_list])\n        if unixtime < min_of_coverage or unixtime > max_of_coverage:\n            return False\n        return True", "response": "Checks if the supplied UNIX time is contained into the time range and if it is contained in the time range."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_closest_weather(weathers_list, unixtime):\n    if not weathers_list:\n        return None\n    if not is_in_coverage(unixtime, weathers_list):\n        raise api_response_error.NotFoundError('Error: the specified time is ' + \\\n                                'not included in the weather coverage range')\n    closest_weather = weathers_list[0]\n    time_distance = abs(closest_weather.get_reference_time() - unixtime)\n    for weather in weathers_list:\n        if abs(weather.get_reference_time() - unixtime) < time_distance:\n            time_distance = abs(weather.get_reference_time() - unixtime)\n            closest_weather = weather\n    return closest_weather", "response": "Returns the item which is the closest weather in time to the provided UNIXtime."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of tuples describing the current set of items for this class.", "response": "def items(cls):\n        \"\"\"\n        All values for this enum\n        :return: list of tuples\n\n        \"\"\"\n        return [\n            cls.PRECIPITATION,\n            cls.WIND,\n            cls.TEMPERATURE,\n            cls.PRESSURE\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the image to disk on a file", "response": "def persist(self, path_to_file):\n        \"\"\"\n        Saves the image to disk on a file\n\n        :param path_to_file: path to the target file\n        :type path_to_file: str\n        :return: `None`\n        \"\"\"\n        with open(path_to_file, 'wb') as f:\n            f.write(self.data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(cls, path_to_file):\n        import mimetypes\n        mimetypes.init()\n        mime = mimetypes.guess_type('file://%s' % path_to_file)[0]\n        img_type = ImageTypeEnum.lookup_by_mime_type(mime)\n        with open(path_to_file, 'rb') as f:\n            data = f.read()\n        return Image(data, image_type=img_type)", "response": "Loads the image data from a file on disk and returns a new Image instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_XML(self, xml_declaration=True, xmlns=True):\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         SO2INDEX_XMLNS_PREFIX,\n                                         SO2INDEX_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)", "response": "Dumps the object fields to an XML - formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat the specified time object to the specified target format type.", "response": "def timeformat(timeobject, timeformat):\n    \"\"\"\n    Formats the specified time object to the target format type.\n\n    :param timeobject: the object conveying the time value\n    :type timeobject: int, ``datetime.datetime`` or ISO8601-formatted\n        string with pattern ``YYYY-MM-DD HH:MM:SS+00``\n    :param timeformat: the target format for the time conversion. May be:\n        '*unix*' (outputs an int UNIXtime), '*date*' (outputs a\n        ``datetime.datetime`` object) or '*iso*' (outputs an ISO8601-formatted\n        string with pattern ``YYYY-MM-DD HH:MM:SS+00``)\n    :type timeformat: str\n    :returns: the formatted time\n    :raises: ValueError when unknown timeformat switches are provided or\n        when negative time values are provided\n    \"\"\"\n    if timeformat == \"unix\":\n        return to_UNIXtime(timeobject)\n    elif timeformat == \"iso\":\n        return to_ISO8601(timeobject)\n    elif timeformat == \"date\":\n        return to_date(timeobject)\n    else:\n        raise ValueError(\"Invalid value for timeformat parameter\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a time value to a date object.", "response": "def to_date(timeobject):\n    \"\"\"\n    Returns the ``datetime.datetime`` object corresponding to the time value\n    conveyed by the specified object, which can be either a UNIXtime, a\n    ``datetime.datetime`` object or an ISO8601-formatted string in the format\n    `YYYY-MM-DD HH:MM:SS+00``.\n\n    :param timeobject: the object conveying the time value\n    :type timeobject: int, ``datetime.datetime`` or ISO8601-formatted\n        string\n    :returns: a ``datetime.datetime`` object\n    :raises: *TypeError* when bad argument types are provided, *ValueError*\n        when negative UNIXtimes are provided\n    \"\"\"\n    if isinstance(timeobject, int):\n        if timeobject < 0:\n            raise ValueError(\"The time value is a negative number\")\n        return datetime.utcfromtimestamp(timeobject).replace(tzinfo=UTC())\n    elif isinstance(timeobject, datetime):\n        return timeobject.replace(tzinfo=UTC())\n    elif isinstance(timeobject, str):\n        return datetime.strptime(timeobject,\n                                 '%Y-%m-%d %H:%M:%S+00').replace(tzinfo=UTC())\n    else:\n        raise TypeError('The time value must be expressed either by an int ' \\\n                         'UNIX time, a datetime.datetime object or an ' \\\n                         'ISO8601-formatted string')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a UNIXtime object to an ISO8601 - formatted string.", "response": "def to_ISO8601(timeobject):\n    \"\"\"\n    Returns the ISO8601-formatted string corresponding to the time value\n    conveyed by the specified object, which can be either a UNIXtime, a\n    ``datetime.datetime`` object or an ISO8601-formatted string in the format\n    `YYYY-MM-DD HH:MM:SS+00``.\n\n    :param timeobject: the object conveying the time value\n    :type timeobject: int, ``datetime.datetime`` or ISO8601-formatted\n        string\n    :returns: an ISO8601-formatted string with pattern\n        `YYYY-MM-DD HH:MM:SS+00``\n    :raises: *TypeError* when bad argument types are provided, *ValueError*\n        when negative UNIXtimes are provided\n    \"\"\"\n    if isinstance(timeobject, int):\n        if timeobject < 0:\n            raise ValueError(\"The time value is a negative number\")\n        return datetime.utcfromtimestamp(timeobject). \\\n            strftime('%Y-%m-%d %H:%M:%S+00')\n    elif isinstance(timeobject, datetime):\n        return timeobject.strftime('%Y-%m-%d %H:%M:%S+00')\n    elif isinstance(timeobject, str):\n        return timeobject\n    else:\n        raise TypeError('The time value must be expressed either by an int ' \\\n                         'UNIX time, a datetime.datetime object or an ' \\\n                         'ISO8601-formatted string')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a time value into a UNIXtime object.", "response": "def to_UNIXtime(timeobject):\n    \"\"\"\n    Returns the UNIXtime corresponding to the time value conveyed by the\n    specified object, which can be either a UNIXtime, a\n    ``datetime.datetime`` object or an ISO8601-formatted string in the format\n    `YYYY-MM-DD HH:MM:SS+00``.\n\n    :param timeobject: the object conveying the time value\n    :type timeobject: int, ``datetime.datetime`` or ISO8601-formatted\n        string\n    :returns: an int UNIXtime\n    :raises: *TypeError* when bad argument types are provided, *ValueError*\n        when negative UNIXtimes are provided\n    \"\"\"\n    if isinstance(timeobject, int):\n        if timeobject < 0:\n            raise ValueError(\"The time value is a negative number\")\n        return timeobject\n    elif isinstance(timeobject, datetime):\n        return _datetime_to_UNIXtime(timeobject)\n    elif isinstance(timeobject, str):\n        return _ISO8601_to_UNIXtime(timeobject)\n    else:\n        raise TypeError('The time value must be expressed either by an int ' \\\n                         'UNIX time, a datetime.datetime object or an ' \\\n                         'ISO8601-formatted string')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an ISO8601 - formatted string in the format YYYY - MM - DD HH - MM - SS + 00 to the corresponding UNIXtime.", "response": "def _ISO8601_to_UNIXtime(iso):\n    \"\"\"\n    Converts an ISO8601-formatted string in the format\n    ``YYYY-MM-DD HH:MM:SS+00`` to the correspondant UNIXtime\n\n    :param iso: the ISO8601-formatted string\n    :type iso: string\n    :returns: an int UNIXtime\n    :raises: *TypeError* when bad argument types are provided, *ValueError*\n        when the ISO8601 string is badly formatted\n\n    \"\"\"\n    try:\n        d = datetime.strptime(iso, '%Y-%m-%d %H:%M:%S+00')\n    except ValueError:\n        raise ValueError(__name__ + \": bad format for input ISO8601 string, ' \\\n            'should have been: YYYY-MM-DD HH:MM:SS+00\")\n    return _datetime_to_UNIXtime(d)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove from this forecast all the weather objects having a reference timestamp in the past with respect to the current timestamp", "response": "def actualize(self):\n        \"\"\"\n        Removes from this forecast all the *Weather* objects having a reference\n        timestamp in the past with respect to the current timestamp\n        \"\"\"\n        current_time = timeutils.now(timeformat='unix')\n        for w in self._weathers:\n            if w.get_reference_time(timeformat='unix') < current_time:\n                self._weathers.remove(w)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_JSON(self):\n        return json.dumps({\"interval\": self._interval,\n                           \"reception_time\": self._reception_time,\n                           \"Location\": json.loads(self._location.to_JSON()),\n                           \"weathers\": json.loads(\"[\" + \\\n                                \",\".join([w.to_JSON() for w in self]) + \"]\")\n                           })", "response": "Dumps the object fields into a JSON formatted string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndumps the object fields to an XML - formatted string.", "response": "def to_XML(self, xml_declaration=True, xmlns=True):\n        \"\"\"\n        Dumps object fields to an XML-formatted string. The 'xml_declaration'\n        switch  enables printing of a leading standard XML line containing XML\n        version and encoding. The 'xmlns' switch enables printing of qualified\n        XMLNS prefixes.\n\n        :param XML_declaration: if ``True`` (default) prints a leading XML\n            declaration line\n        :type XML_declaration: bool\n        :param xmlns: if ``True`` (default) prints full XMLNS prefixes\n        :type xmlns: bool\n        :returns: an XML-formatted string\n\n        \"\"\"\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         FORECAST_XMLNS_PREFIX,\n                                         FORECAST_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _to_DOM(self):\n        root_node = ET.Element(\"forecast\")\n        interval_node = ET.SubElement(root_node, \"interval\")\n        interval_node.text = self._interval\n        reception_time_node = ET.SubElement(root_node, \"reception_time\")\n        reception_time_node.text = str(self._reception_time)\n        root_node.append(self._location._to_DOM())\n        weathers_node = ET.SubElement(root_node, \"weathers\")\n        for weather in self:\n            weathers_node.append(weather._to_DOM())\n        return root_node", "response": "Dumps the object data to a fully traversable DOM representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the temperature time series relative to the meteostation", "response": "def temperature_series(self, unit='kelvin'):\n        \"\"\"Returns the temperature time series relative to the meteostation, in\n        the form of a list of tuples, each one containing the couple\n        timestamp-value\n\n        :param unit: the unit of measure for the temperature values. May be\n            among: '*kelvin*' (default), '*celsius*' or '*fahrenheit*'\n        :type unit: str\n        :returns: a list of tuples\n        :raises: ValueError when invalid values are provided for the unit of\n            measure\n        \"\"\"\n        if unit not in ('kelvin', 'celsius', 'fahrenheit'):\n            raise ValueError(\"Invalid value for parameter 'unit'\")\n        result = []\n        for tstamp in self._station_history.get_measurements():\n            t = self._station_history.get_measurements()[tstamp]['temperature']\n            if unit == 'kelvin':\n                temp = t\n            if unit == 'celsius':\n                temp = temputils.kelvin_to_celsius(t)\n            if unit == 'fahrenheit':\n                temp = temputils.kelvin_to_fahrenheit(t)\n            result.append((tstamp, temp))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef humidity_series(self):\n        return [(tstamp, \\\n                self._station_history.get_measurements()[tstamp]['humidity']) \\\n                for tstamp in self._station_history.get_measurements()]", "response": "Returns the humidity time series relative to the meteostation in\n        the form of a list of tuples each one containing the couple\n        timestamp - value\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pressure_series(self):\n        return [(tstamp, \\\n                self._station_history.get_measurements()[tstamp]['pressure']) \\\n                for tstamp in self._station_history.get_measurements()]", "response": "Returns the atmospheric pressure time series relative to the\n        meteostation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the precipitation time series relative to the meteostation", "response": "def rain_series(self):\n        \"\"\"Returns the precipitation time series relative to the\n        meteostation, in the form of a list of tuples, each one containing the\n        couple timestamp-value\n\n        :returns: a list of tuples\n        \"\"\"\n        return [(tstamp, \\\n                self._station_history.get_measurements()[tstamp]['rain']) \\\n                for tstamp in self._station_history.get_measurements()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wind_series(self):\n        return [(timestamp, \\\n                self._station_history.get_measurements()[timestamp]['wind']) \\\n                for timestamp in self._station_history.get_measurements()]", "response": "Returns the wind speed time series relative to the\n        meteostation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the maximum value in the temperature series preceeded by its timestamp", "response": "def max_temperature(self,  unit='kelvin'):\n        \"\"\"Returns a tuple containing the max value in the temperature\n        series preceeded by its timestamp\n        \n        :param unit: the unit of measure for the temperature values. May be\n            among: '*kelvin*' (default), '*celsius*' or '*fahrenheit*'\n        :type unit: str\n        :returns: a tuple\n        :raises: ValueError when invalid values are provided for the unit of\n            measure or the measurement series is empty\n        \"\"\"\n        if unit not in ('kelvin', 'celsius', 'fahrenheit'):\n            raise ValueError(\"Invalid value for parameter 'unit'\")\n        maximum = max(self._purge_none_samples(self.temperature_series()),\n                   key=itemgetter(1))\n        if unit == 'kelvin':\n            result = maximum\n        if unit == 'celsius':\n            result = (maximum[0], temputils.kelvin_to_celsius(maximum[1]))\n        if unit == 'fahrenheit':\n            result = (maximum[0], temputils.kelvin_to_fahrenheit(maximum[1]))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the minimum temperature value in the temperature series preceeded by its timestamp", "response": "def min_temperature(self, unit='kelvin'):\n        \"\"\"Returns a tuple containing the min value in the temperature\n        series preceeded by its timestamp\n        \n        :param unit: the unit of measure for the temperature values. May be\n            among: '*kelvin*' (default), '*celsius*' or '*fahrenheit*'\n        :type unit: str\n        :returns: a tuple\n        :raises: ValueError when invalid values are provided for the unit of\n            measure or the measurement series is empty\n        \"\"\"\n        if unit not in ('kelvin', 'celsius', 'fahrenheit'):\n            raise ValueError(\"Invalid value for parameter 'unit'\")\n        minimum = min(self._purge_none_samples(self.temperature_series()),\n                   key=itemgetter(1))\n        if unit == 'kelvin':\n            result = minimum\n        if unit == 'celsius':\n            result = (minimum[0], temputils.kelvin_to_celsius(minimum[1]))\n        if unit == 'fahrenheit':\n            result = (minimum[0], temputils.kelvin_to_fahrenheit(minimum[1]))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef average_temperature(self, unit='kelvin'):\n        if unit not in ('kelvin', 'celsius', 'fahrenheit'):\n            raise ValueError(\"Invalid value for parameter 'unit'\")\n        average = self._average(self._purge_none_samples(\n                                                  self.temperature_series()))\n        if unit == 'kelvin':\n            result = average\n        if unit == 'celsius':\n            result = temputils.kelvin_to_celsius(average)\n        if unit == 'fahrenheit':\n            result = temputils.kelvin_to_fahrenheit(average)\n        return result", "response": "Returns the average value in the temperature series."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the max value in the rain series preceeded by its timestamp", "response": "def max_rain(self):\n        \"\"\"Returns a tuple containing the max value in the rain\n        series preceeded by its timestamp\n\n        :returns: a tuple\n        :raises: ValueError when the measurement series is empty\n        \"\"\"\n        return max(self._purge_none_samples(self.rain_series()),\n                   key=lambda item:item[1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps the object fields into a JSON formatted string", "response": "def to_JSON(self):\n        \"\"\"Dumps object fields into a JSON formatted string\n\n        :returns:  the JSON string\n\n        \"\"\"\n        return json.dumps({\"reception_time\": self._reception_time,\n                           \"Location\": json.loads(self._location.to_JSON()),\n                           \"Weather\": json.loads(self._weather.to_JSON())\n                           })"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps the object fields to an XML - formatted string.", "response": "def to_XML(self, xml_declaration=True, xmlns=True):\n        \"\"\"\n        Dumps object fields to an XML-formatted string. The 'xml_declaration'\n        switch  enables printing of a leading standard XML line containing XML\n        version and encoding. The 'xmlns' switch enables printing of qualified\n        XMLNS prefixes.\n\n        :param XML_declaration: if ``True`` (default) prints a leading XML\n            declaration line\n        :type XML_declaration: bool\n        :param xmlns: if ``True`` (default) prints full XMLNS prefixes\n        :type xmlns: bool\n        :returns: an XML-formatted string\n\n        \"\"\"\n        root_node = self._to_DOM()\n        if xmlns:\n            xmlutils.annotate_with_XMLNS(root_node,\n                                         OBSERVATION_XMLNS_PREFIX,\n                                         OBSERVATION_XMLNS_URL)\n        return xmlutils.DOM_node_to_XML(root_node, xml_declaration)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _to_DOM(self):\n        root_node = ET.Element(\"observation\")\n        reception_time_node = ET.SubElement(root_node, \"reception_time\")\n        reception_time_node.text = str(self._reception_time)\n        root_node.append(self._location._to_DOM())\n        root_node.append(self._weather._to_DOM())\n        return root_node", "response": "Dumps the object data to a fully traversable DOM representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninvoking the UV Index endpoint :param params_dict: dict of parameters :returns: a string containing raw JSON data :raises: *ValueError*, *APICallError*", "response": "def get_uvi(self, params_dict):\n        \"\"\"\n        Invokes the UV Index endpoint\n\n        :param params_dict: dict of parameters\n        :returns: a string containing raw JSON data\n        :raises: *ValueError*, *APICallError*\n\n        \"\"\"\n        lat = str(params_dict['lat'])\n        lon = str(params_dict['lon'])\n        params = dict(lat=lat, lon=lon)\n\n        # build request URL\n        uri = http_client.HttpClient.to_url(UV_INDEX_URL, self._API_key, None)\n        _, json_data = self._client.cacheable_get_json(uri, params=params)\n        return json_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninvoking the UV Index History endpoint :param params_dict: dict of parameters :returns: a string containing raw JSON data :raises: *ValueError*, *APICallError*", "response": "def get_uvi_history(self, params_dict):\n        \"\"\"\n        Invokes the UV Index History endpoint\n\n        :param params_dict: dict of parameters\n        :returns: a string containing raw JSON data\n        :raises: *ValueError*, *APICallError*\n\n        \"\"\"\n        lat = str(params_dict['lat'])\n        lon = str(params_dict['lon'])\n        start = str(params_dict['start'])\n        end = str(params_dict['end'])\n        params = dict(lat=lat, lon=lon, start=start, end=end)\n\n        # build request URL\n        uri = http_client.HttpClient.to_url(UV_INDEX_HISTORY_URL,\n                                            self._API_key,\n                                            None)\n        _, json_data = self._client.cacheable_get_json(uri, params=params)\n        return json_data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all items for this enumeration.", "response": "def items(cls):\n        \"\"\"\n        All values for this enum\n        :return: list of str\n\n        \"\"\"\n        return [\n            cls.TEMPERATURE,\n            cls.PRESSURE,\n            cls.HUMIDITY,\n            cls.WIND_SPEED,\n            cls.WIND_DIRECTION,\n            cls.CLOUDS\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of strings representing the items of the enumeration .", "response": "def items(cls):\n        \"\"\"\n        All values for this enum\n        :return: list of str\n\n        \"\"\"\n        return [\n            cls.GREATER_THAN,\n            cls.GREATER_THAN_EQUAL,\n            cls.LESS_THAN,\n            cls.LESS_THAN_EQUAL,\n            cls.EQUAL,\n            cls.NOT_EQUAL\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a JSON string containing a Forecast object and returns a Forecast instance.", "response": "def parse_JSON(self, JSON_string):\n        \"\"\"\n        Parses a *Forecast* instance out of raw JSON data. Only certain\n        properties of the data are used: if these properties are not found or\n        cannot be parsed, an error is issued.\n\n        :param JSON_string: a raw JSON string\n        :type JSON_string: str\n        :returns: a *Forecast* instance or ``None`` if no data is available\n        :raises: *ParseResponseError* if it is impossible to find or parse the\n            data needed to build the result, *APIResponseError* if the JSON\n            string embeds an HTTP status error\n\n        \"\"\"\n        if JSON_string is None:\n            raise parse_response_error.ParseResponseError('JSON data is None')\n        d = json.loads(JSON_string)\n        # Check if server returned errors: this check overcomes the lack of use\n        # of HTTP error status codes by the OWM API 2.5. This mechanism is\n        # supposed to be deprecated as soon as the API fully adopts HTTP for\n        # conveying errors to the clients\n        if 'message' in d and 'cod' in d:\n            if d['cod'] == \"404\":\n                print(\"OWM API: data not found - response payload: \" + json.dumps(d), d['cod'])\n                return None\n            elif d['cod'] != \"200\":\n                raise api_response_error.APIResponseError(\"OWM API: error - response payload: \" + json.dumps(d), d['cod'])\n        try:\n            place = location.location_from_dictionary(d)\n        except KeyError:\n            raise parse_response_error.ParseResponseError(''.join([__name__,\n                      ': impossible to read location info from JSON data']))\n        # Handle the case when no results are found\n        if 'count' in d and d['count'] == \"0\":\n            weathers = []\n        elif 'cnt' in d and d['cnt'] == 0:\n            weathers = []\n        else:\n            if 'list' in d:\n                try:\n                    weathers = [weather.weather_from_dictionary(item) \\\n                                for item in d['list']]\n                except KeyError:\n                    raise parse_response_error.ParseResponseError(\n                          ''.join([__name__, ': impossible to read weather ' \\\n                                   'info from JSON data'])\n                                  )\n            else:\n                raise parse_response_error.ParseResponseError(\n                          ''.join([__name__, ': impossible to read weather ' \\\n                                   'list from JSON data'])\n                          )\n        current_time = int(round(time.time()))\n        return forecast.Forecast(None, current_time, place, weathers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating a polynomial along specified axes.", "response": "def call(poly, args):\n    \"\"\"\n    Evaluate a polynomial along specified axes.\n\n    Args:\n        poly (Poly):\n            Input polynomial.\n        args (numpy.ndarray):\n            Argument to be evaluated. Masked values keeps the variable intact.\n\n    Returns:\n        (Poly, numpy.ndarray):\n            If masked values are used the Poly is returned. Else an numpy array\n            matching the polynomial's shape is returned.\n    \"\"\"\n    args = list(args)\n\n    # expand args to match dim\n    if len(args) < poly.dim:\n        args = args + [np.nan]*(poly.dim-len(args))\n\n    elif len(args) > poly.dim:\n        raise ValueError(\"too many arguments\")\n\n    # Find and perform substitutions, if any\n    x0, x1 = [], []\n    for idx, arg in enumerate(args):\n\n        if isinstance(arg, Poly):\n            poly_ = Poly({\n                tuple(np.eye(poly.dim)[idx]): np.array(1)\n            })\n            x0.append(poly_)\n            x1.append(arg)\n            args[idx] = np.nan\n    if x0:\n        poly = call(poly, args)\n        return substitute(poly, x0, x1)\n\n    # Create masks\n    masks = np.zeros(len(args), dtype=bool)\n    for idx, arg in enumerate(args):\n        if np.ma.is_masked(arg) or np.any(np.isnan(arg)):\n            masks[idx] = True\n            args[idx] = 0\n\n    shape = np.array(\n        args[\n            np.argmax(\n                [np.prod(np.array(arg).shape) for arg in args]\n            )\n        ]\n    ).shape\n    args = np.array([np.ones(shape, dtype=int)*arg for arg in args])\n\n    A = {}\n    for key in poly.keys:\n\n        key_ = np.array(key)*(1-masks)\n        val = np.outer(poly.A[key], np.prod((args.T**key_).T, \\\n                axis=0))\n        val = np.reshape(val, poly.shape + tuple(shape))\n        val = np.where(val != val, 0, val)\n\n        mkey = tuple(np.array(key)*(masks))\n        if not mkey in A:\n            A[mkey] = val\n        else:\n            A[mkey] = A[mkey] + val\n\n    out = Poly(A, poly.dim, None, None)\n    if out.keys and not np.sum(out.keys):\n        out = out.A[out.keys[0]]\n    elif not out.keys:\n        out = np.zeros(out.shape, dtype=out.dtype)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsubstitute a variable in a polynomial array.", "response": "def substitute(P, x0, x1, V=0):\n    \"\"\"\n    Substitute a variable in a polynomial array.\n\n    Args:\n        P (Poly) : Input data.\n        x0 (Poly, int) : The variable to substitute. Indicated with either unit\n                variable, e.g. `x`, `y`, `z`, etc. or through an integer\n                matching the unit variables dimension, e.g. `x==0`, `y==1`,\n                `z==2`, etc.\n        x1 (Poly) : Simple polynomial to substitute `x0` in `P`. If `x1` is an\n                polynomial array, an error will be raised.\n\n    Returns:\n        (Poly) : The resulting polynomial (array) where `x0` is replaced with\n                `x1`.\n\n    Examples:\n        >>> x,y = cp.variable(2)\n        >>> P = cp.Poly([y*y-1, y*x])\n        >>> print(cp.substitute(P, y, x+1))\n        [q0^2+2q0, q0^2+q0]\n\n        With multiple substitutions:\n        >>> print(cp.substitute(P, [x,y], [y,x]))\n        [q0^2-1, q0q1]\n    \"\"\"\n    x0,x1 = map(Poly, [x0,x1])\n    dim = np.max([p.dim for p in [P,x0,x1]])\n    dtype = chaospy.poly.typing.dtyping(P.dtype, x0.dtype, x1.dtype)\n    P, x0, x1 = [chaospy.poly.dimension.setdim(p, dim) for p in [P,x0,x1]]\n\n    if x0.shape:\n        x0 = [x for x in x0]\n    else:\n        x0 = [x0]\n\n    if x1.shape:\n        x1 = [x for x in x1]\n    else:\n        x1 = [x1]\n\n    # Check if substitution is needed.\n    valid = False\n    C = [x.keys[0].index(1) for x in x0]\n    for key in P.keys:\n        if np.any([key[c] for c in C]):\n            valid = True\n            break\n\n    if not valid:\n        return P\n\n    dims = [tuple(np.array(x.keys[0])!=0).index(True) for x in x0]\n\n    dec = is_decomposed(P)\n    if not dec:\n        P = decompose(P)\n\n    P = chaospy.poly.dimension.dimsplit(P)\n\n    shape = P.shape\n    P = [p for p in chaospy.poly.shaping.flatten(P)]\n\n    for i in range(len(P)):\n        for j in range(len(dims)):\n            if P[i].keys and P[i].keys[0][dims[j]]:\n                P[i] = x1[j].__pow__(P[i].keys[0][dims[j]])\n                break\n\n    P = Poly(P, dim, None, dtype)\n    P = chaospy.poly.shaping.reshape(P, shape)\n    P = chaospy.poly.collection.prod(P, 0)\n\n    if not dec:\n        P = chaospy.poly.collection.sum(P, 0)\n\n    return P"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a polynomial array is on component form.", "response": "def is_decomposed(P):\n    \"\"\"\n    Check if a polynomial (array) is on component form.\n\n    Args:\n        P (Poly):\n            Input data.\n\n    Returns:\n        (bool):\n            True if all polynomials in ``P`` are on component form.\n\n    Examples:\n        >>> x,y = cp.variable(2)\n        >>> print(cp.is_decomposed(cp.Poly([1,x,x*y])))\n        True\n        >>> print(cp.is_decomposed(cp.Poly([x+1,x*y])))\n        False\n    \"\"\"\n    if P.shape:\n        return min([is_decomposed(poly) for poly in P])\n    return len(P.keys) <= 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecomposing a polynomial to component form.", "response": "def decompose(P):\n    \"\"\"\n    Decompose a polynomial to component form.\n\n    In array missing values are padded with 0 to make decomposition compatible\n    with ``chaospy.sum(Q, 0)``.\n\n    Args:\n        P (Poly) : Input data.\n\n    Returns:\n        (Poly) : Decomposed polynomial with `P.shape==(M,)+Q.shape` where\n                `M` is the number of components in `P`.\n\n    Examples:\n        >>> q = cp.variable()\n        >>> P = cp.Poly([q**2-1, 2])\n        >>> print(P)\n        [q0^2-1, 2]\n        >>> print(cp.decompose(P))\n        [[-1, 2], [q0^2, 0]]\n        >>> print(cp.sum(cp.decompose(P), 0))\n        [q0^2-1, 2]\n    \"\"\"\n    P = P.copy()\n\n    if not P:\n        return P\n\n    out = [Poly({key:P.A[key]}) for key in P.keys]\n    return Poly(out, None, None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nevaluates the raw statistical moment of a distribution at a specific location.", "response": "def evaluate_moment(\n        distribution,\n        k_data,\n        parameters=None,\n        cache=None,\n):\n    \"\"\"\n    Evaluate raw statistical moments.\n\n    Args:\n        distribution (Dist):\n            Distribution to evaluate.\n        x_data (numpy.ndarray):\n            Locations for where evaluate moment of.\n        parameters (:py:data:typing.Any):\n            Collection of parameters to override the default ones in the\n            distribution.\n        cache (:py:data:typing.Any):\n            A collection of previous calculations in case the same distribution\n            turns up on more than one occasion.\n\n    Returns:\n        The raw statistical moment of ``distribution`` at location ``x_data``\n        using parameters ``parameters``.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    assert len(k_data) == len(distribution), (\n        \"distribution %s is not of length %d\" % (distribution, len(k_data)))\n    assert len(k_data.shape) == 1\n\n    if numpy.all(k_data == 0):\n        return 1.\n\n    def cache_key(distribution):\n        return (tuple(k_data), distribution)\n\n    if cache is None:\n        cache = {}\n    else:\n        if cache_key(distribution) in cache:\n            return cache[cache_key(distribution)]\n\n    from .. import baseclass\n    try:\n        parameters = load_parameters(\n            distribution, \"_mom\", parameters, cache, cache_key)\n        out = distribution._mom(k_data, **parameters)\n\n    except baseclass.StochasticallyDependentError:\n\n        logger.warning(\n            \"Distribution %s has stochastic dependencies; \"\n            \"Approximating moments with quadrature.\", distribution)\n        from .. import approximation\n        out = approximation.approximate_moment(distribution, k_data)\n\n    if isinstance(out, numpy.ndarray):\n        out = out.item()\n\n    cache[cache_key(distribution)] = out\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new object with the same distribution as the given ones.", "response": "def mul(left, right):\n    \"\"\"\n    Distribution multiplication.\n\n    Args:\n        left (Dist, numpy.ndarray) : left hand side.\n        right (Dist, numpy.ndarray) : right hand side.\n    \"\"\"\n    from .mv_mul import MvMul\n    length = max(left, right)\n    if length == 1:\n        return Mul(left, right)\n    return MvMul(left, right)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npoints percentile function. Example: >>> print(chaospy.Uniform().inv([0.1, 0.2, 0.9])) [0.1 0.2 0.9] >>> print(Mul(chaospy.Uniform(), 2).inv([0.1, 0.2, 0.9])) [0.2 0.4 1.8] >>> print(Mul(2, chaospy.Uniform()).inv([0.1, 0.2, 0.9])) [0.2 0.4 1.8] >>> print(Mul(2, 2).inv([0.1, 0.2, 0.9])) [4. 4. 4.] >>> dist = chaospy.Mul([2, 1], chaospy.Iid(chaospy.Uniform(), 2)) >>> print(dist.inv([[0.5, 0.6, 0.7], [0.5, 0.6, 0.7]])) [[1. 1.2 1.4] [0.5 0.6 0.7]] >>> dist = chaospy.Mul(chaospy.Iid(chaospy.Uniform(), 2), [1, 2]) >>> print(dist.inv([[0.5, 0.6, 0.7], [0.5, 0.6, 0.7]])) [[0.5 0.6 0.7] [1. 1.2 1.4]]", "response": "def _ppf(self, uloc, left, right, cache):\n        \"\"\"\n        Point percentile function.\n\n        Example:\n            >>> print(chaospy.Uniform().inv([0.1, 0.2, 0.9]))\n            [0.1 0.2 0.9]\n            >>> print(Mul(chaospy.Uniform(), 2).inv([0.1, 0.2, 0.9]))\n            [0.2 0.4 1.8]\n            >>> print(Mul(2, chaospy.Uniform()).inv([0.1, 0.2, 0.9]))\n            [0.2 0.4 1.8]\n            >>> print(Mul(2, 2).inv([0.1, 0.2, 0.9]))\n            [4. 4. 4.]\n            >>> dist = chaospy.Mul([2, 1], chaospy.Iid(chaospy.Uniform(), 2))\n            >>> print(dist.inv([[0.5, 0.6, 0.7], [0.5, 0.6, 0.7]]))\n            [[1.  1.2 1.4]\n             [0.5 0.6 0.7]]\n            >>> dist = chaospy.Mul(chaospy.Iid(chaospy.Uniform(), 2), [1, 2])\n            >>> print(dist.inv([[0.5, 0.6, 0.7], [0.5, 0.6, 0.7]]))\n            [[0.5 0.6 0.7]\n             [1.  1.2 1.4]]\n        \"\"\"\n        left = evaluation.get_inverse_cache(left, cache)\n        right = evaluation.get_inverse_cache(right, cache)\n\n        if isinstance(left, Dist):\n            if isinstance(right, Dist):\n                raise evaluation.DependencyError(\n                    \"under-defined distribution {} or {}\".format(left, right))\n        elif not isinstance(right, Dist):\n            if self.matrix:\n                return numpy.dot(left, right)\n            return left*right\n\n        else:\n            if not self.matrix:\n                uloc = numpy.where(numpy.asfarray(left).T > 0, uloc.T, 1-uloc.T).T\n            xloc = evaluation.evaluate_inverse(right, uloc, cache=cache)\n            if self.matrix:\n                xloc = numpy.dot(left, xloc)\n            else:\n                xloc *= left\n            return xloc\n\n        if not self.matrix:\n            uloc = numpy.where(numpy.asfarray(right).T > 0, uloc.T, 1-uloc.T).T\n        xloc = evaluation.evaluate_inverse(left, uloc, cache=cache)\n        if self.matrix:\n            xloc = numpy.dot(xloc.T, right).T\n        else:\n            xloc *= right\n        assert uloc.shape == xloc.shape\n        return xloc"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _mom(self, key, left, right, cache):\n        if evaluation.get_dependencies(left, right):\n            raise evaluation.DependencyError(\n                \"sum of dependent distributions not feasible: \"\n                \"{} and {}\".format(left, right)\n            )\n\n        if isinstance(left, Dist):\n            left = evaluation.evaluate_moment(left, key, cache=cache)\n        else:\n            left = (numpy.array(left).T**key).T\n        if isinstance(right, Dist):\n            right = evaluation.evaluate_moment(right, key, cache=cache)\n        else:\n            right = (numpy.array(right).T**key).T\n        return numpy.sum(left*right)", "response": "Evaluates the statistical moments of a single object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sorted_dependencies(dist, reverse=False):\n    from .. import baseclass\n\n    collection = [dist]\n\n    # create DAG as list of nodes and edges:\n    nodes = [dist]\n    edges = []\n    pool = [dist]\n    while pool:\n        dist = pool.pop()\n        for key in sorted(dist.prm):\n            value = dist.prm[key]\n            if not isinstance(value, baseclass.Dist):\n                continue\n            if (dist, value) not in edges:\n                edges.append((dist, value))\n            if value not in nodes:\n                nodes.append(value)\n                pool.append(value)\n\n    # temporary stores used by depth first algorith.\n    permanent_marks = set()\n    temporary_marks = set()\n\n    def visit(node):\n        \"\"\"Depth-first topological sort algorithm.\"\"\"\n        if node in permanent_marks:\n            return\n        if node in temporary_marks:\n            raise DependencyError(\"cycles in dependency structure.\")\n\n        nodes.remove(node)\n        temporary_marks.add(node)\n\n        for node1, node2 in edges:\n            if node1 is node:\n                visit(node2)\n\n        temporary_marks.remove(node)\n        permanent_marks.add(node)\n        pool.append(node)\n\n    # kickstart algorithm.\n    while nodes:\n        node = nodes[0]\n        visit(node)\n\n    if not reverse:\n        pool = list(reversed(pool))\n\n    return pool", "response": "Returns a list of all underlying dependencies from a distribution sorted by topologically."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dependencies(*distributions):\n    from .. import baseclass\n    distributions = [\n        sorted_dependencies(dist) for dist in distributions\n        if isinstance(dist, baseclass.Dist)\n    ]\n\n    dependencies = list()\n    for idx, dist1 in enumerate(distributions):\n        for dist2 in distributions[idx+1:]:\n            dependencies.extend([dist for dist in dist1 if dist in dist2])\n\n    return sorted(dependencies)", "response": "Returns a list of underlying dependencies that are shared between two distributions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef orth_ttr(\n        order, dist, normed=False, sort=\"GR\", retall=False,\n        cross_truncation=1., **kws):\n    \"\"\"\n    Create orthogonal polynomial expansion from three terms recursion formula.\n\n    Args:\n        order (int):\n            Order of polynomial expansion.\n        dist (Dist):\n            Distribution space where polynomials are orthogonal If dist.ttr\n            exists, it will be used. Must be stochastically independent.\n        normed (bool):\n            If True orthonormal polynomials will be used.\n        sort (str):\n            Polynomial sorting. Same as in basis.\n        retall (bool):\n            If true return numerical stabilized norms as well. Roughly the same\n            as ``cp.E(orth**2, dist)``.\n        cross_truncation (float):\n            Use hyperbolic cross truncation scheme to reduce the number of\n            terms in expansion. only include terms where the exponents ``K``\n            satisfied the equation\n            ``order >= sum(K**(1/cross_truncation))**cross_truncation``.\n\n    Returns:\n        (Poly, numpy.ndarray):\n            Orthogonal polynomial expansion and norms of the orthogonal\n            expansion on the form ``E(orth**2, dist)``. Calculated using\n            recurrence coefficients for stability.\n\n    Examples:\n        >>> Z = chaospy.Normal()\n        >>> print(chaospy.around(chaospy.orth_ttr(4, Z), 4))\n        [1.0, q0, q0^2-1.0, q0^3-3.0q0, q0^4-6.0q0^2+3.0]\n    \"\"\"\n    polynomials, norms, _, _ = chaospy.quad.generate_stieltjes(\n        dist=dist, order=numpy.max(order), retall=True, **kws)\n\n    if normed:\n        for idx, poly in enumerate(polynomials):\n            polynomials[idx] = poly / numpy.sqrt(norms[:, idx])\n        norms = norms**0\n\n    dim = len(dist)\n    if dim > 1:\n        mv_polynomials = []\n        mv_norms = []\n        indices = chaospy.bertran.bindex(\n            start=0, stop=order, dim=dim, sort=sort,\n            cross_truncation=cross_truncation,\n        )\n\n        for index in indices:\n            poly = polynomials[index[0]][0]\n            for idx in range(1, dim):\n                poly = poly * polynomials[index[idx]][idx]\n            mv_polynomials.append(poly)\n\n        if retall:\n            for index in indices:\n                mv_norms.append(\n                    numpy.prod([norms[idx, index[idx]] for idx in range(dim)]))\n\n    else:\n        mv_norms = norms[0]\n        mv_polynomials = polynomials\n\n    polynomials = chaospy.poly.flatten(chaospy.poly.Poly(mv_polynomials))\n\n    if retall:\n        return polynomials, numpy.array(mv_norms)\n    return polynomials", "response": "Return the orthogonal polynomial expansion of the given order and distribution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate the probability density function.", "response": "def _pdf(self, xloc, dist, cache):\n        \"\"\"Probability density function.\"\"\"\n        return evaluation.evaluate_density(dist, -xloc, cache=cache)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ttr(self, k, dist, cache):\n        a,b = evaluation.evaluate_recurrence_coefficients(dist, k)\n        return -a, b", "response": "Three terms recursion coefficients."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef quad_genz_keister_22 ( order ):\n    order = sorted(GENZ_KEISTER_22.keys())[order]\n\n    abscissas, weights = GENZ_KEISTER_22[order]\n    abscissas = numpy.array(abscissas)\n    weights = numpy.array(weights)\n\n    weights /= numpy.sum(weights)\n    abscissas *= numpy.sqrt(2)\n\n    return abscissas, weights", "response": "Function that returns the abscissas and weights for a single entry in the hierarchy of genz - keister 22 rule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nidentify the polynomial argument.", "response": "def identify_core(core):\n    \"\"\"Identify the polynomial argument.\"\"\"\n    for datatype, identifier in {\n            int: _identify_scaler,\n            numpy.int8: _identify_scaler,\n            numpy.int16: _identify_scaler,\n            numpy.int32: _identify_scaler,\n            numpy.int64: _identify_scaler,\n            float: _identify_scaler,\n            numpy.float16: _identify_scaler,\n            numpy.float32: _identify_scaler,\n            numpy.float64: _identify_scaler,\n            chaospy.poly.base.Poly: _identify_poly,\n            dict: _identify_dict,\n            numpy.ndarray: _identify_iterable,\n            list: _identify_iterable,\n            tuple: _identify_iterable,\n    }.items():\n        if isinstance(core, datatype):\n            return identifier(core)\n\n    raise TypeError(\n        \"Poly arg: 'core' is not a valid type \" + repr(core))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _identify_poly(core):\n    return core.A, core.dim, core.shape, core.dtype", "response": "Specification for a polynomial."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _identify_iterable(core):\n    if isinstance(core, numpy.ndarray) and not core.shape:\n        return {(0,):core}, 1, (), core.dtype\n\n    core = [chaospy.poly.base.Poly(a) for a in core]\n    shape = (len(core),) + core[0].shape\n\n    dtype = chaospy.poly.typing.dtyping(*[_.dtype for _ in core])\n\n    dims = numpy.array([a.dim for a in core])\n    dim = numpy.max(dims)\n    if dim != numpy.min(dims):\n        core = [chaospy.poly.dimension.setdim(a, dim) for a in core]\n\n    out = {}\n    for idx, core_ in enumerate(core):\n\n        for key in core_.keys:\n\n            if not key in out:\n                out[key] = numpy.zeros(shape, dtype=dtype)\n            out[key][idx] = core_.A[key]\n\n    return out, dim, shape, dtype", "response": "Specification for a list tuple numpy. ndarray."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Corr(poly, dist=None, **kws):\n    if isinstance(poly, distributions.Dist):\n        poly, dist = polynomials.variable(len(poly)), poly\n    else:\n        poly = polynomials.Poly(poly)\n\n    cov = Cov(poly, dist, **kws)\n    var = numpy.diag(cov)\n    vvar = numpy.sqrt(numpy.outer(var, var))\n    return numpy.where(vvar > 0, cov/vvar, 0)", "response": "Returns the correlation matrix of a single element in a set of two - dimensional polynomials."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Skew(poly, dist=None, **kws):\n    if isinstance(poly, distributions.Dist):\n        x = polynomials.variable(len(poly))\n        poly, dist = x, poly\n    else:\n        poly = polynomials.Poly(poly)\n\n    if poly.dim < len(dist):\n        polynomials.setdim(poly, len(dist))\n\n    shape = poly.shape\n    poly = polynomials.flatten(poly)\n\n    m1 = E(poly, dist)\n    m2 = E(poly**2, dist)\n    m3 = E(poly**3, dist)\n    out = (m3-3*m2*m1+2*m1**3)/(m2-m1**2)**1.5\n\n    out = numpy.reshape(out, shape)\n    return out", "response": "Skewness operator.\n\n    Element by element 3rd order statistics of a distribution or polynomial.\n\n    Args:\n        poly (Poly, Dist):\n            Input to take skewness on.\n        dist (Dist):\n            Defines the space the skewness is taken on. It is ignored if\n            ``poly`` is a distribution.\n\n    Returns:\n        (numpy.ndarray):\n            Element for element variance along ``poly``, where\n            ``skewness.shape == poly.shape``.\n\n    Examples:\n        >>> dist = chaospy.J(chaospy.Gamma(1, 1), chaospy.Normal(0, 2))\n        >>> print(chaospy.Skew(dist))\n        [2. 0.]\n        >>> x, y = chaospy.variable(2)\n        >>> poly = chaospy.Poly([1, x, y, 10*x*y])\n        >>> print(chaospy.Skew(poly, dist))\n        [nan  2.  0.  0.]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nevaluate the forward Rosenblatt transformation at the given locations.", "response": "def evaluate_forward(\n        distribution,\n        x_data,\n        parameters=None,\n        cache=None,\n):\n    \"\"\"\n    Evaluate forward Rosenblatt transformation.\n\n    Args:\n        distribution (Dist):\n            Distribution to evaluate.\n        x_data (numpy.ndarray):\n            Locations for where evaluate forward transformation at.\n        parameters (:py:data:typing.Any):\n            Collection of parameters to override the default ones in the\n            distribution.\n        cache (:py:data:typing.Any):\n            A collection of previous calculations in case the same distribution\n            turns up on more than one occasion.\n\n    Returns:\n        The cumulative distribution values of ``distribution`` at location\n        ``x_data`` using parameters ``parameters``.\n    \"\"\"\n    assert len(x_data) == len(distribution), (\n        \"distribution %s is not of length %d\" % (distribution, len(x_data)))\n    assert hasattr(distribution, \"_cdf\"), (\n        \"distribution require the `_cdf` method to function.\")\n\n    cache = cache if cache is not None else {}\n\n    parameters = load_parameters(\n        distribution, \"_cdf\", parameters=parameters, cache=cache)\n\n    # Store cache.\n    cache[distribution] = x_data\n\n    # Evaluate forward function.\n    out = numpy.zeros(x_data.shape)\n    out[:] = distribution._cdf(x_data, **parameters)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Var(poly, dist=None, **kws):\n    if isinstance(poly, distributions.Dist):\n        x = polynomials.variable(len(poly))\n        poly, dist = x, poly\n    else:\n        poly = polynomials.Poly(poly)\n\n    dim = len(dist)\n    if poly.dim<dim:\n        polynomials.setdim(poly, dim)\n\n    shape = poly.shape\n    poly = polynomials.flatten(poly)\n\n    keys = poly.keys\n    N = len(keys)\n    A = poly.A\n\n    keys1 = numpy.array(keys).T\n    if dim==1:\n        keys1 = keys1[0]\n        keys2 = sum(numpy.meshgrid(keys, keys))\n    else:\n        keys2 = numpy.empty((dim, N, N))\n        for i in range(N):\n            for j in range(N):\n                keys2[:, i, j] = keys1[:, i]+keys1[:, j]\n\n    m1 = numpy.outer(*[dist.mom(keys1, **kws)]*2)\n    m2 = dist.mom(keys2, **kws)\n    mom = m2-m1\n\n    out = numpy.zeros(poly.shape)\n    for i in range(N):\n        a = A[keys[i]]\n        out += a*a*mom[i, i]\n        for j in range(i+1, N):\n            b = A[keys[j]]\n            out += 2*a*b*mom[i, j]\n\n    out = out.reshape(shape)\n    return out", "response": "Return a 2nd order statistics of the variance of a 2nd order array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an expected value of a given polynomial or distribution.", "response": "def E(poly, dist=None, **kws):\n    \"\"\"\n    Expected value operator.\n\n    1st order statistics of a probability distribution or polynomial on a given\n    probability space.\n\n    Args:\n        poly (Poly, Dist):\n            Input to take expected value on.\n        dist (Dist):\n            Defines the space the expected value is taken on. It is ignored if\n            ``poly`` is a distribution.\n\n    Returns:\n        (numpy.ndarray):\n            The expected value of the polynomial or distribution, where\n            ``expected.shape == poly.shape``.\n\n    Examples:\n        >>> dist = chaospy.J(chaospy.Gamma(1, 1), chaospy.Normal(0, 2))\n        >>> print(chaospy.E(dist))\n        [1. 0.]\n        >>> x, y = chaospy.variable(2)\n        >>> poly = chaospy.Poly([1, x, y, 10*x*y])\n        >>> print(chaospy.E(poly, dist))\n        [1. 1. 0. 0.]\n    \"\"\"\n    if not isinstance(poly, (distributions.Dist, polynomials.Poly)):\n        print(type(poly))\n        print(\"Approximating expected value...\")\n        out = quadrature.quad(poly, dist, veceval=True, **kws)\n        print(\"done\")\n        return out\n\n    if isinstance(poly, distributions.Dist):\n        dist, poly = poly, polynomials.variable(len(poly))\n\n    if not poly.keys:\n        return numpy.zeros(poly.shape, dtype=int)\n\n    if isinstance(poly, (list, tuple, numpy.ndarray)):\n        return [E(_, dist, **kws) for _ in poly]\n\n    if poly.dim < len(dist):\n        poly = polynomials.setdim(poly, len(dist))\n\n    shape = poly.shape\n    poly = polynomials.flatten(poly)\n\n    keys = poly.keys\n    mom = dist.mom(numpy.array(keys).T, **kws)\n    A = poly.A\n\n    if len(dist) == 1:\n        mom = mom[0]\n\n    out = numpy.zeros(poly.shape)\n    for i in range(len(keys)):\n        out += A[keys[i]]*mom[i]\n\n    out = numpy.reshape(out, shape)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the sensitivity indices for each parameter in a set of parameters in a set of distributions.", "response": "def Sens_m2(poly, dist, **kws):\n    \"\"\"\n    Variance-based decomposition/Sobol' indices.\n\n    Second order sensitivity indices.\n\n    Args:\n        poly (Poly):\n            Polynomial to find second order Sobol indices on.\n        dist (Dist):\n            The distributions of the input used in ``poly``.\n\n    Returns:\n        (numpy.ndarray):\n            First order sensitivity indices for each parameters in ``poly``,\n            with shape ``(len(dist), len(dist)) + poly.shape``.\n\n    Examples:\n        >>> x, y = chaospy.variable(2)\n        >>> poly = chaospy.Poly([1, x*y, x*x*y*y, x*y*y*y])\n        >>> dist = chaospy.Iid(chaospy.Uniform(0, 1), 2)\n        >>> indices = chaospy.Sens_m2(poly, dist)\n        >>> print(indices)\n        [[[0.         0.         0.         0.        ]\n          [0.         0.14285714 0.28571429 0.20930233]]\n        <BLANKLINE>\n         [[0.         0.14285714 0.28571429 0.20930233]\n          [0.         0.         0.         0.        ]]]\n    \"\"\"\n    dim = len(dist)\n    if poly.dim<dim:\n        poly = chaospy.poly.setdim(poly, len(dist))\n\n    zero = [0]*dim\n    out = numpy.zeros((dim, dim) + poly.shape)\n\n    mean = E(poly, dist)\n    V_total = Var(poly, dist)\n    E_cond_i = [None]*dim\n    V_E_cond_i = [None]*dim\n    for i in range(dim):\n        zero[i] = 1\n        E_cond_i[i] = E_cond(poly, zero, dist, **kws) \n        V_E_cond_i[i] = Var(E_cond_i[i], dist, **kws)\n        zero[i] = 0\n\n    for i in range(dim):\n\n        zero[i] = 1\n        for j in range(i+1, dim):\n\n            zero[j] = 1\n            E_cond_ij = E_cond(poly, zero, dist, **kws)\n            out[i, j] = ((Var(E_cond_ij, dist, **kws)-V_E_cond_i[i] - V_E_cond_i[j]) /\n                         (V_total+(V_total == 0))*(V_total != 0))\n            out[j, i] = out[i, j]\n            zero[j] = 0\n\n        zero[i] = 0\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a Chebyshev sampling function.", "response": "def create_chebyshev_samples(order, dim=1):\n    \"\"\"\n    Chebyshev sampling function.\n\n    Args:\n        order (int):\n            The number of samples to create along each axis.\n        dim (int):\n            The number of dimensions to create samples for.\n\n    Returns:\n        samples following Chebyshev sampling scheme mapped to the\n        ``[0, 1]^dim`` hyper-cube and ``shape == (dim, order)``.\n    \"\"\"\n    x_data = .5*numpy.cos(numpy.arange(order, 0, -1)*numpy.pi/(order+1)) + .5\n    x_data = chaospy.quad.combine([x_data]*dim)\n    return x_data.T"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates orthogonal polynomial expansion from Cholesky decomposition.", "response": "def orth_chol(order, dist, normed=True, sort=\"GR\", cross_truncation=1., **kws):\n    \"\"\"\n    Create orthogonal polynomial expansion from Cholesky decomposition.\n\n    Args:\n        order (int):\n            Order of polynomial expansion\n        dist (Dist):\n            Distribution space where polynomials are orthogonal\n        normed (bool):\n            If True orthonormal polynomials will be used instead of monic.\n        sort (str):\n            Ordering argument passed to poly.basis.  If custom basis is used,\n            argument is ignored.\n        cross_truncation (float):\n            Use hyperbolic cross truncation scheme to reduce the number of\n            terms in expansion.\n\n    Examples:\n        >>> Z = chaospy.Normal()\n        >>> print(chaospy.around(chaospy.orth_chol(3, Z), 4))\n        [1.0, q0, 0.7071q0^2-0.7071, 0.4082q0^3-1.2247q0]\n    \"\"\"\n    dim = len(dist)\n    basis = chaospy.poly.basis(\n        start=1, stop=order, dim=dim, sort=sort,\n        cross_truncation=cross_truncation,\n    )\n    length = len(basis)\n\n    cholmat = chaospy.chol.gill_king(chaospy.descriptives.Cov(basis, dist))\n    cholmat_inv = numpy.linalg.inv(cholmat.T).T\n    if not normed:\n        diag_mesh = numpy.repeat(numpy.diag(cholmat_inv), len(cholmat_inv))\n        cholmat_inv /= diag_mesh.reshape(cholmat_inv.shape)\n\n    coefs = numpy.empty((length+1, length+1))\n\n    coefs[1:, 1:] = cholmat_inv\n    coefs[0, 0] = 1\n    coefs[0, 1:] = 0\n\n    expected = -numpy.sum(\n        cholmat_inv*chaospy.descriptives.E(basis, dist, **kws), -1)\n    coefs[1:, 0] = expected\n\n    coefs = coefs.T\n\n    out = {}\n    out[(0,)*dim] = coefs[0]\n    for idx in range(length):\n        index = basis[idx].keys[0]\n        out[index] = coefs[idx+1]\n\n    polynomials = chaospy.poly.Poly(out, dim, coefs.shape[1:], float)\n\n    return polynomials"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dimsplit(P):\n    P = P.copy()\n\n    if not chaospy.poly.caller.is_decomposed(P):\n        raise TypeError(\"Polynomial not on component form.\")\n    A = []\n\n    dim = P.dim\n    coef = P(*(1,)*dim)\n    M = coef!=0\n    zero = (0,)*dim\n    ones = [1]*dim\n    A = [{zero: coef}]\n\n    if zero in P.A:\n\n        del P.A[zero]\n        P.keys.remove(zero)\n\n    for key in P.keys:\n        P.A[key] = (P.A[key]!=0)\n\n    for i in range(dim):\n\n        A.append({})\n        ones[i] = numpy.nan\n        Q = P(*ones)\n        ones[i] = 1\n        if isinstance(Q, numpy.ndarray):\n            continue\n        Q = Q.A\n\n        if zero in Q:\n            del Q[zero]\n\n        for key in Q:\n\n            val = Q[key]\n            A[-1][key] = val\n\n    A = [Poly(a, dim, None, P.dtype) for a in A]\n    P = Poly(A, dim, None, P.dtype)\n    P = P + 1*(P(*(1,)*dim)==0)*M\n\n    return P", "response": "This function splits a polynomial into a set of segments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setdim(P, dim=None):\n    P = P.copy()\n\n    ldim = P.dim\n    if not dim:\n        dim = ldim+1\n\n    if dim==ldim:\n        return P\n\n    P.dim = dim\n    if dim>ldim:\n\n        key = numpy.zeros(dim, dtype=int)\n        for lkey in P.keys:\n            key[:ldim] = lkey\n            P.A[tuple(key)] = P.A.pop(lkey)\n\n    else:\n\n        key = numpy.zeros(dim, dtype=int)\n        for lkey in P.keys:\n            if not sum(lkey[ldim-1:]) or not sum(lkey):\n                P.A[lkey[:dim]] = P.A.pop(lkey)\n            else:\n                del P.A[lkey]\n\n    P.keys = sorted(P.A.keys(), key=sort_key)\n    return P", "response": "Adjust the dimensions of a polynomial."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gill_murray_wright(mat, eps=1e-16):\n    mat = numpy.asfarray(mat)\n    size = mat.shape[0]\n\n    # Calculate gamma(mat) and xi_(mat).\n    gamma = 0.0\n    xi_ = 0.0\n    for idy in range(size):\n        gamma = max(abs(mat[idy, idy]), gamma)\n        for idx in range(idy+1, size):\n            xi_ = max(abs(mat[idy, idx]), xi_)\n\n    # Calculate delta and beta.\n    delta = eps * max(gamma + xi_, 1.0)\n    if size == 1:\n        beta = numpy.sqrt(max(gamma, eps))\n    else:\n        beta = numpy.sqrt(max(gamma, xi_ / numpy.sqrt(size*size - 1.0), eps))\n\n    # Initialise data structures.\n    mat_a = 1.0 * mat\n    mat_r = 0.0 * mat\n    perm = numpy.eye(size, dtype=int)\n\n    # Main loop.\n    for idx in range(size):\n\n        # Row and column swapping, find the index > idx of the largest\n        # idzgonal element.\n        idz = idx\n        for idy in range(idx+1, size):\n            if abs(mat_a[idy, idy]) >= abs(mat_a[idz, idz]):\n                idz = idy\n\n        if idz != idx:\n            mat_a, mat_r, perm = swap_across(idz, idx, mat_a, mat_r, perm)\n\n        # Calculate a_pred.\n        theta_j = 0.0\n        if idx < size-1:\n            for idy in range(idx+1, size):\n                theta_j = max(theta_j, abs(mat_a[idx, idy]))\n        a_pred = max(abs(mat_a[idx, idx]), (theta_j/beta)**2, delta)\n\n        # Calculate row idx of r and update a.\n        mat_r[idx, idx] = numpy.sqrt(a_pred)\n        for idy in range(idx+1, size):\n            mat_r[idx, idy] = mat_a[idx, idy] / mat_r[idx, idx]\n            for idz in range(idx+1, idy+1):\n\n                # Keep matrix a symmetric:\n                mat_a[idy, idz] = mat_a[idz, idy] = \\\n                    mat_a[idz, idy] - mat_r[idx, idy] * mat_r[idx, idz]\n\n    # The Cholesky factor of mat.\n    return perm, mat_r.T", "response": "Gill - Murray - Wright algorithm for pivoting modified Cholesky decomposition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninterchange row and column idy and idx.", "response": "def swap_across(idx, idy, mat_a, mat_r, perm):\n    \"\"\"Interchange row and column idy and idx.\"\"\"\n    # Temporary permutation matrix for swaping 2 rows or columns.\n    size = mat_a.shape[0]\n    perm_new = numpy.eye(size, dtype=int)\n\n    # Modify the permutation matrix perm by swaping columns.\n    perm_row = 1.0*perm[:, idx]\n    perm[:, idx] = perm[:, idy]\n    perm[:, idy] = perm_row\n\n    # Modify the permutation matrix p by swaping rows (same as\n    # columns because p = pT).\n    row_p = 1.0 * perm_new[idx]\n    perm_new[idx] = perm_new[idy]\n    perm_new[idy] = row_p\n\n    # Permute mat_a and r (p = pT).\n    mat_a = numpy.dot(perm_new, numpy.dot(mat_a, perm_new))\n    mat_r = numpy.dot(mat_r, perm_new)\n    return mat_a, mat_r, perm"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a Halton sequence with samples along each axis.", "response": "def create_halton_samples(order, dim=1, burnin=-1, primes=()):\n    \"\"\"\n    Create Halton sequence.\n\n    For ``dim == 1`` the sequence falls back to Van Der Corput sequence.\n\n    Args:\n        order (int):\n            The order of the Halton sequence. Defines the number of samples.\n        dim (int):\n            The number of dimensions in the Halton sequence.\n        burnin (int):\n            Skip the first ``burnin`` samples. If negative, the maximum of\n            ``primes`` is used.\n        primes (tuple):\n            The (non-)prime base to calculate values along each axis. If\n            empty, growing prime values starting from 2 will be used.\n\n    Returns (numpy.ndarray):\n        Halton sequence with ``shape == (dim, order)``.\n    \"\"\"\n    primes = list(primes)\n    if not primes:\n        prime_order = 10*dim\n        while len(primes) < dim:\n            primes = create_primes(prime_order)\n            prime_order *= 2\n    primes = primes[:dim]\n    assert len(primes) == dim, \"not enough primes\"\n\n    if burnin < 0:\n        burnin = max(primes)\n\n    out = numpy.empty((dim, order))\n    indices = [idx+burnin for idx in range(order)]\n    for dim_ in range(dim):\n        out[dim_] = create_van_der_corput_samples(\n            indices, number_base=primes[dim_])\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the upper and lower bounds of a random sample of the class.", "response": "def range(self, x_data=None):\n        \"\"\"\n        Generate the upper and lower bounds of a distribution.\n\n        Args:\n            x_data (numpy.ndarray) :\n                The bounds might vary over the sample space. By providing\n                x_data you can specify where in the space the bound should be\n                taken.  If omitted, a (pseudo-)random sample is used.\n\n        Returns:\n            (numpy.ndarray):\n                The lower (out[0]) and upper (out[1]) bound where\n                out.shape=(2,)+x_data.shape\n        \"\"\"\n        if x_data is None:\n            try:\n                x_data = evaluation.evaluate_inverse(\n                    self, numpy.array([[0.5]]*len(self)))\n            except StochasticallyDependentError:\n                x_data = approximation.find_interior_point(self)\n            shape = (len(self),)\n            if hasattr(self, \"_range\"):\n                return self._range(x_data, {})\n        else:\n            x_data = numpy.asfarray(x_data)\n            shape = x_data.shape\n            x_data = x_data.reshape(len(self), -1)\n\n        q_data = evaluation.evaluate_bound(self, x_data)\n        q_data = q_data.reshape((2,)+shape)\n        return q_data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fwd(self, x_data):\n        x_data = numpy.asfarray(x_data)\n        shape = x_data.shape\n        x_data = x_data.reshape(len(self), -1)\n\n        lower, upper = evaluation.evaluate_bound(self, x_data)\n        q_data = numpy.zeros(x_data.shape)\n        indices = x_data > upper\n        q_data[indices] = 1\n        indices = ~indices & (x_data >= lower)\n\n        q_data[indices] = numpy.clip(evaluation.evaluate_forward(\n            self, x_data), a_min=0, a_max=1)[indices]\n\n        q_data = q_data.reshape(shape)\n        return q_data", "response": "Forward Rosenblatt transformation.\n\n        Args:\n            x_data (numpy.ndarray):\n                Location for the distribution function. ``x_data.shape`` must\n                be compatible with distribution shape.\n\n        Returns:\n            (numpy.ndarray):\n                Evaluated distribution function values, where\n                ``out.shape==x_data.shape``."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cdf(self, x_data):\n        if len(self) > 1 and evaluation.get_dependencies(*self):\n            raise StochasticallyDependentError(\n                \"Cumulative distribution does not support dependencies.\")\n        q_data = self.fwd(x_data)\n        if len(self) > 1:\n            q_data = numpy.prod(q_data, 0)\n        return q_data", "response": "Returns the cumulative distribution function of the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inv(self, q_data, max_iterations=100, tollerance=1e-5):\n        q_data = numpy.asfarray(q_data)\n        assert numpy.all((q_data >= 0) & (q_data <= 1)), \"sanitize your inputs!\"\n        shape = q_data.shape\n        q_data = q_data.reshape(len(self), -1)\n        x_data = evaluation.evaluate_inverse(self, q_data)\n        lower, upper = evaluation.evaluate_bound(self, x_data)\n        x_data = numpy.clip(x_data, a_min=lower, a_max=upper)\n        x_data = x_data.reshape(shape)\n        return x_data", "response": "Inverse Rosenblatt transformation.\n\n        If possible the transformation is done analytically. If not possible,\n        transformation is approximated using an algorithm that alternates\n        between Newton-Raphson and binary search.\n\n        Args:\n            q_data (numpy.ndarray):\n                Probabilities to be inverse. If any values are outside ``[0,\n                1]``, error will be raised. ``q_data.shape`` must be compatible\n                with distribution shape.\n            max_iterations (int):\n                If approximation is used, this sets the maximum number of\n                allowed iterations in the Newton-Raphson algorithm.\n            tollerance (float):\n                If approximation is used, this set the error tolerance level\n                required to define a sample as converged.\n\n        Returns:\n            (numpy.ndarray):\n                Inverted probability values where\n                ``out.shape == q_data.shape``."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the density function of the Rosenblatt distribution.", "response": "def pdf(self, x_data, step=1e-7):\n        \"\"\"\n        Probability density function.\n\n        If possible the density will be calculated analytically. If not\n        possible, it will be approximated by approximating the one-dimensional\n        derivative of the forward Rosenblatt transformation and multiplying the\n        component parts. Note that even if the distribution is multivariate,\n        each component of the Rosenblatt is one-dimensional.\n\n        Args:\n            x_data (numpy.ndarray):\n                Location for the density function. ``x_data.shape`` must be\n                compatible with distribution shape.\n            step (float, numpy.ndarray):\n                If approximation is used, the step length given in the\n                approximation of the derivative. If array provided, elements\n                are used along each axis.\n\n        Returns:\n            (numpy.ndarray):\n                Evaluated density function values. Shapes are related through\n                the identity ``x_data.shape == dist.shape+out.shape``.\n        \"\"\"\n        x_data = numpy.asfarray(x_data)\n        shape = x_data.shape\n        x_data = x_data.reshape(len(self), -1)\n\n        lower, upper = evaluation.evaluate_bound(self, x_data)\n        f_data = numpy.zeros(x_data.shape)\n        indices = (x_data <= upper) & (x_data >= lower)\n        f_data[indices] = evaluation.evaluate_density(self, x_data)[indices]\n        f_data = f_data.reshape(shape)\n        if len(self) > 1:\n            f_data = numpy.prod(f_data, 0)\n        return f_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a random set of random integers from the current hypercube.", "response": "def sample(self, size=(), rule=\"R\", antithetic=None):\n        \"\"\"\n        Create pseudo-random generated samples.\n\n        By default, the samples are created using standard (pseudo-)random\n        samples. However, if needed, the samples can also be created by either\n        low-discrepancy sequences, and/or variance reduction techniques.\n\n        Changing the sampling scheme, use the following ``rule`` flag:\n\n        +-------+-------------------------------------------------+\n        | key   | Description                                     |\n        +=======+=================================================+\n        | ``C`` | Roots of the first order Chebyshev polynomials. |\n        +-------+-------------------------------------------------+\n        | ``NC``| Chebyshev nodes adjusted to ensure nested.      |\n        +-------+-------------------------------------------------+\n        | ``K`` | Korobov lattice.                                |\n        +-------+-------------------------------------------------+\n        | ``R`` | Classical (Pseudo-)Random samples.              |\n        +-------+-------------------------------------------------+\n        | ``RG``| Regular spaced grid.                            |\n        +-------+-------------------------------------------------+\n        | ``NG``| Nested regular spaced grid.                     |\n        +-------+-------------------------------------------------+\n        | ``L`` | Latin hypercube samples.                        |\n        +-------+-------------------------------------------------+\n        | ``S`` | Sobol low-discrepancy sequence.                 |\n        +-------+-------------------------------------------------+\n        | ``H`` | Halton low-discrepancy sequence.                |\n        +-------+-------------------------------------------------+\n        | ``M`` | Hammersley low-discrepancy sequence.            |\n        +-------+-------------------------------------------------+\n\n        All samples are created on the ``[0, 1]``-hypercube, which then is\n        mapped into the domain of the distribution using the inverse Rosenblatt\n        transformation.\n\n        Args:\n            size (numpy.ndarray):\n                The size of the samples to generate.\n            rule (str):\n                Indicator defining the sampling scheme.\n            antithetic (bool, numpy.ndarray):\n                If provided, will be used to setup antithetic variables. If\n                array, defines the axes to mirror.\n\n        Returns:\n            (numpy.ndarray):\n                Random samples with shape ``(len(self),)+self.shape``.\n        \"\"\"\n        size_ = numpy.prod(size, dtype=int)\n        dim = len(self)\n        if dim > 1:\n            if isinstance(size, (tuple, list, numpy.ndarray)):\n                shape = (dim,) + tuple(size)\n            else:\n                shape = (dim, size)\n        else:\n            shape = size\n\n        from . import sampler\n        out = sampler.generator.generate_samples(\n            order=size_, domain=self, rule=rule, antithetic=antithetic)\n        try:\n            out = out.reshape(shape)\n        except:\n            if len(self) == 1:\n                out = out.flatten()\n            else:\n                out = out.reshape(dim, int(out.size/dim))\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mom(self, K, **kws):\n        K = numpy.asarray(K, dtype=int)\n        shape = K.shape\n        dim = len(self)\n\n        if dim > 1:\n            shape = shape[1:]\n\n        size = int(K.size/dim)\n        K = K.reshape(dim, size)\n\n        cache = {}\n        out = [evaluation.evaluate_moment(self, kdata, cache) for kdata in K.T]\n        out = numpy.array(out)\n        return out.reshape(shape)", "response": "Creates non - centralized raw statistical moments from the random variable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ttr(self, kloc, acc=10**3, verbose=1):\n        kloc = numpy.asarray(kloc, dtype=int)\n        shape = kloc.shape\n        kloc = kloc.reshape(len(self), -1)\n        cache = {}\n        out = [evaluation.evaluate_recurrence_coefficients(self, k)\n               for k in kloc.T]\n        out = numpy.array(out).T\n        return out.reshape((2,)+shape)", "response": "This function generates the Three terms relation s coefficient generator."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Acf(poly, dist, N=None, **kws):\n    if N is None:\n        N = len(poly)/2 + 1\n\n    corr = Corr(poly, dist, **kws)\n    out = numpy.empty(N)\n\n    for n in range(N):\n        out[n] = numpy.mean(corr.diagonal(n), 0)\n\n    return out", "response": "Auto-correlation function.\n\n    Args:\n        poly (Poly):\n            Polynomial of interest. Must have ``len(poly) > N``.\n        dist (Dist):\n            Defines the space the correlation is taken on.\n        N (int):\n            The number of time steps appart included. If omited set to\n            ``len(poly)/2+1``.\n\n    Returns:\n        (numpy.ndarray) :\n            Auto-correlation of ``poly`` with shape ``(N,)``. Note that by\n            definition ``Q[0]=1``.\n\n    Examples:\n        >>> poly = chaospy.prange(10)[1:]\n        >>> Z = chaospy.Uniform()\n        >>> print(numpy.around(chaospy.Acf(poly, Z, 5), 4))\n        [1.     0.9915 0.9722 0.9457 0.9127]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting figures for multivariate distribution section.", "response": "def plot_figures():\n    \"\"\"Plot figures for multivariate distribution section.\"\"\"\n    rc(\"figure\", figsize=[8.,4.])\n    rc(\"figure.subplot\", left=.08, top=.95, right=.98)\n    rc(\"image\", cmap=\"gray\")\n    seed(1000)\n\n    Q1 = cp.Gamma(2)\n    Q2 = cp.Normal(0, Q1)\n    Q = cp.J(Q1, Q2)\n    #end\n\n    subplot(121)\n    s,t = meshgrid(linspace(0,5,200), linspace(-6,6,200))\n    contourf(s,t,Q.pdf([s,t]),50)\n    xlabel(\"$q_1$\")\n    ylabel(\"$q_2$\")\n    subplot(122)\n    Qr = Q.sample(500)\n    scatter(*Qr, s=10, c=\"k\", marker=\"s\")\n    xlabel(\"$Q_1$\")\n    ylabel(\"$Q_2$\")\n    axis([0,5,-6,6])\n\n    savefig(\"multivariate.png\"); clf()\n\n    Q2 = cp.Gamma(1)\n    Q1 = cp.Normal(Q2**2, Q2+1)\n    Q = cp.J(Q1, Q2)\n    #end\n\n    subplot(121)\n    s,t = meshgrid(linspace(-4,7,200), linspace(0,3,200))\n    contourf(s,t,Q.pdf([s,t]),30)\n    xlabel(\"$q_1$\")\n    ylabel(\"$q_2$\")\n    subplot(122)\n    Qr = Q.sample(500)\n    scatter(*Qr)\n    xlabel(\"$Q_1$\")\n    ylabel(\"$Q_2$\")\n    axis([-4,7,0,3])\n\n    savefig(\"multivariate2.png\"); clf()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flatten(vari):\n    if isinstance(vari, Poly):\n        shape = int(numpy.prod(vari.shape))\n        return reshape(vari, (shape,))\n\n    return numpy.array(vari).flatten()", "response": "Flatten a shapeable quantity."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reshape(vari, shape):\n\n    if isinstance(vari, Poly):\n        core = vari.A.copy()\n        for key in vari.keys:\n            core[key] = reshape(core[key], shape)\n        out = Poly(core, vari.dim, shape, vari.dtype)\n        return out\n\n    return numpy.asarray(vari).reshape(shape)", "response": "Reshape the shape of a shapeable quantity."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rollaxis(vari, axis, start=0):\n    if isinstance(vari, Poly):\n        core_old = vari.A.copy()\n        core_new = {}\n        for key in vari.keys:\n            core_new[key] = rollaxis(core_old[key], axis, start)\n        return Poly(core_new, vari.dim, None, vari.dtype)\n\n    return numpy.rollaxis(vari, axis, start)", "response": "Roll the specified axis backwards until it lies in a given position."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef swapaxes(vari, ax1, ax2):\n    if isinstance(vari, Poly):\n        core = vari.A.copy()\n        for key in vari.keys:\n            core[key] = swapaxes(core[key], ax1, ax2)\n\n        return Poly(core, vari.dim, None, vari.dtype)\n\n    return numpy.swapaxes(vari, ax1, ax2)", "response": "Interchange two axes of a polynomial."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrolling array elements along a given axis.", "response": "def roll(vari, shift, axis=None):\n    \"\"\"Roll array elements along a given axis.\"\"\"\n    if isinstance(vari, Poly):\n        core = vari.A.copy()\n        for key in vari.keys:\n            core[key] = roll(core[key], shift, axis)\n        return Poly(core, vari.dim, None, vari.dtype)\n\n    return numpy.roll(vari, shift, axis)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a transpose of a shapeable quantety.", "response": "def transpose(vari):\n    \"\"\"\n    Transpose a shapeable quantety.\n\n    Args:\n        vari (chaospy.poly.base.Poly, numpy.ndarray):\n            Quantety of interest.\n\n    Returns:\n        (chaospy.poly.base.Poly, numpy.ndarray):\n            Same type as ``vari``.\n\n    Examples:\n        >>> P = chaospy.reshape(chaospy.prange(4), (2,2))\n        >>> print(P)\n        [[1, q0], [q0^2, q0^3]]\n        >>> print(chaospy.transpose(P))\n        [[1, q0^2], [q0, q0^3]]\n    \"\"\"\n    if isinstance(vari, Poly):\n        core = vari.A.copy()\n        for key in vari.keys:\n            core[key] = transpose(core[key])\n        return Poly(core, vari.dim, vari.shape[::-1], vari.dtype)\n\n    return numpy.transpose(vari)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates an antithetic variates for a set of samples.", "response": "def create_antithetic_variates(samples, axes=()):\n    \"\"\"\n    Generate antithetic variables.\n\n    Args:\n        samples (numpy.ndarray):\n            The samples, assumed to be on the [0, 1]^D hyper-cube, to be\n            reflected.\n        axes (tuple):\n            Boolean array of which axes to reflect. If This to limit the number\n            of points created in higher dimensions by reflecting all axes at\n            once.\n\n    Returns (numpy.ndarray):\n        Same as ``samples``, but with samples internally reflected. roughly\n        equivalent to ``numpy.vstack([samples, 1-samples])`` in one dimensions.\n    \"\"\"\n    samples = numpy.asfarray(samples)\n    assert numpy.all(samples <= 1) and numpy.all(samples >= 0), (\n        \"all samples assumed on interval [0, 1].\")\n    if len(samples.shape) == 1:\n        samples = samples.reshape(1, -1)\n    inverse_samples = 1-samples\n    dims = len(samples)\n\n    if not len(axes):\n        axes = (True,)\n    axes = numpy.asarray(axes, dtype=bool).flatten()\n\n    indices = {tuple(axes*idx) for idx in numpy.ndindex((2,)*dims)}\n    indices = sorted(indices, reverse=True)\n    indices = sorted(indices, key=lambda idx: sum(idx))\n    out = [numpy.where(idx, inverse_samples.T, samples.T).T for idx in indices]\n    out = numpy.dstack(out).reshape(dims, -1)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncombine a list of lists of lists.", "response": "def combine(args, part=None):\n    \"\"\"\n    All linear combination of a list of list.\n\n    Args:\n        args (numpy.ndarray) : List of input arrays.  Components to take linear\n            combination of with `args[i].shape=(N[i], M[i])` where N is to be\n            taken linear combination of and M is static.  M[i] is set to 1 if\n            missing.\n\n    Returns:\n        (numpy.array) : matrix of combinations with shape (numpy.prod(N),\n            numpy.sum(M)).\n\n    Examples:\n        >>> A, B = [1,2], [[4,4],[5,6]]\n        >>> print(chaospy.quad.combine([A, B]))\n        [[1. 4. 4.]\n         [1. 5. 6.]\n         [2. 4. 4.]\n         [2. 5. 6.]]\n    \"\"\"\n    args = [cleanup(arg) for arg in args]\n\n    if part is not None:\n        parts, orders = part\n        if numpy.array(orders).size == 1:\n            orders = [int(numpy.array(orders).item())]*len(args)\n        parts = numpy.array(parts).flatten()\n\n        for i, arg in enumerate(args):\n            m, n = float(parts[i]), float(orders[i])\n            l = len(arg)\n            args[i] = arg[int(m/n*l):int((m+1)/n*l)]\n\n    shapes = [arg.shape for arg in args]\n    size = numpy.prod(shapes, 0)[0]*numpy.sum(shapes, 0)[1]\n\n    if size > 10**9:\n        raise MemoryError(\"Too large sets\")\n\n    if len(args) == 1:\n        out = args[0]\n\n    elif len(args) == 2:\n        out = combine_two(*args)\n\n    else:\n        arg1 = combine_two(*args[:2])\n        out = combine([arg1,]+args[2:])\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cleanup(arg):\n    arg = numpy.asarray(arg)\n    if len(arg.shape) <= 1:\n        arg = arg.reshape(arg.size, 1)\n    elif len(arg.shape) > 2:\n        raise ValueError(\"shapes must be smaller than 3\")\n    return arg", "response": "Clean up the input variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate samples from a regular grid.", "response": "def create_grid_samples(order, dim=1):\n    \"\"\"\n    Create samples from a regular grid.\n\n    Args:\n        order (int):\n            The order of the grid. Defines the number of samples.\n        dim (int):\n            The number of dimensions in the grid\n\n    Returns (numpy.ndarray):\n        Regular grid with ``shape == (dim, order)``.\n    \"\"\"\n    x_data = numpy.arange(1, order+1)/(order+1.)\n    x_data = chaospy.quad.combine([x_data]*dim)\n    return x_data.T"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef terms(order, dim):\n    return int(scipy.special.comb(order+dim, dim, 1))", "response": "Returns the number of terms in an expansion in a given upper order and dimension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsingling to multi - index using graded reverse lexicographical notation.", "response": "def multi_index(idx, dim):\n    \"\"\"\n    Single to multi-index using graded reverse lexicographical notation.\n\n    Parameters\n    ----------\n    idx : int\n        Index in interger notation\n    dim : int\n        The number of dimensions in the multi-index notation\n\n    Returns\n    -------\n    out : tuple\n        Multi-index of `idx` with `len(out)=dim`\n\n    Examples\n    --------\n    >>> for idx in range(5):\n    ...     print(chaospy.bertran.multi_index(idx, 3))\n    (0, 0, 0)\n    (1, 0, 0)\n    (0, 1, 0)\n    (0, 0, 1)\n    (2, 0, 0)\n\n    See Also\n    --------\n    single_index\n    \"\"\"\n    def _rec(idx, dim):\n        idxn = idxm = 0\n        if not dim:\n            return ()\n\n        if idx == 0:\n            return (0, )*dim\n\n        while terms(idxn, dim) <= idx:\n            idxn += 1\n        idx -= terms(idxn-1, dim)\n\n        if idx == 0:\n            return (idxn,) + (0,)*(dim-1)\n        while terms(idxm, dim-1) <= idx:\n            idxm += 1\n\n        return (int(idxn-idxm),) + _rec(idx, dim-1)\n\n    return _rec(idx, dim)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bindex(start, stop=None, dim=1, sort=\"G\", cross_truncation=1.):\n    if stop is None:\n        start, stop = 0, start\n    start = numpy.array(start, dtype=int).flatten()\n    stop = numpy.array(stop, dtype=int).flatten()\n    sort = sort.upper()\n\n    total = numpy.mgrid[(slice(numpy.max(stop), -1, -1),)*dim]\n    total = numpy.array(total).reshape(dim, -1)\n\n    if start.size > 1:\n        for idx, start_ in enumerate(start):\n            total = total[:, total[idx] >= start_]\n    else:\n        total = total[:, total.sum(0) >= start]\n    if stop.size > 1:\n        for idx, stop_ in enumerate(stop):\n            total = total[:, total[idx] <= stop_]\n\n    total = total.T.tolist()\n\n    if \"G\" in sort:\n        total = sorted(total, key=sum)\n\n    else:\n        def cmp_(idxi, idxj):\n            \"\"\"Old style compare method.\"\"\"\n            if not numpy.any(idxi):\n                return 0\n            if idxi[0] == idxj[0]:\n                return cmp(idxi[:-1], idxj[:-1])\n            return (idxi[-1] > idxj[-1]) - (idxi[-1] < idxj[-1])\n        key = functools.cmp_to_key(cmp_)\n        total = sorted(total, key=key)\n\n    if \"I\" in sort:\n        total = total[::-1]\n\n    if \"R\" in sort:\n        total = [idx[::-1] for idx in total]\n\n    for pos, idx in reversed(list(enumerate(total))):\n        idx = numpy.array(idx)\n        cross_truncation = numpy.asfarray(cross_truncation)\n        try:\n            if numpy.any(numpy.sum(idx**(1./cross_truncation)) > numpy.max(stop)**(1./cross_truncation)):\n                del total[pos]\n        except (OverflowError, ZeroDivisionError):\n            pass\n\n    return total", "response": "Generate multi - indices for a set of entries in a set of entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef single_index(idxm):\n    if -1 in idxm:\n        return 0\n    order = int(sum(idxm))\n    dim = len(idxm)\n    if order == 0:\n        return 0\n    return terms(order-1, dim) + single_index(idxm[1:])", "response": "Returns a single - index multi - index sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the index rank according to Bertran s notation.", "response": "def rank(idx, dim):\n    \"\"\"Calculate the index rank according to Bertran's notation.\"\"\"\n    idxm = multi_index(idx, dim)\n    out = 0\n    while idxm[-1:] == (0,):\n        out += 1\n        idxm = idxm[:-1]\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the index of the parent node of the given node.", "response": "def parent(idx, dim, axis=None):\n    \"\"\"\n    Parent node according to Bertran's notation.\n\n    Parameters\n    ----------\n    idx : int\n        Index of the child node.\n    dim : int\n        Dimensionality of the problem.\n    axis : int\n        Assume axis direction.\n\n    Returns\n    -------\n    out : int\n        Index of parent node with `j<=i`, and `j==i` iff `i==0`.\n    axis : int\n        Dimension direction the parent was found.\n    \"\"\"\n    idxm = multi_index(idx, dim)\n    if axis is None:\n        axis = dim - numpy.argmin(1*(numpy.array(idxm)[::-1] == 0))-1\n\n    if not idx:\n        return idx, axis\n\n    if idxm[axis] == 0:\n        idxi = parent(parent(idx, dim)[0], dim)[0]\n        while child(idxi+1, dim, axis) < idx:\n            idxi += 1\n        return idxi, axis\n\n    out = numpy.array(idxm) - 1*(numpy.eye(dim)[axis])\n    return single_index(out), axis"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef child(idx, dim, axis):\n    idxm = multi_index(idx, dim)\n    out = numpy.array(idxm) + 1*(numpy.eye(len(idxm))[axis])\n    return single_index(out)", "response": "Returns a new child node according to Bertran s notation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef olindex(order, dim):\n    idxm = [0]*dim\n    out = []\n\n    def _olindex(idx):\n        \"\"\"Recursive backend for olindex.\"\"\"\n        if numpy.sum(idxm) == order:\n            out.append(idxm[:])\n            return\n\n        if idx == dim:\n            return\n\n        idxm_sum = numpy.sum(idxm)\n        idx_saved = idxm[idx]\n\n        for idxi in range(order - numpy.sum(idxm) + 1):\n\n            idxm[idx] = idxi\n\n            if idxm_sum < order:\n                _olindex(idx+1)\n\n            else:\n                break\n        idxm[idx] = idx_saved\n\n    _olindex(0)\n    return numpy.array(out)", "response": "Create an lexiographical sorted basis for a given order."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an lexiographical sorted basis for a given order.", "response": "def olindices(order, dim):\n    \"\"\"\n    Create an lexiographical sorted basis for a given order.\n\n    Examples:\n        >>> chaospy.bertran.olindices(2, 2)\n        array([[0, 0],\n               [0, 1],\n               [1, 0],\n               [0, 2],\n               [1, 1],\n               [2, 0]])\n    \"\"\"\n    indices = [olindex(o, dim) for o in range(order+1)]\n    indices = numpy.vstack(indices)\n    return indices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring shape is correct.", "response": "def ensure_shape(core, shape, shape_):\n    \"\"\"Ensure shape is correct.\"\"\"\n    core = core.copy()\n    if shape is None:\n        shape = shape_\n    elif isinstance(shape, int):\n        shape = (shape,)\n\n    if tuple(shape) == tuple(shape_):\n        return core, shape\n\n    ones = np.ones(shape, dtype=int)\n    for key, val in core.items():\n        core[key] = val*ones\n\n    return core, shape"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures dtype is correct.", "response": "def ensure_dtype(core, dtype, dtype_):\n    \"\"\"Ensure dtype is correct.\"\"\"\n    core = core.copy()\n    if dtype is None:\n        dtype = dtype_\n\n    if dtype_ == dtype:\n        return core, dtype\n\n    for key, val in {\n            int: chaospy.poly.typing.asint,\n            float: chaospy.poly.typing.asfloat,\n            np.float32: chaospy.poly.typing.asfloat,\n            np.float64: chaospy.poly.typing.asfloat,\n    }.items():\n\n        if dtype == key:\n            converter = val\n            break\n    else:\n        raise ValueError(\"dtype not recognised (%s)\" % str(dtype))\n\n    for key, val in core.items():\n        core[key] = converter(val)\n    return core, dtype"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure that dim is correct.", "response": "def ensure_dim(core, dim, dim_):\n    \"\"\"Ensure that dim is correct.\"\"\"\n    if dim is None:\n        dim = dim_\n    if not dim:\n        return core, 1\n    if dim_ == dim:\n        return core, int(dim)\n\n    if dim > dim_:\n        key_convert = lambda vari: vari[:dim_]\n    else:\n        key_convert = lambda vari: vari + (0,)*(dim-dim_)\n\n    new_core = {}\n    for key, val in core.items():\n        key_ = key_convert(key)\n        if key_ in new_core:\n            new_core[key_] += val\n        else:\n            new_core[key_] = val\n\n    return new_core, int(dim)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sort_key(val):\n    return numpy.sum((max(val)+1)**numpy.arange(len(val)-1, -1, -1)*val)", "response": "Sort key for sorting keys in grevlex order."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a copy of the polynomial.", "response": "def copy(self):\n        \"\"\"Return a copy of the polynomial.\"\"\"\n        return Poly(self.A.copy(), self.dim, self.shape,\n            self.dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconstructing a kernel density estimator for the quantity of interests.", "response": "def QoI_Dist(poly, dist, sample=10000, **kws):\n    \"\"\"\n    Constructs distributions for the quantity of interests.\n\n    The function constructs a kernel density estimator (KDE) for each\n    polynomial (poly) by sampling it.  With the KDEs, distributions (Dists) are\n    constructed.  The Dists can be used for e.g. plotting probability density\n    functions (PDF), or to make a second uncertainty quantification simulation\n    with that newly generated Dists.\n\n    Args:\n        poly (Poly):\n            Polynomial of interest.\n        dist (Dist):\n            Defines the space where the samples for the KDE is taken from the\n            poly.\n        sample (int):\n            Number of samples used in estimation to construct the KDE.\n\n    Returns:\n        (numpy.ndarray):\n            The constructed quantity of interest (QoI) distributions, where\n            ``qoi_dists.shape==poly.shape``.\n\n    Examples:\n        >>> dist = chaospy.Normal(0, 1)\n        >>> x = chaospy.variable(1)\n        >>> poly = chaospy.Poly([x])\n        >>> qoi_dist = chaospy.QoI_Dist(poly, dist)\n        >>> values = qoi_dist[0].pdf([-0.75, 0., 0.75])\n        >>> print(numpy.around(values, 8))\n        [0.29143037 0.39931708 0.29536329]\n    \"\"\"\n    shape = poly.shape\n    poly = polynomials.flatten(poly)\n    dim = len(dist)\n\n    #sample from the inumpyut dist\n    samples = dist.sample(sample, **kws)\n\n    qoi_dists = []\n    for i in range(0, len(poly)):\n        #sample the polynomial solution\n        if dim == 1:\n            dataset = poly[i](samples)\n        else:\n            dataset = poly[i](*samples)\n\n        lo = dataset.min()\n        up = dataset.max()\n\n        #creates qoi_dist\n        qoi_dist = distributions.SampleDist(dataset, lo, up)\n        qoi_dists.append(qoi_dist)\n\n    #reshape the qoi_dists to match the shape of the inumpyut poly\n    qoi_dists = numpy.array(qoi_dists, distributions.Dist)\n    qoi_dists = qoi_dists.reshape(shape)\n\n    if not shape:\n        qoi_dists = qoi_dists.item()\n\n    return qoi_dists"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef quad_gauss_legendre(order, lower=0, upper=1, composite=None):\n    order = numpy.asarray(order, dtype=int).flatten()\n    lower = numpy.asarray(lower).flatten()\n    upper = numpy.asarray(upper).flatten()\n\n    dim = max(lower.size, upper.size, order.size)\n    order = numpy.ones(dim, dtype=int)*order\n    lower = numpy.ones(dim)*lower\n    upper = numpy.ones(dim)*upper\n\n    if composite is None:\n        composite = numpy.array(0)\n    composite = numpy.asarray(composite)\n\n    if not composite.size:\n        composite = numpy.array([numpy.linspace(0, 1, composite+1)]*dim)\n\n    else:\n        composite = numpy.array(composite)\n        if len(composite.shape) <= 1:\n            composite = numpy.transpose([composite])\n        composite = ((composite.T-lower)/(upper-lower)).T\n\n    results = [_gauss_legendre(order[i], composite[i]) for i in range(dim)]\n    abscis = numpy.array([_[0] for _ in results])\n    weights = numpy.array([_[1] for _ in results])\n\n    abscis = chaospy.quad.combine(abscis)\n    weights = chaospy.quad.combine(weights)\n\n    abscis = (upper-lower)*abscis + lower\n    weights = numpy.prod(weights*(upper-lower), 1)\n\n    return abscis.T, weights", "response": "Generate the quadrature nodes and weights in Gauss - Legendre quadrature."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates sets of abscissas and weights for Gauss - Patterson quadrature.", "response": "def quad_gauss_patterson(order, dist):\n    \"\"\"\n    Generate sets abscissas and weights for Gauss-Patterson quadrature.\n\n    Args:\n        order (int) : The quadrature order. Must be in the interval (0, 8).\n        dist (Dist) : The domain to create quadrature over.\n\n    Returns:\n        (numpy.ndarray, numpy.ndarray) : Abscissas and weights.\n\n    Example:\n        >>> X, W = chaospy.quad_gauss_patterson(3, chaospy.Uniform(0, 1))\n        >>> print(numpy.around(X, 4))\n        [[0.0031 0.0198 0.0558 0.1127 0.1894 0.2829 0.3883 0.5    0.6117 0.7171\n          0.8106 0.8873 0.9442 0.9802 0.9969]]\n        >>> print(numpy.around(W, 4))\n        [0.0085 0.0258 0.0465 0.0672 0.0858 0.1003 0.1096 0.1128 0.1096 0.1003\n         0.0858 0.0672 0.0465 0.0258 0.0085]\n\n    Reference:\n        Prem Kythe, Michael Schaeferkotter,\n        Handbook of Computational Methods for Integration,\n        Chapman and Hall, 2004,\n        ISBN: 1-58488-428-2,\n        LC: QA299.3.K98.\n\n        Thomas Patterson,\n        The Optimal Addition of Points to Quadrature Formulae,\n        Mathematics of Computation,\n        Volume 22, Number 104, October 1968, pages 847-856.\n    \"\"\"\n    if len(dist) > 1:\n\n        if isinstance(order, int):\n            values = [quad_gauss_patterson(order, d) for d in dist]\n        else:\n            values = [quad_gauss_patterson(order[i], dist[i])\n                      for i in range(len(dist))]\n\n        abscissas = [_[0][0] for _ in values]\n        weights = [_[1] for _ in values]\n        abscissas = chaospy.quad.combine(abscissas).T\n        weights = numpy.prod(chaospy.quad.combine(weights), -1)\n\n        return abscissas, weights\n\n    order = sorted(PATTERSON_VALUES.keys())[order]\n    abscissas, weights = PATTERSON_VALUES[order]\n\n    lower, upper = dist.range()\n\n    abscissas = .5*(abscissas*(upper-lower)+upper+lower)\n    abscissas = abscissas.reshape(1, abscissas.size)\n    weights /= numpy.sum(weights)\n\n    return abscissas, weights"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_quadrature(\n        order, domain, accuracy=100, sparse=False, rule=\"C\",\n        composite=1, growth=None, part=None, normalize=False, **kws\n):\n    \"\"\"\n    Numerical quadrature node and weight generator.\n\n    Args:\n        order (int):\n            The order of the quadrature.\n        domain (numpy.ndarray, Dist):\n            If array is provided domain is the lower and upper bounds (lo,up).\n            Invalid if gaussian is set.  If Dist is provided, bounds and nodes\n            are adapted to the distribution. This includes weighting the nodes\n            in Clenshaw-Curtis quadrature.\n        accuracy (int):\n            If gaussian is set, but the Dist provieded in domain does not\n            provide an analytical TTR, ac sets the approximation order for the\n            descitized Stieltje's method.\n        sparse (bool):\n            If True used Smolyak's sparse grid instead of normal tensor product\n            grid.\n        rule (str):\n            Rule for generating abscissas and weights. Either done with\n            quadrature rules, or with random samples with constant weights.\n        composite (int):\n            If provided, composite quadrature will be used.  Value determines\n            the number of domains along an axis. Ignored in the case\n            gaussian=True.\n        normalize (bool):\n            In the case of distributions, the abscissas and weights are not\n            tailored to a distribution beyond matching the bounds. If True, the\n            samples are normalized multiplying the weights with the density of\n            the distribution evaluated at the abscissas and normalized\n            afterwards to sum to one.\n        growth (bool):\n            If True sets the growth rule for the composite quadrature rule to\n            exponential for Clenshaw-Curtis quadrature.\n    \"\"\"\n    from ..distributions.baseclass import Dist\n    isdist = isinstance(domain, Dist)\n    if isdist:\n        dim = len(domain)\n    else:\n        dim = np.array(domain[0]).size\n\n    rule = rule.lower()\n    if len(rule) == 1:\n        rule = collection.QUAD_SHORT_NAMES[rule]\n\n    quad_function = collection.get_function(\n        rule,\n        domain,\n        normalize,\n        growth=growth,\n        composite=composite,\n        accuracy=accuracy,\n    )\n\n    if sparse:\n        order = np.ones(len(domain), dtype=int)*order\n        abscissas, weights = sparse_grid.sparse_grid(quad_function, order, dim)\n\n    else:\n        abscissas, weights = quad_function(order)\n\n    assert len(weights) == abscissas.shape[1]\n    assert len(abscissas.shape) == 2\n\n    return abscissas, weights", "response": "Generates a node and weight for a given set of nodes and a given set of nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a deprecation warning do each distribution.", "response": "def deprecation_warning(func, name):\n    \"\"\"Add a deprecation warning do each distribution.\"\"\"\n    @wraps(func)\n    def caller(*args, **kwargs):\n        \"\"\"Docs to be replaced.\"\"\"\n        logger = logging.getLogger(__name__)\n        instance = func(*args, **kwargs)\n        logger.warning(\n            \"Distribution `chaospy.{}` has been renamed to \".format(name) +\n            \"`chaospy.{}` and will be deprecated next release.\".format(instance.__class__.__name__))\n        return instance\n    return caller"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_samples(order, domain=1, rule=\"R\", antithetic=None):\n    logger = logging.getLogger(__name__)\n    logger.debug(\"generating random samples using rule %s\", rule)\n\n    rule = rule.upper()\n\n    if isinstance(domain, int):\n        dim = domain\n        trans = lambda x_data: x_data\n\n    elif isinstance(domain, (tuple, list, numpy.ndarray)):\n        domain = numpy.asfarray(domain)\n        if len(domain.shape) < 2:\n            dim = 1\n        else:\n            dim = len(domain[0])\n        trans = lambda x_data: ((domain[1]-domain[0])*x_data.T + domain[0]).T\n\n    else:\n        dist = domain\n        dim = len(dist)\n        trans = dist.inv\n\n    if antithetic is not None:\n\n        from .antithetic import create_antithetic_variates\n        antithetic = numpy.array(antithetic, dtype=bool).flatten()\n        if antithetic.size == 1 and dim > 1:\n            antithetic = numpy.repeat(antithetic, dim)\n\n        size = numpy.sum(1*numpy.array(antithetic))\n        order_saved = order\n        order = int(numpy.log(order - dim))\n        order = order if order > 1 else 1\n        while order**dim < order_saved:\n            order += 1\n        trans_ = trans\n        trans = lambda x_data: trans_(\n            create_antithetic_variates(x_data, antithetic)[:, :order_saved])\n\n    assert rule in SAMPLERS, \"rule not recognised\"\n    sampler = SAMPLERS[rule]\n    x_data = trans(sampler(order=order, dim=dim))\n\n    logger.debug(\"order: %d, dim: %d -> shape: %s\", order, dim, x_data.shape)\n    return x_data", "response": "Generates samples for the given order and domain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lagrange_polynomial(abscissas, sort=\"GR\"):\n    abscissas = numpy.asfarray(abscissas)\n    if len(abscissas.shape) == 1:\n        abscissas = abscissas.reshape(1, abscissas.size)\n    dim, size = abscissas.shape\n\n    order = 1\n    while chaospy.bertran.terms(order, dim) <= size:\n        order += 1\n\n    indices = numpy.array(chaospy.bertran.bindex(0, order-1, dim, sort)[:size])\n    idx, idy = numpy.mgrid[:size, :size]\n\n    matrix = numpy.prod(abscissas.T[idx]**indices[idy], -1)\n    det = numpy.linalg.det(matrix)\n    if det == 0:\n        raise numpy.linalg.LinAlgError(\"invertible matrix required\")\n\n    vec = chaospy.poly.basis(0, order-1, dim, sort)[:size]\n\n    coeffs = numpy.zeros((size, size))\n\n    if size == 1:\n        out = chaospy.poly.basis(0, 0, dim, sort)*abscissas.item()\n\n    elif size == 2:\n        coeffs = numpy.linalg.inv(matrix)\n        out = chaospy.poly.sum(vec*(coeffs.T), 1)\n\n    else:\n        for i in range(size):\n            for j in range(size):\n                coeffs[i, j] += numpy.linalg.det(matrix[1:, 1:])\n                matrix = numpy.roll(matrix, -1, axis=0)\n            matrix = numpy.roll(matrix, -1, axis=1)\n        coeffs /= det\n        out = chaospy.poly.sum(vec*(coeffs.T), 1)\n\n    return out", "response": "Create a new Lagrange polynomials."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef SampleDist(samples, lo=None, up=None):\n    samples = numpy.asarray(samples)\n    if lo is None:\n        lo = samples.min()\n    if up is None:\n        up = samples.max()\n\n    try:\n        #construct the kernel density estimator\n        dist = sample_dist(samples, lo, up)\n\n    #raised by gaussian_kde if dataset is singular matrix\n    except numpy.linalg.LinAlgError:\n        dist = Uniform(lower=-numpy.inf, upper=numpy.inf)\n\n    return dist", "response": "SampleDist - Constructs a kernel density estimator from a set of samples."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sample(self, size=(), rule=\"R\", antithetic=None, verbose=False, **kws):\n        size_ = numpy.prod(size, dtype=int)\n        dim = len(self)\n        if dim > 1:\n            if isinstance(size, (tuple,list,numpy.ndarray)):\n                shape = (dim,) + tuple(size)\n            else:\n                shape = (dim, size)\n        else:\n            shape = size\n\n        out = self.kernel.resample(size_)[0]\n        try:\n            out = out.reshape(shape)\n        except:\n            if len(self) == 1:\n                out = out.flatten()\n            else:\n                out = out.reshape(dim, out.size/dim)\n\n        return out", "response": "Sample the is\n            from the kernel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bastos_ohagen(mat, eps=1e-16):\n    mat_ref = numpy.asfarray(mat)\n    mat = mat_ref.copy()\n    diag_max = numpy.diag(mat).max()\n    assert len(mat.shape) == 2\n    size = len(mat)\n\n    hitri = numpy.zeros((size, size))\n    piv = numpy.arange(size)\n\n    for idx in range(size):\n\n        idx_max = numpy.argmax(numpy.diag(mat[idx:, idx:])) + idx\n\n        if mat[idx_max, idx_max] <= numpy.abs(diag_max*eps):\n\n            if not idx:\n                raise ValueError(\"Purly negative definite\")\n\n            for j in range(idx, size):\n                hitri[j, j] = hitri[j-1, j-1]/float(j)\n\n            break\n\n        tmp = mat[:, idx].copy()\n        mat[:, idx] = mat[:, idx_max]\n        mat[:, idx_max] = tmp\n        tmp = hitri[:, idx].copy()\n        hitri[:, idx] = hitri[:, idx_max]\n        hitri[:, idx_max] = tmp\n        tmp = mat[idx, :].copy()\n        mat[idx, :] = mat[idx_max, :]\n        mat[idx_max, :] = tmp\n        piv[idx], piv[idx_max] = piv[idx_max], piv[idx]\n\n        hitri[idx, idx] = numpy.sqrt(mat[idx, idx])\n        rval = mat[idx, idx+1:]/hitri[idx, idx]\n        hitri[idx, idx+1:] = rval\n        mat[idx+1:, idx+1:] -= numpy.outer(rval, rval)\n\n    perm = numpy.zeros((size, size), dtype=int)\n    for idx in range(size):\n        perm[idx, piv[idx]] = 1\n\n    return perm, hitri.T", "response": "Bastos - O Hagen algorithm for modified Cholesky decomposition."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _bnd(self, xloc, dist, cache):\n        return numpy.log10(evaluation.evaluate_bound(\n            dist, 10**xloc, cache=cache))", "response": "Compute the BND of the current distribution."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Sens_t(poly, dist, **kws):\n    dim = len(dist)\n    if poly.dim < dim:\n        poly = chaospy.poly.setdim(poly, len(dist))\n\n    zero = [1]*dim\n    out = numpy.zeros((dim,) + poly.shape, dtype=float)\n    V = Var(poly, dist, **kws)\n    for i in range(dim):\n        zero[i] = 0\n        out[i] = ((V-Var(E_cond(poly, zero, dist, **kws), dist, **kws)) /\n                  (V+(V == 0))**(V!=0))\n        zero[i] = 1\n    return out", "response": "Calculates the first order sensitivity index for each parameter in a given polynomial."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a random variable with the given parameters.", "response": "def construct(parent=None, defaults=None, **kwargs):\n    \"\"\"\n    Random variable constructor.\n\n    Args:\n        cdf:\n            Cumulative distribution function. Optional if ``parent`` is used.\n        bnd:\n            Boundary interval. Optional if ``parent`` is used.\n        parent (Dist):\n            Distribution used as basis for new distribution. Any other argument\n            that is omitted will instead take is function from ``parent``.\n        doc (str]):\n            Documentation for the distribution.\n        str (str, :py:data:typing.Callable):\n            Pretty print of the variable.\n        pdf:\n            Probability density function.\n        ppf:\n            Point percentile function.\n        mom:\n            Raw moment generator.\n        ttr:\n            Three terms recursion coefficient generator.\n        init:\n            Custom initialiser method.\n        defaults (dict):\n            Default values to provide to initialiser.\n\n    Returns:\n        (Dist):\n            New custom distribution.\n    \"\"\"\n    for key in kwargs:\n        assert key in LEGAL_ATTRS, \"{} is not legal input\".format(key)\n\n    if parent is not None:\n        for key, value in LEGAL_ATTRS.items():\n            if key not in kwargs and hasattr(parent, value):\n                    kwargs[key] = getattr(parent, value)\n\n    assert \"cdf\" in kwargs, \"cdf function must be defined\"\n    assert \"bnd\" in kwargs, \"bnd function must be defined\"\n    if \"str\" in kwargs and isinstance(kwargs[\"str\"], str):\n        string = kwargs.pop(\"str\")\n        kwargs[\"str\"] = lambda *args, **kwargs: string\n\n    defaults = defaults if defaults else {}\n    for key in defaults:\n        assert key in LEGAL_ATTRS, \"invalid default value {}\".format(key)\n\n    def custom_distribution(**kws):\n\n        prm = defaults.copy()\n        prm.update(kws)\n        dist = Dist(**prm)\n\n        for key, function in kwargs.items():\n            attr_name = LEGAL_ATTRS[key]\n            setattr(dist, attr_name, types.MethodType(function, dist))\n        return dist\n\n    if \"doc\" in kwargs:\n        custom_distribution.__doc__ = kwargs[\"doc\"]\n\n    return custom_distribution"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfit a polynomial approximation over a set of nodes and weights.", "response": "def fit_quadrature(orth, nodes, weights, solves, retall=False, norms=None, **kws):\n    \"\"\"\n    Using spectral projection to create a polynomial approximation over\n    distribution space.\n\n    Args:\n        orth (chaospy.poly.base.Poly):\n            Orthogonal polynomial expansion. Must be orthogonal for the\n            approximation to be accurate.\n        nodes (numpy.ndarray):\n            Where to evaluate the polynomial expansion and model to\n            approximate. ``nodes.shape==(D,K)`` where ``D`` is the number of\n            dimensions and ``K`` is the number of nodes.\n        weights (numpy.ndarray):\n            Weights when doing numerical integration. ``weights.shape == (K,)``\n            must hold.\n        solves (numpy.ndarray):\n            The model evaluation to approximate. If `numpy.ndarray` is\n            provided, it must have ``len(solves) == K``. If callable, it must\n            take a single argument X with ``len(X) == D``, and return\n            a consistent numpy compatible shape.\n        norms (numpy.ndarray):\n            In the of TTR using coefficients to estimate the polynomial norm is\n            more stable than manual calculation. Calculated using quadrature if\n            no provided. ``norms.shape == (len(orth),)`` must hold.\n\n    Returns:\n        (chaospy.poly.base.Poly):\n            Fitted model approximation in the form of an polynomial.\n    \"\"\"\n    orth = chaospy.poly.Poly(orth)\n    nodes = numpy.asfarray(nodes)\n    weights = numpy.asfarray(weights)\n\n    if callable(solves):\n        solves = [solves(node) for node in nodes.T]\n    solves = numpy.asfarray(solves)\n\n    shape = solves.shape\n    solves = solves.reshape(weights.size, int(solves.size/weights.size))\n\n    ovals = orth(*nodes)\n    vals1 = [(val*solves.T*weights).T for val in ovals]\n\n    if norms is None:\n        norms = numpy.sum(ovals**2*weights, -1)\n    else:\n        norms = numpy.array(norms).flatten()\n        assert len(norms) == len(orth)\n\n    coefs = (numpy.sum(vals1, 1).T/norms).T\n    coefs = coefs.reshape(len(coefs), *shape[1:])\n    approx_model = chaospy.poly.transpose(chaospy.poly.sum(orth*coefs.T, -1))\n\n    if retall:\n        return approx_model, coefs\n    return approx_model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a sparse version of the given function for a single entry in the system.", "response": "def sparse_grid(func, order, dim=None, skew=None):\n    \"\"\"\n    Smolyak sparse grid constructor.\n\n    Args:\n        func (:py:data:typing.Callable):\n            Function that takes a single argument ``order`` of type\n            ``numpy.ndarray`` and with ``order.shape = (dim,)``\n        order (int, numpy.ndarray):\n            The order of the grid. If ``numpy.ndarray``, it overrides both\n            ``dim`` and ``skew``.\n        dim (int):\n            Number of dimension.\n        skew (list):\n            Order skewness.\n    \"\"\"\n    if not isinstance(order, int):\n        orders = numpy.array(order).flatten()\n        dim = orders.size\n        m_order = int(numpy.min(orders))\n        skew = [order-m_order for order in orders]\n        return sparse_grid(func, m_order, dim, skew)\n\n    abscissas, weights = [], []\n    bindex = chaospy.bertran.bindex(order-dim+1, order, dim)\n\n    if skew is None:\n        skew = numpy.zeros(dim, dtype=int)\n    else:\n        skew = numpy.array(skew, dtype=int)\n        assert len(skew) == dim\n\n    for idx in range(\n            chaospy.bertran.terms(order, dim)\n            - chaospy.bertran.terms(order-dim, dim)):\n\n        idb = bindex[idx]\n        abscissa, weight = func(skew+idb)\n        weight *= (-1)**(order-sum(idb))*comb(dim-1, order-sum(idb))\n        abscissas.append(abscissa)\n        weights.append(weight)\n\n    abscissas = numpy.concatenate(abscissas, 1)\n    weights = numpy.concatenate(weights, 0)\n\n    abscissas = numpy.around(abscissas, 15)\n    order = numpy.lexsort(tuple(abscissas))\n    abscissas = abscissas.T[order].T\n    weights = weights[order]\n\n    # identify non-unique terms\n    diff = numpy.diff(abscissas.T, axis=0)\n    unique = numpy.ones(len(abscissas.T), bool)\n    unique[1:] = (diff != 0).any(axis=1)\n\n    # merge duplicate nodes\n    length = len(weights)\n    idx = 1\n    while idx < length:\n        while idx < length and unique[idx]:\n            idx += 1\n        idy = idx+1\n        while idy < length and not unique[idy]:\n            idy += 1\n        if idy-idx > 1:\n            weights[idx-1] = numpy.sum(weights[idx-1:idy])\n        idx = idy+1\n\n    abscissas = abscissas[:, unique]\n    weights = weights[unique]\n\n    return abscissas, weights"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating the lower and upper bounds of a set of locations at a given location.", "response": "def evaluate_bound(\n        distribution,\n        x_data,\n        parameters=None,\n        cache=None,\n):\n    \"\"\"\n    Evaluate lower and upper bounds.\n\n    Args:\n        distribution (Dist):\n            Distribution to evaluate.\n        x_data (numpy.ndarray):\n            Locations for where evaluate bounds at. Relevant in the case of\n            multivariate distributions where the bounds are affected by the\n            output of other distributions.\n        parameters (:py:data:typing.Any):\n            Collection of parameters to override the default ones in the\n            distribution.\n        cache (:py:data:typing.Any):\n            A collection of previous calculations in case the same distribution\n            turns up on more than one occasion.\n\n    Returns:\n        The lower and upper bounds of ``distribution`` at location\n        ``x_data`` using parameters ``parameters``.\n    \"\"\"\n    assert len(x_data) == len(distribution)\n    assert len(x_data.shape) == 2\n\n    cache = cache if cache is not None else {}\n\n    parameters = load_parameters(\n        distribution, \"_bnd\", parameters=parameters, cache=cache)\n\n    out = numpy.zeros((2,) + x_data.shape)\n\n    lower, upper = distribution._bnd(x_data.copy(), **parameters)\n    out.T[:, :, 0] = numpy.asfarray(lower).T\n    out.T[:, :, 1] = numpy.asfarray(upper).T\n\n    cache[distribution] = out\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef outer(*args):\n    if len(args) > 2:\n        part1 = args[0]\n        part2 = outer(*args[1:])\n\n    elif len(args) == 2:\n        part1, part2 = args\n\n    else:\n        return args[0]\n\n    dtype = chaospy.poly.typing.dtyping(part1, part2)\n\n    if dtype in (list, tuple, numpy.ndarray):\n\n        part1 = numpy.array(part1)\n        part2 = numpy.array(part2)\n        shape = part1.shape +  part2.shape\n        return numpy.outer(\n            chaospy.poly.shaping.flatten(part1),\n            chaospy.poly.shaping.flatten(part2),\n        )\n\n    if dtype == Poly:\n\n        if isinstance(part1, Poly) and isinstance(part2, Poly):\n\n            if (1,) in (part1.shape, part2.shape):\n                return part1*part2\n\n            shape = part1.shape+part2.shape\n\n            out = []\n            for _ in chaospy.poly.shaping.flatten(part1):\n                out.append(part2*_)\n\n            return chaospy.poly.shaping.reshape(Poly(out), shape)\n\n        if isinstance(part1, (int, float, list, tuple)):\n            part2, part1 = numpy.array(part1), part2\n\n        else:\n            part2 = numpy.array(part2)\n\n        core_old = part1.A\n        core_new = {}\n        for key in part1.keys:\n            core_new[key] = outer(core_old[key], part2)\n        shape = part1.shape+part2.shape\n        dtype = chaospy.poly.typing.dtyping(part1.dtype, part2.dtype)\n        return Poly(core_new, part1.dim, shape, dtype)\n\n    raise NotImplementedError", "response": "Returns the outer product of two sets of elements."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndot product of two polynomial vectors.", "response": "def dot(poly1, poly2):\n    \"\"\"\n    Dot product of polynomial vectors.\n\n    Args:\n        poly1 (Poly) : left part of product.\n        poly2 (Poly) : right part of product.\n\n    Returns:\n        (Poly) : product of poly1 and poly2.\n\n    Examples:\n        >>> poly = cp.prange(3, 1)\n        >>> print(poly)\n        [1, q0, q0^2]\n        >>> print(cp.dot(poly, numpy.arange(3)))\n        2q0^2+q0\n        >>> print(cp.dot(poly, poly))\n        q0^4+q0^2+1\n    \"\"\"\n    if not isinstance(poly1, Poly) and not isinstance(poly2, Poly):\n        return numpy.dot(poly1, poly2)\n\n    poly1 = Poly(poly1)\n    poly2 = Poly(poly2)\n\n    poly = poly1*poly2\n    if numpy.prod(poly1.shape) <= 1 or numpy.prod(poly2.shape) <= 1:\n        return poly\n    return chaospy.poly.sum(poly, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef quad_genz_keister_16(order):\n    order = sorted(GENZ_KEISTER_16.keys())[order]\n\n    abscissas, weights = GENZ_KEISTER_16[order]\n    abscissas = numpy.array(abscissas)\n    weights = numpy.array(weights)\n\n    weights /= numpy.sum(weights)\n    abscissas *= numpy.sqrt(2)\n\n    return abscissas, weights", "response": "Function that generates the abscissas and weights for a single element of the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef orth_gs(order, dist, normed=False, sort=\"GR\", cross_truncation=1., **kws):\n    logger = logging.getLogger(__name__)\n    dim = len(dist)\n\n    if isinstance(order, int):\n        if order == 0:\n            return chaospy.poly.Poly(1, dim=dim)\n        basis = chaospy.poly.basis(\n            0, order, dim, sort, cross_truncation=cross_truncation)\n    else:\n        basis = order\n\n    basis = list(basis)\n\n    polynomials = [basis[0]]\n\n    if normed:\n        for idx in range(1, len(basis)):\n\n            # orthogonalize polynomial:\n            for idy in range(idx):\n                orth = chaospy.descriptives.E(\n                    basis[idx]*polynomials[idy], dist, **kws)\n                basis[idx] = basis[idx] - polynomials[idy]*orth\n\n            # normalize:\n            norms = chaospy.descriptives.E(polynomials[-1]**2, dist, **kws)\n            if norms <= 0:\n                logger.warning(\"Warning: Polynomial cutoff at term %d\", idx)\n                break\n            basis[idx] = basis[idx] / numpy.sqrt(norms)\n\n            polynomials.append(basis[idx])\n\n    else:\n\n        norms = [1.]\n        for idx in range(1, len(basis)):\n\n            # orthogonalize polynomial:\n            for idy in range(idx):\n                orth = chaospy.descriptives.E(\n                    basis[idx]*polynomials[idy], dist, **kws)\n                basis[idx] = basis[idx] - polynomials[idy] * orth / norms[idy]\n\n            norms.append(\n                chaospy.descriptives.E(polynomials[-1]**2, dist, **kws))\n            if norms[-1] <= 0:\n                logger.warning(\"Warning: Polynomial cutoff at term %d\", idx)\n                break\n\n            polynomials.append(basis[idx])\n\n    return chaospy.poly.Poly(polynomials, dim=dim, shape=(len(polynomials),))", "response": "Generate an orthogonal polynomial expansion for a single class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_parameters(\n        distribution,\n        method_name,\n        parameters=None,\n        cache=None,\n        cache_key=lambda x:x,\n):\n    \"\"\"\n    Load parameter values by filling them in from cache.\n\n    Args:\n        distribution (Dist):\n            The distribution to load parameters from.\n        method_name (str):\n            Name of the method for where the parameters should be used.\n            Typically ``\"_pdf\"``, ``_cdf`` or the like.\n        parameters (:py:data:typing.Any):\n            Default parameters to use if there are no cache to retrieve. Use\n            the distributions internal parameters, if not provided.\n        cache (:py:data:typing.Any):\n            A dictionary containing previous evaluations from the stack. If\n            a parameters contains a distribution that contains in the cache, it\n            will be replaced with the cache value. If omitted, a new one will\n            be created.\n        cache_key (:py:data:typing.Any)\n            Redefine the keys of the cache to suite other purposes.\n\n    Returns:\n        Same as ``parameters``, if provided. The ``distribution`` parameter if\n        not. In either case, parameters may be updated with cache values (if\n        provided) or by ``cache`` if the call signature of ``method_name`` (on\n        ``distribution``) contains an ``cache`` argument.\n    \"\"\"\n    from .. import baseclass\n    if cache is None:\n        cache = {}\n    if parameters is None:\n        parameters = {}\n    parameters_ = distribution.prm.copy()\n    parameters_.update(**parameters)\n    parameters = parameters_\n\n    # self aware and should handle things itself:\n    if contains_call_signature(getattr(distribution, method_name), \"cache\"):\n        parameters[\"cache\"] = cache\n\n    # dumb distribution and just wants to evaluate:\n    else:\n        for key, value in parameters.items():\n            if isinstance(value, baseclass.Dist):\n                value = cache_key(value)\n                if value in cache:\n                    parameters[key] = cache[value]\n                else:\n                    raise baseclass.StochasticallyDependentError(\n                        \"evaluating under-defined distribution {}.\".format(distribution))\n\n    return parameters", "response": "Loads the internal parameters from the given distribution and method name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quad_genz_keister_18(order):\n    order = sorted(GENZ_KEISTER_18.keys())[order]\n\n    abscissas, weights = GENZ_KEISTER_18[order]\n    abscissas = numpy.array(abscissas)\n    weights = numpy.array(weights)\n\n    weights /= numpy.sum(weights)\n    abscissas *= numpy.sqrt(2)\n\n    return abscissas, weights", "response": "Function that returns the abscissas and weights for a single entry in the hierarchy of Hermite Genz - Keister 18 rule."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds least common denominator dtype.", "response": "def dtyping(*args):\n    \"\"\"\n    Find least common denominator dtype.\n\n    Examples:\n        >>> str(dtyping(int, float)) in (\"<class 'float'>\", \"<type 'float'>\")\n        True\n        >>> print(dtyping(int, Poly))\n        <class 'chaospy.poly.base.Poly'>\n    \"\"\"\n    args = list(args)\n\n    for idx, arg in enumerate(args):\n\n        if isinstance(arg, Poly):\n            args[idx] = Poly\n\n        elif isinstance(arg, numpy.generic):\n            args[idx] = numpy.asarray(arg).dtype\n\n        elif isinstance(arg, (float, int)):\n            args[idx] = type(arg)\n\n    for type_ in DATATYPES:\n        if type_ in args:\n            return type_\n\n    raise ValueError(\n        \"dtypes not recognised \" + str([str(_) for _ in args]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting dtype of polynomial coefficients to float.", "response": "def asfloat(vari, limit=None):\n    \"\"\"\n    Convert dtype of polynomial coefficients to float.\n\n    Example:\n        >>> poly = 2*cp.variable()+1\n        >>> print(poly)\n        2q0+1\n        >>> print(cp.asfloat(poly))\n        2.0q0+1.0\n    \"\"\"\n    if limit is None:\n        limit = 10**300\n    if isinstance(vari, Poly):\n        core = vari.A.copy()\n        for key in vari.keys:\n            core[key] = core[key]*1.\n        return Poly(core, vari.dim, vari.shape, float)\n\n    return numpy.asfarray(vari)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts dtype of polynomial coefficients to float.", "response": "def asint(vari):\n    \"\"\"\n    Convert dtype of polynomial coefficients to float.\n\n    Example:\n        >>> poly = 1.5*cp.variable()+2.25\n        >>> print(poly)\n        1.5q0+2.25\n        >>> print(cp.asint(poly))\n        q0+2\n    \"\"\"\n    if isinstance(vari, Poly):\n\n        core = vari.A.copy()\n        for key in vari.keys:\n            core[key] = numpy.asarray(core[key], dtype=int)\n\n        return Poly(core, vari.dim, vari.shape, int)\n\n    return numpy.asarray(vari, dtype=int)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef toarray(vari):\n    if isinstance(vari, Poly):\n        shape = vari.shape\n        out = numpy.asarray(\n            [{} for _ in range(numpy.prod(shape))],\n            dtype=object\n        )\n        core = vari.A.copy()\n        for key in core.keys():\n\n            core[key] = core[key].flatten()\n\n            for i in range(numpy.prod(shape)):\n\n                if not numpy.all(core[key][i] == 0):\n                    out[i][key] = core[key][i]\n\n        for i in range(numpy.prod(shape)):\n            out[i] = Poly(out[i], vari.dim, (), vari.dtype)\n\n        out = out.reshape(shape)\n        return out\n\n    return numpy.asarray(vari)", "response": "Convert a numpy array of polynomials into a numpy. asarray of polynomials."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _pdf(self, xloc, dist, length, cache):\n        output = evaluation.evaluate_density(\n            dist, xloc.reshape(1, -1)).reshape(length, -1)\n        assert xloc.shape == output.shape\n        return output", "response": "Probability density function.\n\n        Example:\n            >>> print(chaospy.Iid(chaospy.Uniform(), 2).pdf(\n            ...     [[0.5, 1.5], [0.5, 0.5]]))\n            [1. 0.]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cdf(self, xloc, dist, length, cache):\n        output = evaluation.evaluate_forward(\n            dist, xloc.reshape(1, -1)).reshape(length, -1)\n        assert xloc.shape == output.shape\n        return output", "response": "Cumulative distribution function.\n\n        Example:\n            >>> print(chaospy.Iid(chaospy.Uniform(0, 2), 2).fwd(\n            ...     [[0.1, 0.2, 0.3], [0.2, 0.2, 0.3]]))\n            [[0.05 0.1  0.15]\n             [0.1  0.1  0.15]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npoints percentile function. Example: >>> print(chaospy.Iid(chaospy.Uniform(0, 2), 2).inv( ... [[0.1, 0.2, 0.3], [0.2, 0.2, 0.3]])) [[0.2 0.4 0.6] [0.4 0.4 0.6]]", "response": "def _ppf(self, uloc, dist, length, cache):\n        \"\"\"\n        Point percentile function.\n\n        Example:\n            >>> print(chaospy.Iid(chaospy.Uniform(0, 2), 2).inv(\n            ...     [[0.1, 0.2, 0.3], [0.2, 0.2, 0.3]]))\n            [[0.2 0.4 0.6]\n             [0.4 0.4 0.6]]\n        \"\"\"\n        output = evaluation.evaluate_inverse(\n            dist, uloc.reshape(1, -1)).reshape(length, -1)\n        assert uloc.shape == output.shape\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _mom(self, k, dist, length, cache):\n        return numpy.prod(dist.mom(k), 0)", "response": "Moment generating function.\n\n        Example:\n            >>> print(chaospy.Iid(chaospy.Uniform(), 2).mom(\n            ...     [[0, 0, 1], [0, 1, 1]]))\n            [1.   0.5  0.25]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate_density(\n        distribution,\n        x_data,\n        parameters=None,\n        cache=None,\n):\n    \"\"\"\n    Evaluate probability density function (PDF).\n\n    Args:\n        distribution (Dist):\n            Distribution to evaluate.\n        x_data (numpy.ndarray):\n            Locations for where evaluate density at.\n        parameters (:py:data:typing.Any):\n            Collection of parameters to override the default ones in the\n            distribution.\n        cache (:py:data:typing.Any):\n            A collection of previous calculations in case the same distribution\n            turns up on more than one occasion.\n\n    Returns:\n        The probability density values of ``distribution`` at location\n        ``x_data`` using parameters ``parameters``.\n    \"\"\"\n    assert len(x_data) == len(distribution)\n    assert len(x_data.shape) == 2\n\n    cache = cache if cache is not None else {}\n    out = numpy.zeros(x_data.shape)\n\n    # Distribution self know how to handle density evaluation.\n    if hasattr(distribution, \"_pdf\"):\n        parameters = load_parameters(\n            distribution, \"_pdf\", parameters=parameters, cache=cache)\n        out[:] = distribution._pdf(x_data, **parameters)\n\n    # Approximate density evaluation based on cumulative distribution function.\n    else:\n        from .. import approximation\n        parameters = load_parameters(\n            distribution, \"_cdf\", parameters=parameters, cache=cache)\n        out[:] = approximation.approximate_density(\n            distribution, x_data, parameters=parameters, cache=cache)\n\n    # dependency handling.\n    if distribution in cache:\n        out = numpy.where(x_data == cache[distribution], out, 0)\n    else:\n        cache[distribution] = x_data\n\n    return out", "response": "Evaluate the probability density function at the given locations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sum(vari, axis=None): # pylint: disable=redefined-builtin\n    if isinstance(vari, Poly):\n\n        core = vari.A.copy()\n        for key in vari.keys:\n            core[key] = sum(core[key], axis)\n\n        return Poly(core, vari.dim, None, vari.dtype)\n\n    return np.sum(vari, axis)", "response": "Sum the components of a shapeable quantity along a given axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cumsum(vari, axis=None):\n    if isinstance(vari, Poly):\n        core = vari.A.copy()\n        for key, val in core.items():\n            core[key] = cumsum(val, axis)\n        return Poly(core, vari.dim, None, vari.dtype)\n\n    return np.cumsum(vari, axis)", "response": "Cumulative sum the components of a shapeable quantity along a given axis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prod(vari, axis=None):\n    if isinstance(vari, Poly):\n        if axis is None:\n            vari = chaospy.poly.shaping.flatten(vari)\n            axis = 0\n\n        vari = chaospy.poly.shaping.rollaxis(vari, axis)\n        out = vari[0]\n        for poly in vari[1:]:\n            out = out*poly\n        return out\n\n    return np.prod(vari, axis)", "response": "Return a product of the components of a shapeable quantity along a given axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform the cumulative product of a shapeable quantity over a given axis.", "response": "def cumprod(vari, axis=None):\n    \"\"\"\n    Perform the cumulative product of a shapeable quantity over a given axis.\n\n    Args:\n        vari (chaospy.poly.base.Poly, numpy.ndarray):\n            Input data.\n        axis (int):\n            Axis over which the sum is taken. By default ``axis`` is None, and\n            all elements are summed.\n\n    Returns:\n        (chaospy.poly.base.Poly):\n            An array shaped as ``vari`` but with the specified axis removed.\n\n    Examples:\n        >>> vari = cp.prange(4)\n        >>> print(vari)\n        [1, q0, q0^2, q0^3]\n        >>> print(cp.cumprod(vari))\n        [1, q0, q0^3, q0^6]\n    \"\"\"\n    if isinstance(vari, Poly):\n        if np.prod(vari.shape) == 1:\n            return vari.copy()\n        if axis is None:\n            vari = chaospy.poly.shaping.flatten(vari)\n            axis = 0\n\n        vari = chaospy.poly.shaping.rollaxis(vari, axis)\n        out = [vari[0]]\n\n        for poly in vari[1:]:\n            out.append(out[-1]*poly)\n        return Poly(out, vari.dim, vari.shape, vari.dtype)\n\n    return np.cumprod(vari, axis)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates Leja quadrature node.", "response": "def quad_leja(order, dist):\n    \"\"\"\n    Generate Leja quadrature node.\n\n    Example:\n        >>> abscisas, weights = quad_leja(3, chaospy.Normal(0, 1))\n        >>> print(numpy.around(abscisas, 4))\n        [[-2.7173 -1.4142  0.      1.7635]]\n        >>> print(numpy.around(weights, 4))\n        [0.022  0.1629 0.6506 0.1645]\n    \"\"\"\n    from chaospy.distributions import evaluation\n    if len(dist) > 1 and evaluation.get_dependencies(*list(dist)):\n        raise evaluation.DependencyError(\n            \"Leja quadrature do not supper distribution with dependencies.\")\n\n    if len(dist) > 1:\n        if isinstance(order, int):\n            out = [quad_leja(order, _) for _ in dist]\n        else:\n            out = [quad_leja(order[_], dist[_]) for _ in range(len(dist))]\n\n        abscissas = [_[0][0] for _ in out]\n        weights = [_[1] for _ in out]\n        abscissas = chaospy.quad.combine(abscissas).T\n        weights = chaospy.quad.combine(weights)\n        weights = numpy.prod(weights, -1)\n\n        return abscissas, weights\n\n    lower, upper = dist.range()\n    abscissas = [lower, dist.mom(1), upper]\n    for _ in range(int(order)):\n\n        obj = create_objective(dist, abscissas)\n        opts, vals = zip(\n            *[fminbound(\n                obj, abscissas[idx], abscissas[idx+1], full_output=1)[:2]\n              for idx in range(len(abscissas)-1)]\n        )\n        index = numpy.argmin(vals)\n        abscissas.insert(index+1, opts[index])\n\n    abscissas = numpy.asfarray(abscissas).flatten()[1:-1]\n    weights = create_weights(abscissas, dist)\n    abscissas = abscissas.reshape(1, abscissas.size)\n\n    return numpy.array(abscissas), numpy.array(weights)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_weights(nodes, dist):\n    poly = chaospy.quad.generate_stieltjes(dist, len(nodes)-1, retall=True)[0]\n    poly = chaospy.poly.flatten(chaospy.poly.Poly(poly))\n    weights_inverse = poly(nodes)\n    weights = numpy.linalg.inv(weights_inverse)\n    return weights[:, 0]", "response": "Create weights for the Laja method."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding interior point of the distribution where forward evaluation is guarantied to be both ``distribution.fwd(xloc) > 0`` and ``distribution.fwd(xloc) < 1``. Args: distribution (Dist): Distribution to find interior on. parameters (Optional[Dict[Dist, numpy.ndarray]]): Parameters for the distribution. cache (Optional[Dict[Dist, numpy.ndarray]]): Memory cache for the location in the evaluation so far. iterations (int): The number of iterations allowed to be performed retall (bool): If provided, lower and upper bound which guaranties that ``distribution.fwd(lower) == 0`` and ``distribution.fwd(upper) == 1`` is returned as well. seed (Optional[int]): Fix random seed. Returns: numpy.ndarray: An input array with shape ``(len(distribution),)`` which is guarantied to be on the interior of the probability distribution. Example: >>> distribution = chaospy.MvNormal([1, 2, 3], numpy.eye(3)+.03) >>> midpoint, lower, upper = find_interior_point( ... distribution, retall=True, seed=1234) >>> print(lower.T) [[-64. -64. -64.]] >>> print(numpy.around(midpoint, 4).T) [[ 0.6784 -33.7687 -19.0182]] >>> print(upper.T) [[16. 16. 16.]] >>> distribution = chaospy.Uniform(1000, 1010) >>> midpoint, lower, upper = find_interior_point( ... distribution, retall=True, seed=1234) >>> print(numpy.around(lower, 4)) [[-1.]] >>> print(numpy.around(midpoint, 4)) [[1009.8873]] >>> print(numpy.around(upper, 4)) [[1024.]]", "response": "def find_interior_point(\n        distribution,\n        parameters=None,\n        cache=None,\n        iterations=1000,\n        retall=False,\n        seed=None,\n):\n    \"\"\"\n    Find interior point of the distribution where forward evaluation is\n    guarantied to be both ``distribution.fwd(xloc) > 0`` and\n    ``distribution.fwd(xloc) < 1``.\n\n    Args:\n        distribution (Dist): Distribution to find interior on.\n        parameters (Optional[Dict[Dist, numpy.ndarray]]): Parameters for the\n            distribution.\n        cache (Optional[Dict[Dist, numpy.ndarray]]): Memory cache for the\n            location in the evaluation so far.\n        iterations (int): The number of iterations allowed to be performed\n        retall (bool): If provided, lower and upper bound which guaranties that\n            ``distribution.fwd(lower) == 0`` and\n            ``distribution.fwd(upper) == 1`` is returned as well.\n        seed (Optional[int]): Fix random seed.\n\n    Returns:\n        numpy.ndarray: An input array with shape ``(len(distribution),)`` which\n        is guarantied to be on the interior of the probability distribution.\n\n\n    Example:\n        >>> distribution = chaospy.MvNormal([1, 2, 3], numpy.eye(3)+.03)\n        >>> midpoint, lower, upper = find_interior_point(\n        ...     distribution, retall=True, seed=1234)\n        >>> print(lower.T)\n        [[-64. -64. -64.]]\n        >>> print(numpy.around(midpoint, 4).T)\n        [[  0.6784 -33.7687 -19.0182]]\n        >>> print(upper.T)\n        [[16. 16. 16.]]\n        >>> distribution = chaospy.Uniform(1000, 1010)\n        >>> midpoint, lower, upper = find_interior_point(\n        ...     distribution, retall=True, seed=1234)\n        >>> print(numpy.around(lower, 4))\n        [[-1.]]\n        >>> print(numpy.around(midpoint, 4))\n        [[1009.8873]]\n        >>> print(numpy.around(upper, 4))\n        [[1024.]]\n    \"\"\"\n    random_state = numpy.random.get_state()\n    numpy.random.seed(seed)\n\n    forward = partial(evaluation.evaluate_forward, cache=cache,\n                      distribution=distribution, parameters=parameters)\n\n    dim = len(distribution)\n    upper = numpy.ones((dim, 1))\n    for _ in range(100):\n        indices = forward(x_data=upper) < 1\n        if not numpy.any(indices):\n            break\n        upper[indices] *= 2\n\n    lower = -numpy.ones((dim, 1))\n    for _ in range(100):\n        indices = forward(x_data=lower) > 0\n        if not numpy.any(indices):\n            break\n        lower[indices] *= 2\n\n    for _ in range(iterations):\n\n        rand = numpy.random.random(dim)\n        proposal = (rand*lower.T + (1-rand)*upper.T).T\n        evals = forward(x_data=proposal)\n\n        indices0 = evals > 0\n        indices1 = evals < 1\n\n        range_ = numpy.random.choice(dim, size=dim, replace=False)\n\n        upper_ = numpy.where(indices1, upper, evals)\n        for idx in range_:\n            if upper.flatten()[idx] == upper_.flatten()[idx]:\n                continue\n            if numpy.all(forward(x_data=upper_) == 1):\n                upper = upper_\n                break\n            upper_[idx] = upper[idx]\n\n        lower_ = numpy.where(indices0, lower, evals)\n        for idx in range_:\n            if lower.flatten()[idx] == lower_.flatten()[idx]:\n                continue\n            if numpy.all(forward(x_data=lower_) == 0):\n                lower = lower_\n                break\n            lower_[idx] = lower[idx]\n\n        if numpy.all(indices0 & indices1):\n            break\n\n    else:\n        if retall:\n            return proposal, lower, upper\n        return proposal\n        raise evaluation.DependencyError(\n            \"Too many iterations required to find interior point.\")\n\n    numpy.random.set_state(random_state)\n    if retall:\n        return proposal, lower, upper\n    return proposal"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the inverse Rosenblatt transformation for a single entry.", "response": "def approximate_inverse(\n        distribution,\n        qloc,\n        parameters=None,\n        cache=None,\n        iterations=100,\n        tol=1e-5,\n        seed=None,\n):\n    \"\"\"\n    Calculate the approximation of the inverse Rosenblatt transformation.\n\n    Uses forward Rosenblatt, probability density function (derivative) and\n    boundary function to apply hybrid Newton-Raphson and binary search method.\n\n    Args:\n        distribution (Dist): Distribution to estimate inverse Rosenblatt.\n        qloc (numpy.ndarray): Input values. All values must be on [0,1] and\n            ``qloc.shape == (dim,size)`` where dim is the number of dimensions\n            in distribution and size is the number of values to calculate\n            simultaneously.\n        parameters (Optional[Dict[Dist, numpy.ndarray]]): Parameters for the\n            distribution.\n        cache (Optional[Dict[Dist, numpy.ndarray]]): Memory cache for the\n            location in the evaluation so far.\n        iterations (int): The number of iterations allowed to be performed\n        tol (float): Tolerance parameter determining convergence.\n        seed (Optional[int]): Fix random seed.\n\n    Returns:\n        numpy.ndarray: Approximation of inverse Rosenblatt transformation.\n\n    Example:\n        >>> distribution = chaospy.Normal(1000, 10)\n        >>> qloc = numpy.array([[0.1, 0.2, 0.9]])\n        >>> print(numpy.around(approximate_inverse(\n        ...     distribution, qloc, seed=1234), 4))\n        [[ 987.1845  991.5838 1012.8155]]\n        >>> print(numpy.around(distribution.inv(qloc), 4))\n        [[ 987.1845  991.5838 1012.8155]]\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    logger.debug(\"init approximate_inverse: %s\", distribution)\n\n    # lots of initial values:\n    xloc, xlower, xupper = find_interior_point(\n        distribution, cache=cache, parameters=parameters, retall=True, seed=seed)\n    xloc = (xloc.T * numpy.zeros(qloc.shape).T).T\n    xlower = (xlower.T + numpy.zeros(qloc.shape).T).T\n    xupper = (xupper.T + numpy.zeros(qloc.shape).T).T\n    uloc = numpy.zeros(qloc.shape)\n    ulower = -qloc\n    uupper = 1-qloc\n    indices = numpy.ones(qloc.shape[-1], dtype=bool)\n\n    for idx in range(2*iterations):\n\n        # evaluate function:\n        uloc[:, indices] = (evaluation.evaluate_forward(\n            distribution, xloc, cache=cache, parameters=parameters)-qloc)[:, indices]\n\n        # convergence criteria:\n        indices[indices] = numpy.any(numpy.abs(xupper-xlower) > tol, 0)[indices]\n        logger.debug(\n            \"iter: %s : %s : %s (%s)\",\n            numpy.mean(xlower, -1),\n            numpy.mean(xloc, -1),\n            numpy.mean(xupper, -1),\n            numpy.mean(indices),\n        )\n        if not numpy.any(indices):\n            break\n\n        # narrow down lower boundary:\n        ulower[:, indices] = numpy.where(uloc <= 0, uloc, ulower)[:, indices]\n        xlower[:, indices] = numpy.where(uloc <= 0, xloc, xlower)[:, indices]\n\n        # narrow down upper boundary:\n        uupper[:, indices] = numpy.where(uloc >= 0, uloc, uupper)[:, indices]\n        xupper[:, indices] = numpy.where(uloc >= 0, xloc, xupper)[:, indices]\n\n        # Newton increment every second iteration:\n        xloc_ = numpy.inf\n        if idx % 2 == 0:\n            derivative = evaluation.evaluate_density(\n                distribution, xloc, cache=cache, parameters=parameters)[:, indices]\n            derivative = numpy.where(derivative, derivative, numpy.inf)\n\n            xloc_ = xloc[:, indices] - uloc[:, indices] / derivative\n\n        # use binary search if Newton increment is outside bounds:\n        xloc[:, indices] = numpy.where(\n            (xloc_ < xupper[:, indices]) & (xloc_ > xlower[:, indices]),\n            xloc_, 0.5*(xupper+xlower)[:, indices])\n\n    else:\n        logger.warning(\n            \"Too many iterations required to estimate inverse.\")\n        logger.info(\"{} out of {} did not converge.\".format(\n            numpy.sum(indices), len(indices)))\n    logger.debug(\"end approximate_inverse: %s\", distribution)\n    return xloc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef approximate_moment(\n        dist,\n        K,\n        retall=False,\n        control_var=None,\n        rule=\"F\",\n        order=1000,\n        **kws\n):\n    \"\"\"\n    Approximation method for estimation of raw statistical moments.\n\n    Args:\n        dist : Dist\n            Distribution domain with dim=len(dist)\n        K : numpy.ndarray\n            The exponents of the moments of interest with shape (dim,K).\n        control_var : Dist\n            If provided will be used as a control variable to try to reduce\n            the error.\n        acc (:py:data:typing.Optional[int]):\n            The order of quadrature/MCI\n        sparse : bool\n            If True used Smolyak's sparse grid instead of normal tensor\n            product grid in numerical integration.\n        rule : str\n            Quadrature rule\n            Key     Description\n            ----    -----------\n            \"G\"     Optiomal Gaussian quadrature from Golub-Welsch\n                    Slow for high order and composit is ignored.\n            \"E\"     Gauss-Legendre quadrature\n            \"C\"     Clenshaw-Curtis quadrature. Exponential growth rule is\n                    used when sparse is True to make the rule nested.\n\n            Monte Carlo Integration\n            Key     Description\n            ----    -----------\n            \"H\"     Halton sequence\n            \"K\"     Korobov set\n            \"L\"     Latin hypercube sampling\n            \"M\"     Hammersley sequence\n            \"R\"     (Pseudo-)Random sampling\n            \"S\"     Sobol sequence\n\n        composite (:py:data:typing.Optional[int, numpy.ndarray]):\n            If provided, composite quadrature will be used.\n            Ignored in the case if gaussian=True.\n\n            If int provided, determines number of even domain splits\n            If array of ints, determines number of even domain splits along\n                each axis\n            If array of arrays/floats, determines location of splits\n\n        antithetic (:py:data:typing.Optional[numpy.ndarray]):\n            List of bool. Represents the axes to mirror using antithetic\n            variable during MCI.\n    \"\"\"\n    dim = len(dist)\n    shape = K.shape\n    size = int(K.size/dim)\n    K = K.reshape(dim, size)\n\n    if dim > 1:\n        shape = shape[1:]\n\n    X, W = quad.generate_quadrature(order, dist, rule=rule, normalize=True, **kws)\n\n    grid = numpy.mgrid[:len(X[0]), :size]\n    X = X.T[grid[0]].T\n    K = K.T[grid[1]].T\n    out = numpy.prod(X**K, 0)*W\n\n    if control_var is not None:\n\n        Y = control_var.ppf(dist.fwd(X))\n        mu = control_var.mom(numpy.eye(len(control_var)))\n\n        if (mu.size == 1) and (dim > 1):\n            mu = mu.repeat(dim)\n\n        for d in range(dim):\n            alpha = numpy.cov(out, Y[d])[0, 1]/numpy.var(Y[d])\n            out -= alpha*(Y[d]-mu)\n\n    out = numpy.sum(out, -1)\n    return out", "response": "Returns the raw statistical moments for the given distribution domain and k - values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef approximate_density(\n        dist,\n        xloc,\n        parameters=None,\n        cache=None,\n        eps=1.e-7\n):\n    \"\"\"\n    Approximate the probability density function.\n\n    Args:\n        dist : Dist\n            Distribution in question. May not be an advanced variable.\n        xloc : numpy.ndarray\n            Location coordinates. Requires that xloc.shape=(len(dist), K).\n        eps : float\n            Acceptable error level for the approximations\n        retall : bool\n            If True return Graph with the next calculation state with the\n            approximation.\n\n    Returns:\n        numpy.ndarray: Local probability density function with\n            ``out.shape == xloc.shape``. To calculate actual density function,\n            evaluate ``numpy.prod(out, 0)``.\n\n    Example:\n        >>> distribution = chaospy.Normal(1000, 10)\n        >>> xloc = numpy.array([[990, 1000, 1010]])\n        >>> print(numpy.around(approximate_density(distribution, xloc), 4))\n        [[0.0242 0.0399 0.0242]]\n        >>> print(numpy.around(distribution.pdf(xloc), 4))\n        [[0.0242 0.0399 0.0242]]\n    \"\"\"\n    if parameters is None:\n        parameters = dist.prm.copy()\n    if cache is None:\n        cache = {}\n\n    xloc = numpy.asfarray(xloc)\n    lo, up = numpy.min(xloc), numpy.max(xloc)\n    mu = .5*(lo+up)\n    eps = numpy.where(xloc < mu, eps, -eps)*xloc\n\n    floc = evaluation.evaluate_forward(\n        dist, xloc, parameters=parameters.copy(), cache=cache.copy())\n    for d in range(len(dist)):\n        xloc[d] += eps[d]\n        tmp = evaluation.evaluate_forward(\n            dist, xloc, parameters=parameters.copy(), cache=cache.copy())\n        floc[d] -= tmp[d]\n        xloc[d] -= eps[d]\n\n    floc = numpy.abs(floc / eps)\n    return floc", "response": "Approximate the probability density function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate the samples from the van der Corput.", "response": "def create_van_der_corput_samples(idx, number_base=2):\n    \"\"\"\n    Van der Corput samples.\n\n    Args:\n        idx (int, numpy.ndarray):\n            The index of the sequence. If array is provided, all values in\n            array is returned.\n        number_base (int):\n            The numerical base from where to create the samples from.\n\n    Returns (float, numpy.ndarray):\n        Van der Corput samples.\n    \"\"\"\n    assert number_base > 1\n\n    idx = numpy.asarray(idx).flatten() + 1\n    out = numpy.zeros(len(idx), dtype=float)\n\n    base = float(number_base)\n    active = numpy.ones(len(idx), dtype=bool)\n    while numpy.any(active):\n        out[active] += (idx[active] % number_base)/base\n        idx //= number_base\n        base *= number_base\n        active = idx > 0\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplotting the Heaviside function on the given x - axis and center.", "response": "def plot(self, xmin=-1, xmax=1, center=0,\n             resolution_outside=20, resolution_inside=200):\n        \"\"\"\n        Return arrays x, y for plotting the Heaviside function\n        H(x-`center`) on [`xmin`, `xmax`]. For the exact\n        Heaviside function,\n        ``x = [xmin, center, xmax]; y = [0, 0, 1]``,\n        while for the smoothed version, the ``x`` array\n        is computed on basis of the `eps` parameter, with\n        `resolution_outside` intervals on each side of the smoothed\n        region and `resolution_inside` intervals in the smoothed region.\n        \"\"\"\n        if self.eps == 0:\n            return [xmin, center, xmax], [0, 0, xmax]\n        else:\n            n = float(resolution_inside)/self.eps\n            x = np.concatenate((\n                np.linspace(xmin, center-self.eps, resolution_outside+1),\n                np.linspace(center-self.eps, center+self.eps, n+1),\n                np.linspace(center+self.eps, xmax, resolution_outside+1)))\n            y = self(x)\n            return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot(self, xmin=-1, xmax=1,\n             resolution_outside=20, resolution_inside=200):\n        \"\"\"\n        Return arrays x, y for plotting IndicatorFunction\n        on [`xmin`, `xmax`]. For the exact discontinuous\n        indicator function, we typically have\n        ``x = [xmin, L, L, R, R, xmax]; y = [0, 0, 1, 1, 0, 0]``,\n        while for the smoothed version, the densities of\n        coordinates in the ``x`` array is computed on basis of the\n        `eps` parameter with `resolution_outside` plotting intervals\n        outside the smoothed regions and  `resolution_inside` intervals\n        inside the smoothed regions.\n        \"\"\"\n        if xmin > self.L or xmax < self.R:\n            raise ValueError('xmin=%g > L=%g or xmax=%g < R=%g is meaningless for plot' % (xmin, self.L, xmax, self.R))\n\n        if self.eps_L == 0 and self.eps_R == 0:\n            return ([xmin, self.L, self.L, self.R, self.R, xmax],\n                    [0, 0, 1, 1, 0, 0])\n        else:\n            n = float(resolution_inside)/(0.5*(self.eps_L + self.eps_R))\n            x = np.concatenate((\n                np.linspace(xmin, self.L-self.eps_L, resolution_outside+1),\n                np.linspace(self.L-self.eps_L, self.R+self.eps_R,\n                            resolution_inside+1),\n                np.linspace(self.R+self.eps_R, xmax, resolution_outside+1)))\n            y = self(x)\n            return x, y", "response": "Plot the discontinuous IndicatorFunction for a specific interval of the logarithmic area."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the piecewise constant function.", "response": "def plot(self,\n             resolution_constant_regions=20,\n             resolution_smooth_regions=200):\n        \"\"\"\n        Return arrays x, y for plotting the piecewise constant function.\n        Just the minimum number of straight lines are returned if\n        ``eps=0``, otherwise `resolution_constant_regions` plotting intervals\n        are insed in the constant regions with `resolution_smooth_regions`\n        plotting intervals in the smoothed regions.\n        \"\"\"\n        if self.eps == 0:\n            x = []; y = []\n            for I, value in zip(self._indicator_functions, self._values):\n                x.append(I.L)\n                y.append(value)\n                x.append(I.R)\n                y.append(value)\n            return x, y\n        else:\n            n = float(resolution_smooth_regions)/self.eps\n            if len(self.data) == 1:\n                return [self.L, self.R], [self._values[0], self._values[0]]\n            else:\n                x = [np.linspace(self.data[0][0], self.data[1][0]-self.eps,\n                                 resolution_constant_regions+1)]\n                # Iterate over all internal discontinuities\n                for I in self._indicator_functions[1:]:\n                    x.append(np.linspace(I.L-self.eps, I.L+self.eps,\n                                         resolution_smooth_regions+1))\n                    x.append(np.linspace(I.L+self.eps, I.R-self.eps,\n                                         resolution_constant_regions+1))\n                # Last part\n                x.append(np.linspace(I.R-self.eps, I.R, 3))\n                x = np.concatenate(x)\n                y = self(x)\n                return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef differential(poly, diffvar):\n    poly = Poly(poly)\n    diffvar = Poly(diffvar)\n\n    if not chaospy.poly.caller.is_decomposed(diffvar):\n        sum(differential(poly, chaospy.poly.caller.decompose(diffvar)))\n\n    if diffvar.shape:\n        return Poly([differential(poly, pol) for pol in diffvar])\n\n    if diffvar.dim > poly.dim:\n        poly = chaospy.poly.dimension.setdim(poly, diffvar.dim)\n    else:\n        diffvar = chaospy.poly.dimension.setdim(diffvar, poly.dim)\n\n    qkey = diffvar.keys[0]\n\n    core = {}\n    for key in poly.keys:\n\n        newkey = np.array(key) - np.array(qkey)\n\n        if np.any(newkey < 0):\n            continue\n        newkey = tuple(newkey)\n        core[newkey] = poly.A[key] * np.prod(\n            [fac(key[idx], exact=True) / fac(newkey[idx], exact=True)\n             for idx in range(poly.dim)])\n\n    return Poly(core, poly.dim, poly.shape, poly.dtype)", "response": "Returns a new Jacobian matrix that is the Jacobian matrix of the given polynomial."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npoints percentile function. Example: >>> print(chaospy.Uniform().inv([0.1, 0.2, 0.9])) [0.1 0.2 0.9] >>> print(chaospy.Pow(chaospy.Uniform(), 2).inv([0.1, 0.2, 0.9])) [0.01 0.04 0.81] >>> print(chaospy.Pow(chaospy.Uniform(1, 2), -1).inv([0.1, 0.2, 0.9])) [0.52631579 0.55555556 0.90909091] >>> print(chaospy.Pow(2, chaospy.Uniform()).inv([0.1, 0.2, 0.9])) [1.07177346 1.14869835 1.86606598] >>> print(chaospy.Pow(2, chaospy.Uniform(-1, 0)).inv([0.1, 0.2, 0.9])) [0.53588673 0.57434918 0.93303299] >>> print(chaospy.Pow(2, 3).inv([0.1, 0.2, 0.9])) [8. 8. 8.]", "response": "def _ppf(self, q, left, right, cache):\n        \"\"\"\n        Point percentile function.\n\n        Example:\n            >>> print(chaospy.Uniform().inv([0.1, 0.2, 0.9]))\n            [0.1 0.2 0.9]\n            >>> print(chaospy.Pow(chaospy.Uniform(), 2).inv([0.1, 0.2, 0.9]))\n            [0.01 0.04 0.81]\n            >>> print(chaospy.Pow(chaospy.Uniform(1, 2), -1).inv([0.1, 0.2, 0.9]))\n            [0.52631579 0.55555556 0.90909091]\n            >>> print(chaospy.Pow(2, chaospy.Uniform()).inv([0.1, 0.2, 0.9]))\n            [1.07177346 1.14869835 1.86606598]\n            >>> print(chaospy.Pow(2, chaospy.Uniform(-1, 0)).inv([0.1, 0.2, 0.9]))\n            [0.53588673 0.57434918 0.93303299]\n            >>> print(chaospy.Pow(2, 3).inv([0.1, 0.2, 0.9]))\n            [8. 8. 8.]\n        \"\"\"\n        left = evaluation.get_inverse_cache(left, cache)\n        right = evaluation.get_inverse_cache(right, cache)\n\n        if isinstance(left, Dist):\n            if isinstance(right, Dist):\n                raise StochasticallyDependentError(\n                    \"under-defined distribution {} or {}\".format(left, right))\n        elif not isinstance(right, Dist):\n            return left**right\n\n        else:\n            out = evaluation.evaluate_inverse(right, q, cache=cache)\n            out = numpy.where(left < 0, 1-out, out)\n            out = left**out\n            return out\n\n        right = right + numpy.zeros(q.shape)\n        q = numpy.where(right < 0, 1-q, q)\n        out = evaluation.evaluate_inverse(left, q, cache=cache)**right\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _pdf(self, xloc, left, right, cache):\n        left = evaluation.get_forward_cache(left, cache)\n        right = evaluation.get_forward_cache(right, cache)\n\n        if isinstance(left, Dist):\n            if isinstance(right, Dist):\n                raise StochasticallyDependentError(\n                    \"under-defined distribution {} or {}\".format(left, right))\n\n        elif not isinstance(right, Dist):\n            return numpy.inf\n\n        else:\n\n            assert numpy.all(left > 0), \"imaginary result\"\n            x_ = numpy.where(xloc <= 0, -numpy.inf,\n                    numpy.log(xloc + 1.*(xloc<=0))/numpy.log(left+1.*(left == 1)))\n            num_ = numpy.log(left+1.*(left == 1))*xloc\n            num_ = num_ + 1.*(num_==0)\n\n            out = evaluation.evaluate_density(right, x_, cache=cache)/num_\n            return out\n\n        x_ = numpy.sign(xloc)*numpy.abs(xloc)**(1./right -1)\n        xloc = numpy.sign(xloc)*numpy.abs(xloc)**(1./right)\n        pairs = numpy.sign(xloc**right) == 1\n\n        out = evaluation.evaluate_density(left, xloc, cache=cache)\n        if numpy.any(pairs):\n            out = out + pairs*evaluation.evaluate_density(left, -xloc, cache=cache)\n\n        out = numpy.sign(right)*out * x_ / right\n        out[numpy.isnan(out)] = numpy.inf\n\n        return out", "response": "PDF for a single item."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _mom(self, k, left, right, cache):\n        if isinstance(right, Dist):\n            raise StochasticallyDependentError(\n                \"distribution as exponent not supported.\")\n        if not isinstance(left, Dist):\n            return left**(right*k)\n        if numpy.any(right < 0):\n            raise StochasticallyDependentError(\n                \"distribution to negative power not supported.\")\n        if not numpy.allclose(right, numpy.array(right, dtype=int)):\n            raise StochasticallyDependentError(\n                \"distribution to fractional power not supported.\")\n        return evaluation.evaluate_moment(left, k*right, cache=cache)", "response": "Return the moments of a single object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef evaluate_recurrence_coefficients(\n        distribution,\n        k_data,\n        parameters=None,\n        cache=None,\n):\n    \"\"\"\n    Evaluate three terms recurrence coefficients (TTR).\n\n    Args:\n        distribution (Dist):\n            Distribution to evaluate.\n        x_data (numpy.ndarray):\n            Locations for where evaluate recurrence coefficients for.\n        parameters (:py:data:typing.Any):\n            Collection of parameters to override the default ones in the\n            distribution.\n        cache (:py:data:typing.Any):\n            A collection of previous calculations in case the same distribution\n            turns up on more than one occasion.\n\n    Returns:\n        The recurrence coefficients ``A`` and ``B`` of ``distribution`` at\n        location ``x_data`` using parameters ``parameters``.\n    \"\"\"\n    assert len(k_data) == len(distribution), (\n        \"distribution %s is not of length %d\" % (distribution, len(k_data)))\n    assert len(k_data.shape) == 1\n\n    def cache_key(distribution):\n        return (tuple(k_data), distribution)\n\n    if cache is None:\n        cache = {}\n    else:\n        if cache_key(distribution) in cache:\n            return cache[cache_key(distribution)]\n\n    try:\n        parameters = load_parameters(\n            distribution, \"_ttr\", parameters, cache, cache_key)\n        coeff1, coeff2 = distribution._ttr(k_data, **parameters)\n\n    except NotImplementedError:\n        from ... import quad\n        _, _, coeff1, coeff2 = quad.stieltjes._stieltjes_approx(\n            distribution, order=numpy.max(k_data), accuracy=100, normed=False)\n        range_ = numpy.arange(len(distribution), dtype=int)\n        coeff1 = coeff1[range_, k_data]\n        coeff2 = coeff2[range_, k_data]\n\n    out = numpy.zeros((2,) + k_data.shape)\n    out.T[:, 0] = numpy.asarray(coeff1).T\n    out.T[:, 1] = numpy.asarray(coeff2).T\n    if len(distribution) == 1:\n        out = out[:, 0]\n\n    return out", "response": "Evaluate three terms recurrence coefficients for a given set of locations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate Korobov lattice samples.", "response": "def create_korobov_samples(order, dim, base=17797):\n    \"\"\"\n    Create Korobov lattice samples.\n\n    Args:\n        order (int):\n            The order of the Korobov latice. Defines the number of\n            samples.\n        dim (int):\n            The number of dimensions in the output.\n        base (int):\n            The number based used to calculate the distribution of values.\n\n    Returns (numpy.ndarray):\n        Korobov lattice with ``shape == (dim, order)``\n    \"\"\"\n    values = numpy.empty(dim)\n    values[0] = 1\n    for idx in range(1, dim):\n        values[idx] = base*values[idx-1] % (order+1)\n\n    grid = numpy.mgrid[:dim, :order+1]\n    out = values[grid[0]] * (grid[1]+1) / (order+1.) % 1.\n    return out[:, :order]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the BND of the current distribution.", "response": "def _bnd(self, xloc, dist, cache):\n        \"\"\"Distribution bounds.\"\"\"\n        return numpy.log(evaluation.evaluate_bound(\n            dist, numpy.e**xloc, cache=cache))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot figures for tutorial.", "response": "def plot_figures():\n    \"\"\"Plot figures for tutorial.\"\"\"\n    numpy.random.seed(1000)\n\n\n    def foo(coord, param):\n        return param[0] * numpy.e ** (-param[1] * coord)\n\n    coord = numpy.linspace(0, 10, 200)\n    distribution = cp.J(cp.Uniform(1, 2), cp.Uniform(0.1, 0.2))\n\n    samples = distribution.sample(50)\n    evals = numpy.array([foo(coord, sample) for sample in samples.T])\n\n    plt.plot(coord, evals.T, \"k-\", lw=3, alpha=0.2)\n    plt.xlabel(r\"\\verb;coord;\")\n    plt.ylabel(r\"function evaluations \\verb;foo;\")\n    plt.savefig(\"demonstration.png\")\n    plt.clf()\n\n\n    samples = distribution.sample(1000, \"H\")\n    evals = [foo(coord, sample) for sample in samples.T]\n    expected = numpy.mean(evals, 0)\n    deviation = numpy.std(evals, 0)\n\n    plt.fill_between(\n        coord, expected-deviation, expected+deviation,\n        color=\"k\", alpha=0.3\n    )\n    plt.plot(coord, expected, \"k--\", lw=3)\n    plt.xlabel(r\"\\verb;coord;\")\n    plt.ylabel(r\"function evaluations \\verb;foo;\")\n    plt.title(\"Results using Monte Carlo simulation\")\n    plt.savefig(\"results_montecarlo.png\")\n    plt.clf()\n\n\n    polynomial_expansion = cp.orth_ttr(8, distribution)\n    foo_approx = cp.fit_regression(polynomial_expansion, samples, evals)\n    expected = cp.E(foo_approx, distribution)\n    deviation = cp.Std(foo_approx, distribution)\n\n    plt.fill_between(\n        coord, expected-deviation, expected+deviation,\n        color=\"k\", alpha=0.3\n    )\n    plt.plot(coord, expected, \"k--\", lw=3)\n    plt.xlabel(r\"\\verb;coord;\")\n    plt.ylabel(r\"function evaluations \\verb;foo;\")\n    plt.title(\"Results using point collocation method\")\n    plt.savefig(\"results_collocation.png\")\n    plt.clf()\n\n\n    absissas, weights = cp.generate_quadrature(8, distribution, \"C\")\n    evals = [foo(coord, val) for val in absissas.T]\n    foo_approx = cp.fit_quadrature(polynomial_expansion, absissas, weights, evals)\n    expected = cp.E(foo_approx, distribution)\n    deviation = cp.Std(foo_approx, distribution)\n\n    plt.fill_between(\n        coord, expected-deviation, expected+deviation,\n        color=\"k\", alpha=0.3\n    )\n    plt.plot(coord, expected, \"k--\", lw=3)\n    plt.xlabel(r\"\\verb;coord;\")\n    plt.ylabel(r\"function evaluations \\verb;foo;\")\n    plt.title(\"Results using psuedo-spectral projection method\")\n    plt.savefig(\"results_spectral.png\")\n    plt.clf()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef quad_genz_keister(order, dist, rule=24):\n    assert isinstance(rule, int)\n\n    if len(dist) > 1:\n\n        if isinstance(order, int):\n            values = [quad_genz_keister(order, d, rule) for d in dist]\n        else:\n            values = [quad_genz_keister(order[i], dist[i], rule)\n                      for i in range(len(dist))]\n\n        abscissas = [_[0][0] for _ in values]\n        abscissas = chaospy.quad.combine(abscissas).T\n        weights = [_[1] for _ in values]\n        weights = np.prod(chaospy.quad.combine(weights), -1)\n\n        return abscissas, weights\n\n    foo = chaospy.quad.genz_keister.COLLECTION[rule]\n    abscissas, weights = foo(order)\n    abscissas = dist.inv(scipy.special.ndtr(abscissas))\n    abscissas = abscissas.reshape(1, abscissas.size)\n\n    return abscissas, weights", "response": "Generate a new random set of elements for a genz - keister quadrature rule."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the probability of removing samples from a set of abscissas.", "response": "def probabilistic_collocation(order, dist, subset=.1):\n    \"\"\"\n    Probabilistic collocation method.\n\n    Args:\n        order (int, numpy.ndarray) : Quadrature order along each axis.\n        dist (Dist) : Distribution to generate samples from.\n        subset (float) : Rate of which to removed samples.\n    \"\"\"\n    abscissas, weights = chaospy.quad.collection.golub_welsch(order, dist)\n\n    likelihood = dist.pdf(abscissas)\n\n    alpha = numpy.random.random(len(weights))\n    alpha = likelihood > alpha*subset*numpy.max(likelihood)\n\n    abscissas = abscissas.T[alpha].T\n    weights = weights[alpha]\n    return abscissas, weights"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a function that can be called at the specified order.", "response": "def get_function(rule, domain, normalize, **parameters):\n    \"\"\"\n    Create a quadrature function and set default parameter values.\n\n    Args:\n        rule (str):\n            Name of quadrature rule defined in ``QUAD_FUNCTIONS``.\n        domain (Dist, numpy.ndarray):\n            Defines ``lower`` and ``upper`` that is passed quadrature rule. If\n            ``Dist``, ``domain`` is renamed to ``dist`` and also\n            passed.\n        normalize (bool):\n            In the case of distributions, the abscissas and weights are not\n            tailored to a distribution beyond matching the bounds. If True, the\n            samples are normalized multiplying the weights with the density of\n            the distribution evaluated at the abscissas and normalized\n            afterwards to sum to one.\n        parameters (:py:data:typing.Any):\n            Redefining of the parameter defaults. Only add parameters that the\n            quadrature rule expect.\n    Returns:\n        (:py:data:typing.Callable):\n            Function that can be called only using argument ``order``.\n    \"\"\"\n    from ...distributions.baseclass import Dist\n    if isinstance(domain, Dist):\n        lower, upper = domain.range()\n        parameters[\"dist\"] = domain\n    else:\n        lower, upper = numpy.array(domain)\n    parameters[\"lower\"] = lower\n    parameters[\"upper\"] = upper\n\n    quad_function = QUAD_FUNCTIONS[rule]\n    parameters_spec = inspect.getargspec(quad_function)[0]\n    parameters_spec = {key: None for key in parameters_spec}\n    del parameters_spec[\"order\"]\n\n    for key in parameters_spec:\n        if key in parameters:\n            parameters_spec[key] = parameters[key]\n\n    def _quad_function(order, *args, **kws):\n        \"\"\"Implementation of quadrature function.\"\"\"\n        params = parameters_spec.copy()\n        params.update(kws)\n        abscissas, weights = quad_function(order, *args, **params)\n\n        # normalize if prudent:\n        if rule in UNORMALIZED_QUADRATURE_RULES and normalize:\n            if isinstance(domain, Dist):\n                if len(domain) == 1:\n                    weights *= domain.pdf(abscissas).flatten()\n                else:\n                    weights *= domain.pdf(abscissas)\n            weights /= numpy.sum(weights)\n\n        return abscissas, weights\n\n    return _quad_function"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfit a linear regression of a set of classes.", "response": "def fit_regression(\n        polynomials,\n        abscissas,\n        evals,\n        rule=\"LS\",\n        retall=False,\n        order=0,\n        alpha=-1,\n):\n    \"\"\"\n    Fit a polynomial chaos expansion using linear regression.\n\n    Args:\n        polynomials (chaospy.poly.base.Poly):\n            Polynomial expansion with ``polynomials.shape=(M,)`` and\n            `polynomials.dim=D`.\n        abscissas (numpy.ndarray):\n            Collocation nodes with ``abscissas.shape == (D, K)``.\n        evals (numpy.ndarray):\n            Model evaluations with ``len(evals)=K``.\n        retall (bool):\n            If True return Fourier coefficients in addition to R.\n        order (int):\n            Tikhonov regularization order.\n        alpha (float):\n            Dampning parameter for the Tikhonov regularization. Calculated\n            automatically if negative.\n\n    Returns:\n        (Poly, numpy.ndarray):\n            Fitted polynomial with ``R.shape=evals.shape[1:]`` and ``R.dim=D``.\n            The Fourier coefficients in the estimation.\n\n    Examples:\n        >>> x, y = chaospy.variable(2)\n        >>> polynomials = chaospy.Poly([1, x, y])\n        >>> abscissas = [[-1,-1,1,1], [-1,1,-1,1]]\n        >>> evals = [0,1,1,2]\n        >>> print(chaospy.around(chaospy.fit_regression(\n        ...     polynomials, abscissas, evals), 14))\n        0.5q0+0.5q1+1.0\n    \"\"\"\n    abscissas = numpy.asarray(abscissas)\n    if len(abscissas.shape) == 1:\n        abscissas = abscissas.reshape(1, *abscissas.shape)\n    evals = numpy.array(evals)\n\n    poly_evals = polynomials(*abscissas).T\n    shape = evals.shape[1:]\n    evals = evals.reshape(evals.shape[0], int(numpy.prod(evals.shape[1:])))\n\n    if isinstance(rule, str):\n        rule = rule.upper()\n\n    if rule == \"LS\":\n        uhat = linalg.lstsq(poly_evals, evals)[0]\n\n    elif rule == \"T\":\n        uhat = rlstsq(poly_evals, evals, order=order, alpha=alpha, cross=False)\n\n    elif rule == \"TC\":\n        uhat = rlstsq(poly_evals, evals, order=order, alpha=alpha, cross=True)\n\n    else:\n\n        from sklearn.linear_model.base import LinearModel\n        assert isinstance(rule, LinearModel)\n        uhat = rule.fit(poly_evals, evals).coef_.T\n\n    evals = evals.reshape(evals.shape[0], *shape)\n\n    approx_model = chaospy.poly.sum((polynomials*uhat.T), -1)\n    approx_model = chaospy.poly.reshape(approx_model, shape)\n\n    if retall == 1:\n        return approx_model, uhat\n    elif retall == 2:\n        return approx_model, uhat, poly_evals\n    return approx_model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the Least Squares Minimization using Tikhonov regularization using robust generalized cross - validation.", "response": "def rlstsq(coef_mat, ordinate, order=1, alpha=-1, cross=False):\n    \"\"\"\n    Least Squares Minimization using Tikhonov regularization.\n\n    Includes method for robust generalized cross-validation.\n\n    Args:\n        coef_mat (numpy.ndarray):\n            Coefficient matrix with shape ``(M, N)``.\n        ordinate (numpy.ndarray):\n            Ordinate or \"dependent variable\" values with shape ``(M,)`` or\n            ``(M, K)``. If ``ordinate`` is two-dimensional, the least-squares\n            solution is calculated for each of the ``K`` columns of\n            ``ordinate``.\n        order (int, numpy.ndarray):\n            If int, it is the order of Tikhonov regularization. If\n            `numpy.ndarray`, it will be used as regularization matrix.\n        alpha (float):\n            Lower threshold for the dampening parameter. The real value is\n            calculated using generalised cross validation.\n        cross (bool):\n            Use cross validation to estimate alpha value.\n    \"\"\"\n    coef_mat = numpy.array(coef_mat)\n    ordinate = numpy.array(ordinate)\n    dim1, dim2 = coef_mat.shape\n\n    if cross:\n        out = numpy.empty((dim1, dim2) + ordinate.shape[1:])\n        coef_mat_ = numpy.empty((dim1-1, dim2))\n        ordinate_ = numpy.empty((dim1-1,) + ordinate.shape[1:])\n        for i in range(dim1):\n            coef_mat_[:i] = coef_mat[:i]\n            coef_mat_[i:] = coef_mat[i+1:]\n            ordinate_[:i] = ordinate[:i]\n            ordinate_[i:] = ordinate[i+1:]\n            out[i] = rlstsq(coef_mat_, ordinate_, order, alpha, False)\n\n        return numpy.median(out, 0)\n\n    if order == 0:\n        tikhmat = numpy.eye(dim2)\n\n    elif order == 1:\n        tikhmat = numpy.zeros((dim2-1, dim2))\n        tikhmat[:, :-1] -= numpy.eye(dim2-1)\n        tikhmat[:, 1:] += numpy.eye(dim2-1)\n\n    elif order == 2:\n        tikhmat = numpy.zeros((dim2-2, dim2))\n        tikhmat[:, :-2] += numpy.eye(dim2-2)\n        tikhmat[:, 1:-1] -= 2*numpy.eye(dim2-2)\n        tikhmat[:, 2:] += numpy.eye(dim2-2)\n\n    elif order is None:\n        tikhmat = numpy.zeros(1)\n\n    else:\n        tikhmat = numpy.array(order)\n        assert tikhmat.shape[-1] == dim2 or tikhmat.shape in ((), (1,))\n\n    if alpha < 0 and order is not None:\n\n        gamma = 0.1\n\n        def rgcv_error(alpha):\n            \"\"\"Calculate Tikhonov dampening parameter.\"\"\"\n            if alpha <= 0:\n                return numpy.inf\n            coef_mat_ = numpy.dot(\n                coef_mat.T, coef_mat)+alpha*(numpy.dot(tikhmat.T, tikhmat))\n            try:\n                coef_mat_ = numpy.dot(linalg.inv(coef_mat_), coef_mat.T)\n            except linalg.LinAlgError:\n                return numpy.inf\n\n            abscissas = numpy.dot(coef_mat_, ordinate)\n            res2 = numpy.sum((numpy.dot(coef_mat, abscissas)-ordinate)**2)\n            coef_mat_2 = numpy.dot(coef_mat, coef_mat_)\n            skew = dim1*res2/numpy.trace(numpy.eye(dim1)-coef_mat_2)**2\n            mu2 = numpy.sum(coef_mat_2*coef_mat_2.T)/dim1\n\n            return (gamma + (1-gamma)*mu2)*skew\n\n        alphas = 10.**-numpy.arange(0, 16)\n        evals = numpy.array([rgcv_error(alpha) for alpha in alphas])\n        alpha = alphas[numpy.argmin(evals)]\n\n    out = linalg.inv(\n        numpy.dot(coef_mat.T, coef_mat) + alpha*numpy.dot(tikhmat.T, tikhmat))\n    out = numpy.dot(out, numpy.dot(coef_mat.T, ordinate))\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quad_genz_keister_24 ( order ):\n    order = sorted(GENZ_KEISTER_24.keys())[order]\n\n    abscissas, weights = GENZ_KEISTER_24[order]\n    abscissas = numpy.array(abscissas)\n    weights = numpy.array(weights)\n\n    weights /= numpy.sum(weights)\n    abscissas *= numpy.sqrt(2)\n\n    return abscissas, weights", "response": "This function generates the abscissas and weights for a single element of the hierarchy of genz - keister 24 rule."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef contains_call_signature(caller, key):\n    try:\n        args = inspect.signature(caller).parameters\n    except AttributeError:\n        args = inspect.getargspec(caller).args\n    return key in args", "response": "Check if a function or method call signature contains a specific\n            argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsolves the sensitivity matrix for a given distribution.", "response": "def Sens_m_sample(poly, dist, samples, rule=\"R\"):\n    \"\"\"\n    First order sensitivity indices estimated using Saltelli's method.\n\n    Args:\n        poly (chaospy.Poly):\n            If provided, evaluated samples through polynomials before returned.\n        dist (chaopy.Dist):\n            distribution to sample from.\n        samples (int):\n            The number of samples to draw for each matrix.\n        rule (str):\n            Scheme for generating random samples.\n\n    Return:\n        (numpy.ndarray):\n            array with `shape == (len(dist), len(poly))` where `sens[dim][pol]`\n            is the first sensitivity index for distribution dimensions `dim` and\n            polynomial index `pol`.\n\n    Examples:\n        >>> dist = chaospy.Iid(chaospy.Uniform(), 2)\n        >>> poly = chaospy.basis(2, 2, dim=2)\n        >>> print(poly)\n        [q0^2, q0q1, q1^2]\n        >>> print(numpy.around(Sens_m_sample(poly, dist, 10000, rule=\"M\"), 4))\n        [[0.008  0.0026 0.    ]\n         [0.     0.6464 2.1321]]\n    \"\"\"\n    dim = len(dist)\n\n    generator = Saltelli(dist, samples, poly, rule=rule)\n\n    zeros = [0]*dim\n    ones = [1]*dim\n    index = [0]*dim\n\n    variance = numpy.var(generator[zeros], -1)\n\n    matrix_0 = generator[zeros]\n    matrix_1 = generator[ones]\n    mean = .5*(numpy.mean(matrix_1) + numpy.mean(matrix_0))\n    matrix_0 -= mean\n    matrix_1 -= mean\n\n    out = [\n        numpy.mean(matrix_1*((generator[index]-mean)-matrix_0), -1) /\n        numpy.where(variance, variance, 1)\n        for index in numpy.eye(dim, dtype=bool)\n    ]\n\n    return numpy.array(out)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to generate sensitivity indices for a set of random elements from a polynomial.", "response": "def Sens_m2_sample(poly, dist, samples, rule=\"R\"):\n    \"\"\"\n    Second order sensitivity indices estimated using Saltelli's method.\n\n    Args:\n        poly (chaospy.Poly):\n            If provided, evaluated samples through polynomials before returned.\n        dist (chaopy.Dist):\n            distribution to sample from.\n        samples (int):\n            The number of samples to draw for each matrix.\n        rule (str):\n            Scheme for generating random samples.\n\n    Return:\n        (numpy.ndarray):\n            array with `shape == (len(dist), len(dist), len(poly))` where\n            `sens[dim1][dim2][pol]` is the correlating sensitivity between\n            dimension `dim1` and `dim2` and polynomial index `pol`.\n\n    Examples:\n        >>> dist = chaospy.Iid(chaospy.Uniform(), 2)\n        >>> poly = chaospy.basis(2, 2, dim=2)\n        >>> print(poly)\n        [q0^2, q0q1, q1^2]\n        >>> print(numpy.around(Sens_m2_sample(poly, dist, 10000, rule=\"H\"), 4))\n        [[[ 0.008   0.0026  0.    ]\n          [-0.0871  1.1516  1.2851]]\n        <BLANKLINE>\n         [[-0.0871  1.1516  1.2851]\n          [ 0.      0.7981  1.38  ]]]\n    \"\"\"\n    dim = len(dist)\n\n    generator = Saltelli(dist, samples, poly, rule=rule)\n\n    zeros = [0]*dim\n    ones = [1]*dim\n    index = [0]*dim\n\n    variance = numpy.var(generator[zeros], -1)\n\n    matrix_0 = generator[zeros]\n    matrix_1 = generator[ones]\n    mean = .5*(numpy.mean(matrix_1) + numpy.mean(matrix_0))\n\n    matrix_0 -= mean\n    matrix_1 -= mean\n\n    out = numpy.empty((dim, dim)+poly.shape)\n    for dim1 in range(dim):\n\n        index[dim1] = 1\n        matrix = generator[index]-mean\n        out[dim1, dim1] = numpy.mean(\n            matrix_1*(matrix-matrix_0),\n            -1,\n        ) / numpy.where(variance, variance, 1)\n\n        for dim2 in range(dim1+1, dim):\n\n            index[dim2] = 1\n\n            matrix = generator[index]-mean\n\n            out[dim1, dim2] = out[dim2, dim1] = numpy.mean(\n                matrix_1*(matrix-matrix_0),\n                -1,\n            ) / numpy.where(variance, variance, 1)\n\n            index[dim2] = 0\n\n        index[dim1] = 0\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Sens_t_sample(poly, dist, samples, rule=\"R\"):\n    generator = Saltelli(dist, samples, poly, rule=rule)\n\n    dim = len(dist)\n    zeros = [0]*dim\n    variance = numpy.var(generator[zeros], -1)\n    return numpy.array([\n        1-numpy.mean((generator[~index]-generator[zeros])**2, -1,) /\n        (2*numpy.where(variance, variance, 1))\n        for index in numpy.eye(dim, dtype=bool)\n    ])", "response": "Return a random set of sensitivity indices estimated using Saltelli s method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _bnd(self, xloc, left, right, cache):\n        left = evaluation.get_forward_cache(left, cache)\n        right = evaluation.get_forward_cache(right, cache)\n\n        if isinstance(left, Dist):\n            if isinstance(right, Dist):\n                raise evaluation.DependencyError(\n                    \"under-defined distribution {} or {}\".format(left, right))\n        elif not isinstance(right, Dist):\n            return left+right, left+right\n        else:\n            left, right = right, left\n\n        right = numpy.asfarray(right)\n        if len(right.shape) == 3:\n            xloc_ = (xloc.T-right[0].T).T\n            lower, upper = evaluation.evaluate_bound(left, xloc_, cache=cache.copy())\n            lower0, upper0 = (lower.T+right[0].T).T, (upper.T+right[0].T).T\n\n            xloc_ = (xloc.T-right[1].T).T\n            lower, upper = evaluation.evaluate_bound(left, xloc_, cache=cache)\n            lower1, upper1 = (lower.T+right[1].T).T, (upper.T+right[1].T).T\n\n            lower = numpy.min([lower0, lower1], 0)\n            upper = numpy.max([upper0, upper1], 0)\n\n        else:\n            xloc_ = (xloc.T-right.T).T\n            lower, upper = evaluation.evaluate_bound(left, xloc_, cache=cache.copy())\n            lower, upper = (lower.T+right.T).T, (upper.T+right.T).T\n\n        assert lower.shape == xloc.shape\n        assert upper.shape == xloc.shape\n        return lower, upper", "response": "Function that returns the bounds of a single entry in a set of cache entries."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _pdf(self, xloc, left, right, cache):\n        left = evaluation.get_forward_cache(left, cache)\n        right = evaluation.get_forward_cache(right, cache)\n\n        if isinstance(left, Dist):\n            if isinstance(right, Dist):\n                raise evaluation.DependencyError(\n                    \"under-defined distribution {} or {}\".format(left, right))\n        elif not isinstance(right, Dist):\n            return numpy.inf\n        else:\n            left, right = right, left\n\n        xloc = (xloc.T-numpy.asfarray(right).T).T\n        output = evaluation.evaluate_density(left, xloc, cache=cache)\n        assert output.shape == xloc.shape\n        return output", "response": "Evaluate the probability density function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ppf(self, uloc, left, right, cache):\n        left = evaluation.get_inverse_cache(left, cache)\n        right = evaluation.get_inverse_cache(right, cache)\n\n        if isinstance(left, Dist):\n            if isinstance(right, Dist):\n                raise evaluation.DependencyError(\n                    \"under-defined distribution {} or {}\".format(left, right))\n        elif not isinstance(right, Dist):\n            return left+right\n        else:\n            left, right = right, left\n\n        xloc = evaluation.evaluate_inverse(left, uloc, cache=cache)\n        output = (xloc.T + numpy.asfarray(right).T).T\n        return output", "response": "Point percentile function.\n\n        Example:\n            >>> print(chaospy.Uniform().inv([0.1, 0.2, 0.9]))\n            [0.1 0.2 0.9]\n            >>> print(chaospy.Add(chaospy.Uniform(), 2).inv([0.1, 0.2, 0.9]))\n            [2.1 2.2 2.9]\n            >>> print(chaospy.Add(2, chaospy.Uniform()).inv([0.1, 0.2, 0.9]))\n            [2.1 2.2 2.9]\n            >>> print(chaospy.Add(1, 1).inv([0.1, 0.2, 0.9]))\n            [2. 2. 2.]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _mom(self, keys, left, right, cache):\n        if evaluation.get_dependencies(left, right):\n            raise evaluation.DependencyError(\n                \"sum of dependent distributions not feasible: \"\n                \"{} and {}\".format(left, right)\n            )\n\n        keys_ = numpy.mgrid[tuple(slice(0, key+1, 1) for key in keys)]\n        keys_ = keys_.reshape(len(self), -1)\n\n        if isinstance(left, Dist):\n            left = [\n                evaluation.evaluate_moment(left, key, cache=cache)\n                for key in keys_.T\n            ]\n        else:\n            left = list(reversed(numpy.array(left).T**keys_.T))\n        if isinstance(right, Dist):\n            right = [\n                evaluation.evaluate_moment(right, key, cache=cache)\n                for key in keys_.T\n            ]\n        else:\n            right = list(reversed(numpy.array(right).T**keys_.T))\n\n        out = numpy.zeros(keys.shape)\n        for idx in range(keys_.shape[1]):\n            key = keys_.T[idx]\n            coef = comb(keys.T, key)\n            out += coef*left[idx]*right[idx]*(key <= keys.T)\n\n        if len(self) > 1:\n            out = numpy.prod(out, 1)\n        return out", "response": "Evaluates the statistical moments of the given set of keys."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ttr(self, kloc, left, right, cache):\n        if isinstance(left, Dist):\n            if isinstance(right, Dist):\n                raise StochasticallyDependentError(\n                    \"sum of distributions not feasible: \"\n                    \"{} and {}\".format(left, right)\n                )\n        else:\n            if not isinstance(right, Dist):\n                raise StochasticallyDependentError(\n                    \"recurrence coefficients for constants not feasible: \"\n                    \"{}\".format(left+right)\n                )\n            left, right = right, left\n\n        coeff0, coeff1 = evaluation.evaluate_recurrence_coefficients(\n            left, kloc, cache=cache)\n        return coeff0 + numpy.asarray(right), coeff1", "response": "Method to evaluate the recurrence coefficients for a given recurrence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_stieltjes(\n        dist, order, accuracy=100, normed=False, retall=False, **kws):\n    \"\"\"\n    Discretized Stieltjes' method.\n\n    Args:\n        dist (Dist):\n            Distribution defining the space to create weights for.\n        order (int):\n            The polynomial order create.\n        accuracy (int):\n            The quadrature order of the Clenshaw-Curtis nodes to\n            use at each step, if approximation is used.\n        retall (bool):\n            If included, more values are returned\n\n    Returns:\n        (list): List of polynomials, norms of polynomials and three terms\n            coefficients. The list created from the method with\n            ``len(orth) == order+1``. If ``len(dist) > 1``, then each\n            polynomials are multivariate.\n        (numpy.ndarray, numpy.ndarray, numpy.ndarray): If ``retall`` is true,\n            also return polynomial norms and the three term coefficients.\n            The norms of the polynomials with ``norms.shape = (dim, order+1)``\n            where ``dim`` are the number of dimensions in dist.  The\n            coefficients have ``shape == (dim, order+1)``.\n\n    Examples:\n        >>> dist = chaospy.J(chaospy.Normal(), chaospy.Weibull())\n        >>> orth, norms, coeffs1, coeffs2 = chaospy.generate_stieltjes(\n        ...     dist, 2, retall=True)\n        >>> print(chaospy.around(orth[2], 5))\n        [q0^2-1.0, q1^2-4.0q1+2.0]\n        >>> print(numpy.around(norms, 5))\n        [[1. 1. 2.]\n         [1. 1. 4.]]\n        >>> print(numpy.around(coeffs1, 5))\n        [[0. 0. 0.]\n         [1. 3. 5.]]\n        >>> print(numpy.around(coeffs2, 5))\n        [[1. 1. 2.]\n         [1. 1. 4.]]\n\n        >>> dist = chaospy.Uniform()\n        >>> orth, norms, coeffs1, coeffs2 = chaospy.generate_stieltjes(\n        ...     dist, 2, retall=True)\n        >>> print(chaospy.around(orth[2], 8))\n        q0^2-q0+0.16666667\n        >>> print(numpy.around(norms, 4))\n        [[1.     0.0833 0.0056]]\n    \"\"\"\n    from .. import distributions\n    assert not distributions.evaluation.get_dependencies(dist)\n\n    if len(dist) > 1:\n\n        # one for each dimension:\n        orth, norms, coeff1, coeff2 = zip(*[generate_stieltjes(\n            _, order, accuracy, normed, retall=True, **kws) for _ in dist])\n\n        # ensure each polynomial has its own dimension:\n        orth = [[chaospy.setdim(_, len(orth)) for _ in poly] for poly in orth]\n        orth = [[chaospy.rolldim(_, len(dist)-idx) for _ in poly] for idx, poly in enumerate(orth)]\n        orth = [chaospy.poly.base.Poly(_) for _ in zip(*orth)]\n\n        if not retall:\n            return orth\n\n        # stack results:\n        norms = numpy.vstack(norms)\n        coeff1 = numpy.vstack(coeff1)\n        coeff2 = numpy.vstack(coeff2)\n\n        return orth, norms, coeff1, coeff2\n\n    try:\n        orth, norms, coeff1, coeff2 = _stieltjes_analytical(\n            dist, order, normed)\n    except NotImplementedError:\n        orth, norms, coeff1, coeff2 = _stieltjes_approx(\n            dist, order, accuracy, normed, **kws)\n\n    if retall:\n        assert not numpy.any(numpy.isnan(coeff1))\n        assert not numpy.any(numpy.isnan(coeff2))\n        return orth, norms, coeff1, coeff2\n    return orth", "response": "Generates a new set of polynomials and three terms for a given set of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a random set of unique samples for a single site.", "response": "def create_sobol_samples(order, dim, seed=1):\n    \"\"\"\n    Args:\n        order (int):\n            Number of unique samples to generate.\n        dim (int):\n            Number of spacial dimensions. Must satisfy ``0 < dim < 41``.\n        seed (int):\n            Starting seed. Non-positive values are treated as 1. If omitted,\n            consecutive samples are used.\n\n    Returns:\n        (numpy.ndarray):\n            Quasi-random vector with ``shape == (dim, order)``.\n    \"\"\"\n    assert 0 < dim < DIM_MAX, \"dim in [1, 40]\"\n\n    # global RANDOM_SEED  # pylint: disable=global-statement\n    # if seed is None:\n    #     seed = RANDOM_SEED\n    # RANDOM_SEED += order\n    set_state(seed_value=seed)\n    seed = RANDOM_SEED\n    set_state(step=order)\n\n    # Initialize row 1 of V.\n    samples = SOURCE_SAMPLES.copy()\n    maxcol = int(math.log(2**LOG_MAX-1, 2))+1\n    samples[0, 0:maxcol] = 1\n\n    # Initialize the remaining rows of V.\n    for idx in range(1, dim):\n\n        # The bits of the integer POLY(I) gives the form of polynomial:\n        degree = int(math.log(POLY[idx], 2))\n\n        #Expand this bit pattern to separate components:\n        includ = numpy.array([val == \"1\" for val in bin(POLY[idx])[-degree:]])\n\n        #Calculate the remaining elements of row I as explained\n        #in Bratley and Fox, section 2.\n        for idy in range(degree+1, maxcol+1):\n            newv = samples[idx, idy-degree-1].item()\n            base = 1\n            for idz in range(1, degree+1):\n                base *= 2\n                if includ[idz-1]:\n                    newv = newv ^ base * samples[idx, idy-idz-1].item()\n            samples[idx, idy-1] = newv\n\n    samples = samples[:dim]\n\n    # Multiply columns of V by appropriate power of 2.\n    samples *= 2**(numpy.arange(maxcol, 0, -1, dtype=int))\n\n    #RECIPD is 1/(common denominator of the elements in V).\n    recipd = 0.5**(maxcol+1)\n    lastq = numpy.zeros(dim, dtype=int)\n\n    seed = int(seed) if seed > 1 else 1\n\n    for seed_ in range(seed):\n        lowbit = len(bin(seed_)[2:].split(\"0\")[-1])\n        lastq[:] = lastq ^ samples[:, lowbit]\n\n    #Calculate the new components of QUASI.\n    quasi = numpy.empty((dim, order))\n    for idx in range(order):\n        lowbit = len(bin(seed+idx)[2:].split(\"0\")[-1])\n        quasi[:, idx] = lastq * recipd\n        lastq[:] = lastq ^ samples[:, lowbit]\n\n    return quasi"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a generator function that creates a multivariate integration rule for the given set of functions.", "response": "def rule_generator(*funcs):\n    \"\"\"\n    Constructor for creating multivariate quadrature generator.\n\n    Args:\n        funcs (:py:data:typing.Callable):\n            One dimensional integration rule where each rule returns\n            ``abscissas`` and ``weights`` as one dimensional arrays. They must\n            take one positional argument ``order``.\n\n    Returns:\n        (:py:data:typing.Callable):\n            Multidimensional integration quadrature function that takes the\n            arguments ``order`` and ``sparse``, and a optional ``part``. The\n            argument ``sparse`` is used to select for if Smolyak sparse grid is\n            used, and ``part`` defines if subset of rule should be generated\n            (for parallelization).\n\n    Example:\n        >>> clenshaw_curtis = lambda order: chaospy.quad_clenshaw_curtis(\n        ...         order, lower=-1, upper=1, growth=True)\n        >>> gauss_legendre = lambda order: chaospy.quad_gauss_legendre(\n        ...         order, lower=0, upper=1)\n        >>> quad_func = chaospy.rule_generator(clenshaw_curtis, gauss_legendre)\n        >>> abscissas, weights = quad_func(1)\n        >>> print(numpy.around(abscissas, 4))\n        [[-1.     -1.      0.      0.      1.      1.    ]\n         [ 0.2113  0.7887  0.2113  0.7887  0.2113  0.7887]]\n        >>> print(numpy.around(weights, 4))\n        [0.1667 0.1667 0.6667 0.6667 0.1667 0.1667]\n    \"\"\"\n    dim = len(funcs)\n    tensprod_rule = create_tensorprod_function(funcs)\n    assert hasattr(tensprod_rule, \"__call__\")\n\n    mv_rule = create_mv_rule(tensprod_rule, dim)\n    assert hasattr(mv_rule, \"__call__\")\n    return mv_rule"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a function that returns a tensor product rule.", "response": "def create_tensorprod_function(funcs):\n    \"\"\"Combine 1-D rules into multivariate rule using tensor product.\"\"\"\n    dim = len(funcs)\n\n    def tensprod_rule(order, part=None):\n        \"\"\"Tensor product rule.\"\"\"\n        order = order*numpy.ones(dim, int)\n        values = [funcs[idx](order[idx]) for idx in range(dim)]\n\n        abscissas = [numpy.array(_[0]).flatten() for _ in values]\n        abscissas = chaospy.quad.combine(abscissas, part=part).T\n\n        weights = [numpy.array(_[1]).flatten() for _ in values]\n        weights = numpy.prod(chaospy.quad.combine(weights, part=part), -1)\n\n        return abscissas, weights\n\n    return tensprod_rule"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_mv_rule(tensorprod_rule, dim):\n    def mv_rule(order, sparse=False, part=None):\n        \"\"\"\n        Multidimensional integration rule.\n\n        Args:\n            order (int, numpy.ndarray) : order of integration rule. If numpy.ndarray,\n                order along each axis.\n            sparse (bool) : use Smolyak sparse grid.\n\n        Returns:\n            (numpy.ndarray, numpy.ndarray) abscissas and weights.\n        \"\"\"\n        if sparse:\n            order = numpy.ones(dim, dtype=int)*order\n            tensorprod_rule_ = lambda order, part=part:\\\n                tensorprod_rule(order, part=part)\n            return chaospy.quad.sparse_grid(tensorprod_rule_, order)\n\n        return tensorprod_rule(order, part=part)\n\n    return mv_rule", "response": "Convert a tensor product rule into a multivariate quadrature generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quad_fejer(order, lower=0, upper=1, growth=False, part=None):\n    order = numpy.asarray(order, dtype=int).flatten()\n    lower = numpy.asarray(lower).flatten()\n    upper = numpy.asarray(upper).flatten()\n\n    dim = max(lower.size, upper.size, order.size)\n\n    order = numpy.ones(dim, dtype=int)*order\n    lower = numpy.ones(dim)*lower\n    upper = numpy.ones(dim)*upper\n\n    composite = numpy.array([numpy.arange(2)]*dim)\n\n    if growth:\n        results = [\n            _fejer(numpy.where(order[i] == 0, 0, 2.**(order[i]+1)-2))\n            for i in range(dim)\n        ]\n    else:\n        results = [\n            _fejer(order[i], composite[i]) for i in range(dim)\n        ]\n\n    abscis = [_[0] for _ in results]\n    weight = [_[1] for _ in results]\n\n    abscis = chaospy.quad.combine(abscis, part=part).T\n    weight = chaospy.quad.combine(weight, part=part)\n\n    abscis = ((upper-lower)*abscis.T + lower).T\n    weight = numpy.prod(weight*(upper-lower), -1)\n\n    assert len(abscis) == dim\n    assert len(weight) == len(abscis.T)\n\n    return abscis, weight", "response": "Generate the quadrature abscissas and weights in Fejer quadrature."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fejer(order, composite=None):\n    order = int(order)\n    if order == 0:\n        return numpy.array([.5]), numpy.array([1.])\n\n    order += 2\n\n    theta = (order-numpy.arange(order+1))*numpy.pi/order\n    abscisas = 0.5*numpy.cos(theta) + 0.5\n\n    N, K = numpy.mgrid[:order+1, :order//2]\n    weights = 2*numpy.cos(2*(K+1)*theta[N])/(4*K*(K+2)+3)\n    if order % 2 == 0:\n        weights[:, -1] *= 0.5\n    weights = (1-numpy.sum(weights, -1)) / order\n\n    return abscisas[1:-1], weights[1:-1]", "response": "r September 1. 4. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 3. 2. 2."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a random sample of the latin hyper - cube.", "response": "def create_latin_hypercube_samples(order, dim=1):\n    \"\"\"\n    Latin Hypercube sampling.\n\n    Args:\n        order (int):\n            The order of the latin hyper-cube. Defines the number of samples.\n        dim (int):\n            The number of dimensions in the latin hyper-cube.\n\n    Returns (numpy.ndarray):\n        Latin hyper-cube with ``shape == (dim, order)``.\n    \"\"\"\n    randoms = numpy.random.random(order*dim).reshape((dim, order))\n    for dim_ in range(dim):\n        perm = numpy.random.permutation(order)  # pylint: disable=no-member\n        randoms[dim_] = (perm + randoms[dim_])/order\n    return randoms"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates samples from the Hammersley set.", "response": "def create_hammersley_samples(order, dim=1, burnin=-1, primes=()):\n    \"\"\"\n    Create samples from the Hammersley set.\n\n    For ``dim == 1`` the sequence falls back to Van Der Corput sequence.\n\n    Args:\n        order (int):\n            The order of the Hammersley sequence. Defines the number of samples.\n        dim (int):\n            The number of dimensions in the Hammersley sequence.\n        burnin (int):\n            Skip the first ``burnin`` samples. If negative, the maximum of\n            ``primes`` is used.\n        primes (tuple):\n            The (non-)prime base to calculate values along each axis. If\n            empty, growing prime values starting from 2 will be used.\n\n    Returns:\n        (numpy.ndarray):\n            Hammersley set with ``shape == (dim, order)``.\n    \"\"\"\n    if dim == 1:\n        return create_halton_samples(\n            order=order, dim=1, burnin=burnin, primes=primes)\n    out = numpy.empty((dim, order), dtype=float)\n    out[:dim-1] = create_halton_samples(\n        order=order, dim=dim-1, burnin=burnin, primes=primes)\n    out[dim-1] = numpy.linspace(0, 1, order+2)[1:-1]\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate prime values from 2 and up to threshold.", "response": "def create_primes(threshold):\n    \"\"\"\n    Generate prime values using sieve of Eratosthenes method.\n\n    Args:\n        threshold (int):\n            The upper bound for the size of the prime values.\n\n    Returns (List[int]):\n        All primes from 2 and up to ``threshold``.\n    \"\"\"\n    if threshold == 2:\n        return [2]\n\n    elif threshold < 2:\n        return []\n\n    numbers = list(range(3, threshold+1, 2))\n    root_of_threshold = threshold ** 0.5\n    half = int((threshold+1)/2-1)\n    idx = 0\n    counter = 3\n    while counter <= root_of_threshold:\n        if numbers[idx]:\n            idy = int((counter*counter-3)/2)\n            numbers[idy] = 0\n            while idy < half:\n                numbers[idy] = 0\n                idy += counter\n        idx += 1\n        counter = 2*idx+3\n    return [2] + [number for number in numbers if number]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nevaluates inverse Rosenblatt transformation at a given location.", "response": "def evaluate_inverse(\n        distribution,\n        u_data,\n        cache=None,\n        parameters=None\n):\n    \"\"\"\n    Evaluate inverse Rosenblatt transformation.\n\n    Args:\n        distribution (Dist):\n            Distribution to evaluate.\n        u_data (numpy.ndarray):\n            Locations for where evaluate inverse transformation distribution at.\n        parameters (:py:data:typing.Any):\n            Collection of parameters to override the default ones in the\n            distribution.\n        cache (:py:data:typing.Any):\n            A collection of previous calculations in case the same distribution\n            turns up on more than one occasion.\n\n    Returns:\n        The cumulative distribution values of ``distribution`` at location\n        ``u_data`` using parameters ``parameters``.\n    \"\"\"\n    if cache is None:\n        cache = {}\n    out = numpy.zeros(u_data.shape)\n\n    # Distribution self know how to handle inverse Rosenblatt.\n    if hasattr(distribution, \"_ppf\"):\n        parameters = load_parameters(\n            distribution, \"_ppf\", parameters=parameters, cache=cache)\n        out[:] = distribution._ppf(u_data.copy(), **parameters)\n\n    # Approximate inverse Rosenblatt based on cumulative distribution function.\n    else:\n        from .. import approximation\n        parameters = load_parameters(\n            distribution, \"_cdf\", parameters=parameters, cache=cache)\n        out[:] = approximation.approximate_inverse(\n            distribution, u_data.copy(), cache=cache.copy(), parameters=parameters)\n\n    # Store cache.\n    cache[distribution] = out\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mom_110(self, idxi, idxj, idxk):\n        rank_ = min(\n            chaospy.bertran.rank(idxi, self.dim),\n            chaospy.bertran.rank(idxj, self.dim),\n            chaospy.bertran.rank(idxk, self.dim)\n        )\n        par, axis0 = chaospy.bertran.parent(idxj, self.dim)\n        gpar, _ = chaospy.bertran.parent(par, self.dim, axis0)\n        idxi_child = chaospy.bertran.child(idxi, self.dim, axis0)\n        oneup = chaospy.bertran.child(0, self.dim, axis0)\n\n        out = self(idxi_child, par, 0)\n        for k in range(gpar, idxj):\n            if chaospy.bertran.rank(k, self.dim) >= rank_:\n                out -= self.mom_111(oneup, par, k) * self.mom_111(idxi, k, 0)\n        return out", "response": "Backend moment for i j k == 1 1."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mom_recurse(self, idxi, idxj, idxk):\n        rank_ = min(\n            chaospy.bertran.rank(idxi, self.dim),\n            chaospy.bertran.rank(idxj, self.dim),\n            chaospy.bertran.rank(idxk, self.dim)\n        )\n        par, axis0 = chaospy.bertran.parent(idxk, self.dim)\n        gpar, _ = chaospy.bertran.parent(par, self.dim, axis0)\n        idxi_child = chaospy.bertran.child(idxi, self.dim, axis0)\n        oneup = chaospy.bertran.child(0, self.dim, axis0)\n\n        out1 = self.mom_111(idxi_child, idxj, par)\n        out2 = self.mom_111(\n            chaospy.bertran.child(oneup, self.dim, axis0), par, par)\n        for k in range(gpar, idxk):\n            if chaospy.bertran.rank(k, self.dim) >= rank_:\n                out1 -= self.mom_111(oneup, k, par) \\\n                    * self.mom_111(idxi, idxj, k)\n                out2 -= self.mom_111(oneup, par, k) \\\n                    * self(oneup, k, par)\n        return out1 / out2", "response": "This method recursively walks through the mement hierarchy to find the best match."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a sensitivity vector for a given set of samples for a given set of values.", "response": "def Sens_m_nataf(order, dist, samples, vals, **kws):\n    \"\"\"\n    Variance-based decomposition through the Nataf distribution.\n\n    Generates first order sensitivity indices\n\n    Args:\n        order (int):\n            Polynomial order used ``orth_ttr``.\n        dist (Copula):\n            Assumed to be Nataf with independent components\n        samples (numpy.ndarray):\n            Samples used for evaluation (typically generated from ``dist``.)\n        vals (numpy.ndarray): Evaluations of the model for given samples.\n\n    Returns:\n        (numpy.ndarray):\n            Sensitivity indices with shape ``(len(dist),) + vals.shape[1:]``.\n    \"\"\"\n    assert dist.__class__.__name__ == \"Copula\"\n    trans = dist.prm[\"trans\"]\n    assert trans.__class__.__name__ == \"nataf\"\n    vals = numpy.array(vals)\n\n    cov = trans.prm[\"C\"]\n    cov = numpy.dot(cov, cov.T)\n\n    marginal = dist.prm[\"dist\"]\n    dim = len(dist)\n\n    orth = chaospy.orthogonal.orth_ttr(order, marginal, sort=\"GR\")\n\n    r = range(dim)\n\n    index = [1] + [0]*(dim-1)\n\n    nataf = chaospy.dist.Nataf(marginal, cov, r)\n    samples_ = marginal.inv( nataf.fwd( samples ) )\n    poly, coeffs = chaospy.collocation.fit_regression(\n        orth, samples_, vals, retall=1)\n\n    V = Var(poly, marginal, **kws)\n\n    out = numpy.zeros((dim,) + poly.shape)\n    out[0] = Var(E_cond(poly, index, marginal, **kws),\n                 marginal, **kws)/(V+(V == 0))*(V != 0)\n\n\n    for i in range(1, dim):\n\n        r = r[1:] + r[:1]\n        index = index[-1:] + index[:-1]\n\n        nataf = chaospy.dist.Nataf(marginal, cov, r)\n        samples_ = marginal.inv( nataf.fwd( samples ) )\n        poly, coeffs = chaospy.collocation.fit_regression(\n            orth, samples_, vals, retall=1)\n\n        out[i] = Var(E_cond(poly, index, marginal, **kws),\n                     marginal, **kws)/(V+(V == 0))*(V != 0)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions to compute the bounding box of a set of items.", "response": "def _bnd(self, xloc, left, right, cache):\n        \"\"\"\n        Distribution bounds.\n\n        Example:\n            >>> print(chaospy.Uniform().range([-2, 0, 2, 4]))\n            [[0. 0. 0. 0.]\n             [1. 1. 1. 1.]]\n            >>> print(chaospy.Trunc(chaospy.Uniform(), 0.6).range([-2, 0, 2, 4]))\n            [[0.  0.  0.  0. ]\n             [0.6 0.6 0.6 0.6]]\n            >>> print(chaospy.Trunc(0.4, chaospy.Uniform()).range([-2, 0, 2, 4]))\n            [[0.4 0.4 0.4 0.4]\n             [1.  1.  1.  1. ]]\n        \"\"\"\n        if isinstance(left, Dist):\n            if left in cache:\n                left = cache[left]\n            else:\n                left = evaluation.evaluate_bound(left, xloc, cache=cache)\n        else:\n            left = (numpy.array(left).T * numpy.ones((2,)+xloc.shape).T).T\n\n        if isinstance(right, Dist):\n            if right in cache:\n                right = cache[right]\n            else:\n                right = evaluation.evaluate_bound(right, xloc, cache=cache)\n        else:\n            right = (numpy.array(right).T * numpy.ones((2,)+xloc.shape).T).T\n\n        return left[0], right[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npoints percentile function. Example: >>> print(chaospy.Uniform().inv([0.1, 0.2, 0.9])) [0.1 0.2 0.9] >>> print(chaospy.Trunc(chaospy.Uniform(), 0.4).inv([0.1, 0.2, 0.9])) [0.04 0.08 0.36] >>> print(chaospy.Trunc(0.6, chaospy.Uniform()).inv([0.1, 0.2, 0.9])) [0.64 0.68 0.96]", "response": "def _ppf(self, q, left, right, cache):\n        \"\"\"\n        Point percentile function.\n\n        Example:\n            >>> print(chaospy.Uniform().inv([0.1, 0.2, 0.9]))\n            [0.1 0.2 0.9]\n            >>> print(chaospy.Trunc(chaospy.Uniform(), 0.4).inv([0.1, 0.2, 0.9]))\n            [0.04 0.08 0.36]\n            >>> print(chaospy.Trunc(0.6, chaospy.Uniform()).inv([0.1, 0.2, 0.9]))\n            [0.64 0.68 0.96]\n        \"\"\"\n        if isinstance(left, Dist) and left in cache:\n            left = cache[left]\n        if isinstance(right, Dist) and right in cache:\n            right = cache[right]\n\n        if isinstance(left, Dist):\n            if isinstance(right, Dist):\n                raise StochasticallyDependentError(\n                    \"under-defined distribution {} or {}\".format(left, right))\n        elif not isinstance(right, Dist):\n            raise StochasticallyDependentError(\n                \"truncated variable indirectly depends on underlying variable\")\n        else:\n            left = (numpy.array(left).T*numpy.ones(q.shape).T).T\n            uloc = evaluation.evaluate_forward(right, left)\n            return evaluation.evaluate_inverse(right, q*(1-uloc)+uloc, cache=cache)\n\n        right = (numpy.array(right).T*numpy.ones(q.shape).T).T\n        uloc = evaluation.evaluate_forward(left, right, cache=cache.copy())\n        return evaluation.evaluate_inverse(left, q*uloc, cache=cache)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef basis(start, stop=None, dim=1, sort=\"G\", cross_truncation=1.):\n    if stop is None:\n        start, stop = numpy.array(0), start\n\n    start = numpy.array(start, dtype=int)\n    stop = numpy.array(stop, dtype=int)\n    dim = max(start.size, stop.size, dim)\n    indices = numpy.array(chaospy.bertran.bindex(\n        numpy.min(start), 2*numpy.max(stop), dim, sort, cross_truncation))\n\n    if start.size == 1:\n        bellow = numpy.sum(indices, -1) >= start\n\n    else:\n        start = numpy.ones(dim, dtype=int)*start\n        bellow = numpy.all(indices-start >= 0, -1)\n\n\n    if stop.size == 1:\n        above = numpy.sum(indices, -1) <= stop.item()\n    else:\n        stop = numpy.ones(dim, dtype=int)*stop\n        above = numpy.all(stop-indices >= 0, -1)\n\n    pool = list(indices[above*bellow])\n\n    arg = numpy.zeros(len(pool), dtype=int)\n    arg[0] = 1\n    poly = {}\n    for idx in pool:\n        idx = tuple(idx)\n        poly[idx] = arg\n        arg = numpy.roll(arg, 1)\n    x = numpy.zeros(len(pool), dtype=int)\n    x[0] = 1\n    A = {}\n    for I in pool:\n        I = tuple(I)\n        A[I] = x\n        x = numpy.roll(x,1)\n\n    return Poly(A, dim)", "response": "Returns a polynomial array that is a N - dimensional basis for a single entry in the current state of the entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cutoff(poly, *args):\n    if len(args) == 1:\n        low, high = 0, args[0]\n    else:\n        low, high = args[:2]\n\n    core_old = poly.A\n    core_new = {}\n    for key in poly.keys:\n        if low <= numpy.sum(key) < high:\n            core_new[key] = core_old[key]\n    return Poly(core_new, poly.dim, poly.shape, poly.dtype)", "response": "Remove polynomial components with order outside a given interval."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a Jacobian matrix that is the differential operator.", "response": "def differential(P, Q):\n    \"\"\"\n    Polynomial differential operator.\n\n    Args:\n        P (Poly):\n            Polynomial to be differentiated.\n        Q (Poly):\n            Polynomial to differentiate by. Must be decomposed. If polynomial\n            array, the output is the Jacobian matrix.\n    \"\"\"\n    P, Q = Poly(P), Poly(Q)\n\n    if not chaospy.poly.is_decomposed(Q):\n        differential(chaospy.poly.decompose(Q)).sum(0)\n\n    if Q.shape:\n        return Poly([differential(P, q) for q in Q])\n\n    if Q.dim>P.dim:\n        P = chaospy.poly.setdim(P, Q.dim)\n    else:\n        Q = chaospy.poly.setdim(Q, P.dim)\n\n    qkey = Q.keys[0]\n\n    A = {}\n    for key in P.keys:\n\n        newkey = numpy.array(key) - numpy.array(qkey)\n\n        if numpy.any(newkey<0):\n            continue\n\n        A[tuple(newkey)] = P.A[key]*numpy.prod([fac(key[i], \\\n            exact=True)/fac(newkey[i], exact=True) \\\n            for i in range(P.dim)])\n\n    return Poly(B, P.dim, P.shape, P.dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prange(N=1, dim=1):\n    A = {}\n    r = numpy.arange(N, dtype=int)\n    key = numpy.zeros(dim, dtype=int)\n    for i in range(N):\n        key[-1] = i\n        A[tuple(key)] = 1*(r==i)\n\n    return Poly(A, dim, (N,), int)", "response": "Returns a polynomial array where the exponent vary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rolldim(P, n=1):\n    dim = P.dim\n    shape = P.shape\n    dtype = P.dtype\n    A = dict(((key[n:]+key[:n],P.A[key]) for key in P.keys))\n    return Poly(A, dim, shape, dtype)", "response": "Roll the axes of the input polynomial."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef swapdim(P, dim1=1, dim2=0):\n    if not isinstance(P, Poly):\n        return numpy.swapaxes(P, dim1, dim2)\n\n    dim = P.dim\n    shape = P.shape\n    dtype = P.dtype\n\n    if dim1==dim2:\n        return P\n\n    m = max(dim1, dim2)\n    if P.dim <= m:\n        P = chaospy.poly.dimension.setdim(P, m+1)\n        dim = m+1\n\n    A = {}\n\n    for key in P.keys:\n\n        val = P.A[key]\n        key = list(key)\n        key[dim1], key[dim2] = key[dim2], key[dim1]\n        A[tuple(key)] = val\n\n    return Poly(A, dim, shape, dtype)", "response": "Swap the dim between two variables."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlowering triangle of coefficients.", "response": "def tril(P, k=0):\n    \"\"\"Lower triangle of coefficients.\"\"\"\n    A = P.A.copy()\n    for key in P.keys:\n        A[key] = numpy.tril(P.A[key])\n    return Poly(A, dim=P.dim, shape=P.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tricu(P, k=0):\n    tri = numpy.sum(numpy.mgrid[[slice(0,_,1) for _ in P.shape]], 0)\n    tri = tri<len(tri) + k\n\n    if isinstance(P, Poly):\n        A = P.A.copy()\n        B = {}\n        for key in P.keys:\n            B[key] = A[key]*tri\n        return Poly(B, shape=P.shape, dim=P.dim, dtype=P.dtype)\n\n    out = P*tri\n    return out", "response": "Cross - diagonal upper triangle."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all(A, ax=None):\n    if isinstance(A, Poly):\n        out = numpy.zeros(A.shape, dtype=bool)\n        B = A.A\n        for key in A.keys:\n            out += all(B[key], ax)\n        return out\n\n    return numpy.all(A, ax)", "response": "Test if all values in A evaluate to True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new object with the given number of decimals rounded to the given number of decimals.", "response": "def around(A, decimals=0):\n    \"\"\"\n    Evenly round to the given number of decimals.\n\n    Args:\n        A (Poly, numpy.ndarray):\n            Input data.\n        decimals (int):\n            Number of decimal places to round to (default: 0).  If decimals is\n            negative, it specifies the number of positions to the left of the\n            decimal point.\n\n    Returns:\n        (Poly, numpy.ndarray):\n            Same type as A.\n\n    Examples:\n        >>> P = chaospy.prange(3)*2**-numpy.arange(0, 6, 2, float)\n        >>> print(P)\n        [1.0, 0.25q0, 0.0625q0^2]\n        >>> print(chaospy.around(P))\n        [1.0, 0.0, 0.0]\n        >>> print(chaospy.around(P, 2))\n        [1.0, 0.25q0, 0.06q0^2]\n    \"\"\"\n    if isinstance(A, Poly):\n        B = A.A.copy()\n        for key in A.keys:\n            B[key] = around(B[key], decimals)\n        return Poly(B, A.dim, A.shape, A.dtype)\n\n    return numpy.around(A, decimals)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef diag(A, k=0):\n    if isinstance(A, Poly):\n        core, core_new = A.A, {}\n        for key in A.keys:\n            core_new[key] = numpy.diag(core[key], k)\n\n        return Poly(core_new, A.dim, None, A.dtype)\n\n    return numpy.diag(A, k)", "response": "Extract or construct a diagonal polynomial array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove coefficients that is not larger than a given threshold.", "response": "def prune(A, threshold):\n    \"\"\"\n    Remove coefficients that is not larger than a given threshold.\n\n    Args:\n        A (Poly):\n            Input data.\n        threshold (float):\n            Threshold for which values to cut.\n\n    Returns:\n        (Poly):\n            Same type as A.\n\n    Examples:\n        >>> P = chaospy.sum(chaospy.prange(3)*2**-numpy.arange(0, 6, 2, float))\n        >>> print(P)\n        0.0625q0^2+0.25q0+1.0\n        >>> print(chaospy.prune(P, 0.1))\n        0.25q0+1.0\n        >>> print(chaospy.prune(P, 0.5))\n        1.0\n        >>> print(chaospy.prune(P, 1.5))\n        0.0\n    \"\"\"\n    if isinstance(A, Poly):\n        B = A.A.copy()\n        for key in A.keys:\n            values = B[key].copy()\n            values[numpy.abs(values) < threshold] = 0.\n            B[key] = values\n        return Poly(B, A.dim, A.shape, A.dtype)\n\n    A = A.copy()\n    A[numpy.abs(A) < threshold] = 0.\n    return A"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the PDF of the current state of the object.", "response": "def _pdf(self, xloc, cache, **kwargs):\n        \"\"\"\n        Example:\n            >>> dist = chaospy.J(chaospy.Uniform(), chaospy.Normal())\n            >>> print(numpy.around(dist.pdf([[-0.5, 0.5, 1.5], [-1, 0, 1]]), 4))\n            [0.     0.3989 0.    ]\n            >>> d0 = chaospy.Uniform()\n            >>> dist = chaospy.J(d0, d0+chaospy.Uniform())\n            >>> print(dist.pdf([[-0.5, 0.5, 1.5], [0, 1, 2]]))\n            [0. 1. 0.]\n        \"\"\"\n        floc = numpy.zeros(xloc.shape)\n        for dist in evaluation.sorted_dependencies(self, reverse=True):\n            if dist not in self.inverse_map:\n                continue\n            idx = self.inverse_map[dist]\n            xloc_ = xloc[idx].reshape(1, -1)\n            floc[idx] = evaluation.evaluate_density(\n                dist, xloc_, cache=cache)[0]\n        return floc"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to compute the Moment of a kinetic object.", "response": "def _mom(self, kloc, cache, **kwargs):\n        \"\"\"\n        Example:\n            >>> dist = chaospy.J(chaospy.Uniform(), chaospy.Normal())\n            >>> print(numpy.around(dist.mom([[0, 0, 1], [0, 1, 1]]), 4))\n            [1. 0. 0.]\n            >>> d0 = chaospy.Uniform()\n            >>> dist = chaospy.J(d0, d0+chaospy.Uniform())\n            >>> print(numpy.around(dist.mom([1, 1]), 4))\n            0.5833\n        \"\"\"\n        if evaluation.get_dependencies(*list(self.inverse_map)):\n            raise StochasticallyDependentError(\n                \"Joint distribution with dependencies not supported.\")\n        output = 1.\n        for dist in evaluation.sorted_dependencies(self):\n            if dist not in self.inverse_map:\n                continue\n            idx = self.inverse_map[dist]\n            kloc_ = kloc[idx].reshape(1)\n            output *= evaluation.evaluate_moment(dist, kloc_, cache=cache)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the T matrix for a given kloc.", "response": "def _ttr(self, kloc, cache, **kwargs):\n        \"\"\"\n        Example:\n            >>> dist = chaospy.J(chaospy.Uniform(), chaospy.Normal(), chaospy.Exponential())\n            >>> print(numpy.around(dist.ttr([[1, 2, 3], [1, 2, 3], [1, 2, 3]]), 4))\n            [[[0.5    0.5    0.5   ]\n              [0.0833 0.0667 0.0643]\n              [0.     0.     0.    ]]\n            <BLANKLINE>\n             [[1.     2.     3.    ]\n              [3.     5.     7.    ]\n              [1.     4.     9.    ]]]\n            >>> d0 = chaospy.Uniform()\n            >>> dist = chaospy.J(d0, d0+chaospy.Uniform())\n            >>> print(numpy.around(dist.ttr([1, 1]), 4)) # doctest: +IGNORE_EXCEPTION_DETAIL\n            Traceback (most recent call last):\n                ...\n            chaospy.distributions.baseclass.StochasticallyDependentError: Joint ...\n        \"\"\"\n        if evaluation.get_dependencies(*list(self.inverse_map)):\n            raise StochasticallyDependentError(\n                \"Joint distribution with dependencies not supported.\")\n        output = numpy.zeros((2,)+kloc.shape)\n        for dist in evaluation.sorted_dependencies(self):\n            if dist not in self.inverse_map:\n                continue\n            idx = self.inverse_map[dist]\n            kloc_ = kloc[idx].reshape(1)\n            values = evaluation.evaluate_recurrence_coefficients(\n                dist, kloc_, cache=cache)\n            output.T[idx] = values.T\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the rank - order correlation coefficient of a set of uncorrelated hypotheses.", "response": "def Spearman(poly, dist, sample=10000, retall=False, **kws):\n    \"\"\"\n    Calculate Spearman's rank-order correlation coefficient.\n\n    Args:\n        poly (Poly):\n            Polynomial of interest.\n        dist (Dist):\n            Defines the space where correlation is taken.\n        sample (int):\n            Number of samples used in estimation.\n        retall (bool):\n            If true, return p-value as well.\n\n    Returns:\n        (float, numpy.ndarray):\n            Correlation output ``rho``. Of type float if two-dimensional problem.\n            Correleation matrix if larger.\n        (float, numpy.ndarray):\n            The two-sided p-value for a hypothesis test whose null hypothesis\n            is that two sets of data are uncorrelated, has same dimension as\n            ``rho``.\n    \"\"\"\n    samples = dist.sample(sample, **kws)\n    poly = polynomials.flatten(poly)\n    Y = poly(*samples)\n    if retall:\n        return spearmanr(Y.T)\n    return spearmanr(Y.T)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef schnabel_eskow(mat, eps=1e-16):\n    mat = numpy.asfarray(mat)\n    tau = eps**(1/3.)\n\n    # Create the matrix err and mat.\n    size = mat.shape[0]\n    mat0 = mat\n    mat = 1*mat\n    err = numpy.zeros(size, dtype=float)\n\n    # Permutation matrix.\n    perm = numpy.eye(size)\n\n    # Calculate gamma.\n    gamma = abs(mat.diagonal()).max()\n\n    # Phase one, mat potentially positive definite.\n    ###############################################\n\n    def invariant(mat, k):\n        \"\"\"Return `True` if the invariant is satisfied.\"\"\"\n        A_ = numpy.eye(size)\n        L_ = numpy.eye(size)\n        A_[k:, k:] = numpy.triu(mat[k:, k:], 0) + numpy.triu(mat[k:, k:], 1).T\n        L_[:, :k] = numpy.tril(mat[:, :k])\n        return numpy.allclose(\n            numpy.dot(L_, numpy.dot(A_, L_.T)),\n            numpy.dot(perm, numpy.dot(mat0, perm.T)) + numpy.diag(err)\n        )\n\n    def jiter_factor(mat, j, perm, err):\n        \"\"\"Perform jth iteration of factorisation.\n        \"\"\"\n        assert invariant(mat, j)\n\n        mat[j, j] = numpy.sqrt(mat[j, j])\n        mat[j+1:, j] /= mat[j, j]\n        mat[j+1:, j+1:] -= mat[j+1:, j:j+1]*mat[j+1:, j:j+1].T\n        mat[j, j+1:] = 0\n\n        assert invariant(mat, j+1)\n\n    def permute(mat, perm, i, j):\n        \"\"\"Exchange rows and columns i and j of mat and recored the\n        permutation in perm\"\"\"\n        p = numpy.arange(size, dtype=int)\n        if i != j:\n            p[[i, j]] = j, i\n\n            perm[::] = perm[p, :]\n            mat[::] = mat[p, :]\n            mat[::] = mat[:, p]\n\n    def exec_phasetwo(mat, perm, err, j):\n        \"\"\"Phase 2 of the algorithm, mat not positive definite.\"\"\"\n        if j == size:\n            # delta = err[size].\n            delta = -mat[size-1, size-1] + max(\n                -tau*mat[size-1, size-1]/(1 - tau), tau*tau*gamma)\n\n            err[size-1] = delta\n            mat[size-1, size-1] += delta\n            mat[size-1, size-1] = numpy.sqrt(mat[size-1, size-1])\n\n        else:\n            # Number of iterations performed in phase one (less 1).\n            k = j - 1\n\n            # Calculate the lower Gerschgorin bounds of Ak+1.\n            tmp = mat[k+1:, k+1:]\n            g = tmp.diagonal().copy()\n            tmp = abs(numpy.tril(tmp, -1))\n            g -= tmp.sum(axis=0)\n            g -= tmp.sum(axis=1)\n\n            # Modified Cholesky decomposition.\n            delta_prev = 0.0\n            for j in range(k+1, size-2):\n                # Pivot on the maximum lower Gerschgorin bound\n                # estimate.\n                i = j + numpy.argmax(g[j-(k+1):])\n\n                # Interchange row and column i and j.\n                permute(mat, perm, i, j)\n\n                # Calculate err[j] and add to diagonal.\n                normj = abs(mat[j+1:, j]).sum()\n                delta = max(0.0,\n                            -mat[j, j] + max(normj, tau*tau*gamma),\n                            delta_prev)  # delta = E[size].\n\n                if delta > 0.0:\n                    mat[j, j] += delta\n                    delta_prev = delta\n                err[j] = delta\n\n                # Update Gerschgorin bound estimates.\n                if mat[j, j] != normj:\n                    temp = 1.0 - normj / mat[j, j]\n                    g[j-k:] += abs(mat[j+1:, j])*temp\n\n                # Perform jth iteration of factorisation.\n                jiter_factor(mat, j, perm, err)\n\n            # Final 2*2 submatrix.\n            mini = mat[-2:, -2:]\n            mini[1, 0] = mini[0, 1]\n            eigs = numpy.sort(numpy.linalg.eigvalsh(mini))\n            delta = max(\n                0, -eigs[0] + max(tau*(eigs[1] - eigs[0])/(1 - tau),\n                                  tau*tau*gamma), delta_prev)\n            if delta > 0.0:\n                mat[size-2, size-2] += delta\n                mat[size-1, size-1] += delta\n                delta_prev = delta\n            err[size-2] = err[size-1] = delta\n\n            mat[size-2, size-2] = numpy.sqrt(mat[size-2, size-2])\n            mat[size-1, size-2] /= mat[size-2, size-2]\n            mat[size-1, size-1] = numpy.sqrt(\n                mat[size-1, size-1] - mat[size-1, size-2]**2)\n\n    for j in range(size):\n\n        # Calculate max_Aii and min_Aii\n        diag = mat.diagonal()[j:]\n\n        # Test for phase 2, mat not positive definite.\n        if diag.max() < tau*tau * gamma or diag.min() < - 0.1 * diag.max():\n            exec_phasetwo(mat, perm, err, j)\n            break\n        else:\n            # Pivot on maximum diagonal of remaining submatrix.\n            i = j + numpy.argmax(mat.diagonal()[j:])\n\n            # Interchange row and column i and j.\n            permute(mat, perm, i, j)\n\n            # Test for phase 2 again.\n            min_num = 1e99\n            mat_diag = mat.diagonal()\n            if j + 1 < size:\n                min_num = (mat_diag[i] -\n                           mat[i, j+1:]**2/mat_diag[j+1:]).min()\n            else:\n                min_num = mat_diag[i]\n\n            if j+1 <= size and min_num < - 0.1 * gamma:\n                exec_phasetwo(mat, perm, err, j)\n                break\n\n            # Perform jth iteration of factorisation.\n            else:\n                jiter_factor(mat, j, perm, err)\n\n    # The Cholesky factor of mat.\n    return perm, numpy.tril(mat), err", "response": "Returns a new object that is modified Cholesky factorisation algorithm for modified Cholesky factorisation algorithm for modified Cholesky factorisation algorithm for modified Cholesky factorisation algorithm."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef available_services():\n    all_datas = ()\n    data = ()\n\n    for class_path in settings.TH_SERVICES:\n        class_name = class_path.rsplit('.', 1)[1]\n        # 2nd array position contains the name of the service\n        data = (class_name, class_name.rsplit('Service', 1)[1])\n        all_datas = (data,) + all_datas\n    return all_datas", "response": "get the available services to be activated by the administrator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle(self, *args, **options):\n        from django.db import connection\n        connection.close()\n        failed_tries = settings.DJANGO_TH.get('failed_tries', 10)\n        trigger = TriggerService.objects.filter(\n            Q(provider_failed__lte=failed_tries) |\n            Q(consumer_failed__lte=failed_tries),\n            status=True,\n            user__is_active=True,\n            provider__name__status=True,\n            consumer__name__status=True,\n        ).select_related('consumer__name', 'provider__name')\n        try:\n            with Pool(processes=settings.DJANGO_TH.get('processes')) as pool:\n                p = Pub()\n                result = pool.map_async(p.publishing, trigger)\n                result.get(timeout=60)\n        except TimeoutError as e:\n            logger.warning(e)", "response": "get all the triggers that need to be handled\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the data from the service", "response": "def read_data(self, **kwargs):\n        \"\"\"\n            get the data from the service\n\n            :param kwargs: contain keyword args : trigger_id at least\n            :type kwargs: dict\n            :rtype: list\n        \"\"\"\n        twitter_status_url = 'https://www.twitter.com/{}/status/{}'\n        twitter_fav_url = 'https://www.twitter.com/{}/status/{}'\n        now = arrow.utcnow().to(settings.TIME_ZONE)\n        my_tweets = []\n        search = {}\n        since_id = None\n        trigger_id = kwargs['trigger_id']\n        date_triggered = arrow.get(kwargs['date_triggered'])\n\n        def _get_tweets(twitter_obj, search):\n            \"\"\"\n                get the tweets from twitter and return the filters to use :\n                search and count\n\n                :param twitter_obj: from Twitter model\n                :param search: filter used for twython.search() or\n                twython.get_user_timeline())\n                :type twitter_obj: Object\n                :type search: dict\n                :return: count that limit the quantity of tweet to retrieve,\n                the filter named search, the tweets\n                :rtype: list\n            \"\"\"\n\n            \"\"\"\n                explanations about statuses :\n                when we want to track the tweet of a screen 'statuses' contain all of them\n                when we want to track all the tweet matching a tag 'statuses' contain statuses + metadata array\n                this is why we need to do statuses = statuses['statuses']\n                to be able to handle the result as for screen_name\n            \"\"\"\n\n            # get the tweets for a given tag\n            # https://dev.twitter.com/docs/api/1.1/get/search/tweets\n            statuses = ''\n            count = 100\n            if twitter_obj.tag:\n                count = 100\n                search['count'] = count\n                search['q'] = twitter_obj.tag\n                search['result_type'] = 'recent'\n                # do a search\n                statuses = self.twitter_api.search(**search)\n                # just return the content of te statuses array\n                statuses = statuses['statuses']\n\n            # get the tweets from a given user\n            # https://dev.twitter.com/docs/api/1.1/get/statuses/user_timeline\n            elif twitter_obj.screen:\n                count = 200\n                search['count'] = count\n                search['screen_name'] = twitter_obj.screen\n\n                # call the user timeline and get his tweet\n                try:\n                    if twitter_obj.fav:\n                        count = 20\n                        search['count'] = 20\n                        # get the favorites https://dev.twitter.com/rest/\n                        # reference/get/favorites/list\n                        statuses = self.twitter_api.get_favorites(**search)\n                    else:\n                        statuses = self.twitter_api.get_user_timeline(**search)\n                except TwythonAuthError as e:\n                    logger.error(e.msg, e.error_code)\n                    update_result(trigger_id, msg=e.msg, status=False)\n\n            return count, search, statuses\n\n        if self.token is not None:\n            kw = {'app_label': 'th_twitter', 'model_name': 'Twitter', 'trigger_id': trigger_id}\n            twitter_obj = super(ServiceTwitter, self).read_data(**kw)\n\n            # https://dev.twitter.com/rest/public/timelines\n            if twitter_obj.since_id is not None and twitter_obj.since_id > 0:\n                since_id = twitter_obj.since_id\n                search = {'since_id': twitter_obj.since_id}\n\n            # first request to Twitter\n            count, search, statuses = _get_tweets(twitter_obj, search)\n\n            if len(statuses) > 0:\n                newest = None\n                for status in statuses:\n                    if newest is None:\n                        newest = True\n                        # first query ; get the max id\n                        search['max_id'] = max_id = status['id']\n\n                since_id = search['since_id'] = statuses[-1]['id'] - 1\n\n                count, search, statuses = _get_tweets(twitter_obj, search)\n\n                newest = None\n                if len(statuses) > 0:\n                    my_tweets = []\n                    for s in statuses:\n                        if newest is None:\n                            newest = True\n                            max_id = s['id'] - 1\n                        screen_name = s['user']['screen_name']\n                        # get the text of the tweet + url to this one\n                        if twitter_obj.fav:\n                            url = twitter_fav_url.format(screen_name, s['id_str'])\n                            title = _('Tweet Fav from @{}'.format(screen_name))\n                        else:\n                            url = twitter_status_url.format(screen_name, s['id_str'])\n                            title = _('Tweet from @{}'.format(screen_name))\n                        # Wed Aug 29 17:12:58 +0000 2012\n                        my_date = arrow.get(s['created_at'], 'ddd MMM DD HH:mm:ss Z YYYY')\n                        published = arrow.get(my_date).to(settings.TIME_ZONE)\n                        if date_triggered is not None and published is not None and now >= published >= date_triggered:\n                            if s.get('extended_entities'):\n                                # get a media\n                                extended_entities = s['extended_entities']\n                                if extended_entities.get('media'):\n                                    medias = extended_entities.get('media')\n                                    for media in medias:\n                                        text = s['text'] + ' ' + media.get('media_url_https')\n                            else:\n                                text = s['text']\n\n                            my_tweets.append({'title': title,\n                                              'content': text,\n                                              'link': url,\n                                              'my_date': my_date})\n                            # digester\n                            self.send_digest_event(trigger_id, title, url)\n                    cache.set('th_twitter_' + str(trigger_id), my_tweets)\n                    Twitter.objects.filter(trigger_id=trigger_id).update(\n                        since_id=since_id,\n                        max_id=max_id,\n                        count=count)\n        return my_tweets"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_data(self, trigger_id, **data):\n        status = False\n        # set the title and content of the data\n        title, content = super(ServiceTwitter, self).save_data(trigger_id, **data)\n\n        if data.get('link') and len(data.get('link')) > 0:\n            # remove html tag if any\n            content = html.strip_tags(content)\n\n            if self.title_or_content(title):\n                content = str(\"{title} {link}\").format(title=title, link=data.get('link'))\n                content += get_tags(Twitter, trigger_id)\n            else:\n                content = self.set_twitter_content(content)\n\n            try:\n                self.twitter_api.update_status(status=content)\n                status = True\n            except Exception as inst:\n                logger.critical(\"Twitter ERR {}\".format(inst))\n                update_result(trigger_id, msg=inst, status=False)\n                status = False\n        return status", "response": "let s save the data from the service twitter API"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the request to access to the Twitter website with all its required parms", "response": "def auth(self, request):\n        \"\"\"\n        build the request to access to the Twitter\n        website with all its required parms\n        :param request: makes the url to call Twitter + the callback url\n        :return: go to the Twitter website to ask to the user\n        to allow the access of TriggerHappy\n        \"\"\"\n        callback_url = self.callback_url(request)\n\n        twitter = Twython(self.consumer_key, self.consumer_secret)\n\n        req_token = twitter.get_authentication_tokens(\n            callback_url=callback_url)\n        request.session['oauth_token'] = req_token['oauth_token']\n        request.session['oauth_token_secret'] = req_token['oauth_token_secret']\n\n        return req_token['auth_url']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall from the Service when the user accept the message.", "response": "def callback(self, request, **kwargs):\n        \"\"\"\n            Called from the Service when the user accept to activate it\n        \"\"\"\n        return super(ServiceTwitter, self).callback(request, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_access_token(\n        self, oauth_token, oauth_token_secret, oauth_verifier\n    ):\n        \"\"\"\n        :param oauth_token: oauth_token retrieve by the API Twython\n        get_authentication_tokens()\n        :param oauth_token_secret: oauth_token_secret retrieve by the\n        API Twython get_authentication_tokens()\n        :param oauth_verifier: oauth_verifier retrieve from Twitter\n        :type oauth_token: string\n        :type oauth_token_secret: string\n        :type oauth_verifier: string\n        :return: access_token\n        :rtype: dict\n        \"\"\"\n        twitter = Twython(self.consumer_key,\n                          self.consumer_secret,\n                          oauth_token,\n                          oauth_token_secret)\n        access_token = twitter.get_authorized_tokens(oauth_verifier)\n        return access_token", "response": "Retrieve an access token from Twitter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave data to the service", "response": "def save_data(self, trigger_id, **data):\n        \"\"\"\n            get the data from the service\n\n            :param trigger_id: id of the trigger\n            :params data, dict\n            :rtype: dict\n        \"\"\"\n        status = False\n        service = TriggerService.objects.get(id=trigger_id)\n        desc = service.description\n\n        slack = Slack.objects.get(trigger_id=trigger_id)\n\n        title = self.set_title(data)\n        if title is None:\n            title = data.get('subject')\n        type_action = data.get('type_action', '')\n\n        # set the bot username of Slack to the name of the\n        # provider service\n        username = service.provider.name.name.split('Service')[1]\n        # 'build' a link\n        title_link = ''\n        if data.get('permalink'):\n            title_link = ': <' + data.get('permalink') + '|' + title + '>'\n        else:\n            title_link = ': <' + data.get('link') + '|' + title + '>'\n\n        data = '*' + desc + '*: ' + type_action + title_link\n\n        payload = {'username': username,\n                   'text': data}\n\n        r = requests.post(slack.webhook_url, json=payload)\n\n        if r.status_code == requests.codes.ok:\n            status = True\n        # return the data\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the trigger to fire", "response": "def handle(self, *args, **options):\n        \"\"\"\n            get the trigger to fire\n        \"\"\"\n        trigger_id = options.get('trigger_id')\n        trigger = TriggerService.objects.filter(\n            id=int(trigger_id),\n            status=True,\n            user__is_active=True,\n            provider_failed__lt=settings.DJANGO_TH.get('failed_tries', 10),\n            consumer_failed__lt=settings.DJANGO_TH.get('failed_tries', 10)\n        ).select_related('consumer__name', 'provider__name')\n        try:\n            with Pool(processes=1) as pool:\n                r = Read()\n                result = pool.map_async(r.reading, trigger)\n                result.get(timeout=360)\n                p = Pub()\n                result = pool.map_async(p.publishing, trigger)\n                result.get(timeout=360)\n\n                cache.delete('django_th' + '_fire_trigger_' + str(trigger_id))\n        except TimeoutError as e:\n            logger.warning(e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_data(self, **kwargs):\n        trigger_id = kwargs.get('trigger_id')\n        trigger = Pushbullet.objects.get(trigger_id=trigger_id)\n        date_triggered = kwargs.get('date_triggered')\n        data = list()\n        pushes = self.pushb.get_pushes()\n        for p in pushes:\n            title = 'From Pushbullet'\n            created = arrow.get(p.get('created'))\n            if created > date_triggered and p.get('type') == trigger.type and\\\n               (p.get('sender_email') == p.get('receiver_email') or p.get('sender_email') is None):\n                title = title + ' Channel' if p.get('channel_iden') and p.get('title') is None else title\n                # if sender_email and receiver_email are the same ;\n                # that means that \"I\" made a note or something\n                # if sender_email is None, then \"an API\" does the post\n\n                body = p.get('body')\n                data.append({'title': title, 'content': body})\n                # digester\n                self.send_digest_event(trigger_id, title, '')\n\n        cache.set('th_pushbullet_' + str(trigger_id), data)\n        return data", "response": "read the data from the pushbullet service"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nletting s save the data from the data dict", "response": "def save_data(self, trigger_id, **data):\n        \"\"\"\n            let's save the data\n            :param trigger_id: trigger ID from which to save data\n            :param data: the data to check to be used and save\n            :type trigger_id: int\n            :type data:  dict\n            :return: the status of the save statement\n            :rtype: boolean\n        \"\"\"\n        title, content = super(ServicePushbullet, self).save_data(trigger_id, **data)\n        if self.token:\n            trigger = Pushbullet.objects.get(trigger_id=trigger_id)\n            if trigger.type == 'note':\n                status = self.pushb.push_note(title=title, body=content)\n            elif trigger.type == 'link':\n                status = self.pushb.push_link(title=title, body=content, url=data.get('link'))\n                sentence = str('pushbullet {} created').format(title)\n                logger.debug(sentence)\n            else:\n                # no valid type of pushbullet specified\n                msg = \"no valid type of pushbullet specified\"\n                logger.critical(msg)\n                update_result(trigger_id, msg=msg, status=False)\n                status = False\n        else:\n            msg = \"no token or link provided for trigger ID {} \".format(trigger_id)\n            logger.critical(msg)\n            update_result(trigger_id, msg=msg, status=False)\n            status = False\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef html_entity_decode_char(self, m, defs=htmlentities.entitydefs):\n        try:\n            char = defs[m.group(1)]\n            return \"&{char};\".format(char=char)\n        except ValueError:\n            return m.group(0)\n        except KeyError:\n            return m.group(0)", "response": "decode html entity into one of the html char"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef html_entity_decode_codepoint(self, m,\n                                     defs=htmlentities.codepoint2name):\n        \"\"\"\n            decode html entity into one of the codepoint2name\n        \"\"\"\n        try:\n            char = defs[m.group(1)]\n            return \"&{char};\".format(char=char)\n        except ValueError:\n            return m.group(0)\n        except KeyError:\n            return m.group(0)", "response": "decode html entity into one of the codepoint2name\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if we want to track event for a given action", "response": "def data_filter(trigger_id, **data):\n    \"\"\"\n    check if we want to track event for a given action\n    :param trigger_id:\n    :param data:\n    :return:\n    \"\"\"\n    taiga_obj = Taiga.objects.get(trigger_id=trigger_id)\n\n    action = data.get('action')\n    domain = data.get('type')\n    data = data.get('data')\n\n    t = TaigaDomain.factory(domain)\n    if action == 'create':\n        t.create(taiga_obj, data)\n    elif action == 'change':\n        t.change(taiga_obj, data)\n    elif action == 'delete':\n        t.delete(taiga_obj, data)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves data to the data base on the trigger_id", "response": "def save_data(trigger_id, data):\n    \"\"\"\n        call the consumer and handle the data\n        :param trigger_id:\n        :param data:\n        :return:\n    \"\"\"\n    status = True\n    # consumer - the service which uses the data\n    default_provider.load_services()\n    service = TriggerService.objects.get(id=trigger_id)\n\n    service_consumer = default_provider.get_service(str(service.consumer.name.name))\n    kwargs = {'user': service.user}\n\n    if len(data) > 0:\n        getattr(service_consumer, '__init__')(service.consumer.token, **kwargs)\n        status = getattr(service_consumer, 'save_data')(service.id, **data)\n\n    return status"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_entry(self, url, title, tags):\n        try:\n            self.pocket.add(url=url, title=title, tags=tags)\n            sentence = str('pocket {} created').format(url)\n            logger.debug(sentence)\n            status = True\n        except Exception as e:\n            logger.critical(e)\n            update_result(self.trigger_id, msg=e, status=False)\n            status = False\n        return status", "response": "Create an entry in the nationacloud."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the data from the service", "response": "def read_data(self, **kwargs):\n        \"\"\"\n            get the data from the service\n            As the pocket service does not have any date in its API linked to the note,\n            add the triggered date to the dict data thus the service will be triggered when data will be found\n\n            :param kwargs: contain keyword args : trigger_id at least\n            :type kwargs: dict\n\n            :rtype: list\n        \"\"\"\n        trigger_id = kwargs.get('trigger_id')\n        date_triggered = kwargs.get('date_triggered')\n\n        data = list()\n        # pocket uses a timestamp date format\n        since = arrow.get(date_triggered).timestamp\n        if self.token is not None:\n\n            # get the data from the last time the trigger have been started\n            # timestamp form\n            pockets = self.pocket.get(since=since, state=\"unread\")\n            content = ''\n            if pockets is not None and len(pockets[0]['list']) > 0:\n                for my_pocket in pockets[0]['list'].values():\n                    if my_pocket.get('excerpt'):\n                        content = my_pocket['excerpt']\n                    elif my_pocket.get('given_title'):\n                        content = my_pocket['given_title']\n                    my_date = arrow.get(str(date_triggered), 'YYYY-MM-DD HH:mm:ss').to(settings.TIME_ZONE)\n                    data.append({'my_date': str(my_date),\n                                 'tag': '',\n                                 'link': my_pocket['given_url'],\n                                 'title': my_pocket['given_title'],\n                                 'content': content,\n                                 'tweet_id': 0})\n                    # digester\n                    self.send_digest_event(trigger_id, my_pocket['given_title'], my_pocket['given_url'])\n                cache.set('th_pocket_' + str(trigger_id), data)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_data(self, trigger_id, **data):\n        if data.get('link'):\n            if len(data.get('link')) > 0:\n                # get the pocket data of this trigger\n                from th_pocket.models import Pocket as PocketModel\n                trigger = PocketModel.objects.get(trigger_id=trigger_id)\n\n                title = self.set_title(data)\n                # convert htmlentities\n                title = HtmlEntities(title).html_entity_decode\n\n                status = self._create_entry(url=data.get('link'),\n                                            title=title,\n                                            tags=(trigger.tag.lower()))\n            else:\n                msg = \"no link provided for trigger ID {}, so we ignore it\".format(trigger_id)\n                logger.warning(msg)\n                update_result(trigger_id, msg=msg, status=True)\n                status = True\n        else:\n            msg = \"no token provided for trigger ID {}\".format(trigger_id)\n            logger.critical(msg)\n            update_result(trigger_id, msg=msg, status=False)\n            status = False\n        return status", "response": "let s save the data of the current object in the database"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef auth(self, request):\n        callback_url = self.callback_url(request)\n\n        request_token = Pocket.get_request_token(consumer_key=self.consumer_key, redirect_uri=callback_url)\n        # Save the request token information for later\n        request.session['request_token'] = request_token\n        # URL to redirect user to, to authorize your app\n        auth_url = Pocket.get_auth_url(code=request_token, redirect_uri=callback_url)\n\n        return auth_url", "response": "Auth the user to the Service\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef callback(self, request, **kwargs):\n        access_token = Pocket.get_access_token(consumer_key=self.consumer_key, code=request.session['request_token'])\n        kwargs = {'access_token': access_token}\n        return super(ServicePocket, self).callback(request, **kwargs)", "response": "Called from the Service when the user accept the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_prohibited_element(tag_name, document_element):\n    elements = document_element.getElementsByTagName(tag_name)\n    for element in elements:\n        p = element.parentNode\n        p.removeChild(element)", "response": "Removes a prohibited element from the document element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_data(self, **kwargs):\n        now = arrow.utcnow().to(settings.TIME_ZONE)\n        my_toots = []\n        search = {}\n        since_id = None\n        trigger_id = kwargs['trigger_id']\n        date_triggered = arrow.get(kwargs['date_triggered'])\n\n        def _get_toots(toot_api, toot_obj, search):\n            \"\"\"\n                get the toots from mastodon and return the filters to use\n\n                :param toot_obj: from Mastodon model\n                :param search: filter used for MastodonAPI.search()\n                :type toot_obj: Object ServiceMastodon\n                :type search: dict\n                :return: the filter named search, the toots\n                :rtype: list\n            \"\"\"\n            max_id = 0 if toot_obj.max_id is None else toot_obj.max_id\n            since_id = 0 if toot_obj.since_id is None else toot_obj.since_id\n            # get the toots for a given tag\n            statuses = ''\n\n            if toot_obj.tag:\n                search['q'] = toot_obj.tag\n                # do a search\n                statuses = toot_api.search(**search)\n                # just return the content of te statuses array\n                statuses = statuses['statuses']\n\n            # get the tweets from a given user\n            elif toot_obj.tooter:\n                search['id'] = toot_obj.tooter\n                # call the user timeline and get his toot\n                if toot_obj.fav:\n                    statuses = toot_api.favourites(max_id=max_id,\n                                                   since_id=since_id)\n                else:\n                    user_id = toot_api.account_search(q=toot_obj.tooter)\n                    statuses = toot_api.account_statuses(\n                        id=user_id[0]['id'], max_id=toot_obj.max_id,\n                        since_id=toot_obj.since_id)\n\n            return search, statuses\n\n        if self.token is not None:\n            kw = {'app_label': 'th_mastodon', 'model_name': 'Mastodon', 'trigger_id': trigger_id}\n            toot_obj = super(ServiceMastodon, self).read_data(**kw)\n\n            us = UserService.objects.get(token=self.token, name='ServiceMastodon')\n            try:\n                toot_api = MastodonAPI(\n                    client_id=us.client_id,\n                    client_secret=us.client_secret,\n                    access_token=self.token,\n                    api_base_url=us.host,\n                )\n            except ValueError as e:\n                logger.error(e)\n                update_result(trigger_id, msg=e, status=False)\n\n            if toot_obj.since_id is not None and toot_obj.since_id > 0:\n                since_id = toot_obj.since_id\n                search = {'since_id': toot_obj.since_id}\n\n            # first request to Mastodon\n            search, statuses = _get_toots(toot_api, toot_obj, search)\n\n            if len(statuses) > 0:\n                newest = None\n                for status in statuses:\n                    if newest is None:\n                        newest = True\n                        # first query ; get the max id\n                        search['max_id'] = max_id = status['id']\n\n                since_id = search['since_id'] = statuses[-1]['id'] - 1\n\n                search, statuses = _get_toots(toot_api, toot_obj, search)\n\n                newest = None\n                if len(statuses) > 0:\n                    my_toots = []\n                    for s in statuses:\n                        if newest is None:\n                            newest = True\n                            max_id = s['id'] - 1\n                        toot_name = s['account']['username']\n                        # get the text of the tweet + url to this one\n\n                        title = _('Toot from <a href=\"{}\">@{}</a>'.\n                                  format(us.host, toot_name))\n\n                        my_date = arrow.get(s['created_at']).to(\n                            settings.TIME_ZONE)\n                        published = arrow.get(my_date).to(settings.TIME_ZONE)\n                        if date_triggered is not None and \\\n                           published is not None and \\\n                           now >= published >= date_triggered:\n                            my_toots.append({'title': title,\n                                             'content': s['content'],\n                                             'link': s['url'],\n                                             'my_date': my_date})\n                            # digester\n                            self.send_digest_event(trigger_id, title, s['url'])\n                    cache.set('th_mastodon_' + str(trigger_id), my_toots)\n                    Mastodon.objects.filter(trigger_id=trigger_id).update(\n                        since_id=since_id, max_id=max_id)\n        return my_toots", "response": "read the data from the service"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_data(self, trigger_id, **data):\n        title, content = super(ServiceMastodon, self).save_data(trigger_id, **data)\n        # check if we have a 'good' title\n        if self.title_or_content(title):\n            content = str(\"{title} {link}\").format(title=title, link=data.get('link'))\n            content += get_tags(Mastodon, trigger_id)\n        # if not then use the content\n        else:\n            content += \" \" + data.get('link') + \" \" + get_tags(Mastodon, trigger_id)\n        content = self.set_mastodon_content(content)\n\n        us = UserService.objects.get(user=self.user, token=self.token, name='ServiceMastodon')\n        try:\n            toot_api = MastodonAPI(client_id=us.client_id, client_secret=us.client_secret, access_token=self.token,\n                                   api_base_url=us.host)\n        except ValueError as e:\n            logger.error(e)\n            status = False\n            update_result(trigger_id, msg=e, status=status)\n\n        media_ids = None\n        try:\n            if settings.DJANGO_TH['sharing_media']:\n                # do we have a media in the content ?\n                content, media = self.media_in_content(content)\n                if media:\n                    # upload the media first\n                    media_ids = toot_api.media_post(media_file=media)\n                    media_ids = [media_ids]\n            toot_api.status_post(content, media_ids=media_ids)\n\n            status = True\n        except Exception as inst:\n            logger.critical(\"Mastodon ERR {}\".format(inst))\n            status = False\n            update_result(trigger_id, msg=inst, status=status)\n        return status", "response": "Save the data to the Mastodon database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef media_in_content(self, content):\n        local_file = ''\n        if 'https://t.co' in content:\n            content = re.sub(r'https://t.co/(\\w+)', '', content)\n        if 'https://pbs.twimg.com/media/' in content:\n            m = re.search('https://pbs.twimg.com/media/([\\w\\-_]+).jpg', content)  # NOQA\n            url = 'https://pbs.twimg.com/media/{}.jpg'.format(m.group(1))\n            local_file = download_image(url)\n            content = re.sub(r'https://pbs.twimg.com/media/([\\w\\-_]+).jpg', '',  # NOQA\n                             content)\n\n            return content, local_file\n        return content, local_file", "response": "check if the content contains and url of an image containing a twitter media url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the auth of the services", "response": "def auth(self, request):\n        \"\"\"\n            get the auth of the services\n            :param request: contains the current session\n            :type request: dict\n            :rtype: dict\n        \"\"\"\n        # create app\n        redirect_uris = '%s://%s%s' % (request.scheme, request.get_host(),\n                                       reverse('mastodon_callback'))\n        us = UserService.objects.get(user=request.user,\n                                     name='ServiceMastodon')\n        client_id, client_secret = MastodonAPI.create_app(\n            client_name=\"TriggerHappy\", api_base_url=us.host,\n            redirect_uris=redirect_uris)\n\n        us.client_id = client_id\n        us.client_secret = client_secret\n        us.save()\n\n        us = UserService.objects.get(user=request.user,\n                                     name='ServiceMastodon')\n        # get the token by logging in\n        mastodon = MastodonAPI(\n            client_id=client_id,\n            client_secret=client_secret,\n            api_base_url=us.host\n        )\n        token = mastodon.log_in(username=us.username, password=us.password)\n        us.token = token\n        us.save()\n        return self.callback_url(request)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check(self, request, user):\n        redirect_uris = '%s://%s%s' % (request.scheme, request.get_host(), reverse('mastodon_callback'))\n        us = UserService.objects.get(user=user,\n                                     name='ServiceMastodon')\n        client_id, client_secret = MastodonAPI.create_app(\n            client_name=\"TriggerHappy\", api_base_url=us.host,\n            redirect_uris=redirect_uris)\n\n        # get the token by logging in\n        mastodon = MastodonAPI(\n            client_id=client_id,\n            client_secret=client_secret,\n            api_base_url=us.host\n        )\n        try:\n            mastodon.log_in(username=us.username, password=us.password)\n            return True\n        except MastodonIllegalArgumentError as e:\n            return e", "response": "check if the service is well configured"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the data from the cache", "response": "def get_data(service, cache_data, trigger_id):\n        \"\"\"\n            get the data from the cache\n            :param service: the service name\n            :param cache_data: the data from the cache\n            :type trigger_id: integer\n            :return: Return the data from the cache\n            :rtype: object\n        \"\"\"\n        if service.startswith('th_'):\n            cache = caches['django_th']\n\n            limit = settings.DJANGO_TH.get('publishing_limit', 0)\n\n            # publishing of all the data\n            if limit == 0:\n                return cache_data\n            # or just a set of them\n            if cache_data is not None and len(cache_data) > limit:\n                for data in cache_data[limit:]:\n                    service_str = ''.join((service, '_', str(trigger_id)))\n                    # put that data in a version 2 of the cache\n                    cache.set(service_str, data, version=2)\n                    # delete data from cache version=1\n                    # https://niwinz.github.io/django-redis/latest/#_scan_delete_keys_in_bulk\n                    cache.delete_pattern(service_str)\n                # put in cache unpublished data\n                cache_data = cache_data[:limit]\n        return cache_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_content(data, which_content):\n        content = ''\n        if data.get(which_content):\n            if isinstance(data.get(which_content), feedparser.FeedParserDict):\n                content = data.get(which_content)['value']\n            elif not isinstance(data.get(which_content), str):\n                if 'value' in data.get(which_content)[0]:\n                    content = data.get(which_content)[0].value\n            else:\n                content = data.get(which_content)\n        return content", "response": "get the content that could be hidden\n            in the middle of content or summary detail detail"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_content(self, data):\n        content = self._get_content(data, 'content')\n\n        if content == '':\n            content = self._get_content(data, 'summary_detail')\n\n        if content == '':\n            if data.get('description'):\n                content = data.get('description')\n\n        return content", "response": "handle the content from the provider\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the data from the service", "response": "def read_data(self, **kwargs):\n        \"\"\"\n            get the data from the service\n\n            :param kwargs: contain keyword args : trigger_id and model name\n            :type kwargs: dict\n            :rtype: model\n        \"\"\"\n        model = get_model(kwargs['app_label'], kwargs['model_name'])\n\n        return model.objects.get(trigger_id=kwargs['trigger_id'])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_data(self, **kwargs):\n        cache = caches['django_th']\n        cache_data = cache.get(kwargs.get('cache_stack') + '_' + kwargs.get('trigger_id'))\n        return PublishingLimit.get_data(kwargs.get('cache_stack'), cache_data, int(kwargs.get('trigger_id')))", "response": "process_data is a helper method that returns the data from the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses to save data to the service but first of all make some work about the data to find and the data to convert :param trigger_id: trigger ID from which to save data :param data: the data to check to be used and save :type trigger_id: int :type data: dict :return: the status of the save statement :rtype: boolean", "response": "def save_data(self, trigger_id, **data):\n        \"\"\"\n            used to save data to the service\n            but first of all\n            make some work about the data to find\n            and the data to convert\n            :param trigger_id: trigger ID from which to save data\n            :param data: the data to check to be used and save\n            :type trigger_id: int\n            :type data:  dict\n            :return: the status of the save statement\n            :rtype: boolean\n        \"\"\"\n        title = self.set_title(data)\n        title = HtmlEntities(title).html_entity_decode\n        content = self.set_content(data)\n        content = HtmlEntities(content).html_entity_decode\n        if data.get('output_format'):\n            # pandoc to convert tools\n            import pypandoc\n            content = pypandoc.convert(content, str(data.get('output_format')), format='html')\n        return title, content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the url to go back after the external service call", "response": "def callback_url(self, request):\n        \"\"\"\n            the url to go back after the external service call\n            :param request: contains the current session\n            :type request: dict\n            :rtype: string\n        \"\"\"\n        service = self.service.split('Service')[1].lower()\n        return_to = '{service}_callback'.format(service=service)\n        return '%s://%s%s' % (request.scheme, request.get_host(), reverse(return_to))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall from the Service when the user accept to activate it the url to go back after the external service call", "response": "def callback(self, request, **kwargs):\n        \"\"\"\n            Called from the Service when the user accept to activate it\n            the url to go back after the external service call\n            :param request: contains the current session\n            :param kwargs: keyword args\n            :type request: dict\n            :type kwargs: dict\n            :rtype: string\n        \"\"\"\n        if self.oauth == 'oauth1':\n            token = self.callback_oauth1(request, **kwargs)\n        else:\n            token = self.callback_oauth2(request)\n\n        service_name = ServicesActivated.objects.get(name=self.service)\n\n        UserService.objects.filter(user=request.user, name=service_name).update(token=token)\n        back = self.service.split('Service')[1].lower()\n        back_to = '{back_to}/callback.html'.format(back_to=back)\n        return back_to"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef callback_oauth1(self, request, **kwargs):\n        if kwargs.get('access_token') == '' or kwargs.get('access_token') is None:\n            access_token = self.get_access_token(request.session['oauth_token'],\n                                                 request.session.get('oauth_token_secret', ''),\n                                                 request.GET.get('oauth_verifier', ''))\n        else:\n            access_token = kwargs.get('access_token')\n\n        if type(access_token) == str:\n            token = access_token\n        else:\n            token = '#TH#'.join((access_token.get('oauth_token'), access_token.get('oauth_token_secret')))\n        return token", "response": "Process for oAuth 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess for oAuth 2. 0", "response": "def callback_oauth2(self, request):\n        \"\"\"\n            Process for oAuth 2\n            :param request: contains the current session\n            :return:\n        \"\"\"\n        callback_url = self.callback_url(request)\n\n        oauth = OAuth2Session(client_id=self.consumer_key, redirect_uri=callback_url, scope=self.scope)\n        request_token = oauth.fetch_token(self.REQ_TOKEN,\n                                          code=request.GET.get('code', ''),\n                                          authorization_response=callback_url,\n                                          client_secret=self.consumer_secret,\n                                          scope=self.scope,\n                                          verify=False)\n        return request_token.get('access_token')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_request_token(self, request):\n        if self.oauth == 'oauth1':\n            oauth = OAuth1Session(self.consumer_key, client_secret=self.consumer_secret)\n            request_token = oauth.fetch_request_token(self.REQ_TOKEN)\n            # Save the request token information for later\n            request.session['oauth_token'] = request_token['oauth_token']\n            request.session['oauth_token_secret'] = request_token['oauth_token_secret']\n\n            return request_token\n        else:\n            callback_url = self.callback_url(request)\n            oauth = OAuth2Session(client_id=self.consumer_key, redirect_uri=callback_url, scope=self.scope)\n            authorization_url, state = oauth.authorization_url(self.AUTH_URL)\n            return authorization_url", "response": "Get the request token to the external service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_access_token(self, oauth_token, oauth_token_secret, oauth_verifier):\n        # Using OAuth1Session\n        oauth = OAuth1Session(self.consumer_key,\n                              client_secret=self.consumer_secret,\n                              resource_owner_key=oauth_token,\n                              resource_owner_secret=oauth_token_secret,\n                              verifier=oauth_verifier)\n        oauth_tokens = oauth.fetch_access_token(self.ACC_TOKEN)\n\n        return oauth_tokens", "response": "get the access token from the external service call"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreset failed counter :param pk: :return:", "response": "def reset_failed(self, pk):\n        \"\"\"\n            reset failed counter\n        :param pk:\n        :return:\n        \"\"\"\n        TriggerService.objects.filter(consumer__name__id=pk).update(consumer_failed=0, provider_failed=0)\n        TriggerService.objects.filter(provider__name__id=pk).update(consumer_failed=0, provider_failed=0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending the digest event to the user who owns the trigger.", "response": "def send_digest_event(self, trigger_id, title, link=''):\n        \"\"\"\n        handling of the signal of digest\n        :param trigger_id:\n        :param title:\n        :param link:\n        :return:\n        \"\"\"\n        if settings.DJANGO_TH.get('digest_event'):\n            t = TriggerService.objects.get(id=trigger_id)\n\n            if t.provider.duration != 'n':\n                kwargs = {'user': t.user, 'title': title, 'link': link, 'duration': t.provider.duration}\n\n                signals.digest_event.send(sender=t.provider.name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_data(self, **kwargs):\n        date_triggered = kwargs.get('date_triggered')\n        trigger_id = kwargs.get('trigger_id')\n\n        kwargs['model_name'] = 'Evernote'\n        kwargs['app_label'] = 'th_evernote'\n\n        trigger = super(ServiceEvernote, self).read_data(**kwargs)\n\n        filter_string = self.set_evernote_filter(date_triggered, trigger)\n        evernote_filter = self.set_note_filter(filter_string)\n        data = self.get_evernote_notes(evernote_filter)\n\n        cache.set('th_evernote_' + str(trigger_id), data)\n        return data", "response": "read the data from the service"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_evernote_filter(self, date_triggered, trigger):\n        new_date_triggered = arrow.get(str(date_triggered)[:-6],\n                                       'YYYY-MM-DD HH:mm:ss')\n\n        new_date_triggered = str(new_date_triggered).replace(\n            ':', '').replace('-', '').replace(' ', '')\n        date_filter = \"created:{} \".format(new_date_triggered[:-6])\n\n        notebook_filter = ''\n        if trigger.notebook:\n            notebook_filter = \"notebook:{} \".format(trigger.notebook)\n        tag_filter = \"tag:{} \".format(trigger.tag) if trigger.tag != '' else ''\n\n        complet_filter = ''.join((notebook_filter, tag_filter, date_filter))\n\n        return complet_filter", "response": "build the filter that will be used by evernote\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the notes related to the filter", "response": "def get_evernote_notes(self, evernote_filter):\n        \"\"\"\n            get the notes related to the filter\n            :param evernote_filter: filtering\n            :return: notes\n        \"\"\"\n        data = []\n\n        note_store = self.client.get_note_store()\n        our_note_list = note_store.findNotesMetadata(self.token, evernote_filter, 0, 100,\n                                                     EvernoteMgr.set_evernote_spec())\n\n        for note in our_note_list.notes:\n            whole_note = note_store.getNote(self.token, note.guid, True, True, False, False)\n            content = self._cleaning_content(whole_note.content)\n            data.append({'title': note.title, 'my_date': arrow.get(note.created),\n                         'link': whole_note.attributes.sourceURL, 'content': content})\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_data(self, trigger_id, **data):\n        # set the title and content of the data\n        title, content = super(ServiceEvernote, self).save_data(trigger_id, **data)\n        # get the evernote data of this trigger\n        trigger = Evernote.objects.get(trigger_id=trigger_id)\n        # initialize notestore process\n        note_store = self._notestore(trigger_id, data)\n        if isinstance(note_store, evernote.api.client.Store):\n            # note object\n            note = self._notebook(trigger, note_store)\n            # its attributes\n            note = self._attributes(note, data)\n            # its footer\n            content = self._footer(trigger, data, content)\n            # its title\n            note.title = limit_content(title, 255)\n            # its content\n            note = self._content(note, content)\n            # create a note\n            return EvernoteMgr.create_note(note_store, note, trigger_id, data)\n        else:\n            # so its note an evernote object, so something wrong happens\n            return note_store", "response": "save the data of the object in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a note object from a trigger object.", "response": "def _notebook(trigger, note_store):\n        \"\"\"\n        :param trigger:\u00a0trigger object\n        :param note_store: note_store object\n        :return: note object\n        \"\"\"\n        note = Types.Note()\n        if trigger.notebook:\n            # get the notebookGUID ...\n            notebook_id = EvernoteMgr.get_notebook(note_store, trigger.notebook)\n            # create notebookGUID if it does not exist then return its id\n            note.notebookGuid = EvernoteMgr.set_notebook(note_store, trigger.notebook, notebook_id)\n\n            if trigger.tag:\n                # ... and get the tagGUID if a tag has been provided\n                tag_id = EvernoteMgr.get_tag(note_store, trigger.tag)\n                if tag_id is False:\n                    tag_id = EvernoteMgr.set_tag(note_store, trigger.tag, tag_id)\n                    # set the tag to the note if a tag has been provided\n                    if tag_id:\n                        note.tagGuids = tag_id\n\n            logger.debug(\"notebook that will be used %s\", trigger.notebook)\n        return note"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the attributes of the note object", "response": "def _attributes(note, data):\n        \"\"\"\n        attribute of the note\n        :param note: note object\n        :param data:\n        :return:\n        \"\"\"\n        # attribute of the note: the link to the website\n        note_attribute = EvernoteMgr.set_note_attribute(data)\n        if note_attribute:\n            note.attributes = note_attribute\n        return note"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _footer(trigger, data, content):\n        # footer of the note\n        footer = EvernoteMgr.set_note_footer(data, trigger)\n        content += footer\n        return content", "response": "This function is used to set the footer of the note in the content string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the content to the note object", "response": "def _content(note, content):\n        \"\"\"\n        content of the note\n        :param note: note object\n        :param content: content string to make the main body of the note\n        :return:\n        \"\"\"\n        note.content = EvernoteMgr.set_header()\n        note.content += sanitize(content)\n        return note"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_evernote_client(self, token=None):\n        if token:\n            return EvernoteClient(token=token, sandbox=self.sandbox)\n        else:\n            return EvernoteClient(consumer_key=self.consumer_key, consumer_secret=self.consumer_secret,\n                                  sandbox=self.sandbox)", "response": "get the token from evernote"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef auth(self, request):\n        client = self.get_evernote_client()\n        request_token = client.get_request_token(self.callback_url(request))\n        # Save the request token information for later\n        request.session['oauth_token'] = request_token['oauth_token']\n        request.session['oauth_token_secret'] = request_token['oauth_token_secret']\n        # Redirect the user to the Evernote authorization URL\n        # return the URL string which will be used by redirect()\n        # from the calling func\n        return client.get_authorize_url(request_token)", "response": "Auth the user to the service"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling from the Service when the user accept to activate it", "response": "def callback(self, request, **kwargs):\n        \"\"\"\n            Called from the Service when the user accept to activate it\n        \"\"\"\n        try:\n            client = self.get_evernote_client()\n            # finally we save the user auth token\n            # As we already stored the object ServicesActivated\n            # from the UserServiceCreateView now we update the same\n            # object to the database so :\n            # 1) we get the previous object\n            us = UserService.objects.get(user=request.user, name=ServicesActivated.objects.get(name='ServiceEvernote'))\n            # 2) then get the token\n            us.token = client.get_access_token(request.session['oauth_token'], request.session['oauth_token_secret'],\n                                               request.GET.get('oauth_verifier', ''))\n            # 3) and save everything\n            us.save()\n        except KeyError:\n            return '/'\n\n        return 'evernote/callback.html'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_data(self, trigger_id, **data):\n        data['output_format'] = 'md'\n        title, content = super(ServiceTrello, self).save_data(trigger_id, **data)\n        if len(title):\n            # get the data of this trigger\n            t = Trello.objects.get(trigger_id=trigger_id)\n            # footer of the card\n            footer = self.set_card_footer(data, t)\n            content += footer\n\n            # 1 - we need to search the list and board where we will\n            # store the card so ...\n\n            # 1.a search the board_id by its name\n            # by retrieving all the boards\n            boards = self.trello_instance.list_boards()\n\n            board_id = ''\n            my_list = ''\n            for board in boards:\n                if t.board_name == board.name:\n                    board_id = board.id\n                    break\n\n            if board_id:\n                # 1.b search the list_id by its name\n                my_board = self.trello_instance.get_board(board_id)\n                lists = my_board.open_lists()\n                # just get the open list ; not all the archive ones\n                for list_in_board in lists:\n                    # search the name of the list we set in the form\n                    if t.list_name == list_in_board.name:\n                        # return the (trello) list object to be able to add card at step 3\n                        my_list = my_board.get_list(list_in_board.id)\n                        break\n                # we didnt find the list in that board -> create it\n                if my_list == '':\n                    my_list = my_board.add_list(t.list_name)\n            else:\n                # 2 if board_id and/or list_id does not exist, create it/them\n                my_board = self.trello_instance.add_board(t.board_name)\n                # add the list that didn't exists and return a (trello) list object\n                my_list = my_board.add_list(t.list_name)\n\n            # 3 create the card\n            my_list.add_card(title, content)\n\n            logger.debug(str('trello {} created').format(data['link']))\n            status = True\n        else:\n            sentence = \"no token or link provided for trigger ID {}\".format(trigger_id)\n            update_result(trigger_id, msg=sentence, status=False)\n            status = False\n\n        return status", "response": "save the data of the current state of the card"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_card_footer(data, trigger):\n        footer = ''\n        if data.get('link'):\n            provided_by = _('Provided by')\n            provided_from = _('from')\n            footer_from = \"<br/><br/>{} <em>{}</em> {} <a href='{}'>{}</a>\"\n            description = trigger.trigger.description\n            footer = footer_from.format(provided_by, description, provided_from, data.get('link'), data.get('link'))\n            import pypandoc\n            footer = pypandoc.convert(footer, 'md', format='html')\n        return footer", "response": "set the footer of the note that is shown in the card"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls from the Service when the user accept the object.", "response": "def callback(self, request, **kwargs):\n        \"\"\"\n            Called from the Service when the user accept to activate it\n            :param request: request object\n            :return: callback url\n            :rtype: string , path to the template\n        \"\"\"\n        return super(ServiceTrello, self).callback(request, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the data from the service", "response": "def read_data(self, **kwargs):\n        \"\"\"\n            get the data from the service\n            :param kwargs: contain keyword args : trigger_id at least\n            :type kwargs: dict\n            :rtype: list\n        \"\"\"\n        trigger_id = kwargs.get('trigger_id')\n        date_triggered = str(kwargs.get('date_triggered')).replace(' ', 'T')\n        data = list()\n        if self.token:\n            # check if it remains more than 1 access\n            # then we can create an issue\n            if self.gh.ratelimit_remaining > 1:\n\n                trigger = Github.objects.get(trigger_id=trigger_id)\n                issues = self.gh.issues_on(trigger.repo, trigger.project, since=date_triggered)\n\n                for issue in issues:\n                    content = pypandoc.convert(issue.body, 'md', format='html')\n                    content += self.gh_footer(trigger, issue)\n                    data.append({'title': issue.title, 'content': content})\n                    # digester\n                    self.send_digest_event(trigger_id, issue.title, '')\n                cache.set('th_github_' + str(trigger_id), data)\n            else:\n                # rate limit reach, do nothing right now\n                logger.warning(\"Rate limit reached\")\n                update_result(trigger_id, msg=\"Rate limit reached\", status=True)\n        else:\n            logger.critical(\"no token provided\")\n            update_result(trigger_id, msg=\"No token provided\", status=True)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_data(self, trigger_id, **data):\n        if self.token:\n            title = self.set_title(data)\n            body = self.set_content(data)\n            # get the details of this trigger\n            trigger = Github.objects.get(trigger_id=trigger_id)\n\n            # check if it remains more than 1 access\n            # then we can create an issue\n            limit = self.gh.ratelimit_remaining\n            if limit > 1:\n                # repo goes to \"owner\"\n                # project goes to \"repository\"\n                r = self.gh.create_issue(trigger.repo, trigger.project, title, body)\n            else:\n                # rate limit reach\n                logger.warning(\"Rate limit reached\")\n                update_result(trigger_id, msg=\"Rate limit reached\", status=True)\n                # put again in cache the data that could not be\n                # published in Github yet\n                cache.set('th_github_' + str(trigger_id), data, version=2)\n                return True\n            sentence = str('github {} created').format(r)\n            logger.debug(sentence)\n            status = True\n        else:\n            sentence = \"no token or link provided for trigger ID {} \".format(trigger_id)\n            logger.critical(sentence)\n            update_result(trigger_id, msg=sentence, status=False)\n            status = False\n\n        return status", "response": "let s save the data from github to github"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall from the Service when the user accept the object.", "response": "def callback(self, request, **kwargs):\n        \"\"\"\n            Called from the Service when the user accept to activate it\n            :param request: request object\n            :return: callback url\n            :rtype: string , path to the template\n        \"\"\"\n        access_token = request.session['oauth_token'] + \"#TH#\"\n        access_token += str(request.session['oauth_id'])\n        kwargs = {'access_token': access_token}\n        return super(ServiceGithub, self).callback(request, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the data from the service", "response": "def read_data(self, **kwargs):\n        \"\"\"\n            get the data from the service\n            as the pocket service does not have any date\n            in its API linked to the note,\n            add the triggered date to the dict data\n            thus the service will be triggered when data will be found\n\n            :param kwargs: contain keyword args : trigger_id at least\n            :type kwargs: dict\n\n            :rtype: list\n        \"\"\"\n        trigger_id = kwargs.get('trigger_id')\n        trigger = Reddit.objects.get(trigger_id=trigger_id)\n        date_triggered = arrow.get(kwargs.get('date_triggered'))\n        data = list()\n        submissions = self.reddit.subreddit(trigger.subreddit).top('day')\n        for submission in submissions:\n            title = 'From Reddit ' + submission.title\n            created = arrow.get(submission.created).to(settings.TIME_ZONE)\n            if date_triggered is not None and created is not None \\\n               and created >= date_triggered and not submission.is_self and trigger.share_link:\n                body = submission.selftext if submission.selftext else submission.url\n                data.append({'title': title, 'content': body})\n                self.send_digest_event(trigger_id, title, '')\n\n        cache.set('th_reddit_' + str(trigger_id), data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_data(self, trigger_id, **data):\n        # convert the format to be released in Markdown\n        status = False\n        data['output_format'] = 'md'\n        title, content = super(ServiceReddit, self).save_data(trigger_id, **data)\n        if self.token:\n            trigger = Reddit.objects.get(trigger_id=trigger_id)\n            if trigger.share_link:\n                status = self.reddit.subreddit(trigger.subreddit).submit(title=title, url=content)\n            else:\n                status = self.reddit.subreddit(trigger.subreddit).submit(title=title, selftext=content)\n            sentence = str('reddit submission {} created').format(title)\n            logger.debug(sentence)\n        else:\n            msg = \"no token or link provided for trigger ID {} \".format(trigger_id)\n            logger.critical(msg)\n            update_result(trigger_id, msg=msg, status=False)\n        return status", "response": "let s save the data from the service"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling from the Service when the user accept to activate it the url to go back after the external service call :param request: contains the current session :param kwargs: keyword args :type request: dict :type kwargs: dict :rtype: string", "response": "def callback(self, request, **kwargs):\n        \"\"\"\n            Called from the Service when the user accept to activate it\n            the url to go back after the external service call\n            :param request: contains the current session\n            :param kwargs: keyword args\n            :type request: dict\n            :type kwargs: dict\n            :rtype: string\n        \"\"\"\n        code = request.GET.get('code', '')\n        redirect_uri = '%s://%s%s' % (request.scheme, request.get_host(), reverse(\"reddit_callback\"))\n        reddit = RedditApi(client_id=self.consumer_key,\n                           client_secret=self.consumer_secret,\n                           redirect_uri=redirect_uri,\n                           user_agent=self.user_agent)\n        token = reddit.auth.authorize(code)\n\n        UserService.objects.filter(user=request.user, name='ServiceReddit').update(token=token)\n        return 'reddit/callback.html'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_data(self, **kwargs):\n        trigger_id = kwargs.get('trigger_id')\n        data = list()\n        kwargs['model_name'] = 'Tumblr'\n        kwargs['app_label'] = 'th_tumblr'\n        super(ServiceTumblr, self).read_data(**kwargs)\n        cache.set('th_tumblr_' + str(trigger_id), data)\n        return data", "response": "read the data from the service\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_data(self, trigger_id, **data):\n        from th_tumblr.models import Tumblr\n\n        title, content = super(ServiceTumblr, self).save_data(trigger_id, **data)\n\n        # get the data of this trigger\n        trigger = Tumblr.objects.get(trigger_id=trigger_id)\n        # we suppose we use a tag property for this service\n        status = self.tumblr.create_text(blogname=trigger.blogname,\n                                         title=title,\n                                         body=content,\n                                         state='published',\n                                         tags=trigger.tag)\n\n        return status", "response": "save the data of a specific service in the database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef auth(self, request):\n        request_token = super(ServiceTumblr, self).auth(request)\n        callback_url = self.callback_url(request)\n\n        # URL to redirect user to, to authorize your app\n        auth_url_str = '{auth_url}?oauth_token={token}'\n        auth_url_str += '&oauth_callback={callback_url}'\n        auth_url = auth_url_str.format(auth_url=self.AUTH_URL,\n                                       token=request_token['oauth_token'],\n                                       callback_url=callback_url)\n\n        return auth_url", "response": "Auth the user to the Service\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_object(self, queryset=None):\n        obj = User.objects.get(id=self.request.user.id)\n        return obj", "response": "get only the data of the current user"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the data of the view", "response": "def get_context_data(self, **kwargs):\n        \"\"\"\n            get the data of the view\n\n            data are :\n            1) number of triggers enabled\n            2) number of triggers disabled\n            3) number of activated services\n            4) list of activated services by the connected user\n        \"\"\"\n        triggers_enabled = triggers_disabled = services_activated = ()\n\n        context = super(TriggerListView, self).get_context_data(**kwargs)\n\n        if self.kwargs.get('trigger_filtered_by'):\n            page_link = reverse('trigger_filter_by',\n                                kwargs={'trigger_filtered_by':\n                                        self.kwargs.get('trigger_filtered_by')})\n        elif self.kwargs.get('trigger_ordered_by'):\n            page_link = reverse('trigger_order_by',\n                                kwargs={'trigger_ordered_by':\n                                        self.kwargs.get('trigger_ordered_by')})\n        else:\n            page_link = reverse('home')\n\n        if self.request.user.is_authenticated:\n            # get the enabled triggers\n            triggers_enabled = TriggerService.objects.filter(\n                user=self.request.user, status=1).count()\n            # get the disabled triggers\n            triggers_disabled = TriggerService.objects.filter(\n                user=self.request.user, status=0).count()\n            # get the activated services\n            user_service = UserService.objects.filter(user=self.request.user)\n            \"\"\"\n                List of triggers activated by the user\n            \"\"\"\n            context['trigger_filter_by'] = user_service\n            \"\"\"\n                number of service activated for the current user\n            \"\"\"\n            services_activated = user_service.count()\n\n        \"\"\"\n            which triggers are enabled/disabled\n        \"\"\"\n        context['nb_triggers'] = {'enabled': triggers_enabled,\n                                  'disabled': triggers_disabled}\n        \"\"\"\n            Number of services activated\n        \"\"\"\n        context['nb_services'] = services_activated\n\n        context['page_link'] = page_link\n        context['fire'] = settings.DJANGO_TH.get('fire', False)\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef datas(self):\n        data = feedparser.parse(self.URL_TO_PARSE, agent=self.USER_AGENT)\n\n        # when chardet says\n        # >>> chardet.detect(data)\n        # {'confidence': 0.99, 'encoding': 'utf-8'}\n        # bozo says sometimes\n        # >>> data.bozo_exception\n        # CharacterEncodingOverride('document declared as us-ascii, but parsed as utf-8', )  # invalid Feed\n        # so I remove this detection :(\n        # the issue come from the server that return a charset different from the feeds\n        # it is not related to Feedparser but from the HTTP server itself\n        if data.bozo == 1:\n            data.entries = ''\n\n        return data", "response": "read the data from a given URL or path to a local file"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all the triggers that need to be handled", "response": "def handle(self, *args, **options):\n        \"\"\"\n            get all the triggers that need to be handled\n        \"\"\"\n        from django.db import connection\n        connection.close()\n        failed_tries = settings.DJANGO_TH.get('failed_tries', 10)\n        trigger = TriggerService.objects.filter(\n            Q(provider_failed__lte=failed_tries) |\n            Q(consumer_failed__lte=failed_tries),\n            status=True,\n            user__is_active=True,\n            provider__name__status=True,\n            consumer__name__status=True,\n        ).select_related('consumer__name', 'provider__name')\n\n        with ThreadPoolExecutor(max_workers=settings.DJANGO_TH.get('processes')) as executor:\n            r = Read()\n            for t in trigger:\n                executor.submit(r.reading, t)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check(self, datas, *filers):\n        '''\n            this method permits to reduce the quantity of information to read\n            by applying some filtering\n            here '*filers' can receive a list of properties to be filtered\n        '''\n        # special case : no filter : want to read all the feed\n        if self.match == \"\" and self.does_not_match == '':\n            yield datas\n        # let's filtering :\n        else:\n            condition1 = False\n            condition2 = False\n            # arg contain the property from which we want to check the 'data'\n            for prop in filers:\n                # check if my datas contains my property\n                if prop in datas:\n                    # filter to find only this data\n                    if self.match != '' and condition1 is False:\n                        condition1 = self.filter_that(self.match,\n                                                      datas[prop])\n                    # filter to exclude this data,\n                    # when found, continue to the next entry\n                    if self.does_not_match != '' and condition2 is False:\n                        condition2 = self.filter_that(self.does_not_match,\n                                                      datas[prop])\n                        if condition2:\n                            continue\n        if condition1 and condition2 is False:\n            yield datas", "response": "This method is used to iterate over the datas and filter the data for the filers"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the data from the service", "response": "def read_data(self, **kwargs):\n        \"\"\"\n            get the data from the service\n            as the pocket service does not have any date\n            in its API linked to the note,\n            add the triggered date to the dict data\n            thus the service will be triggered when data will be found\n\n            :param kwargs: contain keyword args : trigger_id at least\n            :type kwargs: dict\n\n            :rtype: list\n        \"\"\"\n        self.date_triggered = arrow.get(kwargs.get('date_triggered'))\n        self.trigger_id = kwargs.get('trigger_id')\n        self.user = kwargs.get('user', '')\n\n        responses = self._get_wall_data()\n\n        data = []\n        try:\n            json_data = responses.json()\n\n            for d in json_data['_embedded']['items']:\n                created_at = arrow.get(d.get('created_at'))\n                date_triggered = arrow.get(self.date_triggered)\n\n                if created_at > date_triggered:\n                    data.append({'title': d.get('title'),\n                                 'content': d.get('content')})\n                    # digester\n                    self.send_digest_event(self.trigger_id,\n                                           d.get('title'),\n                                           link='')\n            if len(data) > 0:\n                cache.set('th_wallabag_' + str(self.trigger_id), data)\n        except Exception as e:\n            logger.critical(e)\n            update_result(self.trigger_id, msg=e, status=False)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wall(self):\n        us = UserService.objects.get(user=self.user, name='ServiceWallabag')\n        params = {\n            'client_id': us.client_id,\n            'client_secret': us.client_secret,\n            'username': us.username,\n            'password': us.password,\n        }\n        try:\n            token = Wall.get_token(host=us.host, **params)\n        except Exception as e:\n            update_result(self.trigger_id, msg=e, status=False)\n            logger.critical('{} {}'.format(self.user, e))\n            return False\n\n        wall = Wall(host=us.host, client_secret=us.client_secret,\n                    client_id=us.client_id, token=token)\n\n        UserService.objects.filter(user=self.user,\n                                   name='ServiceWallabag').update(token=token)\n\n        return wall", "response": "refresh the token from the API\n            then call a Wall instance\n            then store the token\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_entry(self, title, data, tags):\n        status = False\n        if data.get('link') and len(data.get('link')) > 0:\n            wall = self.wall()\n            if wall is not False:\n                try:\n                    wall.post_entries(url=data.get('link').encode(), title=title, tags=(tags.lower()))\n                    logger.debug('wallabag {} created'.format(data.get('link')))\n                    status = True\n                except Exception as e:\n                    logger.critical('issue with something else that a token link ? : {}'.format(data.get('link')))\n                    logger.critical(e)\n                    update_result(self.trigger_id, msg=e, status=False)\n                    status = False\n        else:\n            status = True  # we ignore empty link\n        return status", "response": "create an entry in the database"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nletting s save the data from the data dict", "response": "def save_data(self, trigger_id, **data):\n        \"\"\"\n            let's save the data\n\n            :param trigger_id: trigger ID from which to save data\n            :param data: the data to check to be used and save\n            :type trigger_id: int\n            :type data:  dict\n            :return: the status of the save statement\n            :rtype: boolean\n        \"\"\"\n        self.trigger_id = trigger_id\n\n        trigger = Wallabag.objects.get(trigger_id=trigger_id)\n\n        title = self.set_title(data)\n        if title is not None:\n            # convert htmlentities\n            title = HtmlEntities(title).html_entity_decode\n\n            return self._create_entry(title, data, trigger.tag)\n        else:\n            # we ignore data without title so return True to let\n            # the process continue without\n            # raising exception\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef callback(self, request, **kwargs):\n\n        try:\n            UserService.objects.filter(\n                user=request.user,\n                name=ServicesActivated.objects.get(name='ServiceWallabag')\n            )\n        except KeyError:\n            return '/'\n\n        return 'wallabag/callback.html'", "response": "Called from the Service when the user accept to activate it\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the service is well configured", "response": "def check(self, request, user):\n        \"\"\"\n        check if the service is well configured\n        :return: Boolean\n        \"\"\"\n        us = UserService.objects.get(user=user, name='ServiceWallabag')\n\n        params = {'username': us.username,\n                  'password': us.password,\n                  'client_id': us.client_id,\n                  'client_secret': us.client_secret}\n        try:\n            Wall.get_token(host=us.host, **params)\n            return True\n        except requests.exceptions.HTTPError as e:\n            return e"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef renew_service(request, pk):\n    default_provider.load_services()\n    service = get_object_or_404(ServicesActivated, pk=pk)\n    service_name = str(service.name)\n    service_object = default_provider.get_service(service_name)\n    lets_auth = getattr(service_object, 'auth')\n    getattr(service_object, 'reset_failed')(pk=pk)\n    return redirect(lets_auth(request))", "response": "renew an existing service"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_context_data(self, **kwargs):\n        context = super(UserServiceUpdateView, self).get_context_data(**kwargs)\n        context['service_name_alone'] = self.object.name.name.rsplit('Service')[1]\n        context['service_name'] = self.object.name.name\n        context['SERVICES_AUTH'] = settings.SERVICES_AUTH\n        context['SERVICES_HOSTED_WITH_AUTH'] = settings.SERVICES_HOSTED_WITH_AUTH\n        context['SERVICES_NEUTRAL'] = settings.SERVICES_NEUTRAL\n\n        context['action'] = 'edit'\n        return context", "response": "Add the data from the current object in the current\n        context and add the action to the context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing default value that won t be displayed", "response": "def get_form_kwargs(self):\n        \"\"\"\n        initialize default value that won't be displayed\n        :return:\n        \"\"\"\n        kwargs = super(UserServiceUpdateView, self).get_form_kwargs()\n        kwargs['initial']['user'] = self.request.user\n        kwargs['initial']['name'] = self.object.name\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef form_valid(self, form):\n        valid = True\n        # 'name' is injected in the clean() of the form line 56\n        name = form.cleaned_data.get('name').name\n        user = self.request.user\n        form.save(user=user, service_name=name)\n\n        sa = ServicesActivated.objects.get(name=name)\n        if sa.auth_required and sa.self_hosted:\n            # trigger the checking of the service\n            from django_th.services import default_provider\n            default_provider.load_services()\n            service_provider = default_provider.get_service(name)\n            result = service_provider.check(self.request, user)\n            if result is not True:\n                # the call of the API failed due to an error which is in the result string\n                # return by the call of the API\n                form.add_error('host', result)\n                messages.error(self.request, result)\n                return redirect('edit_service', pk=self.kwargs.get(self.pk_url_kwarg))\n\n        if valid:\n            messages.success(self.request, _('Service %s modified successfully') % name.split('Service')[1])\n            return HttpResponseRedirect(reverse('user_services'))", "response": "save the data\n        :param form:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate if tag or screen is filled validate if tag or screen is filled raise ValidationError", "response": "def clean(self):\n        \"\"\"\n        validate if tag or screen is filled\n        :return:\n        \"\"\"\n        cleaned_data = super(MastodonForm, self).clean()\n        tag = cleaned_data.get(\"tag\")\n        screen = cleaned_data.get(\"tooter\")\n        # check if one of the field is filled when a field is empty the clean() function set it as None\n        if tag is None and screen is None:\n            raise ValidationError(_(\"You have to fill ONE of the fields (or tag + tooter or tooter + fav)\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the result of a specific trigger.", "response": "def update_result(trigger_id, msg, status):\n    \"\"\"\n    :param trigger_id: trigger id\n    :param msg: result msg\n    :param status: status of the handling of the current trigger\n    :return:\n    \"\"\"\n    service = TriggerService.objects.get(id=trigger_id)\n    # if status is True, reset *_failed counter\n    if status:\n        provider_failed = 0\n        consumer_failed = 0\n        counter_ok = service.counter_ok + 1\n        counter_ko = service.counter_ko\n    # otherwise, add 1 to the consumer_failed\n    else:\n        provider_failed = service.provider_failed\n        consumer_failed = service.consumer_failed + 1\n        counter_ok = service.counter_ko\n        counter_ko = service.counter_ko + 1\n\n        status = False if consumer_failed > settings.DJANGO_TH.get('failed_tries', 5) else True\n\n        warn_user_and_admin('consumer', service)\n\n    TriggerService.objects.filter(id=trigger_id).update(\n        result=msg,\n        date_result=now(),\n        provider_failed=provider_failed,\n        consumer_failed=consumer_failed,\n        counter_ok=counter_ok,\n        counter_ko=counter_ko,\n        status=status)\n\n    UserService.objects.filter(user=service.user, name=service.consumer.name).update(\n        counter_ok=counter_ok,\n        counter_ko=counter_ko)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_from_path(path):\n    module_name, class_name = path.rsplit('.', 1)\n    try:\n        return getattr(__import__(module_name, fromlist=[class_name]), class_name)\n    except AttributeError:\n        raise ImportError('Unable to import %s' % path)", "response": "Imports a class dynamically given it s dotted path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_services(self, services=settings.TH_SERVICES):\n        kwargs = {}\n        for class_path in services:\n            module_name, class_name = class_path.rsplit('.', 1)\n            klass = import_from_path(class_path)\n            service = klass(None, **kwargs)\n            self.register(class_name, service)", "response": "load the services from the settings. TH_SERVICES setting"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef recycle():\n    # http://niwinz.github.io/django-redis/latest/#_scan_delete_keys_in_bulk\n    for service in cache.iter_keys('th_*'):\n        try:\n            # get the value from the cache version=2\n            service_value = cache.get(service, version=2)\n            # put it in the version=1\n            cache.set(service, service_value)\n            # remote version=2\n            cache.delete_pattern(service, version=2)\n        except ValueError:\n            pass\n    logger.info('recycle of cache done!')", "response": "recycle the cache from the cache with version = 2 in the main cache\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef provider(self, service_provider, **kwargs):\n        getattr(service_provider, '__init__')(kwargs.get('token'))\n        return getattr(service_provider, 'read_data')(**kwargs)", "response": "get the data of the provider service\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the ceil of nb of tries is reached", "response": "def is_ceil_reached(self, service):\n        \"\"\"\n            check if the ceil of nb of tries is reached\n        :param service:\n        :return:\n        \"\"\"\n        failed = service.provider_failed + 1\n        if failed > settings.DJANGO_TH.get('failed_tries', 10):\n            TriggerService.objects.filter(id=service.id).update(date_result=now(), status=False)\n        else:\n            TriggerService.objects.filter(id=service.id).update(date_result=now(), provider_failed=failed)\n\n        warn_user_and_admin('provider', service)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reading(self, service):\n        # counting the new data to store to display them in the log provider - the service that offer data\n        provider_token = service.provider.token\n        default_provider.load_services()\n        service_provider = default_provider.get_service(str(service.provider.name.name))\n        date_triggered = service.date_triggered if service.date_triggered else service.date_created\n\n        # get the data from the provider service\n        kwargs = {'token': provider_token, 'trigger_id': service.id, 'date_triggered': date_triggered}\n        data = self.provider(service_provider, **kwargs)\n\n        if len(data) > 0:\n            logger.info(\"{} - {} new data\".format(service, len(data)))\n        elif data is False:\n            # if data is False, something went wrong\n            self.is_ceil_reached(service)", "response": "get the data from the service and put theme in cache\n          "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_published(self, entry):\n        published = None\n        if hasattr(entry, 'published_parsed'):\n            if entry.published_parsed is not None:\n                published = datetime.datetime.utcfromtimestamp(time.mktime(entry.published_parsed))\n        elif hasattr(entry, 'created_parsed'):\n            if entry.created_parsed is not None:\n                published = datetime.datetime.utcfromtimestamp(time.mktime(entry.created_parsed))\n        elif hasattr(entry, 'updated_parsed'):\n            if entry.updated_parsed is not None:\n                published = datetime.datetime.utcfromtimestamp(time.mktime(entry.updated_parsed))\n        return published", "response": "get the published attribute"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_data(self, **kwargs):\n        date_triggered = kwargs.get('date_triggered')\n        trigger_id = kwargs.get('trigger_id')\n        kwargs['model_name'] = 'Rss'\n        kwargs['app_label'] = 'django_th'\n        # get the URL from the trigger id\n        rss = super(ServiceRss, self).read_data(**kwargs)\n\n        logger.debug(\"RSS Feeds from %s : url %s\", rss.name, rss.url)\n\n        now = arrow.utcnow().to(settings.TIME_ZONE)\n        my_feeds = []\n\n        # retrieve the data\n        feeds = Feeds(**{'url_to_parse': rss.url}).datas()\n\n        for entry in feeds.entries:\n            # entry.*_parsed may be None when the date in a RSS Feed is invalid\n            # so will have the \"now\" date as default\n            published = self._get_published(entry)\n            if published:\n                published = arrow.get(str(published)).to(settings.TIME_ZONE)\n            date_triggered = arrow.get(str(date_triggered)).to(settings.TIME_ZONE)\n            if date_triggered is not None and published is not None and now >= published >= date_triggered:\n                my_feeds.append(entry)\n                # digester\n                self.send_digest_event(trigger_id, entry.title, entry.link)\n\n        cache.set('th_rss_' + str(trigger_id), my_feeds)\n        cache.set('th_rss_uuid_{}'.format(rss.uuid), my_feeds)\n        # return the data\n        return my_feeds", "response": "read the data from the service"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the activated services added from the administrator", "response": "def activated_services(self, user, provider=None):\n        \"\"\"\n            get the activated services added from the administrator\n            :param user: user\n            :param provider: the selected provider\n            :type user: current user\n            :type provider: string\n            :return: list of activated services\n            :rtype: list\n        \"\"\"\n        services = UserService.objects.filter(name__status=1, user=user)\n\n        choices = []\n        data = ()\n\n        if provider is not None:\n            services = services.exclude(name__exact=provider)\n\n        for class_name in services:\n            data = (class_name.name, class_name.name.name.rsplit('Service', 1)[1])\n            choices.append(data)\n\n        return choices"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle(self, *args, **options):\n        now = arrow.utcnow().to(settings.TIME_ZONE)\n        now = now.date()\n\n        digest = Digest.objects.filter(date_end=str(now)).order_by('user', 'date_end')\n        users = digest.distinct('user')\n\n        subject = 'Your digester'\n\n        msg_plain = render_to_string('digest/email.txt', {'digest': digest, 'subject': subject})\n        msg_html = render_to_string('digest/email.html', {'digest': digest, 'subject': subject})\n        message = msg_plain\n        from_email = settings.ADMINS\n        recipient_list = ()\n        for user in users:\n            recipient_list += (user.user.email,)\n\n        send_mail(subject, message, from_email, recipient_list,\n                  html_message=msg_html)", "response": "sends an email to each user"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_data(self, trigger_id, **data):\n        status = False\n        taiga = Taiga.objects.get(trigger_id=trigger_id)\n        title = self.set_title(data)\n        body = self.set_content(data)\n        # add a 'story' to the project\n        if taiga.project_name:\n            api = self.taiga_api()\n            new_project = api.projects.get_by_slug(taiga.project_name)\n            userstory = new_project.add_user_story(title, description=body)\n            if userstory:\n                status = True\n\n        return status", "response": "save the data from the service to the database"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_notebook(note_store, my_notebook):\n        notebook_id = 0\n        notebooks = note_store.listNotebooks()\n        # get the notebookGUID ...\n        for notebook in notebooks:\n            if notebook.name.lower() == my_notebook.lower():\n                notebook_id = notebook.guid\n                break\n        return notebook_id", "response": "get the notebook from its name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_notebook(note_store, my_notebook, notebook_id):\n        if notebook_id == 0:\n            new_notebook = Types.Notebook()\n            new_notebook.name = my_notebook\n            new_notebook.defaultNotebook = False\n            notebook_id = note_store.createNotebook(new_notebook).guid\n        return notebook_id", "response": "set a notebook in note store"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_tag(note_store, my_tags):\n        tag_id = []\n        listtags = note_store.listTags()\n        # cut the string by piece of tag with comma\n        for my_tag in my_tags.split(','):\n            for tag in listtags:\n                # remove space before and after\n                # thus we keep \"foo bar\"\n                # but not \" foo bar\" nor \"foo bar \"\n                if tag.name.lower() == my_tag.lower().lstrip().rstrip():\n                    tag_id.append(tag.guid)\n                    break\n\n        return tag_id", "response": "get the tags from his Evernote account\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_tag(note_store, my_tags, tag_id):\n        new_tag = Types.Tag()\n        for my_tag in my_tags.split(','):\n            new_tag.name = my_tag\n            note_tag_id = EvernoteMgr.create_tag(note_store, new_tag)\n            if note_tag_id is not False:\n                tag_id.append(note_tag_id)\n            else:\n                return False\n        return tag_id", "response": "create a tag if not exists"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a note in the cache", "response": "def create_note(note_store, note, trigger_id, data):\n        \"\"\"\n            create a note\n            :param note_store Evernote instance\n            :param note\n            :param trigger_id id of the trigger\n            :param data to save or to put in cache\n            :type note_store: Evernote Instance\n            :type note: Note instance\n            :type trigger_id: int\n            :type data: dict\n            :return boolean\n            :rtype boolean\n        \"\"\"\n        # create the note !\n        try:\n            created_note = note_store.createNote(note)\n            sentence = str('note %s created') % created_note.guid\n            logger.debug(sentence)\n            return True\n        except EDAMSystemException as e:\n            return error(trigger_id, data, e)\n        except EDAMUserException as e:\n            if e.errorCode == EDAMErrorCode.ENML_VALIDATION:\n                sentence = \"Data ignored due to validation error : err {code} {msg}\".format(code=e.errorCode,\n                                                                                            msg=e.parameter)\n                logger.warning(sentence)\n                update_result(trigger_id, msg=sentence, status=True)\n                return True\n        except Exception as e:\n            logger.critical(e)\n            update_result(trigger_id, msg=e, status=False)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_tag(note_store, new_tag):\n        try:\n            return note_store.createTag(new_tag).guid\n        except EDAMUserException as e:\n            if e.errorCode == EDAMErrorCode.DATA_CONFLICT:\n                logger.info(\"Evernote Data Conflict Err {0}\".format(e))\n            elif e.errorCode == EDAMErrorCode.BAD_DATA_FORMAT:\n                logger.critical(\"Evernote Err {0}\".format(e))\n            return False", "response": "Create a new tag in the specified note store."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the note attribute", "response": "def set_note_attribute(data):\n        \"\"\"\n           add the link of the 'source' in the note\n        \"\"\"\n        na = False\n        if data.get('link'):\n            na = Types.NoteAttributes()\n            # add the url\n            na.sourceURL = data.get('link')\n            # add the object to the note\n        return na"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_note_footer(data, trigger):\n        footer = ''\n        if data.get('link'):\n            provided_by = _('Provided by')\n            provided_from = _('from')\n            footer_from = \"<br/><br/>{} <em>{}</em> {} <a href='{}'>{}</a>\"\n\n            footer = footer_from.format(\n                provided_by, trigger.trigger.description, provided_from,\n                data.get('link'), data.get('link'))\n\n        return footer", "response": "set the footer of the note"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the spec of the notes", "response": "def set_evernote_spec():\n        \"\"\"\n            set the spec of the notes\n        :return: spec\n        \"\"\"\n        spec = NoteStore.NotesMetadataResultSpec()\n        spec.includeTitle = True\n        spec.includeAttributes = True\n        return spec"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart the handling of only ONE trigger :param request: request object :param trigger_id: the trigger ID to switch the status to True or False :type request: HttpRequest object :type trigger_id: int :return render :rtype HttpResponse", "response": "def fire_trigger(request, trigger_id):\n    \"\"\"\n        start the handling of only ONE trigger\n        :param request: request object\n        :param trigger_id: the trigger ID to switch the status to True or False\n        :type request: HttpRequest object\n        :type trigger_id: int\n        :return render\n        :rtype HttpResponse\n    \"\"\"\n    date = ''\n\n    if cache.get('django_th' + '_fire_trigger_' + str(trigger_id)):\n        template = 'triggers/fire_trigger_ko.html'\n        trigger = TriggerService.objects.get(id=trigger_id)\n        kwargs = {'trigger': trigger}\n    else:\n        now = arrow.utcnow().to(settings.TIME_ZONE).format('YYYY-MM-DD HH:mm:ssZZ')\n\n        cache.set('django_th' + '_fire_trigger_' + str(trigger_id), '*')\n        management.call_command('read_n_pub', trigger_id=trigger_id)\n\n        trigger = TriggerService.objects.get(id=trigger_id)\n        date_result = arrow.get(trigger.date_result).to(settings.TIME_ZONE).format('YYYY-MM-DD HH:mm:ssZZ')\n        date_triggered = arrow.get(trigger.date_triggered).to(settings.TIME_ZONE).format('YYYY-MM-DD HH:mm:ssZZ')\n\n        if date_result < date_triggered and date_triggered > now:\n            date = '*'\n\n        template = 'triggers/fire_trigger.html'\n        kwargs = {'trigger': trigger, 'date': date}\n\n    return render(request, template, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nswitching the status of all the related triggers to the service", "response": "def service_related_triggers_switch_to(request, user_service_id, switch):\n    \"\"\"\n        switch the status of all the triggers related to the service,\n        then go back home\n        :param request: request object\n        :param user_service_id: the service ID to switch the status to\n        True or False of all the related trigger\n        :param switch: the switch value\n        :type request: HttpRequest object\n        :type user_service_id: int\n        :type switch: string off or on\n    \"\"\"\n    status = True\n    if switch == 'off':\n        status = False\n\n    TriggerService.objects.filter(provider__id=user_service_id).update(status=status)\n    TriggerService.objects.filter(consumer__id=user_service_id).update(status=status)\n\n    service = UserService.objects.get(id=user_service_id).name.name.split('Service')[1]\n    messages.warning(request, _('All triggers of %s are now %s') % (service, switch))\n\n    return HttpResponseRedirect(reverse('user_services'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trigger_switch_all_to(request, switch):\n    now = arrow.utcnow().to(settings.TIME_ZONE).format('YYYY-MM-DD HH:mm:ss')\n    status = True\n    if switch == 'off':\n        status = False\n    if status:\n        TriggerService.objects.filter(user=request.user).update(status=status, date_triggered=now)\n    else:\n        TriggerService.objects.filter(user=request.user).update(status=status)\n\n    return HttpResponseRedirect(reverse('base'))", "response": "Switch the status of all the my triggers then go back home\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the activated services added from the administrator", "response": "def list_services(request, step):\n    \"\"\"\n        get the activated services added from the administrator\n        :param request: request object\n        :param step: the step which is proceeded\n        :type request: HttpRequest object\n        :type step: string\n        :return the activated services added from the administrator\n    \"\"\"\n    all_datas = []\n\n    if step == '0':\n        services = ServicesActivated.objects.filter(status=1)\n    elif step == '3':\n        services = ServicesActivated.objects.filter(status=1, id__iexact=request.id)\n    for class_name in services:\n        all_datas.append({class_name: class_name.name.rsplit('Service', 1)[1]})\n\n    return all_datas"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits the provider s object and the data of that trigger.", "response": "def trigger_edit(request, trigger_id, edit_what):\n    \"\"\"\n        edit the provider\n        :param request: request object\n        :param trigger_id: ID of the trigger to edit\n        :param edit_what: edit a 'Provider' or 'Consumer' ?\n        :type request: HttpRequest object\n        :type trigger_id: int\n        :type edit_what: string\n        :return render\n        :rtype HttpResponse\n    \"\"\"\n    if edit_what not in ('Provider', 'Consumer'):\n        # bad request\n        return redirect('base')\n\n    form_name = edit_what + 'Form'\n\n    # get the trigger object\n    service = TriggerService.objects.get(id=trigger_id)\n\n    if can_modify_trigger(request, service.provider.name.status, service.consumer.name.status):\n        return HttpResponseRedirect(reverse('base'))\n\n    if edit_what == 'Consumer':\n        my_service = service.consumer.name.name\n    else:\n        my_service = service.provider.name.name\n\n    # get the service name\n    service_name = str(my_service).split('Service')[1]\n    # get the model of this service\n    model = get_service(my_service)\n\n    # get the data of this service linked to that trigger\n    data = model.objects.get(trigger_id=trigger_id)\n\n    template = service_name.lower() + '/edit_' + edit_what.lower() + \".html\"\n\n    if request.method == 'POST':\n        form = get_service(my_service, 'forms', form_name)(request.POST, instance=data)\n        if form.is_valid():\n            form.save()\n            return HttpResponseRedirect(reverse('trigger_edit_thanks'))\n    else:\n        form = get_service(my_service, 'forms', form_name)(instance=data)\n\n    context = {'description': service.description,\n               'edit_what': edit_what,\n               'data': data,\n               'is_secure': request.is_secure(),\n               'host': request.get_host()}\n\n    return render(request, template, {'form': form, 'context': context})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_data(self, **kwargs):\n        trigger_id = kwargs.get('trigger_id')\n        date_triggered = kwargs.get('date_triggered')\n        data = []\n        project_name = 'Main Project'\n        items = self.todoist.sync()\n        try:\n            for item in items.get('items'):\n                date_added = arrow.get(item.get('date_added'), 'ddd DD MMM YYYY HH:mm:ss ZZ')\n                if date_added > date_triggered:\n                    for project in items.get('projects'):\n                        if item.get('project_id') == project.get('id'):\n                            project_name = project.get('name')\n                    title = 'From TodoIst Project {0}:'.format(project_name)\n                    data.append({'title': title, 'content': item.get('content')})\n\n                    # digester\n                    self.send_digest_event(trigger_id, title, '')\n\n            cache.set('th_todoist_' + str(trigger_id), data)\n        except AttributeError:\n            logger.error(items)\n\n        return data", "response": "get the data from the service"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_data(self, trigger_id, **data):\n        title, content = super(ServiceTodoist, self).save_data(trigger_id, **data)\n\n        if self.token:\n            if title or content or data.get('link'):\n                content = title + ' ' + content + ' ' + data.get('link')\n\n                self.todoist.add_item(content)\n\n                sentence = str('todoist {} created').format(data.get('link'))\n                logger.debug(sentence)\n                status = True\n            else:\n                status = False\n        else:\n            logger.critical(\"no token or link provided for trigger ID {} \".format(trigger_id))\n            status = False\n        return status", "response": "let s save the data from the service to the todoist"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the data from the service", "response": "def read_data(self, **kwargs):\n        \"\"\"\n            get the data from the service\n            as the pocket service does not have any date\n            in its API linked to the note,\n            add the triggered date to the dict data\n            thus the service will be triggered when data will be found\n\n            :param kwargs: contain keyword args : trigger_id at least\n            :type kwargs: dict\n\n            :rtype: list\n        \"\"\"\n        trigger_id = kwargs.get('trigger_id')\n        data = list()\n        cache.set('th_joplin_' + str(trigger_id), data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the data of the specified trigger", "response": "def save_data(self, trigger_id, **data):\n        \"\"\"\n            let's save the data\n            :param trigger_id: trigger ID from which to save data\n            :param data: the data to check to be used and save\n            :type trigger_id: int\n            :type data:  dict\n            :return: the status of the save statement\n            :rtype: boolean\n        \"\"\"\n        from th_joplin.models import Joplin\n\n        status = False\n\n        data['output_format'] = 'markdown_github'\n        title, content = super(ServiceJoplin, self).save_data(trigger_id, **data)\n\n        # get the data of this trigger\n        trigger = Joplin.objects.get(trigger_id=trigger_id)\n        status = self.joplin.create_note(title=title, body=content, parent_id=trigger.folder).status_code\n        if status == 200:\n            status = True\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the service name then load the model_form", "response": "def get_service(service, model_form='models', form_name=''):\n    \"\"\"\n        get the service name then load the model\n        :param service: the service name\n        :param model_form: could be 'models' or 'forms'\n        :param form_name: the name of the form is model_form is 'forms'\n        :type service: string\n        :type model_form: string\n        :type form_name: string\n        :return: the object of the spotted Class.\n        :rtype: object\n\n        :Example:\n\n        class_name could be :\n            th_rss.models\n            th_rss.forms\n        service_name could be :\n            ServiceRss\n        then could call :\n            Rss+ProviderForm\n            Evernote+ConsumerForm\n    \"\"\"\n    service_name = str(service).split('Service')[1]\n\n    class_name = 'th_' + service_name.lower() + '.' + model_form\n\n    if model_form == 'forms':\n        return class_for_name(class_name, service_name + form_name)\n    else:\n        return class_for_name(class_name, service_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert Datetime 9 - tuple to datetime", "response": "def to_datetime(data):\n    \"\"\"\n        convert Datetime 9-tuple to the date and time format\n        feedparser provides this 9-tuple\n        :param data: data to be checked\n        :type data: dict\n    \"\"\"\n    my_date_time = None\n\n    if 'published_parsed' in data:\n        my_date_time = datetime.datetime.utcfromtimestamp(time.mktime(data.get('published_parsed')))\n    elif 'created_parsed' in data:\n        my_date_time = datetime.datetime.utcfromtimestamp(time.mktime(data.get('created_parsed')))\n    elif 'updated_parsed' in data:\n        my_date_time = datetime.datetime.utcfromtimestamp(time.mktime(data.get('updated_parsed')))\n    elif 'my_date' in data:\n        my_date_time = arrow.get(data['my_date'])\n\n    return my_date_time"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_tags(model, trigger_id):\n    # get the data of this trigger\n    trigger = model.objects.get(trigger_id=trigger_id)\n\n    tags = ''\n    if trigger.tag:\n        # is there several tag ?\n        tags = [\"#\" + tag.strip() for tag in trigger.tag.split(',')]\n        tags = str(','.join(tags)) if isinstance(tags, list) else tags\n        tags = ' ' + tags\n    return tags", "response": "get the tags of the base base"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating the content of the post in the content directory of the post", "response": "def _create_content(self, site_title, content, pelican_path, url, **data):\n        \"\"\"\n            create the file in the 'content' directory of pelican\n            :param content: the content of the post\n            :param pelican_path: where the files are created\n            :param url: url of the datasource\n            :param data: the data to check to be used and save\n            :type content: string\n            :type pelican_path: string\n            :type url: string\n            :type data:  dict\n            :return: the status of the save statement\n            :rtype: boolean\n        \"\"\"\n        published = to_datetime(data)\n\n        category = data.get('category') if data.get('category') else ''\n        tags = data.get('tags') if data.get('tags') else ''\n\n        filename = self._set_filename(data.get('title'), pelican_path)\n\n        full_content = self._set_full_content(site_title, data.get('title'),\n                                              published, content, url,\n                                              category, tags)\n\n        try:\n            with open(filename, 'w') as f:\n                f.write(full_content)\n            status = True\n        except Exception as e:\n            logger.critical(e)\n            status = False\n\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_filename(title, pelican_path):\n        # cleaning the special char\n        name = title.replace('/', '_').replace('\\\\', '_').\\\n            replace(' ', '_').replace(':', '_').replace('&', '').\\\n            replace('?', '').replace('!', '')\n\n        return \"{}/{}.html\".format(pelican_path, name)", "response": "set the filename of the post\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_full_content(self, site_title, title, published,\n                          content, url, category='', tags=''):\n        \"\"\"\n            generate the full content of the file\n            create the file in the 'content' directory of pelican\n            :param site_title: title of the website\n            :param title: the title of the post\n            :param content: the content of the post\n            :param published: the date when the data\n            has been published by the provider\n            :param url: url of the datasource\n            :param category: category of this data\n            :type site_title: string\n            :type title: string\n            :type content: string\n            :type published: string\n            :type url: string\n            :param category: string\n            :return: the the complet content\n            :rtype: string\n        \"\"\"\n\n        header = self._set_meta(title, published, category, tags)\n        content = self._set_content(content)\n        footer = self._set_footer(url, site_title)\n\n        full_content = self._set_html_begin() + self._set_title(title)\n        full_content += header + content + footer + self._set_html_end()\n\n        return full_content", "response": "Generate the full content of the file in the content directory of the post."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_meta(self, title, published, category='', tags=''):\n        slug_published = slugify(arrow.get(published).format(\n            'YYYY-MM-DD HH:mm'))\n        slug_title = slugify(title)\n\n        header = '\\n\\t\\t<meta name=\"date\" content=\"{}\" />\\n'.format(published)\n        if tags:\n            header += '\\t\\t<meta name=\"tags\" content=\"{}\" />\\n'.format(tags)\n        if category:\n            header += '\\t\\t<meta name=\"category\" content=\"{}\" />\\n'.format(\n                category)\n        if self.AUTHOR:\n            header += '\\t\\t<meta name=\"authors\" content=\"{}\" />\\n'.format(\n                self.AUTHOR)\n        header += '\\t\\t<meta name=\"slug\" content=\"{}\"/>\\n'.format(\n            slug_published + '-' + slug_title)\n        header += '\\t</head>'\n\n        return header", "response": "set the meta data for the data in the neccesary format"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_data(self, trigger_id, **data):\n        from th_pelican.models import Pelican\n\n        title, content = super(ServicePelican, self).save_data(\n            trigger_id, **data)\n\n        trigger = Pelican.objects.get(trigger_id=trigger_id)\n\n        params = {'tags': trigger.tags.lower(),\n                  'category': trigger.category.lower()}\n\n        if 'tags' in data:\n            del data['tags']\n\n        params.update(data)\n\n        if self._create_content(trigger.title, content, trigger.path,\n                                trigger.url, **params):\n            sentence = 'pelican {} created'\n            status = True\n        else:\n            sentence = 'pelican {} not created'\n            status = False\n        logger.debug(sentence.format(title))\n\n        return status", "response": "let s save the data from Pelican and return the status of the save statement"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_trigger(self, service):\n        now = arrow.utcnow().to(settings.TIME_ZONE).format('YYYY-MM-DD HH:mm:ssZZ')\n        TriggerService.objects.filter(id=service.id).update(date_triggered=now,\n                                                            consumer_failed=0,\n                                                            provider_failed=0,\n                                                            )", "response": "update the date when occurs the trigger\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log_update(self, service, to_update, status, count):\n        if to_update:\n            if status:\n                msg = \"{} - {} new data\".format(service, count)\n                update_result(service.id, msg=\"OK\", status=status)\n                logger.info(msg)\n            else:\n                msg = \"{} AN ERROR OCCURS \".format(service)\n                update_result(service.id, msg=msg, status=status)\n                logger.warning(msg)\n        else:\n            logger.debug(\"{} nothing new \".format(service))", "response": "lets log what we have to update the data at the end of the neccesary log"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef provider(self, service):\n        service_provider = default_provider.get_service(str(service.provider.name.name))\n\n        # 1) get the data from the provider service\n        module_name = 'th_' + service.provider.name.name.split('Service')[1].lower()\n        kwargs = {'trigger_id': str(service.id), 'cache_stack': module_name}\n        return getattr(service_provider, 'process_data')(**kwargs)", "response": "get the data from the cache of the service provider\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall the consumer and handle the data", "response": "def consumer(self, service, data, to_update, status):\n        \"\"\"\n            call the consumer and handle the data\n            :param service:\n            :param data:\n            :param to_update:\n            :param status:\n            :return: status\n        \"\"\"\n        # consumer - the service which uses the data\n        service_consumer = default_provider.get_service(str(service.consumer.name.name))\n        kwargs = {'user': service.user}\n        getattr(service_consumer, '__init__')(service.consumer.token, **kwargs)\n        instance = getattr(service_consumer, 'save_data')\n\n        # 2) for each one\n        for d in data:\n            d['userservice_id'] = service.consumer.id\n            # the consumer will save the data and return if success or not\n            status = instance(service.id, **d)\n\n            to_update = True\n\n        return to_update, status"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef publishing(self, service):\n        # flag to know if we have to update\n        to_update = False\n        # flag to get the status of a service\n        status = False\n        # provider - the service that offer data\n        # check if the service has already been triggered\n        # if date_triggered is None, then it's the first run\n        if service.date_triggered is None:\n            logger.debug(\"first run {}\".format(service))\n            to_update = True\n            status = True\n        # run run run\n        data = self.provider(service)\n        count_new_data = len(data) if data else 0\n        if count_new_data > 0:\n            to_update, status = self.consumer(service, data, to_update, status)\n            # let's log\n        self.log_update(service, to_update, status, count_new_data)\n        # let's update\n        if to_update and status:\n            self.update_trigger(service)", "response": "publishes the cache entry for a service"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef name(function):\n    if isinstance(function, types.FunctionType):\n        return function.__name__\n    else:\n        return str(function)", "response": "Retrieve a pretty name for the function\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef map_t(func):\n    return Transformation('map({0})'.format(name(func)),\n                          partial(map, func),\n                          {ExecutionStrategies.PARALLEL})", "response": "Returns a transformation for the given function that maps the sequence elements."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef starmap_t(func):\n    return Transformation('starmap({})'.format(name(func)),\n                          partial(starmap, func),\n                          {ExecutionStrategies.PARALLEL})", "response": "Returns a transformation for the given function using the given function as the source."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a transformation for the filter function", "response": "def filter_t(func):\n    \"\"\"\n    Transformation for Sequence.filter\n    :param func: filter function\n    :return: transformation\n    \"\"\"\n    return Transformation('filter({0})'.format(name(func)),\n                          partial(filter, func),\n                          {ExecutionStrategies.PARALLEL})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_not_t(func):\n    return Transformation('filter_not({0})'.format(name(func)),\n                          partial(six.moves.filterfalse, func),\n                          {ExecutionStrategies.PARALLEL})", "response": "Returns a filter_not transformation for Sequence. filter_not"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a transformation that slices the sequence at the given index.", "response": "def slice_t(start, until):\n    \"\"\"\n    Transformation for Sequence.slice\n    :param start: start index\n    :param until: until index (does not include element at until)\n    :return: transformation\n    \"\"\"\n    return Transformation(\n        'slice({0}, {1})'.format(start, until),\n        lambda sequence: islice(sequence, start, until),\n        None\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distinct_by_t(func):\n    def distinct_by(sequence):\n        distinct_lookup = {}\n        for element in sequence:\n            key = func(element)\n            if key not in distinct_lookup:\n                distinct_lookup[key] = element\n        return distinct_lookup.values()\n    return Transformation('distinct_by({0})'.format(name(func)), distinct_by, None)", "response": "Transformation for Sequence. distinct_by_t"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new transformation that sorts the sequence by the given key.", "response": "def sorted_t(key=None, reverse=False):\n    \"\"\"\n    Transformation for Sequence.sorted\n    :param key: key to sort by\n    :param reverse: reverse or not\n    :return: transformation\n    \"\"\"\n    return Transformation(\n        'sorted',\n        lambda sequence: sorted(sequence, key=key, reverse=reverse),\n        None\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef order_by_t(func):\n    return Transformation(\n        'order_by({0})'.format(name(func)),\n        lambda sequence: sorted(sequence, key=func),\n        None\n    )", "response": "Returns a new transformation for the sequence. order_by function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef drop_right_t(n):\n    if n <= 0:\n        end_index = None\n    else:\n        end_index = -n\n    return Transformation(\n        'drop_right({0})'.format(n),\n        lambda sequence: sequence[:end_index],\n        None\n    )", "response": "Returns a new transformation that drops the n elements from the right of the sequence"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a transformation that maps the elements of the sequence to the elements of the sequence.", "response": "def flat_map_t(func):\n    \"\"\"\n    Transformation for Sequence.flat_map\n    :param func: function to flat_map\n    :return: transformation\n    \"\"\"\n    return Transformation(\n        'flat_map({0})'.format(name(func)),\n        partial(flat_map_impl, func),\n        {ExecutionStrategies.PARALLEL}\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cartesian_t(iterables, repeat):\n    return Transformation(\n        'cartesian',\n        lambda sequence: product(sequence, *iterables, repeat=repeat),\n        None\n    )", "response": "Returns a transformation that will take the elements of iterables for cartesian product."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tails_t(wrap):\n    return Transformation(\n        'tails',\n        lambda sequence: [wrap(sequence[i:]) for i in range(len(sequence) + 1)],\n        {ExecutionStrategies.PRE_COMPUTE}\n    )", "response": "Returns a new transformation for the tails sequence"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reduce_by_key_impl(func, sequence):\n    result = {}\n    for key, value in sequence:\n        if key in result:\n            result[key] = func(result[key], value)\n        else:\n            result[key] = value\n    return six.viewitems(result)", "response": "Implementation for reduce_by_key_t\n    :param func: reduce function\n    :param sequence: sequence to reduce\n    :return: reduced sequence"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _accumulate(sequence, func):\n    iterator = iter(sequence)\n    total = next(iterator)\n    yield total\n    for element in iterator:\n        total = func(total, element)\n        yield total", "response": "Python 2 accumulate implementation taken from\n    Python2 accumulate implementation taken from\n    https://docs. python. org / 3. 6. 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef accumulate_impl(func, sequence):\n    # pylint: disable=no-name-in-module\n    \"\"\"\n    Implementation for accumulate\n    :param sequence: sequence to accumulate\n    :param func: accumulate function\n    \"\"\"\n    if six.PY3:\n        from itertools import accumulate\n        return accumulate(sequence, func)\n    else:\n        return _accumulate(sequence, func)", "response": "Implementation for accumulate\n    :param sequence: sequence to accumulate\n    :param func: accumulate function"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count_by_value_impl(sequence):\n    counter = collections.Counter()\n    for e in sequence:\n        counter[e] += 1\n    return six.viewitems(counter)", "response": "Implementation for count_by_value_t\n    :param sequence: sequence of values\n    :return: counts by value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef group_by_impl(func, sequence):\n    result = {}\n    for element in sequence:\n        if result.get(func(element)):\n            result.get(func(element)).append(element)\n        else:\n            result[func(element)] = [element]\n    return six.viewitems(result)", "response": "Implementation for group_by_t\n    :param func: grouping function\n    :param sequence: sequence to group\n    :return: grouped sequence"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new transformation that will wrap the children values with this .", "response": "def grouped_t(wrap, size):\n    \"\"\"\n    Transformation for Sequence.grouped\n    :param wrap: wrap children values with this\n    :param size: size of groups\n    :return: transformation\n    \"\"\"\n    return Transformation(\n        'grouped({0})'.format(size),\n        partial(grouped_impl, wrap, size),\n        None\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sliding_impl(wrap, size, step, sequence):\n    i = 0\n    n = len(sequence)\n    while i + size <= n or (step != 1 and i < n):\n        yield wrap(sequence[i: i + size])\n        i += step", "response": "Implementation for sliding_t\n    :param wrap: wrap children values with this\n    :param size: size of window\n    :param step: step size\n    :param sequence: sequence to create sliding windows from\n    :return: sequence of sliding windows"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sliding_t(wrap, size, step):\n    return Transformation(\n        'sliding({0}, {1})'.format(size, step),\n        partial(sliding_impl, wrap, size, step),\n        {ExecutionStrategies.PRE_COMPUTE}\n    )", "response": "Returns a new sequence with sliding children values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef partition_t(wrap, func):\n    return Transformation(\n        'partition({0})'.format(name(func)),\n        partial(partition_impl, wrap, func),\n        None\n    )", "response": "Returns a new transformation that will be applied to the children of the passed in function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inner_join_impl(other, sequence):\n    seq_dict = {}\n    for element in sequence:\n        seq_dict[element[0]] = element[1]\n    seq_kv = seq_dict\n    other_kv = dict(other)\n    keys = seq_kv.keys() if len(seq_kv) < len(other_kv) else other_kv.keys()\n    result = {}\n    for k in keys:\n        if k in seq_kv and k in other_kv:\n            result[k] = (seq_kv[k], other_kv[k])\n    return six.viewitems(result)", "response": "Implementation for part of join_impl\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef join_t(other, join_type):\n    return Transformation(\n        '{0}_join'.format(join_type),\n        partial(join_impl, other, join_type),\n        None\n    )", "response": "Returns a new sequence transformation for the given join type"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_primitive(val):\n    return isinstance(val,\n                      (str, bool, float, complex, bytes, six.text_type)\n                      + six.string_types + six.integer_types)", "response": "Checks if the passed value is a primitive type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_namedtuple(val):\n    val_type = type(val)\n    bases = val_type.__bases__\n    if len(bases) != 1 or bases[0] != tuple:\n        return False\n    fields = getattr(val_type, '_fields', None)\n    return all(isinstance(n, str) for n in fields)", "response": "Checks if val is a namedtuple"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_iterable(val):\n    if isinstance(val, list):\n        return False\n    return isinstance(val, collections.Iterable)", "response": "Check if val is a list but is a collections. Iterable type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit an iterable into parts of length parts", "response": "def split_every(parts, iterable):\n    \"\"\"\n    Split an iterable into parts of length parts\n\n    >>> l = iter([1, 2, 3, 4])\n    >>> split_every(2, l)\n    [[1, 2], [3, 4]]\n\n    :param iterable: iterable to split\n    :param parts: number of chunks\n    :return: return the iterable split in parts\n    \"\"\"\n    return takewhile(bool, (list(islice(iterable, parts)) for _ in count()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunpacks the function and args then apply the function to the arguments and return the result", "response": "def unpack(packed):\n    \"\"\"\n    Unpack the function and args then apply the function to the arguments and return result\n    :param packed: input packed tuple of (func, args)\n    :return: result of applying packed function on packed args\n    \"\"\"\n    func, args = serializer.loads(packed)\n    result = func(*args)\n    if isinstance(result, collections.Iterable):\n        return list(result)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parallelize(func, result, processes=None, partition_size=None):\n    parallel_iter = lazy_parallelize(\n        func, result, processes=processes, partition_size=partition_size)\n    return chain.from_iterable(parallel_iter)", "response": "Returns an iterable which is lazily computed in parallel from applying func on result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the partition size to evenly distribute work across processes.", "response": "def compute_partition_size(result, processes):\n    \"\"\"\n    Attempts to compute the partition size to evenly distribute work across processes. Defaults to\n    1 if the length of result cannot be determined.\n\n    :param result: Result to compute on\n    :param processes: Number of processes to use\n    :return: Best partition size\n    \"\"\"\n    try:\n        return max(math.ceil(len(result) / processes), 1)\n    except TypeError:\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomposing all the function arguments together a", "response": "def compose(*functions):\n    \"\"\"\n    Compose all the function arguments together\n    :param functions: Functions to compose\n    :return: Single composed function\n    \"\"\"\n    # pylint: disable=undefined-variable\n    return reduce(lambda f, g: lambda x: f(g(x)), functions, lambda x: x)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting the sequence of transformations in serial", "response": "def evaluate(self, sequence, transformations):\n        \"\"\"\n        Execute the sequence of transformations in serial\n        :param sequence: Sequence to evaluation\n        :param transformations: Transformations to apply\n        :return: Resulting sequence or value\n        \"\"\"\n        # pylint: disable=no-self-use\n        result = sequence\n        for transform in transformations:\n            strategies = transform.execution_strategies\n            if strategies is not None and ExecutionStrategies.PRE_COMPUTE in strategies:\n                result = transform.function(list(result))\n            else:\n                result = transform.function(result)\n        return iter(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting the sequence of transformations in parallel and return the result.", "response": "def evaluate(self, sequence, transformations):\n        \"\"\"\n        Execute the sequence of transformations in parallel\n        :param sequence: Sequence to evaluation\n        :param transformations: Transformations to apply\n        :return: Resulting sequence or value\n        \"\"\"\n        result = sequence\n        parallel = partial(\n            parallelize, processes=self.processes, partition_size=self.partition_size)\n        staged = []\n        for transform in transformations:\n            strategies = transform.execution_strategies or {}\n            if ExecutionStrategies.PARALLEL in strategies:\n                staged.insert(0, transform.function)\n            else:\n                if staged:\n                    result = parallel(compose(*staged), result)\n                    staged = []\n                if ExecutionStrategies.PRE_COMPUTE in strategies:\n                    result = list(result)\n                result = transform.function(result)\n        if staged:\n            result = parallel(compose(*staged), result)\n        return iter(result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef evaluate(self, sequence):\n        last_cache_index = self.cache_scan()\n        transformations = self.transformations[last_cache_index:]\n        return self.engine.evaluate(sequence, transformations)", "response": "Compute the lineage on the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cache_scan(self):\n        try:\n            return len(self.transformations) - self.transformations[::-1].index(CACHE_T)\n        except ValueError:\n            return 0", "response": "Scan the lineage for the index of the most recent cache."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _wrap(value):\n    if is_primitive(value):\n        return value\n    if isinstance(value, (dict, set)) or is_namedtuple(value):\n        return value\n    elif isinstance(value, collections.Iterable):\n        try:\n            if type(value).__name__ == 'DataFrame':\n                import pandas\n                if isinstance(value, pandas.DataFrame):\n                    return Sequence(value.values)\n        except ImportError: # pragma: no cover\n            pass\n\n        return Sequence(value)\n    else:\n        return value", "response": "Wraps the passed value in a Sequence if it is not a primitive."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _transform(self, *transforms):\n        sequence = None\n        for transform in transforms:\n            if sequence:\n                sequence = Sequence(sequence, transform=transform)\n            else:\n                sequence = Sequence(self, transform=transform)\n        return sequence", "response": "Returns a new sequence with the given transforms applied."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cache(self, delete_lineage=False):\n        if len(self._lineage) == 0 or self._lineage[-1] == transformations.CACHE_T:\n            if not isinstance(self._base_sequence, list):\n                self._base_sequence = list(self._base_sequence)\n                self._lineage.apply(transformations.CACHE_T)\n        else:\n            self._base_sequence = list(self._evaluate())\n            self._lineage.apply(transformations.CACHE_T)\n        if delete_lineage:\n            self._lineage = Lineage(engine=self.engine)\n        return self", "response": "Caches the result of the Sequence so far."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the cartesian product of the passed iterables with the specified number of of repetitions.", "response": "def cartesian(self, *iterables, **kwargs):\n        \"\"\"\n        Returns the cartesian product of the passed iterables with the specified number of\n        repetitions.\n\n        The keyword argument `repeat` is read from kwargs to pass to itertools.cartesian.\n\n        >>> seq.range(2).cartesian(range(2))\n        [(0, 0), (0, 1), (1, 0), (1, 1)]\n\n        :param iterables: elements for cartesian product\n        :param kwargs: the variable `repeat` is read from kwargs\n        :return: cartesian product\n        \"\"\"\n        return self._transform(transformations.cartesian_t(iterables, kwargs.get('repeat', 1)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drop(self, n):\n        if n <= 0:\n            return self._transform(transformations.drop_t(0))\n        else:\n            return self._transform(transformations.drop_t(n))", "response": "Returns a new sequence with first n elements removed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef drop_right(self, n):\n        return self._transform(transformations.CACHE_T, transformations.drop_right_t(n))", "response": "Returns a new sequence with the last n elements dropped."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef take(self, n):\n        if n <= 0:\n            return self._transform(transformations.take_t(0))\n        else:\n            return self._transform(transformations.take_t(n))", "response": "Take the first n elements of the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncounts the number of elements in the sequence that satisfy the predicate func.", "response": "def count(self, func):\n        \"\"\"\n        Counts the number of elements in the sequence which satisfy the predicate func.\n\n        >>> seq([-1, -2, 1, 2]).count(lambda x: x > 0)\n        2\n\n        :param func: predicate to count elements on\n        :return: count of elements that satisfy predicate\n        \"\"\"\n        n = 0\n        for element in self:\n            if func(element):\n                n += 1\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reduce(self, func, *initial):\n        if len(initial) == 0:\n            return _wrap(reduce(func, self))\n        elif len(initial) == 1:\n            return _wrap(reduce(func, self, initial[0]))\n        else:\n            raise ValueError('reduce takes exactly one optional parameter for initial value')", "response": "Reduce the sequence of elements using func."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef product(self, projection=None):\n        if self.empty():\n            if projection:\n                return projection(1)\n            else:\n                return 1\n        if self.size() == 1:\n            if projection:\n                return projection(self.first())\n            else:\n                return self.first()\n\n        if projection:\n            return self.map(projection).reduce(mul)\n        else:\n            return self.reduce(mul)", "response": "Takes product of elements in sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sum(self, projection=None):\n        if projection:\n            return sum(self.map(projection))\n        else:\n            return sum(self)", "response": "Takes sum of elements in sequence.\n Takes sum of elements in sequence.\n 10\n\n 10\n 10"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef average(self, projection=None):\n        length = self.size()\n        if projection:\n            return sum(self.map(projection)) / length\n        else:\n            return sum(self) / length", "response": "Takes the average of elements in the sequence and returns the average of the elements in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef aggregate(self, *args):\n        seed = None\n        result_lambda = identity\n        if len(args) == 1:\n            func = args[0]\n        elif len(args) == 2:\n            seed = args[0]\n            func = args[1]\n        elif len(args) == 3:\n            seed = args[0]\n            func = args[1]\n            result_lambda = args[2]\n        else:\n            raise ValueError('aggregate takes 1-3 arguments, {0} were given'.format(len(args)))\n        if len(args) == 1:\n            return result_lambda(self.drop(1).fold_left(self.first(), func))\n        else:\n            return result_lambda(self.fold_left(seed, func))", "response": "Returns the value of the aggregate function applied to the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fold_left(self, zero_value, func):\n        result = zero_value\n        for element in self:\n            result = func(result, element)\n        return _wrap(result)", "response": "Folds the elements of the sequence from left to right using a function func to reduce the value given by zero_value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfold the elements of the sequence from right to left using a function func.", "response": "def fold_right(self, zero_value, func):\n        \"\"\"\n        Assuming that the sequence elements are of type A, folds from right to left starting with\n        the seed value given by zero_value (of type A) using a function of type\n        func(next: A, current: B) => B. current represents the folded value so far and next is the\n        next element from the sequence to fold into current.\n\n        >>> seq('a', 'b', 'c').fold_left(['start'], lambda next, current: current + [next])\n        ['start', 'c', 'b', a']\n\n        :param zero_value: zero value to reduce into\n        :param func: Two parameter function as described by function docs\n        :return: value from folding values with func into zero_value from right to left\n        \"\"\"\n        result = zero_value\n        for element in self.reverse():\n            result = func(element, result)\n        return _wrap(result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef join(self, other, join_type=\"inner\"):\n        return self._transform(transformations.join_t(other, join_type))", "response": "Join two sets of key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sliding(self, size, step=1):\n        return self._transform(transformations.sliding_t(_wrap, size, step))", "response": "Returns a new sequence of fixed size windows with sliding window over the last size elements."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sorted(self, key=None, reverse=False):\n        return self._transform(transformations.sorted_t(key=key, reverse=reverse))", "response": "Returns a new sequence with the elements sorted by key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef slice(self, start, until):\n        return self._transform(transformations.slice_t(start, until))", "response": "Takes a slice of the sequence starting at start and until but not including until."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_list(self, n=None):\n        if n is None:\n            self.cache()\n            return self._base_sequence\n        else:\n            return self.cache().take(n).list()", "response": "Converts sequence to list of elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the sequence of key - value pairs to a dictionary.", "response": "def to_dict(self, default=None):\n        \"\"\"\n        Converts sequence of (Key, Value) pairs to a dictionary.\n\n        >>> type(seq([('a', 1)]).to_dict())\n        dict\n\n        >>> seq([('a', 1), ('b', 2)]).to_dict()\n        {'a': 1, 'b': 2}\n\n        :param default: Can be a callable zero argument function. When not None, the returned\n            dictionary is a collections.defaultdict with default as value for missing keys. If the\n            value is not callable, then a zero argument lambda function is created returning the\n            value and used for collections.defaultdict\n        :return: dictionary from sequence of (Key, Value) elements\n        \"\"\"\n        dictionary = {}\n        for e in self.sequence:\n            dictionary[e[0]] = e[1]\n        if default is None:\n            return dictionary\n        else:\n            if hasattr(default, '__call__'):\n                return collections.defaultdict(default, dictionary)\n            else:\n                return collections.defaultdict(lambda: default, dictionary)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the sequence to a file.", "response": "def to_file(self, path, delimiter=None, mode='wt', buffering=-1, encoding=None, errors=None,\n                newline=None, compresslevel=9, format=None, check=-1, preset=None, filters=None,\n                compression=None):\n        \"\"\"\n        Saves the sequence to a file by executing str(self) which becomes str(self.to_list()). If\n        delimiter is defined will instead execute self.make_string(delimiter)\n\n        :param path: path to write file\n        :param delimiter: if defined, will call make_string(delimiter) and save that to file.\n        :param mode: file open mode\n        :param buffering: passed to builtins.open\n        :param encoding: passed to builtins.open\n        :param errors: passed to builtins.open\n        :param newline: passed to builtins.open\n        :param compression: compression format\n        :param compresslevel: passed to gzip.open\n        :param format: passed to lzma.open\n        :param check: passed to lzma.open\n        :param preset: passed to lzma.open\n        :param filters: passed to lzma.open\n        \"\"\"\n        with universal_write_open(path, mode=mode, buffering=buffering, encoding=encoding,\n                                  errors=errors, newline=newline, compression=compression,\n                                  compresslevel=compresslevel, format=format, check=check,\n                                  preset=preset, filters=filters) as output:\n            if delimiter:\n                output.write(six.u(self.make_string(delimiter)))\n            else:\n                output.write(six.u(str(self)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving the sequence to a jsonl file.", "response": "def to_jsonl(self, path, mode='wb', compression=None):\n        \"\"\"\n        Saves the sequence to a jsonl file. Each element is mapped using json.dumps then written\n        with a newline separating each element.\n\n        :param path: path to write file\n        :param mode: mode to write in, defaults to 'w' to overwrite contents\n        :param compression: compression format\n        \"\"\"\n        with universal_write_open(path, mode=mode, compression=compression) as output:\n            output.write((self.map(json.dumps).make_string('\\n') + '\\n').encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the sequence to a json file.", "response": "def to_json(self, path, root_array=True, mode=WRITE_MODE, compression=None):\n        \"\"\"\n        Saves the sequence to a json file. If root_array is True, then the sequence will be written\n        to json with an array at the root. If it is False, then the sequence will be converted from\n        a sequence of (Key, Value) pairs to a dictionary so that the json root is a dictionary.\n\n        :param path: path to write file\n        :param root_array: write json root as an array or dictionary\n        :param mode: file open mode\n        \"\"\"\n        with universal_write_open(path, mode=mode, compression=compression) as output:\n            if root_array:\n                json.dump(self.to_list(), output)\n            else:\n                json.dump(self.to_dict(), output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the sequence to a csv file.", "response": "def to_csv(self, path, mode=WRITE_MODE, dialect='excel', compression=None,\n               newline='', **fmtparams):\n        \"\"\"\n        Saves the sequence to a csv file. Each element should be an iterable which will be expanded\n        to the elements of each row.\n\n        :param path: path to write file\n        :param mode: file open mode\n        :param dialect: passed to csv.writer\n        :param fmtparams: passed to csv.writer\n        \"\"\"\n\n        if 'b' in mode:\n            newline = None\n\n        with universal_write_open(path, mode=mode, compression=compression,\n                                  newline=newline) as output:\n            csv_writer = csv.writer(output, dialect=dialect, **fmtparams)\n            for row in self:\n                csv_writer.writerow([six.u(str(element)) for element in row])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _to_sqlite3_by_table(self, conn, table_name):\n        def _insert_item(item):\n            if isinstance(item, dict):\n                cols = ', '.join(item.keys())\n                placeholders = ', '.join('?' * len(item))\n                sql = 'INSERT INTO {} ({}) VALUES ({})'.format(table_name, cols, placeholders)\n                conn.execute(sql, tuple(item.values()))\n            elif is_namedtuple(item):\n                cols = ', '.join(item._fields)\n                placeholders = ', '.join('?' * len(item))\n                sql = 'INSERT INTO {} ({}) VALUES ({})'.format(table_name, cols, placeholders)\n                conn.execute(sql, item)\n            elif isinstance(item, (list, tuple)):\n                placeholders = ', '.join('?' * len(item))\n                sql = 'INSERT INTO {} VALUES ({})'.format(table_name, placeholders)\n                conn.execute(sql, item)\n            else:\n                raise TypeError('item must be one of dict, namedtuple, tuple or list got {}'\n                                .format(type(item)))\n\n        self.for_each(_insert_item)", "response": "Saves the sequence to sqlite3 database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_sqlite3(self, conn, target, *args, **kwargs):\n        # pylint: disable=no-member\n        insert_regex = re.compile(r'(insert|update)\\s+into', flags=re.IGNORECASE)\n        if insert_regex.match(target):\n            insert_f = self._to_sqlite3_by_query\n        else:\n            insert_f = self._to_sqlite3_by_table\n\n        if isinstance(conn, (sqlite3.Connection, sqlite3.Cursor)):\n            insert_f(conn, target)\n            conn.commit()\n        elif isinstance(conn, str):\n            with sqlite3.connect(conn, *args, **kwargs) as input_conn:\n                insert_f(input_conn, target)\n                input_conn.commit()\n        else:\n            raise ValueError('conn must be a must be a file path or sqlite3 Connection/Cursor')", "response": "Saves the sequence to sqlite3 database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_pandas(self, columns=None):\n        # pylint: disable=import-error\n        \"\"\"\n        Converts sequence to a pandas DataFrame using pandas.DataFrame.from_records\n\n        :param columns: columns for pandas to use\n        :return: DataFrame of sequence\n        \"\"\"\n        import pandas\n        return pandas.DataFrame.from_records(self.to_list(), columns=columns)", "response": "Converts sequence to a pandas DataFrame using pandas. DataFrame. from_records\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tabulate(self, n=None, headers=(), tablefmt=\"simple\", floatfmt=\"g\", numalign=\"decimal\",\n                 stralign=\"left\", missingval=\"\"):\n        \"\"\"\n        Return pretty string table of first n rows of sequence or everything if n is None. See\n        https://bitbucket.org/astanin/python-tabulate for details on tabulate parameters\n\n        :param n: Number of rows to show, if set to None return all rows\n        :param headers: Passed to tabulate\n        :param tablefmt: Passed to tabulate\n        :param floatfmt: Passed to tabulate\n        :param numalign: Passed to tabulate\n        :param stralign: Passed to tabulate\n        :param missingval: Passed to tabulate\n        \"\"\"\n        self.cache()\n        length = self.len()\n        if length == 0 or not is_tabulatable(self[0]):\n            return None\n\n        if n is None or n >= length:\n            rows = self.list()\n            message = ''\n        else:\n            rows = self.take(n).list()\n            if tablefmt == 'simple':\n                message = '\\nShowing {} of {} rows'.format(n, length)\n            elif tablefmt == 'html':\n                message = '<p>Showing {} of {} rows'.format(n, length)\n            else:\n                message = ''\n        if len(headers) == 0 and is_namedtuple(rows[0]):\n            headers = rows[0]._fields\n        return tabulate(rows, headers=headers, tablefmt=tablefmt, floatfmt=floatfmt,\n                        numalign=numalign, stralign=stralign, missingval=missingval) + message", "response": "Return pretty string table of first n rows of sequence or all rows if n is None."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open(self, path, delimiter=None, mode='r', buffering=-1, encoding=None, errors=None,\n             newline=None):\n        \"\"\"\n        Reads and parses input files as defined.\n\n        If delimiter is not None, then the file is read in bulk then split on it. If it is None\n        (the default), then the file is parsed as sequence of lines. The rest of the options are\n        passed directly to builtins.open with the exception that write/append file modes is not\n        allowed.\n\n        >>> seq.open('examples/gear_list.txt').take(1)\n        [u'tent\\\\n']\n\n        :param path: path to file\n        :param delimiter: delimiter to split joined text on. if None, defaults to per line split\n        :param mode: file open mode\n        :param buffering: passed to builtins.open\n        :param encoding: passed to builtins.open\n        :param errors: passed to builtins.open\n        :param newline: passed to builtins.open\n        :return: output of file depending on options wrapped in a Sequence via seq\n        \"\"\"\n        if not re.match('^[rbt]{1,3}$', mode):\n            raise ValueError('mode argument must be only have r, b, and t')\n\n        file_open = get_read_function(path, self.disable_compression)\n        file = file_open(path, mode=mode, buffering=buffering, encoding=encoding, errors=errors,\n                         newline=newline)\n        if delimiter is None:\n            return self(file)\n        else:\n            return self(''.join(list(file)).split(delimiter))", "response": "Reads and parses input file as defined."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef csv(self, csv_file, dialect='excel', **fmt_params):\n        if isinstance(csv_file, str):\n            file_open = get_read_function(csv_file, self.disable_compression)\n            input_file = file_open(csv_file)\n        elif hasattr(csv_file, 'next') or hasattr(csv_file, '__next__'):\n            input_file = csv_file\n        else:\n            raise ValueError('csv_file must be a file path or implement the iterator interface')\n\n        csv_input = csvapi.reader(input_file, dialect=dialect, **fmt_params)\n        return self(csv_input).cache(delete_lineage=True)", "response": "Reads and parses a csv file and returns a Sequence object with the cache entries"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef jsonl(self, jsonl_file):\n        if isinstance(jsonl_file, str):\n            file_open = get_read_function(jsonl_file, self.disable_compression)\n            input_file = file_open(jsonl_file)\n        else:\n            input_file = jsonl_file\n        return self(input_file).map(jsonapi.loads).cache(delete_lineage=True)", "response": "Reads and parses a jsonl file and returns a new Seq of the first element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading and parses a json file and returns a dictionary containing the key - value pairs and the key - value pairs.", "response": "def json(self, json_file):\n        \"\"\"\n        Reads and parses the input of a json file handler or file.\n\n        Json files are parsed differently depending on if the root is a dictionary or an array.\n\n        1) If the json's root is a dictionary, these are parsed into a sequence of (Key, Value)\n        pairs\n\n        2) If the json's root is an array, these are parsed into a sequence\n        of entries\n\n        >>> seq.json('examples/users.json').first()\n        [u'sarah', {u'date_created': u'08/08', u'news_email': True, u'email': u'sarah@gmail.com'}]\n\n        :param json_file: path or file containing json content\n        :return: Sequence wrapping jsonl file\n        \"\"\"\n        if isinstance(json_file, str):\n            file_open = get_read_function(json_file, self.disable_compression)\n            input_file = file_open(json_file)\n            json_input = jsonapi.load(input_file)\n        elif hasattr(json_file, 'read'):\n            json_input = jsonapi.load(json_file)\n        else:\n            raise ValueError('json_file must be a file path or implement the iterator interface')\n\n        if isinstance(json_input, list):\n            return self(json_input)\n        else:\n            return self(six.viewitems(json_input))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sqlite3(self, conn, sql, parameters=None, *args, **kwargs):\n\n        if parameters is None:\n            parameters = ()\n\n        if isinstance(conn, (sqlite3api.Connection, sqlite3api.Cursor)):\n            return self(conn.execute(sql, parameters))\n        elif isinstance(conn, str):\n            with sqlite3api.connect(conn, *args, **kwargs) as input_conn:\n                return self(input_conn.execute(sql, parameters))\n        else:\n            raise ValueError('conn must be a must be a file path or sqlite3 Connection/Cursor')", "response": "Reads input by querying from a sqlite database."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nindicates that a formerly enqueued task is complete.", "response": "def task_done(self):\n        '''Indicate that a formerly enqueued task is complete.\n\n        Used by Queue consumer threads.  For each get() used to fetch a task,\n        a subsequent call to task_done() tells the queue that the processing\n        on the task is complete.\n\n        If a join() is currently blocking, it will resume when all items\n        have been processed (meaning that a task_done() call was received\n        for every item that had been put() into the queue).\n\n        Raises a ValueError if called more times than there were items\n        placed in the queue.\n        '''\n        self._parent._check_closing()\n        with self._parent._all_tasks_done:\n            unfinished = self._parent._unfinished_tasks - 1\n            if unfinished <= 0:\n                if unfinished < 0:\n                    raise ValueError('task_done() called too many times')\n                self._parent._all_tasks_done.notify_all()\n                self._parent._loop.call_soon_threadsafe(\n                    self._parent._finished.set)\n            self._parent._unfinished_tasks = unfinished"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nblocking until all items in the Queue have been gotten and processed.", "response": "def join(self):\n        '''Blocks until all items in the Queue have been gotten and processed.\n\n        The count of unfinished tasks goes up whenever an item is added to the\n        queue. The count goes down whenever a consumer thread calls task_done()\n        to indicate the item was retrieved and all work on it is complete.\n\n        When the count of unfinished tasks drops to zero, join() unblocks.\n        '''\n        with self._parent._all_tasks_done:\n            while self._parent._unfinished_tasks:\n                self._parent._all_tasks_done.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nputting an item into the queue.", "response": "def put(self, item, block=True, timeout=None):\n        '''Put an item into the queue.\n\n        If optional args 'block' is true and 'timeout' is None (the default),\n        block if necessary until a free slot is available. If 'timeout' is\n        a non-negative number, it blocks at most 'timeout' seconds and raises\n        the Full exception if no free slot was available within that time.\n        Otherwise ('block' is false), put an item on the queue if a free slot\n        is immediately available, else raise the Full exception ('timeout'\n        is ignored in that case).\n        '''\n        self._parent._check_closing()\n        with self._parent._sync_not_full:\n            if self._parent._maxsize > 0:\n                if not block:\n                    if self._parent._qsize() >= self._parent._maxsize:\n                        raise SyncQueueFull\n                elif timeout is None:\n                    while self._parent._qsize() >= self._parent._maxsize:\n                        self._parent._sync_not_full.wait()\n                elif timeout < 0:\n                    raise ValueError(\"'timeout' must be a non-negative number\")\n                else:\n                    time = self._parent._loop.time\n                    endtime = time() + timeout\n                    while self._parent._qsize() >= self._parent._maxsize:\n                        remaining = endtime - time()\n                        if remaining <= 0.0:\n                            raise SyncQueueFull\n                        self._parent._sync_not_full.wait(remaining)\n            self._parent._put_internal(item)\n            self._parent._sync_not_empty.notify()\n            self._parent._notify_async_not_empty(threadsafe=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving and return an item from the queue.", "response": "def get(self, block=True, timeout=None):\n        '''Remove and return an item from the queue.\n\n        If optional args 'block' is true and 'timeout' is None (the default),\n        block if necessary until an item is available. If 'timeout' is\n        a non-negative number, it blocks at most 'timeout' seconds and raises\n        the Empty exception if no item was available within that time.\n        Otherwise ('block' is false), return an item if one is immediately\n        available, else raise the Empty exception ('timeout' is ignored\n        in that case).\n        '''\n        self._parent._check_closing()\n        with self._parent._sync_not_empty:\n            if not block:\n                if not self._parent._qsize():\n                    raise SyncQueueEmpty\n            elif timeout is None:\n                while not self._parent._qsize():\n                    self._parent._sync_not_empty.wait()\n            elif timeout < 0:\n                raise ValueError(\"'timeout' must be a non-negative number\")\n            else:\n                time = self._parent._loop.time\n                endtime = time() + timeout\n                while not self._parent._qsize():\n                    remaining = endtime - time()\n                    if remaining <= 0.0:\n                        raise SyncQueueEmpty\n                    self._parent._sync_not_empty.wait(remaining)\n            item = self._parent._get()\n            self._parent._sync_not_full.notify()\n            self._parent._notify_async_not_full(threadsafe=True)\n            return item"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the queue is full.", "response": "def full(self):\n        \"\"\"Return True if there are maxsize items in the queue.\n\n        Note: if the Queue was initialized with maxsize=0 (the default),\n        then full() is never True.\n        \"\"\"\n        if self._parent._maxsize <= 0:\n            return False\n        else:\n            return self.qsize() >= self._parent._maxsize"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nputs an item into the queue.", "response": "async def put(self, item):\n        \"\"\"Put an item into the queue.\n\n        Put an item into the queue. If the queue is full, wait until a free\n        slot is available before adding item.\n\n        This method is a coroutine.\n        \"\"\"\n        self._parent._check_closing()\n        async with self._parent._async_not_full:\n            self._parent._sync_mutex.acquire()\n            locked = True\n            try:\n                if self._parent._maxsize > 0:\n                    do_wait = True\n                    while do_wait:\n                        do_wait = (\n                            self._parent._qsize() >= self._parent._maxsize\n                        )\n                        if do_wait:\n                            locked = False\n                            self._parent._sync_mutex.release()\n                            await self._parent._async_not_full.wait()\n                            self._parent._sync_mutex.acquire()\n                            locked = True\n\n                self._parent._put_internal(item)\n                self._parent._async_not_empty.notify()\n                self._parent._notify_sync_not_empty()\n            finally:\n                if locked:\n                    self._parent._sync_mutex.release()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nput an item into the queue without blocking.", "response": "def put_nowait(self, item):\n        \"\"\"Put an item into the queue without blocking.\n\n        If no free slot is immediately available, raise QueueFull.\n        \"\"\"\n        self._parent._check_closing()\n        with self._parent._sync_mutex:\n            if self._parent._maxsize > 0:\n                if self._parent._qsize() >= self._parent._maxsize:\n                    raise AsyncQueueFull\n\n            self._parent._put_internal(item)\n            self._parent._notify_async_not_empty(threadsafe=False)\n            self._parent._notify_sync_not_empty()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get(self):\n        self._parent._check_closing()\n        async with self._parent._async_not_empty:\n            self._parent._sync_mutex.acquire()\n            locked = True\n            try:\n                do_wait = True\n                while do_wait:\n                    do_wait = self._parent._qsize() == 0\n\n                    if do_wait:\n                        locked = False\n                        self._parent._sync_mutex.release()\n                        await self._parent._async_not_empty.wait()\n                        self._parent._sync_mutex.acquire()\n                        locked = True\n\n                item = self._parent._get()\n                self._parent._async_not_full.notify()\n                self._parent._notify_sync_not_full()\n                return item\n            finally:\n                if locked:\n                    self._parent._sync_mutex.release()", "response": "Remove and return an item from the queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_nowait(self):\n        self._parent._check_closing()\n        with self._parent._sync_mutex:\n            if self._parent._qsize() == 0:\n                raise AsyncQueueEmpty\n\n            item = self._parent._get()\n            self._parent._notify_async_not_full(threadsafe=False)\n            self._parent._notify_sync_not_full()\n            return item", "response": "Remove and return an item from the queue. If no item is available raise QueueEmpty."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nindicates that a task is complete.", "response": "def task_done(self):\n        \"\"\"Indicate that a formerly enqueued task is complete.\n\n        Used by queue consumers. For each get() used to fetch a task,\n        a subsequent call to task_done() tells the queue that the processing\n        on the task is complete.\n\n        If a join() is currently blocking, it will resume when all items have\n        been processed (meaning that a task_done() call was received for every\n        item that had been put() into the queue).\n\n        Raises ValueError if called more times than there were items placed in\n        the queue.\n        \"\"\"\n        self._parent._check_closing()\n        with self._parent._all_tasks_done:\n            if self._parent._unfinished_tasks <= 0:\n                raise ValueError('task_done() called too many times')\n            self._parent._unfinished_tasks -= 1\n            if self._parent._unfinished_tasks == 0:\n                self._parent._finished.set()\n                self._parent._all_tasks_done.notify_all()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def join(self):\n        while True:\n            with self._parent._sync_mutex:\n                if self._parent._unfinished_tasks == 0:\n                    break\n            await self._parent._finished.wait()", "response": "Block until all items in the queue have been retrieved and processed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, to_dir, compressionlevel=9):\n        if os.path.exists(to_dir) and not os.path.isdir(to_dir):\n            raise Exception('Not a directory : %s' % to_dir)\n        elif not os.path.exists(to_dir):\n            os.makedirs(to_dir, mode=int('0755', 8))\n        _save(os.path.join(to_dir, FILE_USER_FST_DATA), self.compiledFST[0], compressionlevel)\n        _save(os.path.join(to_dir, FILE_USER_ENTRIES_DATA), pickle.dumps(self.entries), compressionlevel)", "response": "u Save compressed compiled dictionary data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef analyze(self, text):\n        for cfilter in self.char_filters:\n            text = cfilter.filter(text)\n        tokens = self.tokenizer.tokenize(text, stream=True, wakati=False)\n        for tfilter in self.token_filters:\n            tokens = tfilter.filter(tokens)\n        return tokens", "response": "u Analyze the input text with custom CharFilters Tokenizer and TokenFilters."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compileFST(fst):\n    arcs = []\n    address = {}\n    pos = 0\n    for (num, s) in enumerate(fst.dictionary.values()):\n        for i, (c, v) in enumerate(sorted(s.trans_map.items(), reverse=True)):\n            bary = bytearray()\n            flag = 0\n            output_size, output = 0, bytes()\n            if i == 0:\n                flag += FLAG_LAST_ARC\n            if v['output']:\n                flag += FLAG_ARC_HAS_OUTPUT\n                output_size = len(v['output'])\n                output = v['output']\n            # encode flag, label, output_size, output, relative target address\n            bary += pack('b', flag)\n            if PY3:\n                bary += pack('B', c)\n            else:\n                bary += pack('c', c)\n            if output_size > 0:\n                bary += pack('I', output_size)\n                bary += output\n            next_addr = address.get(v['state'].id)\n            assert next_addr is not None\n            target = (pos + len(bary) + 4) - next_addr\n            assert target > 0\n            bary += pack('I', target)\n            # add the arc represented in bytes\n            if PY3:\n                arcs.append(bytes(bary))\n            else:\n                arcs.append(b''.join(chr(b) for b in bary))\n            # address count up\n            pos += len(bary)\n        if s.is_final():\n            bary = bytearray()\n            # final state\n            flag = FLAG_FINAL_ARC\n            output_count = 0\n            if s.final_output and any(len(e) > 0 for e in s.final_output):\n                # the arc has final output\n                flag += FLAG_ARC_HAS_FINAL_OUTPUT\n                output_count = len(s.final_output)\n            if not s.trans_map:\n                flag += FLAG_LAST_ARC\n            # encode flag, output size, output\n            bary += pack('b', flag)\n            if output_count:\n                bary += pack('I', output_count)\n                for out in s.final_output:\n                    output_size = len(out)\n                    bary += pack('I', output_size)\n                    if output_size:\n                        bary += out\n            # add the arc represented in bytes\n            if PY3:\n                arcs.append(bytes(bary))\n            else:\n                arcs.append(b''.join(chr(b) for b in bary))\n            # address count up\n            pos += len(bary)\n        address[s.id] = pos\n\n    logger.debug('compiled arcs size: %d' % len(arcs))\n    arcs.reverse()\n    return b''.join(arcs)", "response": "u convert FST to byte array representing arcs\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tokenize(self, text, stream=False, wakati=False, baseform_unk=True, dotfile=''):\n        if self.wakati:\n            wakati = True\n        if stream:\n            return self.__tokenize_stream(text, wakati, baseform_unk, '')\n        elif dotfile and len(text) < Tokenizer.MAX_CHUNK_SIZE:\n            return list(self.__tokenize_stream(text, wakati, baseform_unk, dotfile))\n        else:\n            return list(self.__tokenize_stream(text, wakati, baseform_unk, ''))", "response": "u Tokenize the input text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ip(request, real_ip_only=False, right_most_proxy=False):\n    best_matched_ip = None\n    warnings.warn('get_ip is deprecated and will be removed in 3.0.', DeprecationWarning)\n    for key in defs.IPWARE_META_PRECEDENCE_ORDER:\n        value = request.META.get(key, request.META.get(key.replace('_', '-'), '')).strip()\n        if value is not None and value != '':\n            ips = [ip.strip().lower() for ip in value.split(',')]\n            if right_most_proxy and len(ips) > 1:\n                ips = reversed(ips)\n            for ip_str in ips:\n                if ip_str and is_valid_ip(ip_str):\n                    if not ip_str.startswith(NON_PUBLIC_IP_PREFIX):\n                        return ip_str\n                    if not real_ip_only:\n                        loopback = defs.IPWARE_LOOPBACK_PREFIX\n                        if best_matched_ip is None:\n                            best_matched_ip = ip_str\n                        elif best_matched_ip.startswith(loopback) and not ip_str.startswith(loopback):\n                            best_matched_ip = ip_str\n    return best_matched_ip", "response": "Returns client s best - matched ip - address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning client s best - matched real ip - address or None.", "response": "def get_real_ip(request, right_most_proxy=False):\n    \"\"\"\n    Returns client's best-matched `real` `externally-routable` ip-address, or None\n    @deprecated - Do not edit\n    \"\"\"\n    warnings.warn('get_real_ip is deprecated and will be removed in 3.0.', DeprecationWarning)\n    return get_ip(request, real_ip_only=True, right_most_proxy=right_most_proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_trusted_ip(request, right_most_proxy=False, trusted_proxies=TRUSTED_PROXY_LIST):\n    warnings.warn('get_trusted_ip is deprecated and will be removed in 3.0.', DeprecationWarning)\n    if trusted_proxies:\n        meta_keys = ['HTTP_X_FORWARDED_FOR', 'X_FORWARDED_FOR']\n        for key in meta_keys:\n            value = request.META.get(key, request.META.get(key.replace('_', '-'), '')).strip()\n            if value:\n                ips = [ip.strip().lower() for ip in value.split(',')]\n                if len(ips) > 1:\n                    if right_most_proxy:\n                        ips.reverse()\n                    for proxy in trusted_proxies:\n                        if proxy in ips[-1]:\n                            return ips[0]\n    return None", "response": "Returns client s ip - address from trusted proxy server list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck the validity of an IPv6 address", "response": "def is_valid_ipv6(ip_str):\n    \"\"\"\n    Check the validity of an IPv6 address\n    \"\"\"\n    try:\n        socket.inet_pton(socket.AF_INET6, ip_str)\n    except socket.error:\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_request_meta(request, key):\n    value = request.META.get(key, request.META.get(key.replace('_', '-'), '')).strip()\n    if value == '':\n        return None\n    return value", "response": "Given a key returns a cleaned up version of the value from request. META or None if the key is not present."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ips_from_string(ip_str):\n    ip_list = []\n\n    for ip in ip_str.split(','):\n        clean_ip = ip.strip().lower()\n        if clean_ip:\n            ip_list.append(clean_ip)\n\n    ip_count = len(ip_list)\n    if ip_count > 0:\n        if is_valid_ip(ip_list[0]) and is_valid_ip(ip_list[-1]):\n            return ip_list, ip_count\n\n    return [], 0", "response": "Given a string it returns a list of one or more valid IP addresses\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a string it returns a tuple of IP and Routable.", "response": "def get_ip_info(ip_str):\n    \"\"\"\n    Given a string, it returns a tuple of (IP, Routable).\n    \"\"\"\n    ip = None\n    is_routable_ip = False\n    if is_valid_ip(ip_str):\n        ip = ip_str\n        is_routable_ip = is_public_ip(ip)\n    return ip, is_routable_ip"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive two IP addresses it returns the best match ip.", "response": "def get_best_ip(last_ip, next_ip):\n    \"\"\"\n    Given two IP addresses, it returns the the best match ip.\n    Order of precedence is (Public, Private, Loopback, None)\n    Right-most IP is returned\n    \"\"\"\n    if last_ip is None:\n        return next_ip\n    if is_public_ip(last_ip) and not is_public_ip(next_ip):\n        return last_ip\n    if is_private_ip(last_ip) and is_loopback_ip(next_ip):\n        return last_ip\n    return next_ip"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse command line arguments.", "response": "def parse_args(sys_argv, usage):\n    \"\"\"\n    Return an OptionParser for the script.\n\n    \"\"\"\n    args = sys_argv[1:]\n\n    parser = OptionParser(usage=usage)\n    options, args = parser.parse_args(args)\n\n    template, context = args\n\n    return template, context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render(template, context=None, **kwargs):\n    renderer = Renderer()\n    return renderer.render(template, context, **kwargs)", "response": "Render a given template string using the given context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_value(context, key):\n    if isinstance(context, dict):\n        # Then we consider the argument a \"hash\" for the purposes of the spec.\n        #\n        # We do a membership test to avoid using exceptions for flow control\n        # (e.g. catching KeyError).\n        if key in context:\n            return context[key]\n    elif type(context).__module__ != _BUILTIN_MODULE:\n        # Then we consider the argument an \"object\" for the purposes of\n        # the spec.\n        #\n        # The elif test above lets us avoid treating instances of built-in\n        # types like integers and strings as objects (cf. issue #81).\n        # Instances of user-defined classes on the other hand, for example,\n        # are considered objects by the test above.\n        try:\n            attr = getattr(context, key)\n        except AttributeError:\n            # TODO: distinguish the case of the attribute not existing from\n            #   an AttributeError being raised by the call to the attribute.\n            #   See the following issue for implementation ideas:\n            #     http://bugs.python.org/issue7559\n            pass\n        else:\n            # TODO: consider using EAFP here instead.\n            #   http://docs.python.org/glossary.html#term-eafp\n            if callable(attr):\n                return attr()\n            return attr\n\n    return _NOT_FOUND", "response": "Retrieve a key s value from a context item."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a ContextStack instance from a sequence of context-like items. This factory-style method is more general than the ContextStack class's constructor in that, unlike the constructor, the argument list can itself contain ContextStack instances. Here is an example illustrating various aspects of this method: >>> obj1 = {'animal': 'cat', 'vegetable': 'carrot', 'mineral': 'copper'} >>> obj2 = ContextStack({'vegetable': 'spinach', 'mineral': 'silver'}) >>> >>> context = ContextStack.create(obj1, None, obj2, mineral='gold') >>> >>> context.get('animal') 'cat' >>> context.get('vegetable') 'spinach' >>> context.get('mineral') 'gold' Arguments: *context: zero or more dictionaries, ContextStack instances, or objects with which to populate the initial context stack. None arguments will be skipped. Items in the *context list are added to the stack in order so that later items in the argument list take precedence over earlier items. This behavior is the same as the constructor's. **kwargs: additional key-value data to add to the context stack. As these arguments appear after all items in the *context list, in the case of key conflicts these values take precedence over all items in the *context list. This behavior is the same as the constructor's.", "response": "def create(*context, **kwargs):\n        \"\"\"\n        Build a ContextStack instance from a sequence of context-like items.\n\n        This factory-style method is more general than the ContextStack class's\n        constructor in that, unlike the constructor, the argument list\n        can itself contain ContextStack instances.\n\n        Here is an example illustrating various aspects of this method:\n\n        >>> obj1 = {'animal': 'cat', 'vegetable': 'carrot', 'mineral': 'copper'}\n        >>> obj2 = ContextStack({'vegetable': 'spinach', 'mineral': 'silver'})\n        >>>\n        >>> context = ContextStack.create(obj1, None, obj2, mineral='gold')\n        >>>\n        >>> context.get('animal')\n        'cat'\n        >>> context.get('vegetable')\n        'spinach'\n        >>> context.get('mineral')\n        'gold'\n\n        Arguments:\n\n          *context: zero or more dictionaries, ContextStack instances, or objects\n            with which to populate the initial context stack.  None\n            arguments will be skipped.  Items in the *context list are\n            added to the stack in order so that later items in the argument\n            list take precedence over earlier items.  This behavior is the\n            same as the constructor's.\n\n          **kwargs: additional key-value data to add to the context stack.\n            As these arguments appear after all items in the *context list,\n            in the case of key conflicts these values take precedence over\n            all items in the *context list.  This behavior is the same as\n            the constructor's.\n\n        \"\"\"\n        items = context\n\n        context = ContextStack()\n\n        for item in items:\n            if item is None:\n                continue\n            if isinstance(item, ContextStack):\n                context._stack.extend(item._stack)\n            else:\n                context.push(item)\n\n        if kwargs:\n            context.push(kwargs)\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, name):\n        if name == '.':\n            try:\n                return self.top()\n            except IndexError:\n                raise KeyNotFoundError(\".\", \"empty context stack\")\n\n        parts = name.split('.')\n\n        try:\n            result = self._get_simple(parts[0])\n        except KeyNotFoundError:\n            raise KeyNotFoundError(name, \"first part\")\n\n        for part in parts[1:]:\n            # The full context stack is not used to resolve the remaining parts.\n            # From the spec--\n            #\n            #   5) If any name parts were retained in step 1, each should be\n            #   resolved against a context stack containing only the result\n            #   from the former resolution.  If any part fails resolution, the\n            #   result should be considered falsey, and should interpolate as\n            #   the empty string.\n            #\n            # TODO: make sure we have a test case for the above point.\n            result = _get_value(result, part)\n            # TODO: consider using EAFP here instead.\n            #   http://docs.python.org/glossary.html#term-eafp\n            if result is _NOT_FOUND:\n                raise KeyNotFoundError(name, \"missing %s\" % repr(part))\n\n        return result", "response": "This method returns the value of the key in the current context stack that contains the specified dotted name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a simple key from the stack.", "response": "def _get_simple(self, name):\n        \"\"\"\n        Query the stack for a non-dotted name.\n\n        \"\"\"\n        for item in reversed(self._stack):\n            result = _get_value(item, name)\n            if result is not _NOT_FOUND:\n                return result\n\n        raise KeyNotFoundError(name, \"part missing\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _to_unicode_soft(self, s):\n        # We type-check to avoid \"TypeError: decoding Unicode is not supported\".\n        # We avoid the Python ternary operator for Python 2.4 support.\n        if isinstance(s, unicode):\n            return s\n        return self.unicode(s)", "response": "Convert a basestring to unicode preserving any unicode subclass."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unicode(self, b, encoding=None):\n        if encoding is None:\n            encoding = self.string_encoding\n\n        # TODO: Wrap UnicodeDecodeErrors with a message about setting\n        # the string_encoding and decode_errors attributes.\n        return unicode(b, encoding, self.decode_errors)", "response": "Convert a byte string to unicode using string_encoding and decode_errors attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_loader(self):\n        return Loader(file_encoding=self.file_encoding, extension=self.file_extension,\n                      to_unicode=self.unicode, search_dirs=self.search_dirs)", "response": "Create a Loader instance using current attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a function that loads a template by name.", "response": "def _make_load_template(self):\n        \"\"\"\n        Return a function that loads a template by name.\n\n        \"\"\"\n        loader = self._make_loader()\n\n        def load_template(template_name):\n            return loader.load_name(template_name)\n\n        return load_template"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a function that loads a partial by name.", "response": "def _make_load_partial(self):\n        \"\"\"\n        Return a function that loads a partial by name.\n\n        \"\"\"\n        if self.partials is None:\n            return self._make_load_template()\n\n        # Otherwise, create a function from the custom partial loader.\n        partials = self.partials\n\n        def load_partial(name):\n            # TODO: consider using EAFP here instead.\n            #     http://docs.python.org/glossary.html#term-eafp\n            #   This would mean requiring that the custom partial loader\n            #   raise a KeyError on name not found.\n            template = partials.get(name)\n            if template is None:\n                raise TemplateNotFoundError(\"Name %s not found in partials: %s\" %\n                                            (repr(name), type(partials)))\n\n            # RenderEngine requires that the return value be unicode.\n            return self._to_unicode_hard(template)\n\n        return load_partial"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_missing_tags_strict(self):\n        val = self.missing_tags\n\n        if val == MissingTags.strict:\n            return True\n        elif val == MissingTags.ignore:\n            return False\n\n        raise Exception(\"Unsupported 'missing_tags' value: %s\" % repr(val))", "response": "Return whether missing_tags is set to strict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the resolve_partial function to pass to RenderEngine. _make_load_partial", "response": "def _make_resolve_partial(self):\n        \"\"\"\n        Return the resolve_partial function to pass to RenderEngine.__init__().\n\n        \"\"\"\n        load_partial = self._make_load_partial()\n\n        if self._is_missing_tags_strict():\n            return load_partial\n        # Otherwise, ignore missing tags.\n\n        def resolve_partial(name):\n            try:\n                return load_partial(name)\n            except TemplateNotFoundError:\n                return u''\n\n        return resolve_partial"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_resolve_context(self):\n        if self._is_missing_tags_strict():\n            return context_get\n        # Otherwise, ignore missing tags.\n\n        def resolve_context(stack, name):\n            try:\n                return context_get(stack, name)\n            except KeyNotFoundError:\n                return u''\n\n        return resolve_context", "response": "Return the resolve_context function to pass to RenderEngine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a RenderEngine instance for rendering.", "response": "def _make_render_engine(self):\n        \"\"\"\n        Return a RenderEngine instance for rendering.\n\n        \"\"\"\n        resolve_context = self._make_resolve_context()\n        resolve_partial = self._make_resolve_partial()\n\n        engine = RenderEngine(literal=self._to_unicode_hard,\n                              escape=self._escape_to_unicode,\n                              resolve_context=resolve_context,\n                              resolve_partial=resolve_partial,\n                              to_str=self.str_coerce)\n        return engine"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _render_object(self, obj, *context, **kwargs):\n        loader = self._make_loader()\n\n        # TODO: consider an approach that does not require using an if\n        #   block here.  For example, perhaps this class's loader can be\n        #   a SpecLoader in all cases, and the SpecLoader instance can\n        #   check the object's type.  Or perhaps Loader and SpecLoader\n        #   can be refactored to implement the same interface.\n        if isinstance(obj, TemplateSpec):\n            loader = SpecLoader(loader)\n            template = loader.load(obj)\n        else:\n            template = loader.load_object(obj)\n\n        context = [obj] + list(context)\n\n        return self._render_string(template, *context, **kwargs)", "response": "Render the template associated with the given object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_name(self, template_name, *context, **kwargs):\n        loader = self._make_loader()\n        template = loader.load_name(template_name)\n        return self._render_string(template, *context, **kwargs)", "response": "Render the template with the given name using the given context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering the template at the given path using the given context.", "response": "def render_path(self, template_path, *context, **kwargs):\n        \"\"\"\n        Render the template at the given path using the given context.\n\n        Read the render() docstring for more information.\n\n        \"\"\"\n        loader = self._make_loader()\n        template = loader.read(template_path)\n\n        return self._render_string(template, *context, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders the given template string using the given context.", "response": "def _render_string(self, template, *context, **kwargs):\n        \"\"\"\n        Render the given template string using the given context.\n\n        \"\"\"\n        # RenderEngine.render() requires that the template string be unicode.\n        template = self._to_unicode_hard(template)\n\n        render_func = lambda engine, stack: engine.render(template, stack)\n\n        return self._render_final(render_func, *context, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a string that can be used to render the template.", "response": "def _render_final(self, render_func, *context, **kwargs):\n        \"\"\"\n        Arguments:\n\n          render_func: a function that accepts a RenderEngine and ContextStack\n            instance and returns a template rendering as a unicode string.\n\n        \"\"\"\n        stack = ContextStack.create(*context, **kwargs)\n        self._context = stack\n\n        engine = self._make_render_engine()\n\n        return render_func(engine, stack)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders the given template string view template or parsed template.", "response": "def render(self, template, *context, **kwargs):\n        \"\"\"\n        Render the given template string, view template, or parsed template.\n\n        Returns a unicode string.\n\n        Prior to rendering, this method will convert a template that is a\n        byte string (type str in Python 2) to unicode using the string_encoding\n        and decode_errors attributes.  See the constructor docstring for\n        more information.\n\n        Arguments:\n\n          template: a template string that is unicode or a byte string,\n            a ParsedTemplate instance, or another object instance.  In the\n            final case, the function first looks for the template associated\n            to the object by calling this class's get_associated_template()\n            method.  The rendering process also uses the passed object as\n            the first element of the context stack when rendering.\n\n          *context: zero or more dictionaries, ContextStack instances, or objects\n            with which to populate the initial context stack.  None\n            arguments are skipped.  Items in the *context list are added to\n            the context stack in order so that later items in the argument\n            list take precedence over earlier items.\n\n          **kwargs: additional key-value data to add to the context stack.\n            As these arguments appear after all items in the *context list,\n            in the case of key conflicts these values take precedence over\n            all items in the *context list.\n\n        \"\"\"\n        if is_string(template):\n            return self._render_string(template, *context, **kwargs)\n        if isinstance(template, ParsedTemplate):\n            render_func = lambda engine, stack: template.render(engine, stack)\n            return self._render_final(render_func, *context, **kwargs)\n        # Otherwise, we assume the template is an object.\n\n        return self._render_object(template, *context, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(path):\n    # This function implementation was chosen to be compatible across Python 2/3.\n    f = open(path, 'rb')\n    # We avoid use of the with keyword for Python 2.4 support.\n    try:\n        b = f.read()\n    finally:\n        f.close()\n\n    return b.decode(FILE_ENCODING)", "response": "Read and return the contents of a text file as a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a unicode string to a file.", "response": "def write(u, path):\n    \"\"\"\n    Write a unicode string to a file (as utf-8).\n\n    \"\"\"\n    print(\"writing to: %s\" % path)\n    # This function implementation was chosen to be compatible across Python 2/3.\n    f = open(path, \"wb\")\n    try:\n        b = u.encode(FILE_ENCODING)\n        f.write(b)\n    finally:\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_temp_path(path, new_ext=None):\n    root, ext = os.path.splitext(path)\n    if new_ext is None:\n        new_ext = ext\n    temp_path = root + TEMP_EXTENSION + new_ext\n    return temp_path", "response": "Creates a temporary file path based on the path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef strip_html_comments(text):\n    lines = text.splitlines(True)  # preserve line endings.\n\n    # Remove HTML comments (which we only allow to take a special form).\n    new_lines = filter(lambda line: not line.startswith(\"<!--\"), lines)\n\n    return \"\".join(new_lines)", "response": "Strip HTML comments from a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_md_to_rst(md_path, rst_temp_path):\n    # Pandoc uses the UTF-8 character encoding for both input and output.\n    command = \"pandoc --write=rst --output=%s %s\" % (rst_temp_path, md_path)\n    print(\"converting with pandoc: %s to %s\\n-->%s\" % (md_path, rst_temp_path,\n                                                       command))\n\n    if os.path.exists(rst_temp_path):\n        os.remove(rst_temp_path)\n\n    os.system(command)\n\n    if not os.path.exists(rst_temp_path):\n        s = (\"Error running: %s\\n\"\n             \"  Did you install pandoc per the %s docstring?\" % (command,\n                                                                 __file__))\n        sys.exit(s)\n\n    return read(rst_temp_path)", "response": "Convert a Markdown file to reStructuredText."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the long_description for setup. py from source files.", "response": "def make_long_description():\n    \"\"\"\n    Generate the reST long_description for setup() from source files.\n\n    Returns the generated long_description as a unicode string.\n\n    \"\"\"\n    readme_path = README_PATH\n\n    # Remove our HTML comments because PyPI does not allow it.\n    # See the setup.py docstring for more info on this.\n    readme_md = strip_html_comments(read(readme_path))\n    history_md = strip_html_comments(read(HISTORY_PATH))\n    license_md = \"\"\"\\\nLicense\n=======\n\n\"\"\" + read(LICENSE_PATH)\n\n    sections = [readme_md, history_md, license_md]\n    md_description = '\\n\\n'.join(sections)\n\n    # Write the combined Markdown file to a temp path.\n    md_ext = os.path.splitext(readme_path)[1]\n    md_description_path = make_temp_path(RST_DESCRIPTION_PATH, new_ext=md_ext)\n    write(md_description, md_description_path)\n\n    rst_temp_path = make_temp_path(RST_DESCRIPTION_PATH)\n    long_description = convert_md_to_rst(md_path=md_description_path,\n                                         rst_temp_path=rst_temp_path)\n\n    return \"\\n\".join([RST_LONG_DESCRIPTION_INTRO, long_description])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publish():\n    long_description = make_long_description()\n\n    if long_description != read(RST_DESCRIPTION_PATH):\n        print(\"\"\"\\\nDescription file not up-to-date: %s\nRun the following command and commit the changes--\n\n    python setup.py %s\n\"\"\" % (RST_DESCRIPTION_PATH, PREP_COMMAND))\n        sys.exit()\n\n    print(\"Description up-to-date: %s\" % RST_DESCRIPTION_PATH)\n\n    answer = raw_input(\"Are you sure you want to publish to PyPI (yes/no)?\")\n\n    if answer != \"yes\":\n        exit(\"Aborted: nothing published\")\n\n    os.system('python setup.py sdist upload')", "response": "Publish this package to PyPI"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_object_directory(self, obj):\n        if not hasattr(obj, '__module__'):\n            return None\n\n        module = sys.modules[obj.__module__]\n\n        if not hasattr(module, '__file__'):\n            # TODO: add a unit test for this case.\n            return None\n\n        path = module.__file__\n\n        return os.path.dirname(path)", "response": "Returns the directory containing an object s defining class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_template_name(self, obj):\n        template_name = obj.__class__.__name__\n\n        def repl(match):\n            return '_' + match.group(0).lower()\n\n        return re.sub('[A-Z]', repl, template_name)[1:]", "response": "This method returns the canonical template name for an object instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating and return the file name for the given template name and template extension.", "response": "def make_file_name(self, template_name, template_extension=None):\n        \"\"\"\n        Generate and return the file name for the given template name.\n\n        Arguments:\n\n          template_extension: defaults to the instance's extension.\n\n        \"\"\"\n        file_name = template_name\n\n        if template_extension is None:\n            template_extension = self.template_extension\n\n        if template_extension is not False:\n            file_name += os.path.extsep + template_extension\n\n        return file_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch for the given file and return the path.", "response": "def _find_path(self, search_dirs, file_name):\n        \"\"\"\n        Search for the given file, and return the path.\n\n        Returns None if the file is not found.\n\n        \"\"\"\n        for dir_path in search_dirs:\n            file_path = os.path.join(dir_path, file_name)\n            if os.path.exists(file_path):\n                return file_path\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_path_required(self, search_dirs, file_name):\n        path = self._find_path(search_dirs, file_name)\n\n        if path is None:\n            raise TemplateNotFoundError('File %s not found in dirs: %s' %\n                                        (repr(file_name), repr(search_dirs)))\n\n        return path", "response": "Find the path to a template with the given file name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the path to a template with the given name.", "response": "def find_name(self, template_name, search_dirs):\n        \"\"\"\n        Return the path to a template with the given name.\n\n        Arguments:\n\n          template_name: the name of the template.\n\n          search_dirs: the list of directories in which to search.\n\n        \"\"\"\n        file_name = self.make_file_name(template_name)\n\n        return self._find_path_required(search_dirs, file_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the path to a template associated with the given object.", "response": "def find_object(self, obj, search_dirs, file_name=None):\n        \"\"\"\n        Return the path to a template associated with the given object.\n\n        \"\"\"\n        if file_name is None:\n            # TODO: should we define a make_file_name() method?\n            template_name = self.make_template_name(obj)\n            file_name = self.make_file_name(template_name)\n\n        dir_path = self.get_object_directory(obj)\n\n        if dir_path is not None:\n            search_dirs = [dir_path] + search_dirs\n\n        path = self._find_path_required(search_dirs, file_name)\n\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string to unicode using the given encoding and return it.", "response": "def unicode(self, s, encoding=None):\n        \"\"\"\n        Convert a string to unicode using the given encoding, and return it.\n\n        This function uses the underlying to_unicode attribute.\n\n        Arguments:\n\n          s: a basestring instance to convert to unicode.  Unlike Python's\n            built-in unicode() function, it is okay to pass unicode strings\n            to this function.  (Passing a unicode string to Python's unicode()\n            with the encoding argument throws the error, \"TypeError: decoding\n            Unicode is not supported.\")\n\n          encoding: the encoding to pass to the to_unicode attribute.\n            Defaults to None.\n\n        \"\"\"\n        if isinstance(s, unicode):\n            return unicode(s)\n\n        return self.to_unicode(s, encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(self, path, encoding=None):\n        b = common.read(path)\n\n        if encoding is None:\n            encoding = self.file_encoding\n\n        return self.unicode(b, encoding)", "response": "Read the template at the given path and return it as a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_file(self, file_name):\n        locator = self._make_locator()\n\n        path = locator.find_file(file_name, self.search_dirs)\n\n        return self.read(path)", "response": "Find and return the template with the given file name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_name(self, name):\n        locator = self._make_locator()\n\n        path = locator.find_name(name, self.search_dirs)\n\n        return self.read(path)", "response": "Find and return the template with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_object(self, obj):\n        locator = self._make_locator()\n\n        path = locator.find_object(obj, self.search_dirs)\n\n        return self.read(path)", "response": "Find and return the template associated to the given object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string of type unicode.", "response": "def render(self, engine, context):\n        \"\"\"\n        Returns: a string of type unicode.\n\n        \"\"\"\n        # We avoid use of the ternary operator for Python 2.4 support.\n        def get_unicode(node):\n            if type(node) is unicode:\n                return node\n            return node.render(engine, context)\n        parts = map(get_unicode, self._parse_tree)\n        s = ''.join(parts)\n\n        return unicode(s)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(template, delimiters=None):\n    if type(template) is not unicode:\n        raise Exception(\"Template is not unicode: %s\" % type(template))\n    parser = _Parser(delimiters)\n    return parser.parse(template)", "response": "Parse a unicode template string and return a ParsedTemplate instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncompiling the template re object for the current tag.", "response": "def _compile_template_re(delimiters):\n    \"\"\"\n    Return a regular expression object (re.RegexObject) instance.\n\n    \"\"\"\n    # The possible tag type characters following the opening tag,\n    # excluding \"=\" and \"{\".\n    tag_types = \"!>&/#^\"\n\n    # TODO: are we following this in the spec?\n    #\n    #   The tag's content MUST be a non-whitespace character sequence\n    #   NOT containing the current closing delimiter.\n    #\n    tag = r\"\"\"\n        (?P<whitespace>[\\ \\t]*)\n        %(otag)s \\s*\n        (?:\n          (?P<change>=) \\s* (?P<delims>.+?)   \\s* = |\n          (?P<raw>{)    \\s* (?P<raw_name>.+?) \\s* } |\n          (?P<tag>[%(tag_types)s]?)  \\s* (?P<tag_key>[\\s\\S]+?)\n        )\n        \\s* %(ctag)s\n    \"\"\" % {'tag_types': tag_types, 'otag': re.escape(delimiters[0]), 'ctag': re.escape(delimiters[1])}\n\n    return re.compile(tag, re.VERBOSE)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(self, template):\n        self._compile_delimiters()\n\n        start_index = 0\n        content_end_index, parsed_section, section_key = None, None, None\n        parsed_template = ParsedTemplate()\n\n        states = []\n\n        while True:\n            match = self._template_re.search(template, start_index)\n\n            if match is None:\n                break\n\n            match_index = match.start()\n            end_index = match.end()\n\n            matches = match.groupdict()\n\n            # Normalize the matches dictionary.\n            if matches['change'] is not None:\n                matches.update(tag='=', tag_key=matches['delims'])\n            elif matches['raw'] is not None:\n                matches.update(tag='&', tag_key=matches['raw_name'])\n\n            tag_type = matches['tag']\n            tag_key = matches['tag_key']\n            leading_whitespace = matches['whitespace']\n\n            # Standalone (non-interpolation) tags consume the entire line,\n            # both leading whitespace and trailing newline.\n            did_tag_begin_line = match_index == 0 or template[match_index - 1] in END_OF_LINE_CHARACTERS\n            did_tag_end_line = end_index == len(template) or template[end_index] in END_OF_LINE_CHARACTERS\n            is_tag_interpolating = tag_type in ['', '&']\n\n            if did_tag_begin_line and did_tag_end_line and not is_tag_interpolating:\n                if end_index < len(template):\n                    end_index += template[end_index] == '\\r' and 1 or 0\n                if end_index < len(template):\n                    end_index += template[end_index] == '\\n' and 1 or 0\n            elif leading_whitespace:\n                match_index += len(leading_whitespace)\n                leading_whitespace = ''\n\n            # Avoid adding spurious empty strings to the parse tree.\n            if start_index != match_index:\n                parsed_template.add(template[start_index:match_index])\n\n            start_index = end_index\n\n            if tag_type in ('#', '^'):\n                # Cache current state.\n                state = (tag_type, end_index, section_key, parsed_template)\n                states.append(state)\n\n                # Initialize new state\n                section_key, parsed_template = tag_key, ParsedTemplate()\n                continue\n\n            if tag_type == '/':\n                if tag_key != section_key:\n                    raise ParsingError(\"Section end tag mismatch: %s != %s\" % (tag_key, section_key))\n\n                # Restore previous state with newly found section data.\n                parsed_section = parsed_template\n\n                (tag_type, section_start_index, section_key, parsed_template) = states.pop()\n                node = self._make_section_node(template, tag_type, tag_key, parsed_section,\n                                               section_start_index, match_index)\n\n            else:\n                node = self._make_interpolation_node(tag_type, tag_key, leading_whitespace)\n\n            parsed_template.add(node)\n\n        # Avoid adding spurious empty strings to the parse tree.\n        if start_index != len(template):\n            parsed_template.add(template[start_index:])\n\n        return parsed_template", "response": "Parse a template string starting at some index."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates and return a node for an interpolation tag.", "response": "def _make_interpolation_node(self, tag_type, tag_key, leading_whitespace):\n        \"\"\"\n        Create and return a non-section node for the parse tree.\n\n        \"\"\"\n        # TODO: switch to using a dictionary instead of a bunch of ifs and elifs.\n        if tag_type == '!':\n            return _CommentNode()\n\n        if tag_type == '=':\n            delimiters = tag_key.split()\n            self._change_delimiters(delimiters)\n            return _ChangeNode(delimiters)\n\n        if tag_type == '':\n            return _EscapeNode(tag_key)\n\n        if tag_type == '&':\n            return _LiteralNode(tag_key)\n\n        if tag_type == '>':\n            return _PartialNode(tag_key, leading_whitespace)\n\n        raise Exception(\"Invalid symbol for interpolation tag: %s\" % repr(tag_type))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating and return a section node for the parse tree.", "response": "def _make_section_node(self, template, tag_type, tag_key, parsed_section,\n                           section_start_index, section_end_index):\n        \"\"\"\n        Create and return a section node for the parse tree.\n\n        \"\"\"\n        if tag_type == '#':\n            return _SectionNode(tag_key, parsed_section, self._delimiters,\n                               template, section_start_index, section_end_index)\n\n        if tag_type == '^':\n            return _InvertedNode(tag_key, parsed_section)\n\n        raise Exception(\"Invalid symbol for section tag: %s\" % repr(tag_type))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_relative(self, spec):\n        if spec.template_rel_path is not None:\n            return os.path.split(spec.template_rel_path)\n        # Otherwise, determine the file name separately.\n\n        locator = self.loader._make_locator()\n\n        # We do not use the ternary operator for Python 2.4 support.\n        if spec.template_name is not None:\n            template_name = spec.template_name\n        else:\n            template_name = locator.make_template_name(spec)\n\n        file_name = locator.make_file_name(template_name, spec.template_extension)\n\n        return (spec.template_rel_directory, file_name)", "response": "Find the path to the template as a relative ( dir file_name pair."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find(self, spec):\n        if spec.template_path is not None:\n            return spec.template_path\n\n        dir_path, file_name = self._find_relative(spec)\n\n        locator = self.loader._make_locator()\n\n        if dir_path is None:\n            # Then we need to search for the path.\n            path = locator.find_object(spec, self.loader.search_dirs, file_name=file_name)\n        else:\n            obj_dir = locator.get_object_directory(spec)\n            path = os.path.join(obj_dir, dir_path, file_name)\n\n        return path", "response": "Find and return the path to the template associated to the instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds and return the template associated to a TemplateSpec instance.", "response": "def load(self, spec):\n        \"\"\"\n        Find and return the template associated to a TemplateSpec instance.\n\n        Returns the template as a unicode string.\n\n        Arguments:\n\n          spec: a TemplateSpec instance.\n\n        \"\"\"\n        if spec.template is not None:\n            return self.loader.unicode(spec.template, spec.template_encoding)\n\n        path = self._find(spec)\n\n        return self.loader.read(path, spec.template_encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch_string(self, context, name):\n        val = self.resolve_context(context, name)\n\n        if callable(val):\n            # Return because _render_value() is already a string.\n            return self._render_value(val(), context)\n\n        if not is_string(val):\n            return self.to_str(val)\n\n        return val", "response": "Fetch a string value from the given context as a basestring instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches the value of a section as a list.", "response": "def fetch_section_data(self, context, name):\n        \"\"\"\n        Fetch the value of a section as a list.\n\n        \"\"\"\n        data = self.resolve_context(context, name)\n\n        # From the spec:\n        #\n        #   If the data is not of a list type, it is coerced into a list\n        #   as follows: if the data is truthy (e.g. `!!data == true`),\n        #   use a single-element list containing the data, otherwise use\n        #   an empty list.\n        #\n        if not data:\n            data = []\n        else:\n            # The least brittle way to determine whether something\n            # supports iteration is by trying to call iter() on it:\n            #\n            #   http://docs.python.org/library/functions.html#iter\n            #\n            # It is not sufficient, for example, to check whether the item\n            # implements __iter__ () (the iteration protocol).  There is\n            # also __getitem__() (the sequence protocol).  In Python 2,\n            # strings do not implement __iter__(), but in Python 3 they do.\n            try:\n                iter(data)\n            except TypeError:\n                # Then the value does not support iteration.\n                data = [data]\n            else:\n                if is_string(data) or isinstance(data, dict):\n                    # Do not treat strings and dicts (which are iterable) as lists.\n                    data = [data]\n                # Otherwise, treat the value as a list.\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering an arbitrary value.", "response": "def _render_value(self, val, context, delimiters=None):\n        \"\"\"\n        Render an arbitrary value.\n\n        \"\"\"\n        if not is_string(val):\n            # In case the template is an integer, for example.\n            val = self.to_str(val)\n        if type(val) is not unicode:\n            val = self.literal(val)\n        return self.render(val, context, delimiters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render(self, template, context_stack, delimiters=None):\n        parsed_template = parse(template, delimiters)\n\n        return parsed_template.render(self, context_stack)", "response": "Render a unicode template string and return as unicode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate script in page frame.", "response": "def evaluate(self, script):\n        \"\"\"\n        Evaluate script in page frame.\n\n        :param script: The script to evaluate.\n        \"\"\"\n        if WEBENGINE:\n            return self.dom.runJavaScript(\"{}\".format(script))\n        else:\n            return self.dom.evaluateJavaScript(\"{}\".format(script))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nclicks the targeted element.", "response": "def click(self, selector, btn=0):\n        \"\"\"\n        Click the targeted element.\n\n        :param selector: A CSS3 selector to targeted element.\n        :param btn: The number of mouse button.\n            0 - left button,\n            1 - middle button,\n            2 - right button\n        \"\"\"\n        return self.evaluate(\"\"\"\n            (function () {{\n                var element = document.querySelector({0});\n                var evt = document.createEvent(\"MouseEvents\");\n                evt.initMouseEvent(\"click\", true, true, window, 1, 1, 1, 1, 1,\n                    false, false, false, false, {1}, element);\n                return element.dispatchEvent(evt);\n            }})();\n        \"\"\".format(repr(selector), repr(btn)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value of the input matched by given selector.", "response": "def set_input_value(self, selector, value):\n        \"\"\"Set the value of the input matched by given selector.\"\"\"\n        script = 'document.querySelector(\"%s\").setAttribute(\"value\", \"%s\")'\n        script = script % (selector, value)\n        self.evaluate(script)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the class of element matched by the given selector.", "response": "def set_class_value(self, selector, classname):\n        \"\"\"Set the class of element matched by the given selector.\"\"\"\n        return self.evaluate(\"\"\"\n            (function () {{\n            var element = document.querySelector({0});\n            element.className = {1};\n            }})();\"\"\".format(repr(selector), repr(classname)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow kernel initialization errors.", "response": "def show_kernel_error(self, error):\n        \"\"\"Show kernel initialization errors.\"\"\"\n        # Remove unneeded blank lines at the beginning\n        eol = sourcecode.get_eol_chars(error)\n        if eol:\n            error = error.replace(eol, '<br>')\n        # Don't break lines in hyphens\n        # From http://stackoverflow.com/q/7691569/438386\n        error = error.replace('-', '&#8209')\n\n        message = _(\"An error occurred while starting the kernel\")\n        kernel_error_template = Template(KERNEL_ERROR)\n        page = kernel_error_template.substitute(css_path=CSS_PATH,\n                                                message=message,\n                                                error=error)\n        self.setHtml(page)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow a loading animation while the kernel is starting.", "response": "def show_loading_page(self):\n        \"\"\"Show a loading animation while the kernel is starting.\"\"\"\n        loading_template = Template(LOADING)\n        loading_img = get_image_path('loading_sprites.png')\n        if os.name == 'nt':\n            loading_img = loading_img.replace('\\\\', '/')\n        message = _(\"Connecting to kernel...\")\n        page = loading_template.substitute(css_path=CSS_PATH,\n                                           loading_img=loading_img,\n                                           message=message)\n        self.setHtml(page)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering attributes that can be computed with the server info.", "response": "def register(self, server_info):\n        \"\"\"Register attributes that can be computed with the server info.\"\"\"\n        # Path relative to the server directory\n        self.path = os.path.relpath(self.filename,\n                                    start=server_info['notebook_dir'])\n\n        # Replace backslashes on Windows\n        if os.name == 'nt':\n            self.path = self.path.replace('\\\\', '/')\n\n        # Server url to send requests to\n        self.server_url = server_info['url']\n\n        # Server token\n        self.token = server_info['token']\n\n        url = url_path_join(self.server_url, 'notebooks',\n                            url_escape(self.path))\n\n        # Set file url to load this notebook\n        self.file_url = self.add_token(url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef go_to(self, url_or_text):\n        if is_text_string(url_or_text):\n            url = QUrl(url_or_text)\n        else:\n            url = url_or_text\n        self.notebookwidget.load(url)", "response": "Go to page utl."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a short name for the notebook.", "response": "def get_short_name(self):\n        \"\"\"Get a short name for the notebook.\"\"\"\n        sname = osp.splitext(osp.basename(self.filename))[0]\n        if len(sname) > 20:\n            fm = QFontMetrics(QFont())\n            sname = fm.elidedText(sname, Qt.ElideRight, 110)\n        return sname"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the kernel id of the client.", "response": "def get_kernel_id(self):\n        \"\"\"\n        Get the kernel id of the client.\n\n        Return a str with the kernel id or None.\n        \"\"\"\n        sessions_url = self.get_session_url()\n        sessions_req = requests.get(sessions_url).content.decode()\n        sessions = json.loads(sessions_req)\n\n        if os.name == 'nt':\n            path = self.path.replace('\\\\', '/')\n        else:\n            path = self.path\n\n        for session in sessions:\n            notebook_path = session.get('notebook', {}).get('path')\n            if notebook_path is not None and notebook_path == path:\n                kernel_id = session['kernel']['id']\n                return kernel_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shutdown_kernel(self):\n        kernel_id = self.get_kernel_id()\n\n        if kernel_id:\n            delete_url = self.add_token(url_path_join(self.server_url,\n                                                      'api/kernels/',\n                                                      kernel_id))\n            delete_req = requests.delete(delete_url)\n            if delete_req.status_code != 204:\n                QMessageBox.warning(\n                    self,\n                    _(\"Server error\"),\n                    _(\"The Jupyter Notebook server \"\n                      \"failed to shutdown the kernel \"\n                      \"associated with this notebook. \"\n                      \"If you want to shut it down, \"\n                      \"you'll have to close Spyder.\"))", "response": "Shutdown the kernel of the client."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef closing_plugin(self, cancelable=False):\r\n        for cl in self.clients:\r\n            cl.close()\r\n        self.set_option('recent_notebooks', self.recent_notebooks)\r\n        return True", "response": "Perform actions before parent main window is closed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_plugin_actions(self):\r\n        create_nb_action = create_action(self,\r\n                                         _(\"New notebook\"),\r\n                                         icon=ima.icon('filenew'),\r\n                                         triggered=self.create_new_client)\r\n        self.save_as_action = create_action(self,\r\n                                            _(\"Save as...\"),\r\n                                            icon=ima.icon('filesaveas'),\r\n                                            triggered=self.save_as)\r\n        open_action = create_action(self,\r\n                                    _(\"Open...\"),\r\n                                    icon=ima.icon('fileopen'),\r\n                                    triggered=self.open_notebook)\r\n        self.open_console_action = create_action(self,\r\n                                                 _(\"Open console\"),\r\n                                                 icon=ima.icon(\r\n                                                         'ipython_console'),\r\n                                                 triggered=self.open_console)\r\n        self.clear_recent_notebooks_action =\\\r\n            create_action(self, _(\"Clear this list\"),\r\n                          triggered=self.clear_recent_notebooks)\r\n        # Plugin actions\r\n        self.menu_actions = [create_nb_action, open_action,\r\n                             self.recent_notebook_menu, MENU_SEPARATOR,\r\n                             self.save_as_action, MENU_SEPARATOR,\r\n                             self.open_console_action]\r\n        self.setup_menu_actions()\r\n\r\n        return self.menu_actions", "response": "Return a list of actions related to plugin."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_plugin(self):\r\n        self.focus_changed.connect(self.main.plugin_focus_changed)\r\n        self.main.add_dockwidget(self)\r\n        self.ipyconsole = self.main.ipyconsole\r\n        self.create_new_client(give_focus=False)\r\n        icon_path = os.path.join(PACKAGE_PATH, 'images', 'icon.svg')\r\n        self.main.add_to_fileswitcher(self, self.tabwidget, self.clients,\r\n                                      QIcon(icon_path))\r\n        self.recent_notebook_menu.aboutToShow.connect(self.setup_menu_actions)", "response": "Register plugin in Spyder s main window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_compatibility(self):\r\n        message = ''\r\n        value = True\r\n        if PYQT4 or PYSIDE:\r\n            message = _(\"You are working with Qt4 and in order to use this \"\r\n                        \"plugin you need to have Qt5.<br><br>\"\r\n                        \"Please update your Qt and/or PyQt packages to \"\r\n                        \"meet this requirement.\")\r\n            value = False\r\n        return value, message", "response": "Check compatibility for PyQt and sWebEngine."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_notebook_actions(self):\r\n        if self.recent_notebooks:\r\n            self.clear_recent_notebooks_action.setEnabled(True)\r\n        else:\r\n            self.clear_recent_notebooks_action.setEnabled(False)\r\n        client = self.get_current_client()\r\n        if client:\r\n            if client.get_filename() != WELCOME:\r\n                self.save_as_action.setEnabled(True)\r\n                self.open_console_action.setEnabled(True)\r\n                self.options_menu.clear()\r\n                add_actions(self.options_menu, self.menu_actions)\r\n                return\r\n        self.save_as_action.setEnabled(False)\r\n        self.open_console_action.setEnabled(False)\r\n        self.options_menu.clear()\r\n        add_actions(self.options_menu, self.menu_actions)", "response": "Update actions of the recent notebooks menu."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an entry to the recent notebooks list.", "response": "def add_to_recent(self, notebook):\r\n        \"\"\"\r\n        Add an entry to recent notebooks.\r\n\r\n        We only maintain the list of the 20 most recent notebooks.\r\n        \"\"\"\r\n        if notebook not in self.recent_notebooks:\r\n            self.recent_notebooks.insert(0, notebook)\r\n            self.recent_notebooks = self.recent_notebooks[:20]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn current notebook with focus if any.", "response": "def get_focus_client(self):\r\n        \"\"\"Return current notebook with focus, if any.\"\"\"\r\n        widget = QApplication.focusWidget()\r\n        for client in self.get_clients():\r\n            if widget is client or widget is client.notebookwidget:\r\n                return client"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the currently selected notebook.", "response": "def get_current_client(self):\r\n        \"\"\"Return the currently selected notebook.\"\"\"\r\n        try:\r\n            client = self.tabwidget.currentWidget()\r\n        except AttributeError:\r\n            client = None\r\n        if client is not None:\r\n            return client"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_current_client_name(self, short=False):\r\n        client = self.get_current_client()\r\n        if client:\r\n            if short:\r\n                return client.get_short_name()\r\n            else:\r\n                return client.get_filename()", "response": "Get the current client name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_new_client(self, filename=None, give_focus=True):\r\n        # Generate the notebook name (in case of a new one)\r\n        if not filename:\r\n            if not osp.isdir(NOTEBOOK_TMPDIR):\r\n                os.makedirs(NOTEBOOK_TMPDIR)\r\n            nb_name = 'untitled' + str(self.untitled_num) + '.ipynb'\r\n            filename = osp.join(NOTEBOOK_TMPDIR, nb_name)\r\n            nb_contents = nbformat.v4.new_notebook()\r\n            nbformat.write(nb_contents, filename)\r\n            self.untitled_num += 1\r\n\r\n        # Save spyder_pythonpath before creating a client\r\n        # because it's needed by our kernel spec.\r\n        if not self.testing:\r\n            CONF.set('main', 'spyder_pythonpath',\r\n                     self.main.get_spyder_pythonpath())\r\n\r\n        # Open the notebook with nbopen and get the url we need to render\r\n        try:\r\n            server_info = nbopen(filename)\r\n        except (subprocess.CalledProcessError, NBServerError):\r\n            QMessageBox.critical(\r\n                self,\r\n                _(\"Server error\"),\r\n                _(\"The Jupyter Notebook server failed to start or it is \"\r\n                  \"taking too much time to do it. Please start it in a \"\r\n                  \"system terminal with the command 'jupyter notebook' to \"\r\n                  \"check for errors.\"))\r\n            # Create a welcome widget\r\n            # See issue 93\r\n            self.untitled_num -= 1\r\n            self.create_welcome_client()\r\n            return\r\n\r\n        welcome_client = self.create_welcome_client()\r\n        client = NotebookClient(self, filename)\r\n        self.add_tab(client)\r\n        if NOTEBOOK_TMPDIR not in filename:\r\n            self.add_to_recent(filename)\r\n            self.setup_menu_actions()\r\n        client.register(server_info)\r\n        client.load_notebook()\r\n        if welcome_client and not self.testing:\r\n            self.tabwidget.setCurrentIndex(0)", "response": "Create a new notebook or load a pre - existing one."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses a client tab from index or widget.", "response": "def close_client(self, index=None, client=None, save=False):\r\n        \"\"\"Close client tab from index or widget (or close current tab).\"\"\"\r\n        if not self.tabwidget.count():\r\n            return\r\n        if client is not None:\r\n            index = self.tabwidget.indexOf(client)\r\n        if index is None and client is None:\r\n            index = self.tabwidget.currentIndex()\r\n        if index is not None:\r\n            client = self.tabwidget.widget(index)\r\n\r\n        is_welcome = client.get_filename() == WELCOME\r\n        if not save and not is_welcome:\r\n            client.save()\r\n            wait_save = QEventLoop()\r\n            QTimer.singleShot(1000, wait_save.quit)\r\n            wait_save.exec_()\r\n            path = client.get_filename()\r\n            fname = osp.basename(path)\r\n            nb_contents = nbformat.read(path, as_version=4)\r\n\r\n            if ('untitled' in fname and len(nb_contents['cells']) > 0 and\r\n                    len(nb_contents['cells'][0]['source']) > 0):\r\n                buttons = QMessageBox.Yes | QMessageBox.No\r\n                answer = QMessageBox.question(self, self.get_plugin_title(),\r\n                                              _(\"<b>{0}</b> has been modified.\"\r\n                                                \"<br>Do you want to \"\r\n                                                \"save changes?\".format(fname)),\r\n                                              buttons)\r\n                if answer == QMessageBox.Yes:\r\n                    self.save_as(close=True)\r\n        if not is_welcome:\r\n            client.shutdown_kernel()\r\n        client.close()\r\n\r\n        # Delete notebook file if it is in temporary directory\r\n        filename = client.get_filename()\r\n        if filename.startswith(get_temp_dir()):\r\n            try:\r\n                os.remove(filename)\r\n            except EnvironmentError:\r\n                pass\r\n\r\n        # Note: notebook index may have changed after closing related widgets\r\n        self.tabwidget.removeTab(self.tabwidget.indexOf(client))\r\n        self.clients.remove(client)\r\n\r\n        self.create_welcome_client()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a welcome client with some instructions.", "response": "def create_welcome_client(self):\r\n        \"\"\"Create a welcome client with some instructions.\"\"\"\r\n        if self.tabwidget.count() == 0:\r\n            welcome = open(WELCOME).read()\r\n            client = NotebookClient(self, WELCOME, ini_message=welcome)\r\n            self.add_tab(client)\r\n            return client"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen a notebook from file.", "response": "def open_notebook(self, filenames=None):\r\n        \"\"\"Open a notebook from file.\"\"\"\r\n        if not filenames:\r\n            filenames, _selfilter = getopenfilenames(self, _(\"Open notebook\"),\r\n                                                     '', FILES_FILTER)\r\n        if filenames:\r\n            for filename in filenames:\r\n                self.create_new_client(filename=filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open_console(self, client=None):\r\n        if not client:\r\n            client = self.get_current_client()\r\n        if self.ipyconsole is not None:\r\n            kernel_id = client.get_kernel_id()\r\n            if not kernel_id:\r\n                QMessageBox.critical(\r\n                    self, _('Error opening console'),\r\n                    _('There is no kernel associated to this notebook.'))\r\n                return\r\n            self.ipyconsole._create_client_for_kernel(kernel_id, None, None,\r\n                                                      None)\r\n            ipyclient = self.ipyconsole.get_current_client()\r\n            ipyclient.allow_rename = False\r\n            self.ipyconsole.rename_client_tab(ipyclient,\r\n                                              client.get_short_name())", "response": "Open an IPython console for the given client or the current one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving a client from one index to another.", "response": "def move_tab(self, index_from, index_to):\r\n        \"\"\"Move tab.\"\"\"\r\n        client = self.clients.pop(index_from)\r\n        self.clients.insert(index_to, client)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_stack_index(self, index, instance):\r\n        if instance == self:\r\n            self.tabwidget.setCurrentIndex(index)", "response": "Set the index of the current notebook."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_version(module='spyder_notebook'):\n    with open(os.path.join(HERE, module, '_version.py'), 'r') as f:\n        data = f.read()\n    lines = data.split('\\n')\n    for line in lines:\n        if line.startswith('VERSION_INFO'):\n            version_tuple = ast.literal_eval(line.split('=')[-1].strip())\n            version = '.'.join(map(str, version_tuple))\n            break\n    return version", "response": "Get version from _version. py."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_best_server(filename):\n    servers = [si for si in notebookapp.list_running_servers()\n               if filename.startswith(si['notebook_dir'])]\n    try:\n        return max(servers, key=lambda si: len(si['notebook_dir']))\n    except ValueError:\n        return None", "response": "Find the best server to open a notebook with."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen a notebook using the best available server.", "response": "def nbopen(filename):\n    \"\"\"\n    Open a notebook using the best available server.\n\n    Returns information about the selected server.\n    \"\"\"\n    filename = osp.abspath(filename)\n    home_dir = get_home_dir()\n    server_info = find_best_server(filename)\n\n    if server_info is not None:\n        print(\"Using existing server at\", server_info['notebook_dir'])\n        return server_info\n    else:\n        if filename.startswith(home_dir):\n            nbdir = home_dir\n        else:\n            nbdir = osp.dirname(filename)\n\n        print(\"Starting new server\")\n        command = [sys.executable, '-m', 'notebook', '--no-browser',\n                   '--notebook-dir={}'.format(nbdir),\n                   '--NotebookApp.password=',\n                   \"--KernelSpecManager.kernel_spec_class='{}'\".format(\n                           KERNELSPEC)]\n\n        if os.name == 'nt':\n            creation_flag = 0x08000000  # CREATE_NO_WINDOW\n        else:\n            creation_flag = 0  # Default value\n\n        if DEV:\n            env = os.environ.copy()\n            env[\"PYTHONPATH\"] = osp.dirname(get_module_path('spyder'))\n            proc = subprocess.Popen(command, creationflags=creation_flag,\n                                    env=env)\n        else:\n            proc = subprocess.Popen(command, creationflags=creation_flag)\n\n        # Kill the server at exit. We need to use psutil for this because\n        # Popen.terminate doesn't work when creationflags or shell=True\n        # are used.\n        def kill_server_and_childs(pid):\n            ps_proc = psutil.Process(pid)\n            for child in ps_proc.children(recursive=True):\n                child.kill()\n            ps_proc.kill()\n\n        atexit.register(kill_server_and_childs, proc.pid)\n\n        # Wait ~25 secs for the server to be up\n        for _x in range(100):\n            server_info = find_best_server(filename)\n            if server_info is not None:\n                break\n            else:\n                time.sleep(0.25)\n\n        if server_info is None:\n            raise NBServerError()\n\n        return server_info"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform an aggregation and make sure that result will be everytime CommandCursor. Will take care for pymongo version differencies", "response": "def aggregate(self, pipeline, **kwargs):\n        \"\"\"Perform an aggregation and make sure that result will be everytime\n        CommandCursor. Will take care for pymongo version differencies\n        :param pipeline: {list} of aggregation pipeline stages\n        :return: {pymongo.command_cursor.CommandCursor}\n        \"\"\"\n        result = self.collection.aggregate(pipeline, **kwargs)\n        if pymongo.version_tuple < (3, 0, 0):\n            result = result['result']\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wrapAppEndpoints(app):\n    for endpoint, func in app.view_functions.items():\n        app.view_functions[endpoint] = wrapHttpEndpoint(func)", "response": "Wraps all endpoints defined in the given flask application to measure how long time each endpoint takes while being executed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters the internal routes for the internal views.", "response": "def registerInternalRouters(app):\n    \"\"\"\n    These are the endpoints which are used to display measurements in the\n    flask-profiler dashboard.\n\n    Note: these should be defined after wrapping user defined endpoints\n    via wrapAppEndpoints()\n    :param app: Flask application instance\n    :return:\n    \"\"\"\n    urlPath = CONF.get(\"endpointRoot\", \"flask-profiler\")\n\n    fp = Blueprint(\n        'flask-profiler', __name__,\n        url_prefix=\"/\" + urlPath,\n        static_folder=\"static/dist/\", static_url_path='/static/dist')\n\n    @fp.route(\"/\".format(urlPath))\n    @auth.login_required\n    def index():\n        return fp.send_static_file(\"index.html\")\n\n    @fp.route(\"/api/measurements/\".format(urlPath))\n    @auth.login_required\n    def filterMeasurements():\n        args = dict(request.args.items())\n        measurements = collection.filter(args)\n        return jsonify({\"measurements\": list(measurements)})\n\n    @fp.route(\"/api/measurements/grouped\".format(urlPath))\n    @auth.login_required\n    def getMeasurementsSummary():\n        args = dict(request.args.items())\n        measurements = collection.getSummary(args)\n        return jsonify({\"measurements\": list(measurements)})\n\n    @fp.route(\"/api/measurements/<measurementId>\".format(urlPath))\n    @auth.login_required\n    def getContext(measurementId):\n        return jsonify(collection.get(measurementId))\n\n    @fp.route(\"/api/measurements/timeseries/\".format(urlPath))\n    @auth.login_required\n    def getRequestsTimeseries():\n        args = dict(request.args.items())\n        return jsonify({\"series\": collection.getTimeseries(args)})\n\n    @fp.route(\"/api/measurements/methodDistribution/\".format(urlPath))\n    @auth.login_required\n    def getMethodDistribution():\n        args = dict(request.args.items())\n        return jsonify({\n            \"distribution\": collection.getMethodDistribution(args)})\n\n    @fp.route(\"/db/dumpDatabase\")\n    @auth.login_required\n    def dumpDatabase():\n        response = jsonify({\n            \"summary\": collection.getSummary()})\n        response.headers[\"Content-Disposition\"] = \"attachment; filename=dump.json\"\n        return response\n\n    @fp.route(\"/db/deleteDatabase\")\n    @auth.login_required\n    def deleteDatabase():\n        response = jsonify({\n            \"status\": collection.truncate()})\n        return response\n\n    @fp.after_request\n    def x_robots_tag_header(response):\n        response.headers['X-Robots-Tag'] = 'noindex, nofollow'\n        return response\n\n    app.register_blueprint(fp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef line_showLog(self):\n        if self.kernel.mva is None:\n            print(\"Can't show log because no session exists\")\n        else:\n            return self.kernel.Display(HTML(self.kernel.cachedlog))", "response": "Display the SAS log for the previous submitted code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay the entire SAS log", "response": "def line_showFullLog(self):\n        \"\"\"\n        SAS Kernel magic to show the entire SAS log since the kernel was started (last restarted)\n        This magic is only available within the SAS Kernel\n        \"\"\"\n        if self.kernel.mva is None:\n            self.kernel._allow_stdin = True\n            self.kernel._start_sas()\n            print(\"Session Started probably not the log you want\")\n        full_log = highlight(self.kernel.mva.saslog(), SASLogLexer(), HtmlFormatter(full=True, style=SASLogStyle, lineseparator=\"<br>\"))\n        return self.kernel.Display(HTML(full_log))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef line_prompt4var(self, *args):\n        prmpt = OrderedDict()\n        for arg in args:\n            assert isinstance(arg, str)\n            prmpt[arg] = False\n        if not len(self.code):\n            if self.kernel.mva is None:\n                self.kernel._allow_stdin = True\n                self.kernel._start_sas()\n            self.kernel.mva.submit(code=self.code, results=\"html\", prompt=prmpt)\n        else:\n            self.kernel.promptDict = prmpt", "response": "Line - prompt for macro variables that will be assigned to the SAS session."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if the log or lst should be returned as the results based on the log and lst output.", "response": "def _which_display(self, log: str, output: str) -> HTML:\n        \"\"\"\n        Determines if the log or lst should be returned as the results for the cell based on parsing the log\n        looking for errors and the presence of lst output.\n\n        :param log: str log from code submission\n        :param output: None or str lst output if there was any\n        :return: The correct results based on log and lst\n        :rtype: str\n        \"\"\"\n        lines = re.split(r'[\\n]\\s*', log)\n        i = 0\n        elog = []\n        for line in lines:\n            i += 1\n            e = []\n            if line.startswith('ERROR'):\n                logger.debug(\"In ERROR Condition\")\n                e = lines[(max(i - 15, 0)):(min(i + 16, len(lines)))]\n            elog = elog + e\n        tlog = '\\n'.join(elog)\n        logger.debug(\"elog count: \" + str(len(elog)))\n        logger.debug(\"tlog: \" + str(tlog))\n\n        color_log = highlight(log, SASLogLexer(), HtmlFormatter(full=True, style=SASLogStyle, lineseparator=\"<br>\"))\n        # store the log for display in the showSASLog nbextension\n        self.cachedlog = color_log\n        # Are there errors in the log? if show the lines on each side of the error\n        if len(elog) == 0 and len(output) > self.lst_len:  # no error and LST output\n            debug1 = 1\n            logger.debug(\"DEBUG1: \" + str(debug1) + \" no error and LST output \")\n            return HTML(output)\n        elif len(elog) == 0 and len(output) <= self.lst_len:  # no error and no LST\n            debug1 = 2\n            logger.debug(\"DEBUG1: \" + str(debug1) + \" no error and no LST\")\n            return HTML(color_log)\n        elif len(elog) > 0 and len(output) <= self.lst_len:  # error and no LST\n            debug1 = 3\n            logger.debug(\"DEBUG1: \" + str(debug1) + \" error and no LST\")\n            return HTML(color_log)\n        else:  # errors and LST\n            debug1 = 4\n            logger.debug(\"DEBUG1: \" + str(debug1) + \" errors and LST\")\n            return HTML(color_log + output)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget completions from kernel for procs and statements.", "response": "def get_completions(self, info):\n        \"\"\"\n        Get completions from kernel for procs and statements.\n        \"\"\"\n        if info['line_num'] > 1:\n            relstart = info['column'] - (info['help_pos'] - info['start'])\n        else:\n            relstart = info['start']\n        seg = info['line'][:relstart]\n        if relstart > 0 and re.match('(?i)proc', seg.rsplit(None, 1)[-1]):\n            potentials = re.findall('(?i)^' + info['obj'] + '.*', self.strproclist, re.MULTILINE)\n            return potentials\n        else:\n            lastproc = info['code'].lower()[:info['help_pos']].rfind('proc')\n            lastdata = info['code'].lower()[:info['help_pos']].rfind('data ')\n            proc = False\n            data = False\n            if lastproc + lastdata == -2:\n                pass\n            else:\n                if lastproc > lastdata:\n                    proc = True\n                else:\n                    data = True\n\n            if proc:\n                # we are not in data section should see if proc option or statement\n                lastsemi = info['code'].rfind(';')\n                mykey = 's'\n                if lastproc > lastsemi:\n                    mykey = 'p'\n                procer = re.search('(?i)proc\\s\\w+', info['code'][lastproc:])\n                method = procer.group(0).split(' ')[-1].upper() + mykey\n                mylist = self.compglo[method][0]\n                potentials = re.findall('(?i)' + info['obj'] + '.+', '\\n'.join(str(x) for x in mylist), re.MULTILINE)\n                return potentials\n            elif data:\n                # we are in statements (probably if there is no data)\n                # assuming we are in the middle of the code\n\n                lastsemi = info['code'].rfind(';')\n                mykey = 's'\n                if lastproc > lastsemi:\n                    mykey = 'p'\n                mylist = self.compglo['DATA' + mykey][0]\n                potentials = re.findall('(?i)^' + info['obj'] + '.*', '\\n'.join(str(x) for x in mylist), re.MULTILINE)\n                return potentials\n            else:\n                potentials = ['']\n                return potentials"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_shutdown(self, restart):\n        print(\"in shutdown function\")\n        if self.hist_file:\n            with open(self.hist_file, 'wb') as fid:\n                data = '\\n'.join(self.hist_cache[-self.max_hist_cache:])\n                fid.write(data.encode('utf-8'))\n        if self.mva:\n            self.mva._endsas()\n            self.mva = None\n        if restart:\n            self.Print(\"Restarting kernel...\")\n            self.reload_magics()\n            self.restart_kernel()\n            self.Print(\"Done!\")\n        return {'status': 'ok', 'restart': restart}", "response": "Shut down the app gracefully saving history."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies from pdbpp https://bitbucket. org / antenocuni / pdb", "response": "def import_from_stdlib(name):\n    \"\"\"Copied from pdbpp https://bitbucket.org/antocuni/pdb\"\"\"\n    import os\n    import types\n    import code  # arbitrary module which stays in the same dir as pdb\n    stdlibdir, _ = os.path.split(code.__file__)\n    pyfile = os.path.join(stdlibdir, name + '.py')\n    result = types.ModuleType(name)\n    exec(compile(open(pyfile).read(), pyfile, 'exec'), result.__dict__)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle_exc(self):\n        exc_info = sys.exc_info()\n        type_, value = exc_info[:2]\n        self.db.obj_cache[id(exc_info)] = exc_info\n\n        return '<a href=\"%d\" class=\"inspect\">%s: %s</a>' % (\n            id(exc_info), escape(type_.__name__), escape(repr(value))\n        )", "response": "Return a formated exception traceback for wdb. js use"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends back captured exceptions", "response": "def fail(self, cmd, title=None, message=None):\n        \"\"\"Send back captured exceptions\"\"\"\n        if message is None:\n            message = self.handle_exc()\n        else:\n            message = escape(message)\n        self.db.send(\n            'Echo|%s' % dump({\n                'for': escape(title or '%s failed' % cmd),\n                'val': message\n            })\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    sys.path.insert(0, os.getcwd())\n    args, extrargs = parser.parse_known_args()\n    sys.argv = ['wdb'] + args.args + extrargs\n\n    if args.file:\n        file = os.path.join(os.getcwd(), args.file)\n        if args.source:\n            print('The source argument cannot be used with file.')\n            sys.exit(1)\n\n        if not os.path.exists(file):\n            print('Error:', file, 'does not exist')\n            sys.exit(1)\n        if args.trace:\n            Wdb.get().run_file(file)\n        else:\n\n            def wdb_pm(xtype, value, traceback):\n                sys.__excepthook__(xtype, value, traceback)\n                wdb = Wdb.get()\n                wdb.reset()\n                wdb.interaction(None, traceback, post_mortem=True)\n\n            sys.excepthook = wdb_pm\n\n            with open(file) as f:\n                code = compile(f.read(), file, 'exec')\n                execute(code, globals(), globals())\n\n    else:\n        source = None\n        if args.source:\n            source = os.path.join(os.getcwd(), args.source)\n            if not os.path.exists(source):\n                print('Error:', source, 'does not exist')\n                sys.exit(1)\n\n        Wdb.get().shell(source)", "response": "Entry point for the Wdb command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _patch_tcpserver():\n    shutdown_request = TCPServer.shutdown_request\n\n    def shutdown_request_patched(*args, **kwargs):\n        thread = current_thread()\n        shutdown_request(*args, **kwargs)\n        if thread in _exc_cache:\n            post_mortem_interaction(*_exc_cache.pop(thread))\n\n    TCPServer.shutdown_request = shutdown_request_patched", "response": "Patch shutdown_request to open blocking interaction after the end of the the\n    request\n\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _format_line(self, side, flag, linenum, text):\n        try:\n            linenum = '%d' % linenum\n            id = ' id=\"%s%s\"' % (self._prefix[side], linenum)\n        except TypeError:\n            # handle blank lines where linenum is '>' or ''\n            id = ''\n        # replace those things that would get confused with HTML symbols\n        text = (\n            text.replace(\"&\", \"&amp;\").replace(\">\",\n                                               \"&gt;\").replace(\"<\", \"&lt;\")\n        )\n\n        type_ = 'neutral'\n        if '\\0+' in text:\n            type_ = 'add'\n        if '\\0-' in text:\n            if type_ == 'add':\n                type_ = 'chg'\n            type_ = 'sub'\n        if '\\0^' in text:\n            type_ = 'chg'\n\n        # make space non-breakable so they don't get compressed or line wrapped\n        text = text.replace(' ', '&nbsp;').rstrip()\n\n        return (\n            '<td class=\"diff_lno\"%s>%s</td>'\n            '<td class=\"diff_line diff_line_%s\">%s</td>' %\n            (id, linenum, type_, text)\n        )", "response": "Returns the HTML markup of a single line."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef up(self):\n        if self.frame:\n            self.frame = self.frame.f_back\n            return self.frame is None", "response": "Go up in stack and return True if top frame"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset trace on current line or on given frame", "response": "def set_trace(frame=None, skip=0, server=None, port=None):\n    \"\"\"Set trace on current line, or on given frame\"\"\"\n    frame = frame or sys._getframe().f_back\n    for i in range(skip):\n        if not frame.f_back:\n            break\n        frame = frame.f_back\n    wdb = Wdb.get(server=server, port=port)\n    wdb.set_trace(frame)\n    return wdb"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart tracing program at callee level breaking on exception or breakpoints on breakpoints.", "response": "def start_trace(\n        full=False, frame=None, below=0, under=None, server=None, port=None\n):\n    \"\"\"Start tracing program at callee level\n       breaking on exception/breakpoints\"\"\"\n    wdb = Wdb.get(server=server, port=port)\n    if not wdb.stepping:\n        wdb.start_trace(full, frame or sys._getframe().f_back, below, under)\n    return wdb"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping tracing for the current thread.", "response": "def stop_trace(frame=None, close_on_exit=False):\n    \"\"\"Stop tracing\"\"\"\n    log.info('Stopping trace')\n    wdb = Wdb.get(True)  # Do not create an istance if there's None\n    if wdb and (not wdb.stepping or close_on_exit):\n        log.info('Stopping trace')\n        wdb.stop_trace(frame or sys._getframe().f_back)\n        if close_on_exit:\n            wdb.die()\n    return wdb"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cleanup():\n    for sck in list(Wdb._sockets):\n        try:\n            sck.close()\n        except Exception:\n            log.warn('Error in cleanup', exc_info=True)", "response": "Close all sockets at exit"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting a shell sourcing source or using vars as locals", "response": "def shell(source=None, vars=None, server=None, port=None):\n    \"\"\"Start a shell sourcing source or using vars as locals\"\"\"\n    Wdb.get(server=server, port=port).shell(source=source, vars=vars)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(no_create=False, server=None, port=None, force_uuid=None):\n        pid = os.getpid()\n        thread = threading.current_thread()\n        wdb = Wdb._instances.get((pid, thread))\n        if not wdb and not no_create:\n            wdb = object.__new__(Wdb)\n            Wdb.__init__(wdb, server, port, force_uuid)\n            wdb.pid = pid\n            wdb.thread = thread\n            Wdb._instances[(pid, thread)] = wdb\n        elif wdb:\n            if (server is not None and wdb.server != server\n                    or port is not None and wdb.port != port):\n                log.warn('Different server/port set, ignoring')\n            else:\n                wdb.reconnect_if_needed()\n        return wdb", "response": "Get the thread local singleton"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop():\n        pid = os.getpid()\n        thread = threading.current_thread()\n        Wdb._instances.pop((pid, thread))", "response": "Remove instance from instance list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the file filename with trace", "response": "def run_file(self, filename):\n        \"\"\"Run the file `filename` with trace\"\"\"\n        import __main__\n        __main__.__dict__.clear()\n        __main__.__dict__.update({\n            \"__name__\": \"__main__\",\n            \"__file__\": filename,\n            \"__builtins__\": __builtins__,\n        })\n        with open(filename, \"rb\") as fp:\n            statement = compile(fp.read(), filename, 'exec')\n        self.run(statement, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the cmd with trace", "response": "def run(self, cmd, fn=None, globals=None, locals=None):\n        \"\"\"Run the cmd `cmd` with trace\"\"\"\n        if globals is None:\n            import __main__\n            globals = __main__.__dict__\n        if locals is None:\n            locals = globals\n        self.reset()\n        if isinstance(cmd, str):\n            str_cmd = cmd\n            cmd = compile(str_cmd, fn or \"<wdb>\", \"exec\")\n            self.compile_cache[id(cmd)] = str_cmd\n        if fn:\n            from linecache import getline\n            lno = 1\n            while True:\n                line = getline(fn, lno, globals)\n                if line is None:\n                    lno = None\n                    break\n                if executable_line(line):\n                    break\n                lno += 1\n\n        self.start_trace()\n        if lno is not None:\n            self.breakpoints.add(LineBreakpoint(fn, lno, temporary=True))\n        try:\n            execute(cmd, globals, locals)\n        finally:\n            self.stop_trace()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to server and send UUID to server", "response": "def connect(self):\n        \"\"\"Connect to wdb server\"\"\"\n        log.info('Connecting socket on %s:%d' % (self.server, self.port))\n        tries = 0\n        while not self._socket and tries < 10:\n            try:\n                time.sleep(.2 * tries)\n                self._socket = Socket((self.server, self.port))\n            except socket.error:\n                tries += 1\n                log.warning(\n                    'You must start/install wdb.server '\n                    '(Retrying on %s:%d) [Try #%d/10]' %\n                    (self.server, self.port, tries)\n                )\n                self._socket = None\n\n        if not self._socket:\n            log.warning('Could not connect to server')\n            return\n\n        Wdb._sockets.append(self._socket)\n        self._socket.send_bytes(self.uuid.encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts tracing from here", "response": "def start_trace(self, full=False, frame=None, below=0, under=None):\n        \"\"\"Start tracing from here\"\"\"\n        if self.tracing:\n            return\n        self.reset()\n        log.info('Starting trace')\n        frame = frame or sys._getframe().f_back\n        # Setting trace without pausing\n        self.set_trace(frame, break_=False)\n        self.tracing = True\n        self.below = below\n        self.under = under\n        self.full = full"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the current trace for this instance.", "response": "def set_trace(self, frame=None, break_=True):\n        \"\"\"Break at current state\"\"\"\n        # We are already tracing, do nothing\n        trace_log.info(\n            'Setting trace %s (stepping %s) (current_trace: %s)' % (\n                pretty_frame(frame or sys._getframe().f_back), self.stepping,\n                sys.gettrace()\n            )\n        )\n        if self.stepping or self.closed:\n            return\n        self.reset()\n        trace = (\n            self.trace_dispatch\n            if trace_log.level >= 30 else self.trace_debug_dispatch\n        )\n        trace_frame = frame = frame or sys._getframe().f_back\n        while frame:\n            frame.f_trace = trace\n            frame = frame.f_back\n        self.state = Step(trace_frame) if break_ else Running(trace_frame)\n        sys.settrace(trace)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop_trace(self, frame=None):\n        self.tracing = False\n        self.full = False\n        frame = frame or sys._getframe().f_back\n        while frame:\n            del frame.f_trace\n            frame = frame.f_back\n        sys.settrace(None)\n        log.info('Stopping trace')", "response": "Stop tracing from here"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_until(self, frame, lineno=None):\n        self.state = Until(frame, frame.f_lineno)", "response": "Stop on the next line number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_continue(self, frame):\n        self.state = Running(frame)\n        if not self.tracing and not self.breakpoints:\n            # If we were in a set_trace and there's no breakpoint to trace for\n            # Run without trace\n            self.stop_trace()", "response": "Stop tracing and break the current process."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nput a breakpoint for filename", "response": "def set_break(\n            self, filename, lineno=None, temporary=False, cond=None,\n            funcname=None\n    ):\n        \"\"\"Put a breakpoint for filename\"\"\"\n        log.info(\n            'Setting break fn:%s lno:%s tmp:%s cond:%s fun:%s' %\n            (filename, lineno, temporary, cond, funcname)\n        )\n        breakpoint = self.get_break(\n            filename, lineno, temporary, cond, funcname\n        )\n        self.breakpoints.add(breakpoint)\n        log.info('Breakpoint %r added' % breakpoint)\n        return breakpoint"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a breakpoint from the breakpoint list", "response": "def clear_break(\n            self, filename, lineno=None, temporary=False, cond=None,\n            funcname=None\n    ):\n        \"\"\"Remove a breakpoint\"\"\"\n        log.info(\n            'Removing break fn:%s lno:%s tmp:%s cond:%s fun:%s' %\n            (filename, lineno, temporary, cond, funcname)\n        )\n\n        breakpoint = self.get_break(\n            filename, lineno, temporary or False, cond, funcname\n        )\n        if temporary is None and breakpoint not in self.breakpoints:\n            breakpoint = self.get_break(filename, lineno, True, cond, funcname)\n\n        try:\n            self.breakpoints.remove(breakpoint)\n            log.info('Breakpoint %r removed' % breakpoint)\n        except Exception:\n            log.info('Breakpoint %r not removed: not found' % breakpoint)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlike a repr but without exception", "response": "def safe_repr(self, obj):\n        \"\"\"Like a repr but without exception\"\"\"\n        try:\n            return repr(obj)\n        except Exception as e:\n            return '??? Broken repr (%s: %s)' % (type(e).__name__, e)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef safe_better_repr(\n            self, obj, context=None, html=True, level=0, full=False\n    ):\n        \"\"\"Repr with inspect links on objects\"\"\"\n        context = context and dict(context) or {}\n        recursion = id(obj) in context\n        if not recursion:\n            context[id(obj)] = obj\n            try:\n                rv = self.better_repr(obj, context, html, level + 1, full)\n            except Exception:\n                rv = None\n            if rv:\n                return rv\n\n        self.obj_cache[id(obj)] = obj\n        if html:\n            return '<a href=\"%d\" class=\"inspect\">%s%s</a>' % (\n                id(obj), 'Recursion of '\n                if recursion else '', escape(self.safe_repr(obj))\n            )\n        return '%s%s' % (\n            'Recursion of ' if recursion else '', self.safe_repr(obj)\n        )", "response": "Return a nicely formatted version of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstealing stream output return them in string restore them", "response": "def capture_output(self, with_hook=True):\n        \"\"\"Steal stream output, return them in string, restore them\"\"\"\n        self.hooked = ''\n\n        def display_hook(obj):\n            # That's some dirty hack\n            self.hooked += self.safe_better_repr(obj)\n            self.last_obj = obj\n\n        stdout, stderr = sys.stdout, sys.stderr\n        if with_hook:\n            d_hook = sys.displayhook\n            sys.displayhook = display_hook\n\n        sys.stdout, sys.stderr = StringIO(), StringIO()\n        out, err = [], []\n        try:\n            yield out, err\n        finally:\n            out.extend(sys.stdout.getvalue().splitlines())\n            err.extend(sys.stderr.getvalue().splitlines())\n            if with_hook:\n                sys.displayhook = d_hook\n\n            sys.stdout, sys.stderr = stdout, stderr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dmp(self, thing):\n\n        def safe_getattr(key):\n            \"\"\"Avoid crash on getattr\"\"\"\n            try:\n                return getattr(thing, key)\n            except Exception as e:\n                return 'Error getting attr \"%s\" from \"%s\" (%s: %s)' % (\n                    key, thing, type(e).__name__, e\n                )\n\n        return dict((\n            escape(key), {\n                'val': self.safe_better_repr(safe_getattr(key)),\n                'type': type(safe_getattr(key)).__name__\n            }\n        ) for key in dir(thing))", "response": "Dump the content of an object in a dict for wdb. js"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_file(self, filename):\n        import linecache\n        # Hack for frozen importlib bootstrap\n        if filename == '<frozen importlib._bootstrap>':\n            filename = os.path.join(\n                os.path.dirname(linecache.__file__), 'importlib',\n                '_bootstrap.py'\n            )\n        return to_unicode_string(\n            ''.join(linecache.getlines(filename)), filename\n        )", "response": "Get file source from cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_stack(self, f, t):\n        stack = []\n        if t and t.tb_frame == f:\n            t = t.tb_next\n        while f is not None:\n            stack.append((f, f.f_lineno))\n            f = f.f_back\n        stack.reverse()\n        i = max(0, len(stack) - 1)\n        while t is not None:\n            stack.append((t.tb_frame, t.tb_lineno))\n            t = t.tb_next\n        if f is None:\n            i = max(0, len(stack) - 1)\n        return stack, i", "response": "Build the stack from frame and traceback"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_trace(self, frame, tb):\n        import linecache\n        frames = []\n        stack, _ = self.get_stack(frame, tb)\n        current = 0\n\n        for i, (stack_frame, lno) in enumerate(stack):\n            code = stack_frame.f_code\n            filename = code.co_filename or '<unspecified>'\n            line = None\n            if filename[0] == '<' and filename[-1] == '>':\n                line = get_source_from_byte_code(code)\n                fn = filename\n            else:\n                fn = os.path.abspath(filename)\n            if not line:\n                linecache.checkcache(filename)\n                line = linecache.getline(filename, lno, stack_frame.f_globals)\n                if not line:\n                    line = self.compile_cache.get(id(code), '')\n                line = to_unicode_string(line, filename)\n                line = line and line.strip()\n            startlnos = dis.findlinestarts(code)\n            lastlineno = list(startlnos)[-1][1]\n            if frame == stack_frame:\n                current = i\n            frames.append({\n                'file': fn,\n                'function': code.co_name,\n                'flno': code.co_firstlineno,\n                'llno': lastlineno,\n                'lno': lno,\n                'code': line,\n                'level': i,\n                'current': frame == stack_frame\n            })\n\n        # While in exception always put the context to the top\n        return stack, frames, current", "response": "Get a dict of the traceback for wdb. js use"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, data):\n        log.debug('Sending %s' % data)\n        if not self._socket:\n            log.warn('No connection')\n            return\n        self._socket.send_bytes(data.encode('utf-8'))", "response": "Send data through websocket"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreceiving data through websocket", "response": "def receive(self, timeout=None):\n        \"\"\"Receive data through websocket\"\"\"\n        log.debug('Receiving')\n        if not self._socket:\n            log.warn('No connection')\n            return\n        try:\n            if timeout:\n                rv = self._socket.poll(timeout)\n                if not rv:\n                    log.info('Connection timeouted')\n                    return 'Quit'\n\n            data = self._socket.recv_bytes()\n        except Exception:\n            log.error('Connection lost')\n            return 'Quit'\n        log.debug('Got %s' % data)\n        return data.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_line(self, frame, arg):\n        log.info('Stopping at line %s' % pretty_frame(frame))\n        self.interaction(frame)", "response": "This function is called when we stop or break at this line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_return(self, frame, return_value):\n        self.obj_cache[id(return_value)] = return_value\n        self.extra_vars['__return__'] = return_value\n        fun = frame.f_code.co_name\n        log.info('Returning from %r with value: %r' % (fun, return_value))\n\n        init = 'Echo|%s' % dump({\n            'for': '__return__',\n            'val': self.safe_better_repr(return_value)\n        })\n        self.interaction(\n            frame,\n            init=init,\n            exception_description='Returning from %s with value %s' %\n            (fun, return_value)\n        )", "response": "This function is called when a return trap is set here."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef breaks(self, frame, no_remove=False):\n        for breakpoint in set(self.breakpoints):\n            if breakpoint.breaks(frame):\n                if breakpoint.temporary and not no_remove:\n                    self.breakpoints.remove(breakpoint)\n                return True\n        return False", "response": "Return True if there s a breakpoint at frame."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all file filename breakpoints", "response": "def get_file_breaks(self, filename):\n        \"\"\"List all file `filename` breakpoints\"\"\"\n        return [\n            breakpoint for breakpoint in self.breakpoints\n            if breakpoint.on_file(filename)\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all line numbers that have a breakpoint", "response": "def get_breaks_lno(self, filename):\n        \"\"\"List all line numbers that have a breakpoint\"\"\"\n        return list(\n            filter(\n                lambda x: x is not None, [\n                    getattr(breakpoint, 'line', None)\n                    for breakpoint in self.breakpoints\n                    if breakpoint.on_file(filename)\n                ]\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef die(self):\n        log.info('Time to die')\n        if self.connected:\n            try:\n                self.send('Die')\n            except Exception:\n                pass\n        if self._socket:\n            self._socket.close()\n        self.pop()", "response": "Send a die to the server and close the socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_process(self, name, cmd, quiet=False, env=None, cwd=None):\n        assert name not in self._processes, \"process names must be unique\"\n        proc = self._process_ctor(cmd,\n                                  name=name,\n                                  quiet=quiet,\n                                  colour=next(self._colours),\n                                  env=env,\n                                  cwd=cwd)\n        self._processes[name] = {}\n        self._processes[name]['obj'] = proc\n\n        # Update printer width to accommodate this process name\n        self._printer.width = max(self._printer.width, len(name))\n\n        return proc", "response": "Add a process to this manager instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loop(self):\n        def _terminate(signum, frame):\n            self._system_print(\"%s received\\n\" % SIGNALS[signum]['name'])\n            self.returncode = SIGNALS[signum]['rc']\n            self.terminate()\n\n        signal.signal(signal.SIGTERM, _terminate)\n        signal.signal(signal.SIGINT, _terminate)\n\n        self._start()\n\n        exit = False\n        exit_start = None\n\n        while 1:\n            try:\n                msg = self.events.get(timeout=0.1)\n            except Empty:\n                if exit:\n                    break\n            else:\n                if msg.type == 'line':\n                    self._printer.write(msg)\n                elif msg.type == 'start':\n                    self._processes[msg.name]['pid'] = msg.data['pid']\n                    self._system_print(\"%s started (pid=%s)\\n\"\n                                       % (msg.name, msg.data['pid']))\n                elif msg.type == 'stop':\n                    self._processes[msg.name]['returncode'] = msg.data['returncode']\n                    self._system_print(\"%s stopped (rc=%s)\\n\"\n                                       % (msg.name, msg.data['returncode']))\n                    if self.returncode is None:\n                        self.returncode = msg.data['returncode']\n\n            if self._all_started() and self._all_stopped():\n                exit = True\n\n            if exit_start is None and self._all_started() and self._any_stopped():\n                exit_start = self._env.now()\n                self.terminate()\n\n            if exit_start is not None:\n                # If we've been in this loop for more than KILL_WAIT seconds,\n                # it's time to kill all remaining children.\n                waiting = self._env.now() - exit_start\n                if waiting > datetime.timedelta(seconds=KILL_WAIT):\n                    self.kill()", "response": "This method loops over all the processes and multiplexes their output onto the printer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _killall(self, force=False):\n        for_termination = []\n\n        for n, p in iteritems(self._processes):\n            if 'returncode' not in p:\n                for_termination.append(n)\n\n        for n in for_termination:\n            p = self._processes[n]\n            signame = 'SIGKILL' if force else 'SIGTERM'\n            self._system_print(\"sending %s to %s (pid %s)\\n\" %\n                               (signame, n, p['pid']))\n            if force:\n                self._env.kill(p['pid'])\n            else:\n                self._env.terminate(p['pid'])", "response": "Kill all remaining processes forcefully if requested."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(content):\n    values = {}\n    for line in content.splitlines():\n        lexer = shlex.shlex(line, posix=True)\n        tokens = list(lexer)\n\n        # parses the assignment statement\n        if len(tokens) < 3:\n            continue\n\n        name, op = tokens[:2]\n        value = ''.join(tokens[2:])\n\n        if op != '=':\n            continue\n        if not re.match(r'[A-Za-z_][A-Za-z_0-9]*', name):\n            continue\n\n        value = value.replace(r'\\n', '\\n')\n        value = value.replace(r'\\t', '\\t')\n        values[name] = value\n\n    return values", "response": "Parse the content of a. env file into a dictionary mapping keys to values."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexpand the specified processes into a list of ProcessParams objects.", "response": "def expand_processes(processes, concurrency=None, env=None, quiet=None, port=None):\n    \"\"\"\n    Get a list of the processes that need to be started given the specified\n    list of process types, concurrency, environment, quietness, and base port\n    number.\n\n    Returns a list of ProcessParams objects, which have `name`, `cmd`, `env`,\n    and `quiet` attributes, corresponding to the parameters to the constructor\n    of `honcho.process.Process`.\n    \"\"\"\n    if env is not None and env.get(\"PORT\") is not None:\n        port = int(env.get(\"PORT\"))\n\n    if quiet is None:\n        quiet = []\n\n    con = defaultdict(lambda: 1)\n    if concurrency is not None:\n        con.update(concurrency)\n\n    out = []\n\n    for name, cmd in compat.iteritems(processes):\n        for i in range(con[name]):\n            n = \"{0}.{1}\".format(name, i + 1)\n            c = cmd\n            q = name in quiet\n            e = {'HONCHO_PROCESS_NAME': n}\n            if env is not None:\n                e.update(env)\n            if port is not None:\n                e['PORT'] = str(port + i)\n\n            params = ProcessParams(n, c, q, e)\n            out.append(params)\n        if port is not None:\n            port += 100\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dashrepl(value):\n    patt = re.compile(r'\\W', re.UNICODE)\n    return re.sub(patt, '-', value)", "response": "Replace any non - word characters with a dash."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntraverses the static folder and add all files that match the pattern", "response": "def traverse_tree(cls, static_dir):\n        \"\"\"traverse the static folders an look for at least one file ending in .scss/.sass\"\"\"\n        for root, dirs, files in os.walk(static_dir):\n            for filename in files:\n                if cls._pattern.match(filename):\n                    APPS_INCLUDE_DIRS.append(static_dir)\n                    return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_sources(self):\n        app_configs = apps.get_app_configs()\n        for app_config in app_configs:\n            ignore_dirs = []\n            for root, dirs, files in os.walk(app_config.path):\n                if [True for idir in ignore_dirs if root.startswith(idir)]:\n                    continue\n                if '__init__.py' not in files:\n                    ignore_dirs.append(root)\n                    continue\n                for filename in files:\n                    basename, ext = os.path.splitext(filename)\n                    if ext != '.py':\n                        continue\n                    yield os.path.abspath(os.path.join(root, filename))", "response": "Find Python sources available for the current configuration."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_source(self, filename):\n        callvisitor = FuncCallVisitor('sass_processor')\n        tree = ast.parse(open(filename, 'rb').read())\n        callvisitor.visit(tree)\n        for sass_fileurl in callvisitor.sass_files:\n            sass_filename = find_file(sass_fileurl)\n            if not sass_filename or sass_filename in self.processed_files:\n                continue\n            if self.delete_files:\n                self.delete_file(sass_filename, sass_fileurl)\n            else:\n                self.compile_sass(sass_filename, sass_fileurl)", "response": "Parse the source file and extract the statements from it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlook for templates and extract the nodes containing the SASS file.", "response": "def find_templates(self):\n        \"\"\"\n        Look for templates and extract the nodes containing the SASS file.\n        \"\"\"\n        paths = set()\n        for loader in self.get_loaders():\n            try:\n                module = import_module(loader.__module__)\n                get_template_sources = getattr(\n                    module, 'get_template_sources', loader.get_template_sources)\n                template_sources = get_template_sources('')\n                paths.update([t.name if isinstance(t, Origin) else t for t in template_sources])\n            except (ImportError, AttributeError):\n                pass\n        if not paths:\n            raise CommandError(\n                \"No template paths found. None of the configured template loaders provided template paths\")\n        templates = set()\n        for path in paths:\n            for root, _, files in os.walk(str(path)):\n                templates.update(os.path.join(root, name)\n                                 for name in files if not name.startswith('.') and\n                                 any(name.endswith(ext) for ext in self.template_exts))\n        if not templates:\n            raise CommandError(\n                \"No templates found. Make sure your TEMPLATE_LOADERS and TEMPLATE_DIRS settings are correct.\")\n        return templates"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompile the given SASS file into CSS and save it into the destination file.", "response": "def compile_sass(self, sass_filename, sass_fileurl):\n        \"\"\"\n        Compile the given SASS file into CSS\n        \"\"\"\n        compile_kwargs = {\n            'filename': sass_filename,\n            'include_paths': SassProcessor.include_paths + APPS_INCLUDE_DIRS,\n            'custom_functions': get_custom_functions(),\n        }\n        if self.sass_precision:\n            compile_kwargs['precision'] = self.sass_precision\n        if self.sass_output_style:\n            compile_kwargs['output_style'] = self.sass_output_style\n        content = sass.compile(**compile_kwargs)\n        self.save_to_destination(content, sass_filename, sass_fileurl)\n        self.processed_files.append(sass_filename)\n        if self.verbosity > 1:\n            self.stdout.write(\"Compiled SASS/SCSS file: '{0}'\\n\".format(sass_filename))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a file from the system.", "response": "def delete_file(self, sass_filename, sass_fileurl):\n        \"\"\"\n        Delete a *.css file, but only if it has been generated through a SASS/SCSS file.\n        \"\"\"\n        if self.use_static_root:\n            destpath = os.path.join(self.static_root, os.path.splitext(sass_fileurl)[0] + '.css')\n        else:\n            destpath = os.path.splitext(sass_filename)[0] + '.css'\n        if os.path.isfile(destpath):\n            os.remove(destpath)\n            self.processed_files.append(sass_filename)\n            if self.verbosity > 1:\n                self.stdout.write(\"Deleted '{0}'\\n\".format(destpath))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\niterates over the nodes recursively yielding the templatetag sass_src node", "response": "def walk_nodes(self, node, original):\n        \"\"\"\n        Iterate over the nodes recursively yielding the templatetag 'sass_src'\n        \"\"\"\n        try:\n            # try with django-compressor<2.1\n            nodelist = self.parser.get_nodelist(node, original=original)\n        except TypeError:\n            nodelist = self.parser.get_nodelist(node, original=original, context=None)\n        for node in nodelist:\n            if isinstance(node, SassSrcNode):\n                if node.is_sass:\n                    yield node\n            else:\n                for node in self.walk_nodes(node, original=original):\n                    yield node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_custom_functions():\n    def get_setting(*args):\n        try:\n            return getattr(settings, args[0])\n        except AttributeError as e:\n            raise TemplateSyntaxError(str(e))\n\n    if hasattr(get_custom_functions, '_custom_functions'):\n        return get_custom_functions._custom_functions\n    get_custom_functions._custom_functions = {sass.SassFunction('get-setting', ('key',), get_setting)}\n    for name, func in getattr(settings, 'SASS_PROCESSOR_CUSTOM_FUNCTIONS', {}).items():\n        try:\n            if isinstance(func, six.string_types):\n                func = import_string(func)\n        except Exception as e:\n            raise TemplateSyntaxError(str(e))\n        else:\n            if not inspect.isfunction(func):\n                raise TemplateSyntaxError(\"{} is not a Python function\".format(func))\n            if six.PY2:\n                func_args = inspect.getargspec(func).args\n            else:\n                func_args = inspect.getfullargspec(func).args\n            sass_func = sass.SassFunction(name, func_args, func)\n            get_custom_functions._custom_functions.add(sass_func)\n    return get_custom_functions._custom_functions", "response": "Return a dict of function names to be used from inside SASS\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download(number=-1, name=\"\", save_dir='./'):\n    df = load_datasets()\n\n    if number > -1:\n        row = df.iloc[[number]]\n    elif name:\n        row = df.loc[df[\"Name\"] == name]\n\n    url = ''.join(row.URL)\n    if not url:\n        print('The word vector you specified was not found. Please specify correct name.')\n\n    widgets = ['Test: ', Percentage(), ' ', Bar(marker=RotatingMarker()), ' ', ETA(), ' ', FileTransferSpeed()]\n    pbar = ProgressBar(widgets=widgets)\n\n    def dlProgress(count, blockSize, totalSize):\n        if pbar.max_value is None:\n            pbar.max_value = totalSize\n            pbar.start()\n\n        pbar.update(min(count * blockSize, totalSize))\n\n    file_name = url.split('/')[-1]\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n    save_path = os.path.join(save_dir, file_name)\n    path, _ = urlretrieve(url, save_path, reporthook=dlProgress)\n    pbar.finish()\n    return path", "response": "Download a pre - trained word vector."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching pre - trained word vectors by their language.", "response": "def search(lang=''):\n    \"\"\"Search pre-trained word vectors by their language\n    :param lang: str, default ''\n    :return: None\n        print search result as pandas DataFrame\n    \"\"\"\n    df = load_datasets()\n    if lang == '':\n        print(df[['Name', 'Dimension', 'Corpus', 'VocabularySize', 'Method', 'Language', 'Author']])\n    else:\n        rows = df[df.Language==lang]\n        print(rows[['Name', 'Dimension', 'Corpus', 'VocabularySize', 'Method', 'Language', 'Author']])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a specific business object by ID.", "response": "def get_by_id(self, business_id, **url_params):\n        \"\"\"Make a request to the business details endpoint. More info at\n        https://www.yelp.com/developers/documentation/v3/business\n\n        Args:\n            business_id (str): The business alias (i.e. yelp-san-francisco) or\n                ID (i.e. 4kMBvIEWPxWkWKFN__8SxQ.\n            **url_params: Dict corresponding to business API params\n                https://www.yelp.com/developers/documentation/v3/business\n\n        Returns:\n            yelp.obj.business.Business object that wraps the response.\n\n        \"\"\"\n        business_path = BUSINESS_PATH.format(business_id=business_id)\n        response = self.client._make_request(business_path, url_params=url_params)\n        return Business(response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_response(raw_response):\n        json_response = raw_response.json()\n        error_info = json_response[\"error\"]\n        code = error_info[\"code\"]\n\n        try:\n            error_cls = _error_map[code]\n        except KeyError:\n            raise NotImplementedError(\n                \"Unknown error code '{}' returned in Yelp API response. \"\n                \"This code may have been newly added. Please ensure you are \"\n                \"using the latest version of the yelp-python library, and if \"\n                \"so, create a new issue at https://github.com/Yelp/yelp-python \"\n                \"to add support for this error.\".format(code)\n            )\n        else:\n            return error_cls(raw_response, **error_info)", "response": "Create an error object from a Yelp API response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, pin, is_differential=False):\n        pin = pin if is_differential else pin + 0x04\n        return self._read(pin)", "response": "read - Read the ADC record."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read(self, pin):\n        config = _ADS1X15_CONFIG_OS_SINGLE\n        config |= (pin & 0x07) << _ADS1X15_CONFIG_MUX_OFFSET\n        config |= _ADS1X15_CONFIG_GAIN[self.gain]\n        config |= self.mode\n        config |= self.rate_config[self.data_rate]\n        config |= _ADS1X15_CONFIG_COMP_QUE_DISABLE\n        self._write_register(_ADS1X15_POINTER_CONFIG, config)\n\n        while not self._conversion_complete():\n            time.sleep(0.01)\n\n        return self.get_last_result()", "response": "Perform an ADC read. Returns the signed integer result of the read."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write_register(self, reg, value):\n        self.buf[0] = reg\n        self.buf[1] = (value >> 8) & 0xFF\n        self.buf[2] = value & 0xFF\n        with self.i2c_device as i2c:\n            i2c.write(self.buf)", "response": "Write 16 bit value to register."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads 16 bit register value.", "response": "def _read_register(self, reg):\n        \"\"\"Read 16 bit register value.\"\"\"\n        self.buf[0] = reg\n        with self.i2c_device as i2c:\n            i2c.write(self.buf, end=1, stop=False)\n            i2c.readinto(self.buf, end=2)\n        return self.buf[0] << 8 | self.buf[1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value(self):\n        return self._ads.read(self._pin_setting, is_differential=self.is_differential)", "response": "Returns the value of an ADC pin as an integer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef voltage(self):\n        raw = self.value\n        volts = raw * (_ADS1X15_PGA_RANGE[self._ads.gain] / (2**(self._ads.bits-1) - 1))\n        return volts", "response": "Returns the voltage from the ADC pin as a floating point value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sequential_id(self, client):\n        if client.client_id not in self._sequential_ids:\n            id_ = sequential_id(\"e:{0}:users\".format(self.name), client.client_id)\n            self._sequential_ids[client.client_id] = id_\n        return self._sequential_ids[client.client_id]", "response": "Return the sequential id for this test for the passed in client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning and records an alternative according to the following parameters.", "response": "def get_alternative(self, client, dt=None, prefetch=False):\n        \"\"\"Returns and records an alternative according to the following\n        precedence:\n          1. An existing alternative\n          2. A server-chosen alternative\n        \"\"\"\n\n        if self.is_archived() or self.is_paused():\n            return self.control\n\n        if self.is_client_excluded(client):\n            return self.control\n\n        chosen_alternative = self.existing_alternative(client)\n        if not chosen_alternative:\n            chosen_alternative, participate = self.choose_alternative(client)\n            if participate and not prefetch:\n                chosen_alternative.record_participation(client, dt=dt)\n\n        return chosen_alternative"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrecords a user s participation in a test along with a given variation", "response": "def record_participation(self, client, dt=None):\n        \"\"\"Record a user's participation in a test along with a given variation\"\"\"\n        if dt is None:\n            date = datetime.now()\n        else:\n            date = dt\n\n        experiment_key = self.experiment.name\n\n        pipe = self.redis.pipeline()\n\n        pipe.sadd(_key(\"p:{0}:years\".format(experiment_key)), date.strftime('%Y'))\n        pipe.sadd(_key(\"p:{0}:months\".format(experiment_key)), date.strftime('%Y-%m'))\n        pipe.sadd(_key(\"p:{0}:days\".format(experiment_key)), date.strftime('%Y-%m-%d'))\n\n        pipe.execute()\n\n        keys = [\n            _key(\"p:{0}:_all:all\".format(experiment_key)),\n            _key(\"p:{0}:_all:{1}\".format(experiment_key, date.strftime('%Y'))),\n            _key(\"p:{0}:_all:{1}\".format(experiment_key, date.strftime('%Y-%m'))),\n            _key(\"p:{0}:_all:{1}\".format(experiment_key, date.strftime('%Y-%m-%d'))),\n            _key(\"p:{0}:{1}:all\".format(experiment_key, self.name)),\n            _key(\"p:{0}:{1}:{2}\".format(experiment_key, self.name, date.strftime('%Y'))),\n            _key(\"p:{0}:{1}:{2}\".format(experiment_key, self.name, date.strftime('%Y-%m'))),\n            _key(\"p:{0}:{1}:{2}\".format(experiment_key, self.name, date.strftime('%Y-%m-%d'))),\n        ]\n        msetbit(keys=keys, args=([self.experiment.sequential_id(client), 1] * len(keys)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sequential_id(k, identifier):\n    key = _key(k)\n    return int(monotonic_zadd(keys=[key], args=[identifier]))", "response": "Map an arbitrary string identifier to a set of sequential ids"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the bindings that will open the buffer in an external editor.", "response": "def load_emacs_open_in_editor_bindings():\n    \"\"\"\n    Pressing C-X C-E will open the buffer in an external editor.\n    \"\"\"\n    registry = Registry()\n\n    registry.add_binding(Keys.ControlX, Keys.ControlE,\n                         filter=EmacsMode() & ~HasSelection())(\n         get_by_name('edit-and-execute-command'))\n\n    return registry"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads extra bindings for scrolling up and down through pages.", "response": "def load_extra_emacs_page_navigation_bindings():\n    \"\"\"\n    Key bindings, for scrolling up and down through pages.\n    This are separate bindings, because GNU readline doesn't have them.\n    \"\"\"\n    registry = ConditionalRegistry(Registry(), EmacsMode())\n    handle = registry.add_binding\n\n    handle(Keys.ControlV)(scroll_page_down)\n    handle(Keys.PageDown)(scroll_page_down)\n    handle(Keys.Escape, 'v')(scroll_page_up)\n    handle(Keys.PageUp)(scroll_page_up)\n\n    return registry"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding all possible completions for this input string.", "response": "def _get_completions_for_match(self, match, complete_event):\n        \"\"\"\n        Yield all the possible completions for this input string.\n        (The completer assumes that the cursor position was at the end of the\n        input string.)\n        \"\"\"\n        for match_variable in match.end_nodes():\n            varname = match_variable.varname\n            start = match_variable.start\n\n            completer = self.completers.get(varname)\n\n            if completer:\n                text = match_variable.value\n\n                # Unwrap text.\n                unwrapped_text = self.compiled_grammar.unescape(varname, text)\n\n                # Create a document, for the completions API (text/cursor_position)\n                document = Document(unwrapped_text, len(unwrapped_text))\n\n                # Call completer\n                for completion in completer.get_completions(document, complete_event):\n                    new_text = unwrapped_text[:len(text) + completion.start_position] + completion.text\n\n                    # Wrap again.\n                    yield Completion(\n                        text=self.compiled_grammar.escape(varname, new_text),\n                        start_position=start - len(match.string),\n                        display=completion.display,\n                        display_meta=completion.display_meta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _remove_duplicates(self, items):\n        result = []\n        for i in items:\n            if i not in result:\n                result.append(i)\n        return result", "response": "Remove duplicates while keeping the order."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef style_from_pygments(style_cls=pygments_DefaultStyle,\n                        style_dict=None,\n                        include_defaults=True):\n    \"\"\"\n    Shortcut to create a :class:`.Style` instance from a Pygments style class\n    and a style dictionary.\n\n    Example::\n\n        from prompt_toolkit.styles.from_pygments import style_from_pygments\n        from pygments.styles import get_style_by_name\n        style = style_from_pygments(get_style_by_name('monokai'))\n\n    :param style_cls: Pygments style class to start from.\n    :param style_dict: Dictionary for this style. `{Token: style}`.\n    :param include_defaults: (`bool`) Include prompt_toolkit extensions.\n    \"\"\"\n    assert style_dict is None or isinstance(style_dict, dict)\n    assert style_cls is None or issubclass(style_cls, pygments_Style)\n\n    styles_dict = {}\n\n    if style_cls is not None:\n        styles_dict.update(style_cls.styles)\n\n    if style_dict is not None:\n        styles_dict.update(style_dict)\n\n    return style_from_dict(styles_dict, include_defaults=include_defaults)", "response": "Shortcut to create a : class :. Style instance from a Pygments style class and a style dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwaits for multiple handles.", "response": "def _wait_for_handles(handles, timeout=-1):\n    \"\"\"\n    Waits for multiple handles. (Similar to 'select') Returns the handle which is ready.\n    Returns `None` on timeout.\n\n    http://msdn.microsoft.com/en-us/library/windows/desktop/ms687025(v=vs.85).aspx\n    \"\"\"\n    arrtype = HANDLE * len(handles)\n    handle_array = arrtype(*handles)\n\n    ret = windll.kernel32.WaitForMultipleObjects(\n        len(handle_array), handle_array, BOOL(False), DWORD(timeout))\n\n    if ret == WAIT_TIMEOUT:\n        return None\n    else:\n        h = handle_array[ret]\n        return h"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a Win32 unnamed Event.", "response": "def _create_event():\n    \"\"\"\n    Creates a Win32 unnamed Event .\n\n    http://msdn.microsoft.com/en-us/library/windows/desktop/ms682396(v=vs.85).aspx\n    \"\"\"\n    return windll.kernel32.CreateEventA(pointer(SECURITY_ATTRIBUTES()), BOOL(True), BOOL(False), None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting for the event that is ready for reading or None on timeout.", "response": "def _ready_for_reading(self, timeout=None):\n        \"\"\"\n        Return the handle that is ready for reading or `None` on timeout.\n        \"\"\"\n        handles = [self._event, self._console_input_reader.handle]\n        handles.extend(self._read_fds.keys())\n        return _wait_for_handles(handles, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall this function in the main event loop.", "response": "def call_from_executor(self, callback, _max_postpone_until=None):\n        \"\"\"\n        Call this function in the main event loop.\n        Similar to Twisted's ``callFromThread``.\n        \"\"\"\n        # Append to list of pending callbacks.\n        self._calls_from_executor.append(callback)\n\n        # Set Windows event.\n        windll.kernel32.SetEvent(self._event)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts watching the file descriptor for read availability.", "response": "def add_reader(self, fd, callback):\n        \" Start watching the file descriptor for read availability. \"\n        h = msvcrt.get_osfhandle(fd)\n        self._read_fds[h] = callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops watching the file descriptor for read availability.", "response": "def remove_reader(self, fd):\n        \" Stop watching the file descriptor for read availability. \"\n        h = msvcrt.get_osfhandle(fd)\n        if h in self._read_fds:\n            del self._read_fds[h]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nindents text of a buffer object.", "response": "def indent(buffer, from_row, to_row, count=1):\n    \"\"\"\n    Indent text of a :class:`.Buffer` object.\n    \"\"\"\n    current_row = buffer.document.cursor_position_row\n    line_range = range(from_row, to_row)\n\n    # Apply transformation.\n    new_text = buffer.transform_lines(line_range, lambda l: '    ' * count + l)\n    buffer.document = Document(\n        new_text,\n        Document(new_text).translate_row_col_to_index(current_row, 0))\n\n    # Go to the start of the line.\n    buffer.cursor_position += buffer.document.get_start_of_line_position(after_whitespace=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unindent(buffer, from_row, to_row, count=1):\n    current_row = buffer.document.cursor_position_row\n    line_range = range(from_row, to_row)\n\n    def transform(text):\n        remove = '    ' * count\n        if text.startswith(remove):\n            return text[len(remove):]\n        else:\n            return text.lstrip()\n\n    # Apply transformation.\n    new_text = buffer.transform_lines(line_range, transform)\n    buffer.document = Document(\n        new_text,\n        Document(new_text).translate_row_col_to_index(current_row, 0))\n\n    # Go to the start of the line.\n    buffer.cursor_position += buffer.document.get_start_of_line_position(after_whitespace=True)", "response": "Unindent text of a buffer object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreformat text, taking the width into account. `to_row` is included. (Vi 'gq' operator.)", "response": "def reshape_text(buffer, from_row, to_row):\n    \"\"\"\n    Reformat text, taking the width into account.\n    `to_row` is included.\n    (Vi 'gq' operator.)\n    \"\"\"\n    lines = buffer.text.splitlines(True)\n    lines_before = lines[:from_row]\n    lines_after = lines[to_row + 1:]\n    lines_to_reformat = lines[from_row:to_row + 1]\n\n    if lines_to_reformat:\n        # Take indentation from the first line.\n        length = re.search(r'^\\s*', lines_to_reformat[0]).end()\n        indent = lines_to_reformat[0][:length].replace('\\n', '')\n\n        # Now, take all the 'words' from the lines to be reshaped.\n        words = ''.join(lines_to_reformat).split()\n\n        # And reshape.\n        width = (buffer.text_width or 80) - len(indent)\n        reshaped_text = [indent]\n        current_width = 0\n        for w in words:\n            if current_width:\n                if len(w) + current_width + 1 > width:\n                    reshaped_text.append('\\n')\n                    reshaped_text.append(indent)\n                    current_width = 0\n                else:\n                    reshaped_text.append(' ')\n                    current_width += 1\n\n            reshaped_text.append(w)\n            current_width += len(w)\n\n        if reshaped_text[-1] != '\\n':\n            reshaped_text.append('\\n')\n\n        # Apply result.\n        buffer.document = Document(\n            text=''.join(lines_before + reshaped_text + lines_after),\n            cursor_position=len(''.join(lines_before + reshaped_text)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an AcceptAction that runs the given handler in the available modules in the terminal.", "response": "def run_in_terminal(cls, handler, render_cli_done=False):\n        \"\"\"\n        Create an :class:`.AcceptAction` that runs the given handler in the\n        terminal.\n\n        :param render_cli_done: When True, render the interface in the 'Done'\n                state first, then execute the function. If False, erase the\n                interface instead.\n        \"\"\"\n        def _handler(cli, buffer):\n            cli.run_in_terminal(lambda: handler(cli, buffer), render_cli_done=render_cli_done)\n        return AcceptAction(handler=_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate buffer and handle the accept action.", "response": "def validate_and_handle(self, cli, buffer):\n        \"\"\"\n        Validate buffer and handle the accept action.\n        \"\"\"\n        if buffer.validate():\n            if self.handler:\n                self.handler(cli, buffer)\n\n            buffer.append_to_history()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngoes to the given index.", "response": "def go_to_index(self, index):\n        \"\"\"\n        Create a new :class:`.CompletionState` object with the new index.\n        \"\"\"\n        return CompletionState(self.original_document, self.current_completions, complete_index=index)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the new text and cursor position for this completion.", "response": "def new_text_and_position(self):\n        \"\"\"\n        Return (new_text, new_cursor_position) for this completion.\n        \"\"\"\n        if self.complete_index is None:\n            return self.original_document.text, self.original_document.cursor_position\n        else:\n            original_text_before_cursor = self.original_document.text_before_cursor\n            original_text_after_cursor = self.original_document.text_after_cursor\n\n            c = self.current_completions[self.complete_index]\n            if c.start_position == 0:\n                before = original_text_before_cursor\n            else:\n                before = original_text_before_cursor[:c.start_position]\n\n            new_text = before + c.text + original_text_after_cursor\n            new_cursor_position = len(before) + len(c.text)\n            return new_text, new_cursor_position"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset the internal state of the current entry.", "response": "def reset(self, initial_document=None, append_to_history=False):\n        \"\"\"\n        :param append_to_history: Append current input to history first.\n        \"\"\"\n        assert initial_document is None or isinstance(initial_document, Document)\n\n        if append_to_history:\n            self.append_to_history()\n\n        initial_document = initial_document or Document()\n\n        self.__cursor_position = initial_document.cursor_position\n\n        # `ValidationError` instance. (Will be set when the input is wrong.)\n        self.validation_error = None\n        self.validation_state = ValidationState.UNKNOWN\n\n        # State of the selection.\n        self.selection_state = None\n\n        # Multiple cursor mode. (When we press 'I' or 'A' in visual-block mode,\n        # we can insert text on multiple lines at once. This is implemented by\n        # using multiple cursors.)\n        self.multiple_cursor_positions = []\n\n        # When doing consecutive up/down movements, prefer to stay at this column.\n        self.preferred_column = None\n\n        # State of complete browser\n        self.complete_state = None  # For interactive completion through Ctrl-N/Ctrl-P.\n\n        # State of Emacs yank-nth-arg completion.\n        self.yank_nth_arg_state = None  # for yank-nth-arg.\n\n        # Remember the document that we had *right before* the last paste\n        # operation. This is used for rotating through the kill ring.\n        self.document_before_paste = None\n\n        # Current suggestion.\n        self.suggestion = None\n\n        # The history search text. (Used for filtering the history when we\n        # browse through it.)\n        self.history_search_text = None\n\n        # Undo/redo stacks\n        self._undo_stack = []  # Stack of (text, cursor_position)\n        self._redo_stack = []\n\n        #: The working lines. Similar to history, except that this can be\n        #: modified. The user can press arrow_up and edit previous entries.\n        #: Ctrl-C should reset this, and copy the whole history back in here.\n        #: Enter should process the current command and append to the real\n        #: history.\n        self._working_lines = self.history.strings[:]\n        self._working_lines.append(initial_document.text)\n        self.__working_index = len(self._working_lines) - 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_text(self, value):\n        working_index = self.working_index\n        working_lines = self._working_lines\n\n        original_value = working_lines[working_index]\n        working_lines[working_index] = value\n\n        # Return True when this text has been changed.\n        if len(value) != len(original_value):\n            # For Python 2, it seems that when two strings have a different\n            # length and one is a prefix of the other, Python still scans\n            # character by character to see whether the strings are different.\n            # (Some benchmarking showed significant differences for big\n            # documents. >100,000 of lines.)\n            return True\n        elif value != original_value:\n            return True\n        return False", "response": "Set the text at the current working_index. Return whether it changed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_cursor_position(self, value):\n        original_position = self.__cursor_position\n        self.__cursor_position = max(0, value)\n\n        return value != original_position", "response": "Set the cursor position. Return whether it changed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the text of the current object.", "response": "def text(self, value):\n        \"\"\"\n        Setting text. (When doing this, make sure that the cursor_position is\n        valid for this text. text/cursor_position should be consistent at any time,\n        otherwise set a Document instead.)\n        \"\"\"\n        assert isinstance(value, six.text_type), 'Got %r' % value\n        assert self.cursor_position <= len(value)\n\n        # Don't allow editing of read-only buffers.\n        if self.read_only():\n            raise EditReadOnlyBuffer()\n\n        changed = self._set_text(value)\n\n        if changed:\n            self._text_changed()\n\n            # Reset history search text.\n            self.history_search_text = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the cursor position.", "response": "def cursor_position(self, value):\n        \"\"\"\n        Setting cursor position.\n        \"\"\"\n        assert isinstance(value, int)\n        assert value <= len(self.text)\n\n        changed = self._set_cursor_position(value)\n\n        if changed:\n            self._cursor_position_changed()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the document instance from the current text cursor position and selection state.", "response": "def document(self):\n        \"\"\"\n        Return :class:`~prompt_toolkit.document.Document` instance from the\n        current text, cursor position and selection state.\n        \"\"\"\n        return self._document_cache[\n            self.text, self.cursor_position, self.selection_state]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_document(self, value, bypass_readonly=False):\n        assert isinstance(value, Document)\n\n        # Don't allow editing of read-only buffers.\n        if not bypass_readonly and self.read_only():\n            raise EditReadOnlyBuffer()\n\n        # Set text and cursor position first.\n        text_changed = self._set_text(value.text)\n        cursor_position_changed = self._set_cursor_position(value.cursor_position)\n\n        # Now handle change events. (We do this when text/cursor position is\n        # both set and consistent.)\n        if text_changed:\n            self._text_changed()\n\n        if cursor_position_changed:\n            self._cursor_position_changed()", "response": "Set the value of the unicode document property."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_to_undo_stack(self, clear_redo_stack=True):\n        # Safe if the text is different from the text at the top of the stack\n        # is different. If the text is the same, just update the cursor position.\n        if self._undo_stack and self._undo_stack[-1][0] == self.text:\n            self._undo_stack[-1] = (self._undo_stack[-1][0], self.cursor_position)\n        else:\n            self._undo_stack.append((self.text, self.cursor_position))\n\n        # Saving anything to the undo stack, clears the redo stack.\n        if clear_redo_stack:\n            self._redo_stack = []", "response": "Save the current state to the undo stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransforms the text on a range of lines.", "response": "def transform_lines(self, line_index_iterator, transform_callback):\n        \"\"\"\n        Transforms the text on a range of lines.\n        When the iterator yield an index not in the range of lines that the\n        document contains, it skips them silently.\n\n        To uppercase some lines::\n\n            new_text = transform_lines(range(5,10), lambda text: text.upper())\n\n        :param line_index_iterator: Iterator of line numbers (int)\n        :param transform_callback: callable that takes the original text of a\n                                   line, and return the new text for this line.\n\n        :returns: The new text.\n        \"\"\"\n        # Split lines\n        lines = self.text.split('\\n')\n\n        # Apply transformation\n        for index in line_index_iterator:\n            try:\n                lines[index] = transform_callback(lines[index])\n            except IndexError:\n                pass\n\n        return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying the given transformation function to the current line.", "response": "def transform_current_line(self, transform_callback):\n        \"\"\"\n        Apply the given transformation function to the current line.\n\n        :param transform_callback: callable that takes a string and return a new string.\n        \"\"\"\n        document = self.document\n        a = document.cursor_position + document.get_start_of_line_position()\n        b = document.cursor_position + document.get_end_of_line_position()\n        self.text = (\n            document.text[:a] +\n            transform_callback(document.text[a:b]) +\n            document.text[b:])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform_region(self, from_, to, transform_callback):\n        assert from_ < to\n\n        self.text = ''.join([\n            self.text[:from_] +\n            transform_callback(self.text[from_:to]) +\n            self.text[to:]\n        ])", "response": "Transform a string from from_ to to_ in order."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves cursor to the previous line.", "response": "def cursor_up(self, count=1):\n        \"\"\" (for multiline edit). Move cursor to the previous line.  \"\"\"\n        original_column = self.preferred_column or self.document.cursor_position_col\n        self.cursor_position += self.document.get_cursor_up_position(\n            count=count, preferred_column=original_column)\n\n        # Remember the original column for the next up/down movement.\n        self.preferred_column = original_column"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cursor_down(self, count=1):\n        original_column = self.preferred_column or self.document.cursor_position_col\n        self.cursor_position += self.document.get_cursor_down_position(\n            count=count, preferred_column=original_column)\n\n        # Remember the original column for the next up/down movement.\n        self.preferred_column = original_column", "response": "Move cursor to the next line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef auto_up(self, count=1, go_to_start_of_line_if_history_changes=False):\n        if self.complete_state:\n            self.complete_previous(count=count)\n        elif self.document.cursor_position_row > 0:\n            self.cursor_up(count=count)\n        elif not self.selection_state:\n            self.history_backward(count=count)\n\n            # Go to the start of the line?\n            if go_to_start_of_line_if_history_changes:\n                self.cursor_position += self.document.get_start_of_line_position()", "response": "Go to the next count lines or history entries."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auto_down(self, count=1, go_to_start_of_line_if_history_changes=False):\n        if self.complete_state:\n            self.complete_next(count=count)\n        elif self.document.cursor_position_row < self.document.line_count - 1:\n            self.cursor_down(count=count)\n        elif not self.selection_state:\n            self.history_forward(count=count)\n\n            # Go to the start of the line?\n            if go_to_start_of_line_if_history_changes:\n                self.cursor_position += self.document.get_start_of_line_position()", "response": "Go to the next count lines."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_before_cursor(self, count=1):\n        assert count >= 0\n        deleted = ''\n\n        if self.cursor_position > 0:\n            deleted = self.text[self.cursor_position - count:self.cursor_position]\n\n            new_text = self.text[:self.cursor_position - count] + self.text[self.cursor_position:]\n            new_cursor_position = self.cursor_position - len(deleted)\n\n            # Set new Document atomically.\n            self.document = Document(new_text, new_cursor_position)\n\n        return deleted", "response": "Delete specified number of characters before cursor and return the deleted text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete specified number of characters and Return the deleted text.", "response": "def delete(self, count=1):\n        \"\"\"\n        Delete specified number of characters and Return the deleted text.\n        \"\"\"\n        if self.cursor_position < len(self.text):\n            deleted = self.document.text_after_cursor[:count]\n            self.text = self.text[:self.cursor_position] + \\\n                self.text[self.cursor_position + len(deleted):]\n            return deleted\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\njoining the next line to the current line by deleting the line ending after the current line.", "response": "def join_next_line(self, separator=' '):\n        \"\"\"\n        Join the next line to the current one by deleting the line ending after\n        the current line.\n        \"\"\"\n        if not self.document.on_last_line:\n            self.cursor_position += self.document.get_end_of_line_position()\n            self.delete()\n\n            # Remove spaces.\n            self.text = (self.document.text_before_cursor + separator +\n                         self.document.text_after_cursor.lstrip(' '))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\njoin the selected lines.", "response": "def join_selected_lines(self, separator=' '):\n        \"\"\"\n        Join the selected lines.\n        \"\"\"\n        assert self.selection_state\n\n        # Get lines.\n        from_, to = sorted([self.cursor_position, self.selection_state.original_cursor_position])\n\n        before = self.text[:from_]\n        lines = self.text[from_:to].splitlines()\n        after = self.text[to:]\n\n        # Replace leading spaces with just one space.\n        lines = [l.lstrip(' ') + separator for l in lines]\n\n        # Set new document.\n        self.document = Document(text=before + ''.join(lines) + after,\n                                 cursor_position=len(before + ''.join(lines[:-1])) - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef swap_characters_before_cursor(self):\n        pos = self.cursor_position\n\n        if pos >= 2:\n            a = self.text[pos - 2]\n            b = self.text[pos - 1]\n\n            self.text = self.text[:pos-2] + b + a + self.text[pos:]", "response": "Swap the last two characters before the cursor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngoing to the next item in the history.", "response": "def go_to_history(self, index):\n        \"\"\"\n        Go to this item in the history.\n        \"\"\"\n        if index < len(self._working_lines):\n            self.working_index = index\n            self.cursor_position = len(self.text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef complete_next(self, count=1, disable_wrap_around=False):\n        if self.complete_state:\n            completions_count = len(self.complete_state.current_completions)\n\n            if self.complete_state.complete_index is None:\n                index = 0\n            elif self.complete_state.complete_index == completions_count - 1:\n                index = None\n\n                if disable_wrap_around:\n                    return\n            else:\n                index = min(completions_count-1, self.complete_state.complete_index + count)\n            self.go_to_completion(index)", "response": "Browse to the next completions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts completion of count completions.", "response": "def complete_previous(self, count=1, disable_wrap_around=False):\n        \"\"\"\n        Browse to the previous completions.\n        (Does nothing if there are no completion.)\n        \"\"\"\n        if self.complete_state:\n            if self.complete_state.complete_index == 0:\n                index = None\n\n                if disable_wrap_around:\n                    return\n            elif self.complete_state.complete_index is None:\n                index = len(self.complete_state.current_completions) - 1\n            else:\n                index = max(0, self.complete_state.complete_index - count)\n\n            self.go_to_completion(index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_completions(self, completions, go_to_first=True, go_to_last=False):\n        assert not (go_to_first and go_to_last)\n\n        # Generate list of all completions.\n        if completions is None:\n            if self.completer:\n                completions = list(self.completer.get_completions(\n                    self.document,\n                    CompleteEvent(completion_requested=True)\n                ))\n            else:\n                completions = []\n\n        # Set `complete_state`.\n        if completions:\n            self.complete_state = CompletionState(\n                original_document=self.document,\n                current_completions=completions)\n            if go_to_first:\n                self.go_to_completion(0)\n            elif go_to_last:\n                self.go_to_completion(len(completions) - 1)\n            else:\n                self.go_to_completion(None)\n\n        else:\n            self.complete_state = None", "response": "Start completions. (Generate list of completions and initialize.)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting a completion based on all the other lines in the document and the history.", "response": "def start_history_lines_completion(self):\n        \"\"\"\n        Start a completion based on all the other lines in the document and the\n        history.\n        \"\"\"\n        found_completions = set()\n        completions = []\n\n        # For every line of the whole history, find matches with the current line.\n        current_line = self.document.current_line_before_cursor.lstrip()\n\n        for i, string in enumerate(self._working_lines):\n            for j, l in enumerate(string.split('\\n')):\n                l = l.strip()\n                if l and l.startswith(current_line):\n                    # When a new line has been found.\n                    if l not in found_completions:\n                        found_completions.add(l)\n\n                        # Create completion.\n                        if i == self.working_index:\n                            display_meta = \"Current, line %s\" % (j+1)\n                        else:\n                            display_meta = \"History %s, line %s\" % (i+1, j+1)\n\n                        completions.append(Completion(\n                            l,\n                            start_position=-len(current_line),\n                            display_meta=display_meta))\n\n        self.set_completions(completions=completions[::-1])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef go_to_completion(self, index):\n        assert index is None or isinstance(index, int)\n        assert self.complete_state\n\n        # Set new completion\n        state = self.complete_state.go_to_index(index)\n\n        # Set text/cursor position\n        new_text, new_cursor_position = state.new_text_and_position()\n        self.document = Document(new_text, new_cursor_position)\n\n        # (changing text/cursor position will unset complete_state.)\n        self.complete_state = state", "response": "Go to a specific completion."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting a given completion.", "response": "def apply_completion(self, completion):\n        \"\"\"\n        Insert a given completion.\n        \"\"\"\n        assert isinstance(completion, Completion)\n\n        # If there was already a completion active, cancel that one.\n        if self.complete_state:\n            self.go_to_completion(None)\n        self.complete_state = None\n\n        # Insert text from the given completion.\n        self.delete_before_cursor(-completion.start_position)\n        self.insert_text(completion.text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _history_matches(self, i):\n        return (self.history_search_text is None or\n                self._working_lines[i].startswith(self.history_search_text))", "response": "True when the current entry matches the history search."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove forwards through the history.", "response": "def history_forward(self, count=1):\n        \"\"\"\n        Move forwards through the history.\n\n        :param count: Amount of items to move forward.\n        \"\"\"\n        self._set_history_search()\n\n        # Go forward in history.\n        found_something = False\n\n        for i in range(self.working_index + 1, len(self._working_lines)):\n            if self._history_matches(i):\n                self.working_index = i\n                count -= 1\n                found_something = True\n            if count == 0:\n                break\n\n        # If we found an entry, move cursor to the end of the first line.\n        if found_something:\n            self.cursor_position = 0\n            self.cursor_position += self.document.get_end_of_line_position()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef history_backward(self, count=1):\n        self._set_history_search()\n\n        # Go back in history.\n        found_something = False\n\n        for i in range(self.working_index - 1, -1, -1):\n            if self._history_matches(i):\n                self.working_index = i\n                count -= 1\n                found_something = True\n            if count == 0:\n                break\n\n        # If we move to another entry, move cursor to the end of the line.\n        if found_something:\n            self.cursor_position = len(self.text)", "response": "Move backwards through history."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef yank_nth_arg(self, n=None, _yank_last_arg=False):\n        assert n is None or isinstance(n, int)\n\n        if not len(self.history):\n            return\n\n        # Make sure we have a `YankNthArgState`.\n        if self.yank_nth_arg_state is None:\n            state = YankNthArgState(n=-1 if _yank_last_arg else 1)\n        else:\n            state = self.yank_nth_arg_state\n\n        if n is not None:\n            state.n = n\n\n        # Get new history position.\n        new_pos = state.history_position - 1\n        if -new_pos > len(self.history):\n            new_pos = -1\n\n        # Take argument from line.\n        line = self.history[new_pos]\n\n        words = [w.strip() for w in _QUOTED_WORDS_RE.split(line)]\n        words = [w for w in words if w]\n        try:\n            word = words[state.n]\n        except IndexError:\n            word = ''\n\n        # Insert new argument.\n        if state.previous_inserted_word:\n            self.delete_before_cursor(len(state.previous_inserted_word))\n        self.insert_text(word)\n\n        # Save state again for next completion. (Note that the 'insert'\n        # operation from above clears `self.yank_nth_arg_state`.)\n        state.previous_inserted_word = word\n        state.history_position = new_pos\n        self.yank_nth_arg_state = state", "response": "Pick nth word from previous line and insert it at current position."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes the current cursor position as the start of this selection.", "response": "def start_selection(self, selection_type=SelectionType.CHARACTERS):\n        \"\"\"\n        Take the current cursor position as the start of this selection.\n        \"\"\"\n        self.selection_state = SelectionState(self.cursor_position, selection_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_selection(self, _cut=False):\n        new_document, clipboard_data = self.document.cut_selection()\n        if _cut:\n            self.document = new_document\n\n        self.selection_state = None\n        return clipboard_data", "response": "Copy selected text and return clipboard data instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef paste_clipboard_data(self, data, paste_mode=PasteMode.EMACS, count=1):\n        assert isinstance(data, ClipboardData)\n        assert paste_mode in (PasteMode.VI_BEFORE, PasteMode.VI_AFTER, PasteMode.EMACS)\n\n        original_document = self.document\n        self.document = self.document.paste_clipboard_data(data, paste_mode=paste_mode, count=count)\n\n        # Remember original document. This assignment should come at the end,\n        # because assigning to 'document' will erase it.\n        self.document_before_paste = original_document", "response": "Paste the data from the clipboard."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef newline(self, copy_margin=True):\n        if copy_margin:\n            self.insert_text('\\n' + self.document.leading_whitespace_in_current_line)\n        else:\n            self.insert_text('\\n')", "response": "Insert a line ending at the current position."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting a new line above the current one.", "response": "def insert_line_above(self, copy_margin=True):\n        \"\"\"\n        Insert a new line above the current one.\n        \"\"\"\n        if copy_margin:\n            insert = self.document.leading_whitespace_in_current_line + '\\n'\n        else:\n            insert = '\\n'\n\n        self.cursor_position += self.document.get_start_of_line_position()\n        self.insert_text(insert)\n        self.cursor_position -= 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts a new line below the current one.", "response": "def insert_line_below(self, copy_margin=True):\n        \"\"\"\n        Insert a new line below the current one.\n        \"\"\"\n        if copy_margin:\n            insert = '\\n' + self.document.leading_whitespace_in_current_line\n        else:\n            insert = '\\n'\n\n        self.cursor_position += self.document.get_end_of_line_position()\n        self.insert_text(insert)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_text(self, data, overwrite=False, move_cursor=True, fire_event=True):\n        # Original text & cursor position.\n        otext = self.text\n        ocpos = self.cursor_position\n\n        # In insert/text mode.\n        if overwrite:\n            # Don't overwrite the newline itself. Just before the line ending,\n            # it should act like insert mode.\n            overwritten_text = otext[ocpos:ocpos + len(data)]\n            if '\\n' in overwritten_text:\n                overwritten_text = overwritten_text[:overwritten_text.find('\\n')]\n\n            self.text = otext[:ocpos] + data + otext[ocpos + len(overwritten_text):]\n        else:\n            self.text = otext[:ocpos] + data + otext[ocpos:]\n\n        if move_cursor:\n            self.cursor_position += len(data)\n\n        # Fire 'on_text_insert' event.\n        if fire_event:\n            self.on_text_insert.fire()", "response": "Insert text at cursor position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self):\n        # Don't call the validator again, if it was already called for the\n        # current input.\n        if self.validation_state != ValidationState.UNKNOWN:\n            return self.validation_state == ValidationState.VALID\n\n        # Validate first. If not valid, set validation exception.\n        if self.validator:\n            try:\n                self.validator.validate(self.document)\n            except ValidationError as e:\n                # Set cursor position (don't allow invalid values.)\n                cursor_position = e.cursor_position\n                self.cursor_position = min(max(0, cursor_position), len(self.text))\n\n                self.validation_state = ValidationState.INVALID\n                self.validation_error = e\n                return False\n\n        self.validation_state = ValidationState.VALID\n        self.validation_error = None\n        return True", "response": "Returns True if valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nappends the current input to the history.", "response": "def append_to_history(self):\n        \"\"\"\n        Append the current input to the history.\n        (Only if valid input.)\n        \"\"\"\n        # Validate first. If not valid, set validation exception.\n        if not self.validate():\n            return\n\n        # Save at the tail of the history. (But don't if the last entry the\n        # history is already the same.)\n        if self.text and (not len(self.history) or self.history[-1] != self.text):\n            self.history.append(self.text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute search on the current document.", "response": "def _search(self, search_state, include_current_position=False, count=1):\n        \"\"\"\n        Execute search. Return (working_index, cursor_position) tuple when this\n        search is applied. Returns `None` when this text cannot be found.\n        \"\"\"\n        assert isinstance(search_state, SearchState)\n        assert isinstance(count, int) and count > 0\n\n        text = search_state.text\n        direction = search_state.direction\n        ignore_case = search_state.ignore_case()\n\n        def search_once(working_index, document):\n            \"\"\"\n            Do search one time.\n            Return (working_index, document) or `None`\n            \"\"\"\n            if direction == IncrementalSearchDirection.FORWARD:\n                # Try find at the current input.\n                new_index = document.find(\n                   text, include_current_position=include_current_position,\n                   ignore_case=ignore_case)\n\n                if new_index is not None:\n                    return (working_index,\n                            Document(document.text, document.cursor_position + new_index))\n                else:\n                    # No match, go forward in the history. (Include len+1 to wrap around.)\n                    # (Here we should always include all cursor positions, because\n                    # it's a different line.)\n                    for i in range(working_index + 1, len(self._working_lines) + 1):\n                        i %= len(self._working_lines)\n\n                        document = Document(self._working_lines[i], 0)\n                        new_index = document.find(text, include_current_position=True,\n                                                  ignore_case=ignore_case)\n                        if new_index is not None:\n                            return (i, Document(document.text, new_index))\n            else:\n                # Try find at the current input.\n                new_index = document.find_backwards(\n                    text, ignore_case=ignore_case)\n\n                if new_index is not None:\n                    return (working_index,\n                            Document(document.text, document.cursor_position + new_index))\n                else:\n                    # No match, go back in the history. (Include -1 to wrap around.)\n                    for i in range(working_index - 1, -2, -1):\n                        i %= len(self._working_lines)\n\n                        document = Document(self._working_lines[i], len(self._working_lines[i]))\n                        new_index = document.find_backwards(\n                            text, ignore_case=ignore_case)\n                        if new_index is not None:\n                            return (i, Document(document.text, len(document.text) + new_index))\n\n        # Do 'count' search iterations.\n        working_index = self.working_index\n        document = self.document\n        for _ in range(count):\n            result = search_once(working_index, document)\n            if result is None:\n                return  # Nothing found.\n            else:\n                working_index, document = result\n\n        return (working_index, document.cursor_position)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a Document instance that has the text and cursor position for this search.", "response": "def document_for_search(self, search_state):\n        \"\"\"\n        Return a :class:`~prompt_toolkit.document.Document` instance that has\n        the text/cursor position for this search, if we would apply it. This\n        will be used in the\n        :class:`~prompt_toolkit.layout.controls.BufferControl` to display\n        feedback while searching.\n        \"\"\"\n        search_result = self._search(search_state, include_current_position=True)\n\n        if search_result is None:\n            return self.document\n        else:\n            working_index, cursor_position = search_result\n\n            # Keep selection, when `working_index` was not changed.\n            if working_index == self.working_index:\n                selection = self.selection_state\n            else:\n                selection = None\n\n            return Document(self._working_lines[working_index],\n                            cursor_position, selection=selection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the cursor position for this search.", "response": "def get_search_position(self, search_state, include_current_position=True, count=1):\n        \"\"\"\n        Get the cursor position for this search.\n        (This operation won't change the `working_index`. It's won't go through\n        the history. Vi text objects can't span multiple items.)\n        \"\"\"\n        search_result = self._search(\n            search_state, include_current_position=include_current_position, count=count)\n\n        if search_result is None:\n            return self.cursor_position\n        else:\n            working_index, cursor_position = search_result\n            return cursor_position"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens code in editor.", "response": "def open_in_editor(self, cli):\n        \"\"\"\n        Open code in editor.\n\n        :param cli: :class:`~prompt_toolkit.interface.CommandLineInterface`\n            instance.\n        \"\"\"\n        if self.read_only():\n            raise EditReadOnlyBuffer()\n\n        # Write to temporary file\n        descriptor, filename = tempfile.mkstemp(self.tempfile_suffix)\n        os.write(descriptor, self.text.encode('utf-8'))\n        os.close(descriptor)\n\n        # Open in editor\n        # (We need to use `cli.run_in_terminal`, because not all editors go to\n        # the alternate screen buffer, and some could influence the cursor\n        # position.)\n        succes = cli.run_in_terminal(lambda: self._open_file_in_editor(filename))\n\n        # Read content again.\n        if succes:\n            with open(filename, 'rb') as f:\n                text = f.read().decode('utf-8')\n\n                # Drop trailing newline. (Editors are supposed to add it at the\n                # end, but we don't need it.)\n                if text.endswith('\\n'):\n                    text = text[:-1]\n\n                self.document = Document(\n                    text=text,\n                    cursor_position=len(text))\n\n        # Clean up temp file.\n        os.remove(filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens a file in editor.", "response": "def _open_file_in_editor(self, filename):\n        \"\"\"\n        Call editor executable.\n\n        Return True when we received a zero return code.\n        \"\"\"\n        # If the 'VISUAL' or 'EDITOR' environment variable has been set, use that.\n        # Otherwise, fall back to the first available editor that we can find.\n        visual = os.environ.get('VISUAL')\n        editor = os.environ.get('EDITOR')\n\n        editors = [\n            visual,\n            editor,\n\n            # Order of preference.\n            '/usr/bin/editor',\n            '/usr/bin/nano',\n            '/usr/bin/pico',\n            '/usr/bin/vi',\n            '/usr/bin/emacs',\n        ]\n\n        for e in editors:\n            if e:\n                try:\n                    # Use 'shlex.split()', because $VISUAL can contain spaces\n                    # and quotes.\n                    returncode = subprocess.call(shlex.split(e) + [filename])\n                    return returncode == 0\n\n                except OSError:\n                    # Executable does not exist, try the next one.\n                    pass\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the event loop as a coroutine.", "response": "def run_as_coroutine(self, stdin, callbacks):\n        \"\"\"\n        The input 'event loop'.\n        \"\"\"\n        # Note: We cannot use \"yield from\", because this package also\n        #       installs on Python 2.\n        assert isinstance(callbacks, EventLoopCallbacks)\n\n        if self.closed:\n            raise Exception('Event loop already closed.')\n\n        timeout = AsyncioTimeout(INPUT_TIMEOUT, callbacks.input_timeout, self.loop)\n        self.running = True\n\n        try:\n            while self.running:\n                timeout.reset()\n\n                # Get keys\n                try:\n                    g = iter(self.loop.run_in_executor(None, self._console_input_reader.read))\n                    while True:\n                        yield next(g)\n                except StopIteration as e:\n                    keys = e.args[0]\n\n                # Feed keys to input processor.\n                for k in keys:\n                    callbacks.feed_key(k)\n        finally:\n            timeout.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an array of all the lines in the text.", "response": "def lines(self):\n        \"\"\"\n        Array of all the lines.\n        \"\"\"\n        # Cache, because this one is reused very often.\n        if self._cache.lines is None:\n            self._cache.lines = _ImmutableLineList(self.text.split('\\n'))\n\n        return self._cache.lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the start indexes of all the lines in the file.", "response": "def _line_start_indexes(self):\n        \"\"\"\n        Array pointing to the start indexes of all the lines.\n        \"\"\"\n        # Cache, because this is often reused. (If it is used, it's often used\n        # many times. And this has to be fast for editing big documents!)\n        if self._cache.line_indexes is None:\n            # Create list of line lengths.\n            line_lengths = map(len, self.lines)\n\n            # Calculate cumulative sums.\n            indexes = [0]\n            append = indexes.append\n            pos = 0\n\n            for line_length in line_lengths:\n                pos += line_length + 1\n                append(pos)\n\n            # Remove the last item. (This is not a new line.)\n            if len(indexes) > 1:\n                indexes.pop()\n\n            self._cache.line_indexes = indexes\n\n        return self._cache.line_indexes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef leading_whitespace_in_current_line(self):\n        current_line = self.current_line\n        length = len(current_line) - len(current_line.lstrip())\n        return current_line[:length]", "response": "The leading whitespace in the left margin of the current line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the column of the cursor.", "response": "def cursor_position_col(self):\n        \"\"\"\n        Current column. (0-based.)\n        \"\"\"\n        # (Don't use self.text_before_cursor to calculate this. Creating\n        # substrings and doing rsplit is too expensive for getting the cursor\n        # position.)\n        _, line_start_index = self._find_line_start_index(self.cursor_position)\n        return self.cursor_position - line_start_index"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the index of the first character on that line.", "response": "def _find_line_start_index(self, index):\n        \"\"\"\n        For the index of a character at a certain line, calculate the index of\n        the first character on that line.\n\n        Return (row, index) tuple.\n        \"\"\"\n        indexes = self._line_start_indexes\n\n        pos = bisect.bisect_right(indexes, index) - 1\n        return pos, indexes[pos]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate_index_to_position(self, index):\n        # Find start of this line.\n        row, row_index = self._find_line_start_index(index)\n        col = index - row_index\n\n        return row, col", "response": "Given an index for the text return the corresponding row and col tuple."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntranslate row and col tuple into a corresponding index.", "response": "def translate_row_col_to_index(self, row, col):\n        \"\"\"\n        Given a (row, col) tuple, return the corresponding index.\n        (Row and col params are 0-based.)\n\n        Negative row/col values are turned into zero.\n        \"\"\"\n        try:\n            result = self._line_start_indexes[row]\n            line = self.lines[row]\n        except IndexError:\n            if row < 0:\n                result = self._line_start_indexes[0]\n                line = self.lines[0]\n            else:\n                result = self._line_start_indexes[-1]\n                line = self.lines[-1]\n\n        result += max(0, min(col, len(line)))\n\n        # Keep in range. (len(self.text) is included, because the cursor can be\n        # right after the end of the text as well.)\n        result = max(0, min(result, len(self.text)))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_match_at_current_position(self, sub):\n        return self.text.find(sub, self.cursor_position) == self.cursor_position", "response": "True when this substring is found at the current position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the next occurrence of a string. Return None if nothing was found.", "response": "def find(self, sub, in_current_line=False, include_current_position=False,\n             ignore_case=False, count=1):\n        \"\"\"\n        Find `text` after the cursor, return position relative to the cursor\n        position. Return `None` if nothing was found.\n\n        :param count: Find the n-th occurance.\n        \"\"\"\n        assert isinstance(ignore_case, bool)\n\n        if in_current_line:\n            text = self.current_line_after_cursor\n        else:\n            text = self.text_after_cursor\n\n        if not include_current_position:\n            if len(text) == 0:\n                return  # (Otherwise, we always get a match for the empty string.)\n            else:\n                text = text[1:]\n\n        flags = re.IGNORECASE if ignore_case else 0\n        iterator = re.finditer(re.escape(sub), text, flags)\n\n        try:\n            for i, match in enumerate(iterator):\n                if i + 1 == count:\n                    if include_current_position:\n                        return match.start(0)\n                    else:\n                        return match.start(0) + 1\n        except StopIteration:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_all(self, sub, ignore_case=False):\n        flags = re.IGNORECASE if ignore_case else 0\n        return [a.start() for a in re.finditer(re.escape(sub), self.text, flags)]", "response": "Find all occurances of the substring. Return a list of absolute tuple containing the start positions of the substring."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the next n - th occurance of a string. Return None if nothing was found.", "response": "def find_backwards(self, sub, in_current_line=False, ignore_case=False, count=1):\n        \"\"\"\n        Find `text` before the cursor, return position relative to the cursor\n        position. Return `None` if nothing was found.\n\n        :param count: Find the n-th occurance.\n        \"\"\"\n        if in_current_line:\n            before_cursor = self.current_line_before_cursor[::-1]\n        else:\n            before_cursor = self.text_before_cursor[::-1]\n\n        flags = re.IGNORECASE if ignore_case else 0\n        iterator = re.finditer(re.escape(sub[::-1]), before_cursor, flags)\n\n        try:\n            for i, match in enumerate(iterator):\n                if i + 1 == count:\n                    return - match.start(0) - len(sub)\n        except StopIteration:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_word_before_cursor(self, WORD=False):\n        if self.text_before_cursor[-1:].isspace():\n            return ''\n        else:\n            return self.text_before_cursor[self.find_start_of_previous_word(WORD=WORD):]", "response": "Return the word before the cursor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_start_of_previous_word(self, count=1, WORD=False):\n        # Reverse the text before the cursor, in order to do an efficient\n        # backwards search.\n        text_before_cursor = self.text_before_cursor[::-1]\n\n        regex = _FIND_BIG_WORD_RE if WORD else _FIND_WORD_RE\n        iterator = regex.finditer(text_before_cursor)\n\n        try:\n            for i, match in enumerate(iterator):\n                if i + 1 == count:\n                    return - match.end(1)\n        except StopIteration:\n            pass", "response": "Find the start of the previous word in the text."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_boundaries_of_current_word(self, WORD=False, include_leading_whitespace=False,\n                                        include_trailing_whitespace=False):\n        \"\"\"\n        Return the relative boundaries (startpos, endpos) of the current word under the\n        cursor. (This is at the current line, because line boundaries obviously\n        don't belong to any word.)\n        If not on a word, this returns (0,0)\n        \"\"\"\n        text_before_cursor = self.current_line_before_cursor[::-1]\n        text_after_cursor = self.current_line_after_cursor\n\n        def get_regex(include_whitespace):\n            return {\n                (False, False): _FIND_CURRENT_WORD_RE,\n                (False, True): _FIND_CURRENT_WORD_INCLUDE_TRAILING_WHITESPACE_RE,\n                (True, False): _FIND_CURRENT_BIG_WORD_RE,\n                (True, True): _FIND_CURRENT_BIG_WORD_INCLUDE_TRAILING_WHITESPACE_RE,\n            }[(WORD, include_whitespace)]\n\n        match_before = get_regex(include_leading_whitespace).search(text_before_cursor)\n        match_after = get_regex(include_trailing_whitespace).search(text_after_cursor)\n\n        # When there is a match before and after, and we're not looking for\n        # WORDs, make sure that both the part before and after the cursor are\n        # either in the [a-zA-Z_] alphabet or not. Otherwise, drop the part\n        # before the cursor.\n        if not WORD and match_before and match_after:\n            c1 = self.text[self.cursor_position - 1]\n            c2 = self.text[self.cursor_position]\n            alphabet = string.ascii_letters + '0123456789_'\n\n            if (c1 in alphabet) != (c2 in alphabet):\n                match_before = None\n\n        return (\n            - match_before.end(1) if match_before else 0,\n            match_after.end(1) if match_after else 0\n        )", "response": "Return the relative boundaries of the current word under the cursor."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the word currently below the cursor.", "response": "def get_word_under_cursor(self, WORD=False):\n        \"\"\"\n        Return the word, currently below the cursor.\n        This returns an empty string when the cursor is on a whitespace region.\n        \"\"\"\n        start, end = self.find_boundaries_of_current_word(WORD=WORD)\n        return self.text[self.cursor_position + start: self.cursor_position + end]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an index relative to the cursor position pointing to the start of the next word. Return None if nothing was found.", "response": "def find_next_word_beginning(self, count=1, WORD=False):\n        \"\"\"\n        Return an index relative to the cursor position pointing to the start\n        of the next word. Return `None` if nothing was found.\n        \"\"\"\n        if count < 0:\n            return self.find_previous_word_beginning(count=-count, WORD=WORD)\n\n        regex = _FIND_BIG_WORD_RE if WORD else _FIND_WORD_RE\n        iterator = regex.finditer(self.text_after_cursor)\n\n        try:\n            for i, match in enumerate(iterator):\n                # Take first match, unless it's the word on which we're right now.\n                if i == 0 and match.start(1) == 0:\n                    count += 1\n\n                if i + 1 == count:\n                    return match.start(1)\n        except StopIteration:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an index relative to the cursor position pointing to the end of the next word. Return None if nothing was found.", "response": "def find_next_word_ending(self, include_current_position=False, count=1, WORD=False):\n        \"\"\"\n        Return an index relative to the cursor position pointing to the end\n        of the next word. Return `None` if nothing was found.\n        \"\"\"\n        if count < 0:\n            return self.find_previous_word_ending(count=-count, WORD=WORD)\n\n        if include_current_position:\n            text = self.text_after_cursor\n        else:\n            text = self.text_after_cursor[1:]\n\n        regex = _FIND_BIG_WORD_RE if WORD else _FIND_WORD_RE\n        iterable = regex.finditer(text)\n\n        try:\n            for i, match in enumerate(iterable):\n                if i + 1 == count:\n                    value = match.end(1)\n\n                    if include_current_position:\n                        return value\n                    else:\n                        return value + 1\n\n        except StopIteration:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_previous_word_beginning(self, count=1, WORD=False):\n        if count < 0:\n            return self.find_next_word_beginning(count=-count, WORD=WORD)\n\n        regex = _FIND_BIG_WORD_RE if WORD else _FIND_WORD_RE\n        iterator = regex.finditer(self.text_before_cursor[::-1])\n\n        try:\n            for i, match in enumerate(iterator):\n                if i + 1 == count:\n                    return - match.end(1)\n        except StopIteration:\n            pass", "response": "Return an index relative to the cursor position pointing to the start of the previous word. Return None if nothing was found."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_previous_word_ending(self, count=1, WORD=False):\n        if count < 0:\n            return self.find_next_word_ending(count=-count, WORD=WORD)\n\n        text_before_cursor = self.text_after_cursor[:1] + self.text_before_cursor[::-1]\n\n        regex = _FIND_BIG_WORD_RE if WORD else _FIND_WORD_RE\n        iterator = regex.finditer(text_before_cursor)\n\n        try:\n            for i, match in enumerate(iterator):\n                # Take first match, unless it's the word on which we're right now.\n                if i == 0 and match.start(1) == 0:\n                    count += 1\n\n                if i + 1 == count:\n                    return -match.start(1) + 1\n        except StopIteration:\n            pass", "response": "Return an index relative to the cursor position pointing to the end of the previous word. Return None if nothing was found."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_next_matching_line(self, match_func, count=1):\n        result = None\n\n        for index, line in enumerate(self.lines[self.cursor_position_row + 1:]):\n            if match_func(line):\n                result = 1 + index\n                count -= 1\n\n            if count == 0:\n                break\n\n        return result", "response": "Find the next matching line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_cursor_left_position(self, count=1):\n        if count < 0:\n            return self.get_cursor_right_position(-count)\n\n        return - min(self.cursor_position_col, count)", "response": "Returns the position of the cursor left."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_cursor_right_position(self, count=1):\n        if count < 0:\n            return self.get_cursor_left_position(-count)\n\n        return min(count, len(self.current_line_after_cursor))", "response": "Returns the position of the right of the cursor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the relative cursor position where we would be if the user pressed the arrow - up button.", "response": "def get_cursor_up_position(self, count=1, preferred_column=None):\n        \"\"\"\n        Return the relative cursor position (character index) where we would be if the\n        user pressed the arrow-up button.\n\n        :param preferred_column: When given, go to this column instead of\n                                 staying at the current column.\n        \"\"\"\n        assert count >= 1\n        column = self.cursor_position_col if preferred_column is None else preferred_column\n\n        return self.translate_row_col_to_index(\n            max(0, self.cursor_position_row - count), column) - self.cursor_position"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the relative cursor position where we would be if the user pressed the arrow - down button.", "response": "def get_cursor_down_position(self, count=1, preferred_column=None):\n        \"\"\"\n        Return the relative cursor position (character index) where we would be if the\n        user pressed the arrow-down button.\n\n        :param preferred_column: When given, go to this column instead of\n                                 staying at the current column.\n        \"\"\"\n        assert count >= 1\n        column = self.cursor_position_col if preferred_column is None else preferred_column\n\n        return self.translate_row_col_to_index(\n            self.cursor_position_row + count, column) - self.cursor_position"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_enclosing_bracket_right(self, left_ch, right_ch, end_pos=None):\n        if self.current_char == right_ch:\n            return 0\n\n        if end_pos is None:\n            end_pos = len(self.text)\n        else:\n            end_pos = min(len(self.text), end_pos)\n\n        stack = 1\n\n        # Look forward.\n        for i in range(self.cursor_position + 1, end_pos):\n            c = self.text[i]\n\n            if c == left_ch:\n                stack += 1\n            elif c == right_ch:\n                stack -= 1\n\n            if stack == 0:\n                return i - self.cursor_position", "response": "Find the right bracket enclosing current position. Return the relative position to the cursor position."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the left bracket enclosing current position. Return the relative position to the cursor position.", "response": "def find_enclosing_bracket_left(self, left_ch, right_ch, start_pos=None):\n        \"\"\"\n        Find the left bracket enclosing current position. Return the relative\n        position to the cursor position.\n\n        When `start_pos` is given, don't look past the position.\n        \"\"\"\n        if self.current_char == left_ch:\n            return 0\n\n        if start_pos is None:\n            start_pos = 0\n        else:\n            start_pos = max(0, start_pos)\n\n        stack = 1\n\n        # Look backward.\n        for i in range(self.cursor_position - 1, start_pos - 1, -1):\n            c = self.text[i]\n\n            if c == right_ch:\n                stack += 1\n            elif c == left_ch:\n                stack -= 1\n\n            if stack == 0:\n                return i - self.cursor_position"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn relative cursor position of matching bracket.", "response": "def find_matching_bracket_position(self, start_pos=None, end_pos=None):\n        \"\"\"\n        Return relative cursor position of matching [, (, { or < bracket.\n\n        When `start_pos` or `end_pos` are given. Don't look past the positions.\n        \"\"\"\n\n        # Look for a match.\n        for A, B in '()', '[]', '{}', '<>':\n            if self.current_char == A:\n                return self.find_enclosing_bracket_right(A, B, end_pos=end_pos) or 0\n            elif self.current_char == B:\n                return self.find_enclosing_bracket_left(A, B, start_pos=start_pos) or 0\n\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the absolute position of the start of the current line.", "response": "def get_start_of_line_position(self, after_whitespace=False):\n        \"\"\" Relative position for the start of this line. \"\"\"\n        if after_whitespace:\n            current_line = self.current_line\n            return len(current_line) - len(current_line.lstrip()) - self.cursor_position_col\n        else:\n            return - len(self.current_line_before_cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_column_cursor_position(self, column):\n        line_length = len(self.current_line)\n        current_column = self.cursor_position_col\n        column = max(0, min(line_length, column))\n\n        return column - current_column", "response": "Return the relative cursor position for this column at the current line."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef selection_range(self):  # XXX: shouldn't this return `None` if there is no selection???\n        if self.selection:\n            from_, to = sorted([self.cursor_position, self.selection.original_cursor_position])\n        else:\n            from_, to = self.cursor_position, self.cursor_position\n\n        return from_, to", "response": "Return the range of the current selection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of tuples for the selection.", "response": "def selection_ranges(self):\n        \"\"\"\n        Return a list of (from, to) tuples for the selection or none if nothing\n        was selected.  start and end position are always included in the\n        selection.\n\n        This will yield several (from, to) tuples in case of a BLOCK selection.\n        \"\"\"\n        if self.selection:\n            from_, to = sorted([self.cursor_position, self.selection.original_cursor_position])\n\n            if self.selection.type == SelectionType.BLOCK:\n                from_line, from_column = self.translate_index_to_position(from_)\n                to_line, to_column = self.translate_index_to_position(to)\n                from_column, to_column = sorted([from_column, to_column])\n                lines = self.lines\n\n                for l in range(from_line, to_line + 1):\n                    line_length = len(lines[l])\n                    if from_column < line_length:\n                        yield (self.translate_row_col_to_index(l, from_column),\n                               self.translate_row_col_to_index(l, min(line_length - 1, to_column)))\n            else:\n                # In case of a LINES selection, go to the start/end of the lines.\n                if self.selection.type == SelectionType.LINES:\n                    from_ = max(0, self.text.rfind('\\n', 0, from_) + 1)\n\n                    if self.text.find('\\n', to) >= 0:\n                        to = self.text.find('\\n', to)\n                    else:\n                        to = len(self.text) - 1\n\n                yield from_, to"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef selection_range_at_line(self, row):\n        if self.selection:\n            row_start = self.translate_row_col_to_index(row, 0)\n            row_end = self.translate_row_col_to_index(row, max(0, len(self.lines[row]) - 1))\n\n            from_, to = sorted([self.cursor_position, self.selection.original_cursor_position])\n\n            # Take the intersection of the current line and the selection.\n            intersection_start = max(row_start, from_)\n            intersection_end = min(row_end, to)\n\n            if intersection_start <= intersection_end:\n                if self.selection.type == SelectionType.LINES:\n                    intersection_start = row_start\n                    intersection_end = row_end\n                elif self.selection.type == SelectionType.BLOCK:\n                    _, col1 = self.translate_index_to_position(from_)\n                    _, col2 = self.translate_index_to_position(to)\n                    col1, col2 = sorted([col1, col2])\n                    intersection_start = self.translate_row_col_to_index(row, col1)\n                    intersection_end = self.translate_row_col_to_index(row, col2)\n\n                _, from_column = self.translate_index_to_position(intersection_start)\n                _, to_column = self.translate_index_to_position(intersection_end)\n\n                return from_column, to_column", "response": "Return the range of the current selection at the given line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tuple of the last two elements of the current document and the last two elements of the clipboard.", "response": "def cut_selection(self):\n        \"\"\"\n        Return a (:class:`.Document`, :class:`.ClipboardData`) tuple, where the\n        document represents the new document when the selection is cut, and the\n        clipboard data, represents whatever has to be put on the clipboard.\n        \"\"\"\n        if self.selection:\n            cut_parts = []\n            remaining_parts = []\n            new_cursor_position = self.cursor_position\n\n            last_to = 0\n            for from_, to in self.selection_ranges():\n                if last_to == 0:\n                    new_cursor_position = from_\n\n                remaining_parts.append(self.text[last_to:from_])\n                cut_parts.append(self.text[from_:to + 1])\n                last_to = to + 1\n\n            remaining_parts.append(self.text[last_to:])\n\n            cut_text = '\\n'.join(cut_parts)\n            remaining_text = ''.join(remaining_parts)\n\n            # In case of a LINES selection, don't include the trailing newline.\n            if self.selection.type == SelectionType.LINES and cut_text.endswith('\\n'):\n                cut_text = cut_text[:-1]\n\n            return (Document(text=remaining_text, cursor_position=new_cursor_position),\n                    ClipboardData(cut_text, self.selection.type))\n        else:\n            return self, ClipboardData('')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef paste_clipboard_data(self, data, paste_mode=PasteMode.EMACS, count=1):\n        assert isinstance(data, ClipboardData)\n        assert paste_mode in (PasteMode.VI_BEFORE, PasteMode.VI_AFTER, PasteMode.EMACS)\n\n        before = (paste_mode == PasteMode.VI_BEFORE)\n        after = (paste_mode == PasteMode.VI_AFTER)\n\n        if data.type == SelectionType.CHARACTERS:\n            if after:\n                new_text = (self.text[:self.cursor_position + 1] + data.text * count +\n                            self.text[self.cursor_position + 1:])\n            else:\n                new_text = self.text_before_cursor + data.text * count + self.text_after_cursor\n\n            new_cursor_position = self.cursor_position + len(data.text) * count\n            if before:\n                new_cursor_position -= 1\n\n        elif data.type == SelectionType.LINES:\n            l = self.cursor_position_row\n            if before:\n                lines = self.lines[:l] + [data.text] * count + self.lines[l:]\n                new_text = '\\n'.join(lines)\n                new_cursor_position = len(''.join(self.lines[:l])) + l\n            else:\n                lines = self.lines[:l + 1] + [data.text] * count + self.lines[l + 1:]\n                new_cursor_position = len(''.join(self.lines[:l + 1])) + l + 1\n                new_text = '\\n'.join(lines)\n\n        elif data.type == SelectionType.BLOCK:\n            lines = self.lines[:]\n            start_line = self.cursor_position_row\n            start_column = self.cursor_position_col + (0 if before else 1)\n\n            for i, line in enumerate(data.text.split('\\n')):\n                index = i + start_line\n                if index >= len(lines):\n                    lines.append('')\n\n                lines[index] = lines[index].ljust(start_column)\n                lines[index] = lines[index][:start_column] + line * count + lines[index][start_column:]\n\n            new_text = '\\n'.join(lines)\n            new_cursor_position = self.cursor_position + (0 if before else 1)\n\n        return Document(text=new_text, cursor_position=new_cursor_position)", "response": "Paste the clipboard data at the current cursor position."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the number of empty lines at the end of the document.", "response": "def empty_line_count_at_the_end(self):\n        \"\"\"\n        Return number of empty lines at the end of the document.\n        \"\"\"\n        count = 0\n        for line in self.lines[::-1]:\n            if not line or line.isspace():\n                count += 1\n            else:\n                break\n\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the start of the current paragraph.", "response": "def start_of_paragraph(self, count=1, before=False):\n        \"\"\"\n        Return the start of the current paragraph. (Relative cursor position.)\n        \"\"\"\n        def match_func(text):\n            return not text or text.isspace()\n\n        line_index = self.find_previous_matching_line(match_func=match_func, count=count)\n\n        if line_index:\n            add = 0 if before else 1\n            return min(0, self.get_cursor_up_position(count=-line_index) + add)\n        else:\n            return -self.cursor_position"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the end of the current paragraph.", "response": "def end_of_paragraph(self, count=1, after=False):\n        \"\"\"\n        Return the end of the current paragraph. (Relative cursor position.)\n        \"\"\"\n        def match_func(text):\n            return not text or text.isspace()\n\n        line_index = self.find_next_matching_line(match_func=match_func, count=count)\n\n        if line_index:\n            add = 0 if after else 1\n            return max(0, self.get_cursor_down_position(count=line_index) - add)\n        else:\n            return len(self.text_after_cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_after(self, text):\n        return Document(\n                text=self.text + text,\n                cursor_position=self.cursor_position,\n                selection=self.selection)", "response": "Insert text after the current document."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert text before the current document.", "response": "def insert_before(self, text):\n        \"\"\"\n        Create a new document, with this text inserted before the buffer.\n        It keeps selection ranges and cursor position in sync.\n        \"\"\"\n        selection_state = self.selection\n\n        if selection_state:\n            selection_state = SelectionState(\n                original_cursor_position=selection_state.original_cursor_position + len(text),\n                type=selection_state.type)\n\n        return Document(\n                text=text + self.text,\n                cursor_position=self.cursor_position + len(text),\n                selection=selection_state)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_key_bindings(\n        get_search_state=None,\n        enable_abort_and_exit_bindings=False,\n        enable_system_bindings=False,\n        enable_search=False,\n        enable_open_in_editor=False,\n        enable_extra_page_navigation=False,\n        enable_auto_suggest_bindings=False):\n    \"\"\"\n    Create a Registry object that contains the default key bindings.\n\n    :param enable_abort_and_exit_bindings: Filter to enable Ctrl-C and Ctrl-D.\n    :param enable_system_bindings: Filter to enable the system bindings (meta-!\n            prompt and Control-Z suspension.)\n    :param enable_search: Filter to enable the search bindings.\n    :param enable_open_in_editor: Filter to enable open-in-editor.\n    :param enable_open_in_editor: Filter to enable open-in-editor.\n    :param enable_extra_page_navigation: Filter for enabling extra page\n        navigation. (Bindings for up/down scrolling through long pages, like in\n        Emacs or Vi.)\n    :param enable_auto_suggest_bindings: Filter to enable fish-style suggestions.\n    \"\"\"\n\n    assert get_search_state is None or callable(get_search_state)\n\n    # Accept both Filters and booleans as input.\n    enable_abort_and_exit_bindings = to_cli_filter(enable_abort_and_exit_bindings)\n    enable_system_bindings = to_cli_filter(enable_system_bindings)\n    enable_search = to_cli_filter(enable_search)\n    enable_open_in_editor = to_cli_filter(enable_open_in_editor)\n    enable_extra_page_navigation = to_cli_filter(enable_extra_page_navigation)\n    enable_auto_suggest_bindings = to_cli_filter(enable_auto_suggest_bindings)\n\n    registry = MergedRegistry([\n        # Load basic bindings.\n        load_basic_bindings(),\n        load_mouse_bindings(),\n\n        ConditionalRegistry(load_abort_and_exit_bindings(),\n                            enable_abort_and_exit_bindings),\n\n        ConditionalRegistry(load_basic_system_bindings(),\n                            enable_system_bindings),\n\n        # Load emacs bindings.\n        load_emacs_bindings(),\n\n        ConditionalRegistry(load_emacs_open_in_editor_bindings(),\n                            enable_open_in_editor),\n\n        ConditionalRegistry(load_emacs_search_bindings(get_search_state=get_search_state),\n                            enable_search),\n\n        ConditionalRegistry(load_emacs_system_bindings(),\n                            enable_system_bindings),\n\n        ConditionalRegistry(load_extra_emacs_page_navigation_bindings(),\n                            enable_extra_page_navigation),\n\n        # Load Vi bindings.\n        load_vi_bindings(get_search_state=get_search_state),\n\n        ConditionalRegistry(load_vi_open_in_editor_bindings(),\n                            enable_open_in_editor),\n\n        ConditionalRegistry(load_vi_search_bindings(get_search_state=get_search_state),\n                            enable_search),\n\n        ConditionalRegistry(load_vi_system_bindings(),\n                            enable_system_bindings),\n\n        ConditionalRegistry(load_extra_vi_page_navigation_bindings(),\n                            enable_extra_page_navigation),\n\n        # Suggestion bindings.\n        # (This has to come at the end, because the Vi bindings also have an\n        # implementation for the \"right arrow\", but we really want the\n        # suggestion binding when a suggestion is available.)\n        ConditionalRegistry(load_auto_suggestion_bindings(),\n                            enable_auto_suggest_bindings),\n    ])\n\n    return registry", "response": "Load key bindings from the specified base classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a Registry object with the default key bindings for the prompt.", "response": "def load_key_bindings_for_prompt(**kw):\n    \"\"\"\n    Create a ``Registry`` object with the defaults key bindings for an input\n    prompt.\n\n    This activates the key bindings for abort/exit (Ctrl-C/Ctrl-D),\n    incremental search and auto suggestions.\n\n    (Not for full screen applications.)\n    \"\"\"\n    kw.setdefault('enable_abort_and_exit_bindings', True)\n    kw.setdefault('enable_search', True)\n    kw.setdefault('enable_auto_suggest_bindings', True)\n\n    return load_key_bindings(**kw)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and return an eventloop instance for an anon_input_list.", "response": "def create_eventloop(inputhook=None, recognize_win32_paste=True):\n    \"\"\"\n    Create and return an\n    :class:`~prompt_toolkit.eventloop.base.EventLoop` instance for a\n    :class:`~prompt_toolkit.interface.CommandLineInterface`.\n    \"\"\"\n    if is_windows():\n        from prompt_toolkit.eventloop.win32 import Win32EventLoop as Loop\n        return Loop(inputhook=inputhook, recognize_paste=recognize_win32_paste)\n    else:\n        from prompt_toolkit.eventloop.posix import PosixEventLoop as Loop\n        return Loop(inputhook=inputhook)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_output(stdout=None, true_color=False, ansi_colors_only=None):\n    stdout = stdout or sys.__stdout__\n    true_color = to_simple_filter(true_color)\n\n    if is_windows():\n        if is_conemu_ansi():\n            return ConEmuOutput(stdout)\n        else:\n            return Win32Output(stdout)\n    else:\n        term = os.environ.get('TERM', '')\n        if PY2:\n            term = term.decode('utf-8')\n\n        return Vt100_Output.from_pty(\n            stdout, true_color=true_color,\n            ansi_colors_only=ansi_colors_only, term=term)", "response": "Create an output instance for the commandline."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an asyncio eventloop for usage in a command line interface.", "response": "def create_asyncio_eventloop(loop=None):\n    \"\"\"\n    Returns an asyncio :class:`~prompt_toolkit.eventloop.EventLoop` instance\n    for usage in a :class:`~prompt_toolkit.interface.CommandLineInterface`. It\n    is a wrapper around an asyncio loop.\n\n    :param loop: The asyncio eventloop (or `None` if the default asyncioloop\n                 should be used.)\n    \"\"\"\n    # Inline import, to make sure the rest doesn't break on Python 2. (Where\n    # asyncio is not available.)\n    if is_windows():\n        from prompt_toolkit.eventloop.asyncio_win32 import Win32AsyncioEventLoop as AsyncioEventLoop\n    else:\n        from prompt_toolkit.eventloop.asyncio_posix import PosixAsyncioEventLoop as AsyncioEventLoop\n\n    return AsyncioEventLoop(loop)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new function that returns three new functions instead of the original function.", "response": "def _split_multiline_prompt(get_prompt_tokens):\n    \"\"\"\n    Take a `get_prompt_tokens` function and return three new functions instead.\n    One that tells whether this prompt consists of multiple lines; one that\n    returns the tokens to be shown on the lines above the input; and another\n    one with the tokens to be shown at the first line of the input.\n    \"\"\"\n    def has_before_tokens(cli):\n        for token, char in get_prompt_tokens(cli):\n            if '\\n' in char:\n                return True\n        return False\n\n    def before(cli):\n        result = []\n        found_nl = False\n        for token, char in reversed(explode_tokens(get_prompt_tokens(cli))):\n            if found_nl:\n                result.insert(0, (token, char))\n            elif char == '\\n':\n                found_nl = True\n        return result\n\n    def first_input_line(cli):\n        result = []\n        for token, char in reversed(explode_tokens(get_prompt_tokens(cli))):\n            if char == '\\n':\n                break\n            else:\n                result.insert(0, (token, char))\n        return result\n\n    return has_before_tokens, before, first_input_line"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_prompt_layout(message='', lexer=None, is_password=False,\n                         reserve_space_for_menu=8,\n                         get_prompt_tokens=None, get_continuation_tokens=None,\n                         get_rprompt_tokens=None,\n                         get_bottom_toolbar_tokens=None,\n                         display_completions_in_columns=False,\n                         extra_input_processors=None, multiline=False,\n                         wrap_lines=True):\n    \"\"\"\n    Create a :class:`.Container` instance for a prompt.\n\n    :param message: Text to be used as prompt.\n    :param lexer: :class:`~prompt_toolkit.layout.lexers.Lexer` to be used for\n        the highlighting.\n    :param is_password: `bool` or :class:`~prompt_toolkit.filters.CLIFilter`.\n        When True, display input as '*'.\n    :param reserve_space_for_menu: Space to be reserved for the menu. When >0,\n        make sure that a minimal height is allocated in the terminal, in order\n        to display the completion menu.\n    :param get_prompt_tokens: An optional callable that returns the tokens to be\n        shown in the menu. (To be used instead of a `message`.)\n    :param get_continuation_tokens: An optional callable that takes a\n        CommandLineInterface and width as input and returns a list of (Token,\n        text) tuples to be used for the continuation.\n    :param get_bottom_toolbar_tokens: An optional callable that returns the\n        tokens for a toolbar at the bottom.\n    :param display_completions_in_columns: `bool` or\n        :class:`~prompt_toolkit.filters.CLIFilter`. Display the completions in\n        multiple columns.\n    :param multiline: `bool` or :class:`~prompt_toolkit.filters.CLIFilter`.\n        When True, prefer a layout that is more adapted for multiline input.\n        Text after newlines is automatically indented, and search/arg input is\n        shown below the input, instead of replacing the prompt.\n    :param wrap_lines: `bool` or :class:`~prompt_toolkit.filters.CLIFilter`.\n        When True (the default), automatically wrap long lines instead of\n        scrolling horizontally.\n    \"\"\"\n    assert isinstance(message, text_type), 'Please provide a unicode string.'\n    assert get_bottom_toolbar_tokens is None or callable(get_bottom_toolbar_tokens)\n    assert get_prompt_tokens is None or callable(get_prompt_tokens)\n    assert get_rprompt_tokens is None or callable(get_rprompt_tokens)\n    assert not (message and get_prompt_tokens)\n\n    display_completions_in_columns = to_cli_filter(display_completions_in_columns)\n    multiline = to_cli_filter(multiline)\n\n    if get_prompt_tokens is None:\n        get_prompt_tokens = lambda _: [(Token.Prompt, message)]\n\n    has_before_tokens, get_prompt_tokens_1, get_prompt_tokens_2 = \\\n        _split_multiline_prompt(get_prompt_tokens)\n\n    # `lexer` is supposed to be a `Lexer` instance. But if a Pygments lexer\n    # class is given, turn it into a PygmentsLexer. (Important for\n    # backwards-compatibility.)\n    try:\n        if pygments_Lexer and issubclass(lexer, pygments_Lexer):\n            lexer = PygmentsLexer(lexer, sync_from_start=True)\n    except TypeError: # Happens when lexer is `None` or an instance of something else.\n        pass\n\n    # Create processors list.\n    input_processors = [\n        ConditionalProcessor(\n            # By default, only highlight search when the search\n            # input has the focus. (Note that this doesn't mean\n            # there is no search: the Vi 'n' binding for instance\n            # still allows to jump to the next match in\n            # navigation mode.)\n            HighlightSearchProcessor(preview_search=True),\n            HasFocus(SEARCH_BUFFER)),\n        HighlightSelectionProcessor(),\n        ConditionalProcessor(AppendAutoSuggestion(), HasFocus(DEFAULT_BUFFER) & ~IsDone()),\n        ConditionalProcessor(PasswordProcessor(), is_password),\n        DisplayMultipleCursors(DEFAULT_BUFFER),\n    ]\n\n    if extra_input_processors:\n        input_processors.extend(extra_input_processors)\n\n    # Show the prompt before the input (using the DefaultPrompt processor.\n    # This also replaces it with reverse-i-search and 'arg' when required.\n    # (Only for single line mode.)\n    # (DefaultPrompt should always be at the end of the processors.)\n    input_processors.append(ConditionalProcessor(\n        DefaultPrompt(get_prompt_tokens_2), ~multiline))\n\n    # Create bottom toolbar.\n    if get_bottom_toolbar_tokens:\n        toolbars = [ConditionalContainer(\n            Window(TokenListControl(get_bottom_toolbar_tokens,\n                                    default_char=Char(' ', Token.Toolbar)),\n                                    height=LayoutDimension.exact(1)),\n            filter=~IsDone() & RendererHeightIsKnown())]\n    else:\n        toolbars = []\n\n    def get_height(cli):\n        # If there is an autocompletion menu to be shown, make sure that our\n        # layout has at least a minimal height in order to display it.\n        if reserve_space_for_menu and not cli.is_done:\n            buff = cli.current_buffer\n\n            # Reserve the space, either when there are completions, or when\n            # `complete_while_typing` is true and we expect completions very\n            # soon.\n            if buff.complete_while_typing() or buff.complete_state is not None:\n                return LayoutDimension(min=reserve_space_for_menu)\n\n        return LayoutDimension()\n\n    # Create and return Container instance.\n    return HSplit([\n        # The main input, with completion menus floating on top of it.\n        FloatContainer(\n            HSplit([\n                ConditionalContainer(\n                    Window(\n                        TokenListControl(get_prompt_tokens_1),\n                        dont_extend_height=True),\n                    Condition(has_before_tokens)\n                ),\n                Window(\n                    BufferControl(\n                        input_processors=input_processors,\n                        lexer=lexer,\n                        # Enable preview_search, we want to have immediate feedback\n                        # in reverse-i-search mode.\n                        preview_search=True),\n                    get_height=get_height,\n                    left_margins=[\n                        # In multiline mode, use the window margin to display\n                        # the prompt and continuation tokens.\n                        ConditionalMargin(\n                            PromptMargin(get_prompt_tokens_2, get_continuation_tokens),\n                            filter=multiline\n                        )\n                    ],\n                    wrap_lines=wrap_lines,\n                ),\n            ]),\n            [\n                # Completion menus.\n                Float(xcursor=True,\n                      ycursor=True,\n                      content=CompletionsMenu(\n                          max_height=16,\n                          scroll_offset=1,\n                          extra_filter=HasFocus(DEFAULT_BUFFER) &\n                                       ~display_completions_in_columns)),\n                Float(xcursor=True,\n                      ycursor=True,\n                      content=MultiColumnCompletionsMenu(\n                          extra_filter=HasFocus(DEFAULT_BUFFER) &\n                                       display_completions_in_columns,\n                          show_meta=True)),\n\n                # The right prompt.\n                Float(right=0, top=0, hide_when_covering_content=True,\n                      content=_RPrompt(get_rprompt_tokens)),\n            ]\n        ),\n        ValidationToolbar(),\n        SystemToolbar(),\n\n        # In multiline mode, we use two toolbars for 'arg' and 'search'.\n        ConditionalContainer(ArgToolbar(), multiline),\n        ConditionalContainer(SearchToolbar(), multiline),\n    ] + toolbars)", "response": "Create a prompt layout for a given prompt."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_prompt_application(\n        message='',\n        multiline=False,\n        wrap_lines=True,\n        is_password=False,\n        vi_mode=False,\n        editing_mode=EditingMode.EMACS,\n        complete_while_typing=True,\n        enable_history_search=False,\n        lexer=None,\n        enable_system_bindings=False,\n        enable_open_in_editor=False,\n        validator=None,\n        completer=None,\n        reserve_space_for_menu=8,\n        auto_suggest=None,\n        style=None,\n        history=None,\n        clipboard=None,\n        get_prompt_tokens=None,\n        get_continuation_tokens=None,\n        get_rprompt_tokens=None,\n        get_bottom_toolbar_tokens=None,\n        display_completions_in_columns=False,\n        get_title=None,\n        mouse_support=False,\n        extra_input_processors=None,\n        key_bindings_registry=None,\n        on_abort=AbortAction.RAISE_EXCEPTION,\n        on_exit=AbortAction.RAISE_EXCEPTION,\n        accept_action=AcceptAction.RETURN_DOCUMENT,\n        erase_when_done=False,\n        default=''):\n    \"\"\"\n    Create an :class:`~Application` instance for a prompt.\n\n    (It is meant to cover 90% of the prompt use cases, where no extreme\n    customization is required. For more complex input, it is required to create\n    a custom :class:`~Application` instance.)\n\n    :param message: Text to be shown before the prompt.\n    :param mulitiline: Allow multiline input. Pressing enter will insert a\n                       newline. (This requires Meta+Enter to accept the input.)\n    :param wrap_lines: `bool` or :class:`~prompt_toolkit.filters.CLIFilter`.\n        When True (the default), automatically wrap long lines instead of\n        scrolling horizontally.\n    :param is_password: Show asterisks instead of the actual typed characters.\n    :param editing_mode: ``EditingMode.VI`` or ``EditingMode.EMACS``.\n    :param vi_mode: `bool`, if True, Identical to ``editing_mode=EditingMode.VI``.\n    :param complete_while_typing: `bool` or\n        :class:`~prompt_toolkit.filters.SimpleFilter`. Enable autocompletion\n        while typing.\n    :param enable_history_search: `bool` or\n        :class:`~prompt_toolkit.filters.SimpleFilter`. Enable up-arrow parting\n        string matching.\n    :param lexer: :class:`~prompt_toolkit.layout.lexers.Lexer` to be used for\n        the syntax highlighting.\n    :param validator: :class:`~prompt_toolkit.validation.Validator` instance\n        for input validation.\n    :param completer: :class:`~prompt_toolkit.completion.Completer` instance\n        for input completion.\n    :param reserve_space_for_menu: Space to be reserved for displaying the menu.\n        (0 means that no space needs to be reserved.)\n    :param auto_suggest: :class:`~prompt_toolkit.auto_suggest.AutoSuggest`\n        instance for input suggestions.\n    :param style: :class:`.Style` instance for the color scheme.\n    :param enable_system_bindings: `bool` or\n        :class:`~prompt_toolkit.filters.CLIFilter`. Pressing Meta+'!' will show\n        a system prompt.\n    :param enable_open_in_editor: `bool` or\n        :class:`~prompt_toolkit.filters.CLIFilter`. Pressing 'v' in Vi mode or\n        C-X C-E in emacs mode will open an external editor.\n    :param history: :class:`~prompt_toolkit.history.History` instance.\n    :param clipboard: :class:`~prompt_toolkit.clipboard.base.Clipboard` instance.\n        (e.g. :class:`~prompt_toolkit.clipboard.in_memory.InMemoryClipboard`)\n    :param get_bottom_toolbar_tokens: Optional callable which takes a\n        :class:`~prompt_toolkit.interface.CommandLineInterface` and returns a\n        list of tokens for the bottom toolbar.\n    :param display_completions_in_columns: `bool` or\n        :class:`~prompt_toolkit.filters.CLIFilter`. Display the completions in\n        multiple columns.\n    :param get_title: Callable that returns the title to be displayed in the\n        terminal.\n    :param mouse_support: `bool` or :class:`~prompt_toolkit.filters.CLIFilter`\n        to enable mouse support.\n    :param default: The default text to be shown in the input buffer. (This can\n        be edited by the user.)\n    \"\"\"\n    if key_bindings_registry is None:\n        key_bindings_registry = load_key_bindings_for_prompt(\n            enable_system_bindings=enable_system_bindings,\n            enable_open_in_editor=enable_open_in_editor)\n\n    # Ensure backwards-compatibility, when `vi_mode` is passed.\n    if vi_mode:\n        editing_mode = EditingMode.VI\n\n    # Make sure that complete_while_typing is disabled when enable_history_search\n    # is enabled. (First convert to SimpleFilter, to avoid doing bitwise operations\n    # on bool objects.)\n    complete_while_typing = to_simple_filter(complete_while_typing)\n    enable_history_search = to_simple_filter(enable_history_search)\n    multiline = to_simple_filter(multiline)\n\n    complete_while_typing = complete_while_typing & ~enable_history_search\n\n    # Accept Pygments styles as well for backwards compatibility.\n    try:\n        if pygments_Style and issubclass(style, pygments_Style):\n            style = style_from_dict(style.styles)\n    except TypeError:  # Happens when style is `None` or an instance of something else.\n        pass\n\n    # Create application\n    return Application(\n        layout=create_prompt_layout(\n            message=message,\n            lexer=lexer,\n            is_password=is_password,\n            reserve_space_for_menu=(reserve_space_for_menu if completer is not None else 0),\n            multiline=Condition(lambda cli: multiline()),\n            get_prompt_tokens=get_prompt_tokens,\n            get_continuation_tokens=get_continuation_tokens,\n            get_rprompt_tokens=get_rprompt_tokens,\n            get_bottom_toolbar_tokens=get_bottom_toolbar_tokens,\n            display_completions_in_columns=display_completions_in_columns,\n            extra_input_processors=extra_input_processors,\n            wrap_lines=wrap_lines),\n        buffer=Buffer(\n            enable_history_search=enable_history_search,\n            complete_while_typing=complete_while_typing,\n            is_multiline=multiline,\n            history=(history or InMemoryHistory()),\n            validator=validator,\n            completer=completer,\n            auto_suggest=auto_suggest,\n            accept_action=accept_action,\n            initial_document=Document(default),\n        ),\n        style=style or DEFAULT_STYLE,\n        clipboard=clipboard,\n        key_bindings_registry=key_bindings_registry,\n        get_title=get_title,\n        mouse_support=mouse_support,\n        editing_mode=editing_mode,\n        erase_when_done=erase_when_done,\n        reverse_vi_search_direction=True,\n        on_abort=on_abort,\n        on_exit=on_exit)", "response": "Create a prompt application."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprompt the user for input and return it.", "response": "def prompt(message='', **kwargs):\n    \"\"\"\n    Get input from the user and return it.\n\n    This is a wrapper around a lot of ``prompt_toolkit`` functionality and can\n    be a replacement for `raw_input`. (or GNU readline.)\n\n    If you want to keep your history across several calls, create one\n    :class:`~prompt_toolkit.history.History` instance and pass it every time.\n\n    This function accepts many keyword arguments. Except for the following,\n    they are a proxy to the arguments of :func:`.create_prompt_application`.\n\n    :param patch_stdout: Replace ``sys.stdout`` by a proxy that ensures that\n            print statements from other threads won't destroy the prompt. (They\n            will be printed above the prompt instead.)\n    :param return_asyncio_coroutine: When True, return a asyncio coroutine. (Python >3.3)\n    :param true_color: When True, use 24bit colors instead of 256 colors.\n    :param refresh_interval: (number; in seconds) When given, refresh the UI\n        every so many seconds.\n    \"\"\"\n    patch_stdout = kwargs.pop('patch_stdout', False)\n    return_asyncio_coroutine = kwargs.pop('return_asyncio_coroutine', False)\n    true_color = kwargs.pop('true_color', False)\n    refresh_interval = kwargs.pop('refresh_interval', 0)\n    eventloop = kwargs.pop('eventloop', None)\n\n    application = create_prompt_application(message, **kwargs)\n\n    return run_application(application,\n        patch_stdout=patch_stdout,\n        return_asyncio_coroutine=return_asyncio_coroutine,\n        true_color=true_color,\n        refresh_interval=refresh_interval,\n        eventloop=eventloop)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_application(\n        application, patch_stdout=False, return_asyncio_coroutine=False,\n        true_color=False, refresh_interval=0, eventloop=None):\n    \"\"\"\n    Run a prompt toolkit application.\n\n    :param patch_stdout: Replace ``sys.stdout`` by a proxy that ensures that\n            print statements from other threads won't destroy the prompt. (They\n            will be printed above the prompt instead.)\n    :param return_asyncio_coroutine: When True, return a asyncio coroutine. (Python >3.3)\n    :param true_color: When True, use 24bit colors instead of 256 colors.\n    :param refresh_interval: (number; in seconds) When given, refresh the UI\n        every so many seconds.\n    \"\"\"\n    assert isinstance(application, Application)\n\n    if return_asyncio_coroutine:\n        eventloop = create_asyncio_eventloop()\n    else:\n        eventloop = eventloop or create_eventloop()\n\n    # Create CommandLineInterface.\n    cli = CommandLineInterface(\n        application=application,\n        eventloop=eventloop,\n        output=create_output(true_color=true_color))\n\n    # Set up refresh interval.\n    if refresh_interval:\n        done = [False]\n        def start_refresh_loop(cli):\n            def run():\n                while not done[0]:\n                    time.sleep(refresh_interval)\n                    cli.request_redraw()\n            t = threading.Thread(target=run)\n            t.daemon = True\n            t.start()\n\n        def stop_refresh_loop(cli):\n            done[0] = True\n\n        cli.on_start += start_refresh_loop\n        cli.on_stop += stop_refresh_loop\n\n    # Replace stdout.\n    patch_context = cli.patch_stdout_context(raw=True) if patch_stdout else DummyContext()\n\n    # Read input and return it.\n    if return_asyncio_coroutine:\n        # Create an asyncio coroutine and call it.\n        exec_context = {'patch_context': patch_context, 'cli': cli,\n                        'Document': Document}\n        exec_(textwrap.dedent('''\n        def prompt_coro():\n            # Inline import, because it slows down startup when asyncio is not\n            # needed.\n            import asyncio\n\n            @asyncio.coroutine\n            def run():\n                with patch_context:\n                    result = yield from cli.run_async()\n\n                if isinstance(result, Document):  # Backwards-compatibility.\n                    return result.text\n                return result\n            return run()\n        '''), exec_context)\n\n        return exec_context['prompt_coro']()\n    else:\n        try:\n            with patch_context:\n                result = cli.run()\n\n            if isinstance(result, Document):  # Backwards-compatibility.\n                return result.text\n            return result\n        finally:\n            eventloop.close()", "response": "Runs a prompt toolkit application."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a confirmation application that returns True or False.", "response": "def create_confirm_application(message):\n    \"\"\"\n    Create a confirmation `Application` that returns True/False.\n    \"\"\"\n    registry = Registry()\n\n    @registry.add_binding('y')\n    @registry.add_binding('Y')\n    def _(event):\n        event.cli.buffers[DEFAULT_BUFFER].text = 'y'\n        event.cli.set_return_value(True)\n\n    @registry.add_binding('n')\n    @registry.add_binding('N')\n    @registry.add_binding(Keys.ControlC)\n    def _(event):\n        event.cli.buffers[DEFAULT_BUFFER].text = 'n'\n        event.cli.set_return_value(False)\n\n    return create_prompt_application(message, key_bindings_registry=registry)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay a confirmation prompt.", "response": "def confirm(message='Confirm (y or n) '):\n    \"\"\"\n    Display a confirmation prompt.\n    \"\"\"\n    assert isinstance(message, text_type)\n\n    app = create_confirm_application(message)\n    return run_application(app)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints a list of ( Token text ) tuples in the given style to the output.", "response": "def print_tokens(tokens, style=None, true_color=False, file=None):\n    \"\"\"\n    Print a list of (Token, text) tuples in the given style to the output.\n    E.g.::\n\n        style = style_from_dict({\n            Token.Hello: '#ff0066',\n            Token.World: '#884444 italic',\n        })\n        tokens = [\n            (Token.Hello, 'Hello'),\n            (Token.World, 'World'),\n        ]\n        print_tokens(tokens, style=style)\n\n    :param tokens: List of ``(Token, text)`` tuples.\n    :param style: :class:`.Style` instance for the color scheme.\n    :param true_color: When True, use 24bit colors instead of 256 colors.\n    :param file: The output file. This can be `sys.stdout` or `sys.stderr`.\n    \"\"\"\n    if style is None:\n        style = DEFAULT_STYLE\n    assert isinstance(style, Style)\n\n    output = create_output(true_color=true_color, stdout=file)\n    renderer_print_tokens(output, tokens, style)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_ansi_color_dict(color_cls):\n    \" Create a table that maps the 16 named ansi colors to their Windows code. \"\n    return {\n        'ansidefault':   color_cls.BLACK,\n        'ansiblack':     color_cls.BLACK,\n        'ansidarkgray':  color_cls.BLACK | color_cls.INTENSITY,\n        'ansilightgray': color_cls.GRAY,\n        'ansiwhite':     color_cls.GRAY | color_cls.INTENSITY,\n        \n        # Low intensity.\n        'ansidarkred':     color_cls.RED,\n        'ansidarkgreen':   color_cls.GREEN,\n        'ansibrown':       color_cls.YELLOW,\n        'ansidarkblue':    color_cls.BLUE,\n        'ansipurple':      color_cls.MAGENTA,\n        'ansiteal':        color_cls.CYAN,\n\n        # High intensity.\n        'ansired':        color_cls.RED | color_cls.INTENSITY,\n        'ansigreen':      color_cls.GREEN | color_cls.INTENSITY,\n        'ansiyellow':     color_cls.YELLOW | color_cls.INTENSITY,\n        'ansiblue':       color_cls.BLUE | color_cls.INTENSITY,\n        'ansifuchsia':    color_cls.MAGENTA | color_cls.INTENSITY,\n        'ansiturquoise':  color_cls.CYAN | color_cls.INTENSITY,\n    }", "response": "Create a table that maps the 16 named ansi colors to their Windows code."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nflushes and call win API function.", "response": "def _winapi(self, func, *a, **kw):\n        \"\"\"\n        Flush and call win API function.\n        \"\"\"\n        self.flush()\n\n        if _DEBUG_RENDER_OUTPUT:\n            self.LOG.write(('%r' % func.__name__).encode('utf-8') + b'\\n')\n            self.LOG.write(b'     ' + ', '.join(['%r' % i for i in a]).encode('utf-8') + b'\\n')\n            self.LOG.write(b'     ' + ', '.join(['%r' % type(i) for i in a]).encode('utf-8') + b'\\n')\n            self.LOG.flush()\n\n        try:\n            return func(*a, **kw)\n        except ArgumentError as e:\n            if _DEBUG_RENDER_OUTPUT:\n                self.LOG.write(('    Error in %r %r %s\\n' % (func.__name__, e, e)).encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the screen buffer info for the current console entry.", "response": "def get_win32_screen_buffer_info(self):\n        \"\"\"\n        Return Screen buffer info.\n        \"\"\"\n        # NOTE: We don't call the `GetConsoleScreenBufferInfo` API through\n        #     `self._winapi`. Doing so causes Python to crash on certain 64bit\n        #     Python versions. (Reproduced with 64bit Python 2.7.6, on Windows\n        #     10). It is not clear why. Possibly, it has to do with passing\n        #     these objects as an argument, or through *args.\n\n        # The Python documentation contains the following - possibly related - warning:\n        #     ctypes does not support passing unions or structures with\n        #     bit-fields to functions by value. While this may work on 32-bit\n        #     x86, it's not guaranteed by the library to work in the general\n        #     case. Unions and structures with bit-fields should always be\n        #     passed to functions by pointer.\n\n        # Also see:\n        #    - https://github.com/ipython/ipython/issues/10070\n        #    - https://github.com/jonathanslenders/python-prompt-toolkit/issues/406\n        #    - https://github.com/jonathanslenders/python-prompt-toolkit/issues/86\n\n        self.flush()\n        sbinfo = CONSOLE_SCREEN_BUFFER_INFO()\n        success = windll.kernel32.GetConsoleScreenBufferInfo(self.hconsole, byref(sbinfo))\n\n        # success = self._winapi(windll.kernel32.GetConsoleScreenBufferInfo,\n        #                        self.hconsole, byref(sbinfo))\n\n        if success:\n            return sbinfo\n        else:\n            raise NoConsoleScreenBufferError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset_attributes(self):\n        \" Reset the console foreground/background color. \"\n        self._winapi(windll.kernel32.SetConsoleTextAttribute, self.hconsole,\n                     self.default_attrs)", "response": "Reset the console foreground / background color."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite to output stream and flush.", "response": "def flush(self):\n        \"\"\"\n        Write to output stream and flush.\n        \"\"\"\n        if not self._buffer:\n            # Only flush stdout buffer. (It could be that Python still has\n            # something in its buffer. -- We want to be sure to print that in\n            # the correct color.)\n            self.stdout.flush()\n            return\n\n        data = ''.join(self._buffer)\n\n        if _DEBUG_RENDER_OUTPUT:\n            self.LOG.write(('%r' % data).encode('utf-8') + b'\\n')\n            self.LOG.flush()\n\n        # Print characters one by one. This appears to be the best soluton\n        # in oder to avoid traces of vertical lines when the completion\n        # menu disappears.\n        for b in data:\n            written = DWORD()\n\n            retval = windll.kernel32.WriteConsoleW(self.hconsole, b, 1, byref(written), None)\n            assert retval != 0\n\n        self._buffer = []"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscrolls the console buffer to the left with the cursor at the bottom.", "response": "def scroll_buffer_to_prompt(self):\n        \"\"\"\n        To be called before drawing the prompt. This should scroll the console\n        to left, with the cursor at the bottom (if possible).\n        \"\"\"\n        # Get current window size\n        info = self.get_win32_screen_buffer_info()\n        sr = info.srWindow\n        cursor_pos = info.dwCursorPosition\n\n        result = SMALL_RECT()\n\n        # Scroll to the left.\n        result.Left = 0\n        result.Right = sr.Right - sr.Left\n\n        # Scroll vertical\n        win_height = sr.Bottom - sr.Top\n        if 0 < sr.Bottom - cursor_pos.Y < win_height - 1:\n            # no vertical scroll if cursor already on the screen\n            result.Bottom = sr.Bottom\n        else:\n            result.Bottom = max(win_height, cursor_pos.Y)\n        result.Top = result.Bottom - win_height\n\n        # Scroll API\n        self._winapi(windll.kernel32.SetConsoleWindowInfo, self.hconsole, True, byref(result))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngo to alternate screen buffer.", "response": "def enter_alternate_screen(self):\n        \"\"\"\n        Go to alternate screen buffer.\n        \"\"\"\n        if not self._in_alternate_screen:\n            GENERIC_READ = 0x80000000\n            GENERIC_WRITE = 0x40000000\n\n            # Create a new console buffer and activate that one.\n            handle = self._winapi(windll.kernel32.CreateConsoleScreenBuffer, GENERIC_READ|GENERIC_WRITE,\n                                  DWORD(0), None, DWORD(1), None)\n\n            self._winapi(windll.kernel32.SetConsoleActiveScreenBuffer, handle)\n            self.hconsole = handle\n            self._in_alternate_screen = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquitting the alternate screen.", "response": "def quit_alternate_screen(self):\n        \"\"\"\n        Make stdout again the active buffer.\n        \"\"\"\n        if self._in_alternate_screen:\n            stdout = self._winapi(windll.kernel32.GetStdHandle, STD_OUTPUT_HANDLE)\n            self._winapi(windll.kernel32.SetConsoleActiveScreenBuffer, stdout)\n            self._winapi(windll.kernel32.CloseHandle, self.hconsole)\n            self.hconsole = stdout\n            self._in_alternate_screen = False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef win32_refresh_window(cls):\n        # Get console handle\n        handle = windll.kernel32.GetConsoleWindow()\n\n        RDW_INVALIDATE = 0x0001\n        windll.user32.RedrawWindow(handle, None, None, c_uint(RDW_INVALIDATE))", "response": "Refresh the whole Window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_color_table():\n        FG = FOREGROUND_COLOR\n        BG = BACKROUND_COLOR\n\n        return [\n            (0x00, 0x00, 0x00, FG.BLACK, BG.BLACK),\n            (0x00, 0x00, 0xaa, FG.BLUE, BG.BLUE),\n            (0x00, 0xaa, 0x00, FG.GREEN, BG.GREEN),\n            (0x00, 0xaa, 0xaa, FG.CYAN, BG.CYAN),\n            (0xaa, 0x00, 0x00, FG.RED, BG.RED),\n            (0xaa, 0x00, 0xaa, FG.MAGENTA, BG.MAGENTA),\n            (0xaa, 0xaa, 0x00, FG.YELLOW, BG.YELLOW),\n            (0x88, 0x88, 0x88, FG.GRAY, BG.GRAY),\n\n            (0x44, 0x44, 0xff, FG.BLUE | FG.INTENSITY, BG.BLUE | BG.INTENSITY),\n            (0x44, 0xff, 0x44, FG.GREEN | FG.INTENSITY, BG.GREEN | BG.INTENSITY),\n            (0x44, 0xff, 0xff, FG.CYAN | FG.INTENSITY, BG.CYAN | BG.INTENSITY),\n            (0xff, 0x44, 0x44, FG.RED | FG.INTENSITY, BG.RED | BG.INTENSITY),\n            (0xff, 0x44, 0xff, FG.MAGENTA | FG.INTENSITY, BG.MAGENTA | BG.INTENSITY),\n            (0xff, 0xff, 0x44, FG.YELLOW | FG.INTENSITY, BG.YELLOW | BG.INTENSITY),\n\n            (0x44, 0x44, 0x44, FG.BLACK | FG.INTENSITY, BG.BLACK | BG.INTENSITY),\n            (0xff, 0xff, 0xff, FG.GRAY | FG.INTENSITY, BG.GRAY | BG.INTENSITY),\n        ]", "response": "Build an RGB - to - 256 color conversion table from a set of color codes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the color for use in the `windll.kernel32.SetConsoleTextAttribute` API call. :param fg_color: Foreground as text. E.g. 'ffffff' or 'red'", "response": "def lookup_fg_color(self, fg_color):\n        \"\"\"\n        Return the color for use in the\n        `windll.kernel32.SetConsoleTextAttribute` API call.\n\n        :param fg_color: Foreground as text. E.g. 'ffffff' or 'red'\n        \"\"\"\n        # Foreground.\n        if fg_color in FG_ANSI_COLORS:\n            return FG_ANSI_COLORS[fg_color]\n        else:\n            return self._color_indexes(fg_color)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lookup_bg_color(self, bg_color):\n        # Background.\n        if bg_color in BG_ANSI_COLORS:\n            return BG_ANSI_COLORS[bg_color]\n        else:\n            return self._color_indexes(bg_color)[1]", "response": "Return the color for use in the the\n        API call."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nested_shape(array_or_tuple):\n    if hasattr(array_or_tuple, 'size'):\n        # pytorch tensors use V.size() to get size of tensor\n        return list(array_or_tuple.size())\n    elif hasattr(array_or_tuple, 'get_shape'):\n        # tensorflow uses V.get_shape() to get size of tensor\n        return array_or_tuple.get_shape().as_list()\n    elif hasattr(array_or_tuple, 'shape'):\n        return array_or_tuple.shape\n\n    try:\n        # treat object as iterable\n        return [nested_shape(item) for item in list(array_or_tuple)]\n    except TypeError:\n        # object is not actually iterable\n        # LB: Maybe we should throw an error?\n        return []", "response": "Figures out the shape of a nested array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the log_track with the current log_track.", "response": "def log_track_update(log_track):\n    \"\"\"count (log_track[0]) up to threshold (log_track[1]), reset count (log_track[0]) and return true when reached\n    \"\"\"\n    log_track[LOG_TRACK_COUNT] += 1\n    if log_track[LOG_TRACK_COUNT] < log_track[LOG_TRACK_THRESHOLD]:\n        return False\n    log_track[LOG_TRACK_COUNT] = 0\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log_tensor_stats(self, tensor, name):\n        # TODO Handle the case of duplicate names.\n\n        if (isinstance(tensor, tuple) or isinstance(tensor, list)):\n            while (isinstance(tensor, tuple) or isinstance(tensor, list)) and (isinstance(tensor[0], tuple) or isinstance(tensor[0], list)):\n                tensor = [item for sublist in tensor for item in sublist]\n            tensor = torch.cat([t.view(-1) for t in tensor])\n\n        # checking for inheritance from _TensorBase didn't work for some reason\n        if not hasattr(tensor, 'shape'):\n            cls = type(tensor)\n            raise TypeError('Expected Tensor, not {}.{}'.format(\n                cls.__module__, cls.__name__))\n        history = self._history()\n        if history is None or not history.compute:\n            return\n\n        # HalfTensors on cpu do not support view(), upconvert to 32bit\n        if isinstance(tensor, torch.HalfTensor):\n            tensor = tensor.clone().type(torch.FloatTensor).detach()\n\n        flat = tensor.view(-1)\n\n        # For pytorch 0.3 we use unoptimized numpy histograms (detach is new in 0.4)\n        if not hasattr(flat, \"detach\"):\n            tensor = flat.cpu().clone().numpy()\n            history.row.update({\n                name: wandb.Histogram(tensor)\n            })\n            return\n\n        if flat.is_cuda:\n            # TODO(jhr): see if pytorch will accept something upstream to check cuda support for ops\n            # until then, we are going to have to catch a specific exception to check for histc support.\n            if self._is_cuda_histc_supported is None:\n                self._is_cuda_histc_supported = True\n                check = torch.cuda.FloatTensor(1).fill_(0)\n                try:\n                    check = flat.histc(bins=self._num_bins)\n                except RuntimeError as e:\n                    # Only work around missing support with specific exception\n                    if str(e).startswith(\"_th_histc is not implemented\"):\n                        self._is_cuda_histc_supported = False\n\n            if not self._is_cuda_histc_supported:\n                flat = flat.cpu().clone().detach()\n\n            # As of torch 1.0.1.post2+nightly, float16 cuda summary ops are not supported (convert to float32)\n            if isinstance(flat, torch.cuda.HalfTensor):\n                flat = flat.clone().type(torch.cuda.FloatTensor).detach()\n\n        if isinstance(flat, torch.HalfTensor):\n            flat = flat.clone().type(torch.FloatTensor).detach()\n\n        tmin = flat.min().item()\n        tmax = flat.max().item()\n        tensor = flat.histc(bins=self._num_bins, min=tmin, max=tmax)\n        tensor = tensor.cpu().clone().detach()\n        bins = torch.linspace(tmin, tmax, steps=self._num_bins + 1)\n\n        history.row.update({\n            name: wandb.Histogram(np_histogram=(\n                tensor.tolist(), bins.tolist()))\n        })", "response": "Add distribution statistics on a tensor s elements to the current History entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog a Variable s gradient s distribution statistics next time backward is called on it.", "response": "def _hook_variable_gradient_stats(self, var, name, log_track):\n        \"\"\"Logs a Variable's gradient's distribution statistics next time backward()\n        is called on it.\n        \"\"\"\n        if not isinstance(var, torch.autograd.Variable):\n            cls = type(var)\n            raise TypeError('Expected torch.Variable, not {}.{}'.format(\n                cls.__module__, cls.__name__))\n\n        handle = self._hook_handles.get(name)\n        if handle is not None and self._torch_hook_handle_is_valid(handle):\n            raise ValueError(\n                'A hook has already been set under name \"{}\"'.format(name))\n\n        def _callback(grad, log_track):\n            if not log_track_update(log_track):\n                return\n            self.log_tensor_stats(grad.data, name)\n\n        handle = var.register_hook(lambda grad: _callback(grad, log_track))\n        self._hook_handles[name] = handle\n        return handle"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_torch_layers(cls, module_graph, variable):\n        # TODO: We're currently not using this, but I left it here incase we want to resurrect! - CVP\n        torch = util.get_module(\"torch\", \"Could not import torch\")\n\n        module_nodes_by_hash = {id(n): n for n in module_graph.nodes}\n        module_parameter_nodes = [\n            n for n in module_graph.nodes if isinstance(n.obj, torch.nn.Parameter)]\n\n        names_by_pid = {id(n.obj): n.name for n in module_parameter_nodes}\n\n        reachable_param_nodes = module_graph[0].reachable_descendents()\n        reachable_params = {}\n        module_reachable_params = {}\n        names = {}\n        for pid, reachable_nodes in reachable_param_nodes.items():\n            node = module_nodes_by_hash[pid]\n            if not isinstance(node.obj, torch.nn.Module):\n                continue\n            module = node.obj\n            reachable_params = {}  # by object id\n            module_reachable_params[id(module)] = reachable_params\n            names[node.name] = set()\n            for reachable_hash in reachable_nodes:\n                reachable = module_nodes_by_hash[reachable_hash]\n                if isinstance(reachable.obj, torch.nn.Parameter):\n                    param = reachable.obj\n                    reachable_params[id(param)] = param\n                    names[node.name].add(names_by_pid[id(param)])\n\n        # we look for correspondences between sets of parameters used in subtrees of the\n        # computation graph and sets of parameters contained in subtrees of the module\n        # graph\n        node_depths = {id(n): d for n, d in module_graph[0].descendent_bfs()}\n        parameter_module_names = {}\n        parameter_modules = {}\n        for param_node in (n for n in module_graph.nodes if isinstance(n.obj, torch.nn.Parameter)):\n            pid = id(param_node.obj)\n            best_node = None\n            best_depth = None\n            best_reachable_params = None\n            for node in module_graph.nodes:\n                if not isinstance(node.obj, torch.nn.Module):\n                    continue\n                module = node.obj\n                reachable_params = module_reachable_params[id(module)]\n                if pid in reachable_params:\n                    depth = node_depths[id(node)]\n                    if best_node is None or (len(reachable_params), depth) <= (len(best_reachable_params), best_depth):\n                        best_node = node\n                        best_depth = depth\n                        best_reachable_params = reachable_params\n\n            parameter_modules[pid] = best_node\n            parameter_module_names[param_node.name] = best_node.name\n\n        # contains all parameters but only a minimal set of modules necessary\n        # to contain them (and which ideally correspond to conceptual layers)\n        reduced_module_graph = cls()\n        rmg_ids = itertools.count()\n        rmg_root = Node(id=next(rmg_ids), node=module_graph[0])\n        reduced_module_graph.add_node(rmg_root)\n        reduced_module_graph.root = rmg_root\n        rmg_nodes_by_pid = {}\n\n        module_nodes_by_pid = {id(n.obj): n for n in module_graph.nodes}\n\n        compute_graph, compute_node_vars = cls.from_torch_compute_graph(\n            variable)\n        for node, _ in reversed(list(compute_graph[0].ancestor_bfs())):\n            param = compute_node_vars.get(node.id)\n            pid = id(param)\n            if not isinstance(param, torch.nn.Parameter):\n                continue\n            if pid not in module_nodes_by_pid:\n                # not all Parameters that occur in the compute graph come from the Module graph\n                continue\n\n            # add the nodes in the order we want to display them on the frontend\n            mid = id(parameter_modules[pid].obj)\n            if mid in rmg_nodes_by_pid:\n                rmg_module = rmg_nodes_by_pid[mid]\n            else:\n                rmg_module = rmg_nodes_by_pid[mid] = Node(\n                    id=next(rmg_ids), node=module_nodes_by_pid[mid])\n                reduced_module_graph.add_node(rmg_module)\n                reduced_module_graph.add_edge(rmg_root, rmg_module)\n\n            rmg_param = Node(id=next(rmg_ids), node=module_nodes_by_pid[pid])\n            rmg_nodes_by_pid[pid] = rmg_param\n            reduced_module_graph.add_node(rmg_param)\n\n            reduced_module_graph.add_edge(rmg_module, rmg_param)\n        return reduced_module_graph", "response": "Recover something like neural net layers from PyTorch Module s and the the\n            compute graph from a Variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_height_for_line(self, lineno, width):\n        try:\n            return self._line_heights[lineno, width]\n        except KeyError:\n            text = token_list_to_text(self.get_line(lineno))\n            result = self.get_height_for_text(text, width)\n\n            # Cache and return\n            self._line_heights[lineno, width] = result\n            return result", "response": "Returns the height that a given line would need if it is rendered in a specific space with the given width."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_tokens_cached(self, cli):\n        return self._token_cache.get(\n            cli.render_counter, lambda: self.get_tokens(cli))", "response": "Get tokens from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef preferred_width(self, cli, max_available_width):\n        text = token_list_to_text(self._get_tokens_cached(cli))\n        line_lengths = [get_cwidth(l) for l in text.split('\\n')]\n        return max(line_lengths)", "response": "Return the preferred width for this control."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mouse_handler(self, cli, mouse_event):\n        if self._tokens:\n            # Read the generator.\n            tokens_for_line = list(split_lines(self._tokens))\n\n            try:\n                tokens = tokens_for_line[mouse_event.position.y]\n            except IndexError:\n                return NotImplemented\n            else:\n                # Find position in the token list.\n                xpos = mouse_event.position.x\n\n                # Find mouse handler for this character.\n                count = 0\n                for item in tokens:\n                    count += len(item[1])\n                    if count >= xpos:\n                        if len(item) >= 3:\n                            # Handler found. Call it.\n                            # (Handler can return NotImplemented, so return\n                            # that result.)\n                            handler = item[2]\n                            return handler(cli, mouse_event)\n                        else:\n                            break\n\n        # Otherwise, don't handle here.\n        return NotImplemented", "response": "Handle mouse events.\n\n        (When the token list contained mouse handlers and the user clicked on\n        on any of these, the matching handler is called. This handler can still\n        return `NotImplemented` in case we want the `Window` to handle this\n        particular event.)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a function that returns the tokens for a given line.", "response": "def _get_tokens_for_line_func(self, cli, document):\n        \"\"\"\n        Create a function that returns the tokens for a given line.\n        \"\"\"\n        # Cache using `document.text`.\n        def get_tokens_for_line():\n            return self.lexer.lex_document(cli, document)\n\n        return self._token_cache.get(document.text, get_tokens_for_line)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_get_processed_line_func(self, cli, document):\n        def transform(lineno, tokens):\n            \" Transform the tokens for a given line number. \"\n            source_to_display_functions = []\n            display_to_source_functions = []\n\n            # Get cursor position at this line.\n            if document.cursor_position_row == lineno:\n                cursor_column = document.cursor_position_col\n            else:\n                cursor_column = None\n\n            def source_to_display(i):\n                \"\"\" Translate x position from the buffer to the x position in the\n                processed token list. \"\"\"\n                for f in source_to_display_functions:\n                    i = f(i)\n                return i\n\n            # Apply each processor.\n            for p in self.input_processors:\n                transformation = p.apply_transformation(\n                    cli, document, lineno, source_to_display, tokens)\n                tokens = transformation.tokens\n\n                if cursor_column:\n                    cursor_column = transformation.source_to_display(cursor_column)\n\n                display_to_source_functions.append(transformation.display_to_source)\n                source_to_display_functions.append(transformation.source_to_display)\n\n            def display_to_source(i):\n                for f in reversed(display_to_source_functions):\n                    i = f(i)\n                return i\n\n            return _ProcessedLine(tokens, source_to_display, display_to_source)\n\n        def create_func():\n            get_line = self._get_tokens_for_line_func(cli, document)\n            cache = {}\n\n            def get_processed_line(i):\n                try:\n                    return cache[i]\n                except KeyError:\n                    processed_line = transform(i, get_line(i))\n                    cache[i] = processed_line\n                    return processed_line\n            return get_processed_line\n\n        return create_func()", "response": "Create a function that takes a line number of the current document and returns a _ProcessedLine object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles mouse events on the current buffer and the cursor position.", "response": "def mouse_handler(self, cli, mouse_event):\n        \"\"\"\n        Mouse handler for this control.\n        \"\"\"\n        buffer = self._buffer(cli)\n        position = mouse_event.position\n\n        # Focus buffer when clicked.\n        if self.has_focus(cli):\n            if self._last_get_processed_line:\n                processed_line = self._last_get_processed_line(position.y)\n\n                # Translate coordinates back to the cursor position of the\n                # original input.\n                xpos = processed_line.display_to_source(position.x)\n                index = buffer.document.translate_row_col_to_index(position.y, xpos)\n\n                # Set the cursor position.\n                if mouse_event.event_type == MouseEventType.MOUSE_DOWN:\n                    buffer.exit_selection()\n                    buffer.cursor_position = index\n\n                elif mouse_event.event_type == MouseEventType.MOUSE_UP:\n                    # When the cursor was moved to another place, select the text.\n                    # (The >1 is actually a small but acceptable workaround for\n                    # selecting text in Vi navigation mode. In navigation mode,\n                    # the cursor can never be after the text, so the cursor\n                    # will be repositioned automatically.)\n                    if abs(buffer.cursor_position - index) > 1:\n                        buffer.start_selection(selection_type=SelectionType.CHARACTERS)\n                        buffer.cursor_position = index\n\n                    # Select word around cursor on double click.\n                    # Two MOUSE_UP events in a short timespan are considered a double click.\n                    double_click = self._last_click_timestamp and time.time() - self._last_click_timestamp < .3\n                    self._last_click_timestamp = time.time()\n\n                    if double_click:\n                        start, end = buffer.document.find_boundaries_of_current_word()\n                        buffer.cursor_position += start\n                        buffer.start_selection(selection_type=SelectionType.CHARACTERS)\n                        buffer.cursor_position += end - start\n                else:\n                    # Don't handle scroll events here.\n                    return NotImplemented\n\n        # Not focussed, but focussing on click events.\n        else:\n            if self.focus_on_click(cli) and mouse_event.event_type == MouseEventType.MOUSE_UP:\n                # Focus happens on mouseup. (If we did this on mousedown, the\n                # up event will be received at the point where this widget is\n                # focussed and be handled anyway.)\n                cli.focus(self.buffer_name)\n            else:\n                return NotImplemented"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of tokens for the arg - prompt.", "response": "def _get_arg_tokens(cli):\n    \"\"\"\n    Tokens for the arg-prompt.\n    \"\"\"\n    arg = cli.input_processor.arg\n\n    return [\n        (Token.Prompt.Arg, '(arg: '),\n        (Token.Prompt.Arg.Text, str(arg)),\n        (Token.Prompt.Arg, ') '),\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new instance of a new prompt with a static message text.", "response": "def from_message(cls, message='> '):\n        \"\"\"\n        Create a default prompt with a static message text.\n        \"\"\"\n        assert isinstance(message, text_type)\n\n        def get_message_tokens(cli):\n            return [(Token.Prompt, message)]\n        return cls(get_message_tokens)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a jsonl file.", "response": "def write_jsonl_file(fname, data):\n    \"\"\"Writes a jsonl file.\n\n    Args:\n        data: list of json encoded data\n    \"\"\"\n    if not isinstance(data, list):\n        print('warning: malformed json data for file', fname)\n        return\n    with open(fname, 'w') as of:\n        for row in data:\n            # TODO: other malformed cases?\n            if row.strip():\n                of.write('%s\\n' % row.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, stdin, callbacks):\n        assert isinstance(stdin, Input)\n        assert isinstance(callbacks, EventLoopCallbacks)\n        assert not self._running\n\n        if self.closed:\n            raise Exception('Event loop already closed.')\n\n        self._running = True\n        self._callbacks = callbacks\n\n        inputstream = InputStream(callbacks.feed_key)\n        current_timeout = [INPUT_TIMEOUT]  # Nonlocal\n\n        # Create reader class.\n        stdin_reader = PosixStdinReader(stdin.fileno())\n\n        # Only attach SIGWINCH signal handler in main thread.\n        # (It's not possible to attach signal handlers in other threads. In\n        # that case we should rely on a the main thread to call this manually\n        # instead.)\n        if in_main_thread():\n            ctx = call_on_sigwinch(self.received_winch)\n        else:\n            ctx = DummyContext()\n\n        def read_from_stdin():\n            \" Read user input. \"\n            # Feed input text.\n            data = stdin_reader.read()\n            inputstream.feed(data)\n\n            # Set timeout again.\n            current_timeout[0] = INPUT_TIMEOUT\n\n            # Quit when the input stream was closed.\n            if stdin_reader.closed:\n                self.stop()\n\n        self.add_reader(stdin, read_from_stdin)\n        self.add_reader(self._schedule_pipe[0], None)\n\n        with ctx:\n            while self._running:\n                # Call inputhook.\n                if self._inputhook_context:\n                    with TimeIt() as inputhook_timer:\n                        def ready(wait):\n                            \" True when there is input ready. The inputhook should return control. \"\n                            return self._ready_for_reading(current_timeout[0] if wait else 0) != []\n                        self._inputhook_context.call_inputhook(ready)\n                    inputhook_duration = inputhook_timer.duration\n                else:\n                    inputhook_duration = 0\n\n                # Calculate remaining timeout. (The inputhook consumed some of the time.)\n                if current_timeout[0] is None:\n                    remaining_timeout = None\n                else:\n                    remaining_timeout = max(0, current_timeout[0] - inputhook_duration)\n\n                # Wait until input is ready.\n                fds = self._ready_for_reading(remaining_timeout)\n\n                # When any of the FDs are ready. Call the appropriate callback.\n                if fds:\n                    # Create lists of high/low priority tasks. The main reason\n                    # for this is to allow painting the UI to happen as soon as\n                    # possible, but when there are many events happening, we\n                    # don't want to call the UI renderer 1000x per second. If\n                    # the eventloop is completely saturated with many CPU\n                    # intensive tasks (like processing input/output), we say\n                    # that drawing the UI can be postponed a little, to make\n                    # CPU available. This will be a low priority task in that\n                    # case.\n                    tasks = []\n                    low_priority_tasks = []\n                    now = None  # Lazy load time. (Fewer system calls.)\n\n                    for fd in fds:\n                        # For the 'call_from_executor' fd, put each pending\n                        # item on either the high or low priority queue.\n                        if fd == self._schedule_pipe[0]:\n                            for c, max_postpone_until in self._calls_from_executor:\n                                if max_postpone_until is None:\n                                    # Execute now.\n                                    tasks.append(c)\n                                else:\n                                    # Execute soon, if `max_postpone_until` is in the future.\n                                    now = now or _now()\n                                    if max_postpone_until < now:\n                                        tasks.append(c)\n                                    else:\n                                        low_priority_tasks.append((c, max_postpone_until))\n                            self._calls_from_executor = []\n\n                            # Flush all the pipe content.\n                            os.read(self._schedule_pipe[0], 1024)\n                        else:\n                            handler = self._read_fds.get(fd)\n                            if handler:\n                                tasks.append(handler)\n\n                    # When there are high priority tasks, run all these.\n                    # Schedule low priority tasks for the next iteration.\n                    if tasks:\n                        for t in tasks:\n                            t()\n\n                        # Postpone low priority tasks.\n                        for t, max_postpone_until in low_priority_tasks:\n                            self.call_from_executor(t, _max_postpone_until=max_postpone_until)\n                    else:\n                        # Currently there are only low priority tasks -> run them right now.\n                        for t, _ in low_priority_tasks:\n                            t()\n\n                else:\n                    # Flush all pending keys on a timeout. (This is most\n                    # important to flush the vt100 'Escape' key early when\n                    # nothing else follows.)\n                    inputstream.flush()\n\n                    # Fire input timeout event.\n                    callbacks.input_timeout()\n                    current_timeout[0] = None\n\n        self.remove_reader(stdin)\n        self.remove_reader(self._schedule_pipe[0])\n\n        self._callbacks = None", "response": "Runs the event loop."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnotify the event loop that SIGWINCH has been received the available log entries.", "response": "def received_winch(self):\n        \"\"\"\n        Notify the event loop that SIGWINCH has been received\n        \"\"\"\n        # Process signal asynchronously, because this handler can write to the\n        # output, and doing this inside the signal handler causes easily\n        # reentrant calls, giving runtime errors..\n\n        # Furthur, this has to be thread safe. When the CommandLineInterface\n        # runs not in the main thread, this function still has to be called\n        # from the main thread. (The only place where we can install signal\n        # handlers.)\n        def process_winch():\n            if self._callbacks:\n                self._callbacks.terminal_size_changed()\n\n        self.call_from_executor(process_winch)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_in_executor(self, callback):\n        # Wait until the main thread is idle.\n        # We start the thread by using `call_from_executor`. The event loop\n        # favours processing input over `calls_from_executor`, so the thread\n        # will not start until there is no more input to process and the main\n        # thread becomes idle for an instant. This is good, because Python\n        # threading favours CPU over I/O -- an autocompletion thread in the\n        # background would cause a significantly slow down of the main thread.\n        # It is mostly noticable when pasting large portions of text while\n        # having real time autocompletion while typing on.\n        def start_executor():\n            threading.Thread(target=callback).start()\n        self.call_from_executor(start_executor)", "response": "Run a long running function in a background thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls this function in the main event loop.", "response": "def call_from_executor(self, callback, _max_postpone_until=None):\n        \"\"\"\n        Call this function in the main event loop.\n        Similar to Twisted's ``callFromThread``.\n\n        :param _max_postpone_until: `None` or `time.time` value. For interal\n            use. If the eventloop is saturated, consider this task to be low\n            priority and postpone maximum until this timestamp. (For instance,\n            repaint is done using low priority.)\n        \"\"\"\n        assert _max_postpone_until is None or isinstance(_max_postpone_until, float)\n        self._calls_from_executor.append((callback, _max_postpone_until))\n\n        if self._schedule_pipe:\n            try:\n                os.write(self._schedule_pipe[1], b'x')\n            except (AttributeError, IndexError, OSError):\n                # Handle race condition. We're in a different thread.\n                # - `_schedule_pipe` could have become None in the meantime.\n                # - We catch `OSError` (actually BrokenPipeError), because the\n                #   main thread could have closed the pipe already.\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_reader(self, fd, callback):\n        \" Add read file descriptor to the event loop. \"\n        fd = fd_to_int(fd)\n        self._read_fds[fd] = callback\n        self.selector.register(fd)", "response": "Add read file descriptor to the event loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves read file descriptor from the event loop.", "response": "def remove_reader(self, fd):\n        \" Remove read file descriptor from the event loop. \"\n        fd = fd_to_int(fd)\n\n        if fd in self._read_fds:\n            del self._read_fds[fd]\n\n        self.selector.unregister(fd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef memoized(maxsize=1024):\n    cache = SimpleCache(maxsize=maxsize)\n\n    def decorator(obj):\n        @wraps(obj)\n        def new_callable(*a, **kw):\n            def create_new():\n                return obj(*a, **kw)\n\n            key = (a, tuple(kw.items()))\n            return cache.get(key, create_new)\n        return new_callable\n    return decorator", "response": "Momoization decorator for immutable classes and pure functions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, key, getter_func):\n        # Look in cache first.\n        try:\n            return self._data[key]\n        except KeyError:\n            # Not found? Get it.\n            value = getter_func()\n            self._data[key] = value\n            self._keys.append(key)\n\n            # Remove the oldest key when the size is exceeded.\n            if len(self._data) > self.maxsize:\n                key_to_remove = self._keys.popleft()\n                if key_to_remove in self._data:\n                    del self._data[key_to_remove]\n\n            return value", "response": "Get object from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_binding(self, function):\n        assert callable(function)\n\n        for b in self.key_bindings:\n            if b.handler == function:\n                self.key_bindings.remove(b)\n                self._clear_cache()\n                return\n\n        # No key binding found for this function. Raise ValueError.\n        raise ValueError('Binding not found: %r' % (function, ))", "response": "Removes a key binding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_bindings_for_keys(self, keys):\n        def get():\n            result = []\n            for b in self.key_bindings:\n                if len(keys) == len(b.keys):\n                    match = True\n                    any_count = 0\n\n                    for i, j in zip(b.keys, keys):\n                        if i != j and i != Keys.Any:\n                            match = False\n                            break\n\n                        if i == Keys.Any:\n                            any_count += 1\n\n                    if match:\n                        result.append((any_count, b))\n\n            # Place bindings that have more 'Any' occurences in them at the end.\n            result = sorted(result, key=lambda item: -item[0])\n\n            return [item[1] for item in result]\n\n        return self._get_bindings_for_keys_cache.get(keys, get)", "response": "Return a list of key bindings that can handle this key."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of key bindings that handle a key sequence starting with the given keys.", "response": "def get_bindings_starting_with_keys(self, keys):\n        \"\"\"\n        Return a list of key bindings that handle a key sequence starting with\n        `keys`. (It does only return bindings for which the sequences are\n        longer than `keys`. And like `get_bindings_for_keys`, it also includes\n        inactive bindings.)\n\n        :param keys: tuple of keys.\n        \"\"\"\n        def get():\n            result = []\n            for b in self.key_bindings:\n                if len(keys) < len(b.keys):\n                    match = True\n                    for i, j in zip(b.keys, keys):\n                        if i != j and i != Keys.Any:\n                            match = False\n                            break\n                    if match:\n                        result.append(b)\n            return result\n\n        return self._get_bindings_starting_with_keys_cache.get(keys, get)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _update_cache(self):\n        \" If the original registry was changed. Update our copy version. \"\n        expected_version = (self.registry._version, self._extra_registry._version)\n\n        if self._last_version != expected_version:\n            registry2 = Registry()\n\n            # Copy all bindings from `self.registry`, adding our condition.\n            for reg in (self.registry, self._extra_registry):\n                for b in reg.key_bindings:\n                    registry2.key_bindings.append(\n                        _Binding(\n                            keys=b.keys,\n                            handler=b.handler,\n                            filter=self.filter & b.filter,\n                            eager=b.eager,\n                            save_before=b.save_before))\n\n            self._registry2 = registry2\n            self._last_version = expected_version", "response": "If the original registry was changed. Update our copy version."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating our merged version of the registry.", "response": "def _update_cache(self):\n        \"\"\"\n        If one of the original registries was changed. Update our merged\n        version.\n        \"\"\"\n        expected_version = (\n            tuple(r._version for r in self.registries) +\n            (self._extra_registry._version, ))\n\n        if self._last_version != expected_version:\n            registry2 = Registry()\n\n            for reg in self.registries:\n                registry2.key_bindings.extend(reg.key_bindings)\n\n            # Copy all bindings from `self._extra_registry`.\n            registry2.key_bindings.extend(self._extra_registry.key_bindings)\n\n            self._registry2 = registry2\n            self._last_version = expected_version"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_config(cls, config_path, config_dict, credstore_env=None):\n\n        if not config_dict:\n            config_file = find_config_file(config_path)\n\n            if not config_file:\n                return cls({}, credstore_env)\n            try:\n                with open(config_file) as f:\n                    config_dict = json.load(f)\n            except (IOError, KeyError, ValueError) as e:\n                # Likely missing new Docker config file or it's in an\n                # unknown format, continue to attempt to read old location\n                # and format.\n                log.debug(e)\n                return cls(_load_legacy_config(config_file), credstore_env)\n\n        res = {}\n        if config_dict.get('auths'):\n            log.debug(\"Found 'auths' section\")\n            res.update({\n                'auths': cls.parse_auth(\n                    config_dict.pop('auths'), raise_on_error=True\n                )\n            })\n        if config_dict.get('credsStore'):\n            log.debug(\"Found 'credsStore' section\")\n            res.update({'credsStore': config_dict.pop('credsStore')})\n        if config_dict.get('credHelpers'):\n            log.debug(\"Found 'credHelpers' section\")\n            res.update({'credHelpers': config_dict.pop('credHelpers')})\n        if res:\n            return cls(res, credstore_env)\n\n        log.debug(\n            \"Couldn't find auth-related section ; attempting to interpret \"\n            \"as auth-only file\"\n        )\n        return cls({'auths': cls.parse_auth(config_dict)}, credstore_env)", "response": "Load authentication data from a Docker configuration file in the given root directory or in the given environment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nest(thing):\n    tfutil = util.get_module('tensorflow.python.util')\n    if tfutil:\n        return tfutil.nest.flatten(thing)\n    else:\n        return [thing]", "response": "Use tensorflows nest function if available otherwise just wrap object in an array"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef val_to_json(key, val, mode=\"summary\", step=None):\n    converted = val\n    typename = util.get_full_typename(val)\n    if util.is_matplotlib_typename(typename):\n        # This handles plots with images in it because plotly doesn't support it\n        # TODO: should we handle a list of plots?\n        val = util.ensure_matplotlib_figure(val)\n        if any(len(ax.images) > 0 for ax in val.axes):\n            PILImage = util.get_module(\n                \"PIL.Image\", required=\"Logging plots with images requires pil: pip install pillow\")\n            buf = six.BytesIO()\n            val.savefig(buf)\n            val = Image(PILImage.open(buf))\n        else:\n            converted = util.convert_plots(val)\n    elif util.is_plotly_typename(typename):\n        converted = util.convert_plots(val)\n    if isinstance(val, IterableMedia):\n        val = [val]\n\n    if isinstance(val, collections.Sequence) and len(val) > 0:\n        is_media = [isinstance(v, IterableMedia) for v in val]\n        if all(is_media):\n            cwd = wandb.run.dir if wandb.run else \".\"\n            if step is None:\n                step = \"summary\"\n            if isinstance(val[0], Image):\n                converted = Image.transform(val, cwd,\n                                            \"{}_{}.jpg\".format(key, step))\n            elif isinstance(val[0], Audio):\n                converted = Audio.transform(val, cwd, key, step)\n            elif isinstance(val[0], Html):\n                converted = Html.transform(val, cwd, key, step)\n            elif isinstance(val[0], Object3D):\n                converted = Object3D.transform(val, cwd, key, step)\n        elif any(is_media):\n            raise ValueError(\n                \"Mixed media types in the same list aren't supported\")\n    elif isinstance(val, Histogram):\n        converted = Histogram.transform(val)\n    elif isinstance(val, Graph):\n        if mode == \"history\":\n            raise ValueError(\"Graphs are only supported in summary\")\n        converted = Graph.transform(val)\n    elif isinstance(val, Table):\n        converted = Table.transform(val)\n    return converted", "response": "Converts a wandb datatype to its JSON representation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert all keys in a potentially nested array into their JSON representation", "response": "def to_json(payload, mode=\"history\"):\n    \"\"\"Converts all keys in a potentially nested array into their JSON representation\"\"\"\n    for key, val in six.iteritems(payload):\n        if isinstance(val, dict):\n            payload[key] = to_json(val, mode)\n        else:\n            payload[key] = val_to_json(\n                key, val, mode, step=payload.get(\"_step\"))\n    return payload"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef guess_mode(self, data):\n        # TODO: do we want to support dimensions being at the beginning of the array?\n        if data.ndim == 2:\n            return \"L\"\n        elif data.shape[-1] == 3:\n            return \"RGB\"\n        elif data.shape[-1] == 4:\n            return \"RGBA\"\n        else:\n            raise ValueError(\n                \"Un-supported shape for image conversion %s\" % list(data.shape))", "response": "Guess what mode of image the np. array is representing\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_uint8(self, data):\n        np = util.get_module(\n            \"numpy\", required=\"wandb.Image requires numpy if not supplying PIL Images: pip install numpy\")\n\n        # I think it's better to check the image range vs the data type, since many\n        # image libraries will return floats between 0 and 255\n\n        # some images have range -1...1 or 0-1\n        dmin = np.min(data)\n        if dmin < 0:\n            data = (data - np.min(data)) / np.ptp(data)\n        if np.max(data) <= 1.0:\n            data = (data * 255).astype(np.int32)\n\n        #assert issubclass(data.dtype.type, np.integer), 'Illegal image format.'\n        return data.clip(0, 255).astype(np.uint8)", "response": "Converts floating point image on the range [ 0 1 ) and integer imageson the range [ 0 255 ) to uint8 clipping if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform(images, out_dir, fname):\n        from PIL import Image as PILImage\n        base = os.path.join(out_dir, \"media\", \"images\")\n        width, height = images[0].image.size\n        num_images_to_log = len(images)\n\n        if num_images_to_log > Image.MAX_IMAGES:\n            logging.warn(\n                \"The maximum number of images to store per step is %i.\" % Image.MAX_IMAGES)\n            num_images_to_log = Image.MAX_IMAGES\n\n        if width * num_images_to_log > Image.MAX_DIMENSION:\n            max_images_by_dimension = Image.MAX_DIMENSION // width\n            logging.warn(\"The maximum total width for all images in a collection is 65500, or {} images, each with a width of {} pixels. Only logging the first {} images.\".format(max_images_by_dimension, width, max_images_by_dimension))\n            num_images_to_log = max_images_by_dimension\n\n        total_width = width * num_images_to_log\n        sprite = PILImage.new(\n            mode='RGB',\n            size=(total_width, height),\n            color=(0, 0, 0))\n        for i, image in enumerate(images[:num_images_to_log]):\n            location = width * i\n            sprite.paste(image.image, (location, 0))\n        util.mkdir_exists_ok(base)\n        sprite.save(os.path.join(base, fname), transparency=0)\n        meta = {\"width\": width, \"height\": height,\n                \"count\": num_images_to_log, \"_type\": \"images\"}\n        # TODO: hacky way to enable image grouping for now\n        grouping = images[0].grouping\n        if grouping:\n            meta[\"grouping\"] = grouping\n        captions = Image.captions(images[:num_images_to_log])\n        if captions:\n            meta[\"captions\"] = captions\n        return meta", "response": "Combine a list of images into a single sprite returning meta information"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef for_prompt(cls, **kw):\n        kw.setdefault('enable_abort_and_exit_bindings', True)\n        kw.setdefault('enable_search', True)\n        kw.setdefault('enable_auto_suggest_bindings', True)\n\n        return cls(**kw)", "response": "Create a KeyBindingManager for an input prompt."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_application(self, app, callback=None):\n        assert isinstance(app, Application)\n        assert callback is None or callable(callback)\n\n        self.cli = CommandLineInterface(\n            application=app,\n            eventloop=self.eventloop,\n            output=self.vt100_output)\n        self.callback = callback\n\n        # Create a parser, and parser callbacks.\n        cb = self.cli.create_eventloop_callbacks()\n        inputstream = InputStream(cb.feed_key)\n\n        # Input decoder for stdin. (Required when working with multibyte\n        # characters, like chinese input.)\n        stdin_decoder_cls = getincrementaldecoder(self.encoding)\n        stdin_decoder = [stdin_decoder_cls()]  # nonlocal\n\n        # Tell the CLI that it's running. We don't start it through the run()\n        # call, but will still want _redraw() to work.\n        self.cli._is_running = True\n\n        def data_received(data):\n            \"\"\" TelnetProtocolParser 'data_received' callback \"\"\"\n            assert isinstance(data, binary_type)\n\n            try:\n                result = stdin_decoder[0].decode(data)\n                inputstream.feed(result)\n            except UnicodeDecodeError:\n                stdin_decoder[0] = stdin_decoder_cls()\n                return ''\n\n        def size_received(rows, columns):\n            \"\"\" TelnetProtocolParser 'size_received' callback \"\"\"\n            self.size = Size(rows=rows, columns=columns)\n            cb.terminal_size_changed()\n\n        self.parser = TelnetProtocolParser(data_received, size_received)", "response": "Set the application for this connection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef feed(self, data):\n        assert isinstance(data, binary_type)\n\n        self.parser.feed(data)\n\n        # Render again.\n        self.cli._redraw()\n\n        # When a return value has been set (enter was pressed), handle command.\n        if self.cli.is_returning:\n            try:\n                return_value = self.cli.return_value()\n            except (EOFError, KeyboardInterrupt) as e:\n                # Control-D or Control-C was pressed.\n                logger.info('%s, closing connection.', type(e).__name__)\n                self.close()\n                return\n\n            # Handle CLI command\n            self._handle_command(return_value)", "response": "Handler for incoming data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles command. This will run in a separate thread, in order not to block the event loop.", "response": "def _handle_command(self, command):\n        \"\"\"\n        Handle command. This will run in a separate thread, in order not\n        to block the event loop.\n        \"\"\"\n        logger.info('Handle command %r', command)\n\n        def in_executor():\n            self.handling_command = True\n            try:\n                if self.callback is not None:\n                    self.callback(self, command)\n            finally:\n                self.server.call_from_executor(done)\n\n        def done():\n            self.handling_command = False\n\n            # Reset state and draw again. (If the connection is still open --\n            # the application could have called TelnetConnection.close()\n            if not self.closed:\n                self.cli.reset()\n                self.cli.buffers[DEFAULT_BUFFER].reset()\n                self.cli.renderer.request_absolute_cursor_position()\n                self.vt100_output.flush()\n                self.cli._redraw()\n\n        self.server.run_in_executor(in_executor)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, data):\n        assert isinstance(data, text_type)\n\n        # When data is send back to the client, we should replace the line\n        # endings. (We didn't allocate a real pseudo terminal, and the telnet\n        # connection is raw, so we are responsible for inserting \\r.)\n        self.stdout.write(data.replace('\\n', '\\r\\n'))\n        self.stdout.flush()", "response": "Send text to the client."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        self.application.client_leaving(self)\n\n        self.conn.close()\n        self.closed = True", "response": "Close the connection to the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_callbacks(self):\n        # Flush all the pipe content.\n        os.read(self._schedule_pipe[0], 1024)\n\n        # Process calls from executor.\n        calls_from_executor, self._calls_from_executor = self._calls_from_executor, []\n        for c in calls_from_executor:\n            c()", "response": "Process callbacks from call_from_executor in eventloop."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns the eventloop for the telnet server.", "response": "def run(self):\n        \"\"\"\n        Run the eventloop for the telnet server.\n        \"\"\"\n        listen_socket = self.create_socket(self.host, self.port)\n        logger.info('Listening for telnet connections on %s port %r', self.host, self.port)\n\n        try:\n            while True:\n                # Removed closed connections.\n                self.connections = set([c for c in self.connections if not c.closed])\n\n                # Ignore connections handling commands.\n                connections = set([c for c in self.connections if not c.handling_command])\n\n                # Wait for next event.\n                read_list = (\n                    [listen_socket, self._schedule_pipe[0]] +\n                    [c.conn for c in connections])\n\n                read, _, _ = select.select(read_list, [], [])\n\n                for s in read:\n                    # When the socket itself is ready, accept a new connection.\n                    if s == listen_socket:\n                        self._accept(listen_socket)\n\n                    # If we receive something on our \"call_from_executor\" pipe, process\n                    # these callbacks in a thread safe way.\n                    elif s == self._schedule_pipe[0]:\n                        self._process_callbacks()\n\n                    # Handle incoming data on socket.\n                    else:\n                        self._handle_incoming_data(s)\n        finally:\n            listen_socket.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naccepting new incoming connection.", "response": "def _accept(self, listen_socket):\n        \"\"\"\n        Accept new incoming connection.\n        \"\"\"\n        conn, addr = listen_socket.accept()\n        connection = TelnetConnection(conn, addr, self.application, self, encoding=self.encoding)\n        self.connections.add(connection)\n\n        logger.info('New connection %r %r', *addr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_incoming_data(self, conn):\n        connection = [c for c in self.connections if c.conn == conn][0]\n        data = conn.recv(1024)\n        if data:\n            connection.feed(data)\n        else:\n            self.connections.remove(connection)", "response": "Handle incoming data on socket."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping around execute that logs in cases of failure.", "response": "def execute(self, *args, **kwargs):\n        \"\"\"Wrapper around execute that logs in cases of failure.\"\"\"\n        try:\n            return self.client.execute(*args, **kwargs)\n        except requests.exceptions.HTTPError as err:\n            res = err.response\n            logger.error(\"%s response executing GraphQL.\" % res.status_code)\n            logger.error(res.text)\n            self.display_gorilla_error_if_found(res)\n            six.reraise(*sys.exc_info())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the current working set of pip packages to requirements. txt", "response": "def save_pip(self, out_dir):\n        \"\"\"Saves the current working set of pip packages to requirements.txt\"\"\"\n        try:\n            import pkg_resources\n\n            installed_packages = [d for d in iter(pkg_resources.working_set)]\n            installed_packages_list = sorted(\n                [\"%s==%s\" % (i.key, i.version) for i in installed_packages]\n            )\n            with open(os.path.join(out_dir, 'requirements.txt'), 'w') as f:\n                f.write(\"\\n\".join(installed_packages_list))\n        except Exception as e:\n            logger.error(\"Error saving pip packages\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the current state of this repository to one or more patches.", "response": "def save_patches(self, out_dir):\n        \"\"\"Save the current state of this repository to one or more patches.\n\n        Makes one patch against HEAD and another one against the most recent\n        commit that occurs in an upstream branch. This way we can be robust\n        to history editing as long as the user never does \"push -f\" to break\n        history on an upstream branch.\n\n        Writes the first patch to <out_dir>/diff.patch and the second to\n        <out_dir>/upstream_diff_<commit_id>.patch.\n\n        Args:\n            out_dir (str): Directory to write the patch files.\n        \"\"\"\n        if not self.git.enabled:\n            return False\n\n        try:\n            root = self.git.root\n            if self.git.dirty:\n                patch_path = os.path.join(out_dir, 'diff.patch')\n                if self.git.has_submodule_diff:\n                    with open(patch_path, 'wb') as patch:\n                        # we diff against HEAD to ensure we get changes in the index\n                        subprocess.check_call(\n                            ['git', 'diff', '--submodule=diff', 'HEAD'], stdout=patch, cwd=root, timeout=5)\n                else:\n                    with open(patch_path, 'wb') as patch:\n                        subprocess.check_call(\n                            ['git', 'diff', 'HEAD'], stdout=patch, cwd=root, timeout=5)\n\n            upstream_commit = self.git.get_upstream_fork_point()\n            if upstream_commit and upstream_commit != self.git.repo.head.commit:\n                sha = upstream_commit.hexsha\n                upstream_patch_path = os.path.join(\n                    out_dir, 'upstream_diff_{}.patch'.format(sha))\n                if self.git.has_submodule_diff:\n                    with open(upstream_patch_path, 'wb') as upstream_patch:\n                        subprocess.check_call(\n                            ['git', 'diff', '--submodule=diff', sha], stdout=upstream_patch, cwd=root, timeout=5)\n                else:\n                    with open(upstream_patch_path, 'wb') as upstream_patch:\n                        subprocess.check_call(\n                            ['git', 'diff', sha], stdout=upstream_patch, cwd=root, timeout=5)\n        except (subprocess.CalledProcessError, subprocess.TimeoutExpired):\n            logger.error('Error generating diff')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef settings(self, key=None, section=None):\n        if not self._settings:\n            self._settings = self.default_settings.copy()\n            section = section or self._settings['section']\n            try:\n                if section in self.settings_parser.sections():\n                    for option in self.settings_parser.options(section):\n                        self._settings[option] = self.settings_parser.get(\n                            section, option)\n            except configparser.InterpolationSyntaxError:\n                print(\"WARNING: Unable to parse settings file\")\n            self._settings[\"project\"] = env.get_project(\n                self._settings.get(\"project\"))\n            self._settings[\"entity\"] = env.get_entity(\n                self._settings.get(\"entity\"))\n            self._settings[\"base_url\"] = env.get_base_url(\n                self._settings.get(\"base_url\"))\n            self._settings[\"ignore_globs\"] = env.get_ignore(\n                self._settings.get(\"ignore_globs\")\n            )\n\n        return self._settings if key is None else self._settings[key]", "response": "Returns the settings overridden from the wandb / settings file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_projects(self, entity=None):\n        query = gql('''\n        query Models($entity: String!) {\n            models(first: 10, entityName: $entity) {\n                edges {\n                    node {\n                        id\n                        name\n                        description\n                    }\n                }\n            }\n        }\n        ''')\n        return self._flatten_edges(self.gql(query, variable_values={\n            'entity': entity or self.settings('entity')})['models'])", "response": "Lists projects in W&B scoped by entity."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef project(self, project, entity=None):\n        query = gql('''\n        query Models($entity: String, $project: String!) {\n            model(name: $project, entityName: $entity) {\n                id\n                name\n                repo\n                dockerImage\n                description\n            }\n        }\n        ''')\n        return self.gql(query, variable_values={\n            'entity': entity, 'project': project})['model']", "response": "Retrive project\n\n        Args:\n            project (str): The project to get details for\n            entity (str, optional): The entity to scope this project to.\n\n        Returns:\n                [{\"id\",\"name\",\"repo\",\"dockerImage\",\"description\"}]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting runs in W&B scoped by project.", "response": "def list_runs(self, project, entity=None):\n        \"\"\"Lists runs in W&B scoped by project.\n\n        Args:\n            project (str): The project to scope the runs to\n            entity (str, optional): The entity to scope this project to.  Defaults to public models\n\n        Returns:\n                [{\"id\",name\",\"description\"}]\n        \"\"\"\n        query = gql('''\n        query Buckets($model: String!, $entity: String!) {\n            model(name: $model, entityName: $entity) {\n                buckets(first: 10) {\n                    edges {\n                        node {\n                            id\n                            name\n                            description\n                        }\n                    }\n                }\n            }\n        }\n        ''')\n        return self._flatten_edges(self.gql(query, variable_values={\n            'entity': entity or self.settings('entity'),\n            'model': project or self.settings('project')})['model']['buckets'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlaunching a run in the cloud.", "response": "def launch_run(self, command, project=None, entity=None, run_id=None):\n        \"\"\"Launch a run in the cloud.\n\n        Args:\n            command (str): The command to run\n            program (str): The file to run\n            project (str): The project to scope the runs to\n            entity (str, optional): The entity to scope this project to.  Defaults to public models\n            run_id (str, optional): The run_id to scope to\n\n        Returns:\n                [{\"podName\",\"status\"}]\n        \"\"\"\n        query = gql('''\n        mutation launchRun(\n            $entity: String\n            $model: String\n            $runId: String\n            $image: String\n            $command: String\n            $patch: String\n            $cwd: String\n            $datasets: [String]\n        ) {\n            launchRun(input: {id: $runId, entityName: $entity, patch: $patch, modelName: $model,\n                image: $image, command: $command, datasets: $datasets, cwd: $cwd}) {\n                podName\n                status\n                runId\n            }\n        }\n        ''')\n        patch = BytesIO()\n        if self.git.dirty:\n            self.git.repo.git.execute(['git', 'diff'], output_stream=patch)\n            patch.seek(0)\n        cwd = \".\"\n        if self.git.enabled:\n            cwd = cwd + os.getcwd().replace(self.git.repo.working_dir, \"\")\n        return self.gql(query, variable_values={\n            'entity': entity or self.settings('entity'),\n            'model': project or self.settings('project'),\n            'command': command,\n            'runId': run_id,\n            'patch': patch.read().decode(\"utf8\"),\n            'cwd': cwd\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_config(self, project, run=None, entity=None):\n        query = gql('''\n        query Model($name: String!, $entity: String!, $run: String!) {\n            model(name: $name, entityName: $entity) {\n                bucket(name: $run) {\n                    config\n                    commit\n                    patch\n                    files(names: [\"wandb-metadata.json\"]) {\n                        edges {\n                            node {\n                                url\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        ''')\n\n        response = self.gql(query, variable_values={\n            'name': project, 'run': run, 'entity': entity\n        })\n        if response['model'] == None:\n            raise ValueError(\"Run {}/{}/{} not found\".format(entity, project, run) )\n        run = response['model']['bucket']\n        commit = run['commit']\n        patch = run['patch']\n        config = json.loads(run['config'] or '{}')\n        if len(run['files']['edges']) > 0:\n            url = run['files']['edges'][0]['node']['url']\n            res = requests.get(url)\n            res.raise_for_status()\n            metadata = res.json()\n        else:\n            metadata = {}\n        return (commit, config, patch, metadata)", "response": "Get the relevant configs for a run."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_resume_status(self, entity, project_name, name):\n        query = gql('''\n        query Model($project: String!, $entity: String, $name: String!) {\n            model(name: $project, entityName: $entity) {\n                id\n                name\n                entity {\n                    id\n                    name\n                }\n\n                bucket(name: $name, missingOk: true) {\n                    id\n                    name\n                    logLineCount\n                    historyLineCount\n                    eventsLineCount\n                    historyTail\n                    eventsTail\n                }\n            }\n        }\n        ''')\n\n        response = self.gql(query, variable_values={\n            'entity': entity, 'project': project_name, 'name': name,\n        })\n\n        if 'model' not in response or 'bucket' not in response['model']:\n            return None\n\n        project = response['model']\n        self.set_setting('project', project_name)\n        if 'entity' in project:\n            self.set_setting('entity', project['entity']['name'])\n\n        return project['bucket']", "response": "Check if a run exists and get resume status."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upsert_project(self, project, id=None, description=None, entity=None):\n        mutation = gql('''\n        mutation UpsertModel($name: String!, $id: String, $entity: String!, $description: String, $repo: String)  {\n            upsertModel(input: { id: $id, name: $name, entityName: $entity, description: $description, repo: $repo }) {\n                model {\n                    name\n                    description\n                }\n            }\n        }\n        ''')\n        response = self.gql(mutation, variable_values={\n            'name': self.format_project(project), 'entity': entity or self.settings('entity'),\n            'description': description, 'repo': self.git.remote_url, 'id': id})\n        return response['upsertModel']['model']", "response": "Create a new project with the given name description and entity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef upsert_run(self, id=None, name=None, project=None, host=None,\n                   group=None, tags=None,\n                   config=None, description=None, entity=None, state=None,\n                   repo=None, job_type=None, program_path=None, commit=None,\n                   sweep_name=None, summary_metrics=None, num_retries=None):\n        \"\"\"Update a run\n\n        Args:\n            id (str, optional): The existing run to update\n            name (str, optional): The name of the run to create\n            group (str, optional): Name of the group this run is a part of\n            project (str, optional): The name of the project\n            config (dict, optional): The latest config params\n            description (str, optional): A description of this project\n            entity (str, optional): The entity to scope this project to.\n            repo (str, optional): Url of the program's repository.\n            state (str, optional): State of the program.\n            job_type (str, optional): Type of job, e.g 'train'.\n            program_path (str, optional): Path to the program.\n            commit (str, optional): The Git SHA to associate the run with\n            summary_metrics (str, optional): The JSON summary metrics\n        \"\"\"\n        mutation = gql('''\n        mutation UpsertBucket(\n            $id: String, $name: String,\n            $project: String,\n            $entity: String!,\n            $groupName: String,\n            $description: String,\n            $commit: String,\n            $config: JSONString,\n            $host: String,\n            $debug: Boolean,\n            $program: String,\n            $repo: String,\n            $jobType: String,\n            $state: String,\n            $sweep: String,\n            $tags: [String!],\n            $summaryMetrics: JSONString,\n        ) {\n            upsertBucket(input: {\n                id: $id,\n                name: $name,\n                groupName: $groupName,\n                modelName: $project,\n                entityName: $entity,\n                description: $description,\n                config: $config,\n                commit: $commit,\n                host: $host,\n                debug: $debug,\n                jobProgram: $program,\n                jobRepo: $repo,\n                jobType: $jobType,\n                state: $state,\n                sweep: $sweep,\n                tags: $tags,\n                summaryMetrics: $summaryMetrics,\n            }) {\n                bucket {\n                    id\n                    name\n                    description\n                    config\n                    project {\n                        id\n                        name\n                        entity {\n                            id\n                            name\n                        }\n                    }\n                }\n            }\n        }\n        ''')\n        if config is not None:\n            config = json.dumps(config)\n        if not description:\n            description = None\n\n        kwargs = {}\n        if num_retries is not None:\n            kwargs['num_retries'] = num_retries\n\n        variable_values = {\n            'id': id, 'entity': entity or self.settings('entity'), 'name': name, 'project': project,\n            'groupName': group, 'tags': tags,\n            'description': description, 'config': config, 'commit': commit,\n            'host': host, 'debug': env.is_debug(), 'repo': repo, 'program': program_path, 'jobType': job_type,\n            'state': state, 'sweep': sweep_name, 'summaryMetrics': summary_metrics\n        }\n\n        response = self.gql(\n            mutation, variable_values=variable_values, **kwargs)\n\n        run = response['upsertBucket']['bucket']\n        project = run.get('project')\n        if project:\n            self.set_setting('project', project['name'])\n            entity = project.get('entity')\n            if entity:\n                self.set_setting('entity', entity['name'])\n\n        return response['upsertBucket']['bucket']", "response": "Updates a run in the cluster with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating temporary resumeable upload urls for a list of files.", "response": "def upload_urls(self, project, files, run=None, entity=None, description=None):\n        \"\"\"Generate temporary resumeable upload urls\n\n        Args:\n            project (str): The project to download\n            files (list or dict): The filenames to upload\n            run (str, optional): The run to upload to\n            entity (str, optional): The entity to scope this project to.  Defaults to wandb models\n\n        Returns:\n            (bucket_id, file_info)\n            bucket_id: id of bucket we uploaded to\n            file_info: A dict of filenames and urls, also indicates if this revision already has uploaded files.\n                {\n                    'weights.h5': { \"url\": \"https://weights.url\" },\n                    'model.json': { \"url\": \"https://model.json\", \"updatedAt\": '2013-04-26T22:22:23.832Z', 'md5': 'mZFLkyvTelC5g8XnyQrpOw==' },\n                }\n        \"\"\"\n        query = gql('''\n        query Model($name: String!, $files: [String]!, $entity: String!, $run: String!, $description: String) {\n            model(name: $name, entityName: $entity) {\n                bucket(name: $run, desc: $description) {\n                    id\n                    files(names: $files) {\n                        edges {\n                            node {\n                                name\n                                url(upload: true)\n                                updatedAt\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        ''')\n        run_id = run or self.settings('run')\n        entity = entity or self.settings('entity')\n        query_result = self.gql(query, variable_values={\n            'name': project, 'run': run_id,\n            'entity': entity,\n            'description': description,\n            'files': [file for file in files]\n        })\n\n        run = query_result['model']['bucket']\n        if run:\n            result = {file['name']: file for file in self._flatten_edges(run['files'])}\n            return run['id'], result\n        else:\n            raise CommError(\"Run does not exist {}/{}/{}.\".format(entity, project, run_id))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate download urls for a specific run and entity.", "response": "def download_urls(self, project, run=None, entity=None):\n        \"\"\"Generate download urls\n\n        Args:\n            project (str): The project to download\n            run (str, optional): The run to upload to\n            entity (str, optional): The entity to scope this project to.  Defaults to wandb models\n\n        Returns:\n            A dict of extensions and urls\n\n                {\n                    'weights.h5': { \"url\": \"https://weights.url\", \"updatedAt\": '2013-04-26T22:22:23.832Z', 'md5': 'mZFLkyvTelC5g8XnyQrpOw==' },\n                    'model.json': { \"url\": \"https://model.url\", \"updatedAt\": '2013-04-26T22:22:23.832Z', 'md5': 'mZFLkyvTelC5g8XnyQrpOw==' }\n                }\n        \"\"\"\n        query = gql('''\n        query Model($name: String!, $entity: String!, $run: String!)  {\n            model(name: $name, entityName: $entity) {\n                bucket(name: $run) {\n                    files {\n                        edges {\n                            node {\n                                name\n                                url\n                                md5\n                                updatedAt\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        ''')\n        query_result = self.gql(query, variable_values={\n            'name': project, 'run': run or self.settings('run'),\n            'entity': entity or self.settings('entity')})\n        files = self._flatten_edges(query_result['model']['bucket']['files'])\n        return {file['name']: file for file in files if file}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating download urls for a specific file in a specific run.", "response": "def download_url(self, project, file_name, run=None, entity=None):\n        \"\"\"Generate download urls\n\n        Args:\n            project (str): The project to download\n            file_name (str): The name of the file to download\n            run (str, optional): The run to upload to\n            entity (str, optional): The entity to scope this project to.  Defaults to wandb models\n\n        Returns:\n            A dict of extensions and urls\n\n                { \"url\": \"https://weights.url\", \"updatedAt\": '2013-04-26T22:22:23.832Z', 'md5': 'mZFLkyvTelC5g8XnyQrpOw==' }\n\n        \"\"\"\n        query = gql('''\n        query Model($name: String!, $fileName: String!, $entity: String!, $run: String!)  {\n            model(name: $name, entityName: $entity) {\n                bucket(name: $run) {\n                    files(names: [$fileName]) {\n                        edges {\n                            node {\n                                name\n                                url\n                                md5\n                                updatedAt\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        ''')\n        query_result = self.gql(query, variable_values={\n            'name': project, 'run': run or self.settings('run'), 'fileName': file_name,\n            'entity': entity or self.settings('entity')})\n        files = self._flatten_edges(query_result['model']['bucket']['files'])\n        return files[0] if len(files) > 0 and files[0].get('updatedAt') else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_file(self, url):\n        response = requests.get(url, stream=True)\n        response.raise_for_status()\n        return (int(response.headers.get('content-length', 0)), response)", "response": "Initiate a streaming download of the file with the content length of the file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload a file from a run and write it to wandb", "response": "def download_write_file(self, metadata, out_dir=None):\n        \"\"\"Download a file from a run and write it to wandb/\n\n        Args:\n            metadata (obj): The metadata object for the file to download. Comes from Api.download_urls().\n\n        Returns:\n            A tuple of the file's local path and the streaming response. The streaming response is None if the file already existed and was up to date.\n        \"\"\"\n        fileName = metadata['name']\n        path = os.path.join(out_dir or wandb_dir(), fileName)\n        if self.file_current(fileName, metadata['md5']):\n            return path, None\n\n        size, response = self.download_file(metadata['url'])\n\n        with open(path, \"wb\") as file:\n            for data in response.iter_content(chunk_size=1024):\n                file.write(data)\n\n        return path, response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload_file(self, url, file, callback=None, extra_headers={}):\n        extra_headers = extra_headers.copy()\n        response = None\n        if os.stat(file.name).st_size == 0:\n            raise CommError(\"%s is an empty file\" % file.name)\n        try:\n            progress = Progress(file, callback=callback)\n            response = requests.put(\n                url, data=progress, headers=extra_headers)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            total = progress.len\n            status = self._status_request(url, total)\n            # TODO(adrian): there's probably even more stuff we should add here\n            # like if we're offline, we should retry then too\n            if status.status_code in (308, 408, 500, 502, 503, 504):\n                util.sentry_reraise(retry.TransientException(exc=e))\n            else:\n                util.sentry_reraise(e)\n\n        return response", "response": "Uploads a file to the W&B with failure resumption\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a new agent in the database", "response": "def register_agent(self, host, sweep_id=None, project_name=None):\n        \"\"\"Register a new agent\n\n        Args:\n            host (str): hostname\n            persistent (bool): long running or oneoff\n            sweep (str): sweep id\n            project_name: (str): model that contains sweep\n        \"\"\"\n        mutation = gql('''\n        mutation CreateAgent(\n            $host: String!\n            $projectName: String!,\n            $entityName: String!,\n            $sweep: String!\n        ) {\n            createAgent(input: {\n                host: $host,\n                projectName: $projectName,\n                entityName: $entityName,\n                sweep: $sweep,\n            }) {\n                agent {\n                    id\n                }\n            }\n        }\n        ''')\n        if project_name is None:\n            project_name = self.settings('project')\n\n        # don't retry on validation errors\n        def no_retry_400(e):\n            if not isinstance(e, requests.HTTPError):\n                return True\n            if e.response.status_code != 400:\n                return True\n            body = json.loads(e.response.content)\n            raise UsageError(body['errors'][0]['message'])\n\n        response = self.gql(mutation, variable_values={\n            'host': host,\n            'entityName': self.settings(\"entity\"),\n            'projectName': project_name,\n            'sweep': sweep_id}, check_retry_fn=no_retry_400)\n        return response['createAgent']['agent']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef agent_heartbeat(self, agent_id, metrics, run_states):\n        mutation = gql('''\n        mutation Heartbeat(\n            $id: ID!,\n            $metrics: JSONString,\n            $runState: JSONString\n        ) {\n            agentHeartbeat(input: {\n                id: $id,\n                metrics: $metrics,\n                runState: $runState\n            }) {\n                agent {\n                    id\n                }\n                commands\n            }\n        }\n        ''')\n        try:\n            response = self.gql(mutation, variable_values={\n                'id': agent_id,\n                'metrics': json.dumps(metrics),\n                'runState': json.dumps(run_states)})\n        except Exception as e:\n            # GQL raises exceptions with stringified python dictionaries :/\n            message = ast.literal_eval(e.args[0])[\"message\"]\n            logger.error('Error communicating with W&B: %s', message)\n            return []\n        else:\n            return json.loads(response['agentHeartbeat']['commands'])", "response": "Notify server about agent state receive commands."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef file_current(self, fname, md5):\n        return os.path.isfile(fname) and util.md5_file(fname) == md5", "response": "Check if a file is the current one"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload files from W&B", "response": "def pull(self, project, run=None, entity=None):\n        \"\"\"Download files from W&B\n\n        Args:\n            project (str): The project to download\n            run (str, optional): The run to upload to\n            entity (str, optional): The entity to scope this project to.  Defaults to wandb models\n\n        Returns:\n            The requests library response object\n        \"\"\"\n        project, run = self.parse_slug(project, run=run)\n        urls = self.download_urls(project, run, entity)\n        responses = []\n        for fileName in urls:\n            _, response = self.download_write_file(urls[fileName])\n            if response:\n                responses.append(response)\n\n        return responses"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push(self, files, run=None, entity=None, project=None, description=None, force=True, progress=False):\n        if project is None:\n            project = self.get_project()\n        if project is None:\n            raise CommError(\"No project configured.\")\n        if run is None:\n            run = self.current_run_id\n\n        # TODO(adrian): we use a retriable version of self.upload_file() so\n        # will never retry self.upload_urls() here. Instead, maybe we should\n        # make push itself retriable.\n        run_id, result = self.upload_urls(\n            project, files, run, entity, description)\n        responses = []\n        for file_name, file_info in result.items():\n            try:\n                # To handle Windows paths\n                # TODO: this doesn't handle absolute paths...\n                normal_name = os.path.join(*file_name.split(\"/\"))\n                open_file = files[normal_name] if isinstance(\n                    files, dict) else open(normal_name, \"rb\")\n            except IOError:\n                print(\"%s does not exist\" % file_name)\n                continue\n            if progress:\n                if hasattr(progress, '__call__'):\n                    responses.append(self.upload_file_retry(\n                        file_info['url'], open_file, progress))\n                else:\n                    length = os.fstat(open_file.fileno()).st_size\n                    with click.progressbar(file=progress, length=length, label='Uploading file: %s' % (file_name),\n                                           fill_char=click.style('&', fg='green')) as bar:\n                        responses.append(self.upload_file_retry(\n                            file_info['url'], open_file, lambda bites, _: bar.update(bites)))\n            else:\n                responses.append(self.upload_file_retry(file_info['url'], open_file))\n            open_file.close()\n        return responses", "response": "Uploads multiple files to W&B"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_file_stream_api(self):\n        if not self._file_stream_api:\n            if self._current_run_id is None:\n                raise UsageError(\n                    'Must have a current run to use file stream API.')\n            self._file_stream_api = FileStreamApi(self, self._current_run_id)\n        return self._file_stream_api", "response": "This creates a new file pusher thread that talks to W&B"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a status request to the specified url and length", "response": "def _status_request(self, url, length):\n        \"\"\"Ask google how much we've uploaded\"\"\"\n        return requests.put(\n            url=url,\n            headers={'Content-Length': '0',\n                     'Content-Range': 'bytes */%i' % length}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the common prefix for all completions.", "response": "def get_common_complete_suffix(document, completions):\n    \"\"\"\n    Return the common prefix for all completions.\n    \"\"\"\n    # Take only completions that don't change the text before the cursor.\n    def doesnt_change_before_cursor(completion):\n        end = completion.text[:-completion.start_position]\n        return document.text_before_cursor.endswith(end)\n\n    completions2 = [c for c in completions if doesnt_change_before_cursor(c)]\n\n    # When there is at least one completion that changes the text before the\n    # cursor, don't return any common part.\n    if len(completions2) != len(completions):\n        return ''\n\n    # Return the common prefix.\n    def get_suffix(completion):\n        return completion.text[-completion.start_position:]\n\n    return _commonprefix([get_suffix(c) for c in completions2])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new Completion object from the given position.", "response": "def new_completion_from_position(self, position):\n        \"\"\"\n        (Only for internal use!)\n        Get a new completion by splitting this one. Used by\n        `CommandLineInterface` when it needs to have a list of new completions\n        after inserting the common prefix.\n        \"\"\"\n        assert isinstance(position, int) and position - self.start_position >= 0\n\n        return Completion(\n            text=self.text[position - self.start_position:],\n            display=self.display,\n            display_meta=self._display_meta,\n            get_display_meta=self._get_display_meta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef display_error(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except wandb.Error as e:\n            exc_type, exc_value, exc_traceback = sys.exc_info()\n            lines = traceback.format_exception(\n                exc_type, exc_value, exc_traceback)\n            logger.error(''.join(lines))\n            click_exc = ClickWandbException(e)\n            click_exc.orig_type = exc_type\n            six.reraise(ClickWandbException, click_exc, sys.exc_info()[2])\n    return wrapper", "response": "Decorator for catching common errors and re - raising as ClickWandbException"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prompt_for_project(ctx, entity):\n    result = ctx.invoke(projects, entity=entity, display=False)\n\n    try:\n        if len(result) == 0:\n            project = click.prompt(\"Enter a name for your first project\")\n            #description = editor()\n            project = api.upsert_project(project, entity=entity)[\"name\"]\n        else:\n            project_names = [project[\"name\"] for project in result]\n            question = {\n                'type': 'list',\n                'name': 'project_name',\n                'message': \"Which project should we use?\",\n                'choices': project_names + [\"Create New\"]\n            }\n            result = whaaaaat.prompt([question])\n            if result:\n                project = result['project_name']\n            else:\n                project = \"Create New\"\n            # TODO: check with the server if the project exists\n            if project == \"Create New\":\n                project = click.prompt(\n                    \"Enter a name for your new project\", value_proc=api.format_project)\n                #description = editor()\n                project = api.upsert_project(project, entity=entity)[\"name\"]\n\n    except wandb.apis.CommError as e:\n        raise ClickException(str(e))\n\n    return project", "response": "Ask the user for a project creating one if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli(ctx):\n    wandb.try_to_set_up_global_logging()\n    if ctx.invoked_subcommand is None:\n        click.echo(ctx.get_help())", "response": "A simple command line tool for listing all available weights and weights."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps for docker run", "response": "def docker_run(ctx, docker_run_args, help):\n    \"\"\"Simple docker wrapper that adds WANDB_API_KEY and WANDB_DOCKER to any docker run command.\n    This will also set the runtime to nvidia if the nvidia-docker executable is present on the system\n    and --runtime wasn't set.\n    \"\"\"\n    args = list(docker_run_args)\n    if len(args) > 0 and args[0] == \"run\":\n        args.pop(0)\n    if help or len(args) == 0:\n        wandb.termlog(\"This commands adds wandb env variables to your docker run calls\")\n        subprocess.call(['docker', 'run'] + args + ['--help'])\n        exit()\n    #TODO: is this what we want?\n    if len([a for a in args if a.startswith(\"--runtime\")]) == 0 and find_executable('nvidia-docker'):\n        args = [\"--runtime\", \"nvidia\"] + args\n    #TODO: image_from_docker_args uses heuristics to find the docker image arg, there are likely cases\n    #where this won't work\n    image = util.image_from_docker_args(args)\n    resolved_image = None\n    if image:\n        resolved_image = wandb.docker.image_id(image)\n    if resolved_image:\n        args = ['-e', 'WANDB_DOCKER=%s' % resolved_image] + args\n    else:\n        wandb.termlog(\"Couldn't detect image argument, running command without the WANDB_DOCKER env variable\")\n    if api.api_key:\n        args = ['-e', 'WANDB_API_KEY=%s' % api.api_key] + args\n    else:\n        wandb.termlog(\"Not logged in, run `wandb login` from the host machine to enable result logging\")\n    subprocess.call(['docker', 'run'] + args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef docker(ctx, docker_run_args, docker_image, nvidia, digest, jupyter, dir, no_dir, shell, port, cmd, no_tty):\n    if not find_executable('docker'):\n        raise ClickException(\n            \"Docker not installed, install it from https://docker.com\" )\n    args = list(docker_run_args)\n    image = docker_image or \"\"\n    # remove run for users used to nvidia-docker\n    if len(args) > 0 and args[0] == \"run\":\n        args.pop(0)\n    if image == \"\" and len(args) > 0:\n        image = args.pop(0)\n    # If the user adds docker args without specifying an image (should be rare)\n    if not util.docker_image_regex(image.split(\"@\")[0]):\n        if image:\n            args = args + [image]\n        image = wandb.docker.default_image(gpu=nvidia)\n        subprocess.call([\"docker\", \"pull\", image])\n    _, repo_name, tag = wandb.docker.parse(image)\n\n    resolved_image = wandb.docker.image_id(image)\n    if resolved_image is None:\n        raise ClickException(\n            \"Couldn't find image locally or in a registry, try running `docker pull %s`\" % image)\n    if digest:\n        sys.stdout.write(resolved_image)\n        exit(0)\n\n    existing = wandb.docker.shell(\n        [\"ps\", \"-f\", \"ancestor=%s\" % resolved_image, \"-q\"])\n    if existing:\n        question = {\n            'type': 'confirm',\n            'name': 'attach',\n            'message': \"Found running container with the same image, do you want to attach?\",\n        }\n        result = whaaaaat.prompt([question])\n        if result and result['attach']:\n            subprocess.call(['docker', 'attach', existing.split(\"\\n\")[0]])\n            exit(0)\n    cwd = os.getcwd()\n    command = ['docker', 'run', '-e', 'LANG=C.UTF-8', '-e', 'WANDB_DOCKER=%s' % resolved_image, '--ipc=host',\n                '-v', wandb.docker.entrypoint+':/wandb-entrypoint.sh', '--entrypoint', '/wandb-entrypoint.sh']\n    if nvidia:\n        command.extend(['--runtime', 'nvidia'])\n    if not no_dir:\n        #TODO: We should default to the working directory if defined\n        command.extend(['-v', cwd+\":\"+dir, '-w', dir])\n    if api.api_key:\n        command.extend(['-e', 'WANDB_API_KEY=%s' % api.api_key])\n    else:\n        wandb.termlog(\"Couldn't find WANDB_API_KEY, run `wandb login` to enable streaming metrics\")\n    if jupyter:\n        command.extend(['-e', 'WANDB_ENSURE_JUPYTER=1', '-p', port+':8888'])\n        no_tty = True\n        cmd = \"jupyter lab --no-browser --ip=0.0.0.0 --allow-root --NotebookApp.token= --notebook-dir %s\" % dir\n    command.extend(args)\n    if no_tty:\n        command.extend([image, shell, \"-c\", cmd])\n    else:\n        if cmd:\n            command.extend(['-e', 'WANDB_COMMAND=%s' % cmd])\n        command.extend(['-it', image, shell])\n        wandb.termlog(\"Launching docker container \\U0001F6A2\")\n    subprocess.call(command)", "response": "W&B docker lets you run your code in a nvidia - docker image"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_values(self):\n        path = self._config_path()\n        if path is not None and os.path.isfile(path):\n            self._load_file(path)", "response": "Load config. yaml from the run directory if available."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads existing config from JSON", "response": "def load_json(self, json):\n        \"\"\"Loads existing config from JSON\"\"\"\n        for key in json:\n            if key == \"wandb_version\":\n                continue\n            self._items[key] = json[key].get('value')\n            self._descriptions[key] = json[key].get('desc')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef persist(self):\n        # In dryrun mode, without wandb run, we don't\n        # save config  on initial load, because the run directory\n        # may not be created yet (because we don't know if we're\n        # being used in a run context, or as an API).\n        # TODO: Defer saving somehow, maybe via an events system\n        path = self._config_path()\n        if path is None:\n            return\n        with open(path, \"w\") as conf_file:\n            conf_file.write(str(self))", "response": "Stores the current configuration for pushing to W&B"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_upstream_fork_point(self):\n        possible_relatives = []\n        try:\n            if not self.repo:\n                return None\n            try:\n                active_branch = self.repo.active_branch\n            except (TypeError, ValueError):\n                logger.debug(\"git is in a detached head state\")\n                return None  # detached head\n            else:\n                tracking_branch = active_branch.tracking_branch()\n                if tracking_branch:\n                    possible_relatives.append(tracking_branch.commit)\n\n            if not possible_relatives:\n                for branch in self.repo.branches:\n                    tracking_branch = branch.tracking_branch()\n                    if tracking_branch is not None:\n                        possible_relatives.append(tracking_branch.commit)\n\n            head = self.repo.head\n            most_recent_ancestor = None\n            for possible_relative in possible_relatives:\n                # at most one:\n                for ancestor in self.repo.merge_base(head, possible_relative):\n                    if most_recent_ancestor is None:\n                        most_recent_ancestor = ancestor\n                    elif self.repo.is_ancestor(most_recent_ancestor, ancestor):\n                        most_recent_ancestor = ancestor\n            return most_recent_ancestor\n        except exc.GitCommandError as e:\n            logger.debug(\"git remote upstream fork point could not be found\")\n            logger.debug(e.message)\n            return None", "response": "Get the most recent ancestor of the upstream branch."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwaits for a list of file descriptors to become ready for reading.", "response": "def select_fds(read_fds, timeout, selector=AutoSelector):\n    \"\"\"\n    Wait for a list of file descriptors (`read_fds`) to become ready for\n    reading. This chooses the most appropriate select-tool for use in\n    prompt-toolkit.\n    \"\"\"\n    # Map to ensure that we return the objects that were passed in originally.\n    # Whether they are a fd integer or an object that has a fileno().\n    # (The 'poll' implementation for instance, returns always integers.)\n    fd_map = dict((fd_to_int(fd), fd) for fd in read_fds)\n\n    # Wait, using selector.\n    sel = selector()\n    try:\n        for fd in read_fds:\n            sel.register(fd)\n\n        result = sel.select(timeout)\n\n        if result is not None:\n            return [fd_map[fd_to_int(fd)] for fd in result]\n    finally:\n        sel.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_text_object_decorator(registry):\n    assert isinstance(registry, BaseRegistry)\n\n    operator_given = ViWaitingForTextObjectMode()\n    navigation_mode = ViNavigationMode()\n    selection_mode = ViSelectionMode()\n\n    def text_object_decorator(*keys, **kw):\n        \"\"\"\n        Register a text object function.\n\n        Usage::\n\n            @text_object('w', filter=..., no_move_handler=False)\n            def handler(event):\n                # Return a text object for this key.\n                return TextObject(...)\n\n        :param no_move_handler: Disable the move handler in navigation mode.\n            (It's still active in selection mode.)\n        \"\"\"\n        filter = kw.pop('filter', Always())\n        no_move_handler = kw.pop('no_move_handler', False)\n        no_selection_handler = kw.pop('no_selection_handler', False)\n        eager = kw.pop('eager', False)\n        assert not kw\n\n        def decorator(text_object_func):\n            assert callable(text_object_func)\n\n            @registry.add_binding(*keys, filter=operator_given & filter, eager=eager)\n            def _(event):\n                # Arguments are multiplied.\n                vi_state = event.cli.vi_state\n                event._arg = (vi_state.operator_arg or 1) * (event.arg or 1)\n\n                # Call the text object handler.\n                text_obj = text_object_func(event)\n                if text_obj is not None:\n                    assert isinstance(text_obj, TextObject)\n\n                    # Call the operator function with the text object.\n                    vi_state.operator_func(event, text_obj)\n\n                # Clear operator.\n                event.cli.vi_state.operator_func = None\n                event.cli.vi_state.operator_arg = None\n\n            # Register a move operation. (Doesn't need an operator.)\n            if not no_move_handler:\n                @registry.add_binding(*keys, filter=~operator_given & filter & navigation_mode, eager=eager)\n                def _(event):\n                    \" Move handler for navigation mode. \"\n                    text_object = text_object_func(event)\n                    event.current_buffer.cursor_position += text_object.start\n\n            # Register a move selection operation.\n            if not no_selection_handler:\n                @registry.add_binding(*keys, filter=~operator_given & filter & selection_mode, eager=eager)\n                def _(event):\n                    \" Move handler for selection mode. \"\n                    text_object = text_object_func(event)\n                    buff = event.current_buffer\n\n                    # When the text object has both a start and end position, like 'i(' or 'iw',\n                    # Turn this into a selection, otherwise the cursor.\n                    if text_object.end:\n                        # Take selection positions from text object.\n                        start, end = text_object.operator_range(buff.document)\n                        start += buff.cursor_position\n                        end += buff.cursor_position\n\n                        buff.selection_state.original_cursor_position = start\n                        buff.cursor_position = end\n\n                        # Take selection type from text object.\n                        if text_object.type == TextObjectType.LINEWISE:\n                            buff.selection_state.type = SelectionType.LINES\n                        else:\n                            buff.selection_state.type = SelectionType.CHARACTERS\n                    else:\n                        event.current_buffer.cursor_position += text_object.start\n\n            # Make it possible to chain @text_object decorators.\n            return text_object_func\n\n        return decorator\n    return text_object_decorator", "response": "Create a decorator that can be used to register Vi text objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a decorator that can be used to register Vi operators.", "response": "def create_operator_decorator(registry):\n    \"\"\"\n    Create a decorator that can be used for registering Vi operators.\n    \"\"\"\n    assert isinstance(registry, BaseRegistry)\n\n    operator_given = ViWaitingForTextObjectMode()\n    navigation_mode = ViNavigationMode()\n    selection_mode = ViSelectionMode()\n\n    def operator_decorator(*keys, **kw):\n        \"\"\"\n        Register a Vi operator.\n\n        Usage::\n\n            @operator('d', filter=...)\n            def handler(cli, text_object):\n                # Do something with the text object here.\n        \"\"\"\n        filter = kw.pop('filter', Always())\n        eager = kw.pop('eager', False)\n        assert not kw\n\n        def decorator(operator_func):\n            @registry.add_binding(*keys, filter=~operator_given & filter & navigation_mode, eager=eager)\n            def _(event):\n                \"\"\"\n                Handle operator in navigation mode.\n                \"\"\"\n                # When this key binding is matched, only set the operator\n                # function in the ViState. We should execute it after a text\n                # object has been received.\n                event.cli.vi_state.operator_func = operator_func\n                event.cli.vi_state.operator_arg = event.arg\n\n            @registry.add_binding(*keys, filter=~operator_given & filter & selection_mode, eager=eager)\n            def _(event):\n                \"\"\"\n                Handle operator in selection mode.\n                \"\"\"\n                buff = event.current_buffer\n                selection_state = buff.selection_state\n\n                # Create text object from selection.\n                if selection_state.type == SelectionType.LINES:\n                    text_obj_type = TextObjectType.LINEWISE\n                elif selection_state.type == SelectionType.BLOCK:\n                    text_obj_type = TextObjectType.BLOCK\n                else:\n                    text_obj_type = TextObjectType.INCLUSIVE\n\n                text_object = TextObject(\n                    selection_state.original_cursor_position - buff.cursor_position,\n                    type=text_obj_type)\n\n                # Execute operator.\n                operator_func(event, text_object)\n\n                # Quit selection mode.\n                buff.selection_state = None\n\n            return operator_func\n        return decorator\n    return operator_decorator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_vi_bindings(get_search_state=None):\n    # Note: Some key bindings have the \"~IsReadOnly()\" filter added. This\n    #       prevents the handler to be executed when the focus is on a\n    #       read-only buffer.\n    #       This is however only required for those that change the ViState to\n    #       INSERT mode. The `Buffer` class itself throws the\n    #       `EditReadOnlyBuffer` exception for any text operations which is\n    #       handled correctly. There is no need to add \"~IsReadOnly\" to all key\n    #       bindings that do text manipulation.\n\n    registry = ConditionalRegistry(Registry(), ViMode())\n    handle = registry.add_binding\n\n    # Default get_search_state.\n    if get_search_state is None:\n        def get_search_state(cli): return cli.search_state\n\n    # (Note: Always take the navigation bindings in read-only mode, even when\n    #  ViState says different.)\n    navigation_mode = ViNavigationMode()\n    insert_mode = ViInsertMode()\n    insert_multiple_mode = ViInsertMultipleMode()\n    replace_mode = ViReplaceMode()\n    selection_mode = ViSelectionMode()\n    operator_given = ViWaitingForTextObjectMode()\n    digraph_mode = ViDigraphMode()\n\n    vi_transform_functions = [\n        # Rot 13 transformation\n        (('g', '?'), Always(), lambda string: codecs.encode(string, 'rot_13')),\n\n        # To lowercase\n        (('g', 'u'), Always(), lambda string: string.lower()),\n\n        # To uppercase.\n        (('g', 'U'), Always(), lambda string: string.upper()),\n\n        # Swap case.\n        (('g', '~'), Always(), lambda string: string.swapcase()),\n        (('~', ), Condition(lambda cli: cli.vi_state.tilde_operator), lambda string: string.swapcase()),\n    ]\n\n    # Insert a character literally (quoted insert).\n    handle(Keys.ControlV, filter=insert_mode)(get_by_name('quoted-insert'))\n\n    @handle(Keys.Escape)\n    def _(event):\n        \"\"\"\n        Escape goes to vi navigation mode.\n        \"\"\"\n        buffer = event.current_buffer\n        vi_state = event.cli.vi_state\n\n        if vi_state.input_mode in (InputMode.INSERT, InputMode.REPLACE):\n            buffer.cursor_position += buffer.document.get_cursor_left_position()\n\n        vi_state.reset(InputMode.NAVIGATION)\n\n        if bool(buffer.selection_state):\n            buffer.exit_selection()\n\n    @handle('k', filter=selection_mode)\n    def _(event):\n        \"\"\"\n        Arrow up in selection mode.\n        \"\"\"\n        event.current_buffer.cursor_up(count=event.arg)\n\n    @handle('j', filter=selection_mode)\n    def _(event):\n        \"\"\"\n        Arrow down in selection mode.\n        \"\"\"\n        event.current_buffer.cursor_down(count=event.arg)\n\n    @handle(Keys.Up, filter=navigation_mode)\n    @handle(Keys.ControlP, filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Arrow up and ControlP in navigation mode go up.\n        \"\"\"\n        event.current_buffer.auto_up(count=event.arg)\n\n    @handle('k', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Go up, but if we enter a new history entry, move to the start of the\n        line.\n        \"\"\"\n        event.current_buffer.auto_up(\n            count=event.arg, go_to_start_of_line_if_history_changes=True)\n\n    @handle(Keys.Down, filter=navigation_mode)\n    @handle(Keys.ControlN, filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Arrow down and Control-N in navigation mode.\n        \"\"\"\n        event.current_buffer.auto_down(count=event.arg)\n\n    @handle('j', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Go down, but if we enter a new history entry, go to the start of the line.\n        \"\"\"\n        event.current_buffer.auto_down(\n            count=event.arg, go_to_start_of_line_if_history_changes=True)\n\n    @handle(Keys.ControlH, filter=navigation_mode)\n    @handle(Keys.Backspace, filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        In navigation-mode, move cursor.\n        \"\"\"\n        event.current_buffer.cursor_position += \\\n            event.current_buffer.document.get_cursor_left_position(count=event.arg)\n\n    @handle(Keys.ControlN, filter=insert_mode)\n    def _(event):\n        b = event.current_buffer\n\n        if b.complete_state:\n            b.complete_next()\n        else:\n            event.cli.start_completion(select_first=True)\n\n    @handle(Keys.ControlP, filter=insert_mode)\n    def _(event):\n        \"\"\"\n        Control-P: To previous completion.\n        \"\"\"\n        b = event.current_buffer\n\n        if b.complete_state:\n            b.complete_previous()\n        else:\n            event.cli.start_completion(select_last=True)\n\n    @handle(Keys.ControlY, filter=insert_mode)\n    def _(event):\n        \"\"\"\n        Accept current completion.\n        \"\"\"\n        event.current_buffer.complete_state = None\n\n    @handle(Keys.ControlE, filter=insert_mode)\n    def _(event):\n        \"\"\"\n        Cancel completion. Go back to originally typed text.\n        \"\"\"\n        event.current_buffer.cancel_completion()\n\n    @handle(Keys.ControlJ, filter=navigation_mode)   # XXX: only if the selected buffer has a return handler.\n    def _(event):\n        \"\"\"\n        In navigation mode, pressing enter will always return the input.\n        \"\"\"\n        b = event.current_buffer\n\n        if b.accept_action.is_returnable:\n            b.accept_action.validate_and_handle(event.cli, b)\n\n    # ** In navigation mode **\n\n    # List of navigation commands: http://hea-www.harvard.edu/~fine/Tech/vi.html\n\n    @handle(Keys.Insert, filter=navigation_mode)\n    def _(event):\n        \" Presing the Insert key. \"\n        event.cli.vi_state.input_mode = InputMode.INSERT\n\n    @handle('a', filter=navigation_mode & ~IsReadOnly())\n            # ~IsReadOnly, because we want to stay in navigation mode for\n            # read-only buffers.\n    def _(event):\n        event.current_buffer.cursor_position += event.current_buffer.document.get_cursor_right_position()\n        event.cli.vi_state.input_mode = InputMode.INSERT\n\n    @handle('A', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        event.current_buffer.cursor_position += event.current_buffer.document.get_end_of_line_position()\n        event.cli.vi_state.input_mode = InputMode.INSERT\n\n    @handle('C', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        \"\"\"\n        # Change to end of line.\n        # Same as 'c$' (which is implemented elsewhere.)\n        \"\"\"\n        buffer = event.current_buffer\n\n        deleted = buffer.delete(count=buffer.document.get_end_of_line_position())\n        event.cli.clipboard.set_text(deleted)\n        event.cli.vi_state.input_mode = InputMode.INSERT\n\n    @handle('c', 'c', filter=navigation_mode & ~IsReadOnly())\n    @handle('S', filter=navigation_mode & ~IsReadOnly())\n    def _(event):  # TODO: implement 'arg'\n        \"\"\"\n        Change current line\n        \"\"\"\n        buffer = event.current_buffer\n\n        # We copy the whole line.\n        data = ClipboardData(buffer.document.current_line, SelectionType.LINES)\n        event.cli.clipboard.set_data(data)\n\n        # But we delete after the whitespace\n        buffer.cursor_position += buffer.document.get_start_of_line_position(after_whitespace=True)\n        buffer.delete(count=buffer.document.get_end_of_line_position())\n        event.cli.vi_state.input_mode = InputMode.INSERT\n\n    @handle('D', filter=navigation_mode)\n    def _(event):\n        buffer = event.current_buffer\n        deleted = buffer.delete(count=buffer.document.get_end_of_line_position())\n        event.cli.clipboard.set_text(deleted)\n\n    @handle('d', 'd', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Delete line. (Or the following 'n' lines.)\n        \"\"\"\n        buffer = event.current_buffer\n\n        # Split string in before/deleted/after text.\n        lines = buffer.document.lines\n\n        before = '\\n'.join(lines[:buffer.document.cursor_position_row])\n        deleted = '\\n'.join(lines[buffer.document.cursor_position_row:\n                                  buffer.document.cursor_position_row + event.arg])\n        after = '\\n'.join(lines[buffer.document.cursor_position_row + event.arg:])\n\n        # Set new text.\n        if before and after:\n            before = before + '\\n'\n\n        # Set text and cursor position.\n        buffer.document = Document(\n            text=before + after,\n            # Cursor At the start of the first 'after' line, after the leading whitespace.\n            cursor_position = len(before) + len(after) - len(after.lstrip(' ')))\n\n        # Set clipboard data\n        event.cli.clipboard.set_data(ClipboardData(deleted, SelectionType.LINES))\n\n    @handle('x', filter=selection_mode)\n    def _(event):\n        \"\"\"\n        Cut selection.\n        ('x' is not an operator.)\n        \"\"\"\n        clipboard_data = event.current_buffer.cut_selection()\n        event.cli.clipboard.set_data(clipboard_data)\n\n    @handle('i', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        event.cli.vi_state.input_mode = InputMode.INSERT\n\n    @handle('I', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        event.cli.vi_state.input_mode = InputMode.INSERT\n        event.current_buffer.cursor_position += \\\n            event.current_buffer.document.get_start_of_line_position(after_whitespace=True)\n\n    @Condition\n    def in_block_selection(cli):\n        buff = cli.current_buffer\n        return buff.selection_state and buff.selection_state.type == SelectionType.BLOCK\n\n    @handle('I', filter=in_block_selection & ~IsReadOnly())\n    def go_to_block_selection(event, after=False):\n        \" Insert in block selection mode. \"\n        buff = event.current_buffer\n\n        # Store all cursor positions.\n        positions = []\n\n        if after:\n            def get_pos(from_to):\n                return from_to[1] + 1\n        else:\n            def get_pos(from_to):\n                return from_to[0]\n\n        for i, from_to in enumerate(buff.document.selection_ranges()):\n            positions.append(get_pos(from_to))\n            if i == 0:\n                buff.cursor_position = get_pos(from_to)\n\n        buff.multiple_cursor_positions = positions\n\n        # Go to 'INSERT_MULTIPLE' mode.\n        event.cli.vi_state.input_mode = InputMode.INSERT_MULTIPLE\n        buff.exit_selection()\n\n    @handle('A', filter=in_block_selection & ~IsReadOnly())\n    def _(event):\n        go_to_block_selection(event, after=True)\n\n    @handle('J', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        \" Join lines. \"\n        for i in range(event.arg):\n            event.current_buffer.join_next_line()\n\n    @handle('g', 'J', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        \" Join lines without space. \"\n        for i in range(event.arg):\n            event.current_buffer.join_next_line(separator='')\n\n    @handle('J', filter=selection_mode & ~IsReadOnly())\n    def _(event):\n        \" Join selected lines. \"\n        event.current_buffer.join_selected_lines()\n\n    @handle('g', 'J', filter=selection_mode & ~IsReadOnly())\n    def _(event):\n        \" Join selected lines without space. \"\n        event.current_buffer.join_selected_lines(separator='')\n\n    @handle('p', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Paste after\n        \"\"\"\n        event.current_buffer.paste_clipboard_data(\n            event.cli.clipboard.get_data(),\n            count=event.arg,\n            paste_mode=PasteMode.VI_AFTER)\n\n    @handle('P', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Paste before\n        \"\"\"\n        event.current_buffer.paste_clipboard_data(\n            event.cli.clipboard.get_data(),\n            count=event.arg,\n            paste_mode=PasteMode.VI_BEFORE)\n\n    @handle('\"', Keys.Any, 'p', filter=navigation_mode)\n    def _(event):\n        \" Paste from named register. \"\n        c = event.key_sequence[1].data\n        if c in vi_register_names:\n            data = event.cli.vi_state.named_registers.get(c)\n            if data:\n                event.current_buffer.paste_clipboard_data(\n                    data, count=event.arg, paste_mode=PasteMode.VI_AFTER)\n\n    @handle('\"', Keys.Any, 'P', filter=navigation_mode)\n    def _(event):\n        \" Paste (before) from named register. \"\n        c = event.key_sequence[1].data\n        if c in vi_register_names:\n            data = event.cli.vi_state.named_registers.get(c)\n            if data:\n                event.current_buffer.paste_clipboard_data(\n                    data, count=event.arg, paste_mode=PasteMode.VI_BEFORE)\n\n    @handle('r', Keys.Any, filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Replace single character under cursor\n        \"\"\"\n        event.current_buffer.insert_text(event.data * event.arg, overwrite=True)\n        event.current_buffer.cursor_position -= 1\n\n    @handle('R', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Go to 'replace'-mode.\n        \"\"\"\n        event.cli.vi_state.input_mode = InputMode.REPLACE\n\n    @handle('s', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        \"\"\"\n        Substitute with new text\n        (Delete character(s) and go to insert mode.)\n        \"\"\"\n        text = event.current_buffer.delete(count=event.arg)\n        event.cli.clipboard.set_text(text)\n        event.cli.vi_state.input_mode = InputMode.INSERT\n\n    @handle('u', filter=navigation_mode, save_before=(lambda e: False))\n    def _(event):\n        for i in range(event.arg):\n            event.current_buffer.undo()\n\n    @handle('V', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Start lines selection.\n        \"\"\"\n        event.current_buffer.start_selection(selection_type=SelectionType.LINES)\n\n    @handle(Keys.ControlV, filter=navigation_mode)\n    def _(event):\n        \" Enter block selection mode. \"\n        event.current_buffer.start_selection(selection_type=SelectionType.BLOCK)\n\n    @handle('V', filter=selection_mode)\n    def _(event):\n        \"\"\"\n        Exit line selection mode, or go from non line selection mode to line\n        selection mode.\n        \"\"\"\n        selection_state = event.current_buffer.selection_state\n\n        if selection_state.type != SelectionType.LINES:\n            selection_state.type = SelectionType.LINES\n        else:\n            event.current_buffer.exit_selection()\n\n    @handle('v', filter=navigation_mode)\n    def _(event):\n        \" Enter character selection mode. \"\n        event.current_buffer.start_selection(selection_type=SelectionType.CHARACTERS)\n\n    @handle('v', filter=selection_mode)\n    def _(event):\n        \"\"\"\n        Exit character selection mode, or go from non-character-selection mode\n        to character selection mode.\n        \"\"\"\n        selection_state = event.current_buffer.selection_state\n\n        if selection_state.type != SelectionType.CHARACTERS:\n            selection_state.type = SelectionType.CHARACTERS\n        else:\n            event.current_buffer.exit_selection()\n\n    @handle(Keys.ControlV, filter=selection_mode)\n    def _(event):\n        \"\"\"\n        Exit block selection mode, or go from non block selection mode to block\n        selection mode.\n        \"\"\"\n        selection_state = event.current_buffer.selection_state\n\n        if selection_state.type != SelectionType.BLOCK:\n            selection_state.type = SelectionType.BLOCK\n        else:\n            event.current_buffer.exit_selection()\n\n\n    @handle('a', 'w', filter=selection_mode)\n    @handle('a', 'W', filter=selection_mode)\n    def _(event):\n        \"\"\"\n        Switch from visual linewise mode to visual characterwise mode.\n        \"\"\"\n        buffer = event.current_buffer\n\n        if buffer.selection_state and buffer.selection_state.type == SelectionType.LINES:\n            buffer.selection_state.type = SelectionType.CHARACTERS\n\n    @handle('x', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Delete character.\n        \"\"\"\n        text = event.current_buffer.delete(count=event.arg)\n        event.cli.clipboard.set_text(text)\n\n    @handle('X', filter=navigation_mode)\n    def _(event):\n        text = event.current_buffer.delete_before_cursor()\n        event.cli.clipboard.set_text(text)\n\n    @handle('y', 'y', filter=navigation_mode)\n    @handle('Y', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Yank the whole line.\n        \"\"\"\n        text = '\\n'.join(event.current_buffer.document.lines_from_current[:event.arg])\n        event.cli.clipboard.set_data(ClipboardData(text, SelectionType.LINES))\n\n    @handle('+', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Move to first non whitespace of next line\n        \"\"\"\n        buffer = event.current_buffer\n        buffer.cursor_position += buffer.document.get_cursor_down_position(count=event.arg)\n        buffer.cursor_position += buffer.document.get_start_of_line_position(after_whitespace=True)\n\n    @handle('-', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Move to first non whitespace of previous line\n        \"\"\"\n        buffer = event.current_buffer\n        buffer.cursor_position += buffer.document.get_cursor_up_position(count=event.arg)\n        buffer.cursor_position += buffer.document.get_start_of_line_position(after_whitespace=True)\n\n    @handle('>', '>', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Indent lines.\n        \"\"\"\n        buffer = event.current_buffer\n        current_row = buffer.document.cursor_position_row\n        indent(buffer, current_row, current_row + event.arg)\n\n    @handle('<', '<', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Unindent lines.\n        \"\"\"\n        current_row = event.current_buffer.document.cursor_position_row\n        unindent(event.current_buffer, current_row, current_row + event.arg)\n\n    @handle('O', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        \"\"\"\n        Open line above and enter insertion mode\n        \"\"\"\n        event.current_buffer.insert_line_above(\n                copy_margin=not event.cli.in_paste_mode)\n        event.cli.vi_state.input_mode = InputMode.INSERT\n\n    @handle('o', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        \"\"\"\n        Open line below and enter insertion mode\n        \"\"\"\n        event.current_buffer.insert_line_below(\n                copy_margin=not event.cli.in_paste_mode)\n        event.cli.vi_state.input_mode = InputMode.INSERT\n\n    @handle('~', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Reverse case of current character and move cursor forward.\n        \"\"\"\n        buffer = event.current_buffer\n        c = buffer.document.current_char\n\n        if c is not None and c != '\\n':\n            buffer.insert_text(c.swapcase(), overwrite=True)\n\n    @handle('g', 'u', 'u', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        \" Lowercase current line. \"\n        buff = event.current_buffer\n        buff.transform_current_line(lambda s: s.lower())\n\n    @handle('g', 'U', 'U', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        \" Uppercase current line. \"\n        buff = event.current_buffer\n        buff.transform_current_line(lambda s: s.upper())\n\n    @handle('g', '~', '~', filter=navigation_mode & ~IsReadOnly())\n    def _(event):\n        \" Swap case of the current line. \"\n        buff = event.current_buffer\n        buff.transform_current_line(lambda s: s.swapcase())\n\n    @handle('#', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Go to previous occurence of this word.\n        \"\"\"\n        b = event.cli.current_buffer\n\n        search_state = get_search_state(event.cli)\n        search_state.text = b.document.get_word_under_cursor()\n        search_state.direction = IncrementalSearchDirection.BACKWARD\n\n        b.apply_search(search_state, count=event.arg,\n                       include_current_position=False)\n\n    @handle('*', filter=navigation_mode)\n    def _(event):\n        \"\"\"\n        Go to next occurence of this word.\n        \"\"\"\n        b = event.cli.current_buffer\n\n        search_state = get_search_state(event.cli)\n        search_state.text = b.document.get_word_under_cursor()\n        search_state.direction = IncrementalSearchDirection.FORWARD\n\n        b.apply_search(search_state, count=event.arg,\n                       include_current_position=False)\n\n    @handle('(', filter=navigation_mode)\n    def _(event):\n        # TODO: go to begin of sentence.\n        # XXX: should become text_object.\n        pass\n\n    @handle(')', filter=navigation_mode)\n    def _(event):\n        # TODO: go to end of sentence.\n        # XXX: should become text_object.\n        pass\n\n    operator = create_operator_decorator(registry)\n    text_object = create_text_object_decorator(registry)\n\n    @text_object(Keys.Any, filter=operator_given)\n    def _(event):\n        \"\"\"\n        Unknown key binding while waiting for a text object.\n        \"\"\"\n        event.cli.output.bell()\n\n    #\n    # *** Operators ***\n    #\n\n    def create_delete_and_change_operators(delete_only, with_register=False):\n        \"\"\"\n        Delete and change operators.\n\n        :param delete_only: Create an operator that deletes, but doesn't go to insert mode.\n        :param with_register: Copy the deleted text to this named register instead of the clipboard.\n        \"\"\"\n        if with_register:\n            handler_keys = ('\"', Keys.Any, 'cd'[delete_only])\n        else:\n            handler_keys = 'cd'[delete_only]\n\n        @operator(*handler_keys, filter=~IsReadOnly())\n        def delete_or_change_operator(event, text_object):\n            clipboard_data = None\n            buff = event.current_buffer\n\n            if text_object:\n                new_document, clipboard_data = text_object.cut(buff)\n                buff.document = new_document\n\n            # Set deleted/changed text to clipboard or named register.\n            if clipboard_data and clipboard_data.text:\n                if with_register:\n                    reg_name = event.key_sequence[1].data\n                    if reg_name in vi_register_names:\n                        event.cli.vi_state.named_registers[reg_name] = clipboard_data\n                else:\n                    event.cli.clipboard.set_data(clipboard_data)\n\n            # Only go back to insert mode in case of 'change'.\n            if not delete_only:\n                event.cli.vi_state.input_mode = InputMode.INSERT\n\n    create_delete_and_change_operators(False, False)\n    create_delete_and_change_operators(False, True)\n    create_delete_and_change_operators(True, False)\n    create_delete_and_change_operators(True, True)\n\n    def create_transform_handler(filter, transform_func, *a):\n        @operator(*a, filter=filter & ~IsReadOnly())\n        def _(event, text_object):\n            \"\"\"\n            Apply transformation (uppercase, lowercase, rot13, swap case).\n            \"\"\"\n            buff = event.current_buffer\n            start, end = text_object.operator_range(buff.document)\n\n            if start < end:\n                # Transform.\n                buff.transform_region(\n                    buff.cursor_position + start,\n                    buff.cursor_position + end,\n                    transform_func)\n\n                # Move cursor\n                buff.cursor_position += (text_object.end or text_object.start)\n\n    for k, f, func in vi_transform_functions:\n        create_transform_handler(f, func, *k)\n\n    @operator('y')\n    def yank_handler(event, text_object):\n        \"\"\"\n        Yank operator. (Copy text.)\n        \"\"\"\n        _, clipboard_data = text_object.cut(event.current_buffer)\n        if clipboard_data.text:\n            event.cli.clipboard.set_data(clipboard_data)\n\n    @operator('\"', Keys.Any, 'y')\n    def _(event, text_object):\n        \" Yank selection to named register. \"\n        c = event.key_sequence[1].data\n        if c in vi_register_names:\n            _, clipboard_data = text_object.cut(event.current_buffer)\n            event.cli.vi_state.named_registers[c] = clipboard_data\n\n    @operator('>')\n    def _(event, text_object):\n        \"\"\"\n        Indent.\n        \"\"\"\n        buff = event.current_buffer\n        from_, to = text_object.get_line_numbers(buff)\n        indent(buff, from_, to + 1, count=event.arg)\n\n    @operator('<')\n    def _(event, text_object):\n        \"\"\"\n        Unindent.\n        \"\"\"\n        buff = event.current_buffer\n        from_, to = text_object.get_line_numbers(buff)\n        unindent(buff, from_, to + 1, count=event.arg)\n\n    @operator('g', 'q')\n    def _(event, text_object):\n        \"\"\"\n        Reshape text.\n        \"\"\"\n        buff = event.current_buffer\n        from_, to = text_object.get_line_numbers(buff)\n        reshape_text(buff, from_, to)\n\n    #\n    # *** Text objects ***\n    #\n\n    @text_object('b')\n    def _(event):\n        \"\"\" Move one word or token left. \"\"\"\n        return TextObject(event.current_buffer.document.find_start_of_previous_word(count=event.arg) or 0)\n\n    @text_object('B')\n    def _(event):\n        \"\"\" Move one non-blank word left \"\"\"\n        return TextObject(event.current_buffer.document.find_start_of_previous_word(count=event.arg, WORD=True) or 0)\n\n    @text_object('$')\n    def key_dollar(event):\n        \"\"\" 'c$', 'd$' and '$':  Delete/change/move until end of line. \"\"\"\n        return TextObject(event.current_buffer.document.get_end_of_line_position())\n\n    @text_object('w')\n    def _(event):\n        \"\"\" 'word' forward. 'cw', 'dw', 'w': Delete/change/move one word.  \"\"\"\n        return TextObject(event.current_buffer.document.find_next_word_beginning(count=event.arg) or\n                            event.current_buffer.document.get_end_of_document_position())\n\n    @text_object('W')\n    def _(event):\n        \"\"\" 'WORD' forward. 'cW', 'dW', 'W': Delete/change/move one WORD.  \"\"\"\n        return TextObject(event.current_buffer.document.find_next_word_beginning(count=event.arg, WORD=True) or\n                            event.current_buffer.document.get_end_of_document_position())\n\n    @text_object('e')\n    def _(event):\n        \"\"\" End of 'word': 'ce', 'de', 'e' \"\"\"\n        end = event.current_buffer.document.find_next_word_ending(count=event.arg)\n        return TextObject(end - 1 if end else 0, type=TextObjectType.INCLUSIVE)\n\n    @text_object('E')\n    def _(event):\n        \"\"\" End of 'WORD': 'cE', 'dE', 'E' \"\"\"\n        end = event.current_buffer.document.find_next_word_ending(count=event.arg, WORD=True)\n        return TextObject(end - 1 if end else 0, type=TextObjectType.INCLUSIVE)\n\n    @text_object('i', 'w', no_move_handler=True)\n    def _(event):\n        \"\"\" Inner 'word': ciw and diw \"\"\"\n        start, end = event.current_buffer.document.find_boundaries_of_current_word()\n        return TextObject(start, end)\n\n    @text_object('a', 'w', no_move_handler=True)\n    def _(event):\n        \"\"\" A 'word': caw and daw \"\"\"\n        start, end = event.current_buffer.document.find_boundaries_of_current_word(include_trailing_whitespace=True)\n        return TextObject(start, end)\n\n    @text_object('i', 'W', no_move_handler=True)\n    def _(event):\n        \"\"\" Inner 'WORD': ciW and diW \"\"\"\n        start, end = event.current_buffer.document.find_boundaries_of_current_word(WORD=True)\n        return TextObject(start, end)\n\n    @text_object('a', 'W', no_move_handler=True)\n    def _(event):\n        \"\"\" A 'WORD': caw and daw \"\"\"\n        start, end = event.current_buffer.document.find_boundaries_of_current_word(WORD=True, include_trailing_whitespace=True)\n        return TextObject(start, end)\n\n    @text_object('a', 'p', no_move_handler=True)\n    def _(event):\n        \"\"\"\n        Auto paragraph.\n        \"\"\"\n        start = event.current_buffer.document.start_of_paragraph()\n        end = event.current_buffer.document.end_of_paragraph(count=event.arg)\n        return TextObject(start, end)\n\n    @text_object('^')\n    def key_circumflex(event):\n        \"\"\" 'c^', 'd^' and '^': Soft start of line, after whitespace. \"\"\"\n        return TextObject(event.current_buffer.document.get_start_of_line_position(after_whitespace=True))\n\n    @text_object('0')\n    def key_zero(event):\n        \"\"\"\n        'c0', 'd0': Hard start of line, before whitespace.\n        (The move '0' key is implemented elsewhere, because a '0' could also change the `arg`.)\n        \"\"\"\n        return TextObject(event.current_buffer.document.get_start_of_line_position(after_whitespace=False))\n\n    def create_ci_ca_handles(ci_start, ci_end, inner, key=None):\n                # TODO: 'dat', 'dit', (tags (like xml)\n        \"\"\"\n        Delete/Change string between this start and stop character. But keep these characters.\n        This implements all the ci\", ci<, ci{, ci(, di\", di<, ca\", ca<, ... combinations.\n        \"\"\"\n        def handler(event):\n            if ci_start == ci_end:\n                # Quotes\n                start = event.current_buffer.document.find_backwards(ci_start, in_current_line=False)\n                end = event.current_buffer.document.find(ci_end, in_current_line=False)\n            else:\n                # Brackets\n                start = event.current_buffer.document.find_enclosing_bracket_left(ci_start, ci_end)\n                end = event.current_buffer.document.find_enclosing_bracket_right(ci_start, ci_end)\n\n            if start is not None and end is not None:\n                offset = 0 if inner else 1\n                return TextObject(start + 1 - offset, end + offset)\n            else:\n                # Nothing found.\n                return TextObject(0)\n\n        if key is None:\n            text_object('ai'[inner], ci_start, no_move_handler=True)(handler)\n            text_object('ai'[inner], ci_end, no_move_handler=True)(handler)\n        else:\n            text_object('ai'[inner], key, no_move_handler=True)(handler)\n\n    for inner in (False, True):\n        for ci_start, ci_end in [('\"', '\"'), (\"'\", \"'\"), (\"`\", \"`\"),\n                                 ('[', ']'), ('<', '>'), ('{', '}'), ('(', ')')]:\n            create_ci_ca_handles(ci_start, ci_end, inner)\n\n        create_ci_ca_handles('(', ')', inner, 'b')  # 'dab', 'dib'\n        create_ci_ca_handles('{', '}', inner, 'B')  # 'daB', 'diB'\n\n    @text_object('{')\n    def _(event):\n        \"\"\"\n        Move to previous blank-line separated section.\n        Implements '{', 'c{', 'd{', 'y{'\n        \"\"\"\n        index = event.current_buffer.document.start_of_paragraph(\n            count=event.arg, before=True)\n        return TextObject(index)\n\n    @text_object('}')\n    def _(event):\n        \"\"\"\n        Move to next blank-line separated section.\n        Implements '}', 'c}', 'd}', 'y}'\n        \"\"\"\n        index = event.current_buffer.document.end_of_paragraph(count=event.arg, after=True)\n        return TextObject(index)\n\n    @text_object('f', Keys.Any)\n    def _(event):\n        \"\"\"\n        Go to next occurance of character. Typing 'fx' will move the\n        cursor to the next occurance of character. 'x'.\n        \"\"\"\n        event.cli.vi_state.last_character_find = CharacterFind(event.data, False)\n        match = event.current_buffer.document.find(\n            event.data, in_current_line=True, count=event.arg)\n        if match:\n            return TextObject(match, type=TextObjectType.INCLUSIVE)\n        else:\n            return TextObject(0)\n\n    @text_object('F', Keys.Any)\n    def _(event):\n        \"\"\"\n        Go to previous occurance of character. Typing 'Fx' will move the\n        cursor to the previous occurance of character. 'x'.\n        \"\"\"\n        event.cli.vi_state.last_character_find = CharacterFind(event.data, True)\n        return TextObject(event.current_buffer.document.find_backwards(\n            event.data, in_current_line=True, count=event.arg) or 0)\n\n    @text_object('t', Keys.Any)\n    def _(event):\n        \"\"\"\n        Move right to the next occurance of c, then one char backward.\n        \"\"\"\n        event.cli.vi_state.last_character_find = CharacterFind(event.data, False)\n        match = event.current_buffer.document.find(\n            event.data, in_current_line=True, count=event.arg)\n        if match:\n            return TextObject(match - 1, type=TextObjectType.INCLUSIVE)\n        else:\n            return TextObject(0)\n\n    @text_object('T', Keys.Any)\n    def _(event):\n        \"\"\"\n        Move left to the previous occurance of c, then one char forward.\n        \"\"\"\n        event.cli.vi_state.last_character_find = CharacterFind(event.data, True)\n        match = event.current_buffer.document.find_backwards(\n            event.data, in_current_line=True, count=event.arg)\n        return TextObject(match + 1 if match else 0)\n\n    def repeat(reverse):\n        \"\"\"\n        Create ',' and ';' commands.\n        \"\"\"\n        @text_object(',' if reverse else ';')\n        def _(event):\n            # Repeat the last 'f'/'F'/'t'/'T' command.\n            pos = 0\n            vi_state = event.cli.vi_state\n\n            type = TextObjectType.EXCLUSIVE\n\n            if vi_state.last_character_find:\n                char = vi_state.last_character_find.character\n                backwards = vi_state.last_character_find.backwards\n\n                if reverse:\n                    backwards = not backwards\n\n                if backwards:\n                    pos = event.current_buffer.document.find_backwards(char, in_current_line=True, count=event.arg)\n                else:\n                    pos = event.current_buffer.document.find(char, in_current_line=True, count=event.arg)\n                    type = TextObjectType.INCLUSIVE\n            if pos:\n                return TextObject(pos, type=type)\n            else:\n                return TextObject(0)\n    repeat(True)\n    repeat(False)\n\n    @text_object('h')\n    @text_object(Keys.Left)\n    def _(event):\n        \"\"\" Implements 'ch', 'dh', 'h': Cursor left. \"\"\"\n        return TextObject(event.current_buffer.document.get_cursor_left_position(count=event.arg))\n\n    @text_object('j', no_move_handler=True, no_selection_handler=True)\n            # Note: We also need `no_selection_handler`, because we in\n            #       selection mode, we prefer the other 'j' binding that keeps\n            #       `buffer.preferred_column`.\n    def _(event):\n        \"\"\" Implements 'cj', 'dj', 'j', ... Cursor up. \"\"\"\n        return TextObject(event.current_buffer.document.get_cursor_down_position(count=event.arg),\n                          type=TextObjectType.LINEWISE)\n\n    @text_object('k', no_move_handler=True, no_selection_handler=True)\n    def _(event):\n        \"\"\" Implements 'ck', 'dk', 'k', ... Cursor up. \"\"\"\n        return TextObject(event.current_buffer.document.get_cursor_up_position(count=event.arg),\n                          type=TextObjectType.LINEWISE)\n\n    @text_object('l')\n    @text_object(' ')\n    @text_object(Keys.Right)\n    def _(event):\n        \"\"\" Implements 'cl', 'dl', 'l', 'c ', 'd ', ' '. Cursor right. \"\"\"\n        return TextObject(event.current_buffer.document.get_cursor_right_position(count=event.arg))\n\n    @text_object('H')\n    def _(event):\n        \"\"\"\n        Moves to the start of the visible region. (Below the scroll offset.)\n        Implements 'cH', 'dH', 'H'.\n        \"\"\"\n        w = find_window_for_buffer_name(event.cli, event.cli.current_buffer_name)\n        b = event.current_buffer\n\n        if w and w.render_info:\n            # When we find a Window that has BufferControl showing this window,\n            # move to the start of the visible area.\n            pos = (b.document.translate_row_col_to_index(\n                       w.render_info.first_visible_line(after_scroll_offset=True), 0) -\n                   b.cursor_position)\n\n        else:\n            # Otherwise, move to the start of the input.\n            pos = -len(b.document.text_before_cursor)\n        return TextObject(pos, type=TextObjectType.LINEWISE)\n\n    @text_object('M')\n    def _(event):\n        \"\"\"\n        Moves cursor to the vertical center of the visible region.\n        Implements 'cM', 'dM', 'M'.\n        \"\"\"\n        w = find_window_for_buffer_name(event.cli, event.cli.current_buffer_name)\n        b = event.current_buffer\n\n        if w and w.render_info:\n            # When we find a Window that has BufferControl showing this window,\n            # move to the center of the visible area.\n            pos = (b.document.translate_row_col_to_index(\n                       w.render_info.center_visible_line(), 0) -\n                   b.cursor_position)\n\n        else:\n            # Otherwise, move to the start of the input.\n            pos = -len(b.document.text_before_cursor)\n        return TextObject(pos, type=TextObjectType.LINEWISE)\n\n    @text_object('L')\n    def _(event):\n        \"\"\"\n        Moves to the end of the visible region. (Above the scroll offset.)\n        \"\"\"\n        w = find_window_for_buffer_name(event.cli, event.cli.current_buffer_name)\n        b = event.current_buffer\n\n        if w and w.render_info:\n            # When we find a Window that has BufferControl showing this window,\n            # move to the end of the visible area.\n            pos = (b.document.translate_row_col_to_index(\n                       w.render_info.last_visible_line(before_scroll_offset=True), 0) -\n                   b.cursor_position)\n\n        else:\n            # Otherwise, move to the end of the input.\n            pos = len(b.document.text_after_cursor)\n        return TextObject(pos, type=TextObjectType.LINEWISE)\n\n    @text_object('n', no_move_handler=True)\n    def _(event):\n        \" Search next. \"\n        buff = event.current_buffer\n        cursor_position = buff.get_search_position(\n            get_search_state(event.cli), include_current_position=False,\n            count=event.arg)\n        return TextObject(cursor_position - buff.cursor_position)\n\n    @handle('n', filter=navigation_mode)\n    def _(event):\n        \" Search next in navigation mode. (This goes through the history.) \"\n        event.current_buffer.apply_search(\n            get_search_state(event.cli), include_current_position=False,\n            count=event.arg)\n\n    @text_object('N', no_move_handler=True)\n    def _(event):\n        \" Search previous. \"\n        buff = event.current_buffer\n        cursor_position = buff.get_search_position(\n            ~get_search_state(event.cli), include_current_position=False,\n            count=event.arg)\n        return TextObject(cursor_position - buff.cursor_position)\n\n    @handle('N', filter=navigation_mode)\n    def _(event):\n        \" Search previous in navigation mode. (This goes through the history.) \"\n        event.current_buffer.apply_search(\n            ~get_search_state(event.cli), include_current_position=False,\n            count=event.arg)\n\n    @handle('z', '+', filter=navigation_mode|selection_mode)\n    @handle('z', 't', filter=navigation_mode|selection_mode)\n    @handle('z', Keys.ControlJ, filter=navigation_mode|selection_mode)\n    def _(event):\n        \"\"\"\n        Scrolls the window to makes the current line the first line in the visible region.\n        \"\"\"\n        w = find_window_for_buffer_name(event.cli, event.cli.current_buffer_name)\n        b = event.cli.current_buffer\n        w.vertical_scroll = b.document.cursor_position_row\n\n    @handle('z', '-', filter=navigation_mode|selection_mode)\n    @handle('z', 'b', filter=navigation_mode|selection_mode)\n    def _(event):\n        \"\"\"\n        Scrolls the window to makes the current line the last line in the visible region.\n        \"\"\"\n        w = find_window_for_buffer_name(event.cli, event.cli.current_buffer_name)\n\n        # We can safely set the scroll offset to zero; the Window will meke\n        # sure that it scrolls at least enough to make the cursor visible\n        # again.\n        w.vertical_scroll = 0\n\n    @handle('z', 'z', filter=navigation_mode|selection_mode)\n    def _(event):\n        \"\"\"\n        Center Window vertically around cursor.\n        \"\"\"\n        w = find_window_for_buffer_name(event.cli, event.cli.current_buffer_name)\n        b = event.cli.current_buffer\n\n        if w and w.render_info:\n            info = w.render_info\n\n            # Calculate the offset that we need in order to position the row\n            # containing the cursor in the center.\n            scroll_height = info.window_height // 2\n\n            y = max(0, b.document.cursor_position_row - 1)\n            height = 0\n            while y > 0:\n                line_height = info.get_height_for_line(y)\n\n                if height + line_height < scroll_height:\n                    height += line_height\n                    y -= 1\n                else:\n                    break\n\n            w.vertical_scroll = y\n\n    @text_object('%')\n    def _(event):\n        \"\"\"\n        Implements 'c%', 'd%', '%, 'y%' (Move to corresponding bracket.)\n        If an 'arg' has been given, go this this % position in the file.\n        \"\"\"\n        buffer = event.current_buffer\n\n        if event._arg:\n            # If 'arg' has been given, the meaning of % is to go to the 'x%'\n            # row in the file.\n            if 0 < event.arg <= 100:\n                absolute_index = buffer.document.translate_row_col_to_index(\n                    int((event.arg * buffer.document.line_count - 1) / 100), 0)\n                return TextObject(absolute_index - buffer.document.cursor_position, type=TextObjectType.LINEWISE)\n            else:\n                return TextObject(0)  # Do nothing.\n\n        else:\n            # Move to the corresponding opening/closing bracket (()'s, []'s and {}'s).\n            match = buffer.document.find_matching_bracket_position()\n            if match:\n                return TextObject(match, type=TextObjectType.INCLUSIVE)\n            else:\n                return TextObject(0)\n\n    @text_object('|')\n    def _(event):\n        # Move to the n-th column (you may specify the argument n by typing\n        # it on number keys, for example, 20|).\n        return TextObject(event.current_buffer.document.get_column_cursor_position(event.arg - 1))\n\n    @text_object('g', 'g')\n    def _(event):\n        \"\"\"\n        Implements 'gg', 'cgg', 'ygg'\n        \"\"\"\n        d = event.current_buffer.document\n\n        if event._arg:\n            # Move to the given line.\n            return TextObject(d.translate_row_col_to_index(event.arg - 1, 0) - d.cursor_position, type=TextObjectType.LINEWISE)\n        else:\n            # Move to the top of the input.\n            return TextObject(d.get_start_of_document_position(), type=TextObjectType.LINEWISE)\n\n    @text_object('g', '_')\n    def _(event):\n        \"\"\"\n        Go to last non-blank of line.\n        'g_', 'cg_', 'yg_', etc..\n        \"\"\"\n        return TextObject(\n            event.current_buffer.document.last_non_blank_of_current_line_position(), type=TextObjectType.INCLUSIVE)\n\n    @text_object('g', 'e')\n    def _(event):\n        \"\"\"\n        Go to last character of previous word.\n        'ge', 'cge', 'yge', etc..\n        \"\"\"\n        prev_end = event.current_buffer.document.find_previous_word_ending(count=event.arg)\n        return TextObject(prev_end - 1 if prev_end is not None else 0, type=TextObjectType.INCLUSIVE)\n\n    @text_object('g', 'E')\n    def _(event):\n        \"\"\"\n        Go to last character of previous WORD.\n        'gE', 'cgE', 'ygE', etc..\n        \"\"\"\n        prev_end = event.current_buffer.document.find_previous_word_ending(count=event.arg, WORD=True)\n        return TextObject(prev_end - 1 if prev_end is not None else 0, type=TextObjectType.INCLUSIVE)\n\n    @text_object('g', 'm')\n    def _(event):\n        \"\"\"\n        Like g0, but half a screenwidth to the right. (Or as much as possible.)\n        \"\"\"\n        w = find_window_for_buffer_name(event.cli, event.cli.current_buffer_name)\n        buff = event.current_buffer\n\n        if w and w.render_info:\n            width = w.render_info.window_width\n            start = buff.document.get_start_of_line_position(after_whitespace=False)\n            start += int(min(width / 2, len(buff.document.current_line)))\n\n            return TextObject(start, type=TextObjectType.INCLUSIVE)\n        return TextObject(0)\n\n    @text_object('G')\n    def _(event):\n        \"\"\"\n        Go to the end of the document. (If no arg has been given.)\n        \"\"\"\n        buf = event.current_buffer\n        return TextObject(buf.document.translate_row_col_to_index(buf.document.line_count - 1, 0) -\n                          buf.cursor_position, type=TextObjectType.LINEWISE)\n\n    #\n    # *** Other ***\n    #\n\n    @handle('G', filter=HasArg())\n    def _(event):\n        \"\"\"\n        If an argument is given, move to this line in the  history. (for\n        example, 15G)\n        \"\"\"\n        event.current_buffer.go_to_history(event.arg - 1)\n\n    for n in '123456789':\n        @handle(n, filter=navigation_mode|selection_mode|operator_given)\n        def _(event):\n            \"\"\"\n            Always handle numberics in navigation mode as arg.\n            \"\"\"\n            event.append_to_arg_count(event.data)\n\n    @handle('0', filter=(navigation_mode|selection_mode|operator_given) & HasArg())\n    def _(event):\n        \" Zero when an argument was already give. \"\n        event.append_to_arg_count(event.data)\n\n    @handle(Keys.Any, filter=replace_mode)\n    def _(event):\n        \"\"\"\n        Insert data at cursor position.\n        \"\"\"\n        event.current_buffer.insert_text(event.data, overwrite=True)\n\n    @handle(Keys.Any, filter=insert_multiple_mode,\n            save_before=(lambda e: not e.is_repeat))\n    def _(event):\n        \"\"\"\n        Insert data at multiple cursor positions at once.\n        (Usually a result of pressing 'I' or 'A' in block-selection mode.)\n        \"\"\"\n        buff = event.current_buffer\n        original_text = buff.text\n\n        # Construct new text.\n        text = []\n        p = 0\n\n        for p2 in buff.multiple_cursor_positions:\n            text.append(original_text[p:p2])\n            text.append(event.data)\n            p = p2\n\n        text.append(original_text[p:])\n\n        # Shift all cursor positions.\n        new_cursor_positions = [\n            p + i + 1 for i, p in enumerate(buff.multiple_cursor_positions)]\n\n        # Set result.\n        buff.text = ''.join(text)\n        buff.multiple_cursor_positions = new_cursor_positions\n        buff.cursor_position += 1\n\n    @handle(Keys.Backspace, filter=insert_multiple_mode)\n    def _(event):\n        \" Backspace, using multiple cursors. \"\n        buff = event.current_buffer\n        original_text = buff.text\n\n        # Construct new text.\n        deleted_something = False\n        text = []\n        p = 0\n\n        for p2 in buff.multiple_cursor_positions:\n            if p2 > 0 and original_text[p2 - 1] != '\\n':  # Don't delete across lines.\n                text.append(original_text[p:p2 - 1])\n                deleted_something = True\n            else:\n                text.append(original_text[p:p2])\n            p = p2\n\n        text.append(original_text[p:])\n\n        if deleted_something:\n            # Shift all cursor positions.\n            lengths = [len(part) for part in text[:-1]]\n            new_cursor_positions = list(accumulate(lengths))\n\n            # Set result.\n            buff.text = ''.join(text)\n            buff.multiple_cursor_positions = new_cursor_positions\n            buff.cursor_position -= 1\n        else:\n            event.cli.output.bell()\n\n    @handle(Keys.Delete, filter=insert_multiple_mode)\n    def _(event):\n        \" Delete, using multiple cursors. \"\n        buff = event.current_buffer\n        original_text = buff.text\n\n        # Construct new text.\n        deleted_something = False\n        text = []\n        new_cursor_positions = []\n        p = 0\n\n        for p2 in buff.multiple_cursor_positions:\n            text.append(original_text[p:p2])\n            if p2 >= len(original_text) or original_text[p2] == '\\n':\n                # Don't delete across lines.\n                p = p2\n            else:\n                p = p2 + 1\n                deleted_something = True\n\n        text.append(original_text[p:])\n\n        if deleted_something:\n            # Shift all cursor positions.\n            lengths = [len(part) for part in text[:-1]]\n            new_cursor_positions = list(accumulate(lengths))\n\n            # Set result.\n            buff.text = ''.join(text)\n            buff.multiple_cursor_positions = new_cursor_positions\n        else:\n            event.cli.output.bell()\n\n\n    @handle(Keys.ControlX, Keys.ControlL, filter=insert_mode)\n    def _(event):\n        \"\"\"\n        Pressing the ControlX - ControlL sequence in Vi mode does line\n        completion based on the other lines in the document and the history.\n        \"\"\"\n        event.current_buffer.start_history_lines_completion()\n\n    @handle(Keys.ControlX, Keys.ControlF, filter=insert_mode)\n    def _(event):\n        \"\"\"\n        Complete file names.\n        \"\"\"\n        # TODO\n        pass\n\n    @handle(Keys.ControlK, filter=insert_mode|replace_mode)\n    def _(event):\n        \" Go into digraph mode. \"\n        event.cli.vi_state.waiting_for_digraph = True\n\n    @Condition\n    def digraph_symbol_1_given(cli):\n        return cli.vi_state.digraph_symbol1 is not None\n\n    @handle(Keys.Any, filter=digraph_mode & ~digraph_symbol_1_given)\n    def _(event):\n        event.cli.vi_state.digraph_symbol1 = event.data\n\n    @handle(Keys.Any, filter=digraph_mode & digraph_symbol_1_given)\n    def _(event):\n        \" Insert digraph. \"\n        try:\n            # Lookup.\n            code = (event.cli.vi_state.digraph_symbol1, event.data)\n            if code not in DIGRAPHS:\n                code = code[::-1]  # Try reversing.\n            symbol = DIGRAPHS[code]\n        except KeyError:\n            # Unkown digraph.\n            event.cli.output.bell()\n        else:\n            # Insert digraph.\n            overwrite = event.cli.vi_state.input_mode == InputMode.REPLACE\n            event.current_buffer.insert_text(\n                six.unichr(symbol), overwrite=overwrite)\n            event.cli.vi_state.waiting_for_digraph = False\n        finally:\n            event.cli.vi_state.waiting_for_digraph = False\n            event.cli.vi_state.digraph_symbol1 = None\n\n    return registry", "response": "Load Vi bindings from the Vi registry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_vi_open_in_editor_bindings():\n    registry = Registry()\n    navigation_mode = ViNavigationMode()\n\n    registry.add_binding('v', filter=navigation_mode)(\n        get_by_name('edit-and-execute-command'))\n    return registry", "response": "Load Vi editor bindings."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_extra_vi_page_navigation_bindings():\n    registry = ConditionalRegistry(Registry(), ViMode())\n    handle = registry.add_binding\n\n    handle(Keys.ControlF)(scroll_forward)\n    handle(Keys.ControlB)(scroll_backward)\n    handle(Keys.ControlD)(scroll_half_page_down)\n    handle(Keys.ControlU)(scroll_half_page_up)\n    handle(Keys.ControlE)(scroll_one_line_down)\n    handle(Keys.ControlY)(scroll_one_line_up)\n    handle(Keys.PageDown)(scroll_page_down)\n    handle(Keys.PageUp)(scroll_page_up)\n\n    return registry", "response": "Load extra Vi page navigation bindings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sorted(self):\n        if self.start < self.end:\n            return self.start, self.end\n        else:\n            return self.end, self.start", "response": "Return a tuple where start < = end."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a start end tuple that indicates the range operators should operate on.", "response": "def operator_range(self, document):\n        \"\"\"\n        Return a (start, end) tuple with start <= end that indicates the range\n        operators should operate on.\n        `buffer` is used to get start and end of line positions.\n        \"\"\"\n        start, end = self.sorted()\n        doc = document\n\n        if (self.type == TextObjectType.EXCLUSIVE and\n                doc.translate_index_to_position(end + doc.cursor_position)[1] == 0):\n            # If the motion is exclusive and the end of motion is on the first\n            # column, the end position becomes end of previous line.\n            end -= 1\n        if self.type == TextObjectType.INCLUSIVE:\n            end += 1\n        if self.type == TextObjectType.LINEWISE:\n            # Select whole lines\n            row, col = doc.translate_index_to_position(start + doc.cursor_position)\n            start = doc.translate_row_col_to_index(row, 0) - doc.cursor_position\n            row, col = doc.translate_index_to_position(end + doc.cursor_position)\n            end = doc.translate_row_col_to_index(row, len(doc.lines[row])) - doc.cursor_position\n        return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_line_numbers(self, buffer):\n        # Get absolute cursor positions from the text object.\n        from_, to = self.operator_range(buffer.document)\n        from_ += buffer.cursor_position\n        to += buffer.cursor_position\n\n        # Take the start of the lines.\n        from_, _ = buffer.document.translate_index_to_position(from_)\n        to, _ = buffer.document.translate_index_to_position(to)\n\n        return from_, to", "response": "Get the start and end line numbers of the line numbers in the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new document and clipboard data instance.", "response": "def cut(self, buffer):\n        \"\"\"\n        Turn text object into `ClipboardData` instance.\n        \"\"\"\n        from_, to = self.operator_range(buffer.document)\n\n        from_ += buffer.cursor_position\n        to += buffer.cursor_position\n        to -= 1  # SelectionState does not include the end position, `operator_range` does.\n\n        document = Document(buffer.text, to, SelectionState(\n            original_cursor_position=from_, type=self.selection_type))\n\n        new_document, clipboard_data = document.cut_selection()\n        return new_document, clipboard_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nscans backwards and find a possible position to start.", "response": "def get_sync_start_position(self, document, lineno):\n        \" Scan backwards, and find a possible position to start. \"\n        pattern = self._compiled_pattern\n        lines = document.lines\n\n        # Scan upwards, until we find a point where we can start the syntax\n        # synchronisation.\n        for i in range(lineno, max(-1, lineno - self.MAX_BACKWARDS), -1):\n            match = pattern.match(lines[i])\n            if match:\n                return i, match.start()\n\n        # No synchronisation point found. If we aren't that far from the\n        # beginning, start at the very beginning, otherwise, just try to start\n        # at the current line.\n        if lineno < self.FROM_START_IF_NO_SYNC_POS_FOUND:\n            return 0, 0\n        else:\n            return lineno, 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new instance of this class based on a Pygments lexer class.", "response": "def from_pygments_lexer_cls(cls, lexer_cls):\n        \"\"\"\n        Create a :class:`.RegexSync` instance for this Pygments lexer class.\n        \"\"\"\n        patterns = {\n            # For Python, start highlighting at any class/def block.\n            'Python':   r'^\\s*(class|def)\\s+',\n            'Python 3': r'^\\s*(class|def)\\s+',\n\n            # For HTML, start at any open/close tag definition.\n            'HTML': r'<[/a-zA-Z]',\n\n            # For javascript, start at a function.\n            'JavaScript': r'\\bfunction\\b'\n\n            # TODO: Add definitions for other languages.\n            #       By default, we start at every possible line.\n        }\n        p = patterns.get(lexer_cls.name, '^')\n        return cls(p)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_filename(cls, filename, sync_from_start=True):\n        # Inline imports: the Pygments dependency is optional!\n        from pygments.util import ClassNotFound\n        from pygments.lexers import get_lexer_for_filename\n\n        try:\n            pygments_lexer = get_lexer_for_filename(filename)\n        except ClassNotFound:\n            return SimpleLexer()\n        else:\n            return cls(pygments_lexer.__class__, sync_from_start=sync_from_start)", "response": "Create a lexer from a filename."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lex_document(self, cli, document):\n        # Cache of already lexed lines.\n        cache = {}\n\n        # Pygments generators that are currently lexing.\n        line_generators = {}  # Map lexer generator to the line number.\n\n        def get_syntax_sync():\n            \" The Syntax synchronisation objcet that we currently use. \"\n            if self.sync_from_start(cli):\n                return SyncFromStart()\n            else:\n                return self.syntax_sync\n\n        def find_closest_generator(i):\n            \" Return a generator close to line 'i', or None if none was fonud. \"\n            for generator, lineno in line_generators.items():\n                if lineno < i and i - lineno < self.REUSE_GENERATOR_MAX_DISTANCE:\n                    return generator\n\n        def create_line_generator(start_lineno, column=0):\n            \"\"\"\n            Create a generator that yields the lexed lines.\n            Each iteration it yields a (line_number, [(token, text), ...]) tuple.\n            \"\"\"\n            def get_tokens():\n                text = '\\n'.join(document.lines[start_lineno:])[column:]\n\n                # We call `get_tokens_unprocessed`, because `get_tokens` will\n                # still replace \\r\\n and \\r by \\n.  (We don't want that,\n                # Pygments should return exactly the same amount of text, as we\n                # have given as input.)\n                for _, t, v in self.pygments_lexer.get_tokens_unprocessed(text):\n                    yield t, v\n\n            return enumerate(split_lines(get_tokens()), start_lineno)\n\n        def get_generator(i):\n            \"\"\"\n            Find an already started generator that is close, or create a new one.\n            \"\"\"\n            # Find closest line generator.\n            generator = find_closest_generator(i)\n            if generator:\n                return generator\n\n            # No generator found. Determine starting point for the syntax\n            # synchronisation first.\n\n            # Go at least x lines back. (Make scrolling upwards more\n            # efficient.)\n            i = max(0, i - self.MIN_LINES_BACKWARDS)\n\n            if i == 0:\n                row = 0\n                column = 0\n            else:\n                row, column = get_syntax_sync().get_sync_start_position(document, i)\n\n            # Find generator close to this point, or otherwise create a new one.\n            generator = find_closest_generator(i)\n            if generator:\n                return generator\n            else:\n                generator = create_line_generator(row, column)\n\n            # If the column is not 0, ignore the first line. (Which is\n            # incomplete. This happens when the synchronisation algorithm tells\n            # us to start parsing in the middle of a line.)\n            if column:\n                next(generator)\n                row += 1\n\n            line_generators[generator] = row\n            return generator\n\n        def get_line(i):\n            \" Return the tokens for a given line number. \"\n            try:\n                return cache[i]\n            except KeyError:\n                generator = get_generator(i)\n\n                # Exhaust the generator, until we find the requested line.\n                for num, line in generator:\n                    cache[num] = line\n                    if num == i:\n                        line_generators[generator] = i\n\n                        # Remove the next item from the cache.\n                        # (It could happen that it's already there, because of\n                        # another generator that started filling these lines,\n                        # but we want to synchronise these lines with the\n                        # current lexer's state.)\n                        if num + 1 in cache:\n                            del cache[num + 1]\n\n                        return cache[num]\n            return []\n\n        return get_line", "response": "Return a list of tokens that are currently lexed for a given line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _bisearch(ucs, table):\n    lbound = 0\n    ubound = len(table) - 1\n\n    if ucs < table[0][0] or ucs > table[ubound][1]:\n        return 0\n    while ubound >= lbound:\n        mid = (lbound + ubound) // 2\n        if ucs > table[mid][1]:\n            lbound = mid + 1\n        elif ucs < table[mid][0]:\n            ubound = mid - 1\n        else:\n            return 1\n\n    return 0", "response": "A helper function for binary search in interval table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wcswidth(pwcs, n=None):\n    # pylint: disable=C0103\n    #         Invalid argument name \"n\"\n\n    end = len(pwcs) if n is None else n\n    idx = slice(0, end)\n    width = 0\n    for char in pwcs[idx]:\n        wcw = wcwidth(char)\n        if wcw < 0:\n            return -1\n        else:\n            width += wcw\n    return width", "response": "Given a unicode string return its printable length on a terminal."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Watchdog file event handler that does different things for every fileVersion.", "response": "def _per_file_event_handler(self):\n        \"\"\"Create a Watchdog file event handler that does different things for every file\n        \"\"\"\n        file_event_handler = PatternMatchingEventHandler()\n        file_event_handler.on_created = self._on_file_created\n        file_event_handler.on_modified = self._on_file_modified\n        file_event_handler.on_moved = self._on_file_moved\n        file_event_handler._patterns = [\n            os.path.join(self._watch_dir, os.path.normpath('*'))]\n        # Ignore hidden files/folders and output.log because we stream it specially\n        file_event_handler._ignore_patterns = [\n            '*/.*',\n            '*.tmp',\n            os.path.join(self._run.dir, OUTPUT_FNAME)\n        ]\n        for glob in self._api.settings(\"ignore_globs\"):\n            file_event_handler._ignore_patterns.append(\n                os.path.join(self._run.dir, glob))\n\n        return file_event_handler"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping file syncing and streaming.", "response": "def _end_file_syncing(self, exitcode):\n        \"\"\"Stops file syncing/streaming but doesn't actually wait for everything to\n        finish. We print progress info later.\n        \"\"\"\n        # TODO: there was a case where _file_event_handlers was getting modified in the loop.\n        for handler in list(self._file_event_handlers.values()):\n            handler.finish()\n\n        self._file_pusher.finish()\n        self._api.get_file_stream_api().finish(exitcode)\n        # In Jupyter notebooks, wandb.init can be called multiple times in the same\n        # process, creating new runs each time. This ensures we get a new file stream\n        # thread\n        self._api._file_stream_api = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets or create an event handler for a particular file.", "response": "def _get_file_event_handler(self, file_path, save_name):\n        \"\"\"Get or create an event handler for a particular file.\n\n        file_path: the file's actual path\n        save_name: its path relative to the run directory (aka the watch directory)\n        \"\"\"\n        self._file_pusher.update_file(save_name, file_path)  # track upload progress\n\n        if save_name not in self._file_event_handlers:\n            if save_name == 'wandb-history.jsonl':\n                self._file_event_handlers['wandb-history.jsonl'] = FileEventHandlerTextStream(\n                    file_path, 'wandb-history.jsonl', self._api)\n            elif save_name == 'wandb-events.jsonl':\n                self._file_event_handlers['wandb-events.jsonl'] = FileEventHandlerTextStream(\n                    file_path, 'wandb-events.jsonl', self._api)\n            elif 'tfevents' in save_name or 'graph.pbtxt' in save_name:\n                # overwrite the tensorboard but not every reload -- just\n                # frequently enough to resemble realtime\n                self._file_event_handlers[save_name] = FileEventHandlerThrottledOverwrite(\n                    file_path, save_name, self._api, self._file_pusher)\n            # Don't try to stream tensorboard files for now.\n            # elif 'tfevents' in save_name:\n            #    # TODO: This is hard-coded, but we want to give users control\n            #    # over streaming files (or detect them).\n            #    self._api.get_file_stream_api().set_file_policy(save_name,\n            #                                                    BinaryFilePolicy())\n            #    self._file_event_handlers[save_name] = FileEventHandlerBinaryStream(\n            #        file_path, save_name, self._api)\n            # Overwrite handler (non-deferred) has a bug, wherein if the file is truncated\n            # during upload, the request to Google hangs (at least, this is my working\n            # theory). So for now we defer uploading everything til the end of the run.\n            # TODO: send wandb-summary during run. One option is to copy to a temporary\n            # file before uploading.\n            elif save_name == config.FNAME:\n                self._file_event_handlers[save_name] = FileEventHandlerConfig(\n                    file_path, save_name, self._api, self._file_pusher, self._run)\n            elif save_name == 'wandb-summary.json':\n                # Load the summary into the syncer process for meta etc to work\n                self._run.summary.load()\n                self._api.get_file_stream_api().set_file_policy(save_name, OverwriteFilePolicy())\n                self._file_event_handlers[save_name] = FileEventHandlerSummary(\n                    file_path, save_name, self._api, self._file_pusher, self._run)\n            elif save_name.startswith('media/'):\n                # Save media files immediately\n                self._file_event_handlers[save_name] = FileEventHandlerOverwrite(\n                    file_path, save_name, self._api, self._file_pusher)\n            else:\n                Handler = FileEventHandlerOverwriteDeferred\n                for policy, globs in six.iteritems(self._user_file_policies):\n                    if policy == \"end\":\n                        continue\n                    for g in globs:\n                        if any(save_name in p for p in glob.glob(os.path.join(self._run.dir, g))):\n                            if policy == \"live\":\n                                Handler = FileEventHandlerThrottledOverwriteMinWait\n                self._file_event_handlers[save_name] = Handler(\n                    file_path, save_name, self._api, self._file_pusher)\n        return self._file_event_handlers[save_name]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mirror_stdout_stderr(self):\n        # TODO: Ideally we could start collecting logs without pushing\n        fs_api = self._api.get_file_stream_api()\n        io_wrap.SimpleTee(sys.stdout, streaming_log.TextStreamPusher(\n            fs_api, OUTPUT_FNAME, prepend_timestamp=True))\n        io_wrap.SimpleTee(sys.stderr, streaming_log.TextStreamPusher(\n            fs_api, OUTPUT_FNAME, prepend_timestamp=True, line_prepend='ERROR'))", "response": "Simple STDOUT and STDERR mirroring used by _init_jupyter"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets up STDOUT and STDERR streams. Only call this once.", "response": "def _get_stdout_stderr_streams(self):\n        \"\"\"Sets up STDOUT and STDERR streams. Only call this once.\"\"\"\n        if six.PY2 or not hasattr(sys.stdout, \"buffer\"):\n            if hasattr(sys.stdout, \"fileno\") and sys.stdout.isatty():\n                try:\n                    stdout = os.fdopen(sys.stdout.fileno(), \"w+\", 0)\n                    stderr = os.fdopen(sys.stderr.fileno(), \"w+\", 0)\n                # OSError [Errno 22] Invalid argument wandb\n                except OSError:\n                    stdout = sys.stdout\n                    stderr = sys.stderr\n            else:\n                stdout = sys.stdout\n                stderr = sys.stderr\n        else:  # we write binary so grab the raw I/O objects in python 3\n            try:\n                stdout = sys.stdout.buffer.raw\n                stderr = sys.stderr.buffer.raw\n            except AttributeError:\n                # The testing environment and potentially others may have screwed with their\n                # io so we fallback to raw stdout / err\n                stdout = sys.stdout.buffer\n                stderr = sys.stderr.buffer\n\n        output_log_path = os.path.join(self._run.dir, OUTPUT_FNAME)\n        self._output_log = WriteSerializingFile(open(output_log_path, 'wb'))\n\n        stdout_streams = [stdout, self._output_log]\n        stderr_streams = [stderr, self._output_log]\n\n        if self._cloud:\n            # Tee stdout/stderr into our TextOutputStream, which will push lines to the cloud.\n            fs_api = self._api.get_file_stream_api()\n            self._stdout_stream = streaming_log.TextStreamPusher(\n                fs_api, OUTPUT_FNAME, prepend_timestamp=True)\n            self._stderr_stream = streaming_log.TextStreamPusher(\n                fs_api, OUTPUT_FNAME, line_prepend='ERROR',\n                prepend_timestamp=True)\n\n            stdout_streams.append(self._stdout_stream)\n            stderr_streams.append(self._stderr_stream)\n\n        return stdout_streams, stderr_streams"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _close_stdout_stderr_streams(self):\n\n        # we don't have tee_file's in headless mode\n        if self._stdout_tee.tee_file is not None:\n            self._stdout_tee.tee_file.close()\n        if self._stderr_tee.tee_file is not None:\n            self._stderr_tee.tee_file.close()\n\n        # TODO(adrian): we should close these even in headless mode\n        # but in python 2 the read thread doesn't stop on its own\n        # for some reason\n        self._stdout_tee.close_join()\n        self._stderr_tee.close_join()\n\n        if self._cloud:\n            # not set in dry run mode\n            self._stdout_stream.close()\n            self._stderr_stream.close()\n\n        self._output_log.f.close()\n        self._output_log = None", "response": "Close the output - capturing streams."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_run(self, env=None):\n        io_wrap.init_sigwinch_handler()\n\n        self._check_update_available(__version__)\n\n        if self._output:\n            wandb.termlog(\"Local directory: %s\" % os.path.relpath(self._run.dir))\n\n        self._system_stats.start()\n        self._meta.start()\n        logger.info(\"system metrics and metadata threads started\")\n        new_step = None\n        if self._cloud:\n            storage_id = None\n            if self._run.resume != 'never':\n                # DNS can hang for 60 seconds, we check for resume status in a thread\n                # TODO: Ideally this thread would continue retrying in case of failure.\n                # Currently we assume we're not resuming in the case of resume = auto,\n                # and we throw an error in the case of resume = must.\n                logger.info(\"checking resume status, waiting at most %d seconds\" % InternalApi.HTTP_TIMEOUT)\n                async_resume_status = util.async_call(self._api.run_resume_status, InternalApi.HTTP_TIMEOUT)\n                resume_status, thread = async_resume_status(self._api.settings(\"entity\"), self._project, self._run.id)\n\n                if resume_status == None and self._run.resume == 'must':\n                    if thread.isAlive():\n                        raise LaunchError(\n                            \"resume='must' but we were unable to connect to the W&B service after %i seconds\" % InternalApi.HTTP_TIMEOUT)\n                    else:\n                        raise LaunchError(\n                            \"resume='must' but run (%s) doesn't exist\" % self._run.id)\n                if resume_status:\n                    storage_id = resume_status['id']\n                    logger.info(\"resuming run from id: %s\" % storage_id)\n                    self._project = self._resolve_project_name(self._project)\n                    self._setup_resume(resume_status)\n                    try:\n                        history = json.loads(json.loads(resume_status['historyTail'])[-1])\n                    except (IndexError,ValueError):\n                        history = {}\n                    new_step = history.get(\"_step\", 0)\n            else:\n                new_step = 0\n\n            # DNS lookups can hang for upto 60 seconds, we wait for HTTP_TIMEOUT (10s)\n            logger.info(\"upserting run before process can begin, waiting at most %d seconds\" % InternalApi.HTTP_TIMEOUT)\n            async_upsert = util.async_call(self._upsert_run, timeout=InternalApi.HTTP_TIMEOUT)\n            _, self._upsert_run_thread = async_upsert(True, storage_id, env)\n            if self._upsert_run_thread.isAlive():\n                logger.error(\"Failed to connect to W&B servers after %i seconds.\\\n                    Letting user process proceed while attempting to reconnect.\" % InternalApi.HTTP_TIMEOUT)\n\n        return new_step", "response": "Create a run from the current state of the run."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _upsert_run(self, retry, storage_id, env):\n        if retry:\n            num_retries = None\n        else:\n            num_retries = 0  # no retries because we want to let the user process run even if the backend is down\n\n        try:\n            upsert_result = self._run.save(\n                id=storage_id, num_retries=num_retries, api=self._api)\n        except wandb.apis.CommError as e:\n            logger.exception(\"communication error with wandb %s\" % e.exc)\n            # TODO: Get rid of str contains check\n            if self._run.resume == 'never' and 'exists' in str(e):\n                raise LaunchError(\n                    \"resume='never' but run (%s) exists\" % self._run.id)\n            else:\n                # Detect bad request code -- this is usually trying to\n                # create a run that has been already deleted\n                if (isinstance(e.exc, requests.exceptions.HTTPError) and\n                    e.exc.response.status_code == 400):\n                    raise LaunchError(\n                        'Failed to connect to W&B. See {} for details.'.format(\n                        util.get_log_file_path()))\n\n                if isinstance(e.exc, (requests.exceptions.HTTPError,\n                                      requests.exceptions.Timeout,\n                                      requests.exceptions.ConnectionError)):\n                    wandb.termerror(\n                        'Failed to connect to W&B. Retrying in the background.')\n                    return False\n\n                launch_error_s = 'Launch exception: {}, see {} for details.  To disable wandb set WANDB_MODE=dryrun'.format(e, util.get_log_file_path())\n                if 'Permission denied' in str(e):\n                    launch_error_s += '\\nRun \"wandb login\", or provide your API key with the WANDB_API_KEY environment variable.'\n\n                raise LaunchError(launch_error_s)\n\n        if self._output:\n            url = self._run.get_url(self._api)\n            wandb.termlog(\"Syncing to %s\" % url)\n            wandb.termlog(\"Run `wandb off` to turn off syncing.\")\n\n        self._run.set_environment(environment=env)\n\n        logger.info(\"saving patches\")\n        self._api.save_patches(self._watch_dir)\n        logger.info(\"saving pip packages\")\n        self._api.save_pip(self._watch_dir)\n        logger.info(\"initializing streaming files api\")\n        self._api.get_file_stream_api().set_file_policy(\n            OUTPUT_FNAME, CRDedupeFilePolicy())\n        self._api.get_file_stream_api().start()\n        self._project = self._api.settings(\"project\")\n\n        # unblock file syncing and console streaming, which need the Run to have a .storage_id\n        logger.info(\"unblocking file change observer, beginning sync with W&B servers\")\n        self._unblock_file_observer()\n\n        return True", "response": "Upsert the Run in the backend."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shutdown(self, exitcode=0):\n        logger.info(\"shutting down system stats and metadata service\")\n        self._system_stats.shutdown()\n        self._meta.shutdown()\n\n        if self._cloud:\n            logger.info(\"stopping streaming files and file change observer\")\n            self._stop_file_observer()\n            self._end_file_syncing(exitcode)\n\n        self._run.history.close()", "response": "Stops the system stats streaming handlers and uploads files without output used by wandb. monitor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlaunching a user process and sync its files to the backend.", "response": "def run_user_process(self, program, args, env):\n        \"\"\"Launch a user process, capture its output, and sync its files to the backend.\n\n        This returns after the process has ended and syncing is done.\n        Captures ctrl-c's, signals, etc.\n        \"\"\"\n        stdout_streams, stderr_streams = self._get_stdout_stderr_streams()\n\n        if sys.platform == \"win32\":\n            # PTYs don't work in windows so we use pipes.\n            self._stdout_tee = io_wrap.Tee.pipe(*stdout_streams)\n            self._stderr_tee = io_wrap.Tee.pipe(*stderr_streams)\n            # Seems like the following actually isn't necessary on Windows\n            # TODO(adrian): we may need to do the following if we use pipes instead of PTYs\n            # because Python on Unix doesn't like writing UTF-8 to files\n            # tell child python interpreters we accept utf-8\n            # env['PYTHONIOENCODING'] = 'UTF-8'\n        else:\n            self._stdout_tee = io_wrap.Tee.pty(*stdout_streams)\n            self._stderr_tee = io_wrap.Tee.pty(*stderr_streams)\n\n        command = [program] + list(args)\n        runner = util.find_runner(program)\n        if runner:\n            command = runner + command\n        command = ' '.join(six.moves.shlex_quote(arg) for arg in command)\n        self._stdout_stream.write_string(command + \"\\n\\n\")\n\n        try:\n            self.proc = subprocess.Popen(\n                command,\n                env=env,\n                stdout=self._stdout_tee.tee_file,\n                stderr=self._stderr_tee.tee_file,\n                shell=True,\n            )\n            self._run.pid = self.proc.pid\n        except (OSError, IOError):\n            raise Exception('Could not find program: %s' % command)\n\n        self._sync_etc()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap an existing process into a new process.", "response": "def wrap_existing_process(self, pid, stdout_read_fd, stderr_read_fd, port=None):\n        \"\"\"Do syncing, etc. for an already-running process.\n\n        This returns after the process has ended and syncing is done.\n        Captures ctrl-c's, signals, etc.\n        \"\"\"\n        stdout_read_file = os.fdopen(stdout_read_fd, 'rb')\n        stderr_read_file = os.fdopen(stderr_read_fd, 'rb')\n        stdout_streams, stderr_streams = self._get_stdout_stderr_streams()\n        self._stdout_tee = io_wrap.Tee(stdout_read_file, *stdout_streams)\n        self._stderr_tee = io_wrap.Tee(stderr_read_file, *stderr_streams)\n\n        self.proc = Process(pid)\n        self._run.pid = pid\n        logger.info(\"wrapping existing process %i\" % pid)\n\n        try:\n            self.init_run()\n        except LaunchError as e:\n            logger.exception(\"catostrophic launch error\")\n            wandb.termerror(str(e))\n            util.sentry_exc(e)\n            self._socket.launch_error()\n            return\n\n        if io_wrap.SIGWINCH_HANDLER is not None:\n            # SIGWINCH_HANDLER (maybe) gets set in self.init_run()\n            io_wrap.SIGWINCH_HANDLER.add_fd(stdout_read_fd)\n            io_wrap.SIGWINCH_HANDLER.add_fd(stderr_read_fd)\n\n        # Signal the main process that we're all hooked up\n        logger.info(\"informing user process we are ready to proceed\")\n        self._socket.ready()\n\n        self._sync_etc(headless=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sync_etc(self, headless=False):\n        # Ignore SIGQUIT (ctrl-\\). The child process will handle it, and we'll\n        # exit when the child process does.\n        #\n        # We disable these signals after running the process so the child doesn't\n        # inherit this behaviour.\n        try:\n            signal.signal(signal.SIGQUIT, signal.SIG_IGN)\n        except (AttributeError, ValueError):  # SIGQUIT doesn't exist on windows, we can't use signal.signal in threads for tests\n            pass\n\n        # Add a space before user output\n        wandb.termlog()\n\n        if env.get_show_run():\n            webbrowser.open_new_tab(self._run.get_url(self._api))\n\n        exitcode = None\n        try:\n            payload = b''\n            parse = False\n            logger.info(\"entering loop for messages from user process\")\n            while True:\n                res = bytearray()\n                # We received multiple messages from the last socket read\n                if payload.find(b'\\0') != -1:\n                    res = payload\n                    payload = b''\n                else:\n                    try:\n                        res = self._socket.recv(1024)\n                    except socket.error as e:\n                        # https://stackoverflow.com/questions/16094618/python-socket-recv-and-signals\n                        if e.errno == errno.EINTR or isinstance(e, socket.timeout):\n                            pass\n                        else:\n                            raise e\n                term = res.find(b'\\0')\n                if term != -1:\n                    payload += res[:term]\n                    parse = True\n                else:\n                    payload += res\n                if parse:\n                    logger.info(\"received message from user process: %s\" % payload.decode('utf8'))\n                    try:\n                        parsed = json.loads(payload.decode('utf8'))\n                    except ValueError:\n                        parsed = {}\n                    if parsed.get(\"exitcode\") is not None:\n                        exitcode = parsed[\"exitcode\"]\n                        break\n                    elif parsed.get(\"save_policy\"):\n                        self.update_user_file_policy(parsed[\"save_policy\"])\n                        payload = b''\n                        parse = False\n                    else:\n                        message = \"Invalid message received from child process: %s\" % str(\n                            payload)\n                        wandb.termerror(message)\n                        util.sentry_exc(message)\n                        break\n                    new_start = term + 1\n                    # There's more to parse, add the remaining bytes\n                    if len(res) > new_start:\n                        payload = res[new_start:]\n                else:\n                    exitcode = self.proc.poll()\n                    if exitcode is not None:\n                        break\n                    time.sleep(1)\n        except KeyboardInterrupt:\n            logger.info(\"process received interrupt signal, shutting down\")\n            exitcode = 255\n            if headless:\n                wandb.termlog('Ctrl-c pressed.')\n            else:\n                wandb.termlog(\n                    'Ctrl-c pressed; waiting for program to end. Press ctrl-c again to kill it.')\n                try:\n                    logger.info(\"waiting for process to finish\")\n                    while self.proc.poll() is None:\n                        time.sleep(0.1)\n                except KeyboardInterrupt:\n                    pass\n\n                if self.proc.poll() is None:\n                    logger.info(\"killing user process\")\n                    wandb.termlog('Program still alive. Killing it.')\n                    try:\n                        self.proc.kill()\n                    except OSError:\n                        pass\n\n        \"\"\"TODO(adrian): garbage that appears in the logs sometimes\n\n        Exception ignored in: <bound method Popen.__del__ of <subprocess.Popen object at 0x111adce48>>\n        Traceback (most recent call last):\n          File \"/Users/adrian/.pyenv/versions/3.6.0/Python.framework/Versions/3.6/lib/python3.6/subprocess.py\", line 760, in __del__\n        AttributeError: 'NoneType' object has no attribute 'warn'\n        \"\"\"\n\n        if exitcode is None:\n            exitcode = 254\n            wandb.termlog(\n                'Killing program failed; syncing files anyway. Press ctrl-c to abort syncing.')\n        else:\n            if exitcode == 0:\n                wandb.termlog('Program ended successfully.')\n                resume_path = os.path.join(wandb.wandb_dir(), wandb_run.RESUME_FNAME)\n                if os.path.exists(resume_path):\n                    os.remove(resume_path)\n            else:\n                wandb.termlog(\n                    'Program failed with code %d. Press ctrl-c to abort syncing.' % exitcode)\n\n        self._meta.data[\"exitcode\"] = exitcode\n        if exitcode == 0:\n            self._meta.data[\"state\"] = \"finished\"\n        elif exitcode == 255:\n            self._meta.data[\"state\"] = \"killed\"\n        else:\n            self._meta.data[\"state\"] = \"failed\"\n\n        # TODO(adrian): these can be slow to complete (due to joining?)\n        logger.info(\"closing log streams and sending exitcode to W&B\")\n        self._close_stdout_stderr_streams()\n        self.shutdown(exitcode)\n\n        # If we're not syncing to the cloud, we're done\n        if not self._cloud:\n            wandb.termlog(\"You can sync this run to the cloud by running: \")\n            wandb.termlog(\"wandb sync %s\" % os.path.relpath(self._run.dir))\n            sys.exit(exitcode)\n        elif exitcode != 0 and time.time() - START_TIME < 30:\n            wandb.termlog(\"Process crashed early, not syncing files\")\n            logger.info(\"process only ran for %d seconds, not syncing files\" % (time.time() - START_TIME))\n            sys.exit(exitcode)\n\n        # Show run summary/history\n        self._run.summary.load()\n        summary = self._run.summary._json_dict\n        if len(summary):\n            logger.info(\"rendering summary\")\n            wandb.termlog('Run summary:')\n            max_len = max([len(k) for k in summary.keys()])\n            format_str = '  {:>%s} {}' % max_len\n            for k, v in summary.items():\n                # arrays etc. might be too large. for now we just don't print them\n                if isinstance(v, six.string_types):\n                    if len(v) >= 20:\n                        v = v[:20] + '...'\n                    wandb.termlog(format_str.format(k, v))\n                elif isinstance(v, numbers.Number):\n                    wandb.termlog(format_str.format(k, v))\n\n        self._run.history.load()\n        history_keys = self._run.history.keys()\n        # Only print sparklines if the terminal is utf-8\n        if len(history_keys) and sys.stdout.encoding == \"UTF_8\":\n            logger.info(\"rendering history\")\n            wandb.termlog('Run history:')\n            max_len = max([len(k) for k in history_keys])\n            for key in history_keys:\n                vals = util.downsample(self._run.history.column(key), 40)\n                if any((not isinstance(v, numbers.Number) for v in vals)):\n                    continue\n                line = sparkline.sparkify(vals)\n                format_str = u'  {:>%s} {}' % max_len\n                wandb.termlog(format_str.format(key, line))\n\n        wandb_files = set([save_name for save_name in self._file_pusher.files() if util.is_wandb_file(save_name)])\n        media_files = set([save_name for save_name in self._file_pusher.files() if save_name.startswith('media')])\n        other_files = set(self._file_pusher.files()) - wandb_files - media_files\n        logger.info(\"syncing files to cloud storage\")\n        if other_files:\n            wandb.termlog('Syncing files in %s:' % os.path.relpath(self._watch_dir))\n            for save_name in sorted(other_files):\n                wandb.termlog('  %s' % save_name)\n            wandb.termlog('plus {} W&B file(s) and {} media file(s)'.format(len(wandb_files), len(media_files)))\n        else:\n            wandb.termlog('Syncing {} W&B file(s) and {} media file(s)'.format(len(wandb_files), len(media_files)))\n\n        self._file_pusher.update_all_files()\n        self._file_pusher.print_status()\n\n        # TODO(adrian): this code has been broken since september 2017\n        # commit ID: abee525b because of these lines:\n        # if fname == 'wandb-history.h5' or 'training.log':\n        #     continue\n        url = self._run.get_url(self._api)\n        if False:\n            # Check md5s of uploaded files against what's on the file system.\n            # TODO: We're currently using the list of uploaded files as our source\n            #     of truth, but really we should use the files on the filesystem\n            #     (ie if we missed a file this wouldn't catch it).\n            # This polls the server, because there a delay between when the file\n            # is done uploading, and when the datastore gets updated with new\n            # metadata via pubsub.\n            wandb.termlog('Verifying uploaded files... ', newline=False)\n            error = False\n            mismatched = None\n            for delay_base in range(4):\n                mismatched = []\n                download_urls = self._api.download_urls(\n                    self._project, run=self._run.id)\n                for fname, info in download_urls.items():\n                    if fname == 'wandb-history.h5' or fname == OUTPUT_FNAME:\n                        continue\n                    local_path = os.path.join(self._watch_dir, fname)\n                    local_md5 = util.md5_file(local_path)\n                    if local_md5 != info['md5']:\n                        mismatched.append((local_path, local_md5, info['md5']))\n                if not mismatched:\n                    break\n                wandb.termlog('  Retrying after %ss' % (delay_base**2))\n                time.sleep(delay_base ** 2)\n\n            if mismatched:\n                print('')\n                error = True\n                for local_path, local_md5, remote_md5 in mismatched:\n                    wandb.termerror(\n                        '{} ({}) did not match uploaded file ({}) md5'.format(\n                            local_path, local_md5, remote_md5))\n            else:\n                print('verified!')\n\n            if error:\n                message = 'Sync failed %s' % url\n                wandb.termerror(message)\n                util.sentry_exc(message)\n            else:\n                wandb.termlog('Synced %s' % url)\n\n        wandb.termlog('Synced %s' % url)\n        logger.info(\"syncing complete: %s\" % url)\n        sys.exit(exitcode)", "response": "Syncs the user s file policy with the current user s current policy."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef token_list_len(tokenlist):\n    ZeroWidthEscape = Token.ZeroWidthEscape\n    return sum(len(item[1]) for item in tokenlist if item[0] != ZeroWidthEscape)", "response": "Returns the amount of characters in this token list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the character width of this token list.", "response": "def token_list_width(tokenlist):\n    \"\"\"\n    Return the character width of this token list.\n    (Take double width characters into account.)\n\n    :param tokenlist: List of (token, text) or (token, text, mouse_handler)\n                      tuples.\n    \"\"\"\n    ZeroWidthEscape = Token.ZeroWidthEscape\n    return sum(get_cwidth(c) for item in tokenlist for c in item[1] if item[0] != ZeroWidthEscape)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef token_list_to_text(tokenlist):\n    ZeroWidthEscape = Token.ZeroWidthEscape\n    return ''.join(item[1] for item in tokenlist if item[0] != ZeroWidthEscape)", "response": "Converts a list of tokens into a single text string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_token_lines(tokenlist):\n    line = []\n    for token, c in explode_tokens(tokenlist):\n        line.append((token, c))\n\n        if c == '\\n':\n            yield line\n            line = []\n\n    yield line", "response": "Iterator that yields tokenlists for each line."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef split_lines(tokenlist):\n    line = []\n\n    for item in tokenlist:\n        # For (token, text) tuples.\n        if len(item) == 2:\n            token, string = item\n            parts = string.split('\\n')\n\n            for part in parts[:-1]:\n                if part:\n                    line.append((token, part))\n                yield line\n                line = []\n\n            line.append((token, parts[-1]))\n                # Note that parts[-1] can be empty, and that's fine. It happens\n                # in the case of [(Token.SetCursorPosition, '')].\n\n        # For (token, text, mouse_handler) tuples.\n        #     I know, partly copy/paste, but understandable and more efficient\n        #     than many tests.\n        else:\n            token, string, mouse_handler = item\n            parts = string.split('\\n')\n\n            for part in parts[:-1]:\n                if part:\n                    line.append((token, part, mouse_handler))\n                yield line\n                line = []\n\n            line.append((token, parts[-1], mouse_handler))\n\n    # Always yield the last line, even when this is an empty line. This ensures\n    # that when `tokenlist` ends with a newline character, an additional empty\n    # line is yielded. (Otherwise, there's no way to differentiate between the\n    # cases where `tokenlist` does and doesn't end with a newline.)\n    yield line", "response": "Takes a single list of Token text tuples and yield one such list for each item in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef explode_tokens(tokenlist):\n    # When the tokenlist is already exploded, don't explode again.\n    if getattr(tokenlist, 'exploded', False):\n        return tokenlist\n\n    result = []\n\n    for token, string in tokenlist:\n        for c in string:\n            result.append((token, c))\n\n    return _ExplodedList(result)", "response": "Turn a list of ( token text ) tuples into another list where each string is\n    exactly one character."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds a Window that contains the given buffer name and return it.", "response": "def find_window_for_buffer_name(cli, buffer_name):\n    \"\"\"\n    Look for a :class:`~prompt_toolkit.layout.containers.Window` in the Layout\n    that contains the :class:`~prompt_toolkit.layout.controls.BufferControl`\n    for the given buffer and return it. If no such Window is found, return None.\n    \"\"\"\n    from prompt_toolkit.interface import CommandLineInterface\n    assert isinstance(cli, CommandLineInterface)\n\n    from .containers import Window\n    from .controls import BufferControl\n\n    for l in cli.layout.walk(cli):\n        if isinstance(l, Window) and isinstance(l.content, BufferControl):\n            if l.content.buffer_name == buffer_name:\n                return l"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_matches(self, key_presses):\n        keys = tuple(k.key for k in key_presses)\n        cli = self._cli_ref()\n\n        # Try match, with mode flag\n        return [b for b in self._registry.get_bindings_for_keys(keys) if b.filter(cli)]", "response": "Get a list of key presses that would handle this key press."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_prefix_of_longer_match(self, key_presses):\n        keys = tuple(k.key for k in key_presses)\n        cli = self._cli_ref()\n\n        # Get the filters for all the key bindings that have a longer match.\n        # Note that we transform it into a `set`, because we don't care about\n        # the actual bindings and executing it more than once doesn't make\n        # sense. (Many key bindings share the same filter.)\n        filters = set(b.filter for b in self._registry.get_bindings_starting_with_keys(keys))\n\n        # When any key binding is active, return True.\n        return any(f(cli) for f in filters)", "response": "Return True if there is any key binding that is bound to a longer match of this keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef feed(self, key_press):\n        assert isinstance(key_press, KeyPress)\n        self.input_queue.append(key_press)", "response": "Feed a new key press into the input queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing all the keys in the input_queue.", "response": "def process_keys(self):\n        \"\"\"\n        Process all the keys in the `input_queue`.\n        (To be called after `feed`.)\n\n        Note: because of the `feed`/`process_keys` separation, it is\n              possible to call `feed` from inside a key binding.\n              This function keeps looping until the queue is empty.\n        \"\"\"\n        while self.input_queue:\n            key_press = self.input_queue.popleft()\n\n            if key_press.key != Keys.CPRResponse:\n                self.beforeKeyPress.fire()\n\n            self._process_coroutine.send(key_press)\n\n            if key_press.key != Keys.CPRResponse:\n                self.afterKeyPress.fire()\n\n        # Invalidate user interface.\n        cli = self._cli_ref()\n        if cli:\n            cli.invalidate()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfixes the cursor position for Vi navigation mode.", "response": "def _fix_vi_cursor_position(self, event):\n        \"\"\"\n        After every command, make sure that if we are in Vi navigation mode, we\n        never put the cursor after the last character of a line. (Unless it's\n        an empty line.)\n        \"\"\"\n        cli = self._cli_ref()\n        if cli:\n            buff = cli.current_buffer\n            preferred_column = buff.preferred_column\n\n            if (ViNavigationMode()(event.cli) and\n                    buff.document.is_cursor_at_the_end_of_line and\n                    len(buff.document.current_line) > 0):\n                buff.cursor_position -= 1\n\n                # Set the preferred_column for arrow up/down again.\n                # (This was cleared after changing the cursor position.)\n                buff.preferred_column = preferred_column"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the argument of the log entry.", "response": "def arg(self):\n        \"\"\"\n        Repetition argument.\n        \"\"\"\n        if self._arg == '-':\n            return -1\n\n        result = int(self._arg or 1)\n\n        # Don't exceed a million.\n        if int(result) >= 1000000:\n            result = 1\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nappend digit to the input argument.", "response": "def append_to_arg_count(self, data):\n        \"\"\"\n        Add digit to the input argument.\n\n        :param data: the typed digit as string\n        \"\"\"\n        assert data in '-0123456789'\n        current = self._arg\n\n        if data == '-':\n            assert current is None or current == '-'\n            result = data\n        elif current is None:\n            result = data\n        else:\n            result = \"%s%s\" % (current, data)\n\n        self.input_processor.arg = result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a set of key presses from the console and return a list of KeyPress instances. It won t return anything when there was nothing to read.", "response": "def read(self):\n        \"\"\"\n        Return a list of `KeyPress` instances. It won't return anything when\n        there was nothing to read.  (This function doesn't block.)\n\n        http://msdn.microsoft.com/en-us/library/windows/desktop/ms684961(v=vs.85).aspx\n        \"\"\"\n        max_count = 2048  # Max events to read at the same time.\n\n        read = DWORD(0)\n        arrtype = INPUT_RECORD * max_count\n        input_records = arrtype()\n\n        # Get next batch of input event.\n        windll.kernel32.ReadConsoleInputW(\n            self.handle, pointer(input_records), max_count, pointer(read))\n\n        # First, get all the keys from the input buffer, in order to determine\n        # whether we should consider this a paste event or not.\n        all_keys = list(self._get_keys(read, input_records))\n\n        if self.recognize_paste and self._is_paste(all_keys):\n            gen = iter(all_keys)\n            for k in gen:\n                # Pasting: if the current key consists of text or \\n, turn it\n                # into a BracketedPaste.\n                data = []\n                while k and (isinstance(k.key, six.text_type) or\n                             k.key == Keys.ControlJ):\n                    data.append(k.data)\n                    try:\n                        k = next(gen)\n                    except StopIteration:\n                        k = None\n\n                if data:\n                    yield KeyPress(Keys.BracketedPaste, ''.join(data))\n                if k is not None:\n                    yield k\n        else:\n            for k in all_keys:\n                yield k"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_keys(self, read, input_records):\n        for i in range(read.value):\n            ir = input_records[i]\n\n            # Get the right EventType from the EVENT_RECORD.\n            # (For some reason the Windows console application 'cmder'\n            # [http://gooseberrycreative.com/cmder/] can return '0' for\n            # ir.EventType. -- Just ignore that.)\n            if ir.EventType in EventTypes:\n                ev = getattr(ir.Event, EventTypes[ir.EventType])\n\n                # Process if this is a key event. (We also have mouse, menu and\n                # focus events.)\n                if type(ev) == KEY_EVENT_RECORD and ev.KeyDown:\n                    for key_press in self._event_to_key_presses(ev):\n                        yield key_press\n\n                elif type(ev) == MOUSE_EVENT_RECORD:\n                    for key_press in self._handle_mouse(ev):\n                        yield key_press", "response": "Generator that yields KeyPress objects from the input records."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _is_paste(keys):\n        # Consider paste when it contains at least one newline and at least one\n        # other character.\n        text_count = 0\n        newline_count = 0\n\n        for k in keys:\n            if isinstance(k.key, six.text_type):\n                text_count += 1\n            if k.key == Keys.ControlJ:\n                newline_count += 1\n\n        return newline_count >= 1 and text_count > 1", "response": "Return True when we should consider this list of keys as a paste\n        event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _event_to_key_presses(self, ev):\n        assert type(ev) == KEY_EVENT_RECORD and ev.KeyDown\n\n        result = None\n\n        u_char = ev.uChar.UnicodeChar\n        ascii_char = u_char.encode('utf-8')\n\n        # NOTE: We don't use `ev.uChar.AsciiChar`. That appears to be latin-1\n        #       encoded. See also:\n        # https://github.com/ipython/ipython/issues/10004\n        # https://github.com/jonathanslenders/python-prompt-toolkit/issues/389\n\n        if u_char == '\\x00':\n            if ev.VirtualKeyCode in self.keycodes:\n                result = KeyPress(self.keycodes[ev.VirtualKeyCode], '')\n        else:\n            if ascii_char in self.mappings:\n                if self.mappings[ascii_char] == Keys.ControlJ:\n                    u_char = '\\n'  # Windows sends \\n, turn into \\r for unix compatibility.\n                result = KeyPress(self.mappings[ascii_char], u_char)\n            else:\n                result = KeyPress(u_char, u_char)\n\n        # Correctly handle Control-Arrow keys.\n        if (ev.ControlKeyState & self.LEFT_CTRL_PRESSED or\n                ev.ControlKeyState & self.RIGHT_CTRL_PRESSED) and result:\n            if result.key == Keys.Left:\n                result.key = Keys.ControlLeft\n\n            if result.key == Keys.Right:\n                result.key = Keys.ControlRight\n\n            if result.key == Keys.Up:\n                result.key = Keys.ControlUp\n\n            if result.key == Keys.Down:\n                result.key = Keys.ControlDown\n\n        # Turn 'Tab' into 'BackTab' when shift was pressed.\n        if ev.ControlKeyState & self.SHIFT_PRESSED and result:\n            if result.key == Keys.Tab:\n                result.key = Keys.BackTab\n\n        # Turn 'Space' into 'ControlSpace' when control was pressed.\n        if (ev.ControlKeyState & self.LEFT_CTRL_PRESSED or\n                ev.ControlKeyState & self.RIGHT_CTRL_PRESSED) and result and result.data == ' ':\n            result = KeyPress(Keys.ControlSpace, ' ')\n\n        # Turn Control-Enter into META-Enter. (On a vt100 terminal, we cannot\n        # detect this combination. But it's really practical on Windows.)\n        if (ev.ControlKeyState & self.LEFT_CTRL_PRESSED or\n                ev.ControlKeyState & self.RIGHT_CTRL_PRESSED) and result and \\\n                result.key == Keys.ControlJ:\n            return [KeyPress(Keys.Escape, ''), result]\n\n        # Return result. If alt was pressed, prefix the result with an\n        # 'Escape' key, just like unix VT100 terminals do.\n\n        # NOTE: Only replace the left alt with escape. The right alt key often\n        #       acts as altgr and is used in many non US keyboard layouts for\n        #       typing some special characters, like a backslash. We don't want\n        #       all backslashes to be prefixed with escape. (Esc-\\ has a\n        #       meaning in E-macs, for instance.)\n        if result:\n            meta_pressed = ev.ControlKeyState & self.LEFT_ALT_PRESSED\n\n            if meta_pressed:\n                return [KeyPress(Keys.Escape, ''), result]\n            else:\n                return [result]\n\n        else:\n            return []", "response": "Convert a KEY_EVENT_RECORD to a list of KeyPress instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles mouse events. Return a list of KeyPress instances.", "response": "def _handle_mouse(self, ev):\n        \"\"\"\n        Handle mouse events. Return a list of KeyPress instances.\n        \"\"\"\n        FROM_LEFT_1ST_BUTTON_PRESSED = 0x1\n\n        result = []\n\n        # Check event type.\n        if ev.ButtonState == FROM_LEFT_1ST_BUTTON_PRESSED:\n            # On a key press, generate both the mouse down and up event.\n            for event_type in [MouseEventType.MOUSE_DOWN, MouseEventType.MOUSE_UP]:\n                data = ';'.join([\n                   event_type,\n                   str(ev.MousePosition.X),\n                   str(ev.MousePosition.Y)\n                ])\n                result.append(KeyPress(Keys.WindowsMouseEvent, data))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tokenize_regex(input):\n    # Regular expression for tokenizing other regular expressions.\n    p = re.compile(r'''^(\n        \\(\\?P\\<[a-zA-Z0-9_-]+\\>  | # Start of named group.\n        \\(\\?#[^)]*\\)             | # Comment\n        \\(\\?=                    | # Start of lookahead assertion\n        \\(\\?!                    | # Start of negative lookahead assertion\n        \\(\\?<=                   | # If preceded by.\n        \\(\\?<                    | # If not preceded by.\n        \\(?:                     | # Start of group. (non capturing.)\n        \\(                       | # Start of group.\n        \\(?[iLmsux]              | # Flags.\n        \\(?P=[a-zA-Z]+\\)         | # Back reference to named group\n        \\)                       | # End of group.\n        \\{[^{}]*\\}               | # Repetition\n        \\*\\? | \\+\\? | \\?\\?\\      | # Non greedy repetition.\n        \\* | \\+ | \\?             | # Repetition\n        \\#.*\\n                   | # Comment\n        \\\\. |\n\n        # Character group.\n        \\[\n            ( [^\\]\\\\]  |  \\\\.)*\n        \\]                  |\n\n        [^(){}]             |\n        .\n    )''', re.VERBOSE)\n\n    tokens = []\n\n    while input:\n        m = p.match(input)\n        if m:\n            token, input = input[:m.end()], input[m.end():]\n            if not token.isspace():\n                tokens.append(token)\n        else:\n            raise Exception('Could not tokenize input regex.')\n\n    return tokens", "response": "Takes a string representing a regular expression as input and tokenizes the other regular expressions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_regex(regex_tokens):\n    # We add a closing brace because that represents the final pop of the stack.\n    tokens = [')'] + regex_tokens[::-1]\n\n    def wrap(lst):\n        \"\"\" Turn list into sequence when it contains several items. \"\"\"\n        if len(lst) == 1:\n            return lst[0]\n        else:\n            return Sequence(lst)\n\n    def _parse():\n        or_list = []\n        result = []\n\n        def wrapped_result():\n            if or_list == []:\n                return wrap(result)\n            else:\n                or_list.append(result)\n                return Any([wrap(i) for i in or_list])\n\n        while tokens:\n            t = tokens.pop()\n\n            if t.startswith('(?P<'):\n                variable = Variable(_parse(), varname=t[4:-1])\n                result.append(variable)\n\n            elif t in ('*', '*?'):\n                greedy = (t == '*')\n                result[-1] = Repeat(result[-1], greedy=greedy)\n\n            elif t in ('+', '+?'):\n                greedy = (t == '+')\n                result[-1] = Repeat(result[-1], min_repeat=1, greedy=greedy)\n\n            elif t in ('?', '??'):\n                if result == []:\n                    raise Exception('Nothing to repeat.' + repr(tokens))\n                else:\n                    greedy = (t == '?')\n                    result[-1] = Repeat(result[-1], min_repeat=0, max_repeat=1, greedy=greedy)\n\n            elif t == '|':\n                or_list.append(result)\n                result = []\n\n            elif t in ('(', '(?:'):\n                result.append(_parse())\n\n            elif t == '(?!':\n                result.append(Lookahead(_parse(), negative=True))\n\n            elif t == '(?=':\n                result.append(Lookahead(_parse(), negative=False))\n\n            elif t == ')':\n                return wrapped_result()\n\n            elif t.startswith('#'):\n                pass\n\n            elif t.startswith('{'):\n                # TODO: implement!\n                raise Exception('{}-style repitition not yet supported' % t)\n\n            elif t.startswith('(?'):\n                raise Exception('%r not supported' % t)\n\n            elif t.isspace():\n                pass\n            else:\n                result.append(Regex(t))\n\n        raise Exception(\"Expecting ')' token\")\n\n    result = _parse()\n\n    if len(tokens) != 0:\n        raise Exception(\"Unmatched parantheses.\")\n    else:\n        return result", "response": "Takes a list of tokens from the tokenizer and returns a parse tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrender the prompt to a Screen instance.", "response": "def write_to_screen(self, cli, screen, mouse_handlers, write_position):\n        \"\"\"\n        Render the prompt to a `Screen` instance.\n\n        :param screen: The :class:`~prompt_toolkit.layout.screen.Screen` class\n            to which the output has to be written.\n        \"\"\"\n        sizes = self._divide_heigths(cli, write_position)\n\n        if self.report_dimensions_callback:\n            self.report_dimensions_callback(cli, sizes)\n\n        if sizes is None:\n            self.window_too_small.write_to_screen(\n                cli, screen, mouse_handlers, write_position)\n        else:\n            # Draw child panes.\n            ypos = write_position.ypos\n            xpos = write_position.xpos\n            width = write_position.width\n\n            for s, c in zip(sizes, self.children):\n                c.write_to_screen(cli, screen, mouse_handlers, WritePosition(xpos, ypos, width, s))\n                ypos += s"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndividing the heights for all rows.", "response": "def _divide_heigths(self, cli, write_position):\n        \"\"\"\n        Return the heights for all rows.\n        Or None when there is not enough space.\n        \"\"\"\n        if not self.children:\n            return []\n\n        # Calculate heights.\n        given_dimensions = self.get_dimensions(cli) if self.get_dimensions else None\n\n        def get_dimension_for_child(c, index):\n            if given_dimensions and given_dimensions[index] is not None:\n                return given_dimensions[index]\n            else:\n                return c.preferred_height(cli, write_position.width, write_position.extended_height)\n\n        dimensions = [get_dimension_for_child(c, index) for index, c in enumerate(self.children)]\n\n        # Sum dimensions\n        sum_dimensions = sum_layout_dimensions(dimensions)\n\n        # If there is not enough space for both.\n        # Don't do anything.\n        if sum_dimensions.min > write_position.extended_height:\n            return\n\n        # Find optimal sizes. (Start with minimal size, increase until we cover\n        # the whole height.)\n        sizes = [d.min for d in dimensions]\n\n        child_generator = take_using_weights(\n            items=list(range(len(dimensions))),\n            weights=[d.weight for d in dimensions])\n\n        i = next(child_generator)\n\n        while sum(sizes) < min(write_position.extended_height, sum_dimensions.preferred):\n            # Increase until we meet at least the 'preferred' size.\n            if sizes[i] < dimensions[i].preferred:\n                sizes[i] += 1\n            i = next(child_generator)\n\n        if not any([cli.is_returning, cli.is_exiting, cli.is_aborting]):\n            while sum(sizes) < min(write_position.height, sum_dimensions.max):\n                # Increase until we use all the available space. (or until \"max\")\n                if sizes[i] < dimensions[i].max:\n                    sizes[i] += 1\n                i = next(child_generator)\n\n        return sizes"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwalks through the hierarchy of the hierarchy.", "response": "def walk(self, cli):\n        \"\"\" Walk through children. \"\"\"\n        yield self\n        for c in self.children:\n            for i in c.walk(cli):\n                yield i"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndivide the widths for all columns.", "response": "def _divide_widths(self, cli, width):\n        \"\"\"\n        Return the widths for all columns.\n        Or None when there is not enough space.\n        \"\"\"\n        if not self.children:\n            return []\n\n        # Calculate widths.\n        given_dimensions = self.get_dimensions(cli) if self.get_dimensions else None\n\n        def get_dimension_for_child(c, index):\n            if given_dimensions and given_dimensions[index] is not None:\n                return given_dimensions[index]\n            else:\n                return c.preferred_width(cli, width)\n\n        dimensions = [get_dimension_for_child(c, index) for index, c in enumerate(self.children)]\n\n        # Sum dimensions\n        sum_dimensions = sum_layout_dimensions(dimensions)\n\n        # If there is not enough space for both.\n        # Don't do anything.\n        if sum_dimensions.min > width:\n            return\n\n        # Find optimal sizes. (Start with minimal size, increase until we cover\n        # the whole height.)\n        sizes = [d.min for d in dimensions]\n\n        child_generator = take_using_weights(\n            items=list(range(len(dimensions))),\n            weights=[d.weight for d in dimensions])\n\n        i = next(child_generator)\n\n        while sum(sizes) < min(width, sum_dimensions.preferred):\n            # Increase until we meet at least the 'preferred' size.\n            if sizes[i] < dimensions[i].preferred:\n                sizes[i] += 1\n            i = next(child_generator)\n\n        while sum(sizes) < min(width, sum_dimensions.max):\n            # Increase until we use all the available space.\n            if sizes[i] < dimensions[i].max:\n                sizes[i] += 1\n            i = next(child_generator)\n\n        return sizes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering the prompt to a Screen instance.", "response": "def write_to_screen(self, cli, screen, mouse_handlers, write_position):\n        \"\"\"\n        Render the prompt to a `Screen` instance.\n\n        :param screen: The :class:`~prompt_toolkit.layout.screen.Screen` class\n            to which the output has to be written.\n        \"\"\"\n        if not self.children:\n            return\n\n        sizes = self._divide_widths(cli, write_position.width)\n\n        if self.report_dimensions_callback:\n            self.report_dimensions_callback(cli, sizes)\n\n        # If there is not enough space.\n        if sizes is None:\n            self.window_too_small.write_to_screen(\n                cli, screen, mouse_handlers, write_position)\n            return\n\n        # Calculate heights, take the largest possible, but not larger than write_position.extended_height.\n        heights = [child.preferred_height(cli, width, write_position.extended_height).preferred\n                   for width, child in zip(sizes, self.children)]\n        height = max(write_position.height, min(write_position.extended_height, max(heights)))\n\n        # Draw child panes.\n        ypos = write_position.ypos\n        xpos = write_position.xpos\n\n        for s, c in zip(sizes, self.children):\n            c.write_to_screen(cli, screen, mouse_handlers, WritePosition(xpos, ypos, s, height))\n            xpos += s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preferred_height(self, cli, width, max_available_height):\n        return self.content.preferred_height(cli, width, max_available_height)", "response": "Return the preferred height of the container."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _area_is_empty(self, screen, write_position):\n        wp = write_position\n        Transparent = Token.Transparent\n\n        for y in range(wp.ypos, wp.ypos + wp.height):\n            if y in screen.data_buffer:\n                row = screen.data_buffer[y]\n\n                for x in range(wp.xpos, wp.xpos + wp.width):\n                    c = row[x]\n                    if c.char != ' ' or c.token != Transparent:\n                        return False\n\n        return True", "response": "Return True when the area below the write position is still empty."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the cursor position coordinates relative to the left / top corner of the rendered screen.", "response": "def cursor_position(self):\n        \"\"\"\n        Return the cursor position coordinates, relative to the left/top corner\n        of the rendered screen.\n        \"\"\"\n        cpos = self.ui_content.cursor_position\n        y, x = self._rowcol_to_yx[cpos.y, cpos.x]\n        return Point(x=x - self._x_offset, y=y - self._y_offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef applied_scroll_offsets(self):\n        if self.displayed_lines[0] == 0:\n            top = 0\n        else:\n            # Get row where the cursor is displayed.\n            y = self.input_line_to_visible_line[self.ui_content.cursor_position.y]\n            top = min(y, self.configured_scroll_offsets.top)\n\n        return ScrollOffsets(\n            top=top,\n            bottom=min(self.ui_content.line_count - self.displayed_lines[-1] - 1,\n                       self.configured_scroll_offsets.bottom),\n\n            # For left/right, it probably doesn't make sense to return something.\n            # (We would have to calculate the widths of all the lines and keep\n            # double width characters in mind.)\n            left=0, right=0)", "response": "Return a ScrollOffsets instance that indicates the actual scroll offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef input_line_to_visible_line(self):\n        result = {}\n        for k, v in self.visible_line_to_input_line.items():\n            if v in result:\n                result[v] = min(result[v], k)\n            else:\n                result[v] = k\n        return result", "response": "Return the dictionary mapping the line numbers of the input buffer to the visible line numbers of the screen."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef first_visible_line(self, after_scroll_offset=False):\n        if after_scroll_offset:\n            return self.displayed_lines[self.applied_scroll_offsets.top]\n        else:\n            return self.displayed_lines[0]", "response": "Return the first visible line in the document that corresponds\n        with the first visible line."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the last visible line.", "response": "def last_visible_line(self, before_scroll_offset=False):\n        \"\"\"\n        Like `first_visible_line`, but for the last visible line.\n        \"\"\"\n        if before_scroll_offset:\n            return self.displayed_lines[-1 - self.applied_scroll_offsets.bottom]\n        else:\n            return self.displayed_lines[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the center visible line.", "response": "def center_visible_line(self, before_scroll_offset=False,\n                            after_scroll_offset=False):\n        \"\"\"\n        Like `first_visible_line`, but for the center visible line.\n        \"\"\"\n        return (self.first_visible_line(after_scroll_offset) +\n                (self.last_visible_line(before_scroll_offset) -\n                 self.first_visible_line(after_scroll_offset)) // 2\n               )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the height of the given line.", "response": "def get_height_for_line(self, lineno):\n        \"\"\"\n        Return the height of the given line.\n        (The height that it would take, if this line became visible.)\n        \"\"\"\n        if self.wrap_lines:\n            return self.ui_content.get_height_for_line(lineno, self.window_width)\n        else:\n            return 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_margin_width(self, cli, margin):\n        # Margin.get_width, needs to have a UIContent instance.\n        def get_ui_content():\n            return self._get_ui_content(cli, width=0, height=0)\n\n        def get_width():\n            return margin.get_width(cli, get_ui_content)\n\n        key = (margin, cli.render_counter)\n        return self._margin_width_cache.get(key, get_width)", "response": "Get the width for this margin."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a UIContent instance from the cache.", "response": "def _get_ui_content(self, cli, width, height):\n        \"\"\"\n        Create a `UIContent` instance.\n        \"\"\"\n        def get_content():\n            return self.content.create_content(cli, width=width, height=height)\n\n        key = (cli.render_counter, width, height)\n        return self._ui_content_cache.get(key, get_content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns False or the Digraph symbol to be used.", "response": "def _get_digraph_char(self, cli):\n        \" Return `False`, or the Digraph symbol to be used. \"\n        if cli.quoted_insert:\n            return '^'\n        if cli.vi_state.waiting_for_digraph:\n            if cli.vi_state.digraph_symbol1:\n                return cli.vi_state.digraph_symbol1\n            return '?'\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_to_screen(self, cli, screen, mouse_handlers, write_position):\n        # Calculate margin sizes.\n        left_margin_widths = [self._get_margin_width(cli, m) for m in self.left_margins]\n        right_margin_widths = [self._get_margin_width(cli, m) for m in self.right_margins]\n        total_margin_width = sum(left_margin_widths + right_margin_widths)\n\n        # Render UserControl.\n        ui_content = self.content.create_content(\n            cli, write_position.width - total_margin_width, write_position.height)\n        assert isinstance(ui_content, UIContent)\n\n        # Scroll content.\n        wrap_lines = self.wrap_lines(cli)\n        scroll_func = self._scroll_when_linewrapping if wrap_lines else self._scroll_without_linewrapping\n\n        scroll_func(\n            ui_content, write_position.width - total_margin_width, write_position.height, cli)\n\n        # Write body\n        visible_line_to_row_col, rowcol_to_yx = self._copy_body(\n            cli, ui_content, screen, write_position,\n            sum(left_margin_widths), write_position.width - total_margin_width,\n            self.vertical_scroll, self.horizontal_scroll,\n            has_focus=self.content.has_focus(cli),\n            wrap_lines=wrap_lines, highlight_lines=True,\n            vertical_scroll_2=self.vertical_scroll_2,\n            always_hide_cursor=self.always_hide_cursor(cli))\n\n        # Remember render info. (Set before generating the margins. They need this.)\n        x_offset=write_position.xpos + sum(left_margin_widths)\n        y_offset=write_position.ypos\n\n        self.render_info = WindowRenderInfo(\n            ui_content=ui_content,\n            horizontal_scroll=self.horizontal_scroll,\n            vertical_scroll=self.vertical_scroll,\n            window_width=write_position.width - total_margin_width,\n            window_height=write_position.height,\n            configured_scroll_offsets=self.scroll_offsets,\n            visible_line_to_row_col=visible_line_to_row_col,\n            rowcol_to_yx=rowcol_to_yx,\n            x_offset=x_offset,\n            y_offset=y_offset,\n            wrap_lines=wrap_lines)\n\n        # Set mouse handlers.\n        def mouse_handler(cli, mouse_event):\n            \"\"\" Wrapper around the mouse_handler of the `UIControl` that turns\n            screen coordinates into line coordinates. \"\"\"\n            # Find row/col position first.\n            yx_to_rowcol = dict((v, k) for k, v in rowcol_to_yx.items())\n            y = mouse_event.position.y\n            x = mouse_event.position.x\n\n            # If clicked below the content area, look for a position in the\n            # last line instead.\n            max_y = write_position.ypos + len(visible_line_to_row_col) - 1\n            y = min(max_y, y)\n\n            while x >= 0:\n                try:\n                    row, col = yx_to_rowcol[y, x]\n                except KeyError:\n                    # Try again. (When clicking on the right side of double\n                    # width characters, or on the right side of the input.)\n                    x -= 1\n                else:\n                    # Found position, call handler of UIControl.\n                    result = self.content.mouse_handler(\n                        cli, MouseEvent(position=Point(x=col, y=row),\n                                        event_type=mouse_event.event_type))\n                    break\n            else:\n                # nobreak.\n                # (No x/y coordinate found for the content. This happens in\n                # case of a FillControl, that only specifies a background, but\n                # doesn't have a content. Report (0,0) instead.)\n                result = self.content.mouse_handler(\n                    cli, MouseEvent(position=Point(x=0, y=0),\n                                    event_type=mouse_event.event_type))\n\n            # If it returns NotImplemented, handle it here.\n            if result == NotImplemented:\n                return self._mouse_handler(cli, mouse_event)\n\n            return result\n\n        mouse_handlers.set_mouse_handler_for_range(\n            x_min=write_position.xpos + sum(left_margin_widths),\n            x_max=write_position.xpos + write_position.width - total_margin_width,\n            y_min=write_position.ypos,\n            y_max=write_position.ypos + write_position.height,\n            handler=mouse_handler)\n\n        # Render and copy margins.\n        move_x = 0\n\n        def render_margin(m, width):\n            \" Render margin. Return `Screen`. \"\n            # Retrieve margin tokens.\n            tokens = m.create_margin(cli, self.render_info, width, write_position.height)\n\n            # Turn it into a UIContent object.\n            # already rendered those tokens using this size.)\n            return TokenListControl.static(tokens).create_content(\n                cli, width + 1, write_position.height)\n\n        for m, width in zip(self.left_margins, left_margin_widths):\n            # Create screen for margin.\n            margin_screen = render_margin(m, width)\n\n            # Copy and shift X.\n            self._copy_margin(cli, margin_screen, screen, write_position, move_x, width)\n            move_x += width\n\n        move_x = write_position.width - sum(right_margin_widths)\n\n        for m, width in zip(self.right_margins, right_margin_widths):\n            # Create screen for margin.\n            margin_screen = render_margin(m, width)\n\n            # Copy and shift X.\n            self._copy_margin(cli, margin_screen, screen, write_position, move_x, width)\n            move_x += width", "response": "Writes the user control to the given screen."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _copy_body(self, cli, ui_content, new_screen, write_position, move_x,\n                   width, vertical_scroll=0, horizontal_scroll=0,\n                   has_focus=False, wrap_lines=False, highlight_lines=False,\n                   vertical_scroll_2=0, always_hide_cursor=False):\n        \"\"\"\n        Copy the UIContent into the output screen.\n        \"\"\"\n        xpos = write_position.xpos + move_x\n        ypos = write_position.ypos\n        line_count = ui_content.line_count\n        new_buffer = new_screen.data_buffer\n        empty_char = _CHAR_CACHE['', Token]\n        ZeroWidthEscape = Token.ZeroWidthEscape\n\n        # Map visible line number to (row, col) of input.\n        # 'col' will always be zero if line wrapping is off.\n        visible_line_to_row_col = {}\n        rowcol_to_yx = {}  # Maps (row, col) from the input to (y, x) screen coordinates.\n\n        # Fill background with default_char first.\n        default_char = ui_content.default_char\n\n        if default_char:\n            for y in range(ypos, ypos + write_position.height):\n                new_buffer_row = new_buffer[y]\n                for x in range(xpos, xpos + width):\n                    new_buffer_row[x] = default_char\n\n        # Copy content.\n        def copy():\n            y = - vertical_scroll_2\n            lineno = vertical_scroll\n\n            while y < write_position.height and lineno < line_count:\n                # Take the next line and copy it in the real screen.\n                line = ui_content.get_line(lineno)\n\n                col = 0\n                x = -horizontal_scroll\n\n                visible_line_to_row_col[y] = (lineno, horizontal_scroll)\n                new_buffer_row = new_buffer[y + ypos]\n\n                for token, text in line:\n                    # Remember raw VT escape sequences. (E.g. FinalTerm's\n                    # escape sequences.)\n                    if token == ZeroWidthEscape:\n                        new_screen.zero_width_escapes[y + ypos][x + xpos] += text\n                        continue\n\n                    for c in text:\n                        char = _CHAR_CACHE[c, token]\n                        char_width = char.width\n\n                        # Wrap when the line width is exceeded.\n                        if wrap_lines and x + char_width > width:\n                            visible_line_to_row_col[y + 1] = (\n                                lineno, visible_line_to_row_col[y][1] + x)\n                            y += 1\n                            x = -horizontal_scroll  # This would be equal to zero.\n                                                    # (horizontal_scroll=0 when wrap_lines.)\n                            new_buffer_row = new_buffer[y + ypos]\n\n                            if y >= write_position.height:\n                                return y  # Break out of all for loops.\n\n                        # Set character in screen and shift 'x'.\n                        if x >= 0 and y >= 0 and x < write_position.width:\n                            new_buffer_row[x + xpos] = char\n\n                            # When we print a multi width character, make sure\n                            # to erase the neighbous positions in the screen.\n                            # (The empty string if different from everything,\n                            # so next redraw this cell will repaint anyway.)\n                            if char_width > 1:\n                                for i in range(1, char_width):\n                                    new_buffer_row[x + xpos + i] = empty_char\n\n                            # If this is a zero width characters, then it's\n                            # probably part of a decomposed unicode character.\n                            # See: https://en.wikipedia.org/wiki/Unicode_equivalence\n                            # Merge it in the previous cell.\n                            elif char_width == 0 and x - 1 >= 0:\n                                prev_char = new_buffer_row[x + xpos - 1]\n                                char2 = _CHAR_CACHE[prev_char.char + c, prev_char.token]\n                                new_buffer_row[x + xpos - 1] = char2\n\n                            # Keep track of write position for each character.\n                            rowcol_to_yx[lineno, col] = (y + ypos, x + xpos)\n\n                        col += 1\n                        x += char_width\n\n                lineno += 1\n                y += 1\n            return y\n\n        y = copy()\n\n        def cursor_pos_to_screen_pos(row, col):\n            \" Translate row/col from UIContent to real Screen coordinates. \"\n            try:\n                y, x = rowcol_to_yx[row, col]\n            except KeyError:\n                # Normally this should never happen. (It is a bug, if it happens.)\n                # But to be sure, return (0, 0)\n                return Point(y=0, x=0)\n\n                # raise ValueError(\n                #     'Invalid position. row=%r col=%r, vertical_scroll=%r, '\n                #     'horizontal_scroll=%r, height=%r' %\n                #     (row, col, vertical_scroll, horizontal_scroll, write_position.height))\n            else:\n                return Point(y=y, x=x)\n\n        # Set cursor and menu positions.\n        if ui_content.cursor_position:\n            screen_cursor_position = cursor_pos_to_screen_pos(\n                    ui_content.cursor_position.y, ui_content.cursor_position.x)\n\n            if has_focus:\n                new_screen.cursor_position = screen_cursor_position\n\n                if always_hide_cursor:\n                    new_screen.show_cursor = False\n                else:\n                    new_screen.show_cursor = ui_content.show_cursor\n\n                self._highlight_digraph(cli, new_screen)\n\n            if highlight_lines:\n                self._highlight_cursorlines(\n                    cli, new_screen, screen_cursor_position, xpos, ypos, width,\n                    write_position.height)\n\n        # Draw input characters from the input processor queue.\n        if has_focus and ui_content.cursor_position:\n            self._show_input_processor_key_buffer(cli, new_screen)\n\n        # Set menu position.\n        if not new_screen.menu_position and ui_content.menu_position:\n            new_screen.menu_position = cursor_pos_to_screen_pos(\n                    ui_content.menu_position.y, ui_content.menu_position.x)\n\n        # Update output screne height.\n        new_screen.height = max(new_screen.height, ypos + write_position.height)\n\n        return visible_line_to_row_col, rowcol_to_yx", "response": "Copy the UIContent into the output screen."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhighlight the current color in the digraph screen.", "response": "def _highlight_digraph(self, cli, new_screen):\n        \"\"\"\n        When we are in Vi digraph mode, put a question mark underneath the\n        cursor.\n        \"\"\"\n        digraph_char = self._get_digraph_char(cli)\n        if digraph_char:\n            cpos = new_screen.cursor_position\n            new_screen.data_buffer[cpos.y][cpos.x] = \\\n                _CHAR_CACHE[digraph_char, Token.Digraph]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying the last pressed key in the input processor s key buffer.", "response": "def _show_input_processor_key_buffer(self, cli, new_screen):\n        \"\"\"\n        When the user is typing a key binding that consists of several keys,\n        display the last pressed key if the user is in insert mode and the key\n        is meaningful to be displayed.\n        E.g. Some people want to bind 'jj' to escape in Vi insert mode. But the\n             first 'j' needs to be displayed in order to get some feedback.\n        \"\"\"\n        key_buffer = cli.input_processor.key_buffer\n\n        if key_buffer and _in_insert_mode(cli) and not cli.is_done:\n            # The textual data for the given key. (Can be a VT100 escape\n            # sequence.)\n            data = key_buffer[-1].data\n\n            # Display only if this is a 1 cell width character.\n            if get_cwidth(data) == 1:\n                cpos = new_screen.cursor_position\n                new_screen.data_buffer[cpos.y][cpos.x] = \\\n                    _CHAR_CACHE[data, Token.PartialKeyBinding]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhighlights the cursor lines and columns.", "response": "def _highlight_cursorlines(self, cli, new_screen, cpos, x, y, width, height):\n        \"\"\"\n        Highlight cursor row/column.\n        \"\"\"\n        cursor_line_token = (':', ) + self.cursorline_token\n        cursor_column_token = (':', ) + self.cursorcolumn_token\n\n        data_buffer = new_screen.data_buffer\n\n        # Highlight cursor line.\n        if self.cursorline(cli):\n            row = data_buffer[cpos.y]\n            for x in range(x, x + width):\n                original_char = row[x]\n                row[x] = _CHAR_CACHE[\n                    original_char.char, original_char.token + cursor_line_token]\n\n        # Highlight cursor column.\n        if self.cursorcolumn(cli):\n            for y2 in range(y, y + height):\n                row = data_buffer[y2]\n                original_char = row[cpos.x]\n                row[cpos.x] = _CHAR_CACHE[\n                   original_char.char, original_char.token + cursor_column_token]\n\n        # Highlight color columns\n        for cc in self.get_colorcolumns(cli):\n            assert isinstance(cc, ColorColumn)\n            color_column_token = (':', ) + cc.token\n            column = cc.position\n\n            for y2 in range(y, y + height):\n                row = data_buffer[y2]\n                original_char = row[column]\n                row[column] = _CHAR_CACHE[\n                   original_char.char, original_char.token + color_column_token]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying the margin screen to the real screen.", "response": "def _copy_margin(self, cli, lazy_screen, new_screen, write_position, move_x, width):\n        \"\"\"\n        Copy characters from the margin screen to the real screen.\n        \"\"\"\n        xpos = write_position.xpos + move_x\n        ypos = write_position.ypos\n\n        margin_write_position = WritePosition(xpos, ypos, width, write_position.height)\n        self._copy_body(cli, lazy_screen, new_screen, margin_write_position, 0, width)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _scroll_when_linewrapping(self, ui_content, width, height, cli):\n        scroll_offsets_bottom = self.scroll_offsets.bottom\n        scroll_offsets_top = self.scroll_offsets.top\n\n        # We don't have horizontal scrolling.\n        self.horizontal_scroll = 0\n\n        # If the current line consumes more than the whole window height,\n        # then we have to scroll vertically inside this line. (We don't take\n        # the scroll offsets into account for this.)\n        # Also, ignore the scroll offsets in this case. Just set the vertical\n        # scroll to this line.\n        if ui_content.get_height_for_line(ui_content.cursor_position.y, width) > height - scroll_offsets_top:\n            # Calculate the height of the text before the cursor, with the line\n            # containing the cursor included, and the character belowe the\n            # cursor included as well.\n            line = explode_tokens(ui_content.get_line(ui_content.cursor_position.y))\n            text_before_cursor = token_list_to_text(line[:ui_content.cursor_position.x + 1])\n            text_before_height = UIContent.get_height_for_text(text_before_cursor, width)\n\n            # Adjust scroll offset.\n            self.vertical_scroll = ui_content.cursor_position.y\n            self.vertical_scroll_2 = min(text_before_height - 1, self.vertical_scroll_2)\n            self.vertical_scroll_2 = max(0, text_before_height - height, self.vertical_scroll_2)\n            return\n        else:\n            self.vertical_scroll_2 = 0\n\n        # Current line doesn't consume the whole height. Take scroll offsets into account.\n        def get_min_vertical_scroll():\n            # Make sure that the cursor line is not below the bottom.\n            # (Calculate how many lines can be shown between the cursor and the .)\n            used_height = 0\n            prev_lineno = ui_content.cursor_position.y\n\n            for lineno in range(ui_content.cursor_position.y, -1, -1):\n                used_height += ui_content.get_height_for_line(lineno, width)\n\n                if used_height > height - scroll_offsets_bottom:\n                    return prev_lineno\n                else:\n                    prev_lineno = lineno\n            return 0\n\n        def get_max_vertical_scroll():\n            # Make sure that the cursor line is not above the top.\n            prev_lineno = ui_content.cursor_position.y\n            used_height = 0\n\n            for lineno in range(ui_content.cursor_position.y - 1, -1, -1):\n                used_height += ui_content.get_height_for_line(lineno, width)\n\n                if used_height > scroll_offsets_top:\n                    return prev_lineno\n                else:\n                    prev_lineno = lineno\n            return prev_lineno\n\n        def get_topmost_visible():\n            \"\"\"\n            Calculate the upper most line that can be visible, while the bottom\n            is still visible. We should not allow scroll more than this if\n            `allow_scroll_beyond_bottom` is false.\n            \"\"\"\n            prev_lineno = ui_content.line_count - 1\n            used_height = 0\n            for lineno in range(ui_content.line_count - 1, -1, -1):\n                used_height += ui_content.get_height_for_line(lineno, width)\n                if used_height > height:\n                    return prev_lineno\n                else:\n                    prev_lineno = lineno\n            return prev_lineno\n\n        # Scroll vertically. (Make sure that the whole line which contains the\n        # cursor is visible.\n        topmost_visible = get_topmost_visible()\n\n            # Note: the `min(topmost_visible, ...)` is to make sure that we\n            # don't require scrolling up because of the bottom scroll offset,\n            # when we are at the end of the document.\n        self.vertical_scroll = max(self.vertical_scroll, min(topmost_visible, get_min_vertical_scroll()))\n        self.vertical_scroll = min(self.vertical_scroll, get_max_vertical_scroll())\n\n        # Disallow scrolling beyond bottom?\n        if not self.allow_scroll_beyond_bottom(cli):\n            self.vertical_scroll = min(self.vertical_scroll, topmost_visible)", "response": "Scrolls the line when the cursor is at the bottom of the screen."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _scroll_without_linewrapping(self, ui_content, width, height, cli):\n        cursor_position = ui_content.cursor_position or Point(0, 0)\n\n        # Without line wrapping, we will never have to scroll vertically inside\n        # a single line.\n        self.vertical_scroll_2 = 0\n\n        if ui_content.line_count == 0:\n            self.vertical_scroll = 0\n            self.horizontal_scroll = 0\n            return\n        else:\n            current_line_text = token_list_to_text(ui_content.get_line(cursor_position.y))\n\n        def do_scroll(current_scroll, scroll_offset_start, scroll_offset_end,\n                      cursor_pos, window_size, content_size):\n            \" Scrolling algorithm. Used for both horizontal and vertical scrolling. \"\n            # Calculate the scroll offset to apply.\n            # This can obviously never be more than have the screen size. Also, when the\n            # cursor appears at the top or bottom, we don't apply the offset.\n            scroll_offset_start = int(min(scroll_offset_start, window_size / 2, cursor_pos))\n            scroll_offset_end = int(min(scroll_offset_end, window_size / 2,\n                                        content_size - 1 - cursor_pos))\n\n            # Prevent negative scroll offsets.\n            if current_scroll < 0:\n                current_scroll = 0\n\n            # Scroll back if we scrolled to much and there's still space to show more of the document.\n            if (not self.allow_scroll_beyond_bottom(cli) and\n                    current_scroll > content_size - window_size):\n                current_scroll = max(0, content_size - window_size)\n\n            # Scroll up if cursor is before visible part.\n            if current_scroll > cursor_pos - scroll_offset_start:\n                current_scroll = max(0, cursor_pos - scroll_offset_start)\n\n            # Scroll down if cursor is after visible part.\n            if current_scroll < (cursor_pos + 1) - window_size + scroll_offset_end:\n                current_scroll = (cursor_pos + 1) - window_size + scroll_offset_end\n\n            return current_scroll\n\n        # When a preferred scroll is given, take that first into account.\n        if self.get_vertical_scroll:\n            self.vertical_scroll = self.get_vertical_scroll(self)\n            assert isinstance(self.vertical_scroll, int)\n        if self.get_horizontal_scroll:\n            self.horizontal_scroll = self.get_horizontal_scroll(self)\n            assert isinstance(self.horizontal_scroll, int)\n\n        # Update horizontal/vertical scroll to make sure that the cursor\n        # remains visible.\n        offsets = self.scroll_offsets\n\n        self.vertical_scroll = do_scroll(\n            current_scroll=self.vertical_scroll,\n            scroll_offset_start=offsets.top,\n            scroll_offset_end=offsets.bottom,\n            cursor_pos=ui_content.cursor_position.y,\n            window_size=height,\n            content_size=ui_content.line_count)\n\n        self.horizontal_scroll = do_scroll(\n            current_scroll=self.horizontal_scroll,\n            scroll_offset_start=offsets.left,\n            scroll_offset_end=offsets.right,\n            cursor_pos=get_cwidth(current_line_text[:ui_content.cursor_position.x]),\n            window_size=width,\n            # We can only analyse the current line. Calculating the width off\n            # all the lines is too expensive.\n            content_size=max(get_cwidth(current_line_text), self.horizontal_scroll + width))", "response": "Scrolls the content of the current line with line wrapping."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _mouse_handler(self, cli, mouse_event):\n        if mouse_event.event_type == MouseEventType.SCROLL_DOWN:\n            self._scroll_down(cli)\n        elif mouse_event.event_type == MouseEventType.SCROLL_UP:\n            self._scroll_up(cli)", "response": "Mouse handler. Called when the UI control doesn t handle this ArcGIS event."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, key_vals=None, overwrite=True):\n        if not key_vals:\n            return\n        write_items = self._update(key_vals, overwrite)\n        self._root._root_set(self._path, write_items)\n        self._root._write(commit=True)", "response": "Update the cache with the given key - values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding a dict encoded by Summary. _encode", "response": "def _decode(self, path, json_value):\n        \"\"\"Decode a `dict` encoded by `Summary._encode()`, loading h5 objects.\n\n        h5 objects may be very large, so we won't have loaded them automatically.\n        \"\"\"\n        if isinstance(json_value, dict):\n            if json_value.get(\"_type\") in H5_TYPES:\n                return self.read_h5(path, json_value)\n            elif json_value.get(\"_type\") == 'data-frame':\n                wandb.termerror(\n                    'This data frame was saved via the wandb data API. Contact support@wandb.com for help.')\n                return None\n            # TODO: transform wandb objects and plots\n            else:\n                return SummarySubDict(self, path)\n        else:\n            return json_value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _encode(self, value, path_from_root):\n\n        # Constructs a new `dict` tree in `json_value` that discards and/or\n        # encodes objects that aren't JSON serializable.\n\n        if isinstance(value, dict):\n            json_value = {}\n            for key, value in six.iteritems(value):\n                json_value[key] = self._encode(value, path_from_root + (key,))\n            return json_value\n        else:\n            path = \".\".join(path_from_root)\n            if util.is_pandas_data_frame(value):\n                return util.encode_data_frame(path, value, self._run)\n            else:\n                friendly_value, converted = util.json_friendly(data_types.val_to_json(path, value))\n                json_value, compressed = util.maybe_compress_summary(friendly_value, util.get_h5_typename(value))\n                if compressed:\n                    self.write_h5(path_from_root, friendly_value)\n\n                return json_value\n        \"\"\"\n            if isinstance(value, dict):\n                json_child[key], converted = util.json_friendly(\n                    self._encode(value, path_from_root + [key]))\n            else:\n        \"\"\"", "response": "Normalize compress and encode sub - objects for backend storage."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscrolls the cursor forward.", "response": "def scroll_forward(event, half=False):\n    \"\"\"\n    Scroll window down.\n    \"\"\"\n    w = _current_window_for_event(event)\n    b = event.cli.current_buffer\n\n    if w and w.render_info:\n        info = w.render_info\n        ui_content = info.ui_content\n\n        # Height to scroll.\n        scroll_height = info.window_height\n        if half:\n            scroll_height //= 2\n\n        # Calculate how many lines is equivalent to that vertical space.\n        y = b.document.cursor_position_row + 1\n        height = 0\n        while y < ui_content.line_count:\n            line_height = info.get_height_for_line(y)\n\n            if height + line_height < scroll_height:\n                height += line_height\n                y += 1\n            else:\n                break\n\n        b.cursor_position = b.document.translate_row_col_to_index(y, 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scroll_one_line_down(event):\n    w = find_window_for_buffer_name(event.cli, event.cli.current_buffer_name)\n    b = event.cli.current_buffer\n\n    if w:\n        # When the cursor is at the top, move to the next line. (Otherwise, only scroll.)\n        if w.render_info:\n            info = w.render_info\n\n            if w.vertical_scroll < info.content_height - info.window_height:\n                if info.cursor_position.y <= info.configured_scroll_offsets.top:\n                    b.cursor_position += b.document.get_cursor_down_position()\n\n                w.vertical_scroll += 1", "response": "Scroll one line down in the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nscrolls the cursor up one line.", "response": "def scroll_one_line_up(event):\n    \"\"\"\n    scroll_offset -= 1\n    \"\"\"\n    w = find_window_for_buffer_name(event.cli, event.cli.current_buffer_name)\n    b = event.cli.current_buffer\n\n    if w:\n        # When the cursor is at the bottom, move to the previous line. (Otherwise, only scroll.)\n        if w.render_info:\n            info = w.render_info\n\n            if w.vertical_scroll > 0:\n                first_line_height = info.get_height_for_line(info.first_visible_line())\n\n                cursor_up = info.cursor_position.y - (info.window_height - 1 - first_line_height -\n                                                      info.configured_scroll_offsets.bottom)\n\n                # Move cursor up, as many steps as the height of the first line.\n                # TODO: not entirely correct yet, in case of line wrapping and many long lines.\n                for _ in range(max(0, cursor_up)):\n                    b.cursor_position += b.document.get_cursor_up_position()\n\n                # Scroll window\n                w.vertical_scroll -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scroll_page_down(event):\n    w = _current_window_for_event(event)\n    b = event.cli.current_buffer\n\n    if w and w.render_info:\n        # Scroll down one page.\n        line_index = max(w.render_info.last_visible_line(), w.vertical_scroll + 1)\n        w.vertical_scroll = line_index\n\n        b.cursor_position = b.document.translate_row_col_to_index(line_index, 0)\n        b.cursor_position += b.document.get_start_of_line_position(after_whitespace=True)", "response": "Scroll page down. (Prefer the cursor at the top of the page, after scrolling.)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nscroll page up. (Prefer the cursor at the bottom of the page, after scrolling.)", "response": "def scroll_page_up(event):\n    \"\"\"\n    Scroll page up. (Prefer the cursor at the bottom of the page, after scrolling.)\n    \"\"\"\n    w = _current_window_for_event(event)\n    b = event.cli.current_buffer\n\n    if w and w.render_info:\n        # Put cursor at the first visible line. (But make sure that the cursor\n        # moves at least one line up.)\n        line_index = max(0, min(w.render_info.first_visible_line(),\n                                b.document.cursor_position_row - 1))\n\n        b.cursor_position = b.document.translate_row_col_to_index(line_index, 0)\n        b.cursor_position += b.document.get_start_of_line_position(after_whitespace=True)\n\n        # Set the scroll offset. We can safely set it to zero; the Window will\n        # make sure that it scrolls at least until the cursor becomes visible.\n        w.vertical_scroll = 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _trim_text(text, max_width):\n    width = get_cwidth(text)\n\n    # When the text is too wide, trim it.\n    if width > max_width:\n        # When there are no double width characters, just use slice operation.\n        if len(text) == width:\n            trimmed_text = (text[:max(1, max_width-3)] + '...')[:max_width]\n            return trimmed_text, len(trimmed_text)\n\n        # Otherwise, loop until we have the desired width. (Rather\n        # inefficient, but ok for now.)\n        else:\n            trimmed_text = ''\n            for c in text:\n                if get_cwidth(trimmed_text + c) <= max_width - 3:\n                    trimmed_text += c\n            trimmed_text += '...'\n\n            return (trimmed_text, get_cwidth(trimmed_text))\n    else:\n        return text, width", "response": "Trim the text to max_width appends dots when the text is too long."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_content(self, cli, width, height):\n        complete_state = cli.current_buffer.complete_state\n        if complete_state:\n            completions = complete_state.current_completions\n            index = complete_state.complete_index  # Can be None!\n\n            # Calculate width of completions menu.\n            menu_width = self._get_menu_width(width, complete_state)\n            menu_meta_width = self._get_menu_meta_width(width - menu_width, complete_state)\n            show_meta = self._show_meta(complete_state)\n\n            def get_line(i):\n                c = completions[i]\n                is_current_completion = (i == index)\n                result = self._get_menu_item_tokens(c, is_current_completion, menu_width)\n\n                if show_meta:\n                    result += self._get_menu_item_meta_tokens(c, is_current_completion, menu_meta_width)\n                return result\n\n            return UIContent(get_line=get_line,\n                             cursor_position=Point(x=0, y=index or 0),\n                             line_count=len(completions),\n                             default_char=Char(' ', self.token))\n\n        return UIContent()", "response": "Create a UIContent object for this control."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the width of the main column.", "response": "def _get_menu_width(self, max_width, complete_state):\n        \"\"\"\n        Return the width of the main column.\n        \"\"\"\n        return min(max_width, max(self.MIN_WIDTH, max(get_cwidth(c.display)\n                   for c in complete_state.current_completions) + 2))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_menu_meta_width(self, max_width, complete_state):\n        if self._show_meta(complete_state):\n            return min(max_width, max(get_cwidth(c.display_meta)\n                       for c in complete_state.current_completions) + 2)\n        else:\n            return 0", "response": "Return the width of the meta column."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mouse_handler(self, cli, mouse_event):\n        b = cli.current_buffer\n\n        if mouse_event.event_type == MouseEventType.MOUSE_UP:\n            # Select completion.\n            b.go_to_completion(mouse_event.position.y)\n            b.complete_state = None\n\n        elif mouse_event.event_type == MouseEventType.SCROLL_DOWN:\n            # Scroll up.\n            b.complete_next(count=3, disable_wrap_around=True)\n\n        elif mouse_event.event_type == MouseEventType.SCROLL_UP:\n            # Scroll down.\n            b.complete_previous(count=3, disable_wrap_around=True)", "response": "Handle mouse events: clicking and scrolling."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preferred_width(self, cli, max_available_width):\n        complete_state = cli.current_buffer.complete_state\n        column_width = self._get_column_width(complete_state)\n        result = int(column_width * math.ceil(len(complete_state.current_completions) / float(self.min_rows)))\n\n        # When the desired width is still more than the maximum available,\n        # reduce by removing columns until we are less than the available\n        # width.\n        while result > column_width and result > max_available_width - self._required_margin:\n            result -= column_width\n        return result + self._required_margin", "response": "Returns the preferred width of the current complete table entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef preferred_height(self, cli, width, max_available_height, wrap_lines):\n        complete_state = cli.current_buffer.complete_state\n        column_width = self._get_column_width(complete_state)\n        column_count = max(1, (width - self._required_margin) // column_width)\n\n        return int(math.ceil(len(complete_state.current_completions) / float(column_count)))", "response": "Returns the preferred height of the completions in the current column."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_content(self, cli, width, height):\n        complete_state = cli.current_buffer.complete_state\n        column_width = self._get_column_width(complete_state)\n        self._render_pos_to_completion = {}\n\n        def grouper(n, iterable, fillvalue=None):\n            \" grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx \"\n            args = [iter(iterable)] * n\n            return zip_longest(fillvalue=fillvalue, *args)\n\n        def is_current_completion(completion):\n            \" Returns True when this completion is the currently selected one. \"\n            return complete_state.complete_index is not None and c == complete_state.current_completion\n\n        # Space required outside of the regular columns, for displaying the\n        # left and right arrow.\n        HORIZONTAL_MARGIN_REQUIRED = 3\n\n        if complete_state:\n            # There should be at least one column, but it cannot be wider than\n            # the available width.\n            column_width = min(width - HORIZONTAL_MARGIN_REQUIRED, column_width)\n\n            # However, when the columns tend to be very wide, because there are\n            # some very wide entries, shrink it anyway.\n            if column_width > self.suggested_max_column_width:\n                # `column_width` can still be bigger that `suggested_max_column_width`,\n                # but if there is place for two columns, we divide by two.\n                column_width //= (column_width // self.suggested_max_column_width)\n\n            visible_columns = max(1, (width - self._required_margin) // column_width)\n\n            columns_ = list(grouper(height, complete_state.current_completions))\n            rows_ = list(zip(*columns_))\n\n            # Make sure the current completion is always visible: update scroll offset.\n            selected_column = (complete_state.complete_index or 0) // height\n            self.scroll = min(selected_column, max(self.scroll, selected_column - visible_columns + 1))\n\n            render_left_arrow = self.scroll > 0\n            render_right_arrow = self.scroll < len(rows_[0]) - visible_columns\n\n            # Write completions to screen.\n            tokens_for_line = []\n\n            for row_index, row in enumerate(rows_):\n                tokens = []\n                middle_row = row_index == len(rows_) // 2\n\n                # Draw left arrow if we have hidden completions on the left.\n                if render_left_arrow:\n                    tokens += [(Token.Scrollbar, '<' if middle_row else ' ')]\n\n                # Draw row content.\n                for column_index, c in enumerate(row[self.scroll:][:visible_columns]):\n                    if c is not None:\n                        tokens += self._get_menu_item_tokens(c, is_current_completion(c), column_width)\n\n                        # Remember render position for mouse click handler.\n                        for x in range(column_width):\n                            self._render_pos_to_completion[(column_index * column_width + x, row_index)] = c\n                    else:\n                        tokens += [(self.token.Completion, ' ' * column_width)]\n\n                # Draw trailing padding. (_get_menu_item_tokens only returns padding on the left.)\n                tokens += [(self.token.Completion, ' ')]\n\n                # Draw right arrow if we have hidden completions on the right.\n                if render_right_arrow:\n                    tokens += [(Token.Scrollbar, '>' if middle_row else ' ')]\n\n                # Newline.\n                tokens_for_line.append(tokens)\n\n        else:\n            tokens = []\n\n        self._rendered_rows = height\n        self._rendered_columns = visible_columns\n        self._total_columns = len(columns_)\n        self._render_left_arrow = render_left_arrow\n        self._render_right_arrow = render_right_arrow\n        self._render_width = column_width * visible_columns + render_left_arrow + render_right_arrow + 1\n\n        def get_line(i):\n            return tokens_for_line[i]\n\n        return UIContent(get_line=get_line, line_count=len(rows_))", "response": "Create a UIContent object for this menu."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_column_width(self, complete_state):\n        return max(get_cwidth(c.display) for c in complete_state.current_completions) + 1", "response": "Return the width of each column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle scoll and click events.", "response": "def mouse_handler(self, cli, mouse_event):\n        \"\"\"\n        Handle scoll and click events.\n        \"\"\"\n        b = cli.current_buffer\n\n        def scroll_left():\n            b.complete_previous(count=self._rendered_rows, disable_wrap_around=True)\n            self.scroll = max(0, self.scroll - 1)\n\n        def scroll_right():\n            b.complete_next(count=self._rendered_rows, disable_wrap_around=True)\n            self.scroll = min(self._total_columns - self._rendered_columns, self.scroll + 1)\n\n        if mouse_event.event_type == MouseEventType.SCROLL_DOWN:\n            scroll_right()\n\n        elif mouse_event.event_type == MouseEventType.SCROLL_UP:\n            scroll_left()\n\n        elif mouse_event.event_type == MouseEventType.MOUSE_UP:\n            x = mouse_event.position.x\n            y = mouse_event.position.y\n\n            # Mouse click on left arrow.\n            if x == 0:\n                if self._render_left_arrow:\n                    scroll_left()\n\n            # Mouse click on right arrow.\n            elif x == self._render_width - 1:\n                if self._render_right_arrow:\n                    scroll_right()\n\n            # Mouse click on completion.\n            else:\n                completion = self._render_pos_to_completion.get((x, y))\n                if completion:\n                    b.apply_completion(completion)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preferred_width(self, cli, max_available_width):\n        if cli.current_buffer.complete_state:\n            state = cli.current_buffer.complete_state\n            return 2 + max(get_cwidth(c.display_meta) for c in state.current_completions)\n        else:\n            return 0", "response": "Report the preferred width of the longest meta text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split_token_in_parts(token):\n    result = []\n    current = []\n    for part in token + (':', ):\n        if part == ':':\n            if current:\n                result.append(tuple(current))\n                current = []\n        else:\n            current.append(part)\n\n    return result", "response": "Takes a Token and turns it into a list of tokens by splitting it on colon."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking a list of Attrs instances and merges them into one.", "response": "def merge_attrs(list_of_attrs):\n    \"\"\"\n    Take a list of :class:`.Attrs` instances and merge them into one.\n    Every `Attr` in the list can override the styling of the previous one.\n    \"\"\"\n    result = DEFAULT_ATTRS\n\n    for attr in list_of_attrs:\n        result = Attrs(\n            color=attr.color or result.color,\n            bgcolor=attr.bgcolor or result.bgcolor,\n            bold=attr.bold or result.bold,\n            underline=attr.underline or result.underline,\n            italic=attr.italic or result.italic,\n            blink=attr.blink or result.blink,\n            reverse=attr.reverse or result.reverse)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset(self):\n        self.counter += 1\n        local_counter = self.counter\n\n        def timer_timeout():\n            if self.counter == local_counter and self.running:\n                self.callback()\n\n        self.loop.call_later(self.timeout, timer_timeout)", "response": "Reset the timeout. Starts a new timer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vendor_import(name):\n    parent_dir = os.path.abspath(os.path.dirname(__file__))\n    vendor_dir = os.path.join(parent_dir, 'vendor')\n\n    sys.path.insert(1, vendor_dir)\n    return import_module(name)", "response": "This enables us to use the vendor directory for packages we don t depend on"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_module(name, required=None):\n    if name not in _not_importable:\n        try:\n            return import_module(name)\n        except ImportError:\n            _not_importable.add(name)\n            if required:\n                raise ValueError(required)\n        except Exception as e:\n            _not_importable.add(name)\n            msg = \"Error importing optional module {}\".format(name)\n            logger.exception(msg)", "response": "Returns the module or None if the module is not found."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ensure_matplotlib_figure(obj):\n    import matplotlib\n    from matplotlib.figure import Figure\n    if obj == matplotlib.pyplot:\n        obj = obj.gcf()\n    elif not isinstance(obj, Figure):\n        if hasattr(obj, \"figure\"):\n            obj = obj.figure\n            # Some matplotlib objects have a figure function\n            if not isinstance(obj, Figure):\n                raise ValueError(\n                    \"Only matplotlib.pyplot or matplotlib.pyplot.Figure objects are accepted.\")\n    if not obj.gca().has_data():\n        raise ValueError(\n            \"You attempted to log an empty plot, pass a figure directly or ensure the global plot isn't closed.\")\n    return obj", "response": "Return the current figure from a matplotlib object or return the object if it s a figure."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef json_friendly(obj):\n    converted = True\n    typename = get_full_typename(obj)\n\n    if is_tf_tensor_typename(typename):\n        obj = obj.eval()\n    elif is_pytorch_tensor_typename(typename):\n        try:\n            if obj.requires_grad:\n                obj = obj.detach()\n        except AttributeError:\n            pass  # before 0.4 is only present on variables\n\n        try:\n            obj = obj.data\n        except RuntimeError:\n            pass  # happens for Tensors before 0.4\n\n        if obj.size():\n            obj = obj.numpy()\n        else:\n            return obj.item(), True\n\n    if np and isinstance(obj, np.ndarray):\n        if obj.size == 1:\n            obj = obj.flatten()[0]\n        elif obj.size <= 32:\n            obj = obj.tolist()\n    elif np and isinstance(obj, np.generic):\n        obj = obj.item()\n    elif isinstance(obj, bytes):\n        obj = obj.decode('utf-8')\n    elif isinstance(obj, (datetime, date)):\n        obj = obj.isoformat()\n    else:\n        converted = False\n    if getsizeof(obj) > VALUE_BYTES_LIMIT:\n        logger.warning(\"Object %s is %i bytes\", obj, getsizeof(obj))\n\n    return obj, converted", "response": "Convert an object into something that s more becoming of JSON"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef launch_browser(attempt_launch_browser=True):\n    _DISPLAY_VARIABLES = ['DISPLAY', 'WAYLAND_DISPLAY', 'MIR_SOCKET']\n    _WEBBROWSER_NAMES_BLACKLIST = [\n        'www-browser', 'lynx', 'links', 'elinks', 'w3m']\n\n    import webbrowser\n\n    launch_browser = attempt_launch_browser\n    if launch_browser:\n        if ('linux' in sys.platform and\n                not any(os.getenv(var) for var in _DISPLAY_VARIABLES)):\n            launch_browser = False\n        try:\n            browser = webbrowser.get()\n            if (hasattr(browser, 'name')\n                    and browser.name in _WEBBROWSER_NAMES_BLACKLIST):\n                launch_browser = False\n        except webbrowser.Error:\n            launch_browser = False\n\n    return launch_browser", "response": "Decide if we should launch a browser"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_tfjob_config():\n    if os.getenv(\"TF_CONFIG\"):\n        try:\n            return json.loads(os.environ[\"TF_CONFIG\"])\n        except ValueError:\n            return False\n    else:\n        return False", "response": "Attempts to parse TFJob config returning False if it can t find it"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_sm_config():\n    sagemaker_config = \"/opt/ml/input/config/hyperparameters.json\"\n    if os.path.exists(sagemaker_config):\n        conf = {}\n        conf[\"sagemaker_training_job_name\"] = os.getenv('TRAINING_JOB_NAME')\n        # Hyper-parameter searchs quote configs...\n        for k, v in six.iteritems(json.load(open(sagemaker_config))):\n            cast = v.strip('\"')\n            if os.getenv(\"WANDB_API_KEY\") is None and k == \"wandb_api_key\":\n                os.environ[\"WANDB_API_KEY\"] = cast\n            else:\n                if re.match(r'^[-\\d]+$', cast):\n                    cast = int(cast)\n                elif re.match(r'^[-.\\d]+$', cast):\n                    cast = float(cast)\n                conf[k] = cast\n        return conf\n    else:\n        return False", "response": "Attempts to parse SageMaker configuration returning False if it can t find it"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencode a Pandas DataFrame into the JSON format.", "response": "def encode_data_frame(name, df, run):\n    \"\"\"Encode a Pandas DataFrame into the JSON/backend format.\n\n    Writes the data to a file and returns a dictionary that we use to represent\n    it in `Summary`'s.\n\n    Arguments:\n        name (str): Name of the DataFrame, eg. the summary key in which it's\n            stored. This is for convenience, so people exploring the\n            directory tree can have some idea of what is in the Parquet files.\n        df (pandas.DataFrame): The DataFrame. Must not have columns named\n            \"wandb_run_id\" or \"wandb_data_frame_id\". They will be added to the\n            DataFrame here.\n        run (wandb_run.Run): The Run the DataFrame is associated with. We need\n            this because the information we store on the DataFrame is derived\n            from the Run it's in.\n\n    Returns:\n        A dict representing the DataFrame that we can store in summaries or\n        histories. This is the format:\n        {\n            '_type': 'data-frame',\n                # Magic field that indicates that this object is a data frame as\n                # opposed to a normal dictionary or anything else.\n            'id': 'asdf',\n                # ID for the data frame that is unique to this Run.\n            'format': 'parquet',\n                # The file format in which the data frame is stored. Currently can\n                # only be Parquet.\n            'current_project_name': 'wfeas',\n                # (Current) name of the project that this Run is in. It'd be\n                # better to store the project's ID because we know it'll never\n                # change but we don't have that here. We store this just in\n                # case because we use the project name in identifiers on the\n                # backend.\n            'path': 'media/data_frames/sdlk.parquet',\n                # Path to the Parquet file in the Run directory.\n        }\n    \"\"\"\n    pandas = get_module(\"pandas\")\n    fastparquet = get_module(\"fastparquet\")\n    if not pandas or not fastparquet:\n        raise wandb.Error(\n            \"Failed to save data frame: unable to import either pandas or fastparquet.\")\n\n    data_frame_id = generate_id()\n\n    # We have to call this wandb_run_id because that name is treated specially by\n    # our filtering code\n    df['wandb_run_id'] = pandas.Series(\n        [six.text_type(run.name)] * len(df.index), index=df.index)\n\n    df['wandb_data_frame_id'] = pandas.Series(\n        [six.text_type(data_frame_id)] * len(df.index), index=df.index)\n    frames_dir = os.path.join(run.dir, DATA_FRAMES_SUBDIR)\n    mkdir_exists_ok(frames_dir)\n    path = os.path.join(frames_dir, '{}-{}.parquet'.format(name, data_frame_id))\n    fastparquet.write(path, df)\n\n    return {\n        'id': data_frame_id,\n        '_type': 'data-frame',\n        'format': 'parquet',\n        'current_project_name': run.project_name(),  # we don't have the project ID here\n        'path': path,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd our host and key to. netrc", "response": "def write_netrc(host, entity, key):\n    \"\"\"Add our host and key to .netrc\"\"\"\n    if len(key) != 40:\n        click.secho(\n            'API-key must be exactly 40 characters long: {} ({} chars)'.format(key, len(key)))\n        return None\n    try:\n        normalized_host = host.split(\"/\")[-1].split(\":\")[0]\n        print(\"Appending key for %s to your netrc file: %s\" %\n              (normalized_host, os.path.expanduser('~/.netrc')))\n        machine_line = 'machine %s' % normalized_host\n        path = os.path.expanduser('~/.netrc')\n        orig_lines = None\n        try:\n            with open(path) as f:\n                orig_lines = f.read().strip().split('\\n')\n        except (IOError, OSError) as e:\n            pass\n        with open(path, 'w') as f:\n            if orig_lines:\n                # delete this machine from the file if it's already there.\n                skip = 0\n                for line in orig_lines:\n                    if machine_line in line:\n                        skip = 2\n                    elif skip:\n                        skip -= 1\n                    else:\n                        f.write('%s\\n' % line)\n            f.write(textwrap.dedent(\"\"\"\\\n            machine {host}\n              login {entity}\n              password {key}\n            \"\"\").format(host=normalized_host, entity=entity, key=key))\n        os.chmod(os.path.expanduser('~/.netrc'),\n                 stat.S_IRUSR | stat.S_IWUSR)\n        return True\n    except IOError as e:\n        click.secho(\"Unable to read ~/.netrc\", fg=\"red\")\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef request_with_retry(func, *args, **kwargs):\n    max_retries = kwargs.pop('max_retries', 30)\n    sleep = 2\n    retry_count = 0\n    while True:\n        try:\n            response = func(*args, **kwargs)\n            response.raise_for_status()\n            return response\n        except (requests.exceptions.ConnectionError,\n                requests.exceptions.HTTPError,  # XXX 500s aren't retryable\n                requests.exceptions.Timeout) as e:\n            if retry_count == max_retries:\n                return e\n            retry_count += 1\n            delay = sleep + random.random() * 0.25 * sleep\n            if isinstance(e, requests.exceptions.HTTPError) and e.response.status_code == 429:\n                logger.info(\n                    \"Rate limit exceeded, retrying in %s seconds\" % delay)\n            else:\n                logger.warning('requests_with_retry encountered retryable exception: %s. args: %s, kwargs: %s',\n                               e, args, kwargs)\n            time.sleep(delay)\n            sleep *= 2\n            if sleep > MAX_SLEEP_SECONDS:\n                sleep = MAX_SLEEP_SECONDS\n        except requests.exceptions.RequestException as e:\n            logger.error(response.json()['error'])  # XXX clean this up\n            logger.exception(\n                'requests_with_retry encountered unretryable exception: %s', e)\n            return e", "response": "Perform a requests http call retrying with exponential backoff."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding a command that will run the specified program.", "response": "def find_runner(program):\n    \"\"\"Return a command that will run program.\n\n    Args:\n        program: The string name of the program to try to run.\n    Returns:\n        commandline list of strings to run the program (eg. with subprocess.call()) or None\n    \"\"\"\n    if os.path.isfile(program) and not os.access(program, os.X_OK):\n        # program is a path to a non-executable file\n        try:\n            opened = open(program)\n        except PermissionError:\n            return None\n        first_line = opened.readline().strip()\n        if first_line.startswith('#!'):\n            return shlex.split(first_line[2:])\n        if program.endswith('.py'):\n            return [sys.executable]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef downsample(values, target_length):\n    assert target_length > 1\n    values = list(values)\n    if len(values) < target_length:\n        return values\n    ratio = float(len(values) - 1) / (target_length - 1)\n    result = []\n    for i in range(target_length):\n        result.append(values[int(i * ratio)])\n    return result", "response": "Downsamples 1d values to target_length including start and end."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef image_from_docker_args(args):\n    bool_args = [\"-t\", \"--tty\", \"--rm\",\"--privileged\", \"--oom-kill-disable\",\"--no-healthcheck\", \"-i\",\n        \"--interactive\", \"--init\", \"--help\", \"--detach\", \"-d\", \"--sig-proxy\", \"-it\", \"-itd\"]\n    last_flag = -2\n    last_arg = \"\"\n    possible_images = []\n    if len(args) > 0 and args[0] == \"run\":\n        args.pop(0)\n    for i, arg in enumerate(args):\n        if arg.startswith(\"-\"):\n            last_flag = i\n            last_arg = arg\n        elif \"@sha256:\" in arg:\n            # Because our regex doesn't match digests\n            possible_images.append(arg)\n        elif docker_image_regex(arg):\n            if last_flag == i - 2:\n                possible_images.append(arg)\n            elif \"=\" in last_arg:\n                possible_images.append(arg)\n            elif last_arg in bool_args and last_flag == i - 1:\n                possible_images.append(arg)\n    most_likely = None\n    for img in possible_images:\n        if \":\" in img or \"@\" in img or \"/\" in img:\n            most_likely = img\n            break\n    if most_likely == None and len(possible_images) > 0:\n        most_likely = possible_images[0]\n    return most_likely", "response": "This function scans the given list of docker image arguments and tries to find the most likely docker image argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a YAML file.", "response": "def load_yaml(file):\n    \"\"\"If pyyaml > 5.1 use full_load to avoid warning\"\"\"\n    if hasattr(yaml, \"full_load\"):\n        return yaml.full_load(file)\n    else:\n        return yaml.load(file)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nping the kubernetes metadata service for the image id", "response": "def image_id_from_k8s():\n    \"\"\"Pings the k8s metadata service for the image id\"\"\"\n    token_path = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n    if os.path.exists(token_path):\n        k8s_server = \"https://{}:{}/api/v1/namespaces/default/pods/{}\".format(\n            os.getenv(\"KUBERNETES_SERVICE_HOST\"), os.getenv(\n                \"KUBERNETES_PORT_443_TCP_PORT\"), os.getenv(\"HOSTNAME\")\n        )\n        try:\n            res = requests.get(k8s_server, verify=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\",\n                               timeout=3, headers={\"Authorization\": \"Bearer {}\".format(open(token_path).read())})\n            res.raise_for_status()\n        except requests.RequestException:\n            return None\n        try:\n            return res.json()[\"status\"][\"containerStatuses\"][0][\"imageID\"].strip(\"docker-pullable://\")\n        except (ValueError, KeyError, IndexError):\n            logger.exception(\"Error checking kubernetes for image id\")\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef async_call(target, timeout=None):\n    q = queue.Queue()\n    def wrapped_target(q, *args, **kwargs):\n        try:\n            q.put(target(*args, **kwargs))\n        except Exception as e:\n            q.put(e)\n\n    def wrapper(*args, **kwargs):\n        thread = threading.Thread(target=wrapped_target, args=(q,)+args, kwargs=kwargs)\n        thread.daemon = True\n        thread.start()\n        try:\n            result = q.get(True, timeout)\n            if isinstance(result, Exception):\n                six.reraise(type(result), result, sys.exc_info()[2])\n            return result, thread\n        except queue.Empty:\n            return None, thread\n    return wrapper", "response": "A wrapper for a method that blocks on the original and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a timevalue for interval comparisons When possible it is a monotonic clock to prevent backwards time issues.", "response": "def stopwatch_now():\n    \"\"\"Get a timevalue for interval comparisons\n\n    When possible it is a monotonic clock to prevent backwards time issues.\n    \"\"\"\n    if six.PY2:\n        now = time.time()\n    else:\n        now = time.monotonic()\n    return now"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the previous focussed : class :. Buffer or None.", "response": "def previous(self, cli):\n        \"\"\"\n        Return the previously focussed :class:`.Buffer` or `None`.\n        \"\"\"\n        if len(self.focus_stack) > 1:\n            try:\n                return self[self.focus_stack[-2]]\n            except KeyError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfocusing the buffer with the given name.", "response": "def focus(self, cli, buffer_name):\n        \"\"\"\n        Focus the buffer with the given name.\n        \"\"\"\n        assert isinstance(buffer_name, six.text_type)\n        self.focus_stack = [buffer_name]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef push_focus(self, cli, buffer_name):\n        assert isinstance(buffer_name, six.text_type)\n        self.focus_stack.append(buffer_name)", "response": "Push a new buffer on the focus stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop_focus(self, cli):\n        if len(self.focus_stack) > 1:\n            self.focus_stack.pop()\n        else:\n            raise IndexError('Cannot pop last item from the focus stack.')", "response": "Pop the last item from the focus stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalize_exceptions(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        message = \"Whoa, you found a bug.\"\n        try:\n            return func(*args, **kwargs)\n        except requests.HTTPError as err:\n            raise CommError(err.response, err)\n        except RetryError as err:\n            if \"response\" in dir(err.last_exception) and err.last_exception.response is not None:\n                try:\n                    message = err.last_exception.response.json().get(\n                        'errors', [{'message': message}])[0]['message']\n                except ValueError:\n                    message = err.last_exception.response.text\n            else:\n                message = err.last_exception\n\n            six.reraise(CommError, CommError(\n                message, err.last_exception), sys.exc_info()[2])\n        except Exception as err:\n            # gql raises server errors with dict's as strings...\n            if len(err.args) > 0:\n                payload = err.args[0]\n            else:\n                payload = err\n            if str(payload).startswith(\"{\"):\n                message = ast.literal_eval(str(payload))[\"message\"]\n            else:\n                message = str(err)\n            if wandb.env.is_debug():\n                six.reraise(*sys.exc_info())\n            else:\n                six.reraise(CommError, CommError(\n                    message, err), sys.exc_info()[2])\n    return wrapper", "response": "Decorator for catching common errors and re - raising as wandb. Error"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, size=-1):\n        bites = self.file.read(size)\n        self.bytes_read += len(bites)\n        self.callback(len(bites), self.bytes_read)\n        return bites", "response": "Read bytes and call the callback"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling watch method to log model topology gradients & weights", "response": "def on_train_begin(self, **kwargs):\n        \"Call watch method to log model topology, gradients & weights\"\n\n        # Set self.best, method inherited from \"TrackerCallback\" by \"SaveModelCallback\"\n        super().on_train_begin()\n\n        # Ensure we don't call \"watch\" multiple times\n        if not WandbCallback.watch_called:\n            WandbCallback.watch_called = True\n\n            # Logs model topology and optionally gradients and weights\n            wandb.watch(self.learn.model, log=self.log)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_epoch_end(self, epoch, smooth_loss, last_metrics, **kwargs):\n        \"Logs training loss, validation loss and custom metrics & log prediction samples & save model\"\n\n        if self.save_model:\n            # Adapted from fast.ai \"SaveModelCallback\"\n            current = self.get_monitor_value()\n            if current is not None and self.operator(current, self.best):\n                print(\n                    f'Better model found at epoch {epoch} with {self.monitor} value: {current}.'\n                )\n                self.best = current\n\n                # Section modified to save within wandb folder\n                with self.model_path.open('wb') as model_file:\n                    self.learn.save(model_file)\n\n        # Log sample predictions\n        if self.show_results:\n            self.learn.show_results()  # pyplot display of sample predictions\n            wandb.log({\"Prediction Samples\": plt}, commit=False)\n\n        # Log losses & metrics\n        # Adapted from fast.ai \"CSVLogger\"\n        logs = {\n            name: stat\n            for name, stat in list(\n                zip(self.learn.recorder.names, [epoch, smooth_loss] +\n                    last_metrics))[1:]\n        }\n        wandb.log(logs)\n\n        # We can now close results figure\n        if self.show_results:\n            plt.close('all')", "response": "Logs training loss validation loss and custom metrics & log prediction samples & save model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the best model.", "response": "def on_train_end(self, **kwargs):\n        \"Load the best model.\"\n\n        if self.save_model:\n            # Adapted from fast.ai \"SaveModelCallback\"\n            if self.model_path.is_file():\n                with self.model_path.open('rb') as model_file:\n                    self.learn.load(model_file, purge=False)\n                    print(f'Loaded best saved model from {self.model_path}')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stream(self, name):\n        if self.stream_name != \"default\":\n            raise ValueError(\"Nested streams aren't supported\")\n        if self._streams.get(name) == None:\n            self._streams[name] = History(self.fname, out_dir=self.out_dir,\n                                          add_callback=self._add_callback, stream_name=name)\n        return self._streams[name]", "response": "Returns a history object for the given name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, row={}, step=None):\n        if not isinstance(row, collections.Mapping):\n            raise wandb.Error('history.add expects dict-like object')\n\n        if step is None:\n            self.update(row)\n            if not self.batched:\n                self._write()\n        else:\n            if not isinstance(step, numbers.Integral):\n                raise wandb.Error(\n                    \"Step must be an integer, not {}\".format(step))\n            elif step < self._steps:\n                warnings.warn(\n                    \"Adding to old History rows isn't currently supported. Dropping.\", wandb.WandbWarning)\n                return\n            elif step == self._steps:\n                pass\n            elif self.batched:\n                raise wandb.Error(\n                    \"Can't log to a particular History step ({}) while in batched mode.\".format(step))\n            else:  # step > self._steps\n                self._write()\n                self._steps = step\n\n            self.update(row)", "response": "Adds or updates a history row."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, new_vals):\n        for k, v in six.iteritems(new_vals):\n            k = k.strip()\n            if k in self.row:\n                warnings.warn(\"Adding history key ({}) that is already set in this step\".format(\n                    k), wandb.WandbWarning)\n            self.row[k] = v", "response": "Update the row with a dictionary of values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a row to the internal list of rows without writing it to disk.", "response": "def _index(self, row):\n        \"\"\"Add a row to the internal list of rows without writing it to disk.\n\n        This function should keep the data structure consistent so it's usable\n        for both adding new rows, and loading pre-existing histories.\n        \"\"\"\n        self.rows.append(row)\n        self._keys.update(row.keys())\n        self._steps += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wandb_pty(resize=True):\n    master_fd, slave_fd = pty.openpty()\n    # raw mode so carriage returns etc. don't get added by the terminal driver,\n    # bash for windows blows up on this so we catch the error and do nothing\n    # TODO(adrian): (when) will this be called on windows?\n    try:\n        tty.setraw(master_fd)\n    except termios.error:\n        pass\n\n    if resize:\n        if SIGWINCH_HANDLER is not None:\n            SIGWINCH_HANDLER.add_fd(master_fd)\n\n    return master_fd, slave_fd", "response": "Get a PTY set to raw mode and register it with SIGWINCH_HANDLER."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef spawn_reader_writer(get_data_fn, put_data_fn):\n    def _reader_thread():\n        while True:\n            out = get_data_fn()\n            put_data_fn(out)\n            if not out:\n                # EOF.\n                # We've passed this on so things farther down the pipeline will\n                # know to shut down.\n                break\n\n    t = threading.Thread(target=_reader_thread)\n    t.daemon = True\n    t.start()\n    return t", "response": "Spawn a thread that reads from a data source and writes to a sink."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef restore(self):\n        # NOTE: dup2 makes `self._from_fd` inheritable unconditionally\n        self.redir_file.flush()\n        os.dup2(self.orig_file.fileno(), self._from_fd)", "response": "Restore self. redo_file to its original state."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef naws(self, data):\n        if len(data) == 4:\n            # NOTE: the first parameter of struct.unpack should be\n            # a 'str' object. Both on Py2/py3. This crashes on OSX\n            # otherwise.\n            columns, rows = struct.unpack(str('!HH'), data)\n            self.size_received_callback(rows, columns)\n        else:\n            logger.warning('Wrong number of NAWS bytes')", "response": "Reads NAWS bytes from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles negotiation of a set of keys.", "response": "def negotiate(self, data):\n        \"\"\"\n        Got negotiate data.\n        \"\"\"\n        command, payload = data[0:1], data[1:]\n        assert isinstance(command, bytes)\n\n        if command == NAWS:\n            self.naws(payload)\n        else:\n            logger.info('Negotiate (%r got bytes)', len(data))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a coroutine sequence.", "response": "def _parse_coroutine(self):\n        \"\"\"\n        Parser state machine.\n        Every 'yield' expression returns the next byte.\n        \"\"\"\n        while True:\n            d = yield\n\n            if d == int2byte(0):\n                pass  # NOP\n\n            # Go to state escaped.\n            elif d == IAC:\n                d2 = yield\n\n                if d2 == IAC:\n                    self.received_data(d2)\n\n                # Handle simple commands.\n                elif d2 in (NOP, DM, BRK, IP, AO, AYT, EC, EL, GA):\n                    self.command_received(d2, None)\n\n                # Handle IAC-[DO/DONT/WILL/WONT] commands.\n                elif d2 in (DO, DONT, WILL, WONT):\n                    d3 = yield\n                    self.command_received(d2, d3)\n\n                # Subnegotiation\n                elif d2 == SB:\n                    # Consume everything until next IAC-SE\n                    data = []\n\n                    while True:\n                        d3 = yield\n\n                        if d3 == IAC:\n                            d4 = yield\n                            if d4 == SE:\n                                break\n                            else:\n                                data.append(d4)\n                        else:\n                            data.append(d3)\n\n                    self.negotiate(b''.join(data))\n            else:\n                self.received_data(d)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfeeds data to the parser.", "response": "def feed(self, data):\n        \"\"\"\n        Feed data to the parser.\n        \"\"\"\n        assert isinstance(data, binary_type)\n        for b in iterbytes(data):\n            self._parser.send(int2byte(b))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_path(self, path):\n        run = self.settings['run']\n        project = self.settings['project']\n        username = self.settings['username']\n        parts = path.replace(\"/runs/\", \"/\").split(\"/\")\n        if \":\" in parts[-1]:\n            run = parts[-1].split(\":\")[-1]\n            parts[-1] = parts[-1].split(\":\")[0]\n        elif parts[-1]:\n            run = parts[-1]\n        if len(parts) > 1:\n            project = parts[1]\n            if username and run == project:\n                project = parts[0]\n            else:\n                username = parts[0]\n        else:\n            project = parts[0]\n        return (username, project, run)", "response": "Parses the path into the appropriate parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef runs(self, path=\"\", filters={}, order=\"-created_at\", per_page=None):\n        username, project, run = self._parse_path(path)\n        if not self._runs.get(path):\n            self._runs[path + str(filters) + str(order)] = Runs(self.client, username, project,\n                                                                filters=filters, order=order, per_page=per_page)\n        return self._runs[path + str(filters) + str(order)]", "response": "Return a set of runs from a project that match the filters provided."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, path=\"\"):\n        username, project, run = self._parse_path(path)\n        if not self._runs.get(path):\n            self._runs[path] = Run(self.client, username, project, run)\n        return self._runs[path]", "response": "Returns a run by parsing the path in the form username project run"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new run for the given project", "response": "def create(cls, api, run_id=None, project=None, username=None):\n        \"\"\"Create a run for the given project\"\"\"\n        run_id = run_id or util.generate_id()\n        project = project or api.settings.get(\"project\")\n        mutation = gql('''\n        mutation upsertRun($project: String, $entity: String, $name: String!) {\n            upsertBucket(input: {modelName: $project, entityName: $entity, name: $name}) {\n                bucket {\n                    project {\n                        name\n                        entity { name }\n                    }\n                    id\n                    name\n                }\n                inserted\n            }\n        }\n        ''')\n        variables = {'entity': username,\n                     'project': project, 'name': run_id}\n        res = api.client.execute(mutation, variable_values=variables)\n        res = res['upsertBucket']['bucket']\n        return Run(api.client, res[\"project\"][\"entity\"][\"name\"],  res[\"project\"][\"name\"], res[\"name\"], {\n            \"id\": res[\"id\"],\n            \"config\": \"{}\",\n            \"systemMetrics\": \"{}\",\n            \"summaryMetrics\": \"{}\",\n            \"tags\": [],\n            \"description\": None,\n            \"state\": \"running\"\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _exec(self, query, **kwargs):\n        variables = {'entity': self.username,\n                     'project': self.project, 'name': self.name}\n        variables.update(kwargs)\n        return self.client.execute(query, variable_values=variables)", "response": "Execute a query against the cloud backend"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning history metrics for a run", "response": "def history(self, samples=500, pandas=True, stream=\"default\"):\n        \"\"\"Return history metrics for a run\n\n        Args:\n            samples (int, optional): The number of samples to return\n            pandas (bool, optional): Return a pandas dataframe\n            stream (str, optional): \"default\" for metrics, \"system\" for machine metrics\n        \"\"\"\n        node = \"history\" if stream == \"default\" else \"events\"\n        query = gql('''\n        query Run($project: String!, $entity: String!, $name: String!, $samples: Int!) {\n            project(name: $project, entityName: $entity) {\n                run(name: $name) { %s(samples: $samples) }\n            }\n        }\n        ''' % node)\n\n        response = self._exec(query, samples=samples)\n        lines = [json.loads(line)\n                 for line in response['project']['run'][node]]\n        if pandas:\n            pandas = util.get_module(\"pandas\")\n            if pandas:\n                lines = pandas.DataFrame.from_records(lines)\n            else:\n                print(\"Unable to load pandas, call history with pandas=False\")\n        return lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_closest_ansi_color(r, g, b, exclude=()):\n    assert isinstance(exclude, tuple)\n\n    # When we have a bit of saturation, avoid the gray-like colors, otherwise,\n    # too often the distance to the gray color is less.\n    saturation = abs(r - g) + abs(g - b) + abs(b - r)  # Between 0..510\n\n    if saturation > 30:\n        exclude += ('ansilightgray', 'ansidarkgray', 'ansiwhite', 'ansiblack')\n\n    # Take the closest color.\n    # (Thanks to Pygments for this part.)\n    distance = 257*257*3  # \"infinity\" (>distance from #000000 to #ffffff)\n    match = 'ansidefault'\n\n    for name, (r2, g2, b2) in ANSI_COLORS_TO_RGB.items():\n        if name != 'ansidefault' and name not in exclude:\n            d = (r - r2) ** 2 + (g - g2) ** 2 + (b - b2) ** 2\n\n            if d < distance:\n                match = name\n                distance = d\n\n    return match", "response": "Find the closest ANSI color. Return it by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_size(fileno):\n    # Thanks to fabric (fabfile.org), and\n    # http://sqizit.bartletts.id.au/2011/02/14/pseudo-terminals-in-python/\n    \"\"\"\n    Get the size of this pseudo terminal.\n\n    :param fileno: stdout.fileno()\n    :returns: A (rows, cols) tuple.\n    \"\"\"\n    # Inline imports, because these modules are not available on Windows.\n    # (This file is used by ConEmuOutput, which is used on Windows.)\n    import fcntl\n    import termios\n\n    # Buffer for the C call\n    buf = array.array(b'h' if six.PY2 else u'h', [0, 0, 0, 0])\n\n    # Do TIOCGWINSZ (Get)\n    # Note: We should not pass 'True' as a fourth parameter to 'ioctl'. (True\n    #       is the default.) This causes segmentation faults on some systems.\n    #       See: https://github.com/jonathanslenders/python-prompt-toolkit/pull/364\n    fcntl.ioctl(fileno, termios.TIOCGWINSZ, buf)\n\n    # Return rows, cols\n    return buf[0], buf[1]", "response": "Get the size of the pseudo terminal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_code(self, value, exclude=()):\n        key = (value, exclude)\n        if key not in self:\n            self[key] = self._get(value, exclude)\n        return self[key]", "response": "Return a tuple of ansi_code ansi_name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nturn 'ffffff', into (0xff, 0xff, 0xff).", "response": "def _color_name_to_rgb(self, color):\n        \" Turn 'ffffff', into (0xff, 0xff, 0xff). \"\n        try:\n            rgb = int(color, 16)\n        except ValueError:\n            raise\n        else:\n            r = (rgb >> 16) & 0xff\n            g = (rgb >> 8) & 0xff\n            b = rgb & 0xff\n            return r, g, b"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a tuple with the vt100 values that represent this color.", "response": "def _colors_to_code(self, fg_color, bg_color):\n        \" Return a tuple with the vt100 values  that represent this color. \"\n        # When requesting ANSI colors only, and both fg/bg color were converted\n        # to ANSI, ensure that the foreground and background color are not the\n        # same. (Unless they were explicitely defined to be the same color.)\n        fg_ansi = [()]\n\n        def get(color, bg):\n            table = BG_ANSI_COLORS if bg else FG_ANSI_COLORS\n\n            if color is None:\n                return ()\n\n            # 16 ANSI colors. (Given by name.)\n            elif color in table:\n                return (table[color], )\n\n            # RGB colors. (Defined as 'ffffff'.)\n            else:\n                try:\n                    rgb = self._color_name_to_rgb(color)\n                except ValueError:\n                    return ()\n\n                # When only 16 colors are supported, use that.\n                if self.ansi_colors_only():\n                    if bg:  # Background.\n                        if fg_color != bg_color:\n                            exclude = (fg_ansi[0], )\n                        else:\n                            exclude = ()\n                        code, name = _16_bg_colors.get_code(rgb, exclude=exclude)\n                        return (code, )\n                    else:  # Foreground.\n                        code, name = _16_fg_colors.get_code(rgb)\n                        fg_ansi[0] = name\n                        return (code, )\n\n                # True colors. (Only when this feature is enabled.)\n                elif self.true_color:\n                    r, g, b = rgb\n                    return (48 if bg else 38, 2, r, g, b)\n\n                # 256 RGB colors.\n                else:\n                    return (48 if bg else 38, 5, _256_colors[rgb])\n\n        result = []\n        result.extend(get(fg_color, False))\n        result.extend(get(bg_color, True))\n\n        return map(six.text_type, result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an Output class from a pseudo terminal.", "response": "def from_pty(cls, stdout, true_color=False, ansi_colors_only=None, term=None):\n        \"\"\"\n        Create an Output class from a pseudo terminal.\n        (This will take the dimensions by reading the pseudo\n        terminal attributes.)\n        \"\"\"\n        assert stdout.isatty()\n        def get_size():\n            rows, columns = _get_size(stdout.fileno())\n            # If terminal (incorrectly) reports its size as 0, pick a reasonable default.\n            # See https://github.com/ipython/ipython/issues/10071\n            return Size(rows=(rows or 24), columns=(columns or 80))\n\n        return cls(stdout, get_size, true_color=true_color,\n                   ansi_colors_only=ansi_colors_only, term=term)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_attributes(self, attrs):\n        if self.true_color() and not self.ansi_colors_only():\n            self.write_raw(self._escape_code_cache_true_color[attrs])\n        else:\n            self.write_raw(self._escape_code_cache[attrs])", "response": "Create new style and output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite to output stream and flush.", "response": "def flush(self):\n        \"\"\"\n        Write to output stream and flush.\n        \"\"\"\n        if not self._buffer:\n            return\n\n        data = ''.join(self._buffer)\n\n        try:\n            # (We try to encode ourself, because that way we can replace\n            # characters that don't exist in the character set, avoiding\n            # UnicodeEncodeError crashes. E.g. u'\\xb7' does not appear in 'ascii'.)\n            # My Arch Linux installation of july 2015 reported 'ANSI_X3.4-1968'\n            # for sys.stdout.encoding in xterm.\n            if self.write_binary:\n                if hasattr(self.stdout, 'buffer'):\n                    out = self.stdout.buffer  # Py3.\n                else:\n                    out = self.stdout\n                out.write(data.encode(self.stdout.encoding or 'utf-8', 'replace'))\n            else:\n                self.stdout.write(data)\n\n            self.stdout.flush()\n        except IOError as e:\n            if e.args and e.args[0] == errno.EINTR:\n                # Interrupted system call. Can happpen in case of a window\n                # resize signal. (Just ignore. The resize handler will render\n                # again anyway.)\n                pass\n            elif e.args and e.args[0] == 0:\n                # This can happen when there is a lot of output and the user\n                # sends a KeyboardInterrupt by pressing Control-C. E.g. in\n                # a Python REPL when we execute \"while True: print('test')\".\n                # (The `ptpython` REPL uses this `Output` class instead of\n                # `stdout` directly -- in order to be network transparent.)\n                # So, just ignore.\n                pass\n            else:\n                raise\n\n        self._buffer = []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhooking into the torch model to collect gradients and the topology of the next backward pass.", "response": "def watch(models, criterion=None, log=\"gradients\", log_freq=100):\n    \"\"\"\n    Hooks into the torch model to collect gradients and the topology.  Should be extended\n    to accept arbitrary ML models.\n\n    :param (torch.Module) models: The model to hook, can be a tuple\n    :param (torch.F) criterion: An optional loss value being optimized\n    :param (str) log: One of \"gradients\", \"parameters\", \"all\", or None\n    :param (int) log_freq: log gradients and parameters every N batches\n    :return: (wandb.Graph) The graph object that will populate after the first backward pass\n    \"\"\"\n    global watch_called\n    if run is None:\n        raise ValueError(\n            \"You must call `wandb.init` before calling watch\")\n    if watch_called:\n        raise ValueError(\n            \"You can only call `wandb.watch` once per process. If you want to watch multiple models, pass them in as a tuple.\"\n        )\n    watch_called = True\n    log_parameters = False\n    log_gradients = True\n    if log == \"all\":\n        log_parameters = True\n    elif log == \"parameters\":\n        log_parameters = True\n        log_gradients = False\n    elif log is None:\n        log_gradients = False\n\n    if not isinstance(models, (tuple, list)):\n        models = (models,)\n    graphs = []\n    prefix = ''\n    for idx, model in enumerate(models):\n        if idx > 0:\n            prefix = \"graph_%i\" % idx\n\n        run.history.torch.add_log_hooks_to_pytorch_module(\n            model, log_parameters=log_parameters, log_gradients=log_gradients, prefix=prefix, log_freq=log_freq)\n\n        graph = wandb_torch.TorchGraph.hook_torch(model, criterion, graph_idx=idx)\n        graphs.append(graph)\n        # NOTE: the graph is set in run.summary by hook_torch on the backward pass\n    return graphs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the jupyter environment and start the run if it isn t already and creates a new run.", "response": "def _init_jupyter(run):\n    \"\"\"Asks for user input to configure the machine if it isn't already and creates a new run.\n    Log pushing and system stats don't start until `wandb.monitor()` is called.\n    \"\"\"\n    from wandb import jupyter\n    # TODO: Should we log to jupyter?\n    # global logging had to be disabled because it set the level to debug\n    # I also disabled run logging because we're rairly using it.\n    # try_to_set_up_global_logging()\n    # run.enable_logging()\n\n    api = InternalApi()\n    if not api.api_key:\n        termerror(\n            \"Not authenticated.  Copy a key from https://app.wandb.ai/profile?message=true\")\n        key = getpass.getpass(\"API Key: \").strip()\n        if len(key) == 40:\n            os.environ[env.API_KEY] = key\n            util.write_netrc(api.api_url, \"user\", key)\n        else:\n            raise ValueError(\"API Key must be 40 characters long\")\n        # Ensure our api client picks up the new key\n        api = InternalApi()\n    os.environ[\"WANDB_JUPYTER\"] = \"true\"\n    run.resume = \"allow\"\n    api.set_current_run_id(run.id)\n    print(\"W&B Run: %s\" % run.get_url(api))\n    print(\"Call `%%wandb` in the cell containing your training loop to display live results.\")\n    try:\n        run.save(api=api)\n    except (CommError, ValueError) as e:\n        termerror(str(e))\n    run.set_environment()\n    run._init_jupyter_agent()\n    ipython = get_ipython()\n    ipython.register_magics(jupyter.WandBMagics)\n\n    def reset_start():\n        \"\"\"Reset START_TIME to when the cell starts\"\"\"\n        global START_TIME\n        START_TIME = time.time()\n    ipython.events.register(\"pre_run_cell\", reset_start)\n    ipython.events.register('post_run_cell', run._stop_jupyter_agent)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave a file matching glob_str to wandb.", "response": "def save(glob_str, base_path=None, policy=\"live\"):\n    \"\"\" Ensure all files matching *glob_str* are synced to wandb with the policy specified.\n\n    base_path: the base path to run the glob relative to\n    policy:\n        live: upload the file as it changes, overwriting the previous version\n        end: only upload file when the run ends\n    \"\"\"\n    global _saved_files\n    if run is None:\n        raise ValueError(\n            \"You must call `wandb.init` before calling save\")\n    if policy not in (\"live\", \"end\"):\n        raise ValueError(\n            'Only \"live\" and \"end\" policies are currently supported.')\n    if base_path is None:\n        base_path = os.path.dirname(glob_str)\n    if isinstance(glob_str, bytes):\n        glob_str = glob_str.decode('utf-8')\n    wandb_glob_str = os.path.relpath(glob_str, base_path)\n    if \"../\" in wandb_glob_str:\n        raise ValueError(\n            \"globs can't walk above base_path\")\n    if (glob_str, base_path, policy) in _saved_files:\n        return []\n    if glob_str.startswith(\"gs://\") or glob_str.startswith(\"s3://\"):\n        termlog(\n            \"%s is a cloud storage url, can't save file to wandb.\" % glob_str)\n    run.send_message(\n        {\"save_policy\": {\"glob\": wandb_glob_str, \"policy\": policy}})\n    files = []\n    for path in glob.glob(glob_str):\n        file_name = os.path.relpath(path, base_path)\n        abs_path = os.path.abspath(path)\n        wandb_path = os.path.join(run.dir, file_name)\n        util.mkdir_exists_ok(os.path.dirname(wandb_path))\n        # We overwrite existing symlinks because namespaces can change in Tensorboard\n        if os.path.islink(wandb_path) and abs_path != os.readlink(wandb_path):\n            os.remove(wandb_path)\n            os.symlink(abs_path, wandb_path)\n        elif not os.path.exists(wandb_path):\n            os.symlink(abs_path, wandb_path)\n        files.append(wandb_path)\n    _saved_files.add((glob_str, base_path, policy))\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload the specified file from the current run directory into the current run directory if it doesn t exist locally.", "response": "def restore(name, run_path=None, replace=False, root=\".\"):\n    \"\"\" Downloads the specified file from cloud storage into the current run directory\n    if it doesn exist.\n\n    name: the name of the file\n    run_path: optional path to a different run to pull files from\n    replace: whether to download the file even if it already exists locally\n    root: the directory to download the file to.  Defaults to the current \n        directory or the run directory if wandb.init was called.\n\n    returns None if it can't find the file, otherwise a file object open for reading\n    raises wandb.CommError if it can't find the run\n    \"\"\"\n    if run_path is None and run is None:\n        raise ValueError(\n            \"You must call `wandb.init` before calling restore or specify a run_path\")\n    api = Api()\n    api_run = api.run(run_path or run.path)\n    root = run.dir if run else root\n    path = os.path.exists(os.path.join(root, name))\n    if path and replace == False:\n        return open(path, \"r\")\n    files = api_run.files([name])\n    if len(files) == 0:\n        return None\n    return files[0].download(root=root, replace=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef monitor(options={}):\n    try:\n        from IPython.display import display\n    except ImportError:\n        def display(stuff): return None\n\n    class Monitor():\n        def __init__(self, options={}):\n            if os.getenv(\"WANDB_JUPYTER\"):\n                display(jupyter.Run())\n            else:\n                self.rm = False\n                termerror(\n                    \"wandb.monitor is only functional in Jupyter notebooks\")\n\n        def __enter__(self):\n            termlog(\n                \"DEPRECATED: with wandb.monitor(): is deprecated, just call wandb.monitor() to see live results.\")\n            pass\n\n        def __exit__(self, *args):\n            pass\n\n    return Monitor(options)", "response": "Starts syncing with W&B if you re in Jupyter."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog a dict to the global run s history.", "response": "def log(row=None, commit=True, *args, **kargs):\n    \"\"\"Log a dict to the global run's history.  If commit is false, enables multiple calls before commiting.\n\n    Eg.\n\n    wandb.log({'train-loss': 0.5, 'accuracy': 0.9})\n    \"\"\"\n    if run is None:\n        raise ValueError(\n            \"You must call `wandb.init` in the same process before calling log\")\n\n    if row is None:\n        row = {}\n    if commit:\n        run.history.add(row, *args, **kargs)\n    else:\n        run.history.update(row, *args, **kargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uninit():\n    global run, config, watch_called, _saved_files\n    run = config = None\n    watch_called = False\n    _saved_files = set()", "response": "Undo the effects of init. Useful for testing."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset_env(exclude=[]):\n    if os.getenv(env.INITED):\n        wandb_keys = [key for key in os.environ.keys() if key.startswith(\n            'WANDB_') and key not in exclude]\n        for key in wandb_keys:\n            del os.environ[key]\n        return True\n    else:\n        return False", "response": "Remove environment variables used in Jupyter notebooks"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef try_to_set_up_global_logging():\n    root = logging.getLogger()\n    root.setLevel(logging.DEBUG)\n    formatter = logging.Formatter(\n        '%(asctime)s %(levelname)-7s %(threadName)-10s:%(process)d [%(filename)s:%(funcName)s():%(lineno)s] %(message)s')\n\n    if env.is_debug():\n        handler = logging.StreamHandler()\n        handler.setLevel(logging.DEBUG)\n        handler.setFormatter(formatter)\n\n        root.addHandler(handler)\n\n    try:\n        handler = logging.FileHandler(GLOBAL_LOG_FNAME, mode='w')\n        handler.setLevel(logging.DEBUG)\n        handler.setFormatter(formatter)\n\n        root.addHandler(handler)\n    except IOError as e:  # eg. in case wandb directory isn't writable\n        termerror('Failed to set up logging: {}'.format(e))\n        return False\n\n    return True", "response": "Try to set up global W&B debug log that gets re - written by every W&B process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a secrets. env file with the W&B ApiKey and any additional secrets passed.", "response": "def sagemaker_auth(overrides={}, path=\".\"):\n    \"\"\" Write a secrets.env file with the W&B ApiKey and any additional secrets passed.\n\n        Args:\n            overrides (dict, optional): Additional environment variables to write to secrets.env\n            path (str, optional): The path to write the secrets file.\n    \"\"\"\n\n    api_key = overrides.get(env.API_KEY, Api().api_key)\n    if api_key is None:\n        raise ValueError(\n            \"Can't find W&B ApiKey, set the WANDB_API_KEY env variable or run `wandb login`\")\n    overrides[env.API_KEY] = api_key\n    with open(os.path.join(path, \"secrets.env\"), \"w\") as file:\n        for k, v in six.iteritems(overrides):\n            file.write(\"{}={}\\n\".format(k, v))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init(job_type=None, dir=None, config=None, project=None, entity=None, reinit=None, tags=None,\n         group=None, allow_val_change=False, resume=False, force=False, tensorboard=False,\n         name=None, id=None):\n    \"\"\"Initialize W&B\n\n    If called from within Jupyter, initializes a new run and waits for a call to\n    `wandb.monitor` to begin pushing metrics.  Otherwise, spawns a new process\n    to communicate with W&B.\n\n    Args:\n        job_type (str, optional): The type of job running, defaults to 'train'\n        config (dict, argparse, or tf.FLAGS, optional): The hyper parameters to store with the run\n        project (str, optional): The project to push metrics to\n        entity (str, optional): The entity to push metrics to\n        dir (str, optional): An absolute path to a directory where metadata will be stored\n        group (str, optional): A unique string shared by all runs in a given group\n        tags (list, optional): A list of tags to apply to the run\n        reinit (bool, optional): Allow multiple calls to init in the same process\n        resume (bool, str, optional): Automatically resume this run if run from the same machine,\n            you can also pass a unique run_id\n        tensorboard (bool, optional): Patch tensorboard or tensorboardX to log all events\n        force (bool, optional): Force authentication with wandb, defaults to False\n\n    Returns:\n        A wandb.run object for metric and config logging.\n    \"\"\"\n    global run\n    global __stage_dir__\n\n    # We allow re-initialization when we're in Jupyter\n    in_jupyter = _get_python_type() != \"python\"\n    if reinit or (in_jupyter and reinit != False):\n        reset_env(exclude=[env.DIR, env.ENTITY, env.PROJECT, env.API_KEY])\n        run = None\n\n    if tensorboard:\n        util.get_module(\"wandb.tensorboard\").patch()\n\n    sagemaker_config = util.parse_sm_config()\n    tf_config = util.parse_tfjob_config()\n    if group == None:\n        group = os.getenv(env.RUN_GROUP)\n    if job_type == None:\n        job_type = os.getenv(env.JOB_TYPE)\n    if sagemaker_config:\n        # Set run_id and potentially grouping if we're in SageMaker\n        run_id = os.getenv('TRAINING_JOB_NAME')\n        if run_id:\n            os.environ[env.RUN_ID] = '-'.join([\n                run_id,\n                os.getenv('CURRENT_HOST', socket.gethostname())])\n        conf = json.load(\n            open(\"/opt/ml/input/config/resourceconfig.json\"))\n        if group == None and len(conf[\"hosts\"]) > 1:\n            group = os.getenv('TRAINING_JOB_NAME')\n        # Set secret variables\n        if os.path.exists(\"secrets.env\"):\n            for line in open(\"secrets.env\", \"r\"):\n                key, val = line.strip().split('=', 1)\n                os.environ[key] = val\n    elif tf_config:\n        cluster = tf_config.get('cluster')\n        job_name = tf_config.get('task', {}).get('type')\n        task_index = tf_config.get('task', {}).get('index')\n        if job_name is not None and task_index is not None:\n            # TODO: set run_id for resuming?\n            run_id = cluster[job_name][task_index].rsplit(\":\")[0]\n            if job_type == None:\n                job_type = job_name\n            if group == None and len(cluster.get(\"worker\", [])) > 0:\n                group = cluster[job_name][0].rsplit(\"-\"+job_name, 1)[0]\n    image = util.image_id_from_k8s()\n    if image:\n        os.environ[env.DOCKER] = image\n    if project:\n        os.environ[env.PROJECT] = project\n    if entity:\n        os.environ[env.ENTITY] = entity\n    if group:\n        os.environ[env.RUN_GROUP] = group\n    if job_type:\n        os.environ[env.JOB_TYPE] = job_type\n    if tags:\n        os.environ[env.TAGS] = \",\".join(tags)\n    if id:\n        os.environ[env.RUN_ID] = id\n    if name:\n        os.environ[env.DESCRIPTION] = name + \\\n            \"\\n\" + os.getenv(env.DESCRIPTION, \"\")\n    if dir:\n        os.environ[env.DIR] = dir\n        util.mkdir_exists_ok(wandb_dir())\n    resume_path = os.path.join(wandb_dir(), wandb_run.RESUME_FNAME)\n    if resume == True:\n        os.environ[env.RESUME] = \"auto\"\n    elif resume:\n        os.environ[env.RESUME] = os.environ.get(env.RESUME, \"allow\")\n        # TODO: remove allowing resume as a string in the future\n        os.environ[env.RUN_ID] = id or resume\n    elif os.path.exists(resume_path):\n        os.remove(resume_path)\n    if os.environ.get(env.RESUME) == 'auto' and os.path.exists(resume_path):\n        if not os.environ.get(env.RUN_ID):\n            os.environ[env.RUN_ID] = json.load(open(resume_path))[\"run_id\"]\n\n    # the following line is useful to ensure that no W&B logging happens in the user\n    # process that might interfere with what they do\n    # logging.basicConfig(format='user process %(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # If a thread calls wandb.init() it will get the same Run object as\n    # the parent. If a child process with distinct memory space calls\n    # wandb.init(), it won't get an error, but it will get a result of\n    # None.\n    # This check ensures that a child process can safely call wandb.init()\n    # after a parent has (only the parent will create the Run object).\n    # This doesn't protect against the case where the parent doesn't call\n    # wandb.init but two children do.\n    if run or os.getenv(env.INITED):\n        return run\n\n    if __stage_dir__ is None:\n        __stage_dir__ = \"wandb\"\n        util.mkdir_exists_ok(wandb_dir())\n\n    try:\n        signal.signal(signal.SIGQUIT, _debugger)\n    except AttributeError:\n        pass\n\n    try:\n        run = wandb_run.Run.from_environment_or_defaults()\n    except IOError as e:\n        termerror('Failed to create run directory: {}'.format(e))\n        raise LaunchError(\"Could not write to filesystem.\")\n\n    run.set_environment()\n\n    def set_global_config(run):\n        global config  # because we already have a local config\n        config = run.config\n    set_global_config(run)\n\n    # set this immediately after setting the run and the config. if there is an\n    # exception after this it'll probably break the user script anyway\n    os.environ[env.INITED] = '1'\n\n    # we do these checks after setting the run and the config because users scripts\n    # may depend on those things\n    if sys.platform == 'win32' and run.mode != 'clirun':\n        termerror(\n            'Headless mode isn\\'t supported on Windows. If you want to use W&B, please use \"wandb run ...\"; running normally.')\n        return run\n\n    if in_jupyter:\n        _init_jupyter(run)\n    elif run.mode == 'clirun':\n        pass\n    elif run.mode == 'run':\n\n        api = InternalApi()\n        # let init_jupyter handle this itself\n        if not in_jupyter and not api.api_key:\n            termlog(\n                \"W&B is a tool that helps track and visualize machine learning experiments\")\n            if force:\n                termerror(\n                    \"No credentials found.  Run \\\"wandb login\\\" or \\\"wandb off\\\" to disable wandb\")\n            else:\n                termlog(\n                    \"No credentials found.  Run \\\"wandb login\\\" to visualize your metrics\")\n                run.mode = \"dryrun\"\n                _init_headless(run, False)\n        else:\n            _init_headless(run)\n    elif run.mode == 'dryrun':\n        termlog(\n            'Dry run mode, not syncing to the cloud.')\n        _init_headless(run, False)\n    else:\n        termerror(\n            'Invalid run mode \"%s\". Please unset WANDB_MODE.' % run.mode)\n        raise LaunchError(\"The WANDB_MODE environment variable is invalid.\")\n\n    # set the run directory in the config so it actually gets persisted\n    run.config.set_run_dir(run.dir)\n\n    if sagemaker_config:\n        run.config.update(sagemaker_config)\n        allow_val_change = True\n    if config:\n        run.config.update(config, allow_val_change=allow_val_change)\n\n    # Access history to ensure resumed is set when resuming\n    run.history\n\n    atexit.register(run.close_files)\n\n    return run", "response": "Initialize W&B with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing and validate color format.", "response": "def _colorformat(text):\n    \"\"\"\n    Parse/validate color format.\n\n    Like in Pygments, but also support the ANSI color names.\n    (These will map to the colors of the 16 color palette.)\n    \"\"\"\n    if text[0:1] == '#':\n        col = text[1:]\n        if col in ANSI_COLOR_NAMES:\n            return col\n        elif len(col) == 6:\n            return col\n        elif len(col) == 3:\n            return col[0]*2 + col[1]*2 + col[2]*2\n    elif text == '':\n        return text\n\n    raise ValueError('Wrong color format %r' % text)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new style instance from a dictionary.", "response": "def style_from_dict(style_dict, include_defaults=True):\n    \"\"\"\n    Create a ``Style`` instance from a dictionary or other mapping.\n\n    The dictionary is equivalent to the ``Style.styles`` dictionary from\n    pygments, with a few additions: it supports 'reverse' and 'blink'.\n\n    Usage::\n\n        style_from_dict({\n            Token: '#ff0000 bold underline',\n            Token.Title: 'blink',\n            Token.SomethingElse: 'reverse',\n        })\n\n    :param include_defaults: Include the defaults (built-in) styling for\n        selected text, etc...)\n    \"\"\"\n    assert isinstance(style_dict, Mapping)\n\n    if include_defaults:\n        s2 = {}\n        s2.update(DEFAULT_STYLE_EXTENSIONS)\n        s2.update(style_dict)\n        style_dict = s2\n\n    # Expand token inheritance and turn style description into Attrs.\n    token_to_attrs = {}\n\n    # (Loop through the tokens in order. Sorting makes sure that\n    # we process the parent first.)\n    for ttype, styledef in sorted(style_dict.items()):\n        # Start from parent Attrs or default Attrs.\n        attrs = DEFAULT_ATTRS\n\n        if 'noinherit' not in styledef:\n            for i in range(1, len(ttype) + 1):\n                try:\n                    attrs = token_to_attrs[ttype[:-i]]\n                except KeyError:\n                    pass\n                else:\n                    break\n\n        # Now update with the given attributes.\n        for part in styledef.split():\n            if part == 'noinherit':\n                pass\n            elif part == 'bold':\n                attrs = attrs._replace(bold=True)\n            elif part == 'nobold':\n                attrs = attrs._replace(bold=False)\n            elif part == 'italic':\n                attrs = attrs._replace(italic=True)\n            elif part == 'noitalic':\n                attrs = attrs._replace(italic=False)\n            elif part == 'underline':\n                attrs = attrs._replace(underline=True)\n            elif part == 'nounderline':\n                attrs = attrs._replace(underline=False)\n\n            # prompt_toolkit extensions. Not in Pygments.\n            elif part == 'blink':\n                attrs = attrs._replace(blink=True)\n            elif part == 'noblink':\n                attrs = attrs._replace(blink=False)\n            elif part == 'reverse':\n                attrs = attrs._replace(reverse=True)\n            elif part == 'noreverse':\n                attrs = attrs._replace(reverse=False)\n\n            # Pygments properties that we ignore.\n            elif part in ('roman', 'sans', 'mono'):\n                pass\n            elif part.startswith('border:'):\n                pass\n\n            # Colors.\n\n            elif part.startswith('bg:'):\n                attrs = attrs._replace(bgcolor=_colorformat(part[3:]))\n            else:\n                attrs = attrs._replace(color=_colorformat(part))\n\n        token_to_attrs[ttype] = attrs\n\n    return _StyleFromDict(token_to_attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall the inputhook. (Called by a prompt-toolkit eventloop.)", "response": "def call_inputhook(self, input_is_ready_func):\n        \"\"\"\n        Call the inputhook. (Called by a prompt-toolkit eventloop.)\n        \"\"\"\n        self._input_is_ready = input_is_ready_func\n\n        # Start thread that activates this pipe when there is input to process.\n        def thread():\n            input_is_ready_func(wait=True)\n            os.write(self._w, b'x')\n\n        threading.Thread(target=thread).start()\n\n        # Call inputhook.\n        self.inputhook(self)\n\n        # Flush the read end of the pipe.\n        try:\n            # Before calling 'os.read', call select.select. This is required\n            # when the gevent monkey patch has been applied. 'os.read' is never\n            # monkey patched and won't be cooperative, so that would block all\n            # other select() calls otherwise.\n            # See: http://www.gevent.org/gevent.os.html\n\n            # Note: On Windows, this is apparently not an issue.\n            #       However, if we would ever want to add a select call, it\n            #       should use `windll.kernel32.WaitForMultipleObjects`,\n            #       because `select.select` can't wait for a pipe on Windows.\n            if not is_windows():\n                select_fds([self._r], timeout=None)\n\n            os.read(self._r, 1024)\n        except OSError:\n            # This happens when the window resizes and a SIGWINCH was received.\n            # We get 'Error: [Errno 4] Interrupted system call'\n            # Just ignore.\n            pass\n        self._input_is_ready = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rename_file(self, old_save_name, new_save_name, new_path):\n        if old_save_name in self._files:\n            del self._files[old_save_name]\n        self.update_file(new_save_name, new_path)", "response": "Rename a file in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(name):\n    assert isinstance(name, six.text_type)\n    def decorator(handler):\n        assert callable(handler)\n\n        _readline_commands[name] = handler\n        return handler\n    return decorator", "response": "Decorator to register a new command handler."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving to the start of the current line.", "response": "def beginning_of_line(event):\n    \" Move to the start of the current line. \"\n    buff = event.current_buffer\n    buff.cursor_position += buff.document.get_start_of_line_position(after_whitespace=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove to the end of the line.", "response": "def end_of_line(event):\n    \" Move to the end of the line. \"\n    buff = event.current_buffer\n    buff.cursor_position += buff.document.get_end_of_line_position()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves forward a character.", "response": "def forward_char(event):\n    \" Move forward a character. \"\n    buff = event.current_buffer\n    buff.cursor_position += buff.document.get_cursor_right_position(count=event.arg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef backward_char(event):\n    \" Move back a character. \"\n    buff = event.current_buffer\n    buff.cursor_position += buff.document.get_cursor_left_position(count=event.arg)", "response": "Move back a character."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving forward to the end of the next word.", "response": "def forward_word(event):\n    \"\"\"\n    Move forward to the end of the next word. Words are composed of letters and\n    digits.\n    \"\"\"\n    buff = event.current_buffer\n    pos = buff.document.find_next_word_ending(count=event.arg)\n\n    if pos:\n        buff.cursor_position += pos"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef backward_word(event):\n    buff = event.current_buffer\n    pos = buff.document.find_previous_word_beginning(count=event.arg)\n\n    if pos:\n        buff.cursor_position += pos", "response": "Move back to the start of the current or previous word."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\naccept the line regardless of where the cursor is.", "response": "def accept_line(event):\n    \" Accept the line regardless of where the cursor is. \"\n    b = event.current_buffer\n    b.accept_action.validate_and_handle(event.cli, b)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove to the end of the input history.", "response": "def end_of_history(event):\n    \"\"\"\n    Move to the end of the input history, i.e., the line currently being entered.\n    \"\"\"\n    event.current_buffer.history_forward(count=10**100)\n    buff = event.current_buffer\n    buff.go_to_history(len(buff._working_lines) - 1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reverse_search_history(event):\n    event.cli.current_search_state.direction = IncrementalSearchDirection.BACKWARD\n    event.cli.push_focus(SEARCH_BUFFER)", "response": "Search backward starting at the current line and moving up through\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes character before the cursor.", "response": "def delete_char(event):\n    \" Delete character before the cursor. \"\n    deleted = event.current_buffer.delete(count=event.arg)\n    if not deleted:\n        event.cli.output.bell()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef backward_delete_char(event):\n    \" Delete the character behind the cursor. \"\n    if event.arg < 0:\n        # When a negative argument has been given, this should delete in front\n        # of the cursor.\n        deleted = event.current_buffer.delete(count=-event.arg)\n    else:\n        deleted = event.current_buffer.delete_before_cursor(count=event.arg)\n\n    if not deleted:\n        event.cli.output.bell()", "response": "Delete the character behind the cursor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transpose_chars(event):\n    b = event.current_buffer\n    p = b.cursor_position\n    if p == 0:\n        return\n    elif p == len(b.text) or b.text[p] == '\\n':\n        b.swap_characters_before_cursor()\n    else:\n        b.cursor_position += b.document.get_cursor_right_position()\n        b.swap_characters_before_cursor()", "response": "Emulate Emacs transpose - char behavior"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef capitalize_word(event):\n    buff = event.current_buffer\n\n    for i in range(event.arg):\n        pos = buff.document.find_next_word_ending()\n        words = buff.document.text_after_cursor[:pos]\n        buff.insert_text(words.title(), overwrite=True)", "response": "Capitalize the current word."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef kill_line(event):\n    buff = event.current_buffer\n    if event.arg < 0:\n        deleted = buff.delete_before_cursor(count=-buff.document.get_start_of_line_position())\n    else:\n        if buff.document.current_char == '\\n':\n            deleted = buff.delete(1)\n        else:\n            deleted = buff.delete(count=buff.document.get_end_of_line_position())\n    event.cli.clipboard.set_text(deleted)", "response": "Kill the text from the cursor to the end of the line."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nkill the current word or if between words to the next word.", "response": "def kill_word(event):\n    \"\"\"\n    Kill from point to the end of the current word, or if between words, to the\n    end of the next word. Word boundaries are the same as forward-word.\n    \"\"\"\n    buff = event.current_buffer\n    pos = buff.document.find_next_word_ending(count=event.arg)\n\n    if pos:\n        deleted = buff.delete(count=pos)\n        event.cli.clipboard.set_text(deleted)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unix_word_rubout(event, WORD=True):\n    buff = event.current_buffer\n    pos = buff.document.find_start_of_previous_word(count=event.arg, WORD=WORD)\n\n    if pos is None:\n        # Nothing found? delete until the start of the document.  (The\n        # input starts with whitespace and no words were found before the\n        # cursor.)\n        pos = - buff.cursor_position\n\n    if pos:\n        deleted = buff.delete_before_cursor(count=-pos)\n\n        # If the previous key press was also Control-W, concatenate deleted\n        # text.\n        if event.is_repeat:\n            deleted += event.cli.clipboard.get_data().text\n\n        event.cli.clipboard.set_text(deleted)\n    else:\n        # Nothing to delete. Bell.\n        event.cli.output.bell()", "response": "Kill the word behind point using whitespace as a word boundary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_horizontal_space(event):\n    \" Delete all spaces and tabs around point. \"\n    buff = event.current_buffer\n    text_before_cursor = buff.document.text_before_cursor\n    text_after_cursor = buff.document.text_after_cursor\n\n    delete_before = len(text_before_cursor) - len(text_before_cursor.rstrip('\\t '))\n    delete_after = len(text_after_cursor) - len(text_after_cursor.lstrip('\\t '))\n\n    buff.delete_before_cursor(count=delete_before)\n    buff.delete(count=delete_after)", "response": "Delete all spaces and tabs around point."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unix_line_discard(event):\n    buff = event.current_buffer\n\n    if buff.document.cursor_position_col == 0 and buff.document.cursor_position > 0:\n        buff.delete_before_cursor(count=1)\n    else:\n        deleted = buff.delete_before_cursor(count=-buff.document.get_start_of_line_position())\n        event.cli.clipboard.set_text(deleted)", "response": "Kill backward from the cursor to the beginning of the current line."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef yank(event):\n    event.current_buffer.paste_clipboard_data(\n        event.cli.clipboard.get_data(), count=event.arg, paste_mode=PasteMode.EMACS)", "response": "Paste data before cursor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert the nth word from the previous command.", "response": "def yank_nth_arg(event):\n    \"\"\"\n    Insert the first argument of the previous command. With an argument, insert\n    the nth word from the previous command (start counting at 0).\n    \"\"\"\n    n = (event.arg if event.arg_present else None)\n    event.current_buffer.yank_nth_arg(n)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlikes yank_nth_arg but yank the last word of each line.", "response": "def yank_last_arg(event):\n    \"\"\"\n    Like `yank_nth_arg`, but if no argument has been given, yank the last word\n    of each line.\n    \"\"\"\n    n = (event.arg if event.arg_present else None)\n    event.current_buffer.yank_last_arg(n)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrotate the kill ring and yank the new top. Only works following yank or yank - pop.", "response": "def yank_pop(event):\n    \"\"\"\n    Rotate the kill ring, and yank the new top. Only works following yank or\n    yank-pop.\n    \"\"\"\n    buff = event.current_buffer\n    doc_before_paste = buff.document_before_paste\n    clipboard = event.cli.clipboard\n\n    if doc_before_paste is not None:\n        buff.document = doc_before_paste\n        clipboard.rotate()\n        buff.paste_clipboard_data(\n            clipboard.get_data(), paste_mode=PasteMode.EMACS)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint the last keboard macro.", "response": "def print_last_kbd_macro(event):\n    \" Print the last keboard macro. \"\n    # TODO: Make the format suitable for the inputrc file.\n    def print_macro():\n        for k in event.cli.input_processor.macro:\n            print(k)\n    event.cli.run_in_terminal(print_macro)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts comment into the current buffer.", "response": "def insert_comment(event):\n    \"\"\"\n    Without numeric argument, comment all lines.\n    With numeric argument, uncomment all lines.\n    In any case accept the input.\n    \"\"\"\n    buff = event.current_buffer\n\n    # Transform all lines.\n    if event.arg != 1:\n        def change(line):\n            return line[1:] if line.startswith('#') else line\n    else:\n        def change(line):\n            return '#' + line\n\n    buff.document = Document(\n        text='\\n'.join(map(change, buff.text.splitlines())),\n        cursor_position=0)\n\n    # Accept input.\n    buff.accept_action.validate_and_handle(event.cli, buff)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef operate_and_get_next(event):\n    buff = event.current_buffer\n    new_index = buff.working_index + 1\n\n    # Accept the current input. (This will also redraw the interface in the\n    # 'done' state.)\n    buff.accept_action.validate_and_handle(event.cli, buff)\n\n    # Set the new index at the start of the next run.\n    def set_working_index():\n        if new_index < len(buff._working_lines):\n            buff.working_index = new_index\n\n    event.cli.pre_run_callables.append(set_working_index)", "response": "Accept the current line for execution and fetch the next line relative to the current line from the history for editing."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nedits the current buffer and execute the action.", "response": "def edit_and_execute(event):\n    \"\"\"\n    Invoke an editor on the current command line, and accept the result.\n    \"\"\"\n    buff = event.current_buffer\n\n    buff.open_in_editor(event.cli)\n    buff.accept_action.validate_and_handle(event.cli, buff)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload key bindings required for mouse events.", "response": "def load_mouse_bindings():\n    \"\"\"\n    Key bindings, required for mouse support.\n    (Mouse events enter through the key binding system.)\n    \"\"\"\n    registry = Registry()\n\n    @registry.add_binding(Keys.Vt100MouseEvent)\n    def _(event):\n        \"\"\"\n        Handling of incoming mouse event.\n        \"\"\"\n        # Typical:   \"Esc[MaB*\"\n        # Urxvt:     \"Esc[96;14;13M\"\n        # Xterm SGR: \"Esc[<64;85;12M\"\n\n        # Parse incoming packet.\n        if event.data[2] == 'M':\n            # Typical.\n            mouse_event, x, y = map(ord, event.data[3:])\n            mouse_event = {\n                32: MouseEventType.MOUSE_DOWN,\n                35: MouseEventType.MOUSE_UP,\n                96: MouseEventType.SCROLL_UP,\n                97: MouseEventType.SCROLL_DOWN,\n            }.get(mouse_event)\n\n            # Handle situations where `PosixStdinReader` used surrogateescapes.\n            if x >= 0xdc00: x-= 0xdc00\n            if y >= 0xdc00: y-= 0xdc00\n\n            x -= 32\n            y -= 32\n        else:\n            # Urxvt and Xterm SGR.\n            # When the '<' is not present, we are not using the Xterm SGR mode,\n            # but Urxvt instead.\n            data = event.data[2:]\n            if data[:1] == '<':\n                sgr = True\n                data = data[1:]\n            else:\n                sgr = False\n\n            # Extract coordinates.\n            mouse_event, x, y = map(int, data[:-1].split(';'))\n            m = data[-1]\n\n            # Parse event type.\n            if sgr:\n                mouse_event = {\n                    (0, 'M'): MouseEventType.MOUSE_DOWN,\n                    (0, 'm'): MouseEventType.MOUSE_UP,\n                    (64, 'M'): MouseEventType.SCROLL_UP,\n                    (65, 'M'): MouseEventType.SCROLL_DOWN,\n                }.get((mouse_event, m))\n            else:\n                mouse_event = {\n                    32: MouseEventType.MOUSE_DOWN,\n                    35: MouseEventType.MOUSE_UP,\n                    96: MouseEventType.SCROLL_UP,\n                    97: MouseEventType.SCROLL_DOWN,\n                    }.get(mouse_event)\n\n        x -= 1\n        y -= 1\n\n        # Only handle mouse events when we know the window height.\n        if event.cli.renderer.height_is_known and mouse_event is not None:\n            # Take region above the layout into account. The reported\n            # coordinates are absolute to the visible part of the terminal.\n            try:\n                y -= event.cli.renderer.rows_above_layout\n            except HeightIsUnknownError:\n                return\n\n            # Call the mouse handler from the renderer.\n            handler = event.cli.renderer.mouse_handlers.mouse_handlers[x,y]\n            handler(event.cli, MouseEvent(position=Point(x=x, y=y),\n                                          event_type=mouse_event))\n\n    @registry.add_binding(Keys.WindowsMouseEvent)\n    def _(event):\n        \"\"\"\n        Handling of mouse events for Windows.\n        \"\"\"\n        assert is_windows()  # This key binding should only exist for Windows.\n\n        # Parse data.\n        event_type, x, y = event.data.split(';')\n        x = int(x)\n        y = int(y)\n\n        # Make coordinates absolute to the visible part of the terminal.\n        screen_buffer_info = event.cli.renderer.output.get_win32_screen_buffer_info()\n        rows_above_cursor = screen_buffer_info.dwCursorPosition.Y - event.cli.renderer._cursor_pos.y\n        y -= rows_above_cursor\n\n        # Call the mouse event handler.\n        handler = event.cli.renderer.mouse_handlers.mouse_handlers[x,y]\n        handler(event.cli, MouseEvent(position=Point(x=x, y=y),\n                                      event_type=event_type))\n\n    return registry"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_abort_and_exit_bindings():\n    registry = Registry()\n    handle = registry.add_binding\n\n    @handle(Keys.ControlC)\n    def _(event):\n        \" Abort when Control-C has been pressed. \"\n        event.cli.abort()\n\n    @Condition\n    def ctrl_d_condition(cli):\n        \"\"\" Ctrl-D binding is only active when the default buffer is selected\n        and empty. \"\"\"\n        return (cli.current_buffer_name == DEFAULT_BUFFER and\n                not cli.current_buffer.text)\n\n    handle(Keys.ControlD, filter=ctrl_d_condition)(get_by_name('end-of-file'))\n\n    return registry", "response": "Load abort and exit bindings for the current buffer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the basic system bindings.", "response": "def load_basic_system_bindings():\n    \"\"\"\n    Basic system bindings (For both Emacs and Vi mode.)\n    \"\"\"\n    registry = Registry()\n\n    suspend_supported = Condition(\n        lambda cli: suspend_to_background_supported())\n\n    @registry.add_binding(Keys.ControlZ, filter=suspend_supported)\n    def _(event):\n        \"\"\"\n        Suspend process to background.\n        \"\"\"\n        event.cli.suspend_to_background()\n\n    return registry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading auto suggestion bindings.", "response": "def load_auto_suggestion_bindings():\n    \"\"\"\n    Key bindings for accepting auto suggestion text.\n    \"\"\"\n    registry = Registry()\n    handle = registry.add_binding\n\n    suggestion_available = Condition(\n        lambda cli:\n            cli.current_buffer.suggestion is not None and\n            cli.current_buffer.document.is_cursor_at_the_end)\n\n    @handle(Keys.ControlF, filter=suggestion_available)\n    @handle(Keys.ControlE, filter=suggestion_available)\n    @handle(Keys.Right, filter=suggestion_available)\n    def _(event):\n        \" Accept suggestion. \"\n        b = event.current_buffer\n        suggestion = b.suggestion\n\n        if suggestion:\n            b.insert_text(suggestion.text)\n\n    return registry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the column types for the current resource.", "response": "def set_columns(self, types):\n        \"\"\"Set the column types\n\n        args:\n            types: iterable of (column_name, type) pairs.\n        \"\"\"\n        if self._types:\n            raise wandb.Error('TypedTable.set_columns called more than once.')\n        try:\n            for key, type_ in types:\n                if type_ not in TYPE_TO_TYPESTRING:\n                    raise wandb.Error('TypedTable.set_columns received invalid type ({}) for key \"{}\".\\n  Valid types: {}'.format(\n                        type_, key, '[%s]' % ', '.join(VALID_TYPE_NAMES)))\n        except TypeError:\n            raise wandb.Error(\n                'TypedTable.set_columns requires iterable of (column_name, type) pairs.')\n        self._types = dict(types)\n        self._output.add({\n            'typemap': {k: TYPE_TO_TYPESTRING[type_] for k, type_ in types},\n            'columns': [t[0] for t in types]})"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a row to the table.", "response": "def add(self, row):\n        \"\"\"Add a row to the table.\n\n        Args:\n            row: A dict whose keys match the keys added in set_columns, and whose\n                values can be cast to the types added in set_columns.\n        \"\"\"\n        if not self._types:\n            raise wandb.Error(\n                'TypedTable.set_columns must be called before add.')\n        mapped_row = {}\n        for key, val in row.items():\n            try:\n                typed_val = self._types[key](val)\n                if hasattr(typed_val, 'encode'):\n                    typed_val = typed_val.encode()\n                mapped_row[key] = typed_val\n            except KeyError:\n                raise wandb.Error(\n                    'TypedTable.add received key (\"%s\") which wasn\\'t provided to set_columns' % key)\n            except:\n                raise wandb.Error('TypedTable.add couldn\\'t convert and encode (\"{}\") provided for key (\"{}\") to type ({})'.format(\n                    val, key, self._types[key]))\n        self._output.add(mapped_row)\n        self._count += 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _output_screen_diff(output, screen, current_pos, previous_screen=None, last_token=None,\n                        is_done=False, use_alternate_screen=False, attrs_for_token=None, size=None,\n                        previous_width=0):  # XXX: drop is_done\n    \"\"\"\n    Render the diff between this screen and the previous screen.\n\n    This takes two `Screen` instances. The one that represents the output like\n    it was during the last rendering and one that represents the current\n    output raster. Looking at these two `Screen` instances, this function will\n    render the difference by calling the appropriate methods of the `Output`\n    object that only paint the changes to the terminal.\n\n    This is some performance-critical code which is heavily optimized.\n    Don't change things without profiling first.\n\n    :param current_pos: Current cursor position.\n    :param last_token: `Token` instance that represents the output attributes of\n            the last drawn character. (Color/attributes.)\n    :param attrs_for_token: :class:`._TokenToAttrsCache` instance.\n    :param width: The width of the terminal.\n    :param prevous_width: The width of the terminal during the last rendering.\n    \"\"\"\n    width, height = size.columns, size.rows\n\n    #: Remember the last printed character.\n    last_token = [last_token]  # nonlocal\n\n    #: Variable for capturing the output.\n    write = output.write\n    write_raw = output.write_raw\n\n    # Create locals for the most used output methods.\n    # (Save expensive attribute lookups.)\n    _output_set_attributes = output.set_attributes\n    _output_reset_attributes = output.reset_attributes\n    _output_cursor_forward = output.cursor_forward\n    _output_cursor_up = output.cursor_up\n    _output_cursor_backward = output.cursor_backward\n\n    # Hide cursor before rendering. (Avoid flickering.)\n    output.hide_cursor()\n\n    def reset_attributes():\n        \" Wrapper around Output.reset_attributes. \"\n        _output_reset_attributes()\n        last_token[0] = None  # Forget last char after resetting attributes.\n\n    def move_cursor(new):\n        \" Move cursor to this `new` point. Returns the given Point. \"\n        current_x, current_y = current_pos.x, current_pos.y\n\n        if new.y > current_y:\n            # Use newlines instead of CURSOR_DOWN, because this meight add new lines.\n            # CURSOR_DOWN will never create new lines at the bottom.\n            # Also reset attributes, otherwise the newline could draw a\n            # background color.\n            reset_attributes()\n            write('\\r\\n' * (new.y - current_y))\n            current_x = 0\n            _output_cursor_forward(new.x)\n            return new\n        elif new.y < current_y:\n            _output_cursor_up(current_y - new.y)\n\n        if current_x >= width - 1:\n            write('\\r')\n            _output_cursor_forward(new.x)\n        elif new.x < current_x or current_x >= width - 1:\n            _output_cursor_backward(current_x - new.x)\n        elif new.x > current_x:\n            _output_cursor_forward(new.x - current_x)\n\n        return new\n\n    def output_char(char):\n        \"\"\"\n        Write the output of this character.\n        \"\"\"\n        # If the last printed character has the same token, it also has the\n        # same style, so we don't output it.\n        the_last_token = last_token[0]\n\n        if the_last_token and the_last_token == char.token:\n            write(char.char)\n        else:\n            _output_set_attributes(attrs_for_token[char.token])\n            write(char.char)\n            last_token[0] = char.token\n\n    # Render for the first time: reset styling.\n    if not previous_screen:\n        reset_attributes()\n\n    # Disable autowrap. (When entering a the alternate screen, or anytime when\n    # we have a prompt. - In the case of a REPL, like IPython, people can have\n    # background threads, and it's hard for debugging if their output is not\n    # wrapped.)\n    if not previous_screen or not use_alternate_screen:\n        output.disable_autowrap()\n\n    # When the previous screen has a different size, redraw everything anyway.\n    # Also when we are done. (We meight take up less rows, so clearing is important.)\n    if is_done or not previous_screen or previous_width != width:  # XXX: also consider height??\n        current_pos = move_cursor(Point(0, 0))\n        reset_attributes()\n        output.erase_down()\n\n        previous_screen = Screen()\n\n    # Get height of the screen.\n    # (height changes as we loop over data_buffer, so remember the current value.)\n    # (Also make sure to clip the height to the size of the output.)\n    current_height = min(screen.height, height)\n\n    # Loop over the rows.\n    row_count = min(max(screen.height, previous_screen.height), height)\n    c = 0  # Column counter.\n\n    for y in range(row_count):\n        new_row = screen.data_buffer[y]\n        previous_row = previous_screen.data_buffer[y]\n        zero_width_escapes_row = screen.zero_width_escapes[y]\n\n        new_max_line_len = min(width - 1, max(new_row.keys()) if new_row else 0)\n        previous_max_line_len = min(width - 1, max(previous_row.keys()) if previous_row else 0)\n\n        # Loop over the columns.\n        c = 0\n        while c < new_max_line_len + 1:\n            new_char = new_row[c]\n            old_char = previous_row[c]\n            char_width = (new_char.width or 1)\n\n            # When the old and new character at this position are different,\n            # draw the output. (Because of the performance, we don't call\n            # `Char.__ne__`, but inline the same expression.)\n            if new_char.char != old_char.char or new_char.token != old_char.token:\n                current_pos = move_cursor(Point(y=y, x=c))\n\n                # Send injected escape sequences to output.\n                if c in zero_width_escapes_row:\n                    write_raw(zero_width_escapes_row[c])\n\n                output_char(new_char)\n                current_pos = current_pos._replace(x=current_pos.x + char_width)\n\n            c += char_width\n\n        # If the new line is shorter, trim it.\n        if previous_screen and new_max_line_len < previous_max_line_len:\n            current_pos = move_cursor(Point(y=y, x=new_max_line_len+1))\n            reset_attributes()\n            output.erase_end_of_line()\n\n    # Correctly reserve vertical space as required by the layout.\n    # When this is a new screen (drawn for the first time), or for some reason\n    # higher than the previous one. Move the cursor once to the bottom of the\n    # output. That way, we're sure that the terminal scrolls up, even when the\n    # lower lines of the canvas just contain whitespace.\n\n    # The most obvious reason that we actually want this behaviour is the avoid\n    # the artifact of the input scrolling when the completion menu is shown.\n    # (If the scrolling is actually wanted, the layout can still be build in a\n    # way to behave that way by setting a dynamic height.)\n    if current_height > previous_screen.height:\n        current_pos = move_cursor(Point(y=current_height - 1, x=0))\n\n    # Move cursor:\n    if is_done:\n        current_pos = move_cursor(Point(y=current_height, x=0))\n        output.erase_down()\n    else:\n        current_pos = move_cursor(screen.cursor_position)\n\n    if is_done or not use_alternate_screen:\n        output.enable_autowrap()\n\n    # Always reset the color attributes. This is important because a background\n    # thread could print data to stdout and we want that to be displayed in the\n    # default colors. (Also, if a background color has been set, many terminals\n    # give weird artifacs on resize events.)\n    reset_attributes()\n\n    if screen.show_cursor or is_done:\n        output.show_cursor()\n\n    return current_pos, last_token[0]", "response": "Render the diff between this screen and the previous screen."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint a list of tokens to the output.", "response": "def print_tokens(output, tokens, style):\n    \"\"\"\n    Print a list of (Token, text) tuples in the given style to the output.\n    \"\"\"\n    assert isinstance(output, Output)\n    assert isinstance(style, Style)\n\n    # Reset first.\n    output.reset_attributes()\n    output.enable_autowrap()\n\n    # Print all (token, text) tuples.\n    attrs_for_token = _TokenToAttrsCache(style.get_attrs_for_token)\n\n    for token, text in tokens:\n        attrs = attrs_for_token[token]\n\n        if attrs:\n            output.set_attributes(attrs)\n        else:\n            output.reset_attributes()\n\n        output.write(text)\n\n    # Reset again.\n    output.reset_attributes()\n    output.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rows_above_layout(self):\n        if self._in_alternate_screen:\n            return 0\n        elif self._min_available_height > 0:\n            total_rows = self.output.get_size().rows\n            last_screen_height = self._last_screen.height if self._last_screen else 0\n            return total_rows - max(self._min_available_height, last_screen_height)\n        else:\n            raise HeightIsUnknownError('Rows above layout is unknown.')", "response": "Return the number of rows visible in the terminal above the layout."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrequests absolute cursor position.", "response": "def request_absolute_cursor_position(self):\n        \"\"\"\n        Get current cursor position.\n        For vt100: Do CPR request. (answer will arrive later.)\n        For win32: Do API call. (Answer comes immediately.)\n        \"\"\"\n        # Only do this request when the cursor is at the top row. (after a\n        # clear or reset). We will rely on that in `report_absolute_cursor_row`.\n        assert self._cursor_pos.y == 0\n\n        # For Win32, we have an API call to get the number of rows below the\n        # cursor.\n        if is_windows():\n            self._min_available_height = self.output.get_rows_below_cursor_position()\n        else:\n            if self.use_alternate_screen:\n                self._min_available_height = self.output.get_size().rows\n            else:\n                # Asks for a cursor position report (CPR).\n                self.waiting_for_cpr = True\n                self.output.ask_for_cpr()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreports that we know the cursor position is below the cursor.", "response": "def report_absolute_cursor_row(self, row):\n        \"\"\"\n        To be called when we know the absolute cursor position.\n        (As an answer of a \"Cursor Position Request\" response.)\n        \"\"\"\n        # Calculate the amount of rows from the cursor position until the\n        # bottom of the terminal.\n        total_rows = self.output.get_size().rows\n        rows_below_cursor = total_rows - row + 1\n\n        # Set the\n        self._min_available_height = rows_below_cursor\n\n        self.waiting_for_cpr = False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render(self, cli, layout, is_done=False):\n        output = self.output\n\n        # Enter alternate screen.\n        if self.use_alternate_screen and not self._in_alternate_screen:\n            self._in_alternate_screen = True\n            output.enter_alternate_screen()\n\n        # Enable bracketed paste.\n        if not self._bracketed_paste_enabled:\n            self.output.enable_bracketed_paste()\n            self._bracketed_paste_enabled = True\n\n        # Enable/disable mouse support.\n        needs_mouse_support = self.mouse_support(cli)\n\n        if needs_mouse_support and not self._mouse_support_enabled:\n            output.enable_mouse_support()\n            self._mouse_support_enabled = True\n\n        elif not needs_mouse_support and self._mouse_support_enabled:\n            output.disable_mouse_support()\n            self._mouse_support_enabled = False\n\n        # Create screen and write layout to it.\n        size = output.get_size()\n        screen = Screen()\n        screen.show_cursor = False  # Hide cursor by default, unless one of the\n                                    # containers decides to display it.\n        mouse_handlers = MouseHandlers()\n\n        if is_done:\n            height = 0  # When we are done, we don't necessary want to fill up until the bottom.\n        else:\n            height = self._last_screen.height if self._last_screen else 0\n            height = max(self._min_available_height, height)\n\n        # When te size changes, don't consider the previous screen.\n        if self._last_size != size:\n            self._last_screen = None\n\n        # When we render using another style, do a full repaint. (Forget about\n        # the previous rendered screen.)\n        # (But note that we still use _last_screen to calculate the height.)\n        if self.style.invalidation_hash() != self._last_style_hash:\n            self._last_screen = None\n            self._attrs_for_token = None\n        if self._attrs_for_token is None:\n            self._attrs_for_token = _TokenToAttrsCache(self.style.get_attrs_for_token)\n        self._last_style_hash = self.style.invalidation_hash()\n\n        layout.write_to_screen(cli, screen, mouse_handlers, WritePosition(\n            xpos=0,\n            ypos=0,\n            width=size.columns,\n            height=(size.rows if self.use_alternate_screen else height),\n            extended_height=size.rows,\n        ))\n\n        # When grayed. Replace all tokens in the new screen.\n        if cli.is_aborting or cli.is_exiting:\n            screen.replace_all_tokens(Token.Aborted)\n\n        # Process diff and write to output.\n        self._cursor_pos, self._last_token = _output_screen_diff(\n            output, screen, self._cursor_pos,\n            self._last_screen, self._last_token, is_done,\n            use_alternate_screen=self.use_alternate_screen,\n            attrs_for_token=self._attrs_for_token,\n            size=size,\n            previous_width=(self._last_size.columns if self._last_size else 0))\n        self._last_screen = screen\n        self._last_size = size\n        self.mouse_handlers = mouse_handlers\n\n        # Write title if it changed.\n        new_title = cli.terminal_title\n\n        if new_title != self._last_title:\n            if new_title is None:\n                self.output.clear_title()\n            else:\n                self.output.set_title(new_title)\n            self._last_title = new_title\n\n        output.flush()", "response": "Render the current interface to the output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nerasing the current state of the current entry.", "response": "def erase(self, leave_alternate_screen=True, erase_title=True):\n        \"\"\"\n        Hide all output and put the cursor back at the first line. This is for\n        instance used for running a system command (while hiding the CLI) and\n        later resuming the same CLI.)\n\n        :param leave_alternate_screen: When True, and when inside an alternate\n            screen buffer, quit the alternate screen.\n        :param erase_title: When True, clear the title from the title bar.\n        \"\"\"\n        output = self.output\n\n        output.cursor_backward(self._cursor_pos.x)\n        output.cursor_up(self._cursor_pos.y)\n        output.erase_down()\n        output.reset_attributes()\n        output.enable_autowrap()\n        output.flush()\n\n        # Erase title.\n        if self._last_title and erase_title:\n            output.clear_title()\n\n        self.reset(leave_alternate_screen=leave_alternate_screen)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear(self):\n        # Erase current output first.\n        self.erase()\n\n        # Send \"Erase Screen\" command and go to (0, 0).\n        output = self.output\n\n        output.erase_screen()\n        output.cursor_goto(0, 0)\n        output.flush()\n\n        self.request_absolute_cursor_position()", "response": "Clear screen and go to 0 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing all the tokens in the screen with the given token.", "response": "def replace_all_tokens(self, token):\n        \"\"\"\n        For all the characters in the screen. Set the token to the given `token`.\n        \"\"\"\n        b = self.data_buffer\n\n        for y, row in b.items():\n            for x, char in row.items():\n                b[y][x] = _CHAR_CACHE[char.char, token]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlog dropped chunks and updates dynamic settings", "response": "def _handle_response(self, response):\n        \"\"\"Logs dropped chunks and updates dynamic settings\"\"\"\n        if isinstance(response, Exception):\n            logging.error(\"dropped chunk %s\" % response)\n        elif response.json().get(\"limits\"):\n            parsed = response.json()\n            self._api.dynamic_settings.update(parsed[\"limits\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push(self, filename, data):\n        self._queue.put(Chunk(filename, data))", "response": "Push a chunk of a file to the streaming endpoint."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclean up. Anything pushed after finish will be dropped. Args: exitcode: The exitcode of the watched process.", "response": "def finish(self, exitcode):\n        \"\"\"Cleans up.\n\n        Anything pushed after finish will be dropped.\n\n        Args:\n            exitcode: The exitcode of the watched process.\n        \"\"\"\n        self._queue.put(self.Finish(exitcode))\n        self._thread.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a request to the root of a v2 docker registry to get the auth token", "response": "def auth_token(registry, repo):\n    \"\"\"Makes a request to the root of a v2 docker registry to get the auth url.\n\n    Always returns a dictionary, if there's no token key we couldn't authenticate\n    \"\"\"\n    # TODO: Cache tokens?\n    auth_info = auth_config.resolve_authconfig(registry)\n    if auth_info:\n        normalized = {k.lower(): v for k, v in six.iteritems(auth_info)}\n        auth_info = (normalized.get(\"username\"), normalized.get(\"password\"))\n    response = requests.get(\"https://{}/v2/\".format(registry), timeout=3)\n    if response.headers.get(\"www-authenticate\"):\n        try:\n            info = www_authenticate.parse(response.headers['www-authenticate'])\n        except ValueError:\n            info = {}\n    else:\n        log.error(\"Received {} when attempting to authenticate with {}\".format(\n            response, registry))\n        info = {}\n    if info.get(\"bearer\"):\n        res = requests.get(info[\"bearer\"][\"realm\"] +\n                           \"?service={}&scope=repository:{}:pull\".format(\n            info[\"bearer\"][\"service\"], repo), auth=auth_info, timeout=3)\n        res.raise_for_status()\n        return res.json()\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef image_id_from_registry(image_name):\n    registry, repository, tag = parse(image_name)\n    try:\n        token = auth_token(registry, repository).get(\"token\")\n        # dockerhub is crazy\n        if registry == \"index.docker.io\":\n            registry = \"registry-1.docker.io\"\n        res = requests.head(\"https://{}/v2/{}/manifests/{}\".format(registry, repository, tag), headers={\n            \"Authorization\": \"Bearer {}\".format(token),\n            \"Accept\": \"application/vnd.docker.distribution.manifest.v2+json\"\n        }, timeout=5)\n        res.raise_for_status()\n    except requests.RequestException:\n        log.error(\"Received {} when attempting to get digest for {}\".format(\n            res, image_name))\n        return None\n    return \"@\".join([registry+\"/\"+repository, res.headers[\"Docker-Content-Digest\"]])", "response": "Get the docker id from a public or private registry"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compile(expression, escape_funcs=None, unescape_funcs=None):\n    return _compile_from_parse_tree(\n        parse_regex(tokenize_regex(expression)),\n        escape_funcs=escape_funcs,\n        unescape_funcs=unescape_funcs)", "response": "Compile a string containing a grammar and return a CompiledGrammar instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef escape(self, varname, value):\n        f = self.escape_funcs.get(varname)\n        return f(value) if f else value", "response": "Escape the value to fit in the place of this variable into the grammar."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _transform(cls, root_node, create_group_func):\n        def transform(node):\n            # Turn `Any` into an OR.\n            if isinstance(node, Any):\n                return '(?:%s)' % '|'.join(transform(c) for c in node.children)\n\n            # Concatenate a `Sequence`\n            elif isinstance(node, Sequence):\n                return ''.join(transform(c) for c in node.children)\n\n            # For Regex and Lookahead nodes, just insert them literally.\n            elif isinstance(node, Regex):\n                return node.regex\n\n            elif isinstance(node, Lookahead):\n                before = ('(?!' if node.negative else '(=')\n                return before + transform(node.childnode) + ')'\n\n            # A `Variable` wraps the children into a named group.\n            elif isinstance(node, Variable):\n                return '(?P<%s>%s)' % (create_group_func(node), transform(node.childnode))\n\n            # `Repeat`.\n            elif isinstance(node, Repeat):\n                return '(?:%s){%i,%s}%s' % (\n                    transform(node.childnode), node.min_repeat,\n                    ('' if node.max_repeat is None else str(node.max_repeat)),\n                    ('' if node.greedy else '?')\n                )\n            else:\n                raise TypeError('Got %r' % (node, ))\n\n        return transform(root_node)", "response": "Transform a node into a regular expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _transform_prefix(cls, root_node, create_group_func):\n        def transform(node):\n            # Generate regexes for all permutations of this OR. Each node\n            # should be in front once.\n            if isinstance(node, Any):\n                for c in node.children:\n                    for r in transform(c):\n                        yield '(?:%s)?' % r\n\n            # For a sequence. We can either have a match for the sequence\n            # of all the children, or for an exact match of the first X\n            # children, followed by a partial match of the next children.\n            elif isinstance(node, Sequence):\n                for i in range(len(node.children)):\n                    a = [cls._transform(c, create_group_func) for c in node.children[:i]]\n                    for c in transform(node.children[i]):\n                        yield '(?:%s)' % (''.join(a) + c)\n\n            elif isinstance(node, Regex):\n                yield '(?:%s)?' % node.regex\n\n            elif isinstance(node, Lookahead):\n                if node.negative:\n                    yield '(?!%s)' % cls._transform(node.childnode, create_group_func)\n                else:\n                    # Not sure what the correct semantics are in this case.\n                    # (Probably it's not worth implementing this.)\n                    raise Exception('Positive lookahead not yet supported.')\n\n            elif isinstance(node, Variable):\n                # (Note that we should not append a '?' here. the 'transform'\n                # method will already recursively do that.)\n                for c in transform(node.childnode):\n                    yield '(?P<%s>%s)' % (create_group_func(node), c)\n\n            elif isinstance(node, Repeat):\n                # If we have a repetition of 8 times. That would mean that the\n                # current input could have for instance 7 times a complete\n                # match, followed by a partial match.\n                prefix = cls._transform(node.childnode, create_group_func)\n\n                for c in transform(node.childnode):\n                    if node.max_repeat:\n                        repeat_sign = '{,%i}' % (node.max_repeat - 1)\n                    else:\n                        repeat_sign = '*'\n                    yield '(?:%s)%s%s(?:%s)?' % (\n                        prefix,\n                        repeat_sign,\n                        ('' if node.greedy else '?'),\n                        c)\n\n            else:\n                raise TypeError('Got %r' % node)\n\n        for r in transform(root_node):\n            yield '^%s$' % r", "response": "Yield all the regular expressions matching a prefix of the grammar\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmatch the string with the grammar.", "response": "def match(self, string):\n        \"\"\"\n        Match the string with the grammar.\n        Returns a :class:`Match` instance or `None` when the input doesn't match the grammar.\n\n        :param string: The input string.\n        \"\"\"\n        m = self._re.match(string)\n\n        if m:\n            return Match(string, [(self._re, m)], self._group_names_to_nodes, self.unescape_funcs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmatches the input string with the grammar.", "response": "def match_prefix(self, string):\n        \"\"\"\n        Do a partial match of the string with the grammar. The returned\n        :class:`Match` instance can contain multiple representations of the\n        match. This will never return `None`. If it doesn't match at all, the \"trailing input\"\n        part will capture all of the input.\n\n        :param string: The input string.\n        \"\"\"\n        # First try to match using `_re_prefix`. If nothing is found, use the patterns that\n        # also accept trailing characters.\n        for patterns in [self._re_prefix, self._re_prefix_with_trailing_input]:\n            matches = [(r, r.match(string)) for r in patterns]\n            matches = [(r, m) for r, m in matches if m]\n\n            if matches != []:\n                return Match(string, matches, self._group_names_to_nodes, self.unescape_funcs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _nodes_to_regs(self):\n        def get_tuples():\n            for r, re_match in self._re_matches:\n                for group_name, group_index in r.groupindex.items():\n                    if group_name != _INVALID_TRAILING_INPUT:\n                        reg = re_match.regs[group_index]\n                        node = self._group_names_to_nodes[group_name]\n                        yield (node, reg)\n\n        return list(get_tuples())", "response": "Return a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of tuples.", "response": "def _nodes_to_values(self):\n        \"\"\"\n        Returns list of list of (Node, string_value) tuples.\n        \"\"\"\n        def is_none(slice):\n            return slice[0] == -1 and slice[1] == -1\n\n        def get(slice):\n            return self.string[slice[0]:slice[1]]\n\n        return [(varname, get(slice), slice) for varname, slice in self._nodes_to_regs() if not is_none(slice)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of variables that are part of the current node.", "response": "def variables(self):\n        \"\"\"\n        Returns :class:`Variables` instance.\n        \"\"\"\n        return Variables([(k, self._unescape(k, v), sl) for k, v, sl in self._nodes_to_values()])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trailing_input(self):\n        slices = []\n\n        # Find all regex group for the name _INVALID_TRAILING_INPUT.\n        for r, re_match in self._re_matches:\n            for group_name, group_index in r.groupindex.items():\n                if group_name == _INVALID_TRAILING_INPUT:\n                    slices.append(re_match.regs[group_index])\n\n        # Take the smallest part. (Smaller trailing text means that a larger input has\n        # been matched, so that is better.)\n        if slices:\n            slice = [max(i[0] for i in slices), max(i[1] for i in slices)]\n            value = self.string[slice[0]:slice[1]]\n            return MatchVariable('<trailing_input>', value, slice)", "response": "Return the MatchVariable instance representing trailing input."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields all the MatchVariable instances for all the nodes having their end position at the end of the input string.", "response": "def end_nodes(self):\n        \"\"\"\n        Yields `MatchVariable` instances for all the nodes having their end\n        position at the end of the input string.\n        \"\"\"\n        for varname, reg in self._nodes_to_regs():\n            # If this part goes until the end of the input string.\n            if reg[1] == len(self.string):\n                value = self._unescape(varname, self.string[reg[0]: reg[1]])\n                yield MatchVariable(varname, value, (reg[0], reg[1]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reset(self, mode=InputMode.INSERT):\n        # Go back to insert mode.\n        self.input_mode = mode\n\n        self.waiting_for_digraph = False\n        self.operator_func = None\n        self.operator_arg = None", "response": "Reset the state of the current node to the given mode. INSERT by default."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_buffer(self, name, buffer, focus=False):\n        assert isinstance(buffer, Buffer)\n        self.buffers[name] = buffer\n\n        if focus:\n            self.buffers.focus(name)\n\n        # Create asynchronous completer / auto suggestion.\n        auto_suggest_function = self._create_auto_suggest_function(buffer)\n        completer_function = self._create_async_completer(buffer)\n        self._async_completers[name] = completer_function\n\n        # Complete/suggest on text insert.\n        def create_on_insert_handler():\n            \"\"\"\n            Wrapper around the asynchronous completer and auto suggestion, that\n            ensures that it's only called while typing if the\n            `complete_while_typing` filter is enabled.\n            \"\"\"\n            def on_text_insert(_):\n                # Only complete when \"complete_while_typing\" is enabled.\n                if buffer.completer and buffer.complete_while_typing():\n                    completer_function()\n\n                # Call auto_suggest.\n                if buffer.auto_suggest:\n                    auto_suggest_function()\n\n            return on_text_insert\n\n        buffer.on_text_insert += create_on_insert_handler()\n\n        def buffer_changed(_):\n            \"\"\"\n            When the text in a buffer changes.\n            (A paste event is also a change, but not an insert. So we don't\n            want to do autocompletions in this case, but we want to propagate\n            the on_buffer_changed event.)\n            \"\"\"\n            # Trigger on_buffer_changed.\n            self.on_buffer_changed.fire()\n\n        buffer.on_text_changed += buffer_changed", "response": "Adds a new buffer to the list of available buffers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting asynchronous completion of this buffer.", "response": "def start_completion(self, buffer_name=None, select_first=False,\n                         select_last=False, insert_common_part=False,\n                         complete_event=None):\n        \"\"\"\n        Start asynchronous autocompletion of this buffer.\n        (This will do nothing if a previous completion was still in progress.)\n        \"\"\"\n        buffer_name = buffer_name or self.current_buffer_name\n        completer = self._async_completers.get(buffer_name)\n\n        if completer:\n            completer(select_first=select_first,\n                      select_last=select_last,\n                      insert_common_part=insert_common_part,\n                      complete_event=CompleteEvent(completion_requested=True))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef terminal_title(self):\n        result = self.application.get_title()\n\n        # Make sure that this function returns a unicode object,\n        # and not a byte string.\n        assert result is None or isinstance(result, six.text_type)\n        return result", "response": "Return the current title to be displayed in the terminal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset(self, reset_current_buffer=False):\n        # Notice that we don't reset the buffers. (This happens just before\n        # returning, and when we have multiple buffers, we clearly want the\n        # content in the other buffers to remain unchanged between several\n        # calls of `run`. (And the same is true for the focus stack.)\n\n        self._exit_flag = False\n        self._abort_flag = False\n\n        self._return_value = None\n\n        self.renderer.reset()\n        self.input_processor.reset()\n        self.layout.reset()\n        self.vi_state.reset()\n\n        # Search new search state. (Does also remember what has to be\n        # highlighted.)\n        self.search_state = SearchState(ignore_case=Condition(lambda: self.is_ignoring_case))\n\n        # Trigger reset event.\n        self.on_reset.fire()", "response": "Reset all buffers and the state of the current command line entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef invalidate(self):\n        # Never schedule a second redraw, when a previous one has not yet been\n        # executed. (This should protect against other threads calling\n        # 'invalidate' many times, resulting in 100% CPU.)\n        if self._invalidated:\n            return\n        else:\n            self._invalidated = True\n\n        # Trigger event.\n        self.on_invalidate.fire()\n\n        if self.eventloop is not None:\n            def redraw():\n                self._invalidated = False\n                self._redraw()\n\n            # Call redraw in the eventloop (thread safe).\n            # Usually with the high priority, in order to make the application\n            # feel responsive, but this can be tuned by changing the value of\n            # `max_render_postpone_time`.\n            if self.max_render_postpone_time:\n                _max_postpone_until = time.time() + self.max_render_postpone_time\n            else:\n                _max_postpone_until = None\n\n            self.eventloop.call_from_executor(\n                redraw, _max_postpone_until=_max_postpone_until)", "response": "Invalidate the current entry in the event loop."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nredraw the command line again.", "response": "def _redraw(self):\n        \"\"\"\n        Render the command line again. (Not thread safe!) (From other threads,\n        or if unsure, use :meth:`.CommandLineInterface.invalidate`.)\n        \"\"\"\n        # Only draw when no sub application was started.\n        if self._is_running and self._sub_cli is None:\n            self.render_counter += 1\n            self.renderer.render(self, self.layout, is_done=self.is_done)\n\n            # Fire render event.\n            self.on_render.fire()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _on_resize(self):\n        # Erase, request position (when cursor is at the start position)\n        # and redraw again. -- The order is important.\n        self.renderer.erase(leave_alternate_screen=False, erase_title=False)\n        self.renderer.request_absolute_cursor_position()\n        self._redraw()", "response": "Called when the window size changes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, reset_current_buffer=False, pre_run=None):\n        assert pre_run is None or callable(pre_run)\n\n        try:\n            self._is_running = True\n\n            self.on_start.fire()\n            self.reset()\n\n            # Call pre_run.\n            self._pre_run(pre_run)\n\n            # Run eventloop in raw mode.\n            with self.input.raw_mode():\n                self.renderer.request_absolute_cursor_position()\n                self._redraw()\n\n                self.eventloop.run(self.input, self.create_eventloop_callbacks())\n        finally:\n            # Clean up renderer. (This will leave the alternate screen, if we use\n            # that.)\n\n            # If exit/abort haven't been called set, but another exception was\n            # thrown instead for some reason, make sure that we redraw in exit\n            # mode.\n            if not self.is_done:\n                self._exit_flag = True\n                self._redraw()\n\n            self.renderer.reset()\n            self.on_stop.fire()\n            self._is_running = False\n\n        # Return result.\n        return self.return_value()", "response": "Runs the eventloop until a return value has been set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a sub application.", "response": "def run_sub_application(self, application, done_callback=None, erase_when_done=False,\n                            _from_application_generator=False):\n        # `erase_when_done` is deprecated, set Application.erase_when_done instead.\n        \"\"\"\n        Run a sub :class:`~prompt_toolkit.application.Application`.\n\n        This will suspend the main application and display the sub application\n        until that one returns a value. The value is returned by calling\n        `done_callback` with the result.\n\n        The sub application will share the same I/O of the main application.\n        That means, it uses the same input and output channels and it shares\n        the same event loop.\n\n        .. note:: Technically, it gets another Eventloop instance, but that is\n            only a proxy to our main event loop. The reason is that calling\n            'stop' --which returns the result of an application when it's\n            done-- is handled differently.\n        \"\"\"\n        assert isinstance(application, Application)\n        assert done_callback is None or callable(done_callback)\n\n        if self._sub_cli is not None:\n            raise RuntimeError('Another sub application started already.')\n\n        # Erase current application.\n        if not _from_application_generator:\n            self.renderer.erase()\n\n        # Callback when the sub app is done.\n        def done():\n            # Redraw sub app in done state.\n            # and reset the renderer. (This reset will also quit the alternate\n            # screen, if the sub application used that.)\n            sub_cli._redraw()\n            if erase_when_done or application.erase_when_done:\n                sub_cli.renderer.erase()\n            sub_cli.renderer.reset()\n            sub_cli._is_running = False  # Don't render anymore.\n\n            self._sub_cli = None\n\n            # Restore main application.\n            if not _from_application_generator:\n                self.renderer.request_absolute_cursor_position()\n                self._redraw()\n\n            # Deliver result.\n            if done_callback:\n                done_callback(sub_cli.return_value())\n\n        # Create sub CommandLineInterface.\n        sub_cli = CommandLineInterface(\n            application=application,\n            eventloop=_SubApplicationEventLoop(self, done),\n            input=self.input,\n            output=self.output)\n        sub_cli._is_running = True  # Allow rendering of sub app.\n\n        sub_cli._redraw()\n        self._sub_cli = sub_cli"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets exit. When Control - D has been pressed.", "response": "def exit(self):\n        \"\"\"\n        Set exit. When Control-D has been pressed.\n        \"\"\"\n        on_exit = self.application.on_exit\n        self._exit_flag = True\n        self._redraw()\n\n        if on_exit == AbortAction.RAISE_EXCEPTION:\n            def eof_error():\n                raise EOFError()\n            self._set_return_callable(eof_error)\n\n        elif on_exit == AbortAction.RETRY:\n            self.reset()\n            self.renderer.request_absolute_cursor_position()\n            self.current_buffer.reset()\n\n        elif on_exit == AbortAction.RETURN_NONE:\n            self.set_return_value(None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets abort. When Control - C has been pressed.", "response": "def abort(self):\n        \"\"\"\n        Set abort. When Control-C has been pressed.\n        \"\"\"\n        on_abort = self.application.on_abort\n        self._abort_flag = True\n        self._redraw()\n\n        if on_abort == AbortAction.RAISE_EXCEPTION:\n            def keyboard_interrupt():\n                raise KeyboardInterrupt()\n            self._set_return_callable(keyboard_interrupt)\n\n        elif on_abort == AbortAction.RETRY:\n            self.reset()\n            self.renderer.request_absolute_cursor_position()\n            self.current_buffer.reset()\n\n        elif on_abort == AbortAction.RETURN_NONE:\n            self.set_return_value(None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun the function func on the terminal.", "response": "def run_in_terminal(self, func, render_cli_done=False, cooked_mode=True):\n        \"\"\"\n        Run function on the terminal above the prompt.\n\n        What this does is first hiding the prompt, then running this callable\n        (which can safely output to the terminal), and then again rendering the\n        prompt which causes the output of this function to scroll above the\n        prompt.\n\n        :param func: The callable to execute.\n        :param render_cli_done: When True, render the interface in the\n                'Done' state first, then execute the function. If False,\n                erase the interface first.\n        :param cooked_mode: When True (the default), switch the input to\n                cooked mode while executing the function.\n\n        :returns: the result of `func`.\n        \"\"\"\n        # Draw interface in 'done' state, or erase.\n        if render_cli_done:\n            self._return_value = True\n            self._redraw()\n            self.renderer.reset()  # Make sure to disable mouse mode, etc...\n        else:\n            self.renderer.erase()\n        self._return_value = None\n\n        # Run system command.\n        if cooked_mode:\n            with self.input.cooked_mode():\n                result = func()\n        else:\n            result = func()\n\n        # Redraw interface again.\n        self.renderer.reset()\n        self.renderer.request_absolute_cursor_position()\n        self._redraw()\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_application_generator(self, coroutine, render_cli_done=False):\n        # Draw interface in 'done' state, or erase.\n        if render_cli_done:\n            self._return_value = True\n            self._redraw()\n            self.renderer.reset()  # Make sure to disable mouse mode, etc...\n        else:\n            self.renderer.erase()\n        self._return_value = None\n\n        # Loop through the generator.\n        g = coroutine()\n        assert isinstance(g, types.GeneratorType)\n\n        def step_next(send_value=None):\n            \" Execute next step of the coroutine.\"\n            try:\n                # Run until next yield, in cooked mode.\n                with self.input.cooked_mode():\n                    result = g.send(send_value)\n            except StopIteration:\n                done()\n            except:\n                done()\n                raise\n            else:\n                # Process yielded value from coroutine.\n                assert isinstance(result, Application)\n                self.run_sub_application(result, done_callback=step_next,\n                                         _from_application_generator=True)\n\n        def done():\n            # Redraw interface again.\n            self.renderer.reset()\n            self.renderer.request_absolute_cursor_position()\n            self._redraw()\n\n        # Start processing coroutine.\n        step_next()", "response": "A generator that yields Application instances and runs them in the terminal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning a system command in the terminal.", "response": "def run_system_command(self, command):\n        \"\"\"\n        Run system command (While hiding the prompt. When finished, all the\n        output will scroll above the prompt.)\n\n        :param command: Shell command to be executed.\n        \"\"\"\n        def wait_for_enter():\n            \"\"\"\n            Create a sub application to wait for the enter key press.\n            This has two advantages over using 'input'/'raw_input':\n            - This will share the same input/output I/O.\n            - This doesn't block the event loop.\n            \"\"\"\n            from .shortcuts import create_prompt_application\n\n            registry = Registry()\n\n            @registry.add_binding(Keys.ControlJ)\n            @registry.add_binding(Keys.ControlM)\n            def _(event):\n                event.cli.set_return_value(None)\n\n            application = create_prompt_application(\n                message='Press ENTER to continue...',\n                key_bindings_registry=registry)\n            self.run_sub_application(application)\n\n        def run():\n            # Try to use the same input/output file descriptors as the one,\n            # used to run this application.\n            try:\n                input_fd = self.input.fileno()\n            except AttributeError:\n                input_fd = sys.stdin.fileno()\n            try:\n                output_fd = self.output.fileno()\n            except AttributeError:\n                output_fd = sys.stdout.fileno()\n\n            # Run sub process.\n            # XXX: This will still block the event loop.\n            p = Popen(command, shell=True,\n                      stdin=input_fd, stdout=output_fd)\n            p.wait()\n\n            # Wait for the user to press enter.\n            wait_for_enter()\n\n        self.run_in_terminal(run)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsuspending the current process to background.", "response": "def suspend_to_background(self, suspend_group=True):\n        \"\"\"\n        (Not thread safe -- to be called from inside the key bindings.)\n        Suspend process.\n\n        :param suspend_group: When true, suspend the whole process group.\n            (This is the default, and probably what you want.)\n        \"\"\"\n        # Only suspend when the opperating system supports it.\n        # (Not on Windows.)\n        if hasattr(signal, 'SIGTSTP'):\n            def run():\n                # Send `SIGSTP` to own process.\n                # This will cause it to suspend.\n\n                # Usually we want the whole process group to be suspended. This\n                # handles the case when input is piped from another process.\n                if suspend_group:\n                    os.kill(0, signal.SIGTSTP)\n                else:\n                    os.kill(os.getpid(), signal.SIGTSTP)\n\n            self.run_in_terminal(run)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting a list of tokens to the output.", "response": "def print_tokens(self, tokens, style=None):\n        \"\"\"\n        Print a list of (Token, text) tuples to the output.\n        (When the UI is running, this method has to be called through\n        `run_in_terminal`, otherwise it will destroy the UI.)\n\n        :param style: Style class to use. Defaults to the active style in the CLI.\n        \"\"\"\n        print_tokens(self.output, tokens, style or self.application.style)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating function for asynchronous autocompletion.", "response": "def _create_async_completer(self, buffer):\n        \"\"\"\n        Create function for asynchronous autocompletion.\n        (Autocomplete in other thread.)\n        \"\"\"\n        complete_thread_running = [False]  # By ref.\n\n        def completion_does_nothing(document, completion):\n            \"\"\"\n            Return `True` if applying this completion doesn't have any effect.\n            (When it doesn't insert any new text.\n            \"\"\"\n            text_before_cursor = document.text_before_cursor\n            replaced_text = text_before_cursor[\n                len(text_before_cursor) + completion.start_position:]\n            return replaced_text == completion.text\n\n        def async_completer(select_first=False, select_last=False,\n                            insert_common_part=False, complete_event=None):\n            document = buffer.document\n            complete_event = complete_event or CompleteEvent(text_inserted=True)\n\n            # Don't start two threads at the same time.\n            if complete_thread_running[0]:\n                return\n\n            # Don't complete when we already have completions.\n            if buffer.complete_state or not buffer.completer:\n                return\n\n            # Otherwise, get completions in other thread.\n            complete_thread_running[0] = True\n\n            def run():\n                completions = list(buffer.completer.get_completions(document, complete_event))\n\n                def callback():\n                    \"\"\"\n                    Set the new complete_state in a safe way. Don't replace an\n                    existing complete_state if we had one. (The user could have\n                    pressed 'Tab' in the meantime. Also don't set it if the text\n                    was changed in the meantime.\n                    \"\"\"\n                    complete_thread_running[0] = False\n\n                    # When there is only one completion, which has nothing to add, ignore it.\n                    if (len(completions) == 1 and\n                            completion_does_nothing(document, completions[0])):\n                        del completions[:]\n\n                    # Set completions if the text was not yet changed.\n                    if buffer.text == document.text and \\\n                            buffer.cursor_position == document.cursor_position and \\\n                            not buffer.complete_state:\n\n                        set_completions = True\n                        select_first_anyway = False\n\n                        # When the common part has to be inserted, and there\n                        # is a common part.\n                        if insert_common_part:\n                            common_part = get_common_complete_suffix(document, completions)\n                            if common_part:\n                                # Insert the common part, update completions.\n                                buffer.insert_text(common_part)\n                                if len(completions) > 1:\n                                    # (Don't call `async_completer` again, but\n                                    # recalculate completions. See:\n                                    # https://github.com/ipython/ipython/issues/9658)\n                                    completions[:] = [\n                                        c.new_completion_from_position(len(common_part))\n                                        for c in completions]\n                                else:\n                                    set_completions = False\n                            else:\n                                # When we were asked to insert the \"common\"\n                                # prefix, but there was no common suffix but\n                                # still exactly one match, then select the\n                                # first. (It could be that we have a completion\n                                # which does * expansion, like '*.py', with\n                                # exactly one match.)\n                                if len(completions) == 1:\n                                    select_first_anyway = True\n\n                        if set_completions:\n                            buffer.set_completions(\n                                completions=completions,\n                                go_to_first=select_first or select_first_anyway,\n                                go_to_last=select_last)\n                        self.invalidate()\n                    elif not buffer.complete_state:\n                        # Otherwise, restart thread.\n                        async_completer()\n\n                if self.eventloop:\n                    self.eventloop.call_from_executor(callback)\n\n            self.eventloop.run_in_executor(run)\n        return async_completer"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_auto_suggest_function(self, buffer):\n        suggest_thread_running = [False]  # By ref.\n\n        def async_suggestor():\n            document = buffer.document\n\n            # Don't start two threads at the same time.\n            if suggest_thread_running[0]:\n                return\n\n            # Don't suggest when we already have a suggestion.\n            if buffer.suggestion or not buffer.auto_suggest:\n                return\n\n            # Otherwise, get completions in other thread.\n            suggest_thread_running[0] = True\n\n            def run():\n                suggestion = buffer.auto_suggest.get_suggestion(self, buffer, document)\n\n                def callback():\n                    suggest_thread_running[0] = False\n\n                    # Set suggestion only if the text was not yet changed.\n                    if buffer.text == document.text and \\\n                            buffer.cursor_position == document.cursor_position:\n\n                        # Set suggestion and redraw interface.\n                        buffer.suggestion = suggestion\n                        self.invalidate()\n                    else:\n                        # Otherwise, restart thread.\n                        async_suggestor()\n\n                if self.eventloop:\n                    self.eventloop.call_from_executor(callback)\n\n            self.eventloop.run_in_executor(run)\n        return async_suggestor", "response": "Create function for asynchronous auto suggestion."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a context manager that will replace sys. stdout with a proxy containing the current stdout and sys. stderr.", "response": "def patch_stdout_context(self, raw=False, patch_stdout=True, patch_stderr=True):\n        \"\"\"\n        Return a context manager that will replace ``sys.stdout`` with a proxy\n        that makes sure that all printed text will appear above the prompt, and\n        that it doesn't destroy the output from the renderer.\n\n        :param patch_stdout: Replace `sys.stdout`.\n        :param patch_stderr: Replace `sys.stderr`.\n        \"\"\"\n        return _PatchStdoutContext(\n            self.stdout_proxy(raw=raw),\n            patch_stdout=patch_stdout, patch_stderr=patch_stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _active_cli(self):\n        cli = self.cli\n\n        # If there is a sub CLI. That one is always active.\n        while cli._sub_cli:\n            cli = cli._sub_cli\n\n        return cli", "response": "Return the active CommandLineInterface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef feed_key(self, key_press):\n        assert isinstance(key_press, KeyPress)\n        cli = self._active_cli\n\n        # Feed the key and redraw.\n        # (When the CLI is in 'done' state, it should return to the event loop\n        # as soon as possible. Ignore all key presses beyond this point.)\n        if not cli.is_done:\n            cli.input_processor.feed(key_press)\n            cli.input_processor.process_keys()", "response": "Feed a key press to the CommandLineInterface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write(self, data):\n        if '\\n' in data:\n            # When there is a newline in the data, write everything before the\n            # newline, including the newline itself.\n            before, after = data.rsplit('\\n', 1)\n            to_write = self._buffer + [before, '\\n']\n            self._buffer = [after]\n\n            def run():\n                for s in to_write:\n                    if self._raw:\n                        self._cli.output.write_raw(s)\n                    else:\n                        self._cli.output.write(s)\n            self._do(run)\n        else:\n            # Otherwise, cache in buffer.\n            self._buffer.append(data)", "response": "Write the data to the output terminal."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsum a list of LayoutDimension instances.", "response": "def sum_layout_dimensions(dimensions):\n    \"\"\"\n    Sum a list of :class:`.LayoutDimension` instances.\n    \"\"\"\n    min = sum([d.min for d in dimensions if d.min is not None])\n    max = sum([d.max for d in dimensions if d.max is not None])\n    preferred = sum([d.preferred for d in dimensions])\n\n    return LayoutDimension(min=min, max=max, preferred=preferred)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef max_layout_dimensions(dimensions):\n    min_ = max([d.min for d in dimensions if d.min is not None])\n    max_ = max([d.max for d in dimensions if d.max is not None])\n    preferred = max([d.preferred for d in dimensions])\n\n    return LayoutDimension(min=min_, max=max_, preferred=preferred)", "response": "Take the maximum of a list of LayoutDimension instances."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a : class :. LayoutDimension with an exact size.", "response": "def exact(cls, amount):\n        \"\"\"\n        Return a :class:`.LayoutDimension` with an exact size. (min, max and\n        preferred set to ``amount``).\n        \"\"\"\n        return cls(min=amount, max=amount, preferred=amount)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_mouse_handler_for_range(self, x_min, x_max, y_min, y_max, handler=None):\n        for x, y in product(range(x_min, x_max), range(y_min, y_max)):\n            self.mouse_handlers[x,y] = handler", "response": "Set mouse handler for a region."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_message(self, options):\n        if not options.get(\"save_policy\"):\n            raise ValueError(\"Only configuring save_policy is supported\")\n        if self.socket:\n            self.socket.send(options)\n        elif self._jupyter_agent:\n            self._jupyter_agent.start()\n            self._jupyter_agent.rm.update_user_file_policy(\n                options[\"save_policy\"])\n        else:\n            wandb.termerror(\n                \"wandb.init hasn't been called, can't configure run\")", "response": "Sends a message to the wandb process changing the policy\n        of saved files."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new Run object from the given environment or defaults.", "response": "def from_environment_or_defaults(cls, environment=None):\n        \"\"\"Create a Run object taking values from the local environment where possible.\n\n        The run ID comes from WANDB_RUN_ID or is randomly generated.\n        The run mode (\"dryrun\", or \"run\") comes from WANDB_MODE or defaults to \"dryrun\".\n        The run directory comes from WANDB_RUN_DIR or is generated from the run ID.\n\n        The Run will have a .config attribute but its run directory won't be set by\n        default.\n        \"\"\"\n        if environment is None:\n            environment = os.environ\n        run_id = environment.get(env.RUN_ID)\n        resume = environment.get(env.RESUME)\n        storage_id = environment.get(env.RUN_STORAGE_ID)\n        mode = environment.get(env.MODE)\n        disabled = InternalApi().disabled()\n        if not mode and disabled:\n            mode = \"dryrun\"\n        elif disabled and mode != \"dryrun\":\n            wandb.termlog(\n                \"WARNING: WANDB_MODE is set to run, but W&B was disabled.  Run `wandb on` to remove this message\")\n        elif disabled:\n            wandb.termlog(\n                'W&B is disabled in this directory.  Run `wandb on` to enable cloud syncing.')\n\n        group = environment.get(env.RUN_GROUP)\n        job_type = environment.get(env.JOB_TYPE)\n        run_dir = environment.get(env.RUN_DIR)\n        sweep_id = environment.get(env.SWEEP_ID)\n        program = environment.get(env.PROGRAM)\n        description = environment.get(env.DESCRIPTION)\n        args = env.get_args()\n        wandb_dir = env.get_dir()\n        tags = env.get_tags()\n        config = Config.from_environment_or_defaults()\n        run = cls(run_id, mode, run_dir,\n                  group, job_type, config,\n                  sweep_id, storage_id, program=program, description=description,\n                  args=args, wandb_dir=wandb_dir, tags=tags,\n                  resume=resume)\n        return run"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the environment variables needed to reconstruct this object inside a user script.", "response": "def set_environment(self, environment=None):\n        \"\"\"Set environment variables needed to reconstruct this object inside\n        a user scripts (eg. in `wandb.init()`).\n        \"\"\"\n        if environment is None:\n            environment = os.environ\n        environment[env.RUN_ID] = self.id\n        environment[env.RESUME] = self.resume\n        if self.storage_id:\n            environment[env.RUN_STORAGE_ID] = self.storage_id\n        environment[env.MODE] = self.mode\n        environment[env.RUN_DIR] = self.dir\n\n        if self.group:\n            environment[env.RUN_GROUP] = self.group\n        if self.job_type:\n            environment[env.JOB_TYPE] = self.job_type\n        if self.wandb_dir:\n            environment[env.DIR] = self.wandb_dir\n        if self.sweep_id is not None:\n            environment[env.SWEEP_ID] = self.sweep_id\n        if self.program is not None:\n            environment[env.PROGRAM] = self.program\n        if self.args is not None:\n            environment[env.ARGS] = json.dumps(self.args)\n        if self.name_and_description is not None:\n            environment[env.DESCRIPTION] = self.name_and_description\n        if len(self.tags) > 0:\n            environment[env.TAGS] = \",\".join(self.tags)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef upload_debug(self):\n        if os.path.exists(self.log_fname):\n            api = InternalApi()\n            api.set_current_run_id(self.id)\n            pusher = FilePusher(api)\n            pusher.update_file(\"wandb-debug.log\", self.log_fname)\n            pusher.file_changed(\"wandb-debug.log\", self.log_fname)\n            pusher.finish()", "response": "Uploads the debug log to cloud storage"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenables logging to the global debug log.", "response": "def enable_logging(self):\n        \"\"\"Enable logging to the global debug log.  This adds a run_id to the log,\n        in case of muliple processes on the same machine.\n\n        Currently no way to disable logging after it's enabled.\n        \"\"\"\n        handler = logging.FileHandler(self.log_fname)\n        handler.setLevel(logging.INFO)\n        run_id = self.id\n\n        class WBFilter(logging.Filter):\n            def filter(self, record):\n                record.run_id = run_id\n                return True\n\n        formatter = logging.Formatter(\n            '%(asctime)s %(levelname)-7s %(threadName)-10s:%(process)d [%(run_id)s:%(filename)s:%(funcName)s():%(lineno)s] %(message)s')\n        handler.setFormatter(formatter)\n        handler.addFilter(WBFilter())\n\n        root = logging.getLogger()\n        root.addHandler(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose open files to avoid Python warnings on termination", "response": "def close_files(self):\n        \"\"\"Close open files to avoid Python warnings on termination:\n\n        Exception ignored in: <_io.FileIO name='wandb/dryrun-20180130_144602-9vmqjhgy/wandb-history.jsonl' mode='wb' closefd=True>\n        ResourceWarning: unclosed file <_io.TextIOWrapper name='wandb/dryrun-20180130_144602-9vmqjhgy/wandb-history.jsonl' mode='w' encoding='UTF-8'>\n        \"\"\"\n        if self._events is not None:\n            self._events.close()\n            self._events = None\n        if self._history is not None:\n            self._history.close()\n            self._history = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays the completions for the current line.", "response": "def display_completions_like_readline(event):\n    \"\"\"\n    Key binding handler for readline-style tab completion.\n    This is meant to be as similar as possible to the way how readline displays\n    completions.\n\n    Generate the completions immediately (blocking) and display them above the\n    prompt in columns.\n\n    Usage::\n\n        # Call this handler when 'Tab' has been pressed.\n        registry.add_binding(Keys.ControlI)(display_completions_like_readline)\n    \"\"\"\n    # Request completions.\n    b = event.current_buffer\n    if b.completer is None:\n        return\n    complete_event = CompleteEvent(completion_requested=True)\n    completions = list(b.completer.get_completions(b.document, complete_event))\n\n    # Calculate the common suffix.\n    common_suffix = get_common_complete_suffix(b.document, completions)\n\n    # One completion: insert it.\n    if len(completions) == 1:\n        b.delete_before_cursor(-completions[0].start_position)\n        b.insert_text(completions[0].text)\n    # Multiple completions with common part.\n    elif common_suffix:\n        b.insert_text(common_suffix)\n    # Otherwise: display all completions.\n    elif completions:\n        _display_completions_like_readline(event.cli, completions)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _display_completions_like_readline(cli, completions):\n    from prompt_toolkit.shortcuts import create_confirm_application\n    assert isinstance(completions, list)\n\n    # Get terminal dimensions.\n    term_size = cli.output.get_size()\n    term_width = term_size.columns\n    term_height = term_size.rows\n\n    # Calculate amount of required columns/rows for displaying the\n    # completions. (Keep in mind that completions are displayed\n    # alphabetically column-wise.)\n    max_compl_width = min(term_width,\n        max(get_cwidth(c.text) for c in completions) + 1)\n    column_count = max(1, term_width // max_compl_width)\n    completions_per_page = column_count * (term_height - 1)\n    page_count = int(math.ceil(len(completions) / float(completions_per_page)))\n        # Note: math.ceil can return float on Python2.\n\n    def display(page):\n        # Display completions.\n        page_completions = completions[page * completions_per_page:\n                                       (page+1) * completions_per_page]\n\n        page_row_count = int(math.ceil(len(page_completions) / float(column_count)))\n        page_columns = [page_completions[i * page_row_count:(i+1) * page_row_count]\n                   for i in range(column_count)]\n\n        result = []\n        for r in range(page_row_count):\n            for c in range(column_count):\n                try:\n                    result.append(page_columns[c][r].text.ljust(max_compl_width))\n                except IndexError:\n                    pass\n            result.append('\\n')\n        cli.output.write(''.join(result))\n        cli.output.flush()\n\n    # User interaction through an application generator function.\n    def run():\n        if len(completions) > completions_per_page:\n            # Ask confirmation if it doesn't fit on the screen.\n            message = 'Display all {} possibilities? (y on n) '.format(len(completions))\n            confirm = yield create_confirm_application(message)\n\n            if confirm:\n                # Display pages.\n                for page in range(page_count):\n                    display(page)\n\n                    if page != page_count - 1:\n                        # Display --MORE-- and go to the next page.\n                        show_more = yield _create_more_application()\n                        if not show_more:\n                            return\n            else:\n                cli.output.write('\\n'); cli.output.flush()\n        else:\n            # Display all completions.\n            display(0)\n\n    cli.run_application_generator(run, render_cli_done=True)", "response": "Display the list of completions in columns above the prompt."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_more_application():\n    from prompt_toolkit.shortcuts import create_prompt_application\n    registry = Registry()\n\n    @registry.add_binding(' ')\n    @registry.add_binding('y')\n    @registry.add_binding('Y')\n    @registry.add_binding(Keys.ControlJ)\n    @registry.add_binding(Keys.ControlI)  # Tab.\n    def _(event):\n        event.cli.set_return_value(True)\n\n    @registry.add_binding('n')\n    @registry.add_binding('N')\n    @registry.add_binding('q')\n    @registry.add_binding('Q')\n    @registry.add_binding(Keys.ControlC)\n    def _(event):\n        event.cli.set_return_value(False)\n\n    return create_prompt_application(\n        '--MORE--', key_bindings_registry=registry, erase_when_done=True)", "response": "Create an application that displays the MORE."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a boolean or CLIFilter instance into a SimpleFilter instance.", "response": "def to_simple_filter(bool_or_filter):\n    \"\"\"\n    Accept both booleans and CLIFilters as input and\n    turn it into a SimpleFilter.\n    \"\"\"\n    if not isinstance(bool_or_filter, (bool, SimpleFilter)):\n        raise TypeError('Expecting a bool or a SimpleFilter instance. Got %r' % bool_or_filter)\n\n    return {\n        True: _always,\n        False: _never,\n    }.get(bool_or_filter, bool_or_filter)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_cli_filter(bool_or_filter):\n    if not isinstance(bool_or_filter, (bool, CLIFilter)):\n        raise TypeError('Expecting a bool or a CLIFilter instance. Got %r' % bool_or_filter)\n\n    return {\n        True: _always,\n        False: _never,\n    }.get(bool_or_filter, bool_or_filter)", "response": "Convert a boolean or CLIFilter instance into a CLIFilter instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, count=1024):\n            # By default we choose a rather small chunk size, because reading\n            # big amounts of input at once, causes the event loop to process\n            # all these key bindings also at once without going back to the\n            # loop. This will make the application feel unresponsive.\n        \"\"\"\n        Read the input and return it as a string.\n\n        Return the text. Note that this can return an empty string, even when\n        the input stream was not yet closed. This means that something went\n        wrong during the decoding.\n        \"\"\"\n        if self.closed:\n            return b''\n\n        # Note: the following works better than wrapping `self.stdin` like\n        #       `codecs.getreader('utf-8')(stdin)` and doing `read(1)`.\n        #       Somehow that causes some latency when the escape\n        #       character is pressed. (Especially on combination with the `select`.)\n        try:\n            data = os.read(self.stdin_fd, count)\n\n            # Nothing more to read, stream is closed.\n            if data == b'':\n                self.closed = True\n                return ''\n        except OSError:\n            # In case of SIGWINCH\n            data = b''\n\n        return self._stdin_decoder.decode(data)", "response": "Read the next count bytes from the input stream and return it as a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses some data splitting it into complete lines buffering the rest into the current one", "response": "def add_string(self, data):\n        \"\"\"Process some data splitting it into complete lines and buffering the rest\n\n        Args:\n            data: A `str` in Python 2 or `bytes` in Python 3\n        Returns:\n            list of complete lines ending with a carriage return (eg. a progress\n            bar) or a newline.\n        \"\"\"\n        lines = []\n        while data:\n            match = self._line_end_re.search(data)\n            if match is None:\n                chunk = data\n            else:\n                chunk = data[:match.end()]\n\n            data = data[len(chunk):]\n\n            if self._buf and self._buf[-1].endswith(b('\\r')) and not chunk.startswith(b('\\n')):\n                # if we get a carriage return followed by something other than\n                # a newline then we assume that we're overwriting the current\n                # line (ie. a progress bar)\n                #\n                # We don't terminate lines that end with a carriage return until\n                # we see what's coming next so we can distinguish between a\n                # progress bar situation and a Windows line terminator.\n                #\n                # TODO(adrian): some day these hacks should be replaced with\n                # real terminal emulation\n                lines.append(self._finish_line())\n\n            self._buf.append(chunk)\n            if chunk.endswith(b('\\n')):\n                lines.append(self._finish_line())\n\n        return lines"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, message, cur_time=None):\n        if cur_time is None:\n            cur_time = time.time()\n        lines = self._line_buffer.add_string(message)\n        for line in lines:\n            #print('ts line', repr(line))\n            timestamp = ''\n            if self._prepend_timestamp:\n                timestamp = datetime.datetime.utcfromtimestamp(\n                    cur_time).isoformat() + ' '\n            line = u'{}{}{}'.format(self._line_prepend, timestamp, line)\n            self._fsapi.push(self._filename, line)", "response": "Write some text to the pusher."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse and streams a tfevents file to the server", "response": "def stream_tfevents(path, file_api, step=0):\n    \"\"\"Parses and streams a tfevents file to the server\"\"\"\n    last_step = 0\n    row = {}\n    buffer = []\n    last_row = {}\n    for summary in tf.train.summary_iterator(path):\n        parsed = tf_summary_to_dict(summary)\n        if last_step != parsed[\"tensorflow_step\"]:\n            step += 1\n            last_step = parsed[\"tensorflow_step\"]\n            # TODO: handle time\n            if len(row) > 0:\n                last_row = to_json(row)\n                buffer.append(Chunk(\"wandb-history.jsonl\",\n                                    util.json_dumps_safer_history(to_json(row))))\n        row.update(parsed)\n    file_api._send(buffer)\n    return last_row"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tf_summary_to_dict(tf_summary_str_or_pb, namespace=\"\"):\n    values = {}\n    if isinstance(tf_summary_str_or_pb, Summary):\n        summary_pb = tf_summary_str_or_pb\n    elif isinstance(tf_summary_str_or_pb, Event):\n        summary_pb = tf_summary_str_or_pb.summary\n        values[\"global_step\"] = tf_summary_str_or_pb.step\n        values[\"_timestamp\"] = tf_summary_str_or_pb.wall_time\n    else:\n        summary_pb = Summary()\n        summary_pb.ParseFromString(tf_summary_str_or_pb)\n\n    for value in summary_pb.value:\n        kind = value.WhichOneof(\"value\")\n        if kind == \"simple_value\":\n            values[namespaced_tag(value.tag, namespace)] = value.simple_value\n        elif kind == \"image\":\n            from PIL import Image\n            image = wandb.Image(Image.open(\n                six.BytesIO(value.image.encoded_image_string)))\n            tag_idx = value.tag.rsplit('/', 1)\n            if len(tag_idx) > 1 and tag_idx[1].isdigit():\n                tag, idx = tag_idx\n                values.setdefault(history_image_key(tag), []).append(image)\n            else:\n                values[history_image_key(value.tag)] = image\n        # Coming soon...\n        # elif kind == \"audio\":\n        #    audio = wandb.Audio(six.BytesIO(value.audio.encoded_audio_string),\n        #                        sample_rate=value.audio.sample_rate, content_type=value.audio.content_type)\n        elif kind == \"histo\":\n            first = value.histo.bucket_limit[0] + \\\n                value.histo.bucket_limit[0] - value.histo.bucket_limit[1]\n            last = value.histo.bucket_limit[-2] + \\\n                value.histo.bucket_limit[-2] - value.histo.bucket_limit[-3]\n            np_histogram = (list(value.histo.bucket), [\n                first] + value.histo.bucket_limit[:-1] + [last])\n            values[namespaced_tag(value.tag)] = wandb.Histogram(\n                np_histogram=np_histogram)\n\n    return values", "response": "Converts a Tensorboard Summary to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the text we are searching for.", "response": "def _get_search_text(self, cli):\n        \"\"\"\n        The text we are searching for.\n        \"\"\"\n        # When the search buffer has focus, take that text.\n        if self.preview_search(cli) and cli.buffers[self.search_buffer_name].text:\n            return cli.buffers[self.search_buffer_name].text\n        # Otherwise, take the text of the last active search.\n        else:\n            return self.get_search_state(cli).text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of row col tuples that need to be highlighted.", "response": "def _get_positions_to_highlight(self, document):\n        \"\"\"\n        Return a list of (row, col) tuples that need to be highlighted.\n        \"\"\"\n        # Try for the character under the cursor.\n        if document.current_char and document.current_char in self.chars:\n            pos = document.find_matching_bracket_position(\n                    start_pos=document.cursor_position - self.max_cursor_distance,\n                    end_pos=document.cursor_position + self.max_cursor_distance)\n\n        # Try for the character before the cursor.\n        elif (document.char_before_cursor and document.char_before_cursor in\n              self._closing_braces and document.char_before_cursor in self.chars):\n            document = Document(document.text, document.cursor_position - 1)\n\n            pos = document.find_matching_bracket_position(\n                    start_pos=document.cursor_position - self.max_cursor_distance,\n                    end_pos=document.cursor_position + self.max_cursor_distance)\n        else:\n            pos = None\n\n        # Return a list of (row, col) tuples that need to be highlighted.\n        if pos:\n            pos += document.cursor_position  # pos is relative.\n            row, col = document.translate_index_to_position(pos)\n            return [(row, col), (document.cursor_position_row, document.cursor_position_col)]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new instance that always inserts the same text.", "response": "def static(cls, text, token=Token):\n        \"\"\"\n        Create a :class:`.BeforeInput` instance that always inserts the same\n        text.\n        \"\"\"\n        def get_static_tokens(cli):\n            return [(token, text)]\n        return cls(get_static_tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef listen(self, max_seconds=30):\n        if not self.connection:\n            self.connect()\n        start = time.time()\n        conn, _, err = select([self.connection], [], [\n                              self.connection], max_seconds)\n        try:\n            if len(err) > 0:\n                raise socket.error(\"Couldn't open socket\")\n            message = b''\n            while True:\n                if time.time() - start > max_seconds:\n                    raise socket.error(\n                        \"Timeout of %s seconds waiting for W&B process\" % max_seconds)\n                res = self.connection.recv(1024)\n                term = res.find(b'\\0')\n                if term != -1:\n                    message += res[:term]\n                    break\n                else:\n                    message += res\n            message = json.loads(message.decode('utf8'))\n            if message['status'] == 'done':\n                return True, None\n            elif message['status'] == 'ready':\n                return True, message\n            elif message['status'] == 'launch_error':\n                return False, None\n            else:\n                raise socket.error(\"Invalid status: %s\" % message['status'])\n        except (socket.error, ValueError) as e:\n            util.sentry_exc(e)\n            return False, None", "response": "Waits for a message from the server to be received and returns a tuple of the status and message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _calc_adu(self):\n        res = super()._calc_adu()\n        self.ensure_one()\n        dafs_to_apply = self.env['ddmrp.adjustment'].search(\n            self._daf_to_apply_domain())\n        if dafs_to_apply:\n            daf = 1\n            values = dafs_to_apply.mapped('value')\n            for val in values:\n                daf *= val\n            prev = self.adu\n            self.adu *= daf\n            _logger.debug(\n                \"DAF=%s applied to %s. ADU: %s -> %s\" %\n                (daf, self.name, prev, self.adu))\n        # Compute generated demand to be applied to components:\n        dafs_to_explode = self.env['ddmrp.adjustment'].search(\n            self._daf_to_apply_domain(False))\n        for daf in dafs_to_explode:\n            prev = self.adu\n            increased_demand = prev * daf.value - prev\n            self.explode_demand_to_components(\n                daf, increased_demand, self.product_uom)\n        return res", "response": "Apply DAFs if existing for the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply extra demand originated by Demand Adjustment Factors to components after the cron update of all the buffers.", "response": "def cron_ddmrp_adu(self, automatic=False):\n        \"\"\"Apply extra demand originated by Demand Adjustment Factors to\n        components after the cron update of all the buffers.\"\"\"\n        self.env['ddmrp.adjustment.demand'].search([]).unlink()\n        super().cron_ddmrp_adu(automatic)\n        today = fields.Date.today()\n        for op in self.search([]).filtered('extra_demand_ids'):\n            to_add = sum(op.extra_demand_ids.filtered(\n                lambda r: r.date_start <= today <= r.date_end\n            ).mapped('extra_demand'))\n            if to_add:\n                op.adu += to_add\n                _logger.debug(\n                    \"DAFs-originated demand applied. %s: ADU += %s\"\n                    % (op.name, to_add))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _compute_dlt(self):\n        res = super()._compute_dlt()\n        for rec in self:\n            ltaf_to_apply = self.env['ddmrp.adjustment'].search(\n                rec._ltaf_to_apply_domain())\n            if ltaf_to_apply:\n                ltaf = 1\n                values = ltaf_to_apply.mapped('value')\n                for val in values:\n                    ltaf *= val\n                prev = rec.dlt\n                rec.dlt *= ltaf\n                _logger.debug(\n                    \"LTAF=%s applied to %s. DLT: %s -> %s\" %\n                    (ltaf, rec.name, prev, rec.dlt))\n        return res", "response": "Apply Lead Time Adj Factor to all records in the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct a new key based on the previous key and separator.", "response": "def _construct_key(previous_key, separator, new_key):\n    \"\"\"\n    Returns the new_key if no previous key exists, otherwise concatenates\n    previous key, separator, and new_key\n    :param previous_key:\n    :param separator:\n    :param new_key:\n    :return: a string if previous_key exists and simply passes through the\n    new_key otherwise\n    \"\"\"\n    if previous_key:\n        return u\"{}{}{}\".format(previous_key, separator, new_key)\n    else:\n        return new_key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flatten(nested_dict, separator=\"_\", root_keys_to_ignore=set()):\n    assert isinstance(nested_dict, dict), \"flatten requires a dictionary input\"\n    assert isinstance(separator, six.string_types), \"separator must be string\"\n\n    # This global dictionary stores the flattened keys and values and is\n    # ultimately returned\n    flattened_dict = dict()\n\n    def _flatten(object_, key):\n        \"\"\"\n        For dict, list and set objects_ calls itself on the elements and for\n        other types assigns the object_ to\n        the corresponding key in the global flattened_dict\n        :param object_: object to flatten\n        :param key: carries the concatenated key for the object_\n        :return: None\n        \"\"\"\n        # Empty object can't be iterated, take as is\n        if not object_:\n            flattened_dict[key] = object_\n        # These object types support iteration\n        elif isinstance(object_, dict):\n            for object_key in object_:\n                if not (not key and object_key in root_keys_to_ignore):\n                    _flatten(object_[object_key], _construct_key(key,\n                                                                 separator,\n                                                                 object_key))\n        elif isinstance(object_, (list, set, tuple)):\n            for index, item in enumerate(object_):\n                _flatten(item, _construct_key(key, separator, index))\n        # Anything left take as is\n        else:\n            flattened_dict[key] = object_\n\n    _flatten(nested_dict, None)\n    return flattened_dict", "response": "Flattens a dictionary with nested structure to a dictionary with no - deep structure"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unflatten(flat_dict, separator='_'):\n    _unflatten_asserts(flat_dict, separator)\n\n    # This global dictionary is mutated and returned\n    unflattened_dict = dict()\n\n    def _unflatten(dic, keys, value):\n        for key in keys[:-1]:\n            dic = dic.setdefault(key, {})\n\n        dic[keys[-1]] = value\n\n    for item in flat_dict:\n        _unflatten(unflattened_dict, item.split(separator), flat_dict[item])\n\n    return unflattened_dict", "response": "Returns a hierarchical dictionary from a flattened dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unflatten_list(flat_dict, separator='_'):\n    _unflatten_asserts(flat_dict, separator)\n\n    # First unflatten the dictionary assuming no lists exist\n    unflattened_dict = unflatten(flat_dict, separator)\n\n    def _convert_dict_to_list(object_, parent_object, parent_object_key):\n        if isinstance(object_, dict):\n            for key in object_:\n                if isinstance(object_[key], dict):\n                    _convert_dict_to_list(object_[key], object_, key)\n            try:\n                keys = [int(key) for key in object_]\n                keys.sort()\n            except (ValueError, TypeError):\n                keys = []\n            keys_len = len(keys)\n\n            if (keys_len > 0 and sum(keys) ==\n                int(((keys_len - 1) * keys_len) / 2) and keys[0] == 0 and\n                    keys[-1] == keys_len - 1 and\n                    check_if_numbers_are_consecutive(keys)):\n\n                # The dictionary looks like a list so we're going to replace it\n                parent_object[parent_object_key] = []\n                for key_index, key in enumerate(keys):\n                    parent_object[parent_object_key].append(object_[str(key)])\n                    # The list item we just added might be a list itself\n                    # https://github.com/amirziai/flatten/issues/15\n                    _convert_dict_to_list(parent_object[parent_object_key][-1],\n                                          parent_object[parent_object_key],\n                                          key_index)\n\n    _convert_dict_to_list(unflattened_dict, None, None)\n    return unflattened_dict", "response": "Unflattens a dictionary and replaces lists with their corresponding values"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if numbers in the list are consecutive", "response": "def check_if_numbers_are_consecutive(list_):\n    \"\"\"\n    Returns True if numbers in the list are consecutive\n\n    :param list_: list of integers\n    :return: Boolean\n    \"\"\"\n    return all((True if second - first == 1 else False\n                for first, second in zip(list_[:-1], list_[1:])))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef strip( text ):\n        '''\n        Strips all color codes from a text.\n        '''\n        members = [attr for attr in Colors.__dict__.keys() if not attr.startswith( \"__\" ) and not attr == 'strip']\n\n        for c in members:\n            text = text.replace( vars( Colors )[c], '' )\n        return text", "response": "Strips all color codes from a text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verbosity(self, *args):\n        '''\n        get/set the verbosity level.\n\n        The verbosity level filters messages that are output\n        to the console. Only messages tagged with a verbosity\n        less-than-or-equal-to the class verbosity are output.\n\n        This does not affect output to non-console devices\n        such as files or remote sockets.\n\n        verbosity():    returns the current level\n        verbosity(<N>): sets the verbosity to <N>\n        \n        '''\n        if len(args):\n            self._verbosity             = args[0]\n        else:\n            return self._verbosity", "response": "get or set the verbosity level"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget or set the tag string itself.", "response": "def tagstring(self, *args):\n        '''\n        get/set the tag string itself.\n\n        If called with non-zero length argument, will toggle the\n        internal b_tag flag to True.\n\n        The tagstring, if flagged TRUE and non-zero length, will\n        prepend each output log line. In this manner, it's possible\n        to post-filter log files for specific tags.\n\n        tagstring():            returns the current tagstring\n        tagstring(<string>):    sets the tagstring to <string>\n\n        '''\n        if len(args):\n            self._str_tag = args[0]\n            self._b_tag   = True\n        else:\n            return self._str_tag"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the tag flag", "response": "def tag(self, *args):\n        '''\n        get/set the tag flag.\n\n        The tag flag toggles the most basic prepending to each log\n        output. The idea with the tagging text is to provide a \n        simple mechanism by which a log output can be filtered/parsed\n        for specific outputs.\n\n        tag():                  returns the current syslog flag\n        tag(True|False):        sets the flag to True|False\n\n        '''\n        if len(args):\n            self._b_tag = args[0]\n        else:\n            return self._b_tag"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef syslog(self, *args):\n        '''\n        get/set the syslog flag.\n\n        The syslog flag toggles prepending each message with\n            a syslog-style prefix.\n\n        syslog():               returns the current syslog flag\n        syslog(True|False):     sets the flag to True|False\n\n        '''\n        if len(args):\n            self._b_syslog = args[0]\n        else:\n            return self._b_syslog", "response": "set the syslog flag"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the str_syslog i. e. the current value of the syslog prepend string.", "response": "def str_syslog(self, *args):\n        '''\n        get/set the str_syslog, i.e. the current value of the\n        syslog prepend string.\n\n        str_syslog():           returns the current syslog string\n        str_syslog(<astr>):     sets the syslog string to <astr>\n\n        '''\n        if len(args):\n            self._str_syslog = args[0]\n        else:\n            return self._str_syslog"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tee(self, *args):\n        '''\n        get/set the tee flag.\n\n        The tee flag toggles any output that is directed to non-console\n        destinations to also appear on the console. Tee'd console output\n        is still verbosity filtered\n        \n        tee():                  returns the current syslog flag\n        tee(True|False):        sets the flag to True|False\n\n        '''\n        if len(args):\n            self._b_tee = args[0]\n        else:\n            return self._b_tee", "response": "get or set the tee flag"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the ASTR_DESTINATION and returns True or False.", "response": "def socket_parse(self, astr_destination):\n        '''\n        Examines <astr_destination> and if of form <str1>:<str2> assumes\n        that <str1> is a host to send datagram comms to over port <str2>.\n\n        Returns True or False.\n        \n        '''\n        t_socketInfo = astr_destination.partition(':')\n        if len(t_socketInfo[1]):\n            self._b_isSocket    = True\n            self._socketRemote  = t_socketInfo[0]\n            self._socketPort    = t_socketInfo[2]\n        else:\n            self._b_isSocket    = False\n        return self._b_isSocket"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget or set the device to which messages are sent.", "response": "def to(self, *args):\n        '''\n        get/set the 'device' to which messages are sent.\n\n        Valid targets are:\n\n            string filenames:           '/tmp/test.log'\n            remote hosts:               'pretoria:1701'\n            system devices:             sys.stdout, sys.stderr\n            special names:              'stdout'\n            file handles:               open('/tmp/test.log')\n            \n        '''\n        if len(args):\n            self._logFile = args[0]\n            if self._logHandle and self._logHandle != sys.stdout:\n                self._logHandle.close()\n            \n            # if type(self._logFile) is types.FileType:\n            if isinstance(self._logFile, IOBase):\n                self._logHandle = self._logFile\n            elif self._logFile == 'stdout':\n                self._logHandle = sys.stdout\n            elif self.socket_parse(self._logFile):\n                self._logHandle = C_dgmsocket(\n                                            self._socketRemote,\n                                            int(self._socketPort))\n            else:\n                self._logHandle = open(self._logFile, \"a\")\n            self._sys_stdout      = self._logHandle\n        else:\n            return self._logFile"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef vprintf(self, alevel, format, *args):\n        '''\n        A verbosity-aware printf.\n\n        '''\n        if self._verbosity and self._verbosity >= alevel:\n            sys.stdout.write(format % args)", "response": "A verbosity - aware printf."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef syslog_generate(str_processName, str_pid):\n      '''\n      Returns a string similar to:\n\n            Tue Oct  9 10:49:53 2012 pretoria message.py[26873]:\n\n      where 'pretoria' is the hostname, 'message.py' is the current process\n      name and 26873 is the current process id.\n      '''\n      localtime = time.asctime( time.localtime(time.time()) )      \n      hostname = os.uname()[1]\n      syslog = '%s %s %s[%s]' % (localtime, hostname, str_processName, str_pid)\n      return syslog", "response": "Generate a syslog message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef density(a_M, *args, **kwargs):\n\n    rows, cols  = a_M.shape\n    a_Mmask     = ones( (rows, cols) )\n    if len(args):\n        a_Mmask = args[0]\n\n    a_M *= a_Mmask\n    # The \"binary\" density determines the density of nonzero elements,\n    # irrespective of their actual value\n    f_binaryMass    = float(size(nonzero(a_M)[0]))\n    f_actualMass    = a_M.sum()\n\n    f_area          = float(size(nonzero(a_Mmask)[0]))\n\n    f_binaryDensity = f_binaryMass / f_area;\n    f_actualDensity = f_actualMass / f_area;\n    return f_actualDensity, f_binaryDensity", "response": "Calculate the density of a passed matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cdf(arr, **kwargs):\n    counts, bin_edges = histogram(arr, **kwargs)\n    cdf = cumsum(counts)\n    return cdf", "response": "Calculates the cumulative distribution function for a set of items in the array"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the center of mass in array grid <ar_grid. Mass elements are grid index values.", "response": "def com_find(ar_grid):\n    \"\"\"\n    Find the center of mass in array grid <ar_grid>. Mass elements\n    are grid index values.\n\n    Return an array, in format (x, y), i.e. col, row!\n    \"\"\"\n    f_x = 0\n    f_y = 0\n    f_m = 0\n\n    for i in range(len(ar_grid)):\n       for j in range(len(ar_grid[i])):\n         if ar_grid[i][j]:\n            # Since python arrays are zero indexed, we need to offset\n            # the loop counters by 1 to account for mass in the 1st\n            # column.\n            f_x += (j+1) * ar_grid[i][j]\n            f_y += (i+1) * ar_grid[i][j]\n            f_m += ar_grid[i][j]\n    f_com = array( (float(f_x)/f_m , float(f_y)/f_m) )\n    return f_com"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_find2D(ar_grid, **kwargs):\n    b_reorder   = True\n    b_oneOffset = True\n\n    for key, value in kwargs.iteritems():\n        if key == 'ordering' and value == 'rc':         b_reorder       = False\n        if key == 'ordering' and value == 'xy':         b_reorder       = True\n        if key == 'indexing' and value == 'zero':       b_oneOffset     = False\n        if key == 'indexing' and value == 'one':        b_oneOffset     = True\n\n    f_Smass = ar_grid.sum()\n    f_comX = (ar_grid[nonzero(ar_grid)] * (nonzero(ar_grid)[1] + 1)).sum() / f_Smass\n    f_comY = (ar_grid[nonzero(ar_grid)] * (nonzero(ar_grid)[0] + 1)).sum() / f_Smass\n\n    if b_reorder:       ar_ret = array( (f_comX, f_comY) )\n    if not b_reorder:   ar_ret = array( (f_comY, f_comX) )\n    if not b_oneOffset: ar_ret -= 1.0\n    return ar_ret", "response": "Find the center of mass in 2D array grid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nenumerating the indices of explicit 2D elements in a 2D array.", "response": "def array2DIndices_enumerate(arr):\n        \"\"\"\n        DESC\n            Given a 2D array defined by arr, prepare an explicit list\n            of the indices.\n\n        ARGS\n            arr        in                 2 element array with the first\n                                          element the rows and the second\n                                          the cols\n\n        RET\n            A list of explicit 2D coordinates.\n        \"\"\"\n\n        rows = arr[0]\n        cols = arr[1]\n        arr_index = zeros((rows * cols, 2))\n        count = 0\n        for row in arange(0, rows):\n           for col in arange(0, cols):\n               arr_index[count] = array([row, col])\n               count = count + 1\n        return arr_index"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef toc(*args, **kwargs):\n    global Gtic_start\n    f_elapsedTime = time.time() - Gtic_start\n    for key, value in kwargs.items():\n        if key == 'sysprint':   return value % f_elapsedTime\n        if key == 'default':    return \"Elapsed time = %f seconds.\" % f_elapsedTime\n    return f_elapsedTime", "response": "Returns the MatLAB function of the same name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pointInGrid(A_point, a_gridSize, *args):\n    b_wrapGridEdges = False # If True, wrap around edges of grid\n\n    if len(args): b_wrapGridEdges = args[0]\n\n    # Check for points \"less than\" grid space\n    if b_wrapGridEdges:\n        W = where(A_point < 0)\n        A_point[W] += a_gridSize[W[1]]\n\n    Wbool = A_point >= 0\n    W = Wbool.prod(axis=1)\n    A_point = A_point[where(W > 0)]\n\n    # Check for points \"more than\" grid space\n    A_inGrid = a_gridSize - A_point\n    if b_wrapGridEdges:\n        W = where(A_inGrid <= 0)\n        A_point[W] = -A_inGrid[W]\n        A_inGrid = a_gridSize - A_point\n\n    Wbool = A_inGrid > 0\n    W = Wbool.prod(axis=1)\n    A_point = A_point[where(W > 0)]\n#    A_point = abs(A_point)\n    return A_point", "response": "This function returns a copy of the problem space that contains a point in a grid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef arr_base10toN(anum10, aradix, *args):\n\n    new_num_arr = array(())\n    current = anum10\n    while current != 0:\n        remainder = current % aradix\n        new_num_arr = r_[remainder, new_num_arr]\n        current = current / aradix\n\n    forcelength = new_num_arr.size\n    # Optionally, allow user to specify word length\n    if len(args): forcelength = args[0]\n    while new_num_arr.size < forcelength:\n        new_num_arr = r_[0, new_num_arr]\n    return new_num_arr", "response": "This function converts an array from base 10 to base radix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchanging a num to a base - n number. Up to base - 36 is supported without special notation.", "response": "def base10toN(num, n):\n    \"\"\"Change a num to a base-n number.\n    Up to base-36 is supported without special notation.\"\"\"\n    num_rep = {10:'a',\n         11:'b',\n         12:'c',\n         13:'d',\n         14:'e',\n         15:'f',\n         16:'g',\n         17:'h',\n         18:'i',\n         19:'j',\n         20:'k',\n         21:'l',\n         22:'m',\n         23:'n',\n         24:'o',\n         25:'p',\n         26:'q',\n         27:'r',\n         28:'s',\n         29:'t',\n         30:'u',\n         31:'v',\n         32:'w',\n         33:'x',\n         34:'y',\n         35:'z'}\n    new_num_string = ''\n    new_num_arr = array(())\n    current = num\n    while current != 0:\n        remainder = current % n\n        if 36 > remainder > 9:\n            remainder_string = num_rep[remainder]\n        elif remainder >= 36:\n            remainder_string = '(' + str(remainder) + ')'\n        else:\n            remainder_string = str(remainder)\n        new_num_string = remainder_string + new_num_string\n        new_num_arr = r_[remainder, new_num_arr]\n        current = current / n\n    print(new_num_arr)\n    return new_num_string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_i2str(ilist):\n    slist = []\n    for el in ilist:\n        slist.append(str(el))\n    return slist", "response": "Convert an integer list into a string list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef system_procRet(str_command, b_echoCommand=0):\n        if b_echoCommand: printf('<p>str_command = %s</p>', str_command)\n        str_stdout = os.popen(str_command).read()\n        retcode = os.popen(str_command).close()\n        return retcode, str_stdout", "response": "Run the system command and return the return code and the standard output stream"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shellne(command):\n\n    child = os.popen(command)\n    data = child.read()\n    err = child.close()\n    if err:\n        raise RuntimeError('%s failed w/ exit code %d' % (command, err))\n    return data", "response": "Runs a shell command and returns the output of the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef str_dateStrip(astr_datestr, astr_sep='/'):\n  try:\n    index = astr_datestr.index(astr_sep)\n  except:\n    return astr_datestr.encode('ascii')\n\n  try:\n    tm = time.strptime(astr_datestr, '%d/%M/%Y')\n  except:\n    try:\n      tm = time.strptime(astr_datestr, '%d/%M/%y')\n    except:\n      error_exit('str_dateStrip', 'parsing date string',\n                 'no conversion was possible', 1)\n  tstr = time.strftime(\"%d%M%Y\", tm)\n  return tstr.encode('ascii')", "response": "Simple date strip method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef str2lst(astr_input, astr_separator=\" \"):\n  alistI = astr_input.split(astr_separator)\n  alistJ = []\n  for i in range(0, len(alistI)):\n    alistI[i] = alistI[i].strip()\n    alistI[i] = alistI[i].encode('ascii')\n    if len(alistI[i]):\n      alistJ.append(alistI[i])\n  return alistJ", "response": "Breaks a string at astr_separator and joins into a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match(self, *args):\n        if self.fall or not args:\n            return True\n        elif self.value in args: # changed for v1.5, see below\n            self.fall = True\n            return True\n        else:\n            return False", "response": "Indicate whether or not to enter a case suite"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef report(     callingClass,\n                astr_key,\n                ab_exitToOs=1,\n                astr_header=\"\"\n                ):\n    '''\n    Error handling.\n\n    Based on the <astr_key>, error information is extracted from\n    _dictErr and sent to log object.\n\n    If <ab_exitToOs> is False, error is considered non-fatal and\n    processing can continue, otherwise processing terminates.\n\n    '''\n    log         = callingClass.log()\n    b_syslog    = log.syslog()\n    log.syslog(False)\n    if ab_exitToOs: log( Colors.RED +    \"\\n:: FATAL ERROR :: \" + Colors.NO_COLOUR )\n    else:           log( Colors.YELLOW + \"\\n::   WARNING   :: \" + Colors.NO_COLOUR )\n    if len(astr_header): log( Colors.BROWN + astr_header + Colors.NO_COLOUR )\n    log( \"\\n\" )\n    log( \"\\tSorry, some error seems to have occurred in:\\n\\t<\" )\n    log( Colors.LIGHT_GREEN + (\"%s\" % callingClass.name()) + Colors.NO_COLOUR + \"::\")\n    log( Colors.LIGHT_CYAN + (\"%s\" % inspect.stack()[2][4][0].strip()) + Colors.NO_COLOUR)\n    log( \"> called by <\")\n    try:\n        caller = inspect.stack()[3][4][0].strip()\n    except:\n        caller = '__main__'\n    log( Colors.LIGHT_GREEN + (\"%s\" % callingClass.name()) + Colors.NO_COLOUR + \"::\")\n    log( Colors.LIGHT_CYAN + (\"%s\" % caller) + Colors.NO_COLOUR)\n    log( \">\\n\")\n\n    log( \"\\tWhile %s\\n\" % callingClass._dictErr[astr_key]['action'] )\n    log( \"\\t%s\\n\" % callingClass._dictErr[astr_key]['error'] )\n    log( \"\\n\" )\n    if ab_exitToOs:\n        log( \"Returning to system with error code %d\\n\" % \\\n                        callingClass._dictErr[astr_key]['exitCode'] )\n        sys.exit( callingClass._dictErr[astr_key]['exitCode'] )\n    log.syslog(b_syslog)\n    return callingClass._dictErr[astr_key]['exitCode']", "response": "Report the error of a specific resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fatal( callingClass, astr_key, astr_extraMsg=\"\" ):\n    '''\n    Convenience dispatcher to the error_exit() method.\n\n    Will raise \"fatal\" error, i.e. terminate script.\n    '''\n    b_exitToOS  = True\n    report( callingClass, astr_key, b_exitToOS, astr_extraMsg )", "response": "This function is used to raise a fatal error in the current context of the script."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget or set the internal pipeline log message object.", "response": "def log(self, *args):\n        '''\n        get/set the internal pipeline log message object.\n\n        Caller can further manipulate the log object with object-specific\n        calls.\n        '''\n        if len(args):\n            self._log = args[0]\n        else:\n            return self._log"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the descriptive name text of this object.", "response": "def name(self, *args):\n        '''\n        get/set the descriptive name text of this object.\n        '''\n        if len(args):\n            self.__name = args[0]\n        else:\n            return self.__name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef description(self, *args):\n        '''\n        Get / set internal object description.\n        '''\n        if len(args):\n            self._str_desc = args[0]\n        else:\n            return self._str_desc", "response": "Get or set internal object description."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess a single slice.", "response": "def process_slice(self, b_rot90=None):\n        '''\n        Processes a single slice.\n        '''\n        if b_rot90:\n            self._Mnp_2Dslice = np.rot90(self._Mnp_2Dslice)\n        if self.func == 'invertIntensities':\n            self.invert_slice_intensities()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef slice_save(self, astr_outputFile):\n        '''\n        Saves a single slice.\n\n        ARGS\n\n        o astr_output\n        The output filename to save the slice to.\n        '''\n        self._log('Outputfile = %s\\n' % astr_outputFile)\n        fformat = astr_outputFile.split('.')[-1]\n        if fformat == 'dcm':\n            if self._dcm:\n                self._dcm.pixel_array.flat = self._Mnp_2Dslice.flat\n                self._dcm.PixelData = self._dcm.pixel_array.tostring()\n                self._dcm.save_as(astr_outputFile)\n            else:\n                raise ValueError('dcm output format only available for DICOM files')\n        else:\n            pylab.imsave(astr_outputFile, self._Mnp_2Dslice, format=fformat, cmap = cm.Greys_r)", "response": "Saves a single slice to a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self):\n        '''\n        Runs the DICOM conversion based on internal state.\n        '''\n        self._log('Converting DICOM image.\\n')\n        try:\n            self._log('PatientName:                                %s\\n' % self._dcm.PatientName)\n        except AttributeError:\n            self._log('PatientName:                                %s\\n' % 'PatientName not found in DCM header.')\n            error.warn(self, 'PatientNameTag')\n        try:\n            self._log('PatientAge:                                 %s\\n' % self._dcm.PatientAge)\n        except AttributeError:\n            self._log('PatientAge:                                 %s\\n' % 'PatientAge not found in DCM header.')\n            error.warn(self, 'PatientAgeTag')\n        try:\n            self._log('PatientSex:                                 %s\\n' % self._dcm.PatientSex)\n        except AttributeError:\n            self._log('PatientSex:                                 %s\\n' % 'PatientSex not found in DCM header.')\n            error.warn(self, 'PatientSexTag')\n        try:\n            self._log('PatientID:                                  %s\\n' % self._dcm.PatientID)\n        except AttributeError:\n            self._log('PatientID:                                  %s\\n' % 'PatientID not found in DCM header.')\n            error.warn(self, 'PatientIDTag')\n        try:\n            self._log('SeriesDescription:                          %s\\n' % self._dcm.SeriesDescription)\n        except AttributeError:\n            self._log('SeriesDescription:                          %s\\n' % 'SeriesDescription not found in DCM header.')\n            error.warn(self, 'SeriesDescriptionTag')\n        try:\n            self._log('ProtocolName:                               %s\\n' % self._dcm.ProtocolName)\n        except AttributeError:\n            self._log('ProtocolName:                               %s\\n' % 'ProtocolName not found in DCM header.')\n            error.warn(self, 'ProtocolNameTag')\n\n        if self._b_convertMiddleSlice:\n            self._log('Converting middle slice in DICOM series:    %d\\n' % self._sliceToConvert)\n\n        l_rot90 = [ True, True, False ]\n        misc.mkdir(self._str_outputDir)\n        if not self._b_3D:\n            str_outputFile = '%s/%s.%s' % (self._str_outputDir,\n                                        self._str_outputFileStem,\n                                        self._str_outputFileType)\n            self.process_slice()\n            self.slice_save(str_outputFile)\n        if self._b_3D:\n            rotCount = 0\n            if self._b_reslice:\n                for dim in ['x', 'y', 'z']:\n                    self.dim_save(dimension = dim, makeSubDir = True, rot90 = l_rot90[rotCount], indexStart = 0, indexStop = -1)\n                    rotCount += 1\n            else:\n                self.dim_save(dimension = 'z', makeSubDir = False, rot90 = False, indexStart = 0, indexStop = -1)", "response": "Runs the DICOM conversion based on internal state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the conversion based on internal state.", "response": "def run(self):\n        '''\n        Runs the NIfTI conversion based on internal state.\n        '''\n\n        self._log('About to perform NifTI to %s conversion...\\n' %\n                  self._str_outputFileType)\n\n        frames     = 1\n        frameStart = 0\n        frameEnd   = 0\n\n        sliceStart = 0\n        sliceEnd   = 0\n\n        if self._b_4D:\n            self._log('4D volume detected.\\n')\n            frames = self._Vnp_4DVol.shape[3]\n        if self._b_3D:\n            self._log('3D volume detected.\\n')\n\n        if self._b_convertMiddleFrame:\n            self._frameToConvert = int(frames/2)\n\n        if self._frameToConvert == -1:\n            frameEnd    = frames\n        else:\n            frameStart  = self._frameToConvert\n            frameEnd    = self._frameToConvert + 1\n\n        for f in range(frameStart, frameEnd):\n            if self._b_4D:\n                self._Vnp_3DVol = self._Vnp_4DVol[:,:,:,f]\n            slices     = self._Vnp_3DVol.shape[2]\n            if self._b_convertMiddleSlice:\n                self._sliceToConvert = int(slices/2)\n\n            if self._sliceToConvert == -1:\n                sliceEnd    = -1\n            else:\n                sliceStart  = self._sliceToConvert\n                sliceEnd    = self._sliceToConvert + 1\n\n            misc.mkdir(self._str_outputDir)\n            if self._b_reslice:\n                for dim in ['x', 'y', 'z']:\n                    self.dim_save(dimension = dim, makeSubDir = True, indexStart = sliceStart, indexStop = sliceEnd, rot90 = True)\n            else:\n                self.dim_save(dimension = 'z', makeSubDir = False, indexStart = sliceStart, indexStop = sliceEnd, rot90 = True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a logger with a file handler.", "response": "def get_logger(name):\n    \"\"\"Return a logger with a file handler.\"\"\"\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # File output handler\n    file_handler = logging.FileHandler(log_path)\n    file_handler.setLevel(logging.INFO)\n    formatter = logging.Formatter(\n        '%(asctime)s %(name)12s %(levelname)8s %(lineno)s %(message)s',\n        datefmt='%m/%d/%Y %I:%M:%S %p')\n    file_handler.setFormatter(formatter)\n\n    logger.addHandler(file_handler)\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the download time.", "response": "def timeit(method):\n    \"\"\"Compute the download time.\"\"\"\n\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = method(*args, **kwargs)\n        end = time.time()\n\n        click.echo('Cost {}s'.format(int(end-start)))\n        return result\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrequires user to login.", "response": "def login(method):\n    \"\"\"Require user to login.\"\"\"\n\n    def wrapper(*args, **kwargs):\n        crawler = args[0].crawler  # args[0] is a NetEase object\n\n        try:\n            if os.path.isfile(cookie_path):\n                with open(cookie_path, 'r') as cookie_file:\n                    cookie = cookie_file.read()\n                expire_time = re.compile(r'\\d{4}-\\d{2}-\\d{2}').findall(cookie)\n                now = time.strftime('%Y-%m-%d', time.localtime(time.time()))\n                if expire_time[0] > now:\n                    crawler.session.cookies.load()\n                else:\n                    crawler.login()\n            else:\n                crawler.login()\n        except RequestException:\n            click.echo('Maybe password error, please try again.')\n            sys.exit(1)\n        result = method(*args, **kwargs)\n        return result\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading a song by its name.", "response": "def download_song_by_search(self, song_name):\n        \"\"\"Download a song by its name.\n\n        :params song_name: song name.\n        \"\"\"\n\n        try:\n            song = self.crawler.search_song(song_name, self.quiet)\n        except RequestException as exception:\n            click.echo(exception)\n        else:\n            self.download_song_by_id(song.song_id, song.song_name, self.folder)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads a song by id and save it to disk.", "response": "def download_song_by_id(self, song_id, song_name, folder='.'):\n        \"\"\"Download a song by id and save it to disk.\n\n        :params song_id: song id.\n        :params song_name: song name.\n        :params folder: storage path.\n        \"\"\"\n\n        try:\n            url = self.crawler.get_song_url(song_id)\n            if self.lyric:\n                # use old api\n                lyric_info = self.crawler.get_song_lyric(song_id)\n            else:\n                lyric_info = None\n            song_name = song_name.replace('/', '')\n            song_name = song_name.replace('.', '')\n            self.crawler.get_song_by_url(url, song_name, folder, lyric_info)\n        except RequestException as exception:\n            click.echo(exception)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a album by its name.", "response": "def download_album_by_search(self, album_name):\n        \"\"\"Download a album by its name.\n\n        :params album_name: album name.\n        \"\"\"\n\n        try:\n            album = self.crawler.search_album(album_name, self.quiet)\n        except RequestException as exception:\n            click.echo(exception)\n        else:\n            self.download_album_by_id(album.album_id, album.album_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading a album by its id.", "response": "def download_album_by_id(self, album_id, album_name):\n        \"\"\"Download a album by its name.\n\n        :params album_id: album id.\n        :params album_name: album name.\n        \"\"\"\n\n        try:\n            # use old api\n            songs = self.crawler.get_album_songs(album_id)\n        except RequestException as exception:\n            click.echo(exception)\n        else:\n            folder = os.path.join(self.folder, album_name)\n            for song in songs:\n                self.download_song_by_id(song.song_id, song.song_name, folder)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading a artist s top50 songs by his name.", "response": "def download_artist_by_search(self, artist_name):\n        \"\"\"Download a artist's top50 songs by his/her name.\n\n        :params artist_name: artist name.\n        \"\"\"\n\n        try:\n            artist = self.crawler.search_artist(artist_name, self.quiet)\n        except RequestException as exception:\n            click.echo(exception)\n        else:\n            self.download_artist_by_id(artist.artist_id, artist.artist_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload a artist s top50 songs by his id.", "response": "def download_artist_by_id(self, artist_id, artist_name):\n        \"\"\"Download a artist's top50 songs by his/her id.\n\n        :params artist_id: artist id.\n        :params artist_name: artist name.\n        \"\"\"\n\n        try:\n            # use old api\n            songs = self.crawler.get_artists_hot_songs(artist_id)\n        except RequestException as exception:\n            click.echo(exception)\n        else:\n            folder = os.path.join(self.folder, artist_name)\n            for song in songs:\n                self.download_song_by_id(song.song_id, song.song_name, folder)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download_playlist_by_search(self, playlist_name):\n\n        try:\n            playlist = self.crawler.search_playlist(\n                playlist_name, self.quiet)\n        except RequestException as exception:\n            click.echo(exception)\n        else:\n            self.download_playlist_by_id(\n                playlist.playlist_id, playlist.playlist_name)", "response": "Download a playlist songs by its name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download_playlist_by_id(self, playlist_id, playlist_name):\n\n        try:\n            songs = self.crawler.get_playlist_songs(\n                playlist_id)\n        except RequestException as exception:\n            click.echo(exception)\n        else:\n            folder = os.path.join(self.folder, playlist_name)\n            for song in songs:\n                self.download_song_by_id(song.song_id, song.song_name, folder)", "response": "Download a playlist s songs by its id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download_user_playlists_by_search(self, user_name):\n\n        try:\n            user = self.crawler.search_user(user_name, self.quiet)\n        except RequestException as exception:\n            click.echo(exception)\n        else:\n            self.download_user_playlists_by_id(user.user_id)", "response": "Download user s playlists by his name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads user s playlists by his id.", "response": "def download_user_playlists_by_id(self, user_id):\n        \"\"\"Download user's playlists by his/her id.\n\n        :params user_id: user id.\n        \"\"\"\n\n        try:\n            playlist = self.crawler.get_user_playlists(user_id)\n        except RequestException as exception:\n            click.echo(exception)\n        else:\n            self.download_playlist_by_id(\n                playlist.playlist_id, playlist.playlist_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download_person_playlists(self):\n\n        with open(person_info_path, 'r') as person_info:\n            user_id = int(person_info.read())\n        self.download_user_playlists_by_id(user_id)", "response": "Download person playlist including private playlist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncapturing Ctrl + C.", "response": "def signal_handler(sign, frame):\n    \"\"\"Capture Ctrl+C.\"\"\"\n    LOG.info('%s => %s', sign, frame)\n    click.echo('Bye')\n    sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef song(netease, name, id):\n    if name:\n        netease.download_song_by_search(name)\n\n    if id:\n        netease.download_song_by_id(id, 'song'+str(id))", "response": "Download a song by name or id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef album(netease, name, id):\n    if name:\n        netease.download_album_by_search(name)\n\n    if id:\n        netease.download_album_by_id(id, 'album'+str(id))", "response": "Download a album s songs by name or id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef artist(netease, name, id):\n    if name:\n        netease.download_artist_by_search(name)\n\n    if id:\n        netease.download_artist_by_id(id, 'artist'+str(id))", "response": "Download a artist s hot songs by name or id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a playlist songs by name and id.", "response": "def playlist(netease, name, id):\n    \"\"\"Download a playlist's songs by id.\"\"\"\n    if name:\n        netease.download_playlist_by_search(name)\n\n    if id:\n        netease.download_playlist_by_id(id, 'playlist'+str(id))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload a user s playlists by name and id.", "response": "def user(netease, name, id):\n    \"\"\"Download a user\\'s playlists by id.\"\"\"\n    if name:\n        netease.download_user_playlists_by_search(name)\n\n    if id:\n        netease.download_user_playlists_by_id(id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisplay the songs returned by search api.", "response": "def select_one_song(songs):\n        \"\"\"Display the songs returned by search api.\n\n        :params songs: API['result']['songs']\n        :return: a Song object.\n        \"\"\"\n\n        if len(songs) == 1:\n            select_i = 0\n        else:\n            table = PrettyTable(['Sequence', 'Song Name', 'Artist Name'])\n            for i, song in enumerate(songs, 1):\n                table.add_row([i, song['name'], song['ar'][0]['name']])\n            click.echo(table)\n\n            select_i = click.prompt('Select one song', type=int, default=1)\n            while select_i < 1 or select_i > len(songs):\n                select_i = click.prompt('Error Select! Select Again', type=int)\n\n        song_id, song_name = songs[select_i-1]['id'], songs[select_i-1]['name']\n        song = Song(song_id, song_name)\n        return song"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select_one_album(albums):\n\n        if len(albums) == 1:\n            select_i = 0\n        else:\n            table = PrettyTable(['Sequence', 'Album Name', 'Artist Name'])\n            for i, album in enumerate(albums, 1):\n                table.add_row([i, album['name'], album['artist']['name']])\n            click.echo(table)\n\n            select_i = click.prompt('Select one album', type=int, default=1)\n            while select_i < 1 or select_i > len(albums):\n                select_i = click.prompt('Error Select! Select Again', type=int)\n\n        album_id = albums[select_i-1]['id']\n        album_name = albums[select_i-1]['name']\n        album = Album(album_id, album_name)\n        return album", "response": "Display the albums returned by search api."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_one_artist(artists):\n\n        if len(artists) == 1:\n            select_i = 0\n        else:\n            table = PrettyTable(['Sequence', 'Artist Name'])\n            for i, artist in enumerate(artists, 1):\n                table.add_row([i, artist['name']])\n            click.echo(table)\n\n            select_i = click.prompt('Select one artist', type=int, default=1)\n            while select_i < 1 or select_i > len(artists):\n                select_i = click.prompt('Error Select! Select Again', type=int)\n\n        artist_id = artists[select_i-1]['id']\n        artist_name = artists[select_i-1]['name']\n        artist = Artist(artist_id, artist_name)\n        return artist", "response": "Display the artists returned by search api."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisplay the playlists returned by search api or user playlist.", "response": "def select_one_playlist(playlists):\n        \"\"\"Display the playlists returned by search api or user playlist.\n\n        :params playlists: API['result']['playlists'] or API['playlist']\n        :return: a Playlist object.\n        \"\"\"\n\n        if len(playlists) == 1:\n            select_i = 0\n        else:\n            table = PrettyTable(['Sequence', 'Name'])\n            for i, playlist in enumerate(playlists, 1):\n                table.add_row([i, playlist['name']])\n            click.echo(table)\n\n            select_i = click.prompt('Select one playlist', type=int, default=1)\n            while select_i < 1 or select_i > len(playlists):\n                select_i = click.prompt('Error Select! Select Again', type=int)\n\n        playlist_id = playlists[select_i-1]['id']\n        playlist_name = playlists[select_i-1]['name']\n        playlist = Playlist(playlist_id, playlist_name)\n        return playlist"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying the users returned by search api.", "response": "def select_one_user(users):\n        \"\"\"Display the users returned by search api.\n\n        :params users: API['result']['userprofiles']\n        :return: a User object.\n        \"\"\"\n\n        if len(users) == 1:\n            select_i = 0\n        else:\n            table = PrettyTable(['Sequence', 'Name'])\n            for i, user in enumerate(users, 1):\n                table.add_row([i, user['nickname']])\n            click.echo(table)\n\n            select_i = click.prompt('Select one user', type=int, default=1)\n            while select_i < 1 or select_i > len(users):\n                select_i = click.prompt('Error Select! Select Again', type=int)\n\n        user_id = users[select_i-1]['userId']\n        user_name = users[select_i-1]['nickname']\n        user = User(user_id, user_name)\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle exception raised by requests library.", "response": "def exception_handle(method):\n    \"\"\"Handle exception raised by requests library.\"\"\"\n\n    def wrapper(*args, **kwargs):\n        try:\n            result = method(*args, **kwargs)\n            return result\n        except ProxyError:\n            LOG.exception('ProxyError when try to get %s.', args)\n            raise ProxyError('A proxy error occurred.')\n        except ConnectionException:\n            LOG.exception('ConnectionError when try to get %s.', args)\n            raise ConnectionException('DNS failure, refused connection, etc.')\n        except Timeout:\n            LOG.exception('Timeout when try to get %s', args)\n            raise Timeout('The request timed out.')\n        except RequestException:\n            LOG.exception('RequestException when try to get %s.', args)\n            raise RequestException('Please check out your network.')\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a get request.", "response": "def get_request(self, url):\n        \"\"\"Send a get request.\n\n        warning: old api.\n        :return: a dict or raise Exception.\n        \"\"\"\n\n        resp = self.session.get(url, timeout=self.timeout,\n                                proxies=self.proxies)\n        result = resp.json()\n        if result['code'] != 200:\n            LOG.error('Return %s when try to get %s', result, url)\n            raise GetRequestIllegal(result)\n        else:\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post_request(self, url, params):\n\n        data = encrypted_request(params)\n        resp = self.session.post(url, data=data, timeout=self.timeout,\n                                 proxies=self.proxies)\n        result = resp.json()\n        if result['code'] != 200:\n            LOG.error('Return %s when try to post %s => %s',\n                      result, url, params)\n            raise PostRequestIllegal(result)\n        else:\n            return result", "response": "Send a post request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search(self, search_content, search_type, limit=9):\n\n        url = 'http://music.163.com/weapi/cloudsearch/get/web?csrf_token='\n        params = {'s': search_content, 'type': search_type, 'offset': 0,\n                  'sub': 'false', 'limit': limit}\n        result = self.post_request(url, params)\n        return result", "response": "Search the cloudsearch API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_song(self, song_name, quiet=False, limit=9):\n\n        result = self.search(song_name, search_type=1, limit=limit)\n\n        if result['result']['songCount'] <= 0:\n            LOG.warning('Song %s not existed!', song_name)\n            raise SearchNotFound('Song {} not existed.'.format(song_name))\n        else:\n            songs = result['result']['songs']\n            if quiet:\n                song_id, song_name = songs[0]['id'], songs[0]['name']\n                song = Song(song_id, song_name)\n                return song\n            else:\n                return self.display.select_one_song(songs)", "response": "Search a song by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_album(self, album_name, quiet=False, limit=9):\n\n        result = self.search(album_name, search_type=10, limit=limit)\n\n        if result['result']['albumCount'] <= 0:\n            LOG.warning('Album %s not existed!', album_name)\n            raise SearchNotFound('Album {} not existed'.format(album_name))\n        else:\n            albums = result['result']['albums']\n            if quiet:\n                album_id, album_name = albums[0]['id'], albums[0]['name']\n                album = Album(album_id, album_name)\n                return album\n            else:\n                return self.display.select_one_album(albums)", "response": "Search album by album name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches artist by artist name.", "response": "def search_artist(self, artist_name, quiet=False, limit=9):\n        \"\"\"Search artist by artist name.\n\n        :params artist_name: artist name.\n        :params quiet: automatically select the best one.\n        :params limit: artist count returned by weapi.\n        :return: a Artist object.\n        \"\"\"\n\n        result = self.search(artist_name, search_type=100, limit=limit)\n\n        if result['result']['artistCount'] <= 0:\n            LOG.warning('Artist %s not existed!', artist_name)\n            raise SearchNotFound('Artist {} not existed.'.format(artist_name))\n        else:\n            artists = result['result']['artists']\n            if quiet:\n                artist_id, artist_name = artists[0]['id'], artists[0]['name']\n                artist = Artist(artist_id, artist_name)\n                return artist\n            else:\n                return self.display.select_one_artist(artists)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch a playlist by name.", "response": "def search_playlist(self, playlist_name, quiet=False, limit=9):\n        \"\"\"Search playlist by playlist name.\n\n        :params playlist_name: playlist name.\n        :params quiet: automatically select the best one.\n        :params limit: playlist count returned by weapi.\n        :return: a Playlist object.\n        \"\"\"\n\n        result = self.search(playlist_name, search_type=1000, limit=limit)\n\n        if result['result']['playlistCount'] <= 0:\n            LOG.warning('Playlist %s not existed!', playlist_name)\n            raise SearchNotFound('playlist {} not existed'.format(playlist_name))\n        else:\n            playlists = result['result']['playlists']\n            if quiet:\n                playlist_id, playlist_name = playlists[0]['id'], playlists[0]['name']\n                playlist = Playlist(playlist_id, playlist_name)\n                return playlist\n            else:\n                return self.display.select_one_playlist(playlists)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_user(self, user_name, quiet=False, limit=9):\n\n        result = self.search(user_name, search_type=1002, limit=limit)\n\n        if result['result']['userprofileCount'] <= 0:\n            LOG.warning('User %s not existed!', user_name)\n            raise SearchNotFound('user {} not existed'.format(user_name))\n        else:\n            users = result['result']['userprofiles']\n            if quiet:\n                user_id, user_name = users[0]['userId'], users[0]['nickname']\n                user = User(user_id, user_name)\n                return user\n            else:\n                return self.display.select_one_user(users)", "response": "Search user by user name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a user s all playlists.", "response": "def get_user_playlists(self, user_id, limit=1000):\n        \"\"\"Get a user's all playlists.\n\n        warning: login is required for private playlist.\n        :params user_id: user id.\n        :params limit: playlist count returned by weapi.\n        :return: a Playlist Object.\n        \"\"\"\n\n        url = 'http://music.163.com/weapi/user/playlist?csrf_token='\n        csrf = ''\n        params = {'offset': 0, 'uid': user_id, 'limit': limit,\n                  'csrf_token': csrf}\n        result = self.post_request(url, params)\n        playlists = result['playlist']\n        return self.display.select_one_playlist(playlists)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a playlist s songs.", "response": "def get_playlist_songs(self, playlist_id, limit=1000):\n        \"\"\"Get a playlists's all songs.\n\n        :params playlist_id: playlist id.\n        :params limit: length of result returned by weapi.\n        :return: a list of Song object.\n        \"\"\"\n\n        url = 'http://music.163.com/weapi/v3/playlist/detail?csrf_token='\n        csrf = ''\n        params = {'id': playlist_id, 'offset': 0, 'total': True,\n                  'limit': limit, 'n': 1000, 'csrf_token': csrf}\n        result = self.post_request(url, params)\n\n        songs = result['playlist']['tracks']\n        songs = [Song(song['id'], song['name']) for song in songs]\n        return songs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a album s all songs.", "response": "def get_album_songs(self, album_id):\n        \"\"\"Get a album's all songs.\n\n        warning: use old api.\n        :params album_id: album id.\n        :return: a list of Song object.\n        \"\"\"\n\n        url = 'http://music.163.com/api/album/{}/'.format(album_id)\n        result = self.get_request(url)\n\n        songs = result['album']['songs']\n        songs = [Song(song['id'], song['name']) for song in songs]\n        return songs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_artists_hot_songs(self, artist_id):\n        url = 'http://music.163.com/api/artist/{}'.format(artist_id)\n        result = self.get_request(url)\n\n        hot_songs = result['hotSongs']\n        songs = [Song(song['id'], song['name']) for song in hot_songs]\n        return songs", "response": "Get a artist s top50 songs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_song_url(self, song_id, bit_rate=320000):\n\n        url = 'http://music.163.com/weapi/song/enhance/player/url?csrf_token='\n        csrf = ''\n        params = {'ids': [song_id], 'br': bit_rate, 'csrf_token': csrf}\n        result = self.post_request(url, params)\n        song_url = result['data'][0]['url']  # download address\n\n        if song_url is None:  # Taylor Swift's song is not available\n            LOG.warning(\n                'Song %s is not available due to copyright issue. => %s',\n                song_id, result)\n            raise SongNotAvailable(\n                'Song {} is not available due to copyright issue.'.format(song_id))\n        else:\n            return song_url", "response": "Get a song s download address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_song_lyric(self, song_id):\n\n        url = 'http://music.163.com/api/song/lyric?os=osx&id={}&lv=-1&kv=-1&tv=-1'.format(  # NOQA\n            song_id)\n        result = self.get_request(url)\n        if 'lrc' in result and result['lrc']['lyric'] is not None:\n            lyric_info = result['lrc']['lyric']\n        else:\n            lyric_info = 'Lyric not found.'\n        return lyric_info", "response": "Get a song s lyric."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading a song and save it to disk.", "response": "def get_song_by_url(self, song_url, song_name, folder, lyric_info):\n        \"\"\"Download a song and save it to disk.\n\n        :params song_url: download address.\n        :params song_name: song name.\n        :params folder: storage path.\n        :params lyric: lyric info.\n        \"\"\"\n\n        if not os.path.exists(folder):\n            os.makedirs(folder)\n        fpath = os.path.join(folder, song_name+'.mp3')\n\n        if sys.platform == 'win32' or sys.platform == 'cygwin':\n            valid_name = re.sub(r'[<>:\"/\\\\|?*]', '', song_name)\n            if valid_name != song_name:\n                click.echo('{} will be saved as: {}.mp3'.format(song_name, valid_name))\n                fpath = os.path.join(folder, valid_name + '.mp3')\n\n        if not os.path.exists(fpath):\n            resp = self.download_session.get(\n                song_url, timeout=self.timeout, stream=True)\n            length = int(resp.headers.get('content-length'))\n            label = 'Downloading {} {}kb'.format(song_name, int(length/1024))\n\n            with click.progressbar(length=length, label=label) as progressbar:\n                with open(fpath, 'wb') as song_file:\n                    for chunk in resp.iter_content(chunk_size=1024):\n                        if chunk:  # filter out keep-alive new chunks\n                            song_file.write(chunk)\n                            progressbar.update(1024)\n\n        if lyric_info:\n            folder = os.path.join(folder, 'lyric')\n            if not os.path.exists(folder):\n                os.makedirs(folder)\n            fpath = os.path.join(folder, song_name+'.lrc')\n            with open(fpath, 'w') as lyric_file:\n                lyric_file.write(lyric_info)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_representation(self, instance):\n        # prepare OrderedDict geojson structure\n        feature = OrderedDict()\n        # the list of fields that will be processed by get_properties\n        # we will remove fields that have been already processed\n        # to increase performance on large numbers\n        fields = list(self.fields.values())\n\n        # optional id attribute\n        if self.Meta.id_field:\n            field = self.fields[self.Meta.id_field]\n            value = field.get_attribute(instance)\n            feature[\"id\"] = field.to_representation(value)\n            fields.remove(field)\n\n        # required type attribute\n        # must be \"Feature\" according to GeoJSON spec\n        feature[\"type\"] = \"Feature\"\n\n        # required geometry attribute\n        # MUST be present in output according to GeoJSON spec\n        field = self.fields[self.Meta.geo_field]\n        geo_value = field.get_attribute(instance)\n        feature[\"geometry\"] = field.to_representation(geo_value)\n        fields.remove(field)\n        # Bounding Box\n        # if auto_bbox feature is enabled\n        # bbox will be determined automatically automatically\n        if self.Meta.auto_bbox and geo_value:\n            feature[\"bbox\"] = geo_value.extent\n        # otherwise it can be determined via another field\n        elif self.Meta.bbox_geo_field:\n            field = self.fields[self.Meta.bbox_geo_field]\n            value = field.get_attribute(instance)\n            feature[\"bbox\"] = value.extent if hasattr(value, 'extent') else None\n            fields.remove(field)\n\n        # GeoJSON properties\n        feature[\"properties\"] = self.get_properties(instance, fields)\n\n        return feature", "response": "Serialize objects -> primitives.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the properties of the current feature metadata which will be used for the GeoJSON properties key.", "response": "def get_properties(self, instance, fields):\n        \"\"\"\n        Get the feature metadata which will be used for the GeoJSON\n        \"properties\" key.\n\n        By default it returns all serializer fields excluding those used for\n        the ID, the geometry and the bounding box.\n\n        :param instance: The current Django model instance\n        :param fields: The list of fields to process (fields already processed have been removed)\n        :return: OrderedDict containing the properties of the current feature\n        :rtype: OrderedDict\n        \"\"\"\n        properties = OrderedDict()\n\n        for field in fields:\n            if field.write_only:\n                continue\n            value = field.get_attribute(instance)\n            representation = None\n            if value is not None:\n                representation = field.to_representation(value)\n            properties[field.field_name] = representation\n\n        return properties"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride the default to_internal_value method to remove the GeoJSON formatting from the data and then add the properties to the data.", "response": "def to_internal_value(self, data):\n        \"\"\"\n        Override the parent method to first remove the GeoJSON formatting\n        \"\"\"\n        if 'properties' in data:\n            data = self.unformat_geojson(data)\n        return super(GeoFeatureModelSerializer, self).to_internal_value(data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _recursive_round(self, value, precision):\n        if hasattr(value, '__iter__'):\n            return tuple(self._recursive_round(v, precision) for v in value)\n        return round(value, precision)", "response": "Recursively round all numbers within an array or nested arrays\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _rm_redundant_points(self, geometry, geo_type):\n        if geo_type in ('MultiPoint', 'LineString'):\n            close = (geo_type == 'LineString')\n            output = []\n            for coord in geometry:\n                coord = tuple(coord)\n                if not output or coord != output[-1]:\n                    output.append(coord)\n            if close and len(output) == 1:\n                output.append(output[0])\n            return tuple(output)\n        if geo_type in ('MultiLineString', 'Polygon'):\n            return [\n                self._rm_redundant_points(c, 'LineString') for c in geometry]\n        if geo_type == 'MultiPolygon':\n            return [self._rm_redundant_points(c, 'Polygon') for c in geometry]\n        return geometry", "response": "Removes redundant coordinates pairs from geometry"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates Django Rest Framework serializer mappings to the corresponding object.", "response": "def ready(self):\n        \"\"\"\n        update Django Rest Framework serializer mappings\n        \"\"\"\n        from django.contrib.gis.db import models\n        from rest_framework.serializers import ModelSerializer\n        from .fields import GeometryField\n\n        try:\n            # drf 3.0\n            field_mapping = ModelSerializer._field_mapping.mapping\n        except AttributeError:\n            # drf 3.1\n            field_mapping = ModelSerializer.serializer_field_mapping\n\n        # map GeoDjango fields to drf-gis GeometryField\n        field_mapping.update({\n            models.GeometryField: GeometryField,\n            models.PointField: GeometryField,\n            models.LineStringField: GeometryField,\n            models.PolygonField: GeometryField,\n            models.MultiPointField: GeometryField,\n            models.MultiLineStringField: GeometryField,\n            models.MultiPolygonField: GeometryField,\n            models.GeometryCollectionField: GeometryField\n        })"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndistances = distance in meters latitude = latitude in degrees at the equator, the distance of one degree is equal in latitude and longitude. at higher latitudes, a degree longitude is shorter in length, proportional to cos(latitude) http://en.wikipedia.org/wiki/Decimal_degrees This function is part of a distance filter where the database 'distance' is in degrees. There's no good single-valued answer to this problem. The distance/ degree is quite constant N/S around the earth (latitude), but varies over a huge range E/W (longitude). Split the difference: I'm going to average the the degrees latitude and degrees longitude corresponding to the given distance. At high latitudes, this will be too short N/S and too long E/W. It splits the errors between the two axes. Errors are < 25 percent for latitudes < 60 degrees N/S.", "response": "def dist_to_deg(self, distance, latitude):\n        \"\"\"\n        distance = distance in meters\n        latitude = latitude in degrees\n\n        at the equator, the distance of one degree is equal in latitude and longitude.\n        at higher latitudes, a degree longitude is shorter in length, proportional to cos(latitude)\n        http://en.wikipedia.org/wiki/Decimal_degrees\n\n        This function is part of a distance filter where the database 'distance' is in degrees.\n        There's no good single-valued answer to this problem.\n        The distance/ degree is quite constant N/S around the earth (latitude),\n        but varies over a huge range E/W (longitude).\n\n        Split the difference: I'm going to average the the degrees latitude and degrees longitude\n        corresponding to the given distance. At high latitudes, this will be too short N/S\n        and too long E/W. It splits the errors between the two axes.\n\n        Errors are < 25 percent for latitudes < 60 degrees N/S.\n        \"\"\"\n        #   d * (180 / pi) / earthRadius   ==> degrees longitude\n        #   (degrees longitude) / cos(latitude)  ==> degrees latitude\n        lat = latitude if latitude >= 0 else -1 * latitude\n        rad2deg = 180 / pi\n        earthRadius = 6378160.0\n        latitudeCorrection = 0.5 * (1 + cos(lat * pi / 180))\n        return (distance / (earthRadius * latitudeCorrection) * rad2deg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _SetCredentials(self, **kwds):\n        args = {\n            'api_key': self._API_KEY,\n            'client': self,\n            'client_id': self._CLIENT_ID,\n            'client_secret': self._CLIENT_SECRET,\n            'package_name': self._PACKAGE,\n            'scopes': self._SCOPES,\n            'user_agent': self._USER_AGENT,\n        }\n        args.update(kwds)\n        # credentials_lib can be expensive to import so do it only if needed.\n        from apitools.base.py import credentials_lib\n        # TODO(craigcitro): It's a bit dangerous to pass this\n        # still-half-initialized self into this method, but we might need\n        # to set attributes on it associated with our credentials.\n        # Consider another way around this (maybe a callback?) and whether\n        # or not it's worth it.\n        self._credentials = credentials_lib.GetCredentials(**args)", "response": "Fetch credentials and set attributes on self. _credentials."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ProcessRequest(self, method_config, request):\n        if self.log_request:\n            logging.info(\n                'Calling method %s with %s: %s', method_config.method_id,\n                method_config.request_type_name, request)\n        return request", "response": "Hook for pre - processing of requests."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ProcessHttpRequest(self, http_request):\n        http_request.headers.update(self.additional_http_headers)\n        if self.log_request:\n            logging.info('Making http %s to %s',\n                         http_request.http_method, http_request.url)\n            logging.info('Headers: %s', pprint.pformat(http_request.headers))\n            if http_request.body:\n                # TODO(craigcitro): Make this safe to print in the case of\n                # non-printable body characters.\n                logging.info('Body:\\n%s',\n                             http_request.loggable_body or http_request.body)\n            else:\n                logging.info('Body: (none)')\n        return http_request", "response": "Hook for pre - processing of http requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef FinalizeTransferUrl(self, url):\n        url_builder = _UrlBuilder.FromUrl(url)\n        if self.global_params.key:\n            url_builder.query_params['key'] = self.global_params.key\n        return url_builder.url", "response": "Modify the url for a given transfer based on auth and version."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the method config for given method.", "response": "def GetMethodConfig(self, method):\n        \"\"\"Returns service cached method config for given method.\"\"\"\n        method_config = self._method_configs.get(method)\n        if method_config:\n            return method_config\n        func = getattr(self, method, None)\n        if func is None:\n            raise KeyError(method)\n        method_config = getattr(func, 'method_config', None)\n        if method_config is None:\n            raise KeyError(method)\n        self._method_configs[method] = config = method_config()\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncombining the given params with the default params.", "response": "def __CombineGlobalParams(self, global_params, default_params):\n        \"\"\"Combine the given params with the defaults.\"\"\"\n        util.Typecheck(global_params, (type(None), self.__client.params_type))\n        result = self.__client.params_type()\n        global_params = global_params or self.__client.params_type()\n        for field in result.all_fields():\n            value = global_params.get_assigned_value(field.name)\n            if value is None:\n                value = default_params.get_assigned_value(field.name)\n            if value not in (None, [], ()):\n                setattr(result, field.name, value)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __FinalUrlValue(self, value, field):\n        if isinstance(field, messages.BytesField) and value is not None:\n            return base64.urlsafe_b64encode(value)\n        elif isinstance(value, six.text_type):\n            return value.encode('utf8')\n        elif isinstance(value, six.binary_type):\n            return value.decode('utf8')\n        elif isinstance(value, datetime.datetime):\n            return value.isoformat()\n        return value", "response": "Encode value for the URL using field to skip encoding for bytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __ConstructQueryParams(self, query_params, request, global_params):\n        # First, handle the global params.\n        global_params = self.__CombineGlobalParams(\n            global_params, self.__client.global_params)\n        global_param_names = util.MapParamNames(\n            [x.name for x in self.__client.params_type.all_fields()],\n            self.__client.params_type)\n        global_params_type = type(global_params)\n        query_info = dict(\n            (param,\n             self.__FinalUrlValue(getattr(global_params, param),\n                                  getattr(global_params_type, param)))\n            for param in global_param_names)\n        # Next, add the query params.\n        query_param_names = util.MapParamNames(query_params, type(request))\n        request_type = type(request)\n        query_info.update(\n            (param,\n             self.__FinalUrlValue(getattr(request, param, None),\n                                  getattr(request_type, param)))\n            for param in query_param_names)\n        query_info = dict((k, v) for k, v in query_info.items()\n                          if v is not None)\n        query_info = self.__EncodePrettyPrint(query_info)\n        query_info = util.MapRequestParams(query_info, type(request))\n        return query_info", "response": "Construct a dictionary of query parameters for this request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __ConstructRelativePath(self, method_config, request,\n                                relative_path=None):\n        \"\"\"Determine the relative path for request.\"\"\"\n        python_param_names = util.MapParamNames(\n            method_config.path_params, type(request))\n        params = dict([(param, getattr(request, param, None))\n                       for param in python_param_names])\n        params = util.MapRequestParams(params, type(request))\n        return util.ExpandRelativePath(method_config, params,\n                                       relative_path=relative_path)", "response": "Construct the relative path for the given request."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes any final general adjustments to the request.", "response": "def __FinalizeRequest(self, http_request, url_builder):\n        \"\"\"Make any final general adjustments to the request.\"\"\"\n        if (http_request.http_method == 'GET' and\n                len(http_request.url) > _MAX_URL_LENGTH):\n            http_request.http_method = 'POST'\n            http_request.headers['x-http-method-override'] = 'GET'\n            http_request.headers[\n                'content-type'] = 'application/x-www-form-urlencoded'\n            http_request.body = url_builder.query\n            url_builder.query_params = {}\n        http_request.url = url_builder.url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess the given http response.", "response": "def __ProcessHttpResponse(self, method_config, http_response, request):\n        \"\"\"Process the given http response.\"\"\"\n        if http_response.status_code not in (http_client.OK,\n                                             http_client.CREATED,\n                                             http_client.NO_CONTENT):\n            raise exceptions.HttpError.FromResponse(\n                http_response, method_config=method_config, request=request)\n        if http_response.status_code == http_client.NO_CONTENT:\n            # TODO(craigcitro): Find out why _replace doesn't seem to work\n            # here.\n            http_response = http_wrapper.Response(\n                info=http_response.info, content='{}',\n                request_url=http_response.request_url)\n\n        content = http_response.content\n        if self._client.response_encoding and isinstance(content, bytes):\n            content = content.decode(self._client.response_encoding)\n\n        if self.__client.response_type_model == 'json':\n            return content\n        response_type = _LoadClass(method_config.response_type_name,\n                                   self.__client.MESSAGES_MODULE)\n        return self.__client.DeserializeMessage(response_type, content)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfilling in the basic headers on http_request.", "response": "def __SetBaseHeaders(self, http_request, client):\n        \"\"\"Fill in the basic headers on http_request.\"\"\"\n        # TODO(craigcitro): Make the default a little better here, and\n        # include the apitools version.\n        user_agent = client.user_agent or 'apitools-client/1.0'\n        http_request.headers['user-agent'] = user_agent\n        http_request.headers['accept'] = 'application/json'\n        http_request.headers['accept-encoding'] = 'gzip, deflate'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfilling in the body on http_request.", "response": "def __SetBody(self, http_request, method_config, request, upload):\n        \"\"\"Fill in the body on http_request.\"\"\"\n        if not method_config.request_field:\n            return\n\n        request_type = _LoadClass(\n            method_config.request_type_name, self.__client.MESSAGES_MODULE)\n        if method_config.request_field == REQUEST_IS_BODY:\n            body_value = request\n            body_type = request_type\n        else:\n            body_value = getattr(request, method_config.request_field)\n            body_field = request_type.field_by_name(\n                method_config.request_field)\n            util.Typecheck(body_field, messages.MessageField)\n            body_type = body_field.type\n\n        # If there was no body provided, we use an empty message of the\n        # appropriate type.\n        body_value = body_value or body_type()\n        if upload and not body_value:\n            # We're going to fill in the body later.\n            return\n        util.Typecheck(body_value, body_type)\n        http_request.headers['content-type'] = 'application/json'\n        http_request.body = self.__client.SerializeMessage(body_value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef PrepareHttpRequest(self, method_config, request, global_params=None,\n                           upload=None, upload_config=None, download=None):\n        \"\"\"Prepares an HTTP request to be sent.\"\"\"\n        request_type = _LoadClass(\n            method_config.request_type_name, self.__client.MESSAGES_MODULE)\n        util.Typecheck(request, request_type)\n        request = self.__client.ProcessRequest(method_config, request)\n\n        http_request = http_wrapper.Request(\n            http_method=method_config.http_method)\n        self.__SetBaseHeaders(http_request, self.__client)\n        self.__SetBody(http_request, method_config, request, upload)\n\n        url_builder = _UrlBuilder(\n            self.__client.url, relative_path=method_config.relative_path)\n        url_builder.query_params = self.__ConstructQueryParams(\n            method_config.query_params, request, global_params)\n\n        # It's important that upload and download go before we fill in the\n        # relative path, so that they can replace it.\n        if upload is not None:\n            upload.ConfigureRequest(upload_config, http_request, url_builder)\n        if download is not None:\n            download.ConfigureRequest(http_request, url_builder)\n\n        url_builder.relative_path = self.__ConstructRelativePath(\n            method_config, request, relative_path=url_builder.relative_path)\n        self.__FinalizeRequest(http_request, url_builder)\n\n        return self.__client.ProcessHttpRequest(http_request)", "response": "Prepares an HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall this method with request.", "response": "def _RunMethod(self, method_config, request, global_params=None,\n                   upload=None, upload_config=None, download=None):\n        \"\"\"Call this method with request.\"\"\"\n        if upload is not None and download is not None:\n            # TODO(craigcitro): This just involves refactoring the logic\n            # below into callbacks that we can pass around; in particular,\n            # the order should be that the upload gets the initial request,\n            # and then passes its reply to a download if one exists, and\n            # then that goes to ProcessResponse and is returned.\n            raise exceptions.NotYetImplementedError(\n                'Cannot yet use both upload and download at once')\n\n        http_request = self.PrepareHttpRequest(\n            method_config, request, global_params, upload, upload_config,\n            download)\n\n        # TODO(craigcitro): Make num_retries customizable on Transfer\n        # objects, and pass in self.__client.num_retries when initializing\n        # an upload or download.\n        if download is not None:\n            download.InitializeDownload(http_request, client=self.client)\n            return\n\n        http_response = None\n        if upload is not None:\n            http_response = upload.InitializeUpload(\n                http_request, client=self.client)\n        if http_response is None:\n            http = self.__client.http\n            if upload and upload.bytes_http:\n                http = upload.bytes_http\n            opts = {\n                'retries': self.__client.num_retries,\n                'max_retry_wait': self.__client.max_retry_wait,\n            }\n            if self.__client.check_response_func:\n                opts['check_response_func'] = self.__client.check_response_func\n            if self.__client.retry_func:\n                opts['retry_func'] = self.__client.retry_func\n            http_response = http_wrapper.MakeRequest(\n                http, http_request, **opts)\n\n        return self.ProcessHttpResponse(method_config, http_response, request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts an HTTP response to the expected message type.", "response": "def ProcessHttpResponse(self, method_config, http_response, request=None):\n        \"\"\"Convert an HTTP response to the expected message type.\"\"\"\n        return self.__client.ProcessResponse(\n            method_config,\n            self.__ProcessHttpResponse(method_config, http_response, request))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a descriptor for an Enum value.", "response": "def describe_enum_value(enum_value):\n    \"\"\"Build descriptor for Enum instance.\n\n    Args:\n      enum_value: Enum value to provide descriptor for.\n\n    Returns:\n      Initialized EnumValueDescriptor instance describing the Enum instance.\n    \"\"\"\n    enum_value_descriptor = EnumValueDescriptor()\n    enum_value_descriptor.name = six.text_type(enum_value.name)\n    enum_value_descriptor.number = enum_value.number\n    return enum_value_descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef describe_enum(enum_definition):\n    enum_descriptor = EnumDescriptor()\n    enum_descriptor.name = enum_definition.definition_name().split('.')[-1]\n\n    values = []\n    for number in enum_definition.numbers():\n        value = enum_definition.lookup_by_number(number)\n        values.append(describe_enum_value(value))\n\n    if values:\n        enum_descriptor.values = values\n\n    return enum_descriptor", "response": "Build a descriptor for an Enum class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef describe_field(field_definition):\n    field_descriptor = FieldDescriptor()\n    field_descriptor.name = field_definition.name\n    field_descriptor.number = field_definition.number\n    field_descriptor.variant = field_definition.variant\n\n    if isinstance(field_definition, messages.EnumField):\n        field_descriptor.type_name = field_definition.type.definition_name()\n\n    if isinstance(field_definition, messages.MessageField):\n        field_descriptor.type_name = (\n            field_definition.message_type.definition_name())\n\n    if field_definition.default is not None:\n        field_descriptor.default_value = _DEFAULT_TO_STRING_MAP[\n            type(field_definition)](field_definition.default)\n\n    # Set label.\n    if field_definition.repeated:\n        field_descriptor.label = FieldDescriptor.Label.REPEATED\n    elif field_definition.required:\n        field_descriptor.label = FieldDescriptor.Label.REQUIRED\n    else:\n        field_descriptor.label = FieldDescriptor.Label.OPTIONAL\n\n    return field_descriptor", "response": "Build descriptor for a single Field instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef describe_message(message_definition):\n    message_descriptor = MessageDescriptor()\n    message_descriptor.name = message_definition.definition_name().split(\n        '.')[-1]\n\n    fields = sorted(message_definition.all_fields(),\n                    key=lambda v: v.number)\n    if fields:\n        message_descriptor.fields = [describe_field(field) for field in fields]\n\n    try:\n        nested_messages = message_definition.__messages__\n    except AttributeError:\n        pass\n    else:\n        message_descriptors = []\n        for name in nested_messages:\n            value = getattr(message_definition, name)\n            message_descriptors.append(describe_message(value))\n\n        message_descriptor.message_types = message_descriptors\n\n    try:\n        nested_enums = message_definition.__enums__\n    except AttributeError:\n        pass\n    else:\n        enum_descriptors = []\n        for name in nested_enums:\n            value = getattr(message_definition, name)\n            enum_descriptors.append(describe_enum(value))\n\n        message_descriptor.enum_types = enum_descriptors\n\n    return message_descriptor", "response": "Build a Descriptor for a Message class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a FileDescriptor instance describing a Python module.", "response": "def describe_file(module):\n    \"\"\"Build a file from a specified Python module.\n\n    Args:\n      module: Python module to describe.\n\n    Returns:\n      Initialized FileDescriptor instance describing the module.\n    \"\"\"\n    descriptor = FileDescriptor()\n    descriptor.package = util.get_package_for_module(module)\n\n    if not descriptor.package:\n        descriptor.package = None\n\n    message_descriptors = []\n    enum_descriptors = []\n\n    # Need to iterate over all top level attributes of the module looking for\n    # message and enum definitions.  Each definition must be itself described.\n    for name in sorted(dir(module)):\n        value = getattr(module, name)\n\n        if isinstance(value, type):\n            if issubclass(value, messages.Message):\n                message_descriptors.append(describe_message(value))\n\n            elif issubclass(value, messages.Enum):\n                enum_descriptors.append(describe_enum(value))\n\n    if message_descriptors:\n        descriptor.message_types = message_descriptors\n\n    if enum_descriptors:\n        descriptor.enum_types = enum_descriptors\n\n    return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef describe_file_set(modules):\n    descriptor = FileSet()\n    file_descriptors = []\n    for module in modules:\n        file_descriptors.append(describe_file(module))\n\n    if file_descriptors:\n        descriptor.files = file_descriptors\n\n    return descriptor", "response": "Build a FileSet instance from a specified Python modules."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef describe(value):\n    if isinstance(value, types.ModuleType):\n        return describe_file(value)\n    elif isinstance(value, messages.Field):\n        return describe_field(value)\n    elif isinstance(value, messages.Enum):\n        return describe_enum_value(value)\n    elif isinstance(value, type):\n        if issubclass(value, messages.Message):\n            return describe_message(value)\n        elif issubclass(value, messages.Enum):\n            return describe_enum(value)\n    return None", "response": "Describe any value as a descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_descriptor_loader(definition_name, importer=__import__):\n    # Attempt to import descriptor as a module.\n    if definition_name.startswith('.'):\n        definition_name = definition_name[1:]\n    if not definition_name.startswith('.'):\n        leaf = definition_name.split('.')[-1]\n        if definition_name:\n            try:\n                module = importer(definition_name, '', '', [leaf])\n            except ImportError:\n                pass\n            else:\n                return describe(module)\n\n    try:\n        # Attempt to use messages.find_definition to find item.\n        return describe(messages.find_definition(definition_name,\n                                                 importer=__import__))\n    except messages.DefinitionNotFoundError as err:\n        # There are things that find_definition will not find, but if\n        # the parent is loaded, its children can be searched for a\n        # match.\n        split_name = definition_name.rsplit('.', 1)\n        if len(split_name) > 1:\n            parent, child = split_name\n            try:\n                parent_definition = import_descriptor_loader(\n                    parent, importer=importer)\n            except messages.DefinitionNotFoundError:\n                # Fall through to original error.\n                pass\n            else:\n                # Check the parent definition for a matching descriptor.\n                if isinstance(parent_definition, EnumDescriptor):\n                    search_list = parent_definition.values or []\n                elif isinstance(parent_definition, MessageDescriptor):\n                    search_list = parent_definition.fields or []\n                else:\n                    search_list = []\n\n                for definition in search_list:\n                    if definition.name == child:\n                        return definition\n\n        # Still didn't find.  Reraise original exception.\n        raise err", "response": "Imports a descriptor from a module or message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lookup_descriptor(self, definition_name):\n        try:\n            return self.__descriptors[definition_name]\n        except KeyError:\n            pass\n\n        if self.__descriptor_loader:\n            definition = self.__descriptor_loader(definition_name)\n            self.__descriptors[definition_name] = definition\n            return definition\n        else:\n            raise messages.DefinitionNotFoundError(\n                'Could not find definition for %s' % definition_name)", "response": "Lookup descriptor by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lookup_package(self, definition_name):\n        while True:\n            descriptor = self.lookup_descriptor(definition_name)\n            if isinstance(descriptor, FileDescriptor):\n                return descriptor.package\n            else:\n                index = definition_name.rfind('.')\n                if index < 0:\n                    return None\n                definition_name = definition_name[:index]", "response": "Determines the package name for any definition name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to load a valid json module.", "response": "def _load_json_module():\n    \"\"\"Try to load a valid json module.\n\n    There are more than one json modules that might be installed.  They are\n    mostly compatible with one another but some versions may be different.\n    This function attempts to load various json modules in a preferred order.\n    It does a basic check to guess if a loaded version of json is compatible.\n\n    Returns:\n      Compatible json module.\n\n    Raises:\n      ImportError if there are no json modules or the loaded json module is\n        not compatible with ProtoRPC.\n    \"\"\"\n    first_import_error = None\n    for module_name in ['json',\n                        'simplejson']:\n        try:\n            module = __import__(module_name, {}, {}, 'json')\n            if not hasattr(module, 'JSONEncoder'):\n                message = (\n                    'json library \"%s\" is not compatible with ProtoRPC' %\n                    module_name)\n                logging.warning(message)\n                raise ImportError(message)\n            else:\n                return module\n        except ImportError as err:\n            if not first_import_error:\n                first_import_error = err\n\n    logging.error('Must use valid json library (json or simplejson)')\n    raise first_import_error"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary instance from a message object.", "response": "def default(self, value):\n        \"\"\"Return dictionary instance from a message object.\n\n        Args:\n        value: Value to get dictionary for.  If not encodable, will\n          call superclasses default method.\n        \"\"\"\n        if isinstance(value, messages.Enum):\n            return str(value)\n\n        if six.PY3 and isinstance(value, bytes):\n            return value.decode('utf8')\n\n        if isinstance(value, messages.Message):\n            result = {}\n            for field in value.all_fields():\n                item = value.get_assigned_value(field.name)\n                if item not in (None, [], ()):\n                    result[field.name] = (\n                        self.__protojson_protocol.encode_field(field, item))\n            # Handle unrecognized fields, so they're included when a message is\n            # decoded then encoded.\n            for unknown_key in value.all_unrecognized_fields():\n                unrecognized_field, _ = value.get_unrecognized_field_info(\n                    unknown_key)\n                # Unknown fields are not encoded as they should have been\n                # processed before we get to here.\n                result[unknown_key] = unrecognized_field\n            return result\n\n        return super(MessageJSONEncoder, self).default(value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encode_field(self, field, value):\n        if isinstance(field, messages.BytesField):\n            if field.repeated:\n                value = [base64.b64encode(byte) for byte in value]\n            else:\n                value = base64.b64encode(value)\n        elif isinstance(field, message_types.DateTimeField):\n            # DateTimeField stores its data as a RFC 3339 compliant string.\n            if field.repeated:\n                value = [i.isoformat() for i in value]\n            else:\n                value = value.isoformat()\n        return value", "response": "Encode a python value to a JSON value appropriate for the given ProtoRPC field instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencoding a Message instance to JSON string.", "response": "def encode_message(self, message):\n        \"\"\"Encode Message instance to JSON string.\n\n        Args:\n          Message instance to encode in to JSON string.\n\n        Returns:\n          String encoding of Message instance in protocol JSON format.\n\n        Raises:\n          messages.ValidationError if message is not initialized.\n        \"\"\"\n        message.check_initialized()\n\n        return json.dumps(message, cls=MessageJSONEncoder,\n                          protojson_protocol=self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode_message(self, message_type, encoded_message):\n        encoded_message = six.ensure_str(encoded_message)\n        if not encoded_message.strip():\n            return message_type()\n\n        dictionary = json.loads(encoded_message)\n        message = self.__decode_dictionary(message_type, dictionary)\n        message.check_initialized()\n        return message", "response": "Merge JSON structure to Message instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the messages. Variant type that describes this value.", "response": "def __find_variant(self, value):\n        \"\"\"Find the messages.Variant type that describes this value.\n\n        Args:\n          value: The value whose variant type is being determined.\n\n        Returns:\n          The messages.Variant value that best describes value's type,\n          or None if it's a type we don't know how to handle.\n\n        \"\"\"\n        if isinstance(value, bool):\n            return messages.Variant.BOOL\n        elif isinstance(value, six.integer_types):\n            return messages.Variant.INT64\n        elif isinstance(value, float):\n            return messages.Variant.DOUBLE\n        elif isinstance(value, six.string_types):\n            return messages.Variant.STRING\n        elif isinstance(value, (list, tuple)):\n            # Find the most specific variant that covers all elements.\n            variant_priority = [None,\n                                messages.Variant.INT64,\n                                messages.Variant.DOUBLE,\n                                messages.Variant.STRING]\n            chosen_priority = 0\n            for v in value:\n                variant = self.__find_variant(v)\n                try:\n                    priority = variant_priority.index(variant)\n                except IndexError:\n                    priority = -1\n                if priority > chosen_priority:\n                    chosen_priority = priority\n            return variant_priority[chosen_priority]\n        # Unrecognized type.\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __decode_dictionary(self, message_type, dictionary):\n        message = message_type()\n        for key, value in six.iteritems(dictionary):\n            if value is None:\n                try:\n                    message.reset(key)\n                except AttributeError:\n                    pass  # This is an unrecognized field, skip it.\n                continue\n\n            try:\n                field = message.field_by_name(key)\n            except KeyError:\n                # Save unknown values.\n                variant = self.__find_variant(value)\n                if variant:\n                    message.set_unrecognized_field(key, value, variant)\n                continue\n\n            if field.repeated:\n                # This should be unnecessary? Or in fact become an error.\n                if not isinstance(value, list):\n                    value = [value]\n                valid_value = [self.decode_field(field, item)\n                               for item in value]\n                setattr(message, field.name, valid_value)\n                continue\n            # This is just for consistency with the old behavior.\n            if value == []:\n                continue\n            try:\n                setattr(message, field.name, self.decode_field(field, value))\n            except messages.DecodeError:\n                # Save unknown enum values.\n                if not isinstance(field, messages.EnumField):\n                    raise\n                variant = self.__find_variant(value)\n                if variant:\n                    message.set_unrecognized_field(key, value, variant)\n\n        return message", "response": "This method takes a dictionary and returns a new Message instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode_field(self, field, value):\n        if isinstance(field, messages.EnumField):\n            try:\n                return field.type(value)\n            except TypeError:\n                raise messages.DecodeError(\n                    'Invalid enum value \"%s\"' % (value or ''))\n\n        elif isinstance(field, messages.BytesField):\n            try:\n                return base64.b64decode(value)\n            except (binascii.Error, TypeError) as err:\n                raise messages.DecodeError('Base64 decoding error: %s' % err)\n\n        elif isinstance(field, message_types.DateTimeField):\n            try:\n                return util.decode_datetime(value)\n            except ValueError as err:\n                raise messages.DecodeError(err)\n\n        elif (isinstance(field, messages.MessageField) and\n              issubclass(field.type, messages.Message)):\n            return self.__decode_dictionary(field.type, value)\n\n        elif (isinstance(field, messages.FloatField) and\n              isinstance(value, (six.integer_types, six.string_types))):\n            try:\n                return float(value)\n            except:  # pylint:disable=bare-except\n                pass\n\n        elif (isinstance(field, messages.IntegerField) and\n              isinstance(value, six.string_types)):\n            try:\n                return int(value)\n            except:  # pylint:disable=bare-except\n                pass\n\n        return value", "response": "Decode a JSON value to a python value compatible with field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef WriteInit(self, out):\n        printer = self._GetPrinter(out)\n        if self.__init_wildcards_file:\n            printer('\"\"\"Common imports for generated %s client library.\"\"\"',\n                    self.__client_info.package)\n            printer('# pylint:disable=wildcard-import')\n        else:\n            printer('\"\"\"Package marker file.\"\"\"')\n        printer()\n        printer('import pkgutil')\n        printer()\n        if self.__init_wildcards_file:\n            printer('from %s import *', self.__base_files_package)\n            if self.__root_package == '.':\n                import_prefix = ''\n            else:\n                import_prefix = '%s.' % self.__root_package\n            printer('from %s%s import *',\n                    import_prefix, self.__client_info.client_rule_name)\n            printer('from %s%s import *',\n                    import_prefix, self.__client_info.messages_rule_name)\n            printer()\n        printer('__path__ = pkgutil.extend_path(__path__, __name__)')", "response": "Write a simple __init__. py for the generated client."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef WriteIntermediateInit(self, out):\n        printer = self._GetPrinter(out)\n        printer('#!/usr/bin/env python')\n        printer('\"\"\"Shared __init__.py for apitools.\"\"\"')\n        printer()\n        printer('from pkgutil import extend_path')\n        printer('__path__ = extend_path(__path__, __name__)')", "response": "Write a simple __init__. py for an intermediate directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef WriteSetupPy(self, out):\n        printer = self._GetPrinter(out)\n        year = datetime.datetime.now().year\n        printer('# Copyright %s Google Inc. All Rights Reserved.' % year)\n        printer('#')\n        printer('# Licensed under the Apache License, Version 2.0 (the'\n                '\"License\");')\n        printer('# you may not use this file except in compliance with '\n                'the License.')\n        printer('# You may obtain a copy of the License at')\n        printer('#')\n        printer('#   http://www.apache.org/licenses/LICENSE-2.0')\n        printer('#')\n        printer('# Unless required by applicable law or agreed to in writing, '\n                'software')\n        printer('# distributed under the License is distributed on an \"AS IS\" '\n                'BASIS,')\n        printer('# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either '\n                'express or implied.')\n        printer('# See the License for the specific language governing '\n                'permissions and')\n        printer('# limitations under the License.')\n        printer()\n        printer('import setuptools')\n        printer('REQUIREMENTS = [')\n        with printer.Indent(indent='    '):\n            parts = self.apitools_version.split('.')\n            major = parts.pop(0)\n            minor = parts.pop(0)\n            printer('\"google-apitools>=%s,~=%s.%s\",',\n                    self.apitools_version, major, minor)\n            printer('\"httplib2>=0.9\",')\n            printer('\"oauth2client>=1.4.12\",')\n        printer(']')\n        printer('_PACKAGE = \"apitools.clients.%s\"' % self.__package)\n        printer()\n        printer('setuptools.setup(')\n        # TODO(craigcitro): Allow customization of these options.\n        with printer.Indent(indent='    '):\n            printer('name=\"google-apitools-%s-%s\",',\n                    self.__package, self.__version)\n            printer('version=\"%s.%s\",',\n                    self.apitools_version, self.__revision)\n            printer('description=\"Autogenerated apitools library for %s\",' % (\n                self.__package,))\n            printer('url=\"https://github.com/google/apitools\",')\n            printer('author=\"Craig Citro\",')\n            printer('author_email=\"craigcitro@google.com\",')\n            printer('packages=setuptools.find_packages(),')\n            printer('install_requires=REQUIREMENTS,')\n            printer('classifiers=[')\n            with printer.Indent(indent='    '):\n                printer('\"Programming Language :: Python :: 2.7\",')\n                printer('\"License :: OSI Approved :: Apache Software '\n                        'License\",')\n            printer('],')\n            printer('license=\"Apache 2.0\",')\n            printer('keywords=\"apitools apitools-%s %s\",' % (\n                self.__package, self.__package))\n        printer(')')", "response": "Write a setup. py for upload to PyPI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DownloadProgressPrinter(response, unused_download):\n    if 'content-range' in response.info:\n        print('Received %s' % response.info['content-range'])\n    else:\n        print('Received %d bytes' % response.length)", "response": "Print download progress based on response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize this download by setting self. http and self. url.", "response": "def _Initialize(self, http, url):\n        \"\"\"Initialize this download by setting self.http and self.url.\n\n        We want the user to be able to override self.http by having set\n        the value in the constructor; in that case, we ignore the provided\n        http.\n\n        Args:\n          http: An httplib2.Http instance or None.\n          url: The url for this transfer.\n\n        Returns:\n          None. Initializes self.\n        \"\"\"\n        self.EnsureUninitialized()\n        if self.http is None:\n            self.__http = http or http_wrapper.GetHttp()\n        self.__url = url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new download object from a filename.", "response": "def FromFile(cls, filename, overwrite=False, auto_transfer=True, **kwds):\n        \"\"\"Create a new download object from a filename.\"\"\"\n        path = os.path.expanduser(filename)\n        if os.path.exists(path) and not overwrite:\n            raise exceptions.InvalidUserInputError(\n                'File %s exists and overwrite not specified' % path)\n        return cls(open(path, 'wb'), close_stream=True,\n                   auto_transfer=auto_transfer, **kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FromStream(cls, stream, auto_transfer=True, total_size=None, **kwds):\n        return cls(stream, auto_transfer=auto_transfer, total_size=total_size,\n                   **kwds)", "response": "Create a new Download object from a stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new Download object from a stream and serialized data.", "response": "def FromData(cls, stream, json_data, http=None, auto_transfer=None,\n                 **kwds):\n        \"\"\"Create a new Download object from a stream and serialized data.\"\"\"\n        info = json.loads(json_data)\n        missing_keys = cls._REQUIRED_SERIALIZATION_KEYS - set(info.keys())\n        if missing_keys:\n            raise exceptions.InvalidDataError(\n                'Invalid serialization data, missing keys: %s' % (\n                    ', '.join(missing_keys)))\n        download = cls.FromStream(stream, **kwds)\n        if auto_transfer is not None:\n            download.auto_transfer = auto_transfer\n        else:\n            download.auto_transfer = info['auto_transfer']\n        setattr(download, '_Download__progress', info['progress'])\n        setattr(download, '_Download__total_size', info['total_size'])\n        download._Initialize(  # pylint: disable=protected-access\n            http, info['url'])\n        return download"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the total size based off info if possible otherwise 0.", "response": "def __SetTotal(self, info):\n        \"\"\"Sets the total size based off info if possible otherwise 0.\"\"\"\n        if 'content-range' in info:\n            _, _, total = info['content-range'].rpartition('/')\n            if total != '*':\n                self.__total_size = int(total)\n        # Note \"total_size is None\" means we don't know it; if no size\n        # info was returned on our initial range request, that means we\n        # have a 0-byte file. (That last statement has been verified\n        # empirically, but is not clearly documented anywhere.)\n        if self.total_size is None:\n            self.__total_size = 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing this download by making a request.", "response": "def InitializeDownload(self, http_request, http=None, client=None):\n        \"\"\"Initialize this download by making a request.\n\n        Args:\n          http_request: The HttpRequest to use to initialize this download.\n          http: The httplib2.Http instance for this request.\n          client: If provided, let this client process the final URL before\n              sending any additional requests. If client is provided and\n              http is not, client.http will be used instead.\n        \"\"\"\n        self.EnsureUninitialized()\n        if http is None and client is None:\n            raise exceptions.UserError('Must provide client or http.')\n        http = http or client.http\n        if client is not None:\n            http_request.url = client.FinalizeTransferUrl(http_request.url)\n        url = http_request.url\n        if self.auto_transfer:\n            end_byte = self.__ComputeEndByte(0)\n            self.__SetRangeHeader(http_request, 0, end_byte)\n            response = http_wrapper.MakeRequest(\n                self.bytes_http or http, http_request)\n            if response.status_code not in self._ACCEPTABLE_STATUSES:\n                raise exceptions.HttpError.FromResponse(response)\n            self.__initial_response = response\n            self.__SetTotal(response.info)\n            url = response.info.get('content-location', response.request_url)\n        if client is not None:\n            url = client.FinalizeTransferUrl(url)\n        self._Initialize(http, url)\n        # Unless the user has requested otherwise, we want to just\n        # go ahead and pump the bytes now.\n        if self.auto_transfer:\n            self.StreamInChunks()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize start and end values based on total size.", "response": "def __NormalizeStartEnd(self, start, end=None):\n        \"\"\"Normalizes start and end values based on total size.\"\"\"\n        if end is not None:\n            if start < 0:\n                raise exceptions.TransferInvalidError(\n                    'Cannot have end index with negative start index ' +\n                    '[start=%d, end=%d]' % (start, end))\n            elif start >= self.total_size:\n                raise exceptions.TransferInvalidError(\n                    'Cannot have start index greater than total size ' +\n                    '[start=%d, total_size=%d]' % (start, self.total_size))\n            end = min(end, self.total_size - 1)\n            if end < start:\n                raise exceptions.TransferInvalidError(\n                    'Range requested with end[%s] < start[%s]' % (end, start))\n            return start, end\n        else:\n            if start < 0:\n                start = max(0, start + self.total_size)\n            return start, self.total_size - 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __ComputeEndByte(self, start, end=None, use_chunks=True):\n        end_byte = end\n\n        if start < 0 and not self.total_size:\n            return end_byte\n\n        if use_chunks:\n            alternate = start + self.chunksize - 1\n            if end_byte is not None:\n                end_byte = min(end_byte, alternate)\n            else:\n                end_byte = alternate\n\n        if self.total_size:\n            alternate = self.total_size - 1\n            if end_byte is not None:\n                end_byte = min(end_byte, alternate)\n            else:\n                end_byte = alternate\n\n        return end_byte", "response": "Compute the last byte to fetch for this request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve a chunk and return the full response.", "response": "def __GetChunk(self, start, end, additional_headers=None):\n        \"\"\"Retrieve a chunk, and return the full response.\"\"\"\n        self.EnsureInitialized()\n        request = http_wrapper.Request(url=self.url)\n        self.__SetRangeHeader(request, start, end=end)\n        if additional_headers is not None:\n            request.headers.update(additional_headers)\n        return http_wrapper.MakeRequest(\n            self.bytes_http, request, retry_func=self.retry_func,\n            retries=self.num_retries)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the response from the AZO ATM and update self. stream.", "response": "def __ProcessResponse(self, response):\n        \"\"\"Process response (by updating self and writing to self.stream).\"\"\"\n        if response.status_code not in self._ACCEPTABLE_STATUSES:\n            # We distinguish errors that mean we made a mistake in setting\n            # up the transfer versus something we should attempt again.\n            if response.status_code in (http_client.FORBIDDEN,\n                                        http_client.NOT_FOUND):\n                raise exceptions.HttpError.FromResponse(response)\n            else:\n                raise exceptions.TransferRetryError(response.content)\n        if response.status_code in (http_client.OK,\n                                    http_client.PARTIAL_CONTENT):\n            try:\n                self.stream.write(six.ensure_binary(response.content))\n            except TypeError:\n                self.stream.write(six.ensure_text(response.content))\n            self.__progress += response.length\n            if response.info and 'content-encoding' in response.info:\n                # TODO(craigcitro): Handle the case where this changes over a\n                # download.\n                self.__encoding = response.info['content-encoding']\n        elif response.status_code == http_client.NO_CONTENT:\n            # It's important to write something to the stream for the case\n            # of a 0-byte download to a file, as otherwise python won't\n            # create the file.\n            self.stream.write('')\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a given byte range from this download in inclusive.", "response": "def GetRange(self, start, end=None, additional_headers=None,\n                 use_chunks=True):\n        \"\"\"Retrieve a given byte range from this download, inclusive.\n\n        Range must be of one of these three forms:\n        * 0 <= start, end = None: Fetch from start to the end of the file.\n        * 0 <= start <= end: Fetch the bytes from start to end.\n        * start < 0, end = None: Fetch the last -start bytes of the file.\n\n        (These variations correspond to those described in the HTTP 1.1\n        protocol for range headers in RFC 2616, sec. 14.35.1.)\n\n        Args:\n          start: (int) Where to start fetching bytes. (See above.)\n          end: (int, optional) Where to stop fetching bytes. (See above.)\n          additional_headers: (bool, optional) Any additional headers to\n              pass with the request.\n          use_chunks: (bool, default: True) If False, ignore self.chunksize\n              and fetch this range in a single request.\n\n        Returns:\n          None. Streams bytes into self.stream.\n        \"\"\"\n        self.EnsureInitialized()\n        progress_end_normalized = False\n        if self.total_size is not None:\n            progress, end_byte = self.__NormalizeStartEnd(start, end)\n            progress_end_normalized = True\n        else:\n            progress = start\n            end_byte = end\n        while (not progress_end_normalized or end_byte is None or\n               progress <= end_byte):\n            end_byte = self.__ComputeEndByte(progress, end=end_byte,\n                                             use_chunks=use_chunks)\n            response = self.__GetChunk(progress, end_byte,\n                                       additional_headers=additional_headers)\n            if not progress_end_normalized:\n                self.__SetTotal(response.info)\n                progress, end_byte = self.__NormalizeStartEnd(start, end)\n                progress_end_normalized = True\n            response = self.__ProcessResponse(response)\n            progress += response.length\n            if response.length == 0:\n                if response.status_code == http_client.OK:\n                    # There can legitimately be no Content-Length header sent\n                    # in some cases (e.g., when there's a Transfer-Encoding\n                    # header) and if this was a 200 response (as opposed to\n                    # 206 Partial Content) we know we're done now without\n                    # looping further on received length.\n                    return\n                raise exceptions.TransferRetryError(\n                    'Zero bytes unexpectedly returned in download response')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstreams the entire download in chunks.", "response": "def StreamInChunks(self, callback=None, finish_callback=None,\n                       additional_headers=None):\n        \"\"\"Stream the entire download in chunks.\"\"\"\n        self.StreamMedia(callback=callback, finish_callback=finish_callback,\n                         additional_headers=additional_headers,\n                         use_chunks=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstreams the entire media in a single request.", "response": "def StreamMedia(self, callback=None, finish_callback=None,\n                    additional_headers=None, use_chunks=True):\n        \"\"\"Stream the entire download.\n\n        Args:\n          callback: (default: None) Callback to call as each chunk is\n              completed.\n          finish_callback: (default: None) Callback to call when the\n              download is complete.\n          additional_headers: (default: None) Additional headers to\n              include in fetching bytes.\n          use_chunks: (bool, default: True) If False, ignore self.chunksize\n              and stream this download in a single request.\n\n        Returns:\n            None. Streams bytes into self.stream.\n        \"\"\"\n        callback = callback or self.progress_callback\n        finish_callback = finish_callback or self.finish_callback\n\n        self.EnsureInitialized()\n        while True:\n            if self.__initial_response is not None:\n                response = self.__initial_response\n                self.__initial_response = None\n            else:\n                end_byte = self.__ComputeEndByte(self.progress,\n                                                 use_chunks=use_chunks)\n                response = self.__GetChunk(\n                    self.progress, end_byte,\n                    additional_headers=additional_headers)\n            if self.total_size is None:\n                self.__SetTotal(response.info)\n            response = self.__ProcessResponse(response)\n            self._ExecuteCallback(callback, response)\n            if (response.status_code == http_client.OK or\n                    self.progress >= self.total_size):\n                break\n        self._ExecuteCallback(finish_callback, response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new Upload object from a file.", "response": "def FromFile(cls, filename, mime_type=None, auto_transfer=True,\n                 gzip_encoded=False, **kwds):\n        \"\"\"Create a new Upload object from a filename.\"\"\"\n        path = os.path.expanduser(filename)\n        if not os.path.exists(path):\n            raise exceptions.NotFoundError('Could not find file %s' % path)\n        if not mime_type:\n            mime_type, _ = mimetypes.guess_type(path)\n            if mime_type is None:\n                raise exceptions.InvalidUserInputError(\n                    'Could not guess mime type for %s' % path)\n        size = os.stat(path).st_size\n        return cls(open(path, 'rb'), mime_type, total_size=size,\n                   close_stream=True, auto_transfer=auto_transfer,\n                   gzip_encoded=gzip_encoded, **kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new Upload object from a stream.", "response": "def FromStream(cls, stream, mime_type, total_size=None, auto_transfer=True,\n                   gzip_encoded=False, **kwds):\n        \"\"\"Create a new Upload object from a stream.\"\"\"\n        if mime_type is None:\n            raise exceptions.InvalidUserInputError(\n                'No mime_type specified for stream')\n        return cls(stream, mime_type, total_size=total_size,\n                   close_stream=False, auto_transfer=auto_transfer,\n                   gzip_encoded=gzip_encoded, **kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new Upload of stream from serialized json_data and http.", "response": "def FromData(cls, stream, json_data, http, auto_transfer=None,\n                 gzip_encoded=False, **kwds):\n        \"\"\"Create a new Upload of stream from serialized json_data and http.\"\"\"\n        info = json.loads(json_data)\n        missing_keys = cls._REQUIRED_SERIALIZATION_KEYS - set(info.keys())\n        if missing_keys:\n            raise exceptions.InvalidDataError(\n                'Invalid serialization data, missing keys: %s' % (\n                    ', '.join(missing_keys)))\n        if 'total_size' in kwds:\n            raise exceptions.InvalidUserInputError(\n                'Cannot override total_size on serialized Upload')\n        upload = cls.FromStream(stream, info['mime_type'],\n                                total_size=info.get('total_size'),\n                                gzip_encoded=gzip_encoded, **kwds)\n        if isinstance(stream, io.IOBase) and not stream.seekable():\n            raise exceptions.InvalidUserInputError(\n                'Cannot restart resumable upload on non-seekable stream')\n        if auto_transfer is not None:\n            upload.auto_transfer = auto_transfer\n        else:\n            upload.auto_transfer = info['auto_transfer']\n        upload.strategy = RESUMABLE_UPLOAD\n        upload._Initialize(  # pylint: disable=protected-access\n            http, info['url'])\n        upload.RefreshResumableUploadState()\n        upload.EnsureInitialized()\n        if upload.auto_transfer:\n            upload.StreamInChunks()\n        return upload"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining and set the default upload strategy for this upload.", "response": "def __SetDefaultUploadStrategy(self, upload_config, http_request):\n        \"\"\"Determine and set the default upload strategy for this upload.\n\n        We generally prefer simple or multipart, unless we're forced to\n        use resumable. This happens when any of (1) the upload is too\n        large, (2) the simple endpoint doesn't support multipart requests\n        and we have metadata, or (3) there is no simple upload endpoint.\n\n        Args:\n          upload_config: Configuration for the upload endpoint.\n          http_request: The associated http request.\n\n        Returns:\n          None.\n        \"\"\"\n        if upload_config.resumable_path is None:\n            self.strategy = SIMPLE_UPLOAD\n        if self.strategy is not None:\n            return\n        strategy = SIMPLE_UPLOAD\n        if (self.total_size is not None and\n                self.total_size > _RESUMABLE_UPLOAD_THRESHOLD):\n            strategy = RESUMABLE_UPLOAD\n        if http_request.body and not upload_config.simple_multipart:\n            strategy = RESUMABLE_UPLOAD\n        if not upload_config.simple_path:\n            strategy = RESUMABLE_UPLOAD\n        self.strategy = strategy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ConfigureRequest(self, upload_config, http_request, url_builder):\n        # Validate total_size vs. max_size\n        if (self.total_size and upload_config.max_size and\n                self.total_size > upload_config.max_size):\n            raise exceptions.InvalidUserInputError(\n                'Upload too big: %s larger than max size %s' % (\n                    self.total_size, upload_config.max_size))\n        # Validate mime type\n        if not util.AcceptableMimeType(upload_config.accept, self.mime_type):\n            raise exceptions.InvalidUserInputError(\n                'MIME type %s does not match any accepted MIME ranges %s' % (\n                    self.mime_type, upload_config.accept))\n\n        self.__SetDefaultUploadStrategy(upload_config, http_request)\n        if self.strategy == SIMPLE_UPLOAD:\n            url_builder.relative_path = upload_config.simple_path\n            if http_request.body:\n                url_builder.query_params['uploadType'] = 'multipart'\n                self.__ConfigureMultipartRequest(http_request)\n            else:\n                url_builder.query_params['uploadType'] = 'media'\n                self.__ConfigureMediaRequest(http_request)\n            # Once the entire body is written, compress the body if configured\n            # to. Both multipart and media request uploads will read the\n            # entire stream into memory, which means full compression is also\n            # safe to perform. Because the strategy is set to SIMPLE_UPLOAD,\n            # StreamInChunks throws an exception, meaning double compression\n            # cannot happen.\n            if self.__gzip_encoded:\n                http_request.headers['Content-Encoding'] = 'gzip'\n                # Turn the body into a stream so that we can compress it, then\n                # read the compressed bytes.  In the event of a retry (e.g. if\n                # our access token has expired), we need to be able to re-read\n                # the body, which we can't do with a stream. So, we consume the\n                # bytes from the stream now and store them in a re-readable\n                # bytes container.\n                http_request.body = (\n                    compression.CompressStream(\n                        six.BytesIO(http_request.body))[0].read())\n        else:\n            url_builder.relative_path = upload_config.resumable_path\n            url_builder.query_params['uploadType'] = 'resumable'\n            self.__ConfigureResumableRequest(http_request)", "response": "Configure the request and url for this upload."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring http_request as a simple request for this upload.", "response": "def __ConfigureMediaRequest(self, http_request):\n        \"\"\"Configure http_request as a simple request for this upload.\"\"\"\n        http_request.headers['content-type'] = self.mime_type\n        http_request.body = self.stream.read()\n        http_request.loggable_body = '<media body>'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconfiguring http_request as a multipart request for this upload.", "response": "def __ConfigureMultipartRequest(self, http_request):\n        \"\"\"Configure http_request as a multipart request for this upload.\"\"\"\n        # This is a multipart/related upload.\n        msg_root = mime_multipart.MIMEMultipart('related')\n        # msg_root should not write out its own headers\n        setattr(msg_root, '_write_headers', lambda self: None)\n\n        # attach the body as one part\n        msg = mime_nonmultipart.MIMENonMultipart(\n            *http_request.headers['content-type'].split('/'))\n        msg.set_payload(http_request.body)\n        msg_root.attach(msg)\n\n        # attach the media as the second part\n        msg = mime_nonmultipart.MIMENonMultipart(*self.mime_type.split('/'))\n        msg['Content-Transfer-Encoding'] = 'binary'\n        msg.set_payload(self.stream.read())\n        msg_root.attach(msg)\n\n        # NOTE: We encode the body, but can't use\n        #       `email.message.Message.as_string` because it prepends\n        #       `> ` to `From ` lines.\n        fp = six.BytesIO()\n        if six.PY3:\n            generator_class = MultipartBytesGenerator\n        else:\n            generator_class = email_generator.Generator\n        g = generator_class(fp, mangle_from_=False)\n        g.flatten(msg_root, unixfrom=False)\n        http_request.body = fp.getvalue()\n\n        multipart_boundary = msg_root.get_boundary()\n        http_request.headers['content-type'] = (\n            'multipart/related; boundary=%r' % multipart_boundary)\n        if isinstance(multipart_boundary, six.text_type):\n            multipart_boundary = multipart_boundary.encode('ascii')\n\n        body_components = http_request.body.split(multipart_boundary)\n        headers, _, _ = body_components[-2].partition(b'\\n\\n')\n        body_components[-2] = b'\\n\\n'.join([headers, b'<media body>\\n\\n--'])\n        http_request.loggable_body = multipart_boundary.join(body_components)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntalking to the server and refresh the state of this resumable upload.", "response": "def RefreshResumableUploadState(self):\n        \"\"\"Talk to the server and refresh the state of this resumable upload.\n\n        Returns:\n          Response if the upload is complete.\n        \"\"\"\n        if self.strategy != RESUMABLE_UPLOAD:\n            return\n        self.EnsureInitialized()\n        refresh_request = http_wrapper.Request(\n            url=self.url, http_method='PUT',\n            headers={'Content-Range': 'bytes */*'})\n        refresh_response = http_wrapper.MakeRequest(\n            self.http, refresh_request, redirections=0,\n            retries=self.num_retries)\n        range_header = self._GetRangeHeaderFromResponse(refresh_response)\n        if refresh_response.status_code in (http_client.OK,\n                                            http_client.CREATED):\n            self.__complete = True\n            self.__progress = self.total_size\n            self.stream.seek(self.progress)\n            # If we're finished, the refresh response will contain the metadata\n            # originally requested. Cache it so it can be returned in\n            # StreamInChunks.\n            self.__final_response = refresh_response\n        elif refresh_response.status_code == http_wrapper.RESUME_INCOMPLETE:\n            if range_header is None:\n                self.__progress = 0\n            else:\n                self.__progress = self.__GetLastByte(range_header) + 1\n            self.stream.seek(self.progress)\n        else:\n            raise exceptions.HttpError.FromResponse(refresh_response)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize this upload from the given http_request.", "response": "def InitializeUpload(self, http_request, http=None, client=None):\n        \"\"\"Initialize this upload from the given http_request.\"\"\"\n        if self.strategy is None:\n            raise exceptions.UserError(\n                'No upload strategy set; did you call ConfigureRequest?')\n        if http is None and client is None:\n            raise exceptions.UserError('Must provide client or http.')\n        if self.strategy != RESUMABLE_UPLOAD:\n            return\n        http = http or client.http\n        if client is not None:\n            http_request.url = client.FinalizeTransferUrl(http_request.url)\n        self.EnsureUninitialized()\n        http_response = http_wrapper.MakeRequest(http, http_request,\n                                                 retries=self.num_retries)\n        if http_response.status_code != http_client.OK:\n            raise exceptions.HttpError.FromResponse(http_response)\n\n        self.__server_chunk_granularity = http_response.info.get(\n            'X-Goog-Upload-Chunk-Granularity')\n        url = http_response.info['location']\n        if client is not None:\n            url = client.FinalizeTransferUrl(url)\n        self._Initialize(http, url)\n\n        # Unless the user has requested otherwise, we want to just\n        # go ahead and pump the bytes now.\n        if self.auto_transfer:\n            return self.StreamInChunks()\n        return http_response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstreaming the media in a single thread.", "response": "def __StreamMedia(self, callback=None, finish_callback=None,\n                      additional_headers=None, use_chunks=True):\n        \"\"\"Helper function for StreamMedia / StreamInChunks.\"\"\"\n        if self.strategy != RESUMABLE_UPLOAD:\n            raise exceptions.InvalidUserInputError(\n                'Cannot stream non-resumable upload')\n        callback = callback or self.progress_callback\n        finish_callback = finish_callback or self.finish_callback\n        # final_response is set if we resumed an already-completed upload.\n        response = self.__final_response\n\n        def CallSendChunk(start):\n            return self.__SendChunk(\n                start, additional_headers=additional_headers)\n\n        def CallSendMediaBody(start):\n            return self.__SendMediaBody(\n                start, additional_headers=additional_headers)\n\n        send_func = CallSendChunk if use_chunks else CallSendMediaBody\n        if not use_chunks and self.__gzip_encoded:\n            raise exceptions.InvalidUserInputError(\n                'Cannot gzip encode non-chunked upload')\n        if use_chunks:\n            self.__ValidateChunksize(self.chunksize)\n        self.EnsureInitialized()\n        while not self.complete:\n            response = send_func(self.stream.tell())\n            if response.status_code in (http_client.OK, http_client.CREATED):\n                self.__complete = True\n                break\n            if response.status_code not in (\n                    http_client.OK, http_client.CREATED,\n                    http_wrapper.RESUME_INCOMPLETE):\n                # Only raise an exception if the error is something we can't\n                # recover from.\n                if (self.strategy != RESUMABLE_UPLOAD or\n                        not self.__IsRetryable(response)):\n                    raise exceptions.HttpError.FromResponse(response)\n                # We want to reset our state to wherever the server left us\n                # before this failed request, and then raise.\n                self.RefreshResumableUploadState()\n\n                self._ExecuteCallback(callback, response)\n                continue\n\n            self.__progress = self.__GetLastByte(\n                self._GetRangeHeaderFromResponse(response))\n            if self.progress + 1 != self.stream.tell():\n                # TODO(craigcitro): Add a better way to recover here.\n                raise exceptions.CommunicationError(\n                    'Failed to transfer all bytes in chunk, upload paused at '\n                    'byte %d' % self.progress)\n            self._ExecuteCallback(callback, response)\n        if self.__complete and hasattr(self.stream, 'seek'):\n            current_pos = self.stream.tell()\n            self.stream.seek(0, os.SEEK_END)\n            end_pos = self.stream.tell()\n            self.stream.seek(current_pos)\n            if current_pos != end_pos:\n                raise exceptions.TransferInvalidError(\n                    'Upload complete with %s additional bytes left in stream' %\n                    (int(end_pos) - int(current_pos)))\n        self._ExecuteCallback(finish_callback, response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends this resumable upload in a single request.", "response": "def StreamMedia(self, callback=None, finish_callback=None,\n                    additional_headers=None):\n        \"\"\"Send this resumable upload in a single request.\n\n        Args:\n          callback: Progress callback function with inputs\n              (http_wrapper.Response, transfer.Upload)\n          finish_callback: Final callback function with inputs\n              (http_wrapper.Response, transfer.Upload)\n          additional_headers: Dict of headers to include with the upload\n              http_wrapper.Request.\n\n        Returns:\n          http_wrapper.Response of final response.\n        \"\"\"\n        return self.__StreamMedia(\n            callback=callback, finish_callback=finish_callback,\n            additional_headers=additional_headers, use_chunks=False)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef StreamInChunks(self, callback=None, finish_callback=None,\n                       additional_headers=None):\n        \"\"\"Send this (resumable) upload in chunks.\"\"\"\n        return self.__StreamMedia(\n            callback=callback, finish_callback=finish_callback,\n            additional_headers=additional_headers)", "response": "Send this ( resumable ) upload in chunks."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __SendMediaRequest(self, request, end):\n        def CheckResponse(response):\n            if response is None:\n                # Caller shouldn't call us if the response is None,\n                # but handle anyway.\n                raise exceptions.RequestError(\n                    'Request to url %s did not return a response.' %\n                    response.request_url)\n        response = http_wrapper.MakeRequest(\n            self.bytes_http, request, retry_func=self.retry_func,\n            retries=self.num_retries, check_response_func=CheckResponse)\n        if response.status_code == http_wrapper.RESUME_INCOMPLETE:\n            last_byte = self.__GetLastByte(\n                self._GetRangeHeaderFromResponse(response))\n            if last_byte + 1 != end:\n                self.stream.seek(last_byte + 1)\n        return response", "response": "Send a request to the specified url."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __SendMediaBody(self, start, additional_headers=None):\n        self.EnsureInitialized()\n        if self.total_size is None:\n            raise exceptions.TransferInvalidError(\n                'Total size must be known for SendMediaBody')\n        body_stream = stream_slice.StreamSlice(\n            self.stream, self.total_size - start)\n\n        request = http_wrapper.Request(url=self.url, http_method='PUT',\n                                       body=body_stream)\n        request.headers['Content-Type'] = self.mime_type\n        if start == self.total_size:\n            # End of an upload with 0 bytes left to send; just finalize.\n            range_string = 'bytes */%s' % self.total_size\n        else:\n            range_string = 'bytes %s-%s/%s' % (start, self.total_size - 1,\n                                               self.total_size)\n\n        request.headers['Content-Range'] = range_string\n        if additional_headers:\n            request.headers.update(additional_headers)\n\n        return self.__SendMediaRequest(request, self.total_size)", "response": "Send the entire media stream in a single request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __SendChunk(self, start, additional_headers=None):\n        self.EnsureInitialized()\n        no_log_body = self.total_size is None\n        request = http_wrapper.Request(url=self.url, http_method='PUT')\n        if self.__gzip_encoded:\n            request.headers['Content-Encoding'] = 'gzip'\n            body_stream, read_length, exhausted = compression.CompressStream(\n                self.stream, self.chunksize)\n            end = start + read_length\n            # If the stream length was previously unknown and the input stream\n            # is exhausted, then we're at the end of the stream.\n            if self.total_size is None and exhausted:\n                self.__total_size = end\n        elif self.total_size is None:\n            # For the streaming resumable case, we need to detect when\n            # we're at the end of the stream.\n            body_stream = buffered_stream.BufferedStream(\n                self.stream, start, self.chunksize)\n            end = body_stream.stream_end_position\n            if body_stream.stream_exhausted:\n                self.__total_size = end\n            # TODO: Here, change body_stream from a stream to a string object,\n            # which means reading a chunk into memory.  This works around\n            # https://code.google.com/p/httplib2/issues/detail?id=176 which can\n            # cause httplib2 to skip bytes on 401's for file objects.\n            # Rework this solution to be more general.\n            body_stream = body_stream.read(self.chunksize)\n        else:\n            end = min(start + self.chunksize, self.total_size)\n            body_stream = stream_slice.StreamSlice(self.stream, end - start)\n        # TODO(craigcitro): Think about clearer errors on \"no data in\n        # stream\".\n        request.body = body_stream\n        request.headers['Content-Type'] = self.mime_type\n        if no_log_body:\n            # Disable logging of streaming body.\n            # TODO: Remove no_log_body and rework as part of a larger logs\n            # refactor.\n            request.loggable_body = '<media body>'\n        if self.total_size is None:\n            # Streaming resumable upload case, unknown total size.\n            range_string = 'bytes %s-%s/*' % (start, end - 1)\n        elif end == start:\n            # End of an upload with 0 bytes left to send; just finalize.\n            range_string = 'bytes */%s' % self.total_size\n        else:\n            # Normal resumable upload case with known sizes.\n            range_string = 'bytes %s-%s/%s' % (start, end - 1, self.total_size)\n\n        request.headers['Content-Range'] = range_string\n        if additional_headers:\n            request.headers.update(additional_headers)\n\n        return self.__SendMediaRequest(request, end)", "response": "Send a chunk of data from the stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncompressing a file - like stream into a file - like buffer.", "response": "def CompressStream(in_stream, length=None, compresslevel=2,\n                   chunksize=16777216):\n\n    \"\"\"Compresses an input stream into a file-like buffer.\n\n    This reads from the input stream until either we've stored at least length\n    compressed bytes, or the input stream has been exhausted.\n\n    This supports streams of unknown size.\n\n    Args:\n        in_stream: The input stream to read from.\n        length: The target number of compressed bytes to buffer in the output\n            stream. If length is none, the input stream will be compressed\n            until it's exhausted.\n\n            The actual length of the output buffer can vary from the target.\n            If the input stream is exhaused, the output buffer may be smaller\n            than expected. If the data is incompressible, the maximum length\n            can be exceeded by can be calculated to be:\n\n              chunksize + 5 * (floor((chunksize - 1) / 16383) + 1) + 17\n\n            This accounts for additional header data gzip adds. For the default\n            16MiB chunksize, this results in the max size of the output buffer\n            being:\n\n              length + 16Mib + 5142 bytes\n\n        compresslevel: Optional, defaults to 2. The desired compression level.\n        chunksize: Optional, defaults to 16MiB. The chunk size used when\n            reading data from the input stream to write into the output\n            buffer.\n\n    Returns:\n        A file-like output buffer of compressed bytes, the number of bytes read\n        from the input stream, and a flag denoting if the input stream was\n        exhausted.\n    \"\"\"\n    in_read = 0\n    in_exhausted = False\n    out_stream = StreamingBuffer()\n    with gzip.GzipFile(mode='wb',\n                       fileobj=out_stream,\n                       compresslevel=compresslevel) as compress_stream:\n        # Read until we've written at least length bytes to the output stream.\n        while not length or out_stream.length < length:\n            data = in_stream.read(chunksize)\n            data_length = len(data)\n            compress_stream.write(data)\n            in_read += data_length\n            # If we read less than requested, the stream is exhausted.\n            if data_length < chunksize:\n                in_exhausted = True\n                break\n    return out_stream, in_read, in_exhausted"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads at most size bytes from this buffer.", "response": "def read(self, size=None):\n        \"\"\"Read at most size bytes from this buffer.\n\n        Bytes read from this buffer are consumed and are permanently removed.\n\n        Args:\n          size: If provided, read no more than size bytes from the buffer.\n            Otherwise, this reads the entire buffer.\n\n        Returns:\n          The bytes read from this buffer.\n        \"\"\"\n        if size is None:\n            size = self.__size\n        ret_list = []\n        while size > 0 and self.__buf:\n            data = self.__buf.popleft()\n            size -= len(data)\n            ret_list.append(data)\n        if size < 0:\n            ret_list[-1], remainder = ret_list[-1][:size], ret_list[-1][size:]\n            self.__buf.appendleft(remainder)\n        ret = b''.join(ret_list)\n        self.__size -= len(ret)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _WriteFile(file_descriptor, package, version, proto_printer):\n    proto_printer.PrintPreamble(package, version, file_descriptor)\n    _PrintEnums(proto_printer, file_descriptor.enum_types)\n    _PrintMessages(proto_printer, file_descriptor.message_types)\n    custom_json_mappings = _FetchCustomMappings(file_descriptor.enum_types)\n    custom_json_mappings.extend(\n        _FetchCustomMappings(file_descriptor.message_types))\n    for mapping in custom_json_mappings:\n        proto_printer.PrintCustomJsonMapping(mapping)", "response": "Writes the given extended file descriptor to the printer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the given extended file descriptor to out as a message file.", "response": "def WriteMessagesFile(file_descriptor, package, version, printer):\n    \"\"\"Write the given extended file descriptor to out as a message file.\"\"\"\n    _WriteFile(file_descriptor, package, version,\n               _Proto2Printer(printer))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef WritePythonFile(file_descriptor, package, version, printer):\n    _WriteFile(file_descriptor, package, version,\n               _ProtoRpcPrinter(printer))", "response": "Write the given extended file descriptor to out."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _FetchCustomMappings(descriptor_ls):\n    custom_mappings = []\n    for descriptor in descriptor_ls:\n        if isinstance(descriptor, ExtendedEnumDescriptor):\n            custom_mappings.extend(\n                _FormatCustomJsonMapping('Enum', m, descriptor)\n                for m in descriptor.enum_mappings)\n        elif isinstance(descriptor, ExtendedMessageDescriptor):\n            custom_mappings.extend(\n                _FormatCustomJsonMapping('Field', m, descriptor)\n                for m in descriptor.field_mappings)\n            custom_mappings.extend(\n                _FetchCustomMappings(descriptor.enum_types))\n            custom_mappings.extend(\n                _FetchCustomMappings(descriptor.message_types))\n    return custom_mappings", "response": "Find and return all custom mappings for descriptors in descriptor_ls."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints all enums to the given proto_printer.", "response": "def _PrintEnums(proto_printer, enum_types):\n    \"\"\"Print all enums to the given proto_printer.\"\"\"\n    enum_types = sorted(enum_types, key=operator.attrgetter('name'))\n    for enum_type in enum_types:\n        proto_printer.PrintEnum(enum_type)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __PrintMessageCommentLines(self, message_type):\n        description = message_type.description or '%s message type.' % (\n            message_type.name)\n        width = self.__printer.CalculateWidth() - 3\n        for line in textwrap.wrap(description, width):\n            self.__printer('// %s', line)\n        PrintIndentedDescriptions(self.__printer, message_type.enum_types,\n                                  'Enums', prefix='// ')\n        PrintIndentedDescriptions(self.__printer, message_type.message_types,\n                                  'Messages', prefix='// ')\n        PrintIndentedDescriptions(self.__printer, message_type.fields,\n                                  'Fields', prefix='// ')", "response": "Print the description of this message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __PrintAdditionalImports(self, imports):\n        google_imports = [x for x in imports if 'google' in x]\n        other_imports = [x for x in imports if 'google' not in x]\n        if other_imports:\n            for import_ in sorted(other_imports):\n                self.__printer(import_)\n            self.__printer()\n        # Note: If we ever were going to add imports from this package, we'd\n        # need to sort those out and put them at the end.\n        if google_imports:\n            for import_ in sorted(google_imports):\n                self.__printer(import_)\n            self.__printer()", "response": "Print additional imports needed for protorpc."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting the docstring for this message.", "response": "def __PrintMessageDocstringLines(self, message_type):\n        \"\"\"Print the docstring for this message.\"\"\"\n        description = message_type.description or '%s message type.' % (\n            message_type.name)\n        short_description = (\n            _EmptyMessage(message_type) and\n            len(description) < (self.__printer.CalculateWidth() - 6))\n        with self.__printer.CommentContext():\n            if short_description:\n                # Note that we use explicit string interpolation here since\n                # we're in comment context.\n                self.__printer('r\"\"\"%s\"\"\"' % description)\n                return\n            for line in textwrap.wrap('r\"\"\"%s' % description,\n                                      self.__printer.CalculateWidth()):\n                self.__printer(line)\n\n            PrintIndentedDescriptions(self.__printer, message_type.enum_types,\n                                      'Enums')\n            PrintIndentedDescriptions(\n                self.__printer, message_type.message_types, 'Messages')\n            PrintIndentedDescriptions(\n                self.__printer, message_type.fields, 'Fields')\n            self.__printer('\"\"\"')\n            self.__printer()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_package_for_module(module):\n    if isinstance(module, six.string_types):\n        try:\n            module = sys.modules[module]\n        except KeyError:\n            return None\n\n    try:\n        return six.text_type(module.package)\n    except AttributeError:\n        if module.__name__ == '__main__':\n            try:\n                file_name = module.__file__\n            except AttributeError:\n                pass\n            else:\n                base_name = os.path.basename(file_name)\n                split_name = os.path.splitext(base_name)\n                if len(split_name) == 1:\n                    return six.text_type(base_name)\n                return u'.'.join(split_name[:-1])\n\n        return six.text_type(module.__name__)", "response": "Get package name for a module."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode_datetime(encoded_datetime):\n    # Check if the string includes a time zone offset.  Break out the\n    # part that doesn't include time zone info.  Convert to uppercase\n    # because all our comparisons should be case-insensitive.\n    time_zone_match = _TIME_ZONE_RE.search(encoded_datetime)\n    if time_zone_match:\n        time_string = encoded_datetime[:time_zone_match.start(1)].upper()\n    else:\n        time_string = encoded_datetime.upper()\n\n    if '.' in time_string:\n        format_string = '%Y-%m-%dT%H:%M:%S.%f'\n    else:\n        format_string = '%Y-%m-%dT%H:%M:%S'\n\n    decoded_datetime = datetime.datetime.strptime(time_string, format_string)\n\n    if not time_zone_match:\n        return decoded_datetime\n\n    # Time zone info was included in the parameter.  Add a tzinfo\n    # object to the datetime.  Datetimes can't be changed after they're\n    # created, so we'll need to create a new one.\n    if time_zone_match.group('z'):\n        offset_minutes = 0\n    else:\n        sign = time_zone_match.group('sign')\n        hours, minutes = [int(value) for value in\n                          time_zone_match.group('hours', 'minutes')]\n        offset_minutes = hours * 60 + minutes\n        if sign == '-':\n            offset_minutes *= -1\n\n    return datetime.datetime(decoded_datetime.year,\n                             decoded_datetime.month,\n                             decoded_datetime.day,\n                             decoded_datetime.hour,\n                             decoded_datetime.minute,\n                             decoded_datetime.second,\n                             decoded_datetime.microsecond,\n                             TimeZoneOffset(offset_minutes))", "response": "Decode a DateTimeField parameter from a string to a python datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef value_from_message(self, message):\n        message = super(DateTimeField, self).value_from_message(message)\n        if message.time_zone_offset is None:\n            return datetime.datetime.utcfromtimestamp(\n                message.milliseconds / 1000.0)\n\n        # Need to subtract the time zone offset, because when we call\n        # datetime.fromtimestamp, it will add the time zone offset to the\n        # value we pass.\n        milliseconds = (message.milliseconds -\n                        60000 * message.time_zone_offset)\n\n        timezone = util.TimeZoneOffset(message.time_zone_offset)\n        return datetime.datetime.fromtimestamp(milliseconds / 1000.0,\n                                               tz=timezone)", "response": "Convert a DateTimeMessage to a datetime. datetime."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DetectGce():\n    metadata_url = 'http://{}'.format(\n        os.environ.get('GCE_METADATA_ROOT', 'metadata.google.internal'))\n    try:\n        o = urllib_request.build_opener(urllib_request.ProxyHandler({})).open(\n            urllib_request.Request(\n                metadata_url, headers={'Metadata-Flavor': 'Google'}))\n    except urllib_error.URLError:\n        return False\n    return (o.getcode() == http_client.OK and\n            o.headers.get('metadata-flavor') == 'Google')", "response": "Detects whether or not we re running on a GCE instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnormalizes scope_spec to a set of strings.", "response": "def NormalizeScopes(scope_spec):\n    \"\"\"Normalize scope_spec to a set of strings.\"\"\"\n    if isinstance(scope_spec, six.string_types):\n        return set(scope_spec.split(' '))\n    elif isinstance(scope_spec, collections.Iterable):\n        return set(scope_spec)\n    raise exceptions.TypecheckError(\n        'NormalizeScopes expected string or iterable, found %s' % (\n            type(scope_spec),))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexpands the relative path for the request.", "response": "def ExpandRelativePath(method_config, params, relative_path=None):\n    \"\"\"Determine the relative path for request.\"\"\"\n    path = relative_path or method_config.relative_path or ''\n\n    for param in method_config.path_params:\n        param_template = '{%s}' % param\n        # For more details about \"reserved word expansion\", see:\n        #   http://tools.ietf.org/html/rfc6570#section-3.2.2\n        reserved_chars = ''\n        reserved_template = '{+%s}' % param\n        if reserved_template in path:\n            reserved_chars = _RESERVED_URI_CHARS\n            path = path.replace(reserved_template, param_template)\n        if param_template not in path:\n            raise exceptions.InvalidUserInputError(\n                'Missing path parameter %s' % param)\n        try:\n            # TODO(craigcitro): Do we want to support some sophisticated\n            # mapping here?\n            value = params[param]\n        except KeyError:\n            raise exceptions.InvalidUserInputError(\n                'Request missing required parameter %s' % param)\n        if value is None:\n            raise exceptions.InvalidUserInputError(\n                'Request missing required parameter %s' % param)\n        try:\n            if not isinstance(value, six.string_types):\n                value = str(value)\n            path = path.replace(param_template,\n                                urllib_parse.quote(value.encode('utf_8'),\n                                                   reserved_chars))\n        except TypeError as e:\n            raise exceptions.InvalidUserInputError(\n                'Error setting required parameter %s to value %s: %s' % (\n                    param, value, e))\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef CalculateWaitForRetry(retry_attempt, max_wait=60):\n\n    wait_time = 2 ** retry_attempt\n    max_jitter = wait_time / 4.0\n    wait_time += random.uniform(-max_jitter, max_jitter)\n    return max(1, min(wait_time, max_wait))", "response": "Calculates amount of time to wait before a retry attempt."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True iff mime_type matches one of the accept_patterns.", "response": "def AcceptableMimeType(accept_patterns, mime_type):\n    \"\"\"Return True iff mime_type is acceptable for one of accept_patterns.\n\n    Note that this function assumes that all patterns in accept_patterns\n    will be simple types of the form \"type/subtype\", where one or both\n    of these can be \"*\". We do not support parameters (i.e. \"; q=\") in\n    patterns.\n\n    Args:\n      accept_patterns: list of acceptable MIME types.\n      mime_type: the mime type we would like to match.\n\n    Returns:\n      Whether or not mime_type matches (at least) one of these patterns.\n    \"\"\"\n    if '/' not in mime_type:\n        raise exceptions.InvalidUserInputError(\n            'Invalid MIME type: \"%s\"' % mime_type)\n    unsupported_patterns = [p for p in accept_patterns if ';' in p]\n    if unsupported_patterns:\n        raise exceptions.GeneratedClientError(\n            'MIME patterns with parameter unsupported: \"%s\"' % ', '.join(\n                unsupported_patterns))\n\n    def MimeTypeMatches(pattern, mime_type):\n        \"\"\"Return True iff mime_type is acceptable for pattern.\"\"\"\n        # Some systems use a single '*' instead of '*/*'.\n        if pattern == '*':\n            pattern = '*/*'\n        return all(accept in ('*', provided) for accept, provided\n                   in zip(pattern.split('/'), mime_type.split('/')))\n\n    return any(MimeTypeMatches(pattern, mime_type)\n               for pattern in accept_patterns)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreverses parameter remappings for URL construction.", "response": "def MapParamNames(params, request_type):\n    \"\"\"Reverse parameter remappings for URL construction.\"\"\"\n    return [encoding.GetCustomJsonFieldMapping(request_type, json_name=p) or p\n            for p in params]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef MapRequestParams(params, request_type):\n    new_params = dict(params)\n    for param_name, value in params.items():\n        field_remapping = encoding.GetCustomJsonFieldMapping(\n            request_type, python_name=param_name)\n        if field_remapping is not None:\n            new_params[field_remapping] = new_params.pop(param_name)\n            param_name = field_remapping\n        if isinstance(value, messages.Enum):\n            new_params[param_name] = encoding.GetCustomJsonEnumMapping(\n                type(value), python_name=str(value)) or str(value)\n    return new_params", "response": "Maps the given dictionary of parameters to values for the specified request type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _JsonValueToPythonValue(json_value):\n    util.Typecheck(json_value, JsonValue)\n    _ValidateJsonValue(json_value)\n    if json_value.is_null:\n        return None\n    entries = [(f, json_value.get_assigned_value(f.name))\n               for f in json_value.all_fields()]\n    assigned_entries = [(f, value)\n                        for f, value in entries if value is not None]\n    field, value = assigned_entries[0]\n    if not isinstance(field, messages.MessageField):\n        return value\n    elif field.message_type is JsonObject:\n        return _JsonObjectToPythonValue(value)\n    elif field.message_type is JsonArray:\n        return _JsonArrayToPythonValue(value)", "response": "Convert the given JsonValue to a json string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the given python value to a JsonValue.", "response": "def _PythonValueToJsonValue(py_value):\n    \"\"\"Convert the given python value to a JsonValue.\"\"\"\n    if py_value is None:\n        return JsonValue(is_null=True)\n    if isinstance(py_value, bool):\n        return JsonValue(boolean_value=py_value)\n    if isinstance(py_value, six.string_types):\n        return JsonValue(string_value=py_value)\n    if isinstance(py_value, numbers.Number):\n        if isinstance(py_value, six.integer_types):\n            if _MININT64 < py_value < _MAXINT64:\n                return JsonValue(integer_value=py_value)\n        return JsonValue(double_value=float(py_value))\n    if isinstance(py_value, dict):\n        return JsonValue(object_value=_PythonValueToJsonObject(py_value))\n    if isinstance(py_value, collections.Iterable):\n        return JsonValue(array_value=_PythonValueToJsonArray(py_value))\n    raise exceptions.InvalidDataError(\n        'Cannot convert \"%s\" to JsonValue' % py_value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _EncodeInt64Field(field, value):\n    capabilities = [\n        messages.Variant.INT64,\n        messages.Variant.UINT64,\n    ]\n    if field.variant not in capabilities:\n        return encoding.CodecResult(value=value, complete=False)\n\n    if field.repeated:\n        result = [str(x) for x in value]\n    else:\n        result = str(value)\n    return encoding.CodecResult(value=result, complete=True)", "response": "Handle the special case of int64 as a string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning s with unicode homoglyphs replaced by ascii equivalents.", "response": "def ReplaceHomoglyphs(s):\n    \"\"\"Returns s with unicode homoglyphs replaced by ascii equivalents.\"\"\"\n    homoglyphs = {\n        '\\xa0': ' ',  # &nbsp; ?\n        '\\u00e3': '',  # TODO(gsfowler) drop after .proto spurious char elided\n        '\\u00a0': ' ',  # &nbsp; ?\n        '\\u00a9': '(C)',  # COPYRIGHT SIGN (would you believe \"asciiglyph\"?)\n        '\\u00ae': '(R)',  # REGISTERED SIGN (would you believe \"asciiglyph\"?)\n        '\\u2014': '-',  # EM DASH\n        '\\u2018': \"'\",  # LEFT SINGLE QUOTATION MARK\n        '\\u2019': \"'\",  # RIGHT SINGLE QUOTATION MARK\n        '\\u201c': '\"',  # LEFT DOUBLE QUOTATION MARK\n        '\\u201d': '\"',  # RIGHT DOUBLE QUOTATION MARK\n        '\\u2026': '...',  # HORIZONTAL ELLIPSIS\n        '\\u2e3a': '-',  # TWO-EM DASH\n    }\n\n    def _ReplaceOne(c):\n        \"\"\"Returns the homoglyph or escaped replacement for c.\"\"\"\n        equiv = homoglyphs.get(c)\n        if equiv is not None:\n            return equiv\n        try:\n            c.encode('ascii')\n            return c\n        except UnicodeError:\n            pass\n        try:\n            return c.encode('unicode-escape').decode('ascii')\n        except UnicodeError:\n            return '?'\n\n    return ''.join([_ReplaceOne(c) for c in s])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef CleanDescription(description):\n    if not isinstance(description, six.string_types):\n        return description\n    if six.PY3:\n        # https://docs.python.org/3/reference/lexical_analysis.html#index-18\n        description = description.replace('\\\\N', '\\\\\\\\N')\n        description = description.replace('\\\\u', '\\\\\\\\u')\n        description = description.replace('\\\\U', '\\\\\\\\U')\n    description = ReplaceHomoglyphs(description)\n    return description.replace('\"\"\"', '\" \" \"')", "response": "Return a version of description safe for printing in a docstring."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexpanding a few abbreviations into full discovery urls.", "response": "def _NormalizeDiscoveryUrls(discovery_url):\n    \"\"\"Expands a few abbreviations into full discovery urls.\"\"\"\n    if discovery_url.startswith('http'):\n        return [discovery_url]\n    elif '.' not in discovery_url:\n        raise ValueError('Unrecognized value \"%s\" for discovery url')\n    api_name, _, api_version = discovery_url.partition('.')\n    return [\n        'https://www.googleapis.com/discovery/v1/apis/%s/%s/rest' % (\n            api_name, api_version),\n        'https://%s.googleapis.com/$discovery/rest?version=%s' % (\n            api_name, api_version),\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _Gunzip(gzipped_content):\n    f = tempfile.NamedTemporaryFile(suffix='gz', mode='w+b', delete=False)\n    try:\n        f.write(gzipped_content)\n        f.close()  # force file synchronization\n        with gzip.open(f.name, 'rb') as h:\n            decompressed_content = h.read()\n        return decompressed_content\n    finally:\n        os.unlink(f.name)", "response": "Returns gunzipped content from gzipped contents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetURLContent(url):\n    response = urllib_request.urlopen(url)\n    encoding = response.info().get('Content-Encoding')\n    if encoding == 'gzip':\n        content = _Gunzip(response.read())\n    else:\n        content = response.read()\n    return content", "response": "Download and return the content of URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef FetchDiscoveryDoc(discovery_url, retries=5):\n    discovery_urls = _NormalizeDiscoveryUrls(discovery_url)\n    discovery_doc = None\n    last_exception = None\n    for url in discovery_urls:\n        for _ in range(retries):\n            try:\n                content = _GetURLContent(url)\n                if isinstance(content, bytes):\n                    content = content.decode('utf8')\n                discovery_doc = json.loads(content)\n                break\n            except (urllib_error.HTTPError, urllib_error.URLError) as e:\n                logging.info(\n                    'Attempting to fetch discovery doc again after \"%s\"', e)\n                last_exception = e\n    if discovery_doc is None:\n        raise CommunicationError(\n            'Could not find discovery doc at any of %s: %s' % (\n                discovery_urls, last_exception))\n    return discovery_doc", "response": "Fetch the discovery document at the given url."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __StripName(self, name):\n        if not name:\n            return name\n        for prefix in self.__strip_prefixes:\n            if name.startswith(prefix):\n                return name[len(prefix):]\n        return name", "response": "Strip strip_prefix entries from name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef CleanName(name):\n        name = re.sub('[^_A-Za-z0-9]', '_', name)\n        if name[0].isdigit():\n            name = '_%s' % name\n        while keyword.iskeyword(name):\n            name = '%s_' % name\n        # If we end up with __ as a prefix, we'll run afoul of python\n        # field renaming, so we manually correct for it.\n        if name.startswith('__'):\n            name = 'f%s' % name\n        return name", "response": "Perform generic name cleaning."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnormalize camelCase entries in path.", "response": "def NormalizeRelativePath(path):\n        \"\"\"Normalize camelCase entries in path.\"\"\"\n        path_components = path.split('/')\n        normalized_components = []\n        for component in path_components:\n            if re.match(r'{[A-Za-z0-9_]+}$', component):\n                normalized_components.append(\n                    '{%s}' % Names.CleanName(component[1:-1]))\n            else:\n                normalized_components.append(component)\n        return '/'.join(normalized_components)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a valid class name from name.", "response": "def ClassName(self, name, separator='_'):\n        \"\"\"Generate a valid class name from name.\"\"\"\n        # TODO(craigcitro): Get rid of this case here and in MethodName.\n        if name is None:\n            return name\n        # TODO(craigcitro): This is a hack to handle the case of specific\n        # protorpc class names; clean this up.\n        if name.startswith(('protorpc.', 'message_types.',\n                            'apitools.base.protorpclite.',\n                            'apitools.base.protorpclite.message_types.')):\n            return name\n        name = self.__StripName(name)\n        name = self.__ToCamel(name, separator=separator)\n        return self.CleanName(name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a valid method name from name.", "response": "def MethodName(self, name, separator='_'):\n        \"\"\"Generate a valid method name from name.\"\"\"\n        if name is None:\n            return None\n        name = Names.__ToCamel(name, separator=separator)\n        return Names.CleanName(name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a valid field name from name.", "response": "def FieldName(self, name):\n        \"\"\"Generate a valid field name from name.\"\"\"\n        # TODO(craigcitro): We shouldn't need to strip this name, but some\n        # of the service names here are excessive. Fix the API and then\n        # remove this.\n        name = self.__StripName(name)\n        if self.__name_convention == 'LOWER_CAMEL':\n            name = Names.__ToLowerCamel(name)\n        elif self.__name_convention == 'LOWER_WITH_UNDER':\n            name = Names.__FromCamel(name)\n        return Names.CleanName(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Create(cls, discovery_doc,\n               scope_ls, client_id, client_secret, user_agent, names, api_key):\n        \"\"\"Create a new ClientInfo object from a discovery document.\"\"\"\n        scopes = set(\n            discovery_doc.get('auth', {}).get('oauth2', {}).get('scopes', {}))\n        scopes.update(scope_ls)\n        package = discovery_doc['name']\n        url_version = discovery_doc['version']\n        base_url, base_path = _ComputePaths(package, url_version,\n                                            discovery_doc)\n\n        client_info = {\n            'package': package,\n            'version': NormalizeVersion(discovery_doc['version']),\n            'url_version': url_version,\n            'scopes': sorted(list(scopes)),\n            'client_id': client_id,\n            'client_secret': client_secret,\n            'user_agent': user_agent,\n            'api_key': api_key,\n            'base_url': base_url,\n            'base_path': base_path,\n        }\n        client_class_name = '%s%s' % (\n            names.ClassName(client_info['package']),\n            names.ClassName(client_info['version']))\n        client_info['client_class_name'] = client_class_name\n        return cls(**client_info)", "response": "Create a new ClientInfo object from a discovery document."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef CommentContext(self):\n        old_context = self.__comment_context\n        self.__comment_context = True\n        yield\n        self.__comment_context = old_context", "response": "Print without any argument formatting."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _RegisterCredentialsMethod(method, position=None):\n    if position is None:\n        position = len(_CREDENTIALS_METHODS)\n    else:\n        position = min(position, len(_CREDENTIALS_METHODS))\n    _CREDENTIALS_METHODS.insert(position, method)\n    return method", "response": "Register a new method for fetching credentials."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetCredentials(package_name, scopes, client_id, client_secret, user_agent,\n                   credentials_filename=None,\n                   api_key=None,  # pylint: disable=unused-argument\n                   client=None,  # pylint: disable=unused-argument\n                   oauth2client_args=None,\n                   **kwds):\n    \"\"\"Attempt to get credentials, using an oauth dance as the last resort.\"\"\"\n    scopes = util.NormalizeScopes(scopes)\n    client_info = {\n        'client_id': client_id,\n        'client_secret': client_secret,\n        'scope': ' '.join(sorted(scopes)),\n        'user_agent': user_agent or '%s-generated/0.1' % package_name,\n    }\n    for method in _CREDENTIALS_METHODS:\n        credentials = method(client_info, **kwds)\n        if credentials is not None:\n            return credentials\n    credentials_filename = credentials_filename or os.path.expanduser(\n        '~/.apitools.token')\n    credentials = CredentialsFromFile(credentials_filename, client_info,\n                                      oauth2client_args=oauth2client_args)\n    if credentials is not None:\n        return credentials\n    raise exceptions.CredentialsError('Could not create valid credentials')", "response": "Get credentials for the specified scopes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ServiceAccountCredentialsFromFile(filename, scopes, user_agent=None):\n    filename = os.path.expanduser(filename)\n    # We have two options, based on our version of oauth2client.\n    if oauth2client.__version__ > '1.5.2':\n        # oauth2client >= 2.0.0\n        credentials = (\n            service_account.ServiceAccountCredentials.from_json_keyfile_name(\n                filename, scopes=scopes))\n        if credentials is not None:\n            if user_agent is not None:\n                credentials.user_agent = user_agent\n        return credentials\n    else:\n        # oauth2client < 2.0.0\n        with open(filename) as keyfile:\n            service_account_info = json.load(keyfile)\n        account_type = service_account_info.get('type')\n        if account_type != oauth2client.client.SERVICE_ACCOUNT:\n            raise exceptions.CredentialsError(\n                'Invalid service account credentials: %s' % (filename,))\n        # pylint: disable=protected-access\n        credentials = service_account._ServiceAccountCredentials(\n            service_account_id=service_account_info['client_id'],\n            service_account_email=service_account_info['client_email'],\n            private_key_id=service_account_info['private_key_id'],\n            private_key_pkcs8_text=service_account_info['private_key'],\n            scopes=scopes, user_agent=user_agent)\n        # pylint: enable=protected-access\n        return credentials", "response": "Use the credentials in filename to create a token for scopes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new credential from the named. p12 keyfile.", "response": "def ServiceAccountCredentialsFromP12File(\n        service_account_name, private_key_filename, scopes, user_agent):\n    \"\"\"Create a new credential from the named .p12 keyfile.\"\"\"\n    private_key_filename = os.path.expanduser(private_key_filename)\n    scopes = util.NormalizeScopes(scopes)\n    if oauth2client.__version__ > '1.5.2':\n        # oauth2client >= 2.0.0\n        credentials = (\n            service_account.ServiceAccountCredentials.from_p12_keyfile(\n                service_account_name, private_key_filename, scopes=scopes))\n        if credentials is not None:\n            credentials.user_agent = user_agent\n        return credentials\n    else:\n        # oauth2client < 2.0.0\n        with open(private_key_filename, 'rb') as key_file:\n            return oauth2client.client.SignedJwtAssertionCredentials(\n                service_account_name, key_file.read(), scopes,\n                user_agent=user_agent)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrequests the given url from the GCE metadata service.", "response": "def _GceMetadataRequest(relative_url, use_metadata_ip=False):\n    \"\"\"Request the given url from the GCE metadata service.\"\"\"\n    if use_metadata_ip:\n        base_url = os.environ.get('GCE_METADATA_IP', '169.254.169.254')\n    else:\n        base_url = os.environ.get(\n            'GCE_METADATA_ROOT', 'metadata.google.internal')\n    url = 'http://' + base_url + '/computeMetadata/v1/' + relative_url\n    # Extra header requirement can be found here:\n    # https://developers.google.com/compute/docs/metadata\n    headers = {'Metadata-Flavor': 'Google'}\n    request = urllib.request.Request(url, headers=headers)\n    opener = urllib.request.build_opener(urllib.request.ProxyHandler({}))\n    try:\n        response = opener.open(request)\n    except urllib.error.URLError as e:\n        raise exceptions.CommunicationError(\n            'Could not reach metadata service: %s' % e.reason)\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _GetRunFlowFlags(args=None):\n    # There's one rare situation where gsutil will not have argparse\n    # available, but doesn't need anything depending on argparse anyway,\n    # since they're bringing their own credentials. So we just allow this\n    # to fail with an ImportError in those cases.\n    #\n    # TODO(craigcitro): Move this import back to the top when we drop\n    # python 2.6 support (eg when gsutil does).\n    import argparse\n\n    parser = argparse.ArgumentParser(parents=[tools.argparser])\n    # Get command line argparse flags.\n    flags, _ = parser.parse_known_args(args=args)\n\n    # Allow `gflags` and `argparse` to be used side-by-side.\n    if hasattr(FLAGS, 'auth_host_name'):\n        flags.auth_host_name = FLAGS.auth_host_name\n    if hasattr(FLAGS, 'auth_host_port'):\n        flags.auth_host_port = FLAGS.auth_host_port\n    if hasattr(FLAGS, 'auth_local_webserver'):\n        flags.noauth_local_webserver = (not FLAGS.auth_local_webserver)\n    return flags", "response": "Retrieves command line flags based on gflags module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading credentials from a file.", "response": "def CredentialsFromFile(path, client_info, oauth2client_args=None):\n    \"\"\"Read credentials from a file.\"\"\"\n    user_agent = client_info['user_agent']\n    scope_key = client_info['scope']\n    if not isinstance(scope_key, six.string_types):\n        scope_key = ':'.join(scope_key)\n    storage_key = client_info['client_id'] + user_agent + scope_key\n\n    if _NEW_FILESTORE:\n        credential_store = multiprocess_file_storage.MultiprocessFileStorage(\n            path, storage_key)\n    else:\n        credential_store = multistore_file.get_credential_storage_custom_string_key(  # noqa\n            path, storage_key)\n    if hasattr(FLAGS, 'auth_local_webserver'):\n        FLAGS.auth_local_webserver = False\n    credentials = credential_store.get()\n    if credentials is None or credentials.invalid:\n        print('Generating new OAuth credentials ...')\n        for _ in range(20):\n            # If authorization fails, we want to retry, rather than let this\n            # cascade up and get caught elsewhere. If users want out of the\n            # retry loop, they can ^C.\n            try:\n                flow = oauth2client.client.OAuth2WebServerFlow(**client_info)\n                flags = _GetRunFlowFlags(args=oauth2client_args)\n                credentials = tools.run_flow(flow, credential_store, flags)\n                break\n            except (oauth2client.client.FlowExchangeError, SystemExit) as e:\n                # Here SystemExit is \"no credential at all\", and the\n                # FlowExchangeError is \"invalid\" -- usually because\n                # you reused a token.\n                print('Invalid authorization: %s' % (e,))\n            except httplib2.HttpLib2Error as e:\n                print('Communication error: %s' % (e,))\n                raise exceptions.CredentialsError(\n                    'Communication error creating credentials: %s' % e)\n    return credentials"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the userinfo associated with the given credentials.", "response": "def GetUserinfo(credentials, http=None):  # pylint: disable=invalid-name\n    \"\"\"Get the userinfo associated with the given credentials.\n\n    This is dependent on the token having either the userinfo.email or\n    userinfo.profile scope for the given token.\n\n    Args:\n      credentials: (oauth2client.client.Credentials) incoming credentials\n      http: (httplib2.Http, optional) http instance to use\n\n    Returns:\n      The email address for this token, or None if the required scopes\n      aren't available.\n    \"\"\"\n    http = http or httplib2.Http()\n    url = _GetUserinfoUrl(credentials)\n    # We ignore communication woes here (i.e. SSL errors, socket\n    # timeout), as handling these should be done in a common location.\n    response, content = http.request(url)\n    if response.status == http_client.BAD_REQUEST:\n        credentials.refresh(http)\n        url = _GetUserinfoUrl(credentials)\n        response, content = http.request(url)\n    return json.loads(content or '{}')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GetServiceAccountCredentials(\n        client_info, service_account_name=None, service_account_keyfile=None,\n        service_account_json_keyfile=None, **unused_kwds):\n    \"\"\"Returns ServiceAccountCredentials from give file.\"\"\"\n    if ((service_account_name and not service_account_keyfile) or\n            (service_account_keyfile and not service_account_name)):\n        raise exceptions.CredentialsError(\n            'Service account name or keyfile provided without the other')\n    scopes = client_info['scope'].split()\n    user_agent = client_info['user_agent']\n    # Use the .json credentials, if provided.\n    if service_account_json_keyfile:\n        return ServiceAccountCredentialsFromFile(\n            service_account_json_keyfile, scopes, user_agent=user_agent)\n    # Fall back to .p12 if there's no .json credentials.\n    if service_account_name is not None:\n        return ServiceAccountCredentialsFromP12File(\n            service_account_name, service_account_keyfile, scopes, user_agent)", "response": "Returns a list of ServiceAccountCredentials from give file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the application default credentials for the given ADC.", "response": "def _GetApplicationDefaultCredentials(\n        client_info, skip_application_default_credentials=False,\n        **unused_kwds):\n    \"\"\"Returns ADC with right scopes.\"\"\"\n    scopes = client_info['scope'].split()\n    if skip_application_default_credentials:\n        return None\n    gc = oauth2client.client.GoogleCredentials\n    with cache_file_lock:\n        try:\n            # pylint: disable=protected-access\n            # We've already done our own check for GAE/GCE\n            # credentials, we don't want to pay for checking again.\n            credentials = gc._implicit_credentials_from_files()\n        except oauth2client.client.ApplicationDefaultCredentialsError:\n            return None\n    # If we got back a non-service account credential, we need to use\n    # a heuristic to decide whether or not the application default\n    # credential will work for us. We assume that if we're requesting\n    # cloud-platform, our scopes are a subset of cloud scopes, and the\n    # ADC will work.\n    cp = 'https://www.googleapis.com/auth/cloud-platform'\n    if credentials is None:\n        return None\n    if not isinstance(credentials, gc) or cp in scopes:\n        return credentials.create_scoped(scopes)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the cache file to see if it matches the given credentials.", "response": "def _CheckCacheFileForMatch(self, cache_filename, scopes):\n        \"\"\"Checks the cache file to see if it matches the given credentials.\n\n        Args:\n          cache_filename: Cache filename to check.\n          scopes: Scopes for the desired credentials.\n\n        Returns:\n          List of scopes (if cache matches) or None.\n        \"\"\"\n        creds = {  # Credentials metadata dict.\n            'scopes': sorted(list(scopes)) if scopes else None,\n            'svc_acct_name': self.__service_account_name,\n        }\n        cache_file = _MultiProcessCacheFile(cache_filename)\n        try:\n            cached_creds_str = cache_file.LockedRead()\n            if not cached_creds_str:\n                return None\n            cached_creds = json.loads(cached_creds_str)\n            if creds['svc_acct_name'] == cached_creds['svc_acct_name']:\n                if creds['scopes'] in (None, cached_creds['scopes']):\n                    return cached_creds['scopes']\n        except KeyboardInterrupt:\n            raise\n        except:  # pylint: disable=bare-except\n            # Treat exceptions as a cache miss.\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the credential metadata to the cache file.", "response": "def _WriteCacheFile(self, cache_filename, scopes):\n        \"\"\"Writes the credential metadata to the cache file.\n\n        This does not save the credentials themselves (CredentialStore class\n        optionally handles that after this class is initialized).\n\n        Args:\n          cache_filename: Cache filename to check.\n          scopes: Scopes for the desired credentials.\n        \"\"\"\n        # Credentials metadata dict.\n        creds = {'scopes': sorted(list(scopes)),\n                 'svc_acct_name': self.__service_account_name}\n        creds_str = json.dumps(creds)\n        cache_file = _MultiProcessCacheFile(cache_filename)\n        try:\n            cache_file.LockedWrite(creds_str)\n        except KeyboardInterrupt:\n            raise\n        except:  # pylint: disable=bare-except\n            # Treat exceptions as a cache miss.\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn instance scopes based on GCE metadata server.", "response": "def _ScopesFromMetadataServer(self, scopes):\n        \"\"\"Returns instance scopes based on GCE metadata server.\"\"\"\n        if not util.DetectGce():\n            raise exceptions.ResourceUnavailableError(\n                'GCE credentials requested outside a GCE instance')\n        if not self.GetServiceAccount(self.__service_account_name):\n            raise exceptions.ResourceUnavailableError(\n                'GCE credentials requested but service account '\n                '%s does not exist.' % self.__service_account_name)\n        if scopes:\n            scope_ls = util.NormalizeScopes(scopes)\n            instance_scopes = self.GetInstanceScopes()\n            if scope_ls > instance_scopes:\n                raise exceptions.CredentialsError(\n                    'Instance did not have access to scopes %s' % (\n                        sorted(list(scope_ls - instance_scopes)),))\n        else:\n            scopes = self.GetInstanceScopes()\n        return scopes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _do_refresh_request(self, unused_http_request):\n        relative_url = 'instance/service-accounts/{0}/token'.format(\n            self.__service_account_name)\n        try:\n            response = _GceMetadataRequest(relative_url)\n        except exceptions.CommunicationError:\n            self.invalid = True\n            if self.store:\n                self.store.locked_put(self)\n            raise\n        content = response.read()\n        try:\n            credential_info = json.loads(content)\n        except ValueError:\n            raise exceptions.CredentialsError(\n                'Could not parse response as JSON: %s' % content)\n\n        self.access_token = credential_info['access_token']\n        if 'expires_in' in credential_info:\n            expires_in = int(credential_info['expires_in'])\n            self.token_expiry = (\n                datetime.timedelta(seconds=expires_in) +\n                datetime.datetime.utcnow())\n        else:\n            self.token_expiry = None\n        self.invalid = False\n        if self.store:\n            self.store.locked_put(self)", "response": "Refresh self. access_token by querying the metadata server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrefreshing self.access_token. Args: _: (ignored) A function matching httplib2.Http.request's signature.", "response": "def _refresh(self, _):\n        \"\"\"Refresh self.access_token.\n\n        Args:\n          _: (ignored) A function matching httplib2.Http.request's signature.\n        \"\"\"\n        # pylint: disable=import-error\n        from google.appengine.api import app_identity\n        try:\n            token, _ = app_identity.get_access_token(self._scopes)\n        except app_identity.Error as e:\n            raise exceptions.CredentialsError(str(e))\n        self.access_token = token"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef LockedRead(self):\n        file_contents = None\n        with self._thread_lock:\n            if not self._EnsureFileExists():\n                return None\n            with self._process_lock_getter() as acquired_plock:\n                if not acquired_plock:\n                    return None\n                with open(self._filename, 'rb') as f:\n                    file_contents = f.read().decode(encoding=self._encoding)\n        return file_contents", "response": "Acquire an interprocess lock and dump cache contents."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef LockedWrite(self, cache_data):\n        if isinstance(cache_data, six.text_type):\n            cache_data = cache_data.encode(encoding=self._encoding)\n\n        with self._thread_lock:\n            if not self._EnsureFileExists():\n                return False\n            with self._process_lock_getter() as acquired_plock:\n                if not acquired_plock:\n                    return False\n                with open(self._filename, 'wb') as f:\n                    f.write(cache_data)\n                return True", "response": "Acquire an interprocess lock and write a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nensures that a file exists. Returns False on error True on success.", "response": "def _EnsureFileExists(self):\n        \"\"\"Touches a file; returns False on error, True on success.\"\"\"\n        if not os.path.exists(self._filename):\n            old_umask = os.umask(0o177)\n            try:\n                open(self._filename, 'a+b').close()\n            except OSError:\n                return False\n            finally:\n                os.umask(old_umask)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef YieldFromList(\n        service, request, global_params=None, limit=None, batch_size=100,\n        method='List', field='items', predicate=None,\n        current_token_attribute='pageToken',\n        next_token_attribute='nextPageToken',\n        batch_size_attribute='maxResults'):\n    \"\"\"Make a series of List requests, keeping track of page tokens.\n\n    Args:\n      service: apitools_base.BaseApiService, A service with a .List() method.\n      request: protorpc.messages.Message, The request message\n          corresponding to the service's .List() method, with all the\n          attributes populated except the .maxResults and .pageToken\n          attributes.\n      global_params: protorpc.messages.Message, The global query parameters to\n           provide when calling the given method.\n      limit: int, The maximum number of records to yield. None if all available\n          records should be yielded.\n      batch_size: int, The number of items to retrieve per request.\n      method: str, The name of the method used to fetch resources.\n      field: str, The field in the response that will be a list of items.\n      predicate: lambda, A function that returns true for items to be yielded.\n      current_token_attribute: str, The name of the attribute in a\n          request message holding the page token for the page being\n          requested.\n      next_token_attribute: str, The name of the attribute in a\n          response message holding the page token for the next page.\n      batch_size_attribute: str, The name of the attribute in a\n          response message holding the maximum number of results to be\n          returned. None if caller-specified batch size is unsupported.\n\n    Yields:\n      protorpc.message.Message, The resources listed by the service.\n\n    \"\"\"\n    request = encoding.CopyProtoMessage(request)\n    setattr(request, current_token_attribute, None)\n    while limit is None or limit:\n        if batch_size_attribute:\n            # On Py3, None is not comparable so min() below will fail.\n            # On Py2, None is always less than any number so if batch_size\n            # is None, the request_batch_size will always be None regardless\n            # of the value of limit. This doesn't generally strike me as the\n            # correct behavior, but this change preserves the existing Py2\n            # behavior on Py3.\n            if batch_size is None:\n                request_batch_size = None\n            else:\n                request_batch_size = min(batch_size, limit or batch_size)\n            setattr(request, batch_size_attribute, request_batch_size)\n        response = getattr(service, method)(request,\n                                            global_params=global_params)\n        items = getattr(response, field)\n        if predicate:\n            items = list(filter(predicate, items))\n        for item in items:\n            yield item\n            if limit is None:\n                continue\n            limit -= 1\n            if not limit:\n                return\n        token = getattr(response, next_token_attribute)\n        if not token:\n            return\n        setattr(request, current_token_attribute, token)", "response": "Yields a set of resources from a list request."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints a docstring for a service method.", "response": "def __PrintDocstring(self, printer, method_info, method_name, name):\n        \"\"\"Print a docstring for a service method.\"\"\"\n        if method_info.description:\n            description = util.CleanDescription(method_info.description)\n            first_line, newline, remaining = method_info.description.partition(\n                '\\n')\n            if not first_line.endswith('.'):\n                first_line = '%s.' % first_line\n            description = '%s%s%s' % (first_line, newline, remaining)\n        else:\n            description = '%s method for the %s service.' % (method_name, name)\n        with printer.CommentContext():\n            printer('r\"\"\"%s' % description)\n        printer()\n        printer('Args:')\n        printer('  request: (%s) input message', method_info.request_type_name)\n        printer('  global_params: (StandardQueryParameters, default: None) '\n                'global arguments')\n        if method_info.upload_config:\n            printer('  upload: (Upload, default: None) If present, upload')\n            printer('      this stream with the request.')\n        if method_info.supports_download:\n            printer(\n                '  download: (Download, default: None) If present, download')\n            printer('      data from the request via this stream.')\n        printer('Returns:')\n        printer('  (%s) The response message.', method_info.response_type_name)\n        printer('\"\"\"')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a single service declaration to a proto file.", "response": "def __WriteProtoServiceDeclaration(self, printer, name, method_info_map):\n        \"\"\"Write a single service declaration to a proto file.\"\"\"\n        printer()\n        printer('service %s {', self.__GetServiceClassName(name))\n        with printer.Indent():\n            for method_name, method_info in method_info_map.items():\n                for line in textwrap.wrap(method_info.description,\n                                          printer.CalculateWidth() - 3):\n                    printer('// %s', line)\n                printer('rpc %s (%s) returns (%s);',\n                        method_name,\n                        method_info.request_type_name,\n                        method_info.response_type_name)\n        printer('}')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the services in this registry to out as proto.", "response": "def WriteProtoFile(self, printer):\n        \"\"\"Write the services in this registry to out as proto.\"\"\"\n        self.Validate()\n        client_info = self.__client_info\n        printer('// Generated services for %s version %s.',\n                client_info.package, client_info.version)\n        printer()\n        printer('syntax = \"proto2\";')\n        printer('package %s;', self.__package)\n        printer('import \"%s\";', client_info.messages_proto_file_name)\n        printer()\n        for name, method_info_map in self.__service_method_info_map.items():\n            self.__WriteProtoServiceDeclaration(printer, name, method_info_map)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef WriteFile(self, printer):\n        self.Validate()\n        client_info = self.__client_info\n        printer('\"\"\"Generated client library for %s version %s.\"\"\"',\n                client_info.package, client_info.version)\n        printer('# NOTE: This file is autogenerated and should not be edited '\n                'by hand.')\n        printer('from %s import base_api', self.__base_files_package)\n        if self.__root_package:\n            import_prefix = 'from {0} '.format(self.__root_package)\n        else:\n            import_prefix = ''\n        printer('%simport %s as messages', import_prefix,\n                client_info.messages_rule_name)\n        printer()\n        printer()\n        printer('class %s(base_api.BaseApiClient):',\n                client_info.client_class_name)\n        with printer.Indent():\n            printer(\n                '\"\"\"Generated client library for service %s version %s.\"\"\"',\n                client_info.package, client_info.version)\n            printer()\n            printer('MESSAGES_MODULE = messages')\n            printer('BASE_URL = {0!r}'.format(client_info.base_url))\n            printer()\n            printer('_PACKAGE = {0!r}'.format(client_info.package))\n            printer('_SCOPES = {0!r}'.format(\n                client_info.scopes or\n                ['https://www.googleapis.com/auth/userinfo.email']))\n            printer('_VERSION = {0!r}'.format(client_info.version))\n            printer('_CLIENT_ID = {0!r}'.format(client_info.client_id))\n            printer('_CLIENT_SECRET = {0!r}'.format(client_info.client_secret))\n            printer('_USER_AGENT = {0!r}'.format(client_info.user_agent))\n            printer('_CLIENT_CLASS_NAME = {0!r}'.format(\n                client_info.client_class_name))\n            printer('_URL_VERSION = {0!r}'.format(client_info.url_version))\n            printer('_API_KEY = {0!r}'.format(client_info.api_key))\n            printer()\n            printer(\"def __init__(self, url='', credentials=None,\")\n            with printer.Indent(indent='             '):\n                printer('get_credentials=True, http=None, model=None,')\n                printer('log_request=False, log_response=False,')\n                printer('credentials_args=None, default_global_params=None,')\n                printer('additional_http_headers=None, '\n                        'response_encoding=None):')\n            with printer.Indent():\n                printer('\"\"\"Create a new %s handle.\"\"\"', client_info.package)\n                printer('url = url or self.BASE_URL')\n                printer(\n                    'super(%s, self).__init__(', client_info.client_class_name)\n                printer('    url, credentials=credentials,')\n                printer('    get_credentials=get_credentials, http=http, '\n                        'model=model,')\n                printer('    log_request=log_request, '\n                        'log_response=log_response,')\n                printer('    credentials_args=credentials_args,')\n                printer('    default_global_params=default_global_params,')\n                printer('    additional_http_headers=additional_http_headers,')\n                printer('    response_encoding=response_encoding)')\n                for name in self.__service_method_info_map.keys():\n                    printer('self.%s = self.%s(self)',\n                            name, self.__GetServiceClassName(name))\n            for name, method_info in self.__service_method_info_map.items():\n                self.__WriteSingleService(\n                    printer, name, method_info, client_info.client_class_name)", "response": "Writes the services in this registry to out."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __CreateRequestType(self, method_description, body_type=None):\n        schema = {}\n        schema['id'] = self.__names.ClassName('%sRequest' % (\n            self.__names.ClassName(method_description['id'], separator='.'),))\n        schema['type'] = 'object'\n        schema['properties'] = collections.OrderedDict()\n        if 'parameterOrder' not in method_description:\n            ordered_parameters = list(method_description.get('parameters', []))\n        else:\n            ordered_parameters = method_description['parameterOrder'][:]\n            for k in method_description['parameters']:\n                if k not in ordered_parameters:\n                    ordered_parameters.append(k)\n        for parameter_name in ordered_parameters:\n            field_name = self.__names.CleanName(parameter_name)\n            field = dict(method_description['parameters'][parameter_name])\n            if 'type' not in field:\n                raise ValueError('No type found in parameter %s' % field)\n            schema['properties'][field_name] = field\n        if body_type is not None:\n            body_field_name = self.__GetRequestField(\n                method_description, body_type)\n            if body_field_name in schema['properties']:\n                raise ValueError('Failed to normalize request resource name')\n            if 'description' not in body_type:\n                body_type['description'] = (\n                    'A %s resource to be passed as the request body.' % (\n                        self.__GetRequestType(body_type),))\n            schema['properties'][body_field_name] = body_type\n        self.__message_registry.AddDescriptorFromSchema(schema['id'], schema)\n        return schema['id']", "response": "Create a request type for this method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an empty response type.", "response": "def __CreateVoidResponseType(self, method_description):\n        \"\"\"Create an empty response type.\"\"\"\n        schema = {}\n        method_name = self.__names.ClassName(\n            method_description['id'], separator='.')\n        schema['id'] = self.__names.ClassName('%sResponse' % method_name)\n        schema['type'] = 'object'\n        schema['description'] = 'An empty %s response.' % method_name\n        self.__message_registry.AddDescriptorFromSchema(schema['id'], schema)\n        return schema['id']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __NeedRequestType(self, method_description, request_type):\n        if not request_type:\n            return True\n        method_id = method_description.get('id', '')\n        if method_id in self.__unelidable_request_methods:\n            return True\n        message = self.__message_registry.LookupDescriptorOrDie(request_type)\n        if message is None:\n            return True\n        field_names = [x.name for x in message.fields]\n        parameters = method_description.get('parameters', {})\n        for param_name, param_info in parameters.items():\n            if (param_info.get('location') != 'path' or\n                    self.__names.CleanName(param_name) not in field_names):\n                break\n        else:\n            return False\n        return True", "response": "Determine if this method needs a new request type created."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __MaxSizeToInt(self, max_size):\n        size_groups = re.match(r'(?P<size>\\d+)(?P<unit>.B)?$', max_size)\n        if size_groups is None:\n            raise ValueError('Could not parse maxSize')\n        size, unit = size_groups.group('size', 'unit')\n        shift = 0\n        if unit is not None:\n            unit_dict = {'KB': 10, 'MB': 20, 'GB': 30, 'TB': 40}\n            shift = unit_dict.get(unit.upper())\n            if shift is None:\n                raise ValueError('Unknown unit %s' % unit)\n        return int(size) * (1 << shift)", "response": "Convert max_size to an int."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __ComputeUploadConfig(self, media_upload_config, method_id):\n        config = base_api.ApiUploadInfo()\n        if 'maxSize' in media_upload_config:\n            config.max_size = self.__MaxSizeToInt(\n                media_upload_config['maxSize'])\n        if 'accept' not in media_upload_config:\n            logging.warn(\n                'No accept types found for upload configuration in '\n                'method %s, using */*', method_id)\n        config.accept.extend([\n            str(a) for a in media_upload_config.get('accept', '*/*')])\n\n        for accept_pattern in config.accept:\n            if not _MIME_PATTERN_RE.match(accept_pattern):\n                logging.warn('Unexpected MIME type: %s', accept_pattern)\n        protocols = media_upload_config.get('protocols', {})\n        for protocol in ('simple', 'resumable'):\n            media = protocols.get(protocol, {})\n            for attr in ('multipart', 'path'):\n                if attr in media:\n                    setattr(config, '%s_%s' % (protocol, attr), media[attr])\n        return config", "response": "Compute the upload config for this method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the base_api. ApiMethodInfo for this method.", "response": "def __ComputeMethodInfo(self, method_description, request, response,\n                            request_field):\n        \"\"\"Compute the base_api.ApiMethodInfo for this method.\"\"\"\n        relative_path = self.__names.NormalizeRelativePath(\n            ''.join((self.__client_info.base_path,\n                     method_description['path'])))\n        method_id = method_description['id']\n        ordered_params = []\n        for param_name in method_description.get('parameterOrder', []):\n            param_info = method_description['parameters'][param_name]\n            if param_info.get('required', False):\n                ordered_params.append(param_name)\n        method_info = base_api.ApiMethodInfo(\n            relative_path=relative_path,\n            method_id=method_id,\n            http_method=method_description['httpMethod'],\n            description=util.CleanDescription(\n                method_description.get('description', '')),\n            query_params=[],\n            path_params=[],\n            ordered_params=ordered_params,\n            request_type_name=self.__names.ClassName(request),\n            response_type_name=self.__names.ClassName(response),\n            request_field=request_field,\n        )\n        flat_path = method_description.get('flatPath', None)\n        if flat_path is not None:\n            flat_path = self.__names.NormalizeRelativePath(\n                self.__client_info.base_path + flat_path)\n            if flat_path != relative_path:\n                method_info.flat_path = flat_path\n        if method_description.get('supportsMediaUpload', False):\n            method_info.upload_config = self.__ComputeUploadConfig(\n                method_description.get('mediaUpload'), method_id)\n        method_info.supports_download = method_description.get(\n            'supportsMediaDownload', False)\n        self.__all_scopes.update(method_description.get('scopes', ()))\n        for param, desc in method_description.get('parameters', {}).items():\n            param = self.__names.CleanName(param)\n            location = desc['location']\n            if location == 'query':\n                method_info.query_params.append(param)\n            elif location == 'path':\n                method_info.path_params.append(param)\n            else:\n                raise ValueError(\n                    'Unknown parameter location %s for parameter %s' % (\n                        location, param))\n        method_info.path_params.sort()\n        method_info.query_params.sort()\n        return method_info"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __GetRequestField(self, method_description, body_type):\n        body_field_name = self.__BodyFieldName(body_type)\n        if body_field_name in method_description.get('parameters', {}):\n            body_field_name = self.__names.FieldName(\n                '%s_resource' % body_field_name)\n        # It's exceedingly unlikely that we'd get two name collisions, which\n        # means it's bound to happen at some point.\n        while body_field_name in method_description.get('parameters', {}):\n            body_field_name = self.__names.FieldName(\n                '%s_body' % body_field_name)\n        return body_field_name", "response": "Determine the request field for this method."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AddServiceFromResource(self, service_name, methods):\n        service_name = self.__names.CleanName(service_name)\n        method_descriptions = methods.get('methods', {})\n        method_info_map = collections.OrderedDict()\n        items = sorted(method_descriptions.items())\n        for method_name, method_description in items:\n            method_name = self.__names.MethodName(method_name)\n\n            # NOTE: According to the discovery document, if the request or\n            # response is present, it will simply contain a `$ref`.\n            body_type = method_description.get('request')\n            if body_type is None:\n                request_type = None\n            else:\n                request_type = self.__GetRequestType(body_type)\n            if self.__NeedRequestType(method_description, request_type):\n                request = self.__CreateRequestType(\n                    method_description, body_type=body_type)\n                request_field = self.__GetRequestField(\n                    method_description, body_type)\n            else:\n                request = request_type\n                request_field = base_api.REQUEST_IS_BODY\n\n            if 'response' in method_description:\n                response = method_description['response']['$ref']\n            else:\n                response = self.__CreateVoidResponseType(method_description)\n\n            method_info_map[method_name] = self.__ComputeMethodInfo(\n                method_description, request, response, request_field)\n\n        nested_services = methods.get('resources', {})\n        services = sorted(nested_services.items())\n        for subservice_name, submethods in services:\n            new_service_name = '%s_%s' % (service_name, subservice_name)\n            self.AddServiceFromResource(new_service_name, submethods)\n\n        self.__RegisterService(service_name, method_info_map)", "response": "Add a new service from a resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compress(data, compresslevel=9):\n    buf = io.BytesIO()\n    with GzipFile(fileobj=buf, mode='wb', compresslevel=compresslevel) as f:\n        f.write(data)\n    return buf.getvalue()", "response": "Compress data in one shot and return the compressed string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecompress a gzip compressed string in one shot.", "response": "def decompress(data):\n    \"\"\"Decompress a gzip compressed string in one shot.\n    Return the decompressed string.\n    \"\"\"\n    with GzipFile(fileobj=io.BytesIO(data)) as f:\n        return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rewind(self):\n        '''Return the uncompressed stream file position indicator to the\n        beginning of the file'''\n        if self.mode != READ:\n            raise OSError(\"Can't rewind in write mode\")\n        self.fileobj.seek(0)\n        self._new_member = True\n        self.extrabuf = b\"\"\n        self.extrasize = 0\n        self.extrastart = 0\n        self.offset = 0", "response": "Return the uncompressed stream file position indicator to the\n        beginning of the file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrebuilding all http connections in the httplib2. Http instance.", "response": "def RebuildHttpConnections(http):\n    \"\"\"Rebuilds all http connections in the httplib2.Http instance.\n\n    httplib2 overloads the map in http.connections to contain two different\n    types of values:\n    { scheme string:  connection class } and\n    { scheme + authority string : actual http connection }\n    Here we remove all of the entries for actual connections so that on the\n    next request httplib2 will rebuild them from the connection types.\n\n    Args:\n      http: An httplib2.Http instance.\n    \"\"\"\n    if getattr(http, 'connections', None):\n        for conn_key in list(http.connections.keys()):\n            if ':' in conn_key:\n                del http.connections[conn_key]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef HandleExceptionsAndRebuildHttpConnections(retry_args):\n    # If the server indicates how long to wait, use that value.  Otherwise,\n    # calculate the wait time on our own.\n    retry_after = None\n\n    # Transport failures\n    if isinstance(retry_args.exc, (http_client.BadStatusLine,\n                                   http_client.IncompleteRead,\n                                   http_client.ResponseNotReady)):\n        logging.debug('Caught HTTP error %s, retrying: %s',\n                      type(retry_args.exc).__name__, retry_args.exc)\n    elif isinstance(retry_args.exc, socket.error):\n        logging.debug('Caught socket error, retrying: %s', retry_args.exc)\n    elif isinstance(retry_args.exc, socket.gaierror):\n        logging.debug(\n            'Caught socket address error, retrying: %s', retry_args.exc)\n    elif isinstance(retry_args.exc, socket.timeout):\n        logging.debug(\n            'Caught socket timeout error, retrying: %s', retry_args.exc)\n    elif isinstance(retry_args.exc, httplib2.ServerNotFoundError):\n        logging.debug(\n            'Caught server not found error, retrying: %s', retry_args.exc)\n    elif isinstance(retry_args.exc, ValueError):\n        # oauth2client tries to JSON-decode the response, which can result\n        # in a ValueError if the response was invalid. Until that is fixed in\n        # oauth2client, need to handle it here.\n        logging.debug('Response content was invalid (%s), retrying',\n                      retry_args.exc)\n    elif (isinstance(retry_args.exc, TokenRefreshError) and\n          hasattr(retry_args.exc, 'status') and\n          (retry_args.exc.status == TOO_MANY_REQUESTS or\n           retry_args.exc.status >= 500)):\n        logging.debug(\n            'Caught transient credential refresh error (%s), retrying',\n            retry_args.exc)\n    elif isinstance(retry_args.exc, exceptions.RequestError):\n        logging.debug('Request returned no response, retrying')\n    # API-level failures\n    elif isinstance(retry_args.exc, exceptions.BadStatusCodeError):\n        logging.debug('Response returned status %s, retrying',\n                      retry_args.exc.status_code)\n    elif isinstance(retry_args.exc, exceptions.RetryAfterError):\n        logging.debug('Response returned a retry-after header, retrying')\n        retry_after = retry_args.exc.retry_after\n    else:\n        raise retry_args.exc\n    RebuildHttpConnections(retry_args.http)\n    logging.debug('Retrying request to url %s after exception %s',\n                  retry_args.http_request.url, retry_args.exc)\n    time.sleep(\n        retry_after or util.CalculateWaitForRetry(\n            retry_args.num_retries, max_wait=retry_args.max_retry_wait))", "response": "This function handles exceptions and rebuilds the HTTP connections."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a request via the given http.", "response": "def MakeRequest(http, http_request, retries=7, max_retry_wait=60,\n                redirections=5,\n                retry_func=HandleExceptionsAndRebuildHttpConnections,\n                check_response_func=CheckResponse):\n    \"\"\"Send http_request via the given http, performing error/retry handling.\n\n    Args:\n      http: An httplib2.Http instance, or a http multiplexer that delegates to\n          an underlying http, for example, HTTPMultiplexer.\n      http_request: A Request to send.\n      retries: (int, default 7) Number of retries to attempt on retryable\n          replies (such as 429 or 5XX).\n      max_retry_wait: (int, default 60) Maximum number of seconds to wait\n          when retrying.\n      redirections: (int, default 5) Number of redirects to follow.\n      retry_func: Function to handle retries on exceptions. Argument is an\n          ExceptionRetryArgs tuple.\n      check_response_func: Function to validate the HTTP response.\n          Arguments are (Response, response content, url).\n\n    Raises:\n      InvalidDataFromServerError: if there is no response after retries.\n\n    Returns:\n      A Response object.\n\n    \"\"\"\n    retry = 0\n    first_req_time = time.time()\n    while True:\n        try:\n            return _MakeRequestNoRetry(\n                http, http_request, redirections=redirections,\n                check_response_func=check_response_func)\n        # retry_func will consume the exception types it handles and raise.\n        # pylint: disable=broad-except\n        except Exception as e:\n            retry += 1\n            if retry >= retries:\n                raise\n            else:\n                total_wait_sec = time.time() - first_req_time\n                retry_func(ExceptionRetryArgs(http, http_request, e, retry,\n                                              max_retry_wait, total_wait_sec))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a request via the given http.", "response": "def _MakeRequestNoRetry(http, http_request, redirections=5,\n                        check_response_func=CheckResponse):\n    \"\"\"Send http_request via the given http.\n\n    This wrapper exists to handle translation between the plain httplib2\n    request/response types and the Request and Response types above.\n\n    Args:\n      http: An httplib2.Http instance, or a http multiplexer that delegates to\n          an underlying http, for example, HTTPMultiplexer.\n      http_request: A Request to send.\n      redirections: (int, default 5) Number of redirects to follow.\n      check_response_func: Function to validate the HTTP response.\n          Arguments are (Response, response content, url).\n\n    Returns:\n      A Response object.\n\n    Raises:\n      RequestError if no response could be parsed.\n\n    \"\"\"\n    connection_type = None\n    # Handle overrides for connection types.  This is used if the caller\n    # wants control over the underlying connection for managing callbacks\n    # or hash digestion.\n    if getattr(http, 'connections', None):\n        url_scheme = parse.urlsplit(http_request.url).scheme\n        if url_scheme and url_scheme in http.connections:\n            connection_type = http.connections[url_scheme]\n\n    # Custom printing only at debuglevel 4\n    new_debuglevel = 4 if httplib2.debuglevel == 4 else 0\n    with _Httplib2Debuglevel(http_request, new_debuglevel, http=http):\n        info, content = http.request(\n            str(http_request.url), method=str(http_request.http_method),\n            body=http_request.body, headers=http_request.headers,\n            redirections=redirections, connection_type=connection_type)\n\n    if info is None:\n        raise exceptions.RequestError()\n\n    response = Response(info, content, http_request.url)\n    check_response_func(response)\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the request body ; handles logging and length measurement.", "response": "def body(self, value):\n        \"\"\"Sets the request body; handles logging and length measurement.\"\"\"\n        self.__body = value\n        if value is not None:\n            # Avoid calling len() which cannot exceed 4GiB in 32-bit python.\n            body_length = getattr(\n                self.__body, 'length', None) or len(self.__body)\n            self.headers['content-length'] = str(body_length)\n        else:\n            self.headers.pop('content-length', None)\n        # This line ensures we don't try to print large requests.\n        if not isinstance(value, (type(None), six.string_types)):\n            self.loggable_body = '<media body>'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef length(self):\n        def ProcessContentRange(content_range):\n            _, _, range_spec = content_range.partition(' ')\n            byte_range, _, _ = range_spec.partition('/')\n            start, _, end = byte_range.partition('-')\n            return int(end) - int(start) + 1\n\n        if '-content-encoding' in self.info and 'content-range' in self.info:\n            # httplib2 rewrites content-length in the case of a compressed\n            # transfer; we can't trust the content-length header in that\n            # case, but we *can* trust content-range, if it's present.\n            return ProcessContentRange(self.info['content-range'])\n        elif 'content-length' in self.info:\n            return int(self.info.get('content-length'))\n        elif 'content-range' in self.info:\n            return ProcessContentRange(self.info['content-range'])\n        return len(self.content)", "response": "Return the length of this response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading from the buffer.", "response": "def read(self, size=None):  # pylint: disable=invalid-name\n        \"\"\"Reads from the buffer.\"\"\"\n        if size is None or size < 0:\n            raise exceptions.NotYetImplementedError(\n                'Illegal read of size %s requested on BufferedStream. '\n                'Wrapped stream %s is at position %s-%s, '\n                '%s bytes remaining.' %\n                (size, self.__stream, self.__start_pos, self.__end_pos,\n                 self._bytes_remaining))\n\n        data = ''\n        if self._bytes_remaining:\n            size = min(size, self._bytes_remaining)\n            data = self.__buffered_data[\n                self.__buffer_pos:self.__buffer_pos + size]\n            self.__buffer_pos += size\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef WriteProtoFile(self, printer):\n        self.Validate()\n        extended_descriptor.WriteMessagesFile(\n            self.__file_descriptor, self.__package, self.__client_info.version,\n            printer)", "response": "Write the messages file to out as proto."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the messages file to out.", "response": "def WriteFile(self, printer):\n        \"\"\"Write the messages file to out.\"\"\"\n        self.Validate()\n        extended_descriptor.WritePythonFile(\n            self.__file_descriptor, self.__package, self.__client_info.version,\n            printer)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __RegisterDescriptor(self, new_descriptor):\n        if not isinstance(new_descriptor, (\n                extended_descriptor.ExtendedMessageDescriptor,\n                extended_descriptor.ExtendedEnumDescriptor)):\n            raise ValueError('Cannot add descriptor of type %s' % (\n                type(new_descriptor),))\n        full_name = self.__ComputeFullName(new_descriptor.name)\n        if full_name in self.__message_registry:\n            raise ValueError(\n                'Attempt to re-register descriptor %s' % full_name)\n        if full_name not in self.__nascent_types:\n            raise ValueError('Directly adding types is not supported')\n        new_descriptor.full_name = full_name\n        self.__message_registry[full_name] = new_descriptor\n        if isinstance(new_descriptor,\n                      extended_descriptor.ExtendedMessageDescriptor):\n            self.__current_env.message_types.append(new_descriptor)\n        elif isinstance(new_descriptor,\n                        extended_descriptor.ExtendedEnumDescriptor):\n            self.__current_env.enum_types.append(new_descriptor)\n        self.__unknown_types.discard(full_name)\n        self.__nascent_types.remove(full_name)", "response": "Register the given descriptor in this registry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a new EnumDescriptor with the given name with the given enum values and enum descriptions.", "response": "def AddEnumDescriptor(self, name, description,\n                          enum_values, enum_descriptions):\n        \"\"\"Add a new EnumDescriptor named name with the given enum values.\"\"\"\n        message = extended_descriptor.ExtendedEnumDescriptor()\n        message.name = self.__names.ClassName(name)\n        message.description = util.CleanDescription(description)\n        self.__DeclareDescriptor(message.name)\n        for index, (enum_name, enum_description) in enumerate(\n                zip(enum_values, enum_descriptions)):\n            enum_value = extended_descriptor.ExtendedEnumValueDescriptor()\n            enum_value.name = self.__names.NormalizeEnumName(enum_name)\n            if enum_value.name != enum_name:\n                message.enum_mappings.append(\n                    extended_descriptor.ExtendedEnumDescriptor.JsonEnumMapping(\n                        python_name=enum_value.name, json_name=enum_name))\n                self.__AddImport('from %s import encoding' %\n                                 self.__base_files_package)\n            enum_value.number = index\n            enum_value.description = util.CleanDescription(\n                enum_description or '<no description>')\n            message.values.append(enum_value)\n        self.__RegisterDescriptor(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeclares schema as an alias for alias_for.", "response": "def __DeclareMessageAlias(self, schema, alias_for):\n        \"\"\"Declare schema as an alias for alias_for.\"\"\"\n        # TODO(craigcitro): This is a hack. Remove it.\n        message = extended_descriptor.ExtendedMessageDescriptor()\n        message.name = self.__names.ClassName(schema['id'])\n        message.alias_for = alias_for\n        self.__DeclareDescriptor(message.name)\n        self.__AddImport('from %s import extra_types' %\n                         self.__base_files_package)\n        self.__RegisterDescriptor(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an additionalProperties field to message.", "response": "def __AddAdditionalProperties(self, message, schema, properties):\n        \"\"\"Add an additionalProperties field to message.\"\"\"\n        additional_properties_info = schema['additionalProperties']\n        entries_type_name = self.__AddAdditionalPropertyType(\n            message.name, additional_properties_info)\n        description = util.CleanDescription(\n            additional_properties_info.get('description'))\n        if description is None:\n            description = 'Additional properties of type %s' % message.name\n        attrs = {\n            'items': {\n                '$ref': entries_type_name,\n            },\n            'description': description,\n            'type': 'array',\n        }\n        field_name = 'additionalProperties'\n        message.fields.append(self.__FieldDescriptorFromProperties(\n            field_name, len(properties) + 1, attrs))\n        self.__AddImport('from %s import encoding' % self.__base_files_package)\n        message.decorators.append(\n            'encoding.MapUnrecognizedFields(%r)' % field_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AddDescriptorFromSchema(self, schema_name, schema):\n        # TODO(craigcitro): Is schema_name redundant?\n        if self.__GetDescriptor(schema_name):\n            return\n        if schema.get('enum'):\n            self.__DeclareEnum(schema_name, schema)\n            return\n        if schema.get('type') == 'any':\n            self.__DeclareMessageAlias(schema, 'extra_types.JsonValue')\n            return\n        if schema.get('type') != 'object':\n            raise ValueError('Cannot create message descriptors for type %s' %\n                             schema.get('type'))\n        message = extended_descriptor.ExtendedMessageDescriptor()\n        message.name = self.__names.ClassName(schema['id'])\n        message.description = util.CleanDescription(schema.get(\n            'description', 'A %s object.' % message.name))\n        self.__DeclareDescriptor(message.name)\n        with self.__DescriptorEnv(message):\n            properties = schema.get('properties', {})\n            for index, (name, attrs) in enumerate(sorted(properties.items())):\n                field = self.__FieldDescriptorFromProperties(\n                    name, index + 1, attrs)\n                message.fields.append(field)\n                if field.name != name:\n                    message.field_mappings.append(\n                        type(message).JsonFieldMapping(\n                            python_name=field.name, json_name=name))\n                    self.__AddImport(\n                        'from %s import encoding' % self.__base_files_package)\n            if 'additionalProperties' in schema:\n                self.__AddAdditionalProperties(message, schema, properties)\n        self.__RegisterDescriptor(message)", "response": "Add a new MessageDescriptor based on schema."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __AddAdditionalPropertyType(self, name, property_schema):\n        new_type_name = 'AdditionalProperty'\n        property_schema = dict(property_schema)\n        # We drop the description here on purpose, so the resulting\n        # messages are less repetitive.\n        property_schema.pop('description', None)\n        description = 'An additional property for a %s object.' % name\n        schema = {\n            'id': new_type_name,\n            'type': 'object',\n            'description': description,\n            'properties': {\n                'key': {\n                    'type': 'string',\n                    'description': 'Name of the additional property.',\n                },\n                'value': property_schema,\n            },\n        }\n        self.AddDescriptorFromSchema(new_type_name, schema)\n        return new_type_name", "response": "Add a new nested AdditionalProperty message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __AddEntryType(self, entry_type_name, entry_schema, parent_name):\n        entry_schema.pop('description', None)\n        description = 'Single entry in a %s.' % parent_name\n        schema = {\n            'id': entry_type_name,\n            'type': 'object',\n            'description': description,\n            'properties': {\n                'entry': {\n                    'type': 'array',\n                    'items': entry_schema,\n                },\n            },\n        }\n        self.AddDescriptorFromSchema(entry_type_name, schema)\n        return entry_type_name", "response": "Add a type for a list entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a field descriptor for these attrs.", "response": "def __FieldDescriptorFromProperties(self, name, index, attrs):\n        \"\"\"Create a field descriptor for these attrs.\"\"\"\n        field = descriptor.FieldDescriptor()\n        field.name = self.__names.CleanName(name)\n        field.number = index\n        field.label = self.__ComputeLabel(attrs)\n        new_type_name_hint = self.__names.ClassName(\n            '%sValue' % self.__names.ClassName(name))\n        type_info = self.__GetTypeInfo(attrs, new_type_name_hint)\n        field.type_name = type_info.type_name\n        field.variant = type_info.variant\n        if 'default' in attrs:\n            # TODO(craigcitro): Correctly handle non-primitive default values.\n            default = attrs['default']\n            if not (field.type_name == 'string' or\n                    field.variant == messages.Variant.ENUM):\n                default = str(json.loads(default))\n            if field.variant == messages.Variant.ENUM:\n                default = self.__names.NormalizeEnumName(default)\n            field.default_value = default\n        extended_field = extended_descriptor.ExtendedFieldDescriptor()\n        extended_field.name = field.name\n        extended_field.description = util.CleanDescription(\n            attrs.get('description', 'A %s attribute.' % field.type_name))\n        extended_field.field_descriptor = field\n        return extended_field"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a TypeInfo object for the given attributes.", "response": "def __GetTypeInfo(self, attrs, name_hint):\n        \"\"\"Return a TypeInfo object for attrs, creating one if needed.\"\"\"\n\n        type_ref = self.__names.ClassName(attrs.get('$ref'))\n        type_name = attrs.get('type')\n        if not (type_ref or type_name):\n            raise ValueError('No type found for %s' % attrs)\n\n        if type_ref:\n            self.__AddIfUnknown(type_ref)\n            # We don't actually know this is a message -- it might be an\n            # enum. However, we can't check that until we've created all the\n            # types, so we come back and fix this up later.\n            return TypeInfo(\n                type_name=type_ref, variant=messages.Variant.MESSAGE)\n\n        if 'enum' in attrs:\n            enum_name = '%sValuesEnum' % name_hint\n            return self.__DeclareEnum(enum_name, attrs)\n\n        if 'format' in attrs:\n            type_info = self.PRIMITIVE_FORMAT_MAP.get(attrs['format'])\n            if type_info is None:\n                # If we don't recognize the format, the spec says we fall back\n                # to just using the type name.\n                if type_name in self.PRIMITIVE_TYPE_INFO_MAP:\n                    return self.PRIMITIVE_TYPE_INFO_MAP[type_name]\n                raise ValueError('Unknown type/format \"%s\"/\"%s\"' % (\n                    attrs['format'], type_name))\n            if type_info.type_name.startswith((\n                    'apitools.base.protorpclite.message_types.',\n                    'message_types.')):\n                self.__AddImport(\n                    'from %s import message_types as _message_types' %\n                    self.__protorpc_package)\n            if type_info.type_name.startswith('extra_types.'):\n                self.__AddImport(\n                    'from %s import extra_types' % self.__base_files_package)\n            return type_info\n\n        if type_name in self.PRIMITIVE_TYPE_INFO_MAP:\n            type_info = self.PRIMITIVE_TYPE_INFO_MAP[type_name]\n            if type_info.type_name.startswith('extra_types.'):\n                self.__AddImport(\n                    'from %s import extra_types' % self.__base_files_package)\n            return type_info\n\n        if type_name == 'array':\n            items = attrs.get('items')\n            if not items:\n                raise ValueError('Array type with no item type: %s' % attrs)\n            entry_name_hint = self.__names.ClassName(\n                items.get('title') or '%sListEntry' % name_hint)\n            entry_label = self.__ComputeLabel(items)\n            if entry_label == descriptor.FieldDescriptor.Label.REPEATED:\n                parent_name = self.__names.ClassName(\n                    items.get('title') or name_hint)\n                entry_type_name = self.__AddEntryType(\n                    entry_name_hint, items.get('items'), parent_name)\n                return TypeInfo(type_name=entry_type_name,\n                                variant=messages.Variant.MESSAGE)\n            return self.__GetTypeInfo(items, entry_name_hint)\n        elif type_name == 'any':\n            self.__AddImport('from %s import extra_types' %\n                             self.__base_files_package)\n            return self.PRIMITIVE_TYPE_INFO_MAP['any']\n        elif type_name == 'object':\n            # TODO(craigcitro): Think of a better way to come up with names.\n            if not name_hint:\n                raise ValueError(\n                    'Cannot create subtype without some name hint')\n            schema = dict(attrs)\n            schema['id'] = name_hint\n            self.AddDescriptorFromSchema(name_hint, schema)\n            self.__AddIfUnknown(name_hint)\n            return TypeInfo(\n                type_name=name_hint, variant=messages.Variant.MESSAGE)\n\n        raise ValueError('Unknown type: %s' % type_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _GetDiscoveryDocFromFlags(args):\n    if args.discovery_url:\n        try:\n            return util.FetchDiscoveryDoc(args.discovery_url)\n        except exceptions.CommunicationError:\n            raise exceptions.GeneratedClientError(\n                'Could not fetch discovery doc')\n\n    infile = os.path.expanduser(args.infile) or '/dev/stdin'\n    with io.open(infile, encoding='utf8') as f:\n        return json.loads(util.ReplaceHomoglyphs(f.read()))", "response": "Get the discovery doc from flags."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _GetCodegenFromFlags(args):\n    discovery_doc = _GetDiscoveryDocFromFlags(args)\n    names = util.Names(\n        args.strip_prefix,\n        args.experimental_name_convention,\n        args.experimental_capitalize_enums)\n\n    if args.client_json:\n        try:\n            with io.open(args.client_json, encoding='utf8') as client_json:\n                f = json.loads(util.ReplaceHomoglyphs(client_json.read()))\n                web = f.get('installed', f.get('web', {}))\n                client_id = web.get('client_id')\n                client_secret = web.get('client_secret')\n        except IOError:\n            raise exceptions.NotFoundError(\n                'Failed to open client json file: %s' % args.client_json)\n    else:\n        client_id = args.client_id\n        client_secret = args.client_secret\n\n    if not client_id:\n        logging.warning('No client ID supplied')\n        client_id = ''\n\n    if not client_secret:\n        logging.warning('No client secret supplied')\n        client_secret = ''\n\n    client_info = util.ClientInfo.Create(\n        discovery_doc, args.scope, client_id, client_secret,\n        args.user_agent, names, args.api_key)\n    outdir = os.path.expanduser(args.outdir) or client_info.default_directory\n    if os.path.exists(outdir) and not args.overwrite:\n        raise exceptions.ConfigurationValueError(\n            'Output directory exists, pass --overwrite to replace '\n            'the existing files.')\n    if not os.path.exists(outdir):\n        os.makedirs(outdir)\n\n    return gen_client_lib.DescriptorGenerator(\n        discovery_doc, client_info, names, args.root_package, outdir,\n        base_package=args.base_package,\n        protorpc_package=args.protorpc_package,\n        init_wildcards_file=(args.init_file == 'wildcards'),\n        use_proto2=args.experimental_proto2_output,\n        unelidable_request_methods=args.unelidable_request_methods,\n        apitools_version=args.apitools_version)", "response": "Create a codegen object from flags."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GenerateClient(args):\n\n    \"\"\"Driver for client code generation.\"\"\"\n\n    codegen = _GetCodegenFromFlags(args)\n    if codegen is None:\n        logging.error('Failed to create codegen, exiting.')\n        return 128\n    _WriteGeneratedFiles(args, codegen)\n    if args.init_file != 'none':\n        _WriteInit(codegen)", "response": "Driver for client code generation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a client as a pip - installable tarball.", "response": "def GeneratePipPackage(args):\n\n    \"\"\"Generate a client as a pip-installable tarball.\"\"\"\n\n    discovery_doc = _GetDiscoveryDocFromFlags(args)\n    package = discovery_doc['name']\n    original_outdir = os.path.expanduser(args.outdir)\n    args.outdir = os.path.join(\n        args.outdir, 'apitools/clients/%s' % package)\n    args.root_package = 'apitools.clients.%s' % package\n    codegen = _GetCodegenFromFlags(args)\n    if codegen is None:\n        logging.error('Failed to create codegen, exiting.')\n        return 1\n    _WriteGeneratedFiles(args, codegen)\n    _WriteInit(codegen)\n    with util.Chdir(original_outdir):\n        _WriteSetupPy(codegen)\n        with util.Chdir('apitools'):\n            _WriteIntermediateInit(codegen)\n            with util.Chdir('clients'):\n                _WriteIntermediateInit(codegen)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads at most size bytes from this slice.", "response": "def read(self, size=None):  # pylint: disable=missing-docstring\n        \"\"\"Read at most size bytes from this slice.\n\n        Compared to other streams, there is one case where we may\n        unexpectedly raise an exception on read: if the underlying stream\n        is exhausted (i.e. returns no bytes on read), and the size of this\n        slice indicates we should still be able to read more bytes, we\n        raise exceptions.StreamExhausted.\n\n        Args:\n          size: If provided, read no more than size bytes from the stream.\n\n        Returns:\n          The bytes read from this slice.\n\n        Raises:\n          exceptions.StreamExhausted\n\n        \"\"\"\n        if size is not None:\n            read_size = min(size, self.__remaining_bytes)\n        else:\n            read_size = self.__remaining_bytes\n        data = self.__stream.read(read_size)\n        if read_size > 0 and not data:\n            raise exceptions.StreamExhausted(\n                'Not enough bytes in stream; expected %d, exhausted '\n                'after %d' % (\n                    self.__max_bytes,\n                    self.__max_bytes - self.__remaining_bytes))\n        self.__remaining_bytes -= len(data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download_setuptools(\n    version=DEFAULT_VERSION, download_base=DEFAULT_URL, to_dir=os.curdir,\n    delay = 15\n):\n    \"\"\"Download setuptools from a specified location and return its filename\n\n    `version` should be a valid setuptools version number that is available\n    as an egg for download under the `download_base` URL (which should end\n    with a '/'). `to_dir` is the directory where the egg will be downloaded.\n    `delay` is the number of seconds to pause before an actual download attempt.\n    \"\"\"\n    import urllib2, shutil\n    egg_name = \"setuptools-%s-py%s.egg\" % (version,sys.version[:3])\n    url = download_base + egg_name\n    saveto = os.path.join(to_dir, egg_name)\n    src = dst = None\n    if not os.path.exists(saveto):  # Avoid repeated downloads\n        try:\n            from distutils import log\n            if delay:\n                log.warn(\"\"\"\n---------------------------------------------------------------------------\nThis script requires setuptools version %s to run (even to display\nhelp).  I will attempt to download it for you (from\n%s), but\nyou may need to enable firewall access for this script first.\nI will start the download in %d seconds.\n\n(Note: if this machine does not have network access, please obtain the file\n\n   %s\n\nand place it in this directory before rerunning this script.)\n---------------------------------------------------------------------------\"\"\",\n                    version, download_base, delay, url\n                ); from time import sleep; sleep(delay)\n            log.warn(\"Downloading %s\", url)\n            src = urllib2.urlopen(url)\n            # Read/write all in one block, so we don't create a corrupt file\n            # if the download is interrupted.\n            data = _validate_md5(egg_name, src.read())\n            dst = open(saveto,\"wb\"); dst.write(data)\n        finally:\n            if src: src.close()\n            if dst: dst.close()\n    return os.path.realpath(saveto)", "response": "Download setuptools from a specified location and return its filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls or upgrade setuptools and EasyInstall", "response": "def main(argv, version=DEFAULT_VERSION):\n    \"\"\"Install or upgrade setuptools and EasyInstall\"\"\"\n    try:\n        import setuptools\n    except ImportError:\n        egg = None\n        try:\n            egg = download_setuptools(version, delay=0)\n            sys.path.insert(0,egg)\n            from setuptools.command.easy_install import main\n            return main(list(argv)+[egg])   # we're done here\n        finally:\n            if egg and os.path.exists(egg):\n                os.unlink(egg)\n    else:\n        if setuptools.__version__ == '0.0.1':\n            print >>sys.stderr, (\n            \"You have an obsolete version of setuptools installed.  Please\\n\"\n            \"remove it from your system entirely before rerunning this script.\"\n            )\n            sys.exit(2)\n\n    req = \"setuptools>=\"+version\n    import pkg_resources\n    try:\n        pkg_resources.require(req)\n    except pkg_resources.VersionConflict:\n        try:\n            from setuptools.command.easy_install import main\n        except ImportError:\n            from easy_install import main\n        main(list(argv)+[download_setuptools(delay=0)])\n        sys.exit(0) # try to force an exit\n    else:\n        if argv:\n            from setuptools.command.easy_install import main\n            main(argv)\n        else:\n            print \"Setuptools version\",version,\"or greater has been installed.\"\n            print '(Run \"ez_setup.py -U setuptools\" to reinstall or upgrade.)'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_md5(filenames):\n\n    import re\n\n    for name in filenames:\n        base = os.path.basename(name)\n        f = open(name,'rb')\n        md5_data[base] = md5(f.read()).hexdigest()\n        f.close()\n\n    data = [\"    %r: %r,\\n\" % it for it in md5_data.items()]\n    data.sort()\n    repl = \"\".join(data)\n\n    import inspect\n    srcfile = inspect.getsourcefile(sys.modules[__name__])\n    f = open(srcfile, 'rb'); src = f.read(); f.close()\n\n    match = re.search(\"\\nmd5_data = {\\n([^}]+)}\", src)\n    if not match:\n        print >>sys.stderr, \"Internal error!\"\n        sys.exit(2)\n\n    src = src[:match.start(1)] + repl + src[match.end(1):]\n    f = open(srcfile,'w')\n    f.write(src)\n    f.close()", "response": "Update our built - in md5 registry with the contents of the given files."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a request to the batch.", "response": "def Add(self, service, method, request, global_params=None):\n        \"\"\"Add a request to the batch.\n\n        Args:\n          service: A class inheriting base_api.BaseApiService.\n          method: A string indicated desired method from the service. See\n              the example in the class docstring.\n          request: An input message appropriate for the specified\n              service.method.\n          global_params: Optional additional parameters to pass into\n              method.PrepareHttpRequest.\n\n        Returns:\n          None\n\n        \"\"\"\n        # Retrieve the configs for the desired method and service.\n        method_config = service.GetMethodConfig(method)\n        upload_config = service.GetUploadConfig(method)\n\n        # Prepare the HTTP Request.\n        http_request = service.PrepareHttpRequest(\n            method_config, request, global_params=global_params,\n            upload_config=upload_config)\n\n        # Create the request and add it to our master list.\n        api_request = self.ApiCall(\n            http_request, self.retryable_codes, service, method_config)\n        self.api_requests.append(api_request)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Execute(self, http, sleep_between_polls=5, max_retries=5,\n                max_batch_size=None, batch_request_callback=None):\n        \"\"\"Execute all of the requests in the batch.\n\n        Args:\n          http: httplib2.Http object for use in the request.\n          sleep_between_polls: Integer number of seconds to sleep between\n              polls.\n          max_retries: Max retries. Any requests that have not succeeded by\n              this number of retries simply report the last response or\n              exception, whatever it happened to be.\n          max_batch_size: int, if specified requests will be split in batches\n              of given size.\n          batch_request_callback: function of (http_response, exception) passed\n              to BatchHttpRequest which will be run on any given results.\n\n        Returns:\n          List of ApiCalls.\n        \"\"\"\n        requests = [request for request in self.api_requests\n                    if not request.terminal_state]\n        batch_size = max_batch_size or len(requests)\n\n        for attempt in range(max_retries):\n            if attempt:\n                time.sleep(sleep_between_polls)\n\n            for i in range(0, len(requests), batch_size):\n                # Create a batch_http_request object and populate it with\n                # incomplete requests.\n                batch_http_request = BatchHttpRequest(\n                    batch_url=self.batch_url,\n                    callback=batch_request_callback,\n                    response_encoding=self.response_encoding\n                )\n                for request in itertools.islice(requests,\n                                                i, i + batch_size):\n                    batch_http_request.Add(\n                        request.http_request, request.HandleResponse)\n                batch_http_request.Execute(http)\n\n                if hasattr(http.request, 'credentials'):\n                    if any(request.authorization_failed\n                           for request in itertools.islice(requests,\n                                                           i, i + batch_size)):\n                        http.request.credentials.refresh(http)\n\n            # Collect retryable requests.\n            requests = [request for request in self.api_requests if not\n                        request.terminal_state]\n            if not requests:\n                break\n\n        return self.api_requests", "response": "Execute all of the requests in the batch."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a Content - ID header value to an id.", "response": "def _ConvertHeaderToId(header):\n        \"\"\"Convert a Content-ID header value to an id.\n\n        Presumes the Content-ID header conforms to the format that\n        _ConvertIdToHeader() returns.\n\n        Args:\n          header: A string indicating the Content-ID header value.\n\n        Returns:\n          The extracted id value.\n\n        Raises:\n          BatchError if the header is not in the expected format.\n        \"\"\"\n        if not (header.startswith('<') or header.endswith('>')):\n            raise exceptions.BatchError(\n                'Invalid value for Content-ID: %s' % header)\n        if '+' not in header:\n            raise exceptions.BatchError(\n                'Invalid value for Content-ID: %s' % header)\n        _, request_id = header[1:-1].rsplit('+', 1)\n\n        return urllib_parse.unquote(request_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _SerializeRequest(self, request):\n        # Construct status line\n        parsed = urllib_parse.urlsplit(request.url)\n        request_line = urllib_parse.urlunsplit(\n            ('', '', parsed.path, parsed.query, ''))\n        if not isinstance(request_line, six.text_type):\n            request_line = request_line.decode('utf-8')\n        status_line = u' '.join((\n            request.http_method,\n            request_line,\n            u'HTTP/1.1\\n'\n        ))\n        major, minor = request.headers.get(\n            'content-type', 'application/json').split('/')\n        msg = mime_nonmultipart.MIMENonMultipart(major, minor)\n\n        # MIMENonMultipart adds its own Content-Type header.\n        # Keep all of the other headers in `request.headers`.\n        for key, value in request.headers.items():\n            if key == 'content-type':\n                continue\n            msg[key] = value\n\n        msg['Host'] = parsed.netloc\n        msg.set_unixfrom(None)\n\n        if request.body is not None:\n            msg.set_payload(request.body)\n\n        # Serialize the mime message.\n        str_io = six.StringIO()\n        # maxheaderlen=0 means don't line wrap headers.\n        gen = generator.Generator(str_io, maxheaderlen=0)\n        gen.flatten(msg, unixfrom=False)\n        body = str_io.getvalue()\n\n        return status_line + body", "response": "Convert a http_wrapper. Request object into a string in application / http format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _DeserializeResponse(self, payload):\n        # Strip off the status line.\n        status_line, payload = payload.split('\\n', 1)\n        _, status, _ = status_line.split(' ', 2)\n\n        # Parse the rest of the response.\n        parser = email_parser.Parser()\n        msg = parser.parsestr(payload)\n\n        # Get the headers.\n        info = dict(msg)\n        info['status'] = status\n\n        # Create Response from the parsed headers.\n        content = msg.get_payload()\n\n        return http_wrapper.Response(info, content, self.__batch_url)", "response": "Convert string into Response and content."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Add(self, request, callback=None):\n        handler = RequestResponseAndHandler(request, None, callback)\n        self.__request_response_handlers[self._NewId()] = handler", "response": "Add a new request to the batch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserializing batch request send to server process response.", "response": "def _Execute(self, http):\n        \"\"\"Serialize batch request, send to server, process response.\n\n        Args:\n          http: A httplib2.Http object to be used to make the request with.\n\n        Raises:\n          httplib2.HttpLib2Error if a transport error has occured.\n          apiclient.errors.BatchError if the response is the wrong format.\n        \"\"\"\n        message = mime_multipart.MIMEMultipart('mixed')\n        # Message should not write out its own headers.\n        setattr(message, '_write_headers', lambda self: None)\n\n        # Add all the individual requests.\n        for key in self.__request_response_handlers:\n            msg = mime_nonmultipart.MIMENonMultipart('application', 'http')\n            msg['Content-Transfer-Encoding'] = 'binary'\n            msg['Content-ID'] = self._ConvertIdToHeader(key)\n\n            body = self._SerializeRequest(\n                self.__request_response_handlers[key].request)\n            msg.set_payload(body)\n            message.attach(msg)\n\n        request = http_wrapper.Request(self.__batch_url, 'POST')\n        request.body = message.as_string()\n        request.headers['content-type'] = (\n            'multipart/mixed; boundary=\"%s\"') % message.get_boundary()\n\n        response = http_wrapper.MakeRequest(http, request)\n\n        if response.status_code >= 300:\n            raise exceptions.HttpError.FromResponse(response)\n\n        # Prepend with a content-type header so Parser can handle it.\n        header = 'content-type: %s\\r\\n\\r\\n' % response.info['content-type']\n\n        content = response.content\n        if isinstance(content, bytes) and self.__response_encoding:\n            content = response.content.decode(self.__response_encoding)\n\n        parser = email_parser.Parser()\n        mime_response = parser.parsestr(header + content)\n\n        if not mime_response.is_multipart():\n            raise exceptions.BatchError(\n                'Response not in multipart/mixed format.')\n\n        for part in mime_response.get_payload():\n            request_id = self._ConvertHeaderToId(part['Content-ID'])\n            response = self._DeserializeResponse(part.get_payload())\n\n            # Disable protected access because namedtuple._replace(...)\n            # is not actually meant to be protected.\n            # pylint: disable=protected-access\n            self.__request_response_handlers[request_id] = (\n                self.__request_response_handlers[request_id]._replace(\n                    response=response))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Execute(self, http):\n\n        self._Execute(http)\n\n        for key in self.__request_response_handlers:\n            response = self.__request_response_handlers[key].response\n            callback = self.__request_response_handlers[key].handler\n\n            exception = None\n\n            if response.status_code >= 300:\n                exception = exceptions.HttpError.FromResponse(response)\n\n            if callback is not None:\n                callback(response, exception)\n            if self.__callback is not None:\n                self.__callback(response, exception)", "response": "Executes all the requests as a single batched HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_definition(name, relative_to=None, importer=__import__):\n    # Check parameters.\n    if not (relative_to is None or\n            isinstance(relative_to, types.ModuleType) or\n            isinstance(relative_to, type) and\n            issubclass(relative_to, Message)):\n        raise TypeError(\n            'relative_to must be None, Message definition or module.'\n            '  Found: %s' % relative_to)\n\n    name_path = name.split('.')\n\n    # Handle absolute path reference.\n    if not name_path[0]:\n        relative_to = None\n        name_path = name_path[1:]\n\n    def search_path():\n        \"\"\"Performs a single iteration searching the path from relative_to.\n\n        This is the function that searches up the path from a relative object.\n\n          fully.qualified.object . relative.or.nested.Definition\n                                   ---------------------------->\n                                                      ^\n                                                      |\n                                this part of search --+\n\n        Returns:\n          Message or Enum at the end of name_path, else None.\n        \"\"\"\n        next_part = relative_to\n        for node in name_path:\n            # Look for attribute first.\n            attribute = getattr(next_part, node, None)\n\n            if attribute is not None:\n                next_part = attribute\n            else:\n                # If module, look for sub-module.\n                if (next_part is None or\n                        isinstance(next_part, types.ModuleType)):\n                    if next_part is None:\n                        module_name = node\n                    else:\n                        module_name = '%s.%s' % (next_part.__name__, node)\n\n                    try:\n                        fromitem = module_name.split('.')[-1]\n                        next_part = importer(module_name, '', '',\n                                             [str(fromitem)])\n                    except ImportError:\n                        return None\n                else:\n                    return None\n\n            if not isinstance(next_part, types.ModuleType):\n                if not (isinstance(next_part, type) and\n                        issubclass(next_part, (Message, Enum))):\n                    return None\n\n        return next_part\n\n    while True:\n        found = search_path()\n        if isinstance(found, type) and issubclass(found, (Enum, Message)):\n            return found\n        else:\n            # Find next relative_to to search against.\n            #\n            #   fully.qualified.object . relative.or.nested.Definition\n            #   <---------------------\n            #           ^\n            #           |\n            #   does this part of search\n            if relative_to is None:\n                # Fully qualified search was done.  Nothing found.  Fail.\n                raise DefinitionNotFoundError(\n                    'Could not find definition for %s' % name)\n            else:\n                if isinstance(relative_to, types.ModuleType):\n                    # Find parent module.\n                    module_path = relative_to.__name__.split('.')[:-1]\n                    if not module_path:\n                        relative_to = None\n                    else:\n                        # Should not raise ImportError. If it does...\n                        # weird and unexpected. Propagate.\n                        relative_to = importer(\n                            '.'.join(module_path), '', '', [module_path[-1]])\n                elif (isinstance(relative_to, type) and\n                      issubclass(relative_to, Message)):\n                    parent = relative_to.message_definition()\n                    if parent is None:\n                        last_module_name = relative_to.__module__.split(\n                            '.')[-1]\n                        relative_to = importer(\n                            relative_to.__module__, '', '', [last_module_name])\n                    else:\n                        relative_to = parent", "response": "Find a definition by name relative to a message definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string that can be used to create a definition name for a class.", "response": "def definition_name(cls):\n        \"\"\"Helper method for creating definition name.\n\n        Names will be generated to include the classes package name,\n        scope (if the class is nested in another definition) and class\n        name.\n\n        By default, the package name for a definition is derived from\n        its module name. However, this value can be overriden by\n        placing a 'package' attribute in the module that contains the\n        definition class. For example:\n\n          package = 'some.alternate.package'\n\n          class MyMessage(Message):\n            ...\n\n          >>> MyMessage.definition_name()\n          some.alternate.package.MyMessage\n\n        Returns:\n          Dot-separated fully qualified name of definition.\n\n        \"\"\"\n        outer_definition_name = cls.outer_definition_name()\n        if outer_definition_name is None:\n            return six.text_type(cls.__name__)\n        return u'%s.%s' % (outer_definition_name, cls.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake dictionary version of enumerated class.", "response": "def to_dict(cls):\n        \"\"\"Make dictionary version of enumerated class.\n\n        Dictionary created this way can be used with def_num.\n\n        Returns:\n          A dict (name) -> number\n        \"\"\"\n        return dict((item.name, item.number) for item in iter(cls))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that all required fields are initialized.", "response": "def check_initialized(self):\n        \"\"\"Check class for initialization status.\n\n        Check that all required fields are initialized\n\n        Raises:\n          ValidationError: If message is not initialized.\n        \"\"\"\n        for name, field in self.__by_name.items():\n            value = getattr(self, name)\n            if value is None:\n                if field.required:\n                    raise ValidationError(\n                        \"Message %s is missing required field %s\" %\n                        (type(self).__name__, name))\n            else:\n                try:\n                    if (isinstance(field, MessageField) and\n                            issubclass(field.message_type, Message)):\n                        if field.repeated:\n                            for item in value:\n                                item_message_value = field.value_to_message(\n                                    item)\n                                item_message_value.check_initialized()\n                        else:\n                            message_value = field.value_to_message(value)\n                            message_value.check_initialized()\n                except ValidationError as err:\n                    if not hasattr(err, 'message_name'):\n                        err.message_name = type(self).__name__\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the assigned value of an attribute.", "response": "def get_assigned_value(self, name):\n        \"\"\"Get the assigned value of an attribute.\n\n        Get the underlying value of an attribute. If value has not\n        been set, will not return the default for the field.\n\n        Args:\n          name: Name of attribute to get.\n\n        Returns:\n          Value of attribute, None if it has not been set.\n\n        \"\"\"\n        message_type = type(self)\n        try:\n            field = message_type.field_by_name(name)\n        except KeyError:\n            raise AttributeError('Message %s has no field %s' % (\n                message_type.__name__, name))\n        return self.__tags.get(field.number)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset(self, name):\n        message_type = type(self)\n        try:\n            field = message_type.field_by_name(name)\n        except KeyError:\n            if name not in message_type.__by_name:\n                raise AttributeError('Message %s has no field %s' % (\n                    message_type.__name__, name))\n        if field.repeated:\n            self.__tags[field.number] = FieldList(field, [])\n        else:\n            self.__tags.pop(field.number, None)", "response": "Reset assigned value for a field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the value and variant of an unknown field in this message.", "response": "def get_unrecognized_field_info(self, key, value_default=None,\n                                    variant_default=None):\n        \"\"\"Get the value and variant of an unknown field in this message.\n\n        Args:\n          key: The name or number of the field to retrieve.\n          value_default: Value to be returned if the key isn't found.\n          variant_default: Value to be returned as variant if the key isn't\n            found.\n\n        Returns:\n          (value, variant), where value and variant are whatever was passed\n          to set_unrecognized_field.\n        \"\"\"\n        value, variant = self.__unrecognized_fields.get(key, (value_default,\n                                                              variant_default))\n        return value, variant"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset an unrecognized field in the message.", "response": "def set_unrecognized_field(self, key, value, variant):\n        \"\"\"Set an unrecognized field, used when decoding a message.\n\n        Args:\n          key: The name or number used to refer to this unknown value.\n          value: The value of the field.\n          variant: Type information needed to interpret the value or re-encode\n            it.\n\n        Raises:\n          TypeError: If the variant is not an instance of messages.Variant.\n        \"\"\"\n        if not isinstance(variant, Variant):\n            raise TypeError('Variant type %s is not valid.' % variant)\n        self.__unrecognized_fields[key] = value, variant"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating item appending to list.", "response": "def append(self, value):\n        \"\"\"Validate item appending to list.\"\"\"\n        self.__field.validate_element(value)\n        return list.append(self, value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates extension of list.", "response": "def extend(self, sequence):\n        \"\"\"Validate extension of list.\"\"\"\n        self.__field.validate(sequence)\n        return list.extend(self, sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert(self, index, value):\n        self.__field.validate_element(value)\n        return list.insert(self, index, value)", "response": "Validate item insertion to list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate a single element of the field.", "response": "def validate_element(self, value):\n        \"\"\"Validate single element of field.\n\n        This is different from validate in that it is used on individual\n        values of repeated fields.\n\n        Args:\n          value: Value to validate.\n\n        Returns:\n          The value casted in the expected type.\n\n        Raises:\n          ValidationError if value is not expected type.\n        \"\"\"\n        if not isinstance(value, self.type):\n\n            # Authorize int values as float.\n            if isinstance(value, six.integer_types) and self.type == float:\n                return float(value)\n\n            if value is None:\n                if self.required:\n                    raise ValidationError('Required field is missing')\n            else:\n                try:\n                    name = self.name\n                except AttributeError:\n                    raise ValidationError('Expected type %s for %s, '\n                                          'found %s (type %s)' %\n                                          (self.type, self.__class__.__name__,\n                                           value, type(value)))\n                else:\n                    raise ValidationError(\n                        'Expected type %s for field %s, found %s (type %s)' %\n                        (self.type, name, value, type(value)))\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates a string and return the value.", "response": "def validate_element(self, value):\n        \"\"\"Validate StringField allowing for str and unicode.\n\n        Raises:\n          ValidationError if a str value is not UTF-8.\n        \"\"\"\n        # If value is str is it considered valid.  Satisfies \"required=True\".\n        if isinstance(value, bytes):\n            try:\n                six.text_type(value, 'UTF-8')\n            except UnicodeDecodeError as err:\n                try:\n                    _ = self.name\n                except AttributeError:\n                    validation_error = ValidationError(\n                        'Field encountered non-UTF-8 string %r: %s' % (value,\n                                                                       err))\n                else:\n                    validation_error = ValidationError(\n                        'Field %s encountered non-UTF-8 string %r: %s' % (\n                            self.name, value, err))\n                    validation_error.field_name = self.name\n                raise validation_error\n        else:\n            return super(StringField, self).validate_element(value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmessage type used for field.", "response": "def type(self):\n        \"\"\"Message type used for field.\"\"\"\n        if self.__type is None:\n            message_type = find_definition(\n                self.__type_name, self.message_definition())\n            if not (message_type is not Message and\n                    isinstance(message_type, type) and\n                    issubclass(message_type, Message)):\n                raise FieldDefinitionError(\n                    'Invalid message class: %s' % message_type)\n            self.__type = message_type\n        return self.__type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef value_from_message(self, message):\n        if not isinstance(message, self.message_type):\n            raise DecodeError('Expected type %s, got %s: %r' %\n                              (self.message_type.__name__,\n                               type(message).__name__,\n                               message))\n        return message", "response": "Convert a message instance to a value instance of expected user type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value_to_message(self, value):\n        if not isinstance(value, self.type):\n            raise EncodeError('Expected type %s, got %s: %r' %\n                              (self.type.__name__,\n                               type(value).__name__,\n                               value))\n        return value", "response": "Convert a value instance to a message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate default element of Enum field.", "response": "def validate_default_element(self, value):\n        \"\"\"Validate default element of Enum field.\n\n        Enum fields allow for delayed resolution of default values\n        when the type of the field has not been resolved. The default\n        value of a field may be a string or an integer. If the Enum\n        type of the field has been resolved, the default value is\n        validated against that type.\n\n        Args:\n          value: Value to validate.\n\n        Raises:\n          ValidationError if value is not expected message type.\n\n        \"\"\"\n        if isinstance(value, (six.string_types, six.integer_types)):\n            # Validation of the value does not happen for delayed resolution\n            # enumerated types.  Ignore if type is not yet resolved.\n            if self.__type:\n                self.__type(value)\n            return value\n\n        return super(EnumField, self).validate_default_element(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef type(self):\n        if self.__type is None:\n            found_type = find_definition(\n                self.__type_name, self.message_definition())\n            if not (found_type is not Enum and\n                    isinstance(found_type, type) and\n                    issubclass(found_type, Enum)):\n                raise FieldDefinitionError(\n                    'Invalid enum type: %s' % found_type)\n\n            self.__type = found_type\n        return self.__type", "response": "Enum type used for field."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default(self):\n        try:\n            return self.__resolved_default\n        except AttributeError:\n            resolved_default = super(EnumField, self).default\n            if isinstance(resolved_default, (six.string_types,\n                                             six.integer_types)):\n                # pylint:disable=not-callable\n                resolved_default = self.type(resolved_default)\n            self.__resolved_default = resolved_default\n            return self.__resolved_default", "response": "Default for enum field.\n\n        Will cause resolution of Enum type and unresolved default value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef RegisterCustomMessageCodec(encoder, decoder):\n    def Register(cls):\n        _CUSTOM_MESSAGE_CODECS[cls] = _Codec(encoder=encoder, decoder=decoder)\n        return cls\n    return Register", "response": "Register a custom encoder and decoder for this message class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RegisterCustomFieldCodec(encoder, decoder):\n    def Register(field):\n        _CUSTOM_FIELD_CODECS[field] = _Codec(encoder=encoder, decoder=decoder)\n        return field\n    return Register", "response": "Register a custom encoder and decoder for this field."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a custom encoder and decoder for all fields of this type.", "response": "def RegisterFieldTypeCodec(encoder, decoder):\n    \"\"\"Register a custom encoder/decoder for all fields of this type.\"\"\"\n    def Register(field_type):\n        _FIELD_TYPE_CODECS[field_type] = _Codec(\n            encoder=encoder, decoder=decoder)\n        return field_type\n    return Register"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef MessageToJson(message, include_fields=None):\n    result = _ProtoJsonApiTools.Get().encode_message(message)\n    return _IncludeFields(result, message, include_fields)", "response": "Convert the given message to JSON."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the given dictionary to an AdditionalProperty message.", "response": "def DictToAdditionalPropertyMessage(properties, additional_property_type,\n                                    sort_items=False):\n    \"\"\"Convert the given dictionary to an AdditionalProperty message.\"\"\"\n    items = properties.items()\n    if sort_items:\n        items = sorted(items)\n    map_ = []\n    for key, value in items:\n        map_.append(additional_property_type.AdditionalProperty(\n            key=key, value=value))\n    return additional_property_type(additionalProperties=map_)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a repr - style string for a protorpc message.", "response": "def MessageToRepr(msg, multiline=False, **kwargs):\n    \"\"\"Return a repr-style string for a protorpc message.\n\n    protorpc.Message.__repr__ does not return anything that could be considered\n    python code. Adding this function lets us print a protorpc message in such\n    a way that it could be pasted into code later, and used to compare against\n    other things.\n\n    Args:\n      msg: protorpc.Message, the message to be repr'd.\n      multiline: bool, True if the returned string should have each field\n          assignment on its own line.\n      **kwargs: {str:str}, Additional flags for how to format the string.\n\n    Known **kwargs:\n      shortstrings: bool, True if all string values should be\n          truncated at 100 characters, since when mocking the contents\n          typically don't matter except for IDs, and IDs are usually\n          less than 100 characters.\n      no_modules: bool, True if the long module name should not be printed with\n          each type.\n\n    Returns:\n      str, A string of valid python (assuming the right imports have been made)\n      that recreates the message passed into this function.\n\n    \"\"\"\n\n    # TODO(jasmuth): craigcitro suggests a pretty-printer from apitools/gen.\n\n    indent = kwargs.get('indent', 0)\n\n    def IndentKwargs(kwargs):\n        kwargs = dict(kwargs)\n        kwargs['indent'] = kwargs.get('indent', 0) + 4\n        return kwargs\n\n    if isinstance(msg, list):\n        s = '['\n        for item in msg:\n            if multiline:\n                s += '\\n' + ' ' * (indent + 4)\n            s += MessageToRepr(\n                item, multiline=multiline, **IndentKwargs(kwargs)) + ','\n        if multiline:\n            s += '\\n' + ' ' * indent\n        s += ']'\n        return s\n\n    if isinstance(msg, messages.Message):\n        s = type(msg).__name__ + '('\n        if not kwargs.get('no_modules'):\n            s = msg.__module__ + '.' + s\n        names = sorted([field.name for field in msg.all_fields()])\n        for name in names:\n            field = msg.field_by_name(name)\n            if multiline:\n                s += '\\n' + ' ' * (indent + 4)\n            value = getattr(msg, field.name)\n            s += field.name + '=' + MessageToRepr(\n                value, multiline=multiline, **IndentKwargs(kwargs)) + ','\n        if multiline:\n            s += '\\n' + ' ' * indent\n        s += ')'\n        return s\n\n    if isinstance(msg, six.string_types):\n        if kwargs.get('shortstrings') and len(msg) > 100:\n            msg = msg[:100]\n\n    if isinstance(msg, datetime.datetime):\n\n        class SpecialTZInfo(datetime.tzinfo):\n\n            def __init__(self, offset):\n                super(SpecialTZInfo, self).__init__()\n                self.offset = offset\n\n            def __repr__(self):\n                s = 'TimeZoneOffset(' + repr(self.offset) + ')'\n                if not kwargs.get('no_modules'):\n                    s = 'apitools.base.protorpclite.util.' + s\n                return s\n\n        msg = datetime.datetime(\n            msg.year, msg.month, msg.day, msg.hour, msg.minute, msg.second,\n            msg.microsecond, SpecialTZInfo(msg.tzinfo.utcoffset(0)))\n\n    return repr(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the requested fields to the encoded message.", "response": "def _IncludeFields(encoded_message, message, include_fields):\n    \"\"\"Add the requested fields to the encoded message.\"\"\"\n    if include_fields is None:\n        return encoded_message\n    result = json.loads(encoded_message)\n    for field_name in include_fields:\n        try:\n            value = _GetField(message, field_name.split('.'))\n            nullvalue = None\n            if isinstance(value, list):\n                nullvalue = []\n        except KeyError:\n            raise exceptions.InvalidDataError(\n                'No field named %s in message of type %s' % (\n                    field_name, type(message)))\n        _SetField(result, field_name.split('.'), nullvalue)\n    return json.dumps(result)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrewrite unknown fields in message into message. destination.", "response": "def _DecodeUnknownFields(message, encoded_message):\n    \"\"\"Rewrite unknown fields in message into message.destination.\"\"\"\n    destination = _UNRECOGNIZED_FIELD_MAPPINGS.get(type(message))\n    if destination is None:\n        return message\n    pair_field = message.field_by_name(destination)\n    if not isinstance(pair_field, messages.MessageField):\n        raise exceptions.InvalidDataFromServerError(\n            'Unrecognized fields must be mapped to a compound '\n            'message type.')\n    pair_type = pair_field.message_type\n    # TODO(craigcitro): Add more error checking around the pair\n    # type being exactly what we suspect (field names, etc).\n    if isinstance(pair_type.value, messages.MessageField):\n        new_values = _DecodeUnknownMessages(\n            message, json.loads(encoded_message), pair_type)\n    else:\n        new_values = _DecodeUnrecognizedFields(message, pair_type)\n    setattr(message, destination, new_values)\n    # We could probably get away with not setting this, but\n    # why not clear it?\n    setattr(message, '_Message__unrecognized_fields', {})\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess unknown fields in encoded_message of a message type.", "response": "def _DecodeUnknownMessages(message, encoded_message, pair_type):\n    \"\"\"Process unknown fields in encoded_message of a message type.\"\"\"\n    field_type = pair_type.value.type\n    new_values = []\n    all_field_names = [x.name for x in message.all_fields()]\n    for name, value_dict in six.iteritems(encoded_message):\n        if name in all_field_names:\n            continue\n        value = PyValueToMessage(field_type, value_dict)\n        if pair_type.value.repeated:\n            value = _AsMessageList(value)\n        new_pair = pair_type(key=name, value=value)\n        new_values.append(new_pair)\n    return new_values"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _DecodeUnrecognizedFields(message, pair_type):\n    new_values = []\n    codec = _ProtoJsonApiTools.Get()\n    for unknown_field in message.all_unrecognized_fields():\n        # TODO(craigcitro): Consider validating the variant if\n        # the assignment below doesn't take care of it. It may\n        # also be necessary to check it in the case that the\n        # type has multiple encodings.\n        value, _ = message.get_unrecognized_field_info(unknown_field)\n        value_type = pair_type.field_by_name('value')\n        if isinstance(value_type, messages.MessageField):\n            decoded_value = DictToMessage(value, pair_type.value.message_type)\n        else:\n            decoded_value = codec.decode_field(\n                pair_type.value, value)\n        try:\n            new_pair_key = str(unknown_field)\n        except UnicodeEncodeError:\n            new_pair_key = protojson.ProtoJson().decode_field(\n                pair_type.key, unknown_field)\n        new_pair = pair_type(key=new_pair_key, value=decoded_value)\n        new_values.append(new_pair)\n    return new_values", "response": "Process unrecognized fields in message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _SafeEncodeBytes(field, value):\n    try:\n        if field.repeated:\n            result = [base64.urlsafe_b64encode(byte) for byte in value]\n        else:\n            result = base64.urlsafe_b64encode(value)\n        complete = True\n    except TypeError:\n        result = value\n        complete = False\n    return CodecResult(value=result, complete=complete)", "response": "Encode the bytes in value as urlsafe base64."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _SafeDecodeBytes(unused_field, value):\n    try:\n        result = base64.urlsafe_b64decode(str(value))\n        complete = True\n    except TypeError:\n        result = value\n        complete = False\n    return CodecResult(value=result, complete=complete)", "response": "Decode the urlsafe base64 value into bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing unknown enums from the given Proto message.", "response": "def _ProcessUnknownEnums(message, encoded_message):\n    \"\"\"Add unknown enum values from encoded_message as unknown fields.\n\n    ProtoRPC diverges from the usual protocol buffer behavior here and\n    doesn't allow unknown fields. Throwing on unknown fields makes it\n    impossible to let servers add new enum values and stay compatible\n    with older clients, which isn't reasonable for us. We simply store\n    unrecognized enum values as unknown fields, and all is well.\n\n    Args:\n      message: Proto message we've decoded thus far.\n      encoded_message: JSON string we're decoding.\n\n    Returns:\n      message, with any unknown enums stored as unrecognized fields.\n    \"\"\"\n    if not encoded_message:\n        return message\n    decoded_message = json.loads(six.ensure_str(encoded_message))\n    for field in message.all_fields():\n        if (isinstance(field, messages.EnumField) and\n                field.name in decoded_message and\n                message.get_assigned_value(field.name) is None):\n            message.set_unrecognized_field(\n                field.name, decoded_message[field.name], messages.Variant.ENUM)\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ProcessUnknownMessages(message, encoded_message):\n    if not encoded_message:\n        return message\n    decoded_message = json.loads(six.ensure_str(encoded_message))\n    message_fields = [x.name for x in message.all_fields()] + list(\n        message.all_unrecognized_fields())\n    missing_fields = [x for x in decoded_message.keys()\n                      if x not in message_fields]\n    for field_name in missing_fields:\n        message.set_unrecognized_field(field_name, decoded_message[field_name],\n                                       messages.Variant.STRING)\n    return message", "response": "Processes unknown fields in the message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AddCustomJsonEnumMapping(enum_type, python_name, json_name,\n                             package=None):  # pylint: disable=unused-argument\n    \"\"\"Add a custom wire encoding for a given enum value.\n\n    This is primarily used in generated code, to handle enum values\n    which happen to be Python keywords.\n\n    Args:\n      enum_type: (messages.Enum) An enum type\n      python_name: (basestring) Python name for this value.\n      json_name: (basestring) JSON name to be used on the wire.\n      package: (NoneType, optional) No effect, exists for legacy compatibility.\n    \"\"\"\n    if not issubclass(enum_type, messages.Enum):\n        raise exceptions.TypecheckError(\n            'Cannot set JSON enum mapping for non-enum \"%s\"' % enum_type)\n    if python_name not in enum_type.names():\n        raise exceptions.InvalidDataError(\n            'Enum value %s not a value for type %s' % (python_name, enum_type))\n    field_mappings = _JSON_ENUM_MAPPINGS.setdefault(enum_type, {})\n    _CheckForExistingMappings('enum', enum_type, python_name, json_name)\n    field_mappings[python_name] = json_name", "response": "Adds a custom wire encoding for a given enum value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AddCustomJsonFieldMapping(message_type, python_name, json_name,\n                              package=None):  # pylint: disable=unused-argument\n    \"\"\"Add a custom wire encoding for a given message field.\n\n    This is primarily used in generated code, to handle enum values\n    which happen to be Python keywords.\n\n    Args:\n      message_type: (messages.Message) A message type\n      python_name: (basestring) Python name for this value.\n      json_name: (basestring) JSON name to be used on the wire.\n      package: (NoneType, optional) No effect, exists for legacy compatibility.\n    \"\"\"\n    if not issubclass(message_type, messages.Message):\n        raise exceptions.TypecheckError(\n            'Cannot set JSON field mapping for '\n            'non-message \"%s\"' % message_type)\n    try:\n        _ = message_type.field_by_name(python_name)\n    except KeyError:\n        raise exceptions.InvalidDataError(\n            'Field %s not recognized for type %s' % (\n                python_name, message_type))\n    field_mappings = _JSON_FIELD_MAPPINGS.setdefault(message_type, {})\n    _CheckForExistingMappings('field', message_type, python_name, json_name)\n    field_mappings[python_name] = json_name", "response": "Adds a custom wire encoding for a given message field."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetCustomJsonEnumMapping(enum_type, python_name=None, json_name=None):\n    return _FetchRemapping(enum_type, 'enum',\n                           python_name=python_name, json_name=json_name,\n                           mappings=_JSON_ENUM_MAPPINGS)", "response": "Retrieves the appropriate remapping for the given enum type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetCustomJsonFieldMapping(message_type, python_name=None, json_name=None):\n    return _FetchRemapping(message_type, 'field',\n                           python_name=python_name, json_name=json_name,\n                           mappings=_JSON_FIELD_MAPPINGS)", "response": "Retrieves the appropriate remapping for the given field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _FetchRemapping(type_name, mapping_type, python_name=None, json_name=None,\n                    mappings=None):\n    \"\"\"Common code for fetching a key or value from a remapping dict.\"\"\"\n    if python_name and json_name:\n        raise exceptions.InvalidDataError(\n            'Cannot specify both python_name and json_name '\n            'for %s remapping' % mapping_type)\n    if not (python_name or json_name):\n        raise exceptions.InvalidDataError(\n            'Must specify either python_name or json_name for %s remapping' % (\n                mapping_type,))\n    field_remappings = mappings.get(type_name, {})\n    if field_remappings:\n        if python_name:\n            return field_remappings.get(python_name)\n        elif json_name:\n            if json_name in list(field_remappings.values()):\n                return [k for k in field_remappings\n                        if field_remappings[k] == json_name][0]\n    return None", "response": "Internal function that fetches a key or value from a remapping dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate that no mappings exist for the given values.", "response": "def _CheckForExistingMappings(mapping_type, message_type,\n                              python_name, json_name):\n    \"\"\"Validate that no mappings exist for the given values.\"\"\"\n    if mapping_type == 'field':\n        getter = GetCustomJsonFieldMapping\n    elif mapping_type == 'enum':\n        getter = GetCustomJsonEnumMapping\n    remapping = getter(message_type, python_name=python_name)\n    if remapping is not None and remapping != json_name:\n        raise exceptions.InvalidDataError(\n            'Cannot add mapping for %s \"%s\", already mapped to \"%s\"' % (\n                mapping_type, python_name, remapping))\n    remapping = getter(message_type, json_name=json_name)\n    if remapping is not None and remapping != python_name:\n        raise exceptions.InvalidDataError(\n            'Cannot add mapping for %s \"%s\", already mapped to \"%s\"' % (\n                mapping_type, json_name, remapping))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the provided list - as - JsonValue to a list.", "response": "def _AsMessageList(msg):\n    \"\"\"Convert the provided list-as-JsonValue to a list.\"\"\"\n    # This really needs to live in extra_types, but extra_types needs\n    # to import this file to be able to register codecs.\n    # TODO(craigcitro): Split out a codecs module and fix this ugly\n    # import.\n    from apitools.base.py import extra_types\n\n    def _IsRepeatedJsonValue(msg):\n        \"\"\"Return True if msg is a repeated value as a JsonValue.\"\"\"\n        if isinstance(msg, extra_types.JsonArray):\n            return True\n        if isinstance(msg, extra_types.JsonValue) and msg.array_value:\n            return True\n        return False\n\n    if not _IsRepeatedJsonValue(msg):\n        raise ValueError('invalid argument to _AsMessageList')\n    if isinstance(msg, extra_types.JsonValue):\n        msg = msg.array_value\n    if isinstance(msg, extra_types.JsonArray):\n        msg = msg.entries\n    return msg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _IsMap(message, field):\n    value = message.get_assigned_value(field.name)\n    if not isinstance(value, messages.Message):\n        return False\n    try:\n        additional_properties = value.field_by_name('additionalProperties')\n    except KeyError:\n        return False\n    else:\n        return additional_properties.repeated", "response": "Returns whether the field is actually a map - type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _MapItems(message, field):\n    assert _IsMap(message, field)\n    map_message = message.get_assigned_value(field.name)\n    additional_properties = map_message.get_assigned_value(\n        'additionalProperties')\n    for kv_pair in additional_properties:\n        yield kv_pair.key, kv_pair.value", "response": "Yields the key - value pairs of the map values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding the locations of unrecognized fields within \"message\". If a sub-message is found to have unrecognized fields, that sub-message will not be searched any further. We prune the search of the sub-message because we assume it is malformed and further checks will not yield productive errors. Args: message: The Message instance to search. _edges: Internal arg for passing state. Yields: (edges_to_message, field_names): edges_to_message: List[ProtoEdge], The edges (relative to \"message\") describing the path to the sub-message where the unrecognized fields were found. field_names: List[Str], The names of the field(s) that were unrecognized in the sub-message.", "response": "def UnrecognizedFieldIter(message, _edges=()):  # pylint: disable=invalid-name\n    \"\"\"Yields the locations of unrecognized fields within \"message\".\n\n    If a sub-message is found to have unrecognized fields, that sub-message\n    will not be searched any further. We prune the search of the sub-message\n    because we assume it is malformed and further checks will not yield\n    productive errors.\n\n    Args:\n      message: The Message instance to search.\n      _edges: Internal arg for passing state.\n\n    Yields:\n      (edges_to_message, field_names):\n        edges_to_message: List[ProtoEdge], The edges (relative to \"message\")\n            describing the path to the sub-message where the unrecognized\n            fields were found.\n        field_names: List[Str], The names of the field(s) that were\n            unrecognized in the sub-message.\n    \"\"\"\n    if not isinstance(message, messages.Message):\n        # This is a primitive leaf, no errors found down this path.\n        return\n\n    field_names = message.all_unrecognized_fields()\n    if field_names:\n        # This message is malformed. Stop recursing and report it.\n        yield _edges, field_names\n        return\n\n    # Recurse through all fields in the current message.\n    for field in message.all_fields():\n        value = message.get_assigned_value(field.name)\n        if field.repeated:\n            for i, item in enumerate(value):\n                repeated_edge = ProtoEdge(EdgeType.REPEATED, field.name, i)\n                iter_ = UnrecognizedFieldIter(item, _edges + (repeated_edge,))\n                for (e, y) in iter_:\n                    yield e, y\n        elif _IsMap(message, field):\n            for key, item in _MapItems(message, field):\n                map_edge = ProtoEdge(EdgeType.MAP, field.name, key)\n                iter_ = UnrecognizedFieldIter(item, _edges + (map_edge,))\n                for (e, y) in iter_:\n                    yield e, y\n        else:\n            scalar_edge = ProtoEdge(EdgeType.SCALAR, field.name, None)\n            iter_ = UnrecognizedFieldIter(value, _edges + (scalar_edge,))\n            for (e, y) in iter_:\n                yield e, y"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecoding the given JSON value.", "response": "def decode_field(self, field, value):\n        \"\"\"Decode the given JSON value.\n\n        Args:\n          field: a messages.Field for the field we're decoding.\n          value: a python value we'd like to decode.\n\n        Returns:\n          A value suitable for assignment to field.\n        \"\"\"\n        for decoder in _GetFieldCodecs(field, 'decoder'):\n            result = decoder(field, value)\n            value = result.value\n            if result.complete:\n                return value\n        if isinstance(field, messages.MessageField):\n            field_value = self.decode_message(\n                field.message_type, json.dumps(value))\n        elif isinstance(field, messages.EnumField):\n            value = GetCustomJsonEnumMapping(\n                field.type, json_name=value) or value\n            try:\n                field_value = super(\n                    _ProtoJsonApiTools, self).decode_field(field, value)\n            except messages.DecodeError:\n                if not isinstance(value, six.string_types):\n                    raise\n                field_value = None\n        else:\n            field_value = super(\n                _ProtoJsonApiTools, self).decode_field(field, value)\n        return field_value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encode_field(self, field, value):\n        for encoder in _GetFieldCodecs(field, 'encoder'):\n            result = encoder(field, value)\n            value = result.value\n            if result.complete:\n                return value\n        if isinstance(field, messages.EnumField):\n            if field.repeated:\n                remapped_value = [GetCustomJsonEnumMapping(\n                    field.type, python_name=e.name) or e.name for e in value]\n            else:\n                remapped_value = GetCustomJsonEnumMapping(\n                    field.type, python_name=value.name)\n            if remapped_value:\n                return remapped_value\n        if (isinstance(field, messages.MessageField) and\n                not isinstance(field, message_types.DateTimeField)):\n            value = json.loads(self.encode_message(value))\n        return super(_ProtoJsonApiTools, self).encode_field(field, value)", "response": "Encode the given value as JSON."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive an iterator it returns n items.", "response": "def group_iter(iterator, n=2):\n    \"\"\" Given an iterator, it returns sub-lists made of n items.\n    (except the last that can have len < n)\n\n    \"\"\"\n\n    # Use slices instead of an iterator when we have a flat list\n    if isinstance(iterator, list):\n\n        length = len(iterator)\n        for i in range(int(math.ceil(old_div(float(length), n)))):\n            yield iterator[i * n: (i + 1) * n]\n\n    else:\n        accumulator = []\n        for item in iterator:\n            accumulator.append(item)\n            if len(accumulator) == n:\n                yield accumulator\n                accumulator = []\n\n        # Yield what's left\n        if len(accumulator) != 0:\n            yield accumulator"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef memoize_single_argument(f):\n    class memodict(dict):\n\n        def __missing__(self, key):\n            ret = self[key] = f(key)\n            return ret\n    return memodict().__getitem__", "response": "Memoization decorator for a function taking a single argument"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_class_by_path(taskpath):\n\n    return getattr(\n        importlib.import_module(\n            re.sub(\n                r\"\\.[^.]+$\",\n                \"\",\n                taskpath)),\n        re.sub(\n            r\"^.*\\.\",\n            \"\",\n            taskpath))", "response": "Given a taskpath returns the main task class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits for network service to appear AttributeNames", "response": "def wait_for_net_service(server, port, timeout=None, poll_interval=0.1):\n    \"\"\" Wait for network service to appear\n        @param timeout: in seconds, if None or 0 wait forever\n        @return: True of False, if timeout is None may return only True or\n                 throw unhandled network exception\n    \"\"\"\n    import socket\n    import errno\n\n    s = socket.socket()\n    if timeout:\n        from time import time as now\n        # time module is needed to calc timeout shared between two exceptions\n        end = now() + timeout\n\n    while True:\n        try:\n            if timeout:\n                next_timeout = end - now()\n                if next_timeout < 0:\n                    return False\n                else:\n                    s.settimeout(next_timeout)\n\n            s.connect((server, port))\n\n        except socket.timeout as err:\n            # this exception occurs only if timeout is set\n            if timeout:\n                return False\n\n        except Exception as err:\n            # catch timeout exception from underlying network library\n            # this one is different from socket.timeout\n            if not isinstance(err.args, tuple) or err.args[0] != errno.ETIMEDOUT:\n                pass  # raise\n        else:\n            s.close()\n            return True\n        time.sleep(poll_interval)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nqueue some jobs on a raw queue", "response": "def queue_raw_jobs(queue, params_list, **kwargs):\n    \"\"\" Queue some jobs on a raw queue \"\"\"\n\n    from .queue import Queue\n    queue_obj = Queue(queue)\n    queue_obj.enqueue_raw_jobs(params_list, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nqueue multiple jobs on a regular queue", "response": "def queue_jobs(main_task_path, params_list, queue=None, batch_size=1000):\n    \"\"\" Queue multiple jobs on a regular queue \"\"\"\n    if len(params_list) == 0:\n        return []\n    if queue is None:\n        task_def = context.get_current_config().get(\"tasks\", {}).get(main_task_path) or {}\n        queue = task_def.get(\"queue\", \"default\")\n\n    from .queue import Queue\n    queue_obj = Queue(queue)\n\n    if queue_obj.is_raw:\n        raise Exception(\"Can't queue regular jobs on a raw queue\")\n\n    all_ids = []\n\n    for params_group in group_iter(params_list, n=batch_size):\n\n        context.metric(\"jobs.status.queued\", len(params_group))\n\n        # Insert the job in MongoDB\n        job_ids = Job.insert([{\n            \"path\": main_task_path,\n            \"params\": params,\n            \"queue\": queue,\n            \"datequeued\": datetime.datetime.utcnow(),\n            \"status\": \"queued\"\n        } for params in params_group], w=1, return_jobs=False)\n\n        all_ids += job_ids\n\n    queue_obj.notify(len(all_ids))\n    set_queues_size({queue: len(all_ids)})\n\n    return all_ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching the current job data and possibly flag it as started.", "response": "def fetch(self, start=False, full_data=True):\n        \"\"\" Get the current job data and possibly flag it as started. \"\"\"\n\n        if self.id is None:\n            return self\n\n        if full_data is True:\n            fields = None\n        elif isinstance(full_data, dict):\n            fields = full_data\n        else:\n            fields = {\n                \"_id\": 0,\n                \"path\": 1,\n                \"params\": 1,\n                \"status\": 1,\n                \"retry_count\": 1,\n            }\n\n        if start:\n            self.datestarted = datetime.datetime.utcnow()\n            self.set_data(self.collection.find_and_modify(\n                {\n                    \"_id\": self.id,\n                    \"status\": {\"$nin\": [\"cancel\", \"abort\", \"maxretries\"]}\n                },\n                {\"$set\": {\n                    \"status\": \"started\",\n                    \"datestarted\": self.datestarted,\n                    \"worker\": self.worker.id\n                },\n                \"$unset\": {\n                    \"dateexpires\": 1 # we don't want started jobs to expire unexpectedly\n                }},\n                projection=fields)\n            )\n\n            context.metric(\"jobs.status.started\")\n\n        else:\n            self.set_data(self.collection.find_one({\n                \"_id\": self.id\n            }, projection=fields))\n\n        if self.data is None:\n            context.log.info(\n                \"Job %s not found in MongoDB or status was cancelled!\" %\n                self.id)\n\n        self.stored = True\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self):\n\n        if not self.saved and self.data and \"progress\" in self.data:\n            # TODO should we save more fields?\n            self.collection.update({\"_id\": self.id}, {\"$set\": {\n                \"progress\": self.data[\"progress\"]\n            }})\n            self.saved = True", "response": "Saves the current job metadata to MongoDB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninserting a job into MongoDB", "response": "def insert(cls, jobs_data, queue=None, statuses_no_storage=None, return_jobs=True, w=None, j=None):\n        \"\"\" Insert a job into MongoDB \"\"\"\n\n        now = datetime.datetime.utcnow()\n        for data in jobs_data:\n            if data[\"status\"] == \"started\":\n                data[\"datestarted\"] = now\n\n        no_storage = (statuses_no_storage is not None) and (\"started\" in statuses_no_storage)\n        if no_storage and return_jobs:\n            for data in jobs_data:\n                data[\"_id\"] = ObjectId()  # Give the job a temporary ID\n        else:\n            inserted = context.connections.mongodb_jobs.mrq_jobs.insert(\n                jobs_data,\n                manipulate=True,\n                w=w,\n                j=j\n            )\n\n        if return_jobs:\n            jobs = []\n            for data in jobs_data:\n                job = cls(data[\"_id\"], queue=queue)\n                job.set_data(data)\n                job.statuses_no_storage = statuses_no_storage\n                job.stored = (not no_storage)\n                if data[\"status\"] == \"started\":\n                    job.datestarted = data[\"datestarted\"]\n                jobs.append(job)\n\n            return jobs\n        else:\n            return inserted"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _attach_original_exception(self, exc):\n\n        original_exception = sys.exc_info()\n        if original_exception[0] is not None:\n            exc.original_exception = original_exception", "response": "Attaches the original exception to the exception object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef retry(self, queue=None, delay=None, max_retries=None):\n\n        max_retries = max_retries\n        if max_retries is None:\n            max_retries = self.max_retries\n\n        if self.data.get(\"retry_count\", 0) >= max_retries:\n            raise MaxRetriesInterrupt()\n\n        exc = RetryInterrupt()\n\n        exc.queue = queue or self.queue or self.data.get(\"queue\") or \"default\"\n        exc.retry_count = self.data.get(\"retry_count\", 0) + 1\n        exc.delay = delay\n        if exc.delay is None:\n            exc.delay = self.retry_delay\n\n        self._attach_original_exception(exc)\n\n        raise exc", "response": "Interrupts the current job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perform(self):\n\n        if self.data is None:\n            return\n\n        context.log.debug(\"Starting %s(%s)\" % (self.data[\"path\"], self.data[\"params\"]))\n        task_class = load_class_by_path(self.data[\"path\"])\n\n        self.task = task_class()\n\n        self.task.is_main_task = True\n\n        if not self.task.max_concurrency:\n\n            result = self.task.run_wrapped(self.data[\"params\"])\n\n        else:\n\n            if self.task.max_concurrency > 1:\n                raise NotImplementedError()\n\n            lock = None\n            try:\n\n                # TODO: implement a semaphore\n                lock = context.connections.redis.lock(self.redis_max_concurrency_key, timeout=self.timeout + 5)\n                if not lock.acquire(blocking=True, blocking_timeout=0):\n                    raise MaxConcurrencyInterrupt()\n\n                result = self.task.run_wrapped(self.data[\"params\"])\n\n            finally:\n                try:\n                    if lock:\n                        lock.release()\n                except LockError:\n                    pass\n\n        self.save_success(result)\n\n        if context.get_current_config().get(\"trace_greenlets\"):\n\n            # TODO: this is not the exact greenlet_time measurement because it doesn't\n            # take into account the last switch's time. This is why we force a last switch.\n            # This does cause a performance overhead. Instead, we should print the\n            # last timing directly from the trace() function in context?\n\n            # pylint: disable=protected-access\n\n            gevent.sleep(0)\n            current_greenlet = gevent.getcurrent()\n            t = (datetime.datetime.utcnow() - self.datestarted).total_seconds()\n\n            context.log.debug(\n                \"Job %s success: %0.6fs total, %0.6fs in greenlet, %s switches\" %\n                (self.id,\n                 t,\n                 current_greenlet._trace_time,\n                 current_greenlet._trace_switches - 1)\n            )\n\n        else:\n            context.log.debug(\"Job %s success: %0.6fs total\" % (\n                self.id, (datetime.datetime.utcnow() -\n                          self.datestarted).total_seconds()\n            ))\n\n        return result", "response": "Loads and starts the main task for this job and saves the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwait for this job to finish.", "response": "def wait(self, poll_interval=1, timeout=None, full_data=False):\n        \"\"\" Wait for this job to finish. \"\"\"\n\n        end_time = None\n        if timeout:\n            end_time = time.time() + timeout\n\n        while end_time is None or time.time() < end_time:\n\n            job_data = self.collection.find_one({\n                \"_id\": ObjectId(self.id),\n                \"status\": {\"$nin\": [\"started\", \"queued\"]}\n            }, projection=({\n                \"_id\": 0,\n                \"result\": 1,\n                \"status\": 1\n            } if not full_data else None))\n\n            if job_data:\n                return job_data\n\n            time.sleep(poll_interval)\n        raise Exception(\"Waited for job result for %s seconds, timeout.\" % timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef kill(self, block=False, reason=\"unknown\"):\n\n        current_greenletid = id(gevent.getcurrent())\n\n        trace = \"Job killed: %s\" % reason\n        for greenlet, job in context._GLOBAL_CONTEXT[\"greenlets\"].values():\n            greenletid = id(greenlet)\n            if job and job.id == self.id and greenletid != current_greenletid:\n                greenlet.kill(block=block)\n                trace += \"\\n\\n--- Greenlet %s ---\\n\" % greenletid\n                trace += \"\".join(traceback.format_stack(greenlet.gr_frame))\n            context._GLOBAL_CONTEXT[\"greenlets\"].pop(greenletid, None)\n\n        if reason == \"timeout\" and self.data[\"status\"] != \"timeout\":\n            updates = {\n                \"exceptiontype\": \"TimeoutInterrupt\",\n                \"traceback\": trace\n            }\n            self._save_status(\"timeout\", updates=updates, exception=False)", "response": "Forcefully kill all greenlets associated with this job."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate or add a new traceback history.", "response": "def _save_traceback_history(self, status, trace, job_exc):\n        \"\"\" Create traceback history or add a new traceback to history. \"\"\"\n        failure_date = datetime.datetime.utcnow()\n\n        new_history = {\n            \"date\": failure_date,\n            \"status\": status,\n            \"exceptiontype\": job_exc.__name__\n        }\n\n        traces = trace.split(\"---- Original exception: -----\")\n        if len(traces) > 1:\n            new_history[\"original_traceback\"] = traces[1]\n        worker = context.get_current_worker()\n        if worker:\n            new_history[\"worker\"] = worker.id\n        new_history[\"traceback\"] = traces[0]\n        self.collection.update({\n            \"_id\": self.id\n        }, {\"$push\": {\"traceback_history\": new_history}})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove all caches that are not used by the current thread.", "response": "def trace_memory_clean_caches(self):\n        \"\"\" Avoid polluting results with some builtin python caches \"\"\"\n\n        urllib.parse.clear_cache()\n        re.purge()\n        linecache.clearcache()\n        copyreg.clear_extension_cache()\n\n        if hasattr(fnmatch, \"purge\"):\n            fnmatch.purge()  # pylint: disable=no-member\n        elif hasattr(fnmatch, \"_purge\"):\n            fnmatch._purge()  # pylint: disable=no-member\n\n        if hasattr(encodings, \"_cache\") and len(encodings._cache) > 0:\n            encodings._cache = {}\n\n        for handler in context.log.handlers:\n            handler.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef trace_memory_start(self):\n\n        self.trace_memory_clean_caches()\n\n        objgraph.show_growth(limit=30)\n\n        gc.collect()\n        self._memory_start = self.worker.get_memory()[\"total\"]", "response": "Starts measuring memory consumption"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trace_memory_stop(self):\n\n        self.trace_memory_clean_caches()\n\n        objgraph.show_growth(limit=30)\n\n        trace_type = context.get_current_config()[\"trace_memory_type\"]\n        if trace_type:\n\n            filename = '%s/%s-%s.png' % (\n                context.get_current_config()[\"trace_memory_output_dir\"],\n                trace_type,\n                self.id)\n\n            chain = objgraph.find_backref_chain(\n                random.choice(\n                    objgraph.by_type(trace_type)\n                ),\n                objgraph.is_proper_module\n            )\n            objgraph.show_chain(chain, filename=filename)\n            del filename\n            del chain\n\n        gc.collect()\n        self._memory_stop = self.worker.get_memory()[\"total\"]\n\n        diff = self._memory_stop - self._memory_start\n\n        context.log.debug(\"Memory diff for job %s : %s\" % (self.id, diff))\n\n        # We need to update it later than the results, we need them off memory\n        # already.\n        self.collection.update(\n            {\"_id\": self.id},\n            {\"$set\": {\n                \"memory_diff\": diff\n            }},\n            w=1\n        )", "response": "Stops measuring memory consumption"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all known subqueues", "response": "def get_known_subqueues(self):\n        \"\"\" Returns all known subqueues \"\"\"\n\n        all_queues_from_mongodb = Queue.all_known(sources=(\"jobs\", ))\n\n        idprefix = self.id\n        if not idprefix.endswith(\"/\"):\n            idprefix += \"/\"\n\n        return {q for q in all_queues_from_mongodb if q.startswith(idprefix)}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef size(self):\n\n        if self.id.endswith(\"/\"):\n            subqueues = self.get_known_subqueues()\n            if len(subqueues) == 0:\n                return 0\n            else:\n                with context.connections.redis.pipeline(transaction=False) as pipe:\n                    for subqueue in subqueues:\n                        pipe.get(\"queuesize:%s\" % subqueue)\n                    return [int(size or 0) for size in pipe.execute()]\n        else:\n            return int(context.connections.redis.get(\"queuesize:%s\" % self.id) or 0)", "response": "Returns the total number of queued jobs on the queue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of job ids on a queue", "response": "def list_job_ids(self, skip=0, limit=20):\n        \"\"\" Returns a list of job ids on a queue \"\"\"\n\n        return [str(x[\"_id\"]) for x in self.collection.find(\n            {\"status\": \"queued\"},\n            sort=[(\"_id\", -1 if self.is_reverse else 1)],\n            projection={\"_id\": 1})\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dequeue_jobs(self, max_jobs=1, job_class=None, worker=None):\n\n        if job_class is None:\n            from .job import Job\n            job_class = Job\n\n        count = 0\n\n\n\n        # TODO: remove _id sort after full migration to datequeued\n        sort_order = [(\"datequeued\", -1 if self.is_reverse else 1), (\"_id\", -1 if self.is_reverse else 1)]\n\n        # MongoDB optimization: with many jobs it's faster to fetch the IDs first and do the atomic update second\n        # Some jobs may have been stolen by another worker in the meantime but it's a balance (should we over-fetch?)\n        # job_ids = None\n        # if max_jobs > 5:\n        #     job_ids = [x[\"_id\"] for x in self.collection.find(\n        #         self.base_dequeue_query,\n        #         limit=max_jobs,\n        #         sort=sort_order,\n        #         projection={\"_id\": 1}\n        #     )]\n\n        #     if len(job_ids) == 0:\n        #         return\n\n        for i in range(max_jobs):  # if job_ids is None else len(job_ids)):\n\n            # if job_ids is not None:\n            #     query = {\n            #         \"status\": \"queued\",\n            #         \"_id\": job_ids[i]\n            #     }\n            #     sort_order = None\n            # else:\n            query = self.base_dequeue_query\n\n            job_data = self.collection.find_one_and_update(\n                query,\n                {\"$set\": {\n                    \"status\": \"started\",\n                    \"datestarted\": datetime.datetime.utcnow(),\n                    \"worker\": worker.id if worker else None\n                }, \"$unset\": {\n                    \"dateexpires\": 1 # we don't want started jobs to expire unexpectedly\n                }},\n                sort=sort_order,\n                return_document=ReturnDocument.AFTER,\n                projection={\n                    \"_id\": 1,\n                    \"path\": 1,\n                    \"params\": 1,\n                    \"status\": 1,\n                    \"retry_count\": 1,\n                    \"queue\": 1,\n                    \"datequeued\": 1\n                }\n            )\n\n            if not job_data:\n                break\n\n            if worker:\n                worker.status = \"spawn\"\n\n            count += 1\n            context.metric(\"queues.%s.dequeued\" % job_data[\"queue\"], 1)\n\n            job = job_class(job_data[\"_id\"], queue=self.id, start=False)\n            job.set_data(job_data)\n            job.datestarted = datetime.datetime.utcnow()\n\n            context.metric(\"jobs.status.started\")\n\n            yield job\n\n        context.metric(\"queues.all.dequeued\", count)", "response": "Fetch a maximum of max_jobs jobs from this queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jsonify(*args, **kwargs):\n    return Response(\n        json.dumps(\n            dict(\n                *args,\n                **kwargs),\n            cls=MongoJSONEncoder),\n        mimetype='application/json')", "response": "jsonify with support for MongoDB ObjectId\nicense"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a username and password combination is valid.", "response": "def check_auth(username, pwd):\n    \"\"\"This function is called to check if a username /\n    password combination is valid.\n    \"\"\"\n    cfg = get_current_config()\n    return username == cfg[\"dashboard_httpauth\"].split(\n        \":\")[0] and pwd == cfg[\"dashboard_httpauth\"].split(\":\")[1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the number of jobs to dequeue and time of the last known queue & subqueue", "response": "def queuestats(self):\n        \"\"\" Compute ETAs for every known queue & subqueue \"\"\"\n\n        start_time = time.time()\n        log.debug(\"Starting queue stats...\")\n\n        # Fetch all known queues\n        queues = [Queue(q) for q in Queue.all_known()]\n\n        new_queues = {queue.id for queue in queues}\n        old_queues = set(self.queue_etas.keys())\n\n        for deleted_queue in old_queues.difference(new_queues):\n            self.queue_etas.pop(deleted_queue)\n\n        t = time.time()\n        stats = {}\n\n        for queue in queues:\n            cnt = queue.count_jobs_to_dequeue()\n            eta = self.queue_etas[queue.id].next(cnt, t=t)\n\n            # Number of jobs to dequeue, ETA, Time of stats\n            stats[queue.id] = \"%d %s %d\" % (cnt, eta if eta is not None else \"N\", int(t))\n\n        with connections.redis.pipeline(transaction=True) as pipe:\n            if random.randint(0, 100) == 0 or len(stats) == 0:\n                pipe.delete(self.redis_queuestats_key)\n            if len(stats) > 0:\n                pipe.hmset(self.redis_queuestats_key, stats)\n            pipe.execute()\n\n        log.debug(\"... done queue stats in %0.4fs\" % (time.time() - start_time))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_orchestrate(self, group):\n\n        log.debug(\"Starting orchestration run for worker group %s\" % group[\"_id\"])\n\n        agents = self.fetch_worker_group_agents(group)\n\n        # Evaluate what workers are currently, rightfully there. They won't be touched.\n        for agent in agents:\n            desired_workers = self.get_desired_workers_for_agent(group, agent)\n            agent[\"new_desired_workers\"] = []\n            agent[\"new_desired_workers\"] = desired_workers\n\n        for agent in agents:\n            if sorted(agent[\"new_desired_workers\"]) != sorted(agent.get(\"desired_workers\", [])):\n                connections.mongodb_jobs.mrq_agents.update_one({\"_id\": agent[\"_id\"]}, {\"$set\": {\n                    \"desired_workers\": agent[\"new_desired_workers\"]\n                }})\n\n        # Remember the date of the last successful orchestration (will be reported)\n        self.dateorchestrated = datetime.datetime.utcnow()\n\n        log.debug(\"Orchestration finished.\")", "response": "Manage the desired workers of all the agents in the given group."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a Gevent pool and runs a map function in a random greenlet of the specified size.", "response": "def subpool_map(pool_size, func, iterable):\n    \"\"\" Starts a Gevent pool and run a map. Takes care of setting current_job and cleaning up. \"\"\"\n\n    from .context import get_current_job, set_current_job, log\n\n    if not pool_size:\n        return [func(*args) for args in iterable]\n\n    counter = itertools_count()\n\n    current_job = get_current_job()\n\n    def inner_func(*args):\n        \"\"\" As each call to 'func' will be done in a random greenlet of the subpool, we need to\n            register their IDs with set_current_job() to make get_current_job() calls work properly\n            inside 'func'.\n        \"\"\"\n        next(counter)\n        if current_job:\n            set_current_job(current_job)\n\n        try:\n          ret = func(*args)\n        except Exception as exc:\n          trace = traceback.format_exc()\n          exc.subpool_traceback = trace\n          raise\n\n        if current_job:\n            set_current_job(None)\n        return ret\n\n    def inner_iterable():\n        \"\"\" This will be called inside the pool's main greenlet, which ID also needs to be registered \"\"\"\n        if current_job:\n            set_current_job(current_job)\n\n        for x in iterable:\n            yield x\n\n        if current_job:\n            set_current_job(None)\n\n    start_time = time.time()\n    pool = gevent.pool.Pool(size=pool_size)\n    ret = pool.map(inner_func, inner_iterable())\n    pool.join(raise_error=True)\n    total_time = time.time() - start_time\n\n    log.debug(\"SubPool ran %s greenlets in %0.6fs\" % (counter, total_time))\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subpool_imap(pool_size, func, iterable, flatten=False, unordered=False, buffer_size=None):\n\n  from .context import get_current_job, set_current_job, log\n\n  if not pool_size:\n    for args in iterable:\n      yield func(*args)\n\n  counter = itertools_count()\n\n  current_job = get_current_job()\n\n  def inner_func(*args):\n    \"\"\" As each call to 'func' will be done in a random greenlet of the subpool, we need to\n        register their IDs with set_current_job() to make get_current_job() calls work properly\n        inside 'func'.\n    \"\"\"\n    next(counter)\n    if current_job:\n      set_current_job(current_job)\n\n    try:\n      ret = func(*args)\n    except Exception as exc:\n      trace = traceback.format_exc()\n      exc.subpool_traceback = trace\n      raise\n\n    if current_job:\n      set_current_job(None)\n    return ret\n\n  def inner_iterable():\n    \"\"\" This will be called inside the pool's main greenlet, which ID also needs to be registered \"\"\"\n    if current_job:\n      set_current_job(current_job)\n\n    for x in iterable:\n      yield x\n\n    if current_job:\n      set_current_job(None)\n\n  start_time = time.time()\n  pool = gevent.pool.Pool(size=pool_size)\n\n  if unordered:\n    iterator = pool.imap_unordered(inner_func, inner_iterable(), maxsize=buffer_size or pool_size)\n  else:\n    iterator = pool.imap(inner_func, inner_iterable())\n\n  for x in iterator:\n    if flatten:\n      for y in x:\n        yield y\n    else:\n      yield x\n\n  pool.join(raise_error=True)\n  total_time = time.time() - start_time\n\n  log.debug(\"SubPool ran %s greenlets in %0.6fs\" % (counter, total_time))", "response": "Generator version of subpool_map."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _hash_task(task):\n\n    params = task.get(\"params\")\n    if params:\n        params = json.dumps(sorted(list(task[\"params\"].items()), key=lambda x: x[0]))  # pylint: disable=no-member\n\n    full = [str(task.get(x)) for x in [\"path\", \"interval\", \"dailytime\", \"weekday\", \"monthday\", \"queue\"]]\n\n    full.extend([str(params)])\n    return \" \".join(full)", "response": "Returns a unique hash for identify a task and its params"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that the scheduler config is valid.", "response": "def check_config_integrity(self):\n        \"\"\" Make sure the scheduler config is valid \"\"\"\n        tasks_by_hash = {_hash_task(t): t for t in self.config_tasks}\n\n        if len(tasks_by_hash) != len(self.config_tasks):\n            raise Exception(\"Fatal error: there was a hash duplicate in the scheduled tasks config.\")\n\n        for h, task in tasks_by_hash.items():\n            if task.get(\"monthday\") and not task.get(\"dailytime\"):\n                raise Exception(\"Fatal error: you can't schedule a task with 'monthday' and without 'dailytime' (%s)\" % h)\n            if task.get(\"weekday\") and not task.get(\"dailytime\"):\n                raise Exception(\"Fatal error: you can't schedule a task with 'weekday' and without 'dailytime' (%s)\" % h)\n\n            if not task.get(\"monthday\") and not task.get(\"weekday\") and not task.get(\"dailytime\") and not task.get(\"interval\"):\n                raise Exception(\"Fatal error: scheduler must be specified one of monthday,weekday,dailytime,interval. (%s)\" % h)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sync_config_tasks(self):\n\n        tasks_by_hash = {_hash_task(t): t for t in self.config_tasks}\n\n        for task in self.all_tasks:\n            if tasks_by_hash.get(task[\"hash\"]):\n                del tasks_by_hash[task[\"hash\"]]\n            else:\n                self.collection.remove({\"_id\": task[\"_id\"]})\n                log.debug(\"Scheduler: deleted %s\" % task[\"hash\"])\n\n        # What remains are the new ones to be inserted\n        for h, task in tasks_by_hash.items():\n            task[\"hash\"] = h\n            task[\"datelastqueued\"] = datetime.datetime.fromtimestamp(0)\n            if task.get(\"dailytime\"):\n                # Because MongoDB can store datetimes but not times,\n                # we add today's date to the dailytime.\n                # The date part will be discarded in check()\n                task[\"dailytime\"] = datetime.datetime.combine(\n                    datetime.datetime.utcnow(), task[\"dailytime\"])\n                task[\"interval\"] = 3600 * 24\n\n                # Avoid to queue task in check() if today dailytime is already passed\n                if datetime.datetime.utcnow().time() > task[\"dailytime\"].time():\n                    task[\"datelastqueued\"] = datetime.datetime.utcnow()\n\n            self.collection.find_one_and_update({\"hash\": task[\"hash\"]}, {\"$set\": task}, upsert=True)\n            log.debug(\"Scheduler: added %s\" % task[\"hash\"])", "response": "Syncs the list of tasks in the config file with the current configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an integer with the number of available actions for the current period in seconds. If zero the number of available actions for the current period in seconds is reached.", "response": "def ratelimit(key, limit, per=1, redis=None):\n    \"\"\" Returns an integer with the number of available actions for the\n    current period in seconds. If zero, rate was already reached. \"\"\"\n\n    if redis is None:\n        redis = connections.redis\n\n    # http://redis.io/commands/INCR\n    now = int(time.time())\n\n    k = \"ratelimit:%s:%s\" % (key, now // per)\n\n    with redis.pipeline(transaction=True) as pipeline:\n        pipeline.incr(k, 1)\n        pipeline.expire(k, per + 10)\n        value = pipeline.execute()\n\n    current = int(value[0]) - 1\n\n    if current >= limit:\n        return 0\n    else:\n        return limit - current"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef patch_pymongo(config):\n\n    # Nothing to change!\n    if not config[\"print_mongodb\"] and not config[\"trace_io\"]:\n        return\n\n    from termcolor import cprint\n\n    # Print because we are very early and log() may not be ready yet.\n    cprint(\"Monkey-patching MongoDB methods...\", \"white\")\n\n    def gen_monkey_patch(base_object, method):\n        base_method = getattr(base_object, method)\n\n        def mrq_monkey_patched(self, *args, **kwargs):\n\n            if config[\"trace_io\"]:\n                comment = \"mrq\"\n\n                worker = get_current_worker()\n                job = get_current_job()\n                if job:\n                    job.set_current_io({\n                        \"type\": \"mongodb.%s\" % method,\n                        \"data\": {\n                            \"collection\": self.full_name\n                        }\n                        # Perf issue? All MongoDB data will get jsonified!\n                        # \"data\": json.dumps(args)[0:300]\n                    })\n                    comment = {\"job\": job.id}\n                elif worker:\n                    comment = {\"worker\": worker.id}\n\n                # Tag potentially expensive queries with their job id for easier debugging\n                if method in [\"find\", \"find_and_modify\", \"count\", \"update_many\", \"update\", \"delete_many\"]:\n                    if len(args) > 0 and isinstance(args[0], dict) and \"$comment\" not in args[0]:\n                        query = copy.copy(args[0])\n                        query[\"$comment\"] = comment\n                        args = (query, ) + args[1:]\n\n            if config[\"print_mongodb\"]:\n                if self.full_name in config.get(\"print_mongodb_hidden_collections\", []):\n                    cprint(\"[MONGO] %s.%s%s %s\" % (\n                        self.full_name, method, \"-hidden-\", kwargs\n                    ), \"magenta\")\n                else:\n                    cprint(\"[MONGO] %s.%s%s %s\" % (\n                        self.full_name, method, args, kwargs\n                    ), \"magenta\")\n\n            if config.get(\"mongodb_pre_hook\"):\n                config.get(\"mongodb_pre_hook\")({\n                    \"collection\": self.full_name,\n                    \"method\": method,\n                    \"args\": args,\n                    \"kwargs\": kwargs,\n                    \"client\": self.database.client,\n                    \"job\": job\n                })\n\n            start_time = time.time()\n            ret = False\n            try:\n                ret = base_method(self, *args, **kwargs)\n            finally:\n                stop_time = time.time()\n\n                job = None\n\n                if config[\"trace_io\"]:\n                    job = get_current_job()\n                    if job:\n                        job.set_current_io(None)\n\n                if config.get(\"mongodb_post_hook\"):\n                    config.get(\"mongodb_post_hook\")({\n                        \"collection\": self.full_name,\n                        \"method\": method,\n                        \"args\": args,\n                        \"kwargs\": kwargs,\n                        \"client\": self.database.client,\n                        \"job\": job,\n                        \"result\": ret,\n                        \"time\": stop_time - start_time\n                    })\n\n            return ret\n\n        # Needed to avoid breaking mongokit\n        mrq_monkey_patched.__doc__ = method.__doc__\n\n        return mrq_monkey_patched\n\n    from pymongo.collection import Collection\n    pymongo_method_whitelist = (\n        \"bulk_write\",\n        \"find\", \"find_one_and_delete\", \"find_one_and_replace\", \"find_one_and_update\",\n        \"update\", \"update_one\", \"update_many\",\n        \"drop\",\n        \"count\",\n        \"save\",\n        \"insert\", \"insert_one\", \"insert_many\",\n        \"replace_one\",\n        \"remove\", \"delete_one\", \"delete_many\",\n        \"find_and_modify\",\n        \"parallel_scan\",\n        \"options\",\n        \"aggregate\",\n        \"group\", \"distinct\",\n        \"rename\",\n        \"map_reduce\", \"inline_map_reduce\",\n        \"create_indexes\", \"create_index\", \"ensure_index\", \"drop_index\", \"reindex\", \"list_indexes\"\n    )\n    for method in pymongo_method_whitelist:\n        if hasattr(Collection, method) and getattr(Collection, method).__name__ != \"mrq_monkey_patched\":\n            setattr(Collection, method, gen_monkey_patch(Collection, method))", "response": "Monkey - patch pymongo s methods to add some logging"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npatch the network latency to allow for a given number of seconds.", "response": "def patch_network_latency(seconds=0.01):\n    \"\"\" Add random latency to all I/O operations \"\"\"\n\n    # Accept float(0.1), \"0.1\", \"0.1-0.2\"\n    def sleep():\n        if isinstance(seconds, float):\n            time.sleep(seconds)\n        elif isinstance(seconds, basestring):\n            # pylint: disable=maybe-no-member\n            if \"-\" in seconds:\n                time.sleep(random.uniform(\n                    float(seconds.split(\"-\")[0]),\n                    float(seconds.split(\"-\")[1])\n                ))\n            else:\n                time.sleep(float(seconds))\n\n    def _patched_method(old_method, *args, **kwargs):\n        sleep()\n        return old_method(*args, **kwargs)\n\n    socket_methods = [\n        \"send\", \"sendall\", \"sendto\", \"recv\", \"recvfrom\", \"recvfrom_into\", \"recv_into\",\n        \"connect\", \"connect_ex\", \"close\"\n    ]\n\n    from socket import socket as _socketmodule\n    from gevent.socket import socket as _geventmodule\n    from gevent.ssl import SSLSocket as _sslmodule   # pylint: disable=no-name-in-module\n\n    for method in socket_methods:\n        patch_method(_socketmodule, method, _patched_method)\n        patch_method(_geventmodule, method, _patched_method)\n        patch_method(_sslmodule, method, _patched_method)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npatches httplib. HTTPConnection class to use urllib2 or urllib3 requests.", "response": "def patch_io_httplib(config):\n    \"\"\" Patch the base httplib.HTTPConnection class, which is used in most HTTP libraries\n        like urllib2 or urllib3/requests. \"\"\"\n\n    # pylint: disable=import-error\n\n    def start(method, url):\n        job = get_current_job()\n        if job:\n            job.set_current_io({\n                \"type\": \"http.%s\" % method.lower(),\n                \"data\": {\n                    \"url\": url\n                }\n            })\n\n    def stop():\n        job = get_current_job()\n        if job:\n            job.set_current_io(None)\n\n    class mrq_wrapped_socket(object):\n        \"\"\" Socket-like object that keeps track of 'trace_args' and wraps our monitoring code\n            around blocking I/O calls. \"\"\"\n\n        def __init__(self, obj, parent_connection):\n            self._obj = obj\n            self._parent_connection = parent_connection\n\n            def _make_patched_method(method):\n                def _patched_method(*args, **kwargs):\n\n                    # In the case of HTTPS, we may connect() before having called conn.request()\n                    # For requests/urllib3, we may need to plug ourselves at the\n                    # connectionpool.urlopen level\n                    if not hasattr(self._parent_connection, \"_traced_args\"):\n                        return getattr(self._obj, method)(*args, **kwargs)\n\n                    start(*self._parent_connection._traced_args)  # pylint: disable=protected-access\n                    try:\n                        data = getattr(self._obj, method)(*args, **kwargs)\n                    finally:\n                        stop()\n                    return data\n                return _patched_method\n\n            # Replace socket methods with instrumented ones\n            for method in [\n\n              # socket\n              \"send\", \"sendall\", \"sendto\", \"recv\", \"recvfrom\", \"recvfrom_into\", \"recv_into\",\n              \"connect\", \"connect_ex\", \"close\",\n\n              # fileobject\n              \"read\", \"readline\", \"write\", \"writelines\", \"seek\"\n            ]:\n                setattr(self, method, _make_patched_method(method))\n\n        # Forward all other calls/attributes to the base socket\n        def __getattr__(self, attr):\n            # cprint(attr, \"green\")\n            return getattr(self._obj, attr)\n\n        def makefile(self, *args, **kwargs):\n            newsock = self._obj.makefile(*args, **kwargs)\n            return mrq_wrapped_socket(newsock, self._parent_connection)\n\n    def request(old_method, self, method, url, body=None, headers=None, *args, **kwargs):\n\n        if headers is None:\n            headers = {}\n\n        # This is for proxy support - TODO show that in dashboard?\n        if re.search(r\"^http(s?)\\:\\/\\/\", url):\n            report_url = url\n        else:\n            protocol = \"http\"\n            if hasattr(self, \"key_file\"):\n                protocol = \"https\"\n\n            report_url = \"%s://%s%s%s\" % (\n                protocol,\n                self.host,\n                (\":%s\" % self.port) if self.port != 80 else \"\",\n                url\n            )\n\n        self._traced_args = (method, report_url)  # pylint: disable=protected-access\n        res = old_method(self, method, url, body=body, headers=headers)\n        return res\n\n    def connect(old_method, self, *args, **kwargs):\n\n        # In the case of HTTPS, we may connect() before having called conn.request()\n        # For requests/urllib3, we may need to plug ourselves at the connectionpool.urlopen level\n        if not hasattr(self, \"_traced_args\"):\n            ret = old_method(self, *args, **kwargs)\n        else:\n            start(*self._traced_args)  # pylint: disable=protected-access\n            try:\n                ret = old_method(self, *args, **kwargs)\n            finally:\n                stop()\n        self.sock = mrq_wrapped_socket(self.sock, self)\n\n        return ret\n\n    from http.client import HTTPConnection, HTTPSConnection\n\n    patch_method(HTTPConnection, \"request\", request)\n    patch_method(HTTPConnection, \"connect\", connect)\n    patch_method(HTTPSConnection, \"connect\", connect)\n\n    # Try to patch requests & urllib3 as they are very popular python modules.\n    try:\n        from requests.packages.urllib3.connection import (\n            HTTPConnection,\n            UnverifiedHTTPSConnection,\n            VerifiedHTTPSConnection\n        )\n\n        patch_method(HTTPConnection, \"connect\", connect)\n        patch_method(UnverifiedHTTPSConnection, \"connect\", connect)\n        patch_method(VerifiedHTTPSConnection, \"connect\", connect)\n\n    except ImportError:\n        pass\n\n    try:\n        from urllib3.connection import (\n            HTTPConnection,\n            UnverifiedHTTPSConnection,\n            VerifiedHTTPSConnection\n        )\n\n        patch_method(HTTPConnection, \"connect\", connect)\n        patch_method(UnverifiedHTTPSConnection, \"connect\", connect)\n        patch_method(VerifiedHTTPSConnection, \"connect\", connect)\n\n    except ImportError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef greenlet_report(self):\n\n        self.report_worker(w=1)\n        while True:\n            try:\n                self.report_worker()\n            except Exception as e:  # pylint: disable=broad-except\n                self.log.error(\"When reporting: %s\" % e)\n            finally:\n                time.sleep(self.config[\"report_interval\"])", "response": "This greenlet runs in background to update the current status of the current node in MongoDB every N seconds."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef greenlet_logs(self):\n\n        while True:\n            try:\n                self.flush_logs()\n            except Exception as e:  # pylint: disable=broad-except\n                self.log.error(\"When flushing logs: %s\" % e)\n            finally:\n                time.sleep(self.config[\"report_interval\"])", "response": "This greenlet will update the current log records in MongoDB every 10 seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the list of currently known queues and subqueues", "response": "def refresh_queues(self, fatal=False):\n        \"\"\" Updates the list of currently known queues and subqueues \"\"\"\n\n        try:\n            queues = []\n            prefixes = [q for q in self.config[\"queues\"] if q.endswith(\"/\")]\n            known_subqueues = Queue.all_known(prefixes=prefixes)\n\n            for q in self.config[\"queues\"]:\n                queues.append(Queue(q))\n                if q.endswith(\"/\"):\n                    for subqueue in known_subqueues:\n                        if subqueue.startswith(q):\n                            queues.append(Queue(subqueue))\n\n            self.queues = queues\n\n        except Exception as e:  # pylint: disable=broad-except\n            self.log.error(\"When refreshing subqueues: %s\", e)\n            if fatal:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_worker_report(self, with_memory=False):\n\n        greenlets = []\n        for greenlet in list(self.gevent_pool):\n            g = {}\n            short_stack = []\n            stack = traceback.format_stack(greenlet.gr_frame)\n            for s in stack[1:]:\n                if \"/gevent/hub.py\" in s:\n                    break\n                short_stack.append(s)\n            g[\"stack\"] = short_stack\n\n            job = get_current_job(id(greenlet))\n            if job:\n                job.save()\n                if job.data:\n                    g[\"path\"] = job.data[\"path\"]\n                g[\"datestarted\"] = job.datestarted\n                g[\"id\"] = str(job.id)\n                g[\"time\"] = getattr(greenlet, \"_trace_time\", 0)\n                g[\"switches\"] = getattr(greenlet, \"_trace_switches\", None)\n\n                # pylint: disable=protected-access\n                if job._current_io is not None:\n                    g[\"io\"] = job._current_io\n\n            greenlets.append(g)\n\n        # When faking network latency, all sockets are affected, including OS ones, but\n        # we still want reliable reports so this is disabled.\n        if (not with_memory) or (self.config[\"add_network_latency\"] != \"0\" and self.config[\"add_network_latency\"]):\n            cpu = {\n                \"user\": 0,\n                \"system\": 0,\n                \"percent\": 0\n            }\n            mem = {\"rss\": 0, \"swap\": 0, \"total\": 0}\n        else:\n            cpu_times = self.process.cpu_times()\n            cpu = {\n                \"user\": cpu_times.user,\n                \"system\": cpu_times.system,\n                \"percent\": self.process.cpu_percent(0)\n            }\n            mem = self.get_memory()\n\n        # Avoid sharing passwords or sensitive config!\n        whitelisted_config = [\n            \"max_jobs\",\n            \"max_memory\"\n            \"greenlets\",\n            \"processes\",\n            \"queues\",\n            \"dequeue_strategy\",\n            \"scheduler\",\n            \"name\",\n            \"local_ip\",\n            \"external_ip\",\n            \"agent_id\",\n            \"worker_group\"\n        ]\n\n        io = None\n        if self._traced_io:\n            io = {}\n            for k, v in iteritems(self._traced_io):\n                if k == \"total\":\n                    io[k] = v\n                else:\n                    io[k] = sorted(list(v.items()), reverse=True, key=lambda x: x[1])\n\n        used_pool_slots = len(self.gevent_pool)\n        used_avg = self.pool_usage_average.next(used_pool_slots)\n\n        return {\n            \"status\": self.status,\n            \"config\": {k: v for k, v in iteritems(self.config) if k in whitelisted_config},\n            \"done_jobs\": self.done_jobs,\n            \"usage_avg\": used_avg / self.pool_size,\n            \"datestarted\": self.datestarted,\n            \"datereported\": datetime.datetime.utcnow(),\n            \"name\": self.name,\n            \"io\": io,\n            \"_id\": str(self.id),\n            \"process\": {\n                \"pid\": self.process.pid,\n                \"cpu\": cpu,\n                \"mem\": mem\n                # https://code.google.com/p/psutil/wiki/Documentation\n                # get_open_files\n                # get_connections\n                # get_num_ctx_switches\n                # get_num_fds\n                # get_io_counters\n                # get_nice\n            },\n            \"jobs\": greenlets\n        }", "response": "Returns a dict containing all the data we can about the current status of the worker and its jobs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef greenlet_admin(self):\n\n        if self.config[\"processes\"] > 1:\n            self.log.debug(\n                \"Admin server disabled because of multiple processes.\")\n            return\n\n        class Devnull(object):\n            def write(self, *_):\n                pass\n\n        from gevent import pywsgi\n\n        def admin_routes(env, start_response):\n            path = env[\"PATH_INFO\"]\n            status = \"200 OK\"\n            res = \"\"\n            if path in [\"/\", \"/report\", \"/report_mem\"]:\n                report = self.get_worker_report(with_memory=(path == \"/report_mem\"))\n                res = bytes(json_stdlib.dumps(report, cls=MongoJSONEncoder), 'utf-8')\n            elif path == \"/wait_for_idle\":\n                self.wait_for_idle()\n                res = bytes(\"idle\", \"utf-8\")\n            else:\n                status = \"404 Not Found\"\n            start_response(status, [('Content-Type', 'application/json')])\n            return [res]\n\n        server = pywsgi.WSGIServer((self.config[\"admin_ip\"], self.config[\"admin_port\"]), admin_routes, log=Devnull())\n\n        try:\n            self.log.debug(\"Starting admin server on port %s\" % self.config[\"admin_port\"])\n            server.serve_forever()\n        except Exception as e:  # pylint: disable=broad-except\n            self.log.debug(\"Error in admin server : %s\" % e)", "response": "This greenlet is used to get status information about the worker\n            when the admin_port was given."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwaits until the worker has nothing more to do.", "response": "def wait_for_idle(self):\n        \"\"\" Waits until the worker has nothing more to do. Very useful in tests \"\"\"\n\n        # Be mindful that this is being executed in a different greenlet than the work_* methods.\n\n        while True:\n\n            time.sleep(0.01)\n\n            with self.work_lock:\n\n                if self.status != \"wait\":\n                    continue\n\n                if len(self.gevent_pool) > 0:\n                    continue\n\n                # Force a refresh of the current subqueues, one might just have been created.\n                self.refresh_queues()\n\n                # We might be dequeueing a new subqueue. Double check that we don't have anything more to do\n                outcome, dequeue_jobs = self.work_once(free_pool_slots=1, max_jobs=None)\n\n                if outcome is \"wait\" and dequeue_jobs == 0:\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef work(self):\n        self.work_init()\n\n        self.work_loop(max_jobs=self.max_jobs, max_time=self.max_time)\n\n        self.work_stop()", "response": "Starts the work loop."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndo one work for new jobs inside the inner work loop", "response": "def work_once(self, free_pool_slots=1, max_jobs=None):\n        \"\"\" Does one lookup for new jobs, inside the inner work loop \"\"\"\n\n        dequeued_jobs = 0\n\n        available_queues = [\n            queue for queue in self.queues\n            if queue.root_id not in self.paused_queues and\n            queue.id not in self.paused_queues\n        ]\n\n        for queue_i in range(len(available_queues)):\n\n            queue = available_queues[(queue_i + self.queue_offset) % len(available_queues)]\n\n            max_jobs_per_queue = free_pool_slots - dequeued_jobs\n\n            if max_jobs_per_queue <= 0:\n                queue_i -= 1\n                break\n\n            if self.config[\"dequeue_strategy\"] == \"parallel\":\n                max_jobs_per_queue = max(1, int(max_jobs_per_queue / (len(available_queues) - queue_i)))\n\n            for job in queue.dequeue_jobs(\n                max_jobs=max_jobs_per_queue,\n                job_class=self.job_class,\n                worker=self\n            ):\n                dequeued_jobs += 1\n\n                self.gevent_pool.spawn(self.perform_job, job)\n\n        # At the next pass, start at the next queue to avoid always dequeuing the same one\n        if self.config[\"dequeue_strategy\"] == \"parallel\":\n            self.queue_offset = (self.queue_offset + queue_i + 1) % len(self.queues)\n\n        # TODO consider this when dequeuing jobs to have strict limits\n        if max_jobs and self.done_jobs >= max_jobs:\n            self.log.info(\"Reached max_jobs=%s\" % self.done_jobs)\n            return \"break\", dequeued_jobs\n\n        # We seem to have exhausted available jobs, we can sleep for a\n        # while.\n        if dequeued_jobs == 0:\n\n            if self.config[\"dequeue_strategy\"] == \"burst\":\n                self.log.info(\"Burst mode: stopping now because queues were empty\")\n                return \"break\", dequeued_jobs\n\n            return \"wait\", dequeued_jobs\n\n        return None, dequeued_jobs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwaits for new jobs to arrive", "response": "def work_wait(self):\n        \"\"\" Wait for new jobs to arrive \"\"\"\n\n        if len(self.queues_with_notify) > 0:\n            # https://github.com/antirez/redis/issues/874\n            connections.redis.blpop(*(self.queues_with_notify + [max(1, int(self.config[\"max_latency\"]))]))\n        else:\n            gevent.sleep(self.config[\"max_latency\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps a job. perform call with timeout logic and exception handlers.", "response": "def perform_job(self, job):\n        \"\"\" Wraps a job.perform() call with timeout logic and exception handlers.\n\n            This is the first call happening inside the greenlet.\n        \"\"\"\n\n        if self.config[\"trace_memory\"]:\n            job.trace_memory_start()\n\n        set_current_job(job)\n\n        try:\n            job.perform()\n\n        except MaxConcurrencyInterrupt:\n            self.log.error(\"Max concurrency reached\")\n            job._save_status(\"maxconcurrency\", exception=True)\n\n        except RetryInterrupt:\n            self.log.error(\"Caught retry\")\n            job.save_retry(sys.exc_info()[1])\n\n        except MaxRetriesInterrupt:\n            self.log.error(\"Max retries reached\")\n            job._save_status(\"maxretries\", exception=True)\n\n        except AbortInterrupt:\n            self.log.error(\"Caught abort\")\n            job.save_abort()\n\n        except TimeoutInterrupt:\n            self.log.error(\"Job timeouted after %s seconds\" % job.timeout)\n            job._save_status(\"timeout\", exception=True)\n\n        except JobInterrupt:\n            self.log.error(\"Job interrupted\")\n            job._save_status(\"interrupt\", exception=True)\n\n        except Exception:\n            self.log.error(\"Job failed\")\n            job._save_status(\"failed\", exception=True)\n\n        finally:\n\n            set_current_job(None)\n\n            self.done_jobs += 1\n\n            if self.config[\"trace_memory\"]:\n                job.trace_memory_stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shutdown_now(self):\n\n        self.log.info(\"Forced shutdown...\")\n        self.status = \"killing\"\n\n        self.gevent_pool.kill(exception=JobInterrupt, block=False)\n\n        raise StopRequested()", "response": "Forced shutdown of all the jobs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize_job_ids(self, job_ids):\n        if len(job_ids) == 0 or self.use_large_ids:\n            return job_ids\n        elif isinstance(job_ids[0], ObjectId):\n            return [x.binary for x in job_ids]\n        else:\n            return [bytes.fromhex(str(x)) for x in job_ids]", "response": "Returns a list of job_ids serialized for storage in Redis"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the id that should be used to pause the current queue", "response": "def _get_pausable_id(self):\n      \"\"\"\n          Get the queue id (either id or root_id) that should be used to pause/unpause the current queue\n          TODO: handle subqueues with more than one level, e.g. \"queue/subqueue/\"\n      \"\"\"\n      queue = self.id\n      if self.id.endswith(\"/\"):\n          queue = self.root_id\n      return queue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_paused(self):\n        root_is_paused = False\n        if self.root_id != self.id:\n            root_is_paused = context.connections.redis.sismember(redis_key(\"paused_queues\"), self.root_id)\n\n        return root_is_paused or context.connections.redis.sismember(redis_key(\"paused_queues\"), self.id)", "response": "Returns whether the queue is paused or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all active queues based on their lengths in Redis.", "response": "def all_active(cls):\n        \"\"\" List active queues, based on their lengths in Redis. Warning, uses the unscalable KEYS redis command \"\"\"\n\n        prefix = context.get_current_config()[\"redis_prefix\"]\n        queues = []\n        for key in context.connections.redis.keys():\n            if key.startswith(prefix):\n                queues.append(Queue(key[len(prefix) + 3:]))\n\n        return queues"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist all currently known queues", "response": "def all_known(cls, sources=None, prefixes=None):\n        \"\"\" List all currently known queues \"\"\"\n\n        sources = sources or (\"config\", \"jobs\", \"raw_subqueues\")\n\n        queues = set()\n\n        if \"config\" in sources and not prefixes:\n            # Some queues are explicitly declared in the config (including all root raw queues)\n            cfg = context.get_current_config()\n\n            queues_from_config = [\n                t.get(\"queue\")\n                for t in (cfg.get(\"tasks\") or {}).values()\n                if t.get(\"queue\")\n            ]\n\n            queues_from_config += Queue.get_queues_config().keys()\n\n            queues_from_config += [\n                t.get(\"retry_queue\")\n                for t in Queue.get_queues_config().values()\n                if t.get(\"retry_queue\")\n            ]\n\n            queues |= set(queues_from_config)\n\n        if \"jobs\" in sources:\n\n            # This will get all queues from mongodb, including those where we have only non-queued jobs\n            for q in context.connections.mongodb_jobs.mrq_jobs.distinct(\"queue\"):\n                if prefixes and not any(q.startswith(p) for p in prefixes):\n                    continue\n                queues.add(q)\n\n        if \"raw_subqueues\" in sources:\n            for q in Queue.get_queues_config():\n                if prefixes and not any(q + \"/\" == p for p in prefixes):\n                    continue\n                queue_obj = Queue(q)\n                if queue_obj.is_raw and queue_obj.has_subqueues:\n                    # TODO: optimize this with a single SUNION on all keys\n                    queues |= queue_obj.get_known_subqueues()\n\n        return queues"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all queues in MongoDB via aggregation with their queued jobs counts. Might be slow.", "response": "def all(cls):\n        \"\"\" List all queues in MongoDB via aggregation, with their queued jobs counts. Might be slow. \"\"\"\n\n        # Start with raw queues we know exist from the config\n        queues = {x: 0 for x in Queue.get_queues_config()}\n\n        stats = list(context.connections.mongodb_jobs.mrq_jobs.aggregate([\n            {\"$match\": {\"status\": \"queued\"}},\n            {\"$group\": {\"_id\": \"$queue\", \"jobs\": {\"$sum\": 1}}}\n        ]))\n\n        queues.update({x[\"_id\"]: x[\"jobs\"] for x in stats})\n\n        return queues"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef notify(self, new_jobs_count):\n\n        if not self.use_notify():\n            return\n\n        # Not really useful to send more than 100 notifs (to be configured)\n        count = min(new_jobs_count, 100)\n\n        notify_key = redis_key(\"notify\", self)\n\n        context.connections.redis.lpush(notify_key, *([1] * count))\n        context.connections.redis.expire(notify_key, max(1, int(context.get_current_config()[\"max_latency\"] * 2)))", "response": "Send new_jobs_count jobs on this queue to the workers if needed"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_known_subqueues(self):\n        if not self.has_subqueues:\n            return set()\n        return set(context.connections.redis.smembers(self.redis_key_known_subqueues))", "response": "Returns a set of all known subqueues"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef size(self):\n\n        if self.id.endswith(\"/\"):\n            return sum(Queue(q).size() for q in self.get_known_subqueues())\n\n        # ZSET\n        if self.is_sorted:\n            return context.connections.redis.zcard(self.redis_key)\n        # SET\n        elif self.is_set:\n            return context.connections.redis.scard(self.redis_key)\n        # LIST\n        else:\n            return context.connections.redis.llen(self.redis_key)", "response": "Returns the total number of queued jobs on the queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding Jobs to this queue with raw parameters.", "response": "def enqueue_raw_jobs(self, params_list):\n        \"\"\" Add Jobs to this queue with raw parameters. They are not yet in MongoDB. \"\"\"\n\n        if len(params_list) == 0:\n            return\n\n        if self.is_subqueue:\n            context.connections.redis.sadd(self.redis_key_known_subqueues, self.id)\n\n        # ZSET\n        if self.is_sorted:\n\n            if not isinstance(params_list, dict) and self.is_timed:\n                now = time.time()\n                params_list = {x: now for x in params_list}\n\n            context.connections.redis.zadd(self.redis_key, **params_list)\n\n        # SET\n        elif self.is_set:\n            context.connections.redis.sadd(self.redis_key, *params_list)\n\n        # LIST\n        else:\n            context.connections.redis.rpush(self.redis_key, *params_list)\n\n        context.metric(\"queues.%s.enqueued\" % self.id, len(params_list))\n        context.metric(\"queues.all.enqueued\", len(params_list))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_raw_jobs(self, params_list):\n\n        if len(params_list) == 0:\n            return\n\n        # ZSET\n        if self.is_sorted:\n            context.connections.redis.zrem(self.redis_key, *iter(params_list))\n\n        # SET\n        elif self.is_set:\n            context.connections.redis.srem(self.redis_key, *params_list)\n\n        else:\n            # O(n)! Use with caution.\n            for k in params_list:\n                context.connections.redis.lrem(self.redis_key, 1, k)\n\n        context.metric(\"queues.%s.removed\" % self.id, len(params_list))\n        context.metric(\"queues.all.removed\", len(params_list))", "response": "Remove jobs from a raw queue with their raw params."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count_jobs_to_dequeue(self):\n\n        # timed ZSET\n        if self.is_timed:\n            return context.connections.redis.zcount(\n                self.redis_key,\n                \"-inf\",\n                time.time())\n\n        # In all other cases, it's the same as .size()\n        else:\n            return self.size()", "response": "Returns the number of jobs that can be dequeued right now from the queue."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_sorted_graph(\n            self,\n            start=0,\n            stop=100,\n            slices=100,\n            include_inf=False,\n            exact=False):\n        \"\"\" Returns a graph of the distribution of jobs in a sorted set \"\"\"\n\n        if not self.is_sorted:\n            raise Exception(\"Not a sorted queue\")\n\n        with context.connections.redis.pipeline(transaction=exact) as pipe:\n            interval = old_div(float(stop - start), slices)\n            for i in range(0, slices):\n                pipe.zcount(self.redis_key,\n                            (start + i * interval),\n                            \"(%s\" % (start + (i + 1) * interval))\n            if include_inf:\n                pipe.zcount(self.redis_key, stop, \"+inf\")\n                pipe.zcount(self.redis_key, \"-inf\", \"(%s\" % start)\n            data = pipe.execute()\n\n        if include_inf:\n            return data[-1:] + data[:-1]\n\n        return data", "response": "Returns a graph of the distribution of jobs in a sorted set."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls signal handlers for the specified process.", "response": "def install_signal_handlers(self):\n        \"\"\" Handle events like Ctrl-C from the command line. \"\"\"\n\n        self.graceful_stop = False\n\n        def request_shutdown_now():\n            self.shutdown_now()\n\n        def request_shutdown_graceful():\n\n            # Second time CTRL-C, shutdown now\n            if self.graceful_stop:\n                self.shutdown_now()\n            else:\n                self.graceful_stop = True\n                self.shutdown_graceful()\n\n        # First time CTRL-C, try to shutdown gracefully\n        gevent.signal(signal.SIGINT, request_shutdown_graceful)\n\n        # User (or Heroku) requests a stop now, just mark tasks as interrupted.\n        gevent.signal(signal.SIGTERM, request_shutdown_now)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the processes that are currently running commands.", "response": "def set_commands(self, commands, timeout=None):\n        \"\"\" Sets the processes' desired commands for this pool and manages diff to reach that state \"\"\"\n        self.desired_commands = commands\n\n        target_commands = list(self.desired_commands)\n        for process in list(self.processes):\n            found = False\n            for i in range(len(target_commands)):\n                if process[\"command\"] == target_commands[i]:\n                    target_commands.pop(i)\n                    found = True\n                    break\n\n            if not found:\n                self.stop_process(process, timeout)\n\n        # What is left are the commands to add\n        # TODO: we should only do this once memory conditions allow\n        for command in target_commands:\n            self.spawn(command)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nspawns a new process and adds it to the pool", "response": "def spawn(self, command):\n        \"\"\" Spawns a new process and adds it to the pool \"\"\"\n\n        # process_name\n        # output\n        # time before starting (wait for port?)\n        # start_new_session=True : avoid sending parent signals to child\n\n        env = dict(os.environ)\n        env[\"MRQ_IS_SUBPROCESS\"] = \"1\"\n        env.update(self.extra_env or {})\n\n        # Extract env variables from shell commands.\n        parts = shlex.split(command)\n        for p in list(parts):\n            if \"=\" in p:\n                env[p.split(\"=\")[0]] = p[len(p.split(\"=\")[0]) + 1:]\n                parts.pop(0)\n            else:\n                break\n\n        p = subprocess.Popen(parts, shell=False, close_fds=True, env=env, cwd=os.getcwd())\n\n        self.processes.append({\n            \"subprocess\": p,\n            \"pid\": p.pid,\n            \"command\": command,\n            \"psutil\": psutil.Process(pid=p.pid)\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wait(self):\n\n        while True:\n            if not self.greenlet_watch:\n                break\n\n            if self.stopping:\n                gevent.sleep(0.1)\n            else:\n                gevent.sleep(1)", "response": "Waits for the pool to be fully stopped"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef watch_processes(self):\n\n        for process in list(self.processes):\n            self.watch_process(process)\n\n        # Cleanup processes\n        self.processes = [p for p in self.processes if not p.get(\"dead\")]\n\n        if self.stopping and len(self.processes) == 0:\n            self.stop_watch()", "response": "Manages the status of all the known processes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef watch_process(self, process):\n\n        status = process[\"psutil\"].status()\n\n        # TODO: how to avoid zombies?\n        # print process[\"pid\"], status\n\n        if process.get(\"terminate\"):\n            if status in (\"zombie\", \"dead\"):\n                process[\"dead\"] = True\n            elif process.get(\"terminate_at\"):\n                if time.time() > (process[\"terminate_at\"] + 5):\n                    log.warning(\"Process %s had to be sent SIGKILL\" % (process[\"pid\"], ))\n                    process[\"subprocess\"].send_signal(signal.SIGKILL)\n                elif time.time() > process[\"terminate_at\"]:\n                    log.warning(\"Process %s had to be sent SIGTERM\" % (process[\"pid\"], ))\n                    process[\"subprocess\"].send_signal(signal.SIGTERM)\n\n        else:\n            if status in (\"zombie\", \"dead\"):\n                # Restart a new process right away (TODO: sleep a bit? max retries?)\n                process[\"dead\"] = True\n                self.spawn(process[\"command\"])\n\n            elif status not in (\"running\", \"sleeping\"):\n                log.warning(\"Process %s was in status %s\" % (process[\"pid\"], status))", "response": "Manages the status of a single process"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(self, timeout=None):\n\n        self.stopping = True\n\n        for process in list(self.processes):\n            self.stop_process(process, timeout=timeout)", "response": "Stop all the processes in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitiate a graceful stop of one process", "response": "def stop_process(self, process, timeout=None):\n        \"\"\" Initiates a graceful stop of one process \"\"\"\n\n        process[\"terminate\"] = True\n        if timeout is not None:\n            process[\"terminate_at\"] = time.time() + timeout\n        process[\"subprocess\"].send_signal(signal.SIGINT)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nterminate the processes right now with a SIGTERM", "response": "def terminate(self):\n        \"\"\" Terminates the processes right now with a SIGTERM \"\"\"\n\n        for process in list(self.processes):\n            process[\"subprocess\"].send_signal(signal.SIGTERM)\n\n        self.stop_watch()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nkills the processes right now with a SIGKILL", "response": "def kill(self):\n        \"\"\" Kills the processes right now with a SIGKILL \"\"\"\n\n        for process in list(self.processes):\n            process[\"subprocess\"].send_signal(signal.SIGKILL)\n\n        self.stop_watch()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstopping the periodic watch greenlet thus the pool itself", "response": "def stop_watch(self):\n        \"\"\" Stops the periodic watch greenlet, thus the pool itself \"\"\"\n\n        if self.greenlet_watch:\n            self.greenlet_watch.kill(block=False)\n            self.greenlet_watch = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a config dict merged from several sources", "response": "def get_config(\n        sources=(\n            \"file\",\n            \"env\"),\n        env_prefix=\"MRQ_\",\n        file_path=None,\n        parser=None,\n        extra=None,\n        config_type=None):\n    \"\"\" Returns a config dict merged from several possible sources \"\"\"\n\n    if not parser:\n        parser = argparse.ArgumentParser()\n\n    add_parser_args(parser, config_type)\n    parser_types = {action.dest: action.type for action in parser._actions if action.dest}\n\n    if config_type in [\"run\"]:\n        default_config = parser.parse_args([\"notask\"]).__dict__\n    else:\n        default_config = parser.parse_args([]).__dict__\n\n    # Keys that can't be passed from the command line\n    default_config[\"tasks\"] = {}\n    default_config[\"log_handlers\"] = {}\n    default_config[\"scheduled_tasks\"] = {}\n\n    # Only keep values actually passed on the command line\n    from_args = {}\n    if \"args\" in sources:\n        cmdline_parser = ArgumentParserIgnoringDefaults(argument_default=argparse.SUPPRESS)\n        add_parser_args(cmdline_parser, config_type)\n        from_args = cmdline_parser.parse_args().__dict__\n\n    # If we were given another config file, use it\n\n    if file_path is not None:\n        config_file = file_path\n    elif from_args.get(\"config\"):\n        config_file = from_args.get(\"config\")\n    # If a mrq-config.py file is in the current directory, use it!\n    elif os.path.isfile(os.path.join(os.getcwd(), \"mrq-config.py\")):\n        config_file = os.path.join(os.getcwd(), \"mrq-config.py\")\n    else:\n        config_file = None\n\n    from_file = {}\n    if config_file and \"file\" in sources:\n        sys.path.insert(0, os.path.dirname(config_file))\n        config_module = __import__(os.path.basename(config_file.replace(\".py\", \"\")))\n        sys.path.pop(0)\n        for k, v in config_module.__dict__.items():\n\n            # We only keep variables starting with an uppercase character.\n            if k[0].isupper():\n                from_file[k.lower()] = v\n\n    # Merge the config in the order given by the user\n    merged_config = default_config\n\n    config_keys = set(list(default_config.keys()) + list(from_file.keys()))\n\n    for part in sources:\n        for name in config_keys:\n\n            if part == \"env\":\n                value = os.environ.get(env_prefix + name.upper())\n                if value:\n                    if name == \"queues\":\n                        value = re.split(\"\\s+\", value)\n                    if parser_types.get(name):\n                        value = parser_types[name](value)\n                    merged_config[name] = value\n            elif part == \"args\" and name in from_args:\n                merged_config[name] = from_args[name]\n            elif part == \"file\" and name in from_file:\n                merged_config[name] = from_file[name]\n\n    if extra:\n        merged_config.update(extra)\n\n    if merged_config[\"profile\"]:\n        import cProfile, pstats\n        profiler = cProfile.Profile()\n        profiler.enable()\n\n        def print_profiling():\n            pstats.Stats(profiler).sort_stats(\"cumulative\").print_stats()\n\n        atexit.register(print_profiling)\n\n    if merged_config[\"version\"]:\n        print(\"MRQ version: %s\" % VERSION)\n        print(\"Python version: %s\" % sys.version)\n        sys.exit(1)\n\n    if \"no_import_patch\" in from_args:\n        print(\"WARNING: --no_import_patch will be deprecated in MRQ 1.0!\")\n\n    return merged_config"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends data over Telegram.", "response": "def send(messages=None, conf=None, parse_mode=None, disable_web_page_preview=False, files=None, images=None,\n         captions=None, locations=None, timeout=30):\n    \"\"\"Send data over Telegram. All arguments are optional.\n\n    Always use this function with explicit keyword arguments. So\n    `send(messages=[\"Hello!\"])` instead of `send([\"Hello!\"])` as the latter\n    will *break* when I change the order of the arguments.\n\n    The `file` type is the [file object][] returned by the `open()` function.\n    To send an image/file you open it in binary mode:\n    ``` python\n    import telegram_send\n\n    with open(\"image.jpg\", \"rb\") as f:\n        telegram_send.send(images=[f])\n    ```\n\n    [file object]: https://docs.python.org/3/glossary.html#term-file-object\n\n    # Arguments\n\n    conf (str): Path of configuration file to use. Will use the default config if not specified.\n                `~` expands to user's home directory.\n    messages (List[str]): The messages to send.\n    parse_mode (str): Specifies formatting of messages, one of `[\"text\", \"markdown\", \"html\"]`.\n    disable_web_page_preview (bool): Disables web page previews for all links in the messages.\n    files (List[file]): The files to send.\n    images (List[file]): The images to send.\n    captions (List[str]): The captions to send with the images.\n    locations (List[str]): The locations to send. Locations are strings containing the latitude and longitude\n                           separated by whitespace or a comma.\n    timeout (int|float): The read timeout for network connections in seconds.\n    \"\"\"\n    conf = expanduser(conf) if conf else get_config_path()\n    config = configparser.ConfigParser()\n    if not config.read(conf) or not config.has_section(\"telegram\"):\n        raise ConfigError(\"Config not found\")\n    missing_options = set([\"token\", \"chat_id\"]) - set(config.options(\"telegram\"))\n    if len(missing_options) > 0:\n        raise ConfigError(\"Missing options in config: {}\".format(\", \".join(missing_options)))\n    token = config.get(\"telegram\", \"token\")\n    chat_id = int(config.get(\"telegram\", \"chat_id\")) if config.get(\"telegram\", \"chat_id\").isdigit() else config.get(\"telegram\", \"chat_id\")\n\n    request = telegram.utils.request.Request(read_timeout=timeout)\n    bot = telegram.Bot(token, request=request)\n\n    # We let the user specify \"text\" as a parse mode to be more explicit about\n    # the lack of formatting applied to the message, but \"text\" isn't a supported\n    # parse_mode in python-telegram-bot. Instead, set the parse_mode to None\n    # in this case.\n    if parse_mode == \"text\":\n        parse_mode = None\n\n    if messages:\n\n        def send_message(message):\n            return bot.send_message(chat_id=chat_id, text=message, parse_mode=parse_mode, disable_web_page_preview=disable_web_page_preview)\n\n        for m in messages:\n            if len(m) > MAX_MESSAGE_LENGTH:\n                warn(markup(\"Message longer than MAX_MESSAGE_LENGTH=%d, splitting into smaller messages.\" % MAX_MESSAGE_LENGTH, \"red\"))\n                ms = split_message(m, MAX_MESSAGE_LENGTH)\n                for m in ms:\n                    send_message(m)\n            elif len(m) == 0:\n                continue\n            else:\n                send_message(m)\n\n    if files:\n        for f in files:\n            bot.send_document(chat_id=chat_id, document=f)\n\n    if images:\n        if captions:\n            # make captions equal length when not all images have captions\n            captions += [None] * (len(images) - len(captions))\n            for (i, c) in zip(images, captions):\n                bot.send_photo(chat_id=chat_id, photo=i, caption=c)\n        else:\n            for i in images:\n                bot.send_photo(chat_id=chat_id, photo=i)\n\n    if locations:\n        it = iter(locations)\n        for loc in it:\n            if \",\" in loc:\n                lat, lon = loc.split(\",\")\n            else:\n                lat = loc\n                lon = next(it)\n            bot.send_location(chat_id=chat_id, latitude=float(lat), longitude=float(lon))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying the user to configure the bot.", "response": "def configure(conf, channel=False, group=False, fm_integration=False):\n    \"\"\"Guide user to set up the bot, saves configuration at `conf`.\n\n    # Arguments\n\n    conf (str): Path where to save the configuration file. May contain `~` for\n                user's home.\n    channel (Optional[bool]): Configure a channel.\n    group (Optional[bool]): Configure a group.\n    fm_integration (Optional[bool]): Setup file manager integration.\n    \"\"\"\n    conf = expanduser(conf) if conf else get_config_path()\n    prompt = \"\u276f \" if not sys.platform.startswith(\"win32\") else \"> \"\n    contact_url = \"https://telegram.me/\"\n\n    print(\"Talk with the {} on Telegram ({}), create a bot and insert the token\"\n          .format(markup(\"BotFather\", \"cyan\"), contact_url + \"BotFather\"))\n    try:\n        token = input(markup(prompt, \"magenta\")).strip()\n    except UnicodeEncodeError:\n        # some users can only display ASCII\n        prompt = \"> \"\n        token = input(markup(prompt, \"magenta\")).strip()\n\n    try:\n        bot = telegram.Bot(token)\n        bot_name = bot.get_me().username\n    except:\n        print(markup(\"Something went wrong, please try again.\\n\", \"red\"))\n        return configure()\n\n    print(\"Connected with {}.\\n\".format(markup(bot_name, \"cyan\")))\n\n    if channel:\n        print(\"Do you want to send to a {} or a {} channel? [pub/priv]\"\n              .format(markup(\"public\", \"bold\"), markup(\"private\", \"bold\")))\n        channel_type = input(markup(prompt, \"magenta\")).strip()\n        if channel_type.startswith(\"pub\"):\n            print(\"\\nEnter your channel's public name or link:\")\n            chat_id = input(markup(prompt, \"magenta\")).strip()\n            if \"/\" in chat_id:\n                chat_id = \"@\" + chat_id.split(\"/\")[-1]\n            elif chat_id.startswith(\"@\"):\n                pass\n            else:\n                chat_id = \"@\" + chat_id\n        else:\n            print(\"\\nOpen https://web.telegram.org in your browser, sign in and open your private channel.\"\n                  \"\\nNow copy the URL in the address bar and enter it here:\")\n            url = input(markup(prompt, \"magenta\")).strip()\n            chat_id = \"-100\" + re.match(\".+web\\.telegram\\.org\\/#\\/im\\?p=c(\\d+)\", url).group(1)\n\n        authorized = False\n        while not authorized:\n            try:\n                bot.send_chat_action(chat_id=chat_id, action=\"typing\")\n                authorized = True\n            except (telegram.error.Unauthorized, telegram.error.BadRequest):\n                # Telegram returns a BadRequest when a non-admin bot tries to send to a private channel\n                input(\"Please add {} as administrator to your channel and press Enter\"\n                      .format(markup(bot_name, \"cyan\")))\n        print(markup(\"\\nCongratulations! telegram-send can now post to your channel!\", \"green\"))\n    else:\n        password = \"\".join([str(randint(0, 9)) for _ in range(5)])\n        bot_url = contact_url + bot_name\n        fancy_bot_name = markup(bot_name, \"cyan\")\n        if group:\n            password = \"/{}@{}\".format(password, bot_name)\n            print(\"Please add {} to your group\\nand send the following message to the group: {}\\n\"\n                  .format(fancy_bot_name, markup(password, \"bold\")))\n        else:\n            print(\"Please add {} on Telegram ({})\\nand send it the password: {}\\n\"\n                  .format(fancy_bot_name, bot_url, markup(password, \"bold\")))\n\n        update, update_id = None, None\n\n        def get_user():\n            updates = bot.get_updates(offset=update_id, timeout=10)\n            for update in updates:\n                if update.message:\n                    if update.message.text == password:\n                        return update, None\n            if len(updates) > 0:\n                return None, updates[-1].update_id + 1\n            else:\n                return None, None\n\n        while update is None:\n            try:\n                update, update_id = get_user()\n            except Exception as e:\n                print(\"Error! {}\".format(e))\n\n        chat_id = update.message.chat_id\n        user = update.message.from_user.username or update.message.from_user.first_name\n        m = (\"Congratulations {}! \".format(user), \"\\ntelegram-send is now ready for use!\")\n        ball = \"\ud83c\udf8a\"\n        print(markup(\"\".join(m), \"green\"))\n        bot.send_message(chat_id=chat_id, text=ball + \" \" + m[0] + ball + m[1])\n\n    config = configparser.ConfigParser()\n    config.add_section(\"telegram\")\n    config.set(\"telegram\", \"TOKEN\", token)\n    config.set(\"telegram\", \"chat_id\", str(chat_id))\n    # above 3 lines in py3: config[\"telegram\"] = {\"TOKEN\": token, \"chat_id\": chat_id}\n    conf_dir = dirname(conf)\n    if conf_dir:\n        makedirs_check(conf_dir)\n    with open(conf, \"w\") as f:\n        config.write(f)\n    if fm_integration:\n        if not sys.platform.startswith(\"win32\"):\n            return integrate_file_manager()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split_message(message, max_length):\n    ms = []\n    while len(message) > max_length:\n        ms.append(message[:max_length])\n        message = message[max_length:]\n    ms.append(message)\n    return ms", "response": "Split large message into smaller messages each smaller than the max_length."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_capture_plugin(self):\n        for plugin in self.config.plugins.plugins:\n            if plugin.name == \"capture\":\n                return plugin\n        return None", "response": "Returns the capture plugin if it exists or None if not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nissuing an inspectionType service message to define generic properties of a given PyLint message type.", "response": "def report_message_type(self, msg):\n        \"\"\"Issues an `inspectionType` service message to define generic properties of a given PyLint message type.\n        :param utils.Message msg: a PyLint message\n        \"\"\"\n        desc = get_message_description(self.linter, msg.msg_id)\n        self.tc.message('inspectionType', id=msg.msg_id, name=msg.symbol, description=desc, category=msg.category)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nissues an inspection service message based on a PyLint message.", "response": "def handle_message(self, msg):\n        \"\"\"Issues an `inspection` service message based on a PyLint message.\n        Registers each message type upon first encounter.\n\n        :param utils.Message msg: a PyLint message\n        \"\"\"\n        if msg.msg_id not in self.msg_types:\n            self.report_message_type(msg)\n            self.msg_types.add(msg.msg_id)\n\n        self.tc.message('inspection', typeId=msg.msg_id, message=msg.msg,\n                        file=os.path.relpath(msg.abspath).replace('\\\\', '/'),\n                        line=str(msg.line),\n                        SEVERITY=TC_SEVERITY.get(msg.category))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nissuing the final PyLint score as a TeamCity build statistic value", "response": "def display_reports(self, layout):\n        \"\"\"Issues the final PyLint score as a TeamCity build statistic value\"\"\"\n        try:\n            score = self.linter.stats['global_note']\n        except (AttributeError, KeyError):\n            pass\n        else:\n            self.tc.message('buildStatisticValue', key='PyLintScore', value=str(score))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts shortcuts buttons to support shortcut buttons.", "response": "def convert_shortcut_buttons(items):\n        \"\"\"\n        support shortcut buttons [{'type':'web_url', 'title':'open web url', 'value':'https://~~'}]\n        \"\"\"\n        if items is not None and isinstance(items, list):\n            result = []\n            for item in items:\n                if isinstance(item, BaseButton):\n                    result.append(item)\n                elif isinstance(item, dict):\n                    if item.get('type') in ['web_url', 'postback', 'phone_number', 'element_share']:\n                        type = item.get('type')\n                        title = item.get('title')\n                        value = item.get('value', item.get('url', item.get('payload')))\n\n                        if type == 'web_url':\n                            result.append(ButtonWeb(title=title, url=value))\n                        elif type == 'postback':\n                            result.append(ButtonPostBack(title=title, payload=value))\n                        elif type == 'phone_number':\n                            result.append(ButtonPhoneNumber(title=title, payload=value))\n                        elif type == 'element_share':\n                            result.append(ButtonShare())\n\n                    else:\n                        raise ValueError('Invalid button type')\n                else:\n                    raise ValueError('Invalid buttons variables')\n            return result\n        else:\n            return items"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nallow adding a webhook_handler as an alternative to the decorators", "response": "def set_webhook_handler(self, scope, callback):\n        \"\"\"\n        Allows adding a webhook_handler as an alternative to the decorators\n        \"\"\"\n        scope = scope.lower()\n\n        if scope == 'after_send':\n            self._after_send = callback\n            return\n\n        if scope not in Page.WEBHOOK_ENDPOINTS:\n            raise ValueError(\"The 'scope' argument must be one of {}.\".format(Page.WEBHOOK_ENDPOINTS))\n\n        self._webhook_handlers[scope] = callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts quick reply items to list of QuickReply objects.", "response": "def convert_shortcut_quick_reply(items):\n        \"\"\"\n        support shortcut [{'title':'title', 'payload':'payload'}]\n        \"\"\"\n        if items is not None and isinstance(items, list):\n            result = []\n            for item in items:\n                if isinstance(item, QuickReply):\n                    result.append(item)\n                elif isinstance(item, dict):\n                    result.append(QuickReply(title=item.get('title'), payload=item.get('payload')))\n                else:\n                    raise ValueError('Invalid quick_replies variables')\n            return result\n        else:\n            return items"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a button to the recipient", "response": "def send_button(recipient):\n    \"\"\"\n    Shortcuts are supported\n    page.send(recipient, Template.Buttons(\"hello\", [\n        {'type': 'web_url', 'title': 'Open Web URL', 'value': 'https://www.oculus.com/en-us/rift/'},\n        {'type': 'postback', 'title': 'tigger Postback', 'value': 'DEVELOPED_DEFINED_PAYLOAD'},\n        {'type': 'phone_number', 'title': 'Call Phone Number', 'value': '+16505551234'},\n    ]))\n    \"\"\"\n    page.send(recipient, Template.Buttons(\"hello\", [\n        Template.ButtonWeb(\"Open Web URL\", \"https://www.oculus.com/en-us/rift/\"),\n        Template.ButtonPostBack(\"trigger Postback\", \"DEVELOPED_DEFINED_PAYLOAD\"),\n        Template.ButtonPhoneNumber(\"Call Phone Number\", \"+16505551234\")\n    ]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_quick_reply(recipient):\n    page.send(recipient, \"What's your favorite movie genre?\",\n              quick_replies=[QuickReply(title=\"Action\", payload=\"PICK_ACTION\"),\n                             QuickReply(title=\"Comedy\", payload=\"PICK_COMEDY\")],\n              metadata=\"DEVELOPER_DEFINED_METADATA\")", "response": "Send a quick reply to the recipient."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a source s windows", "response": "def getWindows(input):\n    \"\"\"Get a source's windows\"\"\"\n    with rasterio.open(input) as src:\n        return [[window, ij] for ij, window in src.block_windows()]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef array_stack(arrays):\n    shapes = np.array([a.shape for a in arrays])\n\n    if not np.all(np.roll(shapes[:, 1:], 1, axis=0) == shapes[:, 1:]):\n        raise ValueError(\n            \"All input arrays must have the same height and width for this mode\"\n        )\n\n    width = arrays[0].shape[-1]\n    height = arrays[0].shape[-2]\n\n    return np.array([a for subarray in arrays for a in subarray]).reshape(\n        shapes[:, 0].sum(), height, width\n    )", "response": "Stack arrays in a single array."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes an array and sets any value above the mean to the max", "response": "def read_function(data, window, ij, g_args):\n    \"\"\"Takes an array, and sets any value above the mean to the max, the rest to 0\"\"\"\n    output = (data[0] > numpy.mean(data[0])).astype(data[0].dtype) * data[0].max()\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init_worker(inpaths, g_args):\n    global global_args\n    global srcs\n    global_args = g_args\n    srcs = [rasterio.open(i) for i in inpaths]", "response": "The multiprocessing worker initializer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, processes=4):\n        if processes == 1:\n            self.pool = MockTub(init_worker, (self.inpaths, self.global_args))\n        else:\n            self.pool = Pool(processes, init_worker, (self.inpaths, self.global_args))\n\n        self.options[\"transform\"] = guard_transform(self.options[\"transform\"])\n\n        if self.mode == \"manual_read\":\n            reader_worker = manual_reader(self.run_function)\n        elif self.mode == \"array_read\":\n            reader_worker = array_reader(self.run_function)\n        else:\n            reader_worker = simple_reader(self.run_function)\n\n        if isinstance(self.outpath_or_dataset, rasterio.io.DatasetWriter):\n            destination = self.outpath_or_dataset\n        else:\n            destination = rasterio.open(self.outpath_or_dataset, \"w\", **self.options)\n\n        # Open an output file, work through the function in parallel,\n        # and write out the data.\n        with destination as dst:\n            for data, window in self.pool.imap_unordered(reader_worker, self.windows):\n                dst.write(data, window=window)\n\n        self.pool.close()\n        self.pool.join()", "response": "Run the function in parallel and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserializes only with letters numbers and _", "response": "def safe_serialize_type(l):\n    '''serialize only with letters, numbers and _'''\n\n    if isinstance(l, str):\n        return l\n    elif isinstance(l, list):\n        return '%s_%s_' % (l[0], ''.join(map(safe_serialize_type, l[1:])))\n    else:\n        return str(l)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if n is a tuple index.", "response": "def tuple_index(self, n):\n        '''s[<int>] where s is a Tuple[T1..]'''\n        return n.args and n.args[-1].type == 'index' and general_type(n.args[-1].sequence.pseudo_type) == 'Tuple' and\\\n               n.args[-1].index.type == 'int' and\\\n               (n.args[-1].index.value == -1 or n.args[-1].index.value == len(n.args[-1].sequence.pseudo_type) - 2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates code based on templates and gen functions and gen functions.", "response": "def generate(self, tree):\n        '''\n        generates code based on templates and gen functions\n        defined in the <x> lang generator\n        '''\n        for middleware in DEFAULT_MIDDLEWARES + self.middlewares:\n            tree = middleware.process(tree) # changed in place!!\n        original = self._generate_node(tree)\n        # first n lines n dependencies\n        # after that additional code\n\n        if self.a and tree.type == 'module':\n            p = original.split('\\n')\n            r = '\\n'.join(p[:len(tree.dependencies)] + (['\\n'] if tree.dependencies else []) + self.a + ['\\n'] + p[len(tree.dependencies):]) + '\\n'\n        else:\n            r = original\n        r = re.sub(CLOSING_CURLY_ENDLINES, r'}\\n\\2}', r)\n        r = re.sub(JS_BRACKET, r'}\\1', r)\n        return re.sub(TOO_MANY_ENDLINES, r'\\n\\n', r)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a template and returns a list of sub - templates", "response": "def _parse_template(self, code, label):\n        '''\n        Pare smart indented templates\n\n        Takes a template a returns a list of sub-templates, taking in account\n        the indentation of the original code based on the first line indentation(0)\n        Special treatment of whitespace: returns special Offset and INTERNAL_WHITESPACE, so the generation can be configurable\n        It auto detects the indentation width used, as the indent of the first indented line\n        >>> indented(\"\"\"\n          def %<code>\n            e =\n            %<code2>\n          \"\"\")\n        ['def', INTERNAL_WHITESPACE, Placeholder('code', 0), NEWLINE,\n          Offset(1),'e', INTERNAL_WHITESPACE, '=', NEWLINE,\n          Placeholder('code2', 1), NEWLINE]\n        '''\n\n        if isinstance(code, tuple):\n            return tuple(self._parse_template(c, label) for c in code)\n        elif isinstance(code, dict):\n            return {\n                k: self._parse_template(v, label) if k != '_key' else v\n                for k, v\n                in code.items()\n            }\n        elif not isinstance(code, str):\n            return []\n\n        lines = code.split('\\n')\n        parsed = []\n        if len(lines) == 1:\n            i = re.match(r'^( +)', lines[0])\n            indent_size = len(i.group()) if i else 0\n            indent = 1 if i else 0\n            actual = lines\n            base = 0\n        else:\n            base = len(re.match(r'^( *)', lines[1]).group())\n            rebased = [line[base:] for line in lines]\n            for line in rebased:\n                i = re.match(r'^( +)', line)\n                if i:\n                    indent_size = len(i.group())\n                    break\n            else:\n                indent_size = 0\n            actual = rebased[1:]\n\n        for line in actual:\n            j = LINE_FIRS.match(line)\n            indent = len(j.group()) // indent_size if j else 0\n            if parsed:\n                parsed.append(Offset(indent))\n            in_placeholder = False\n            in_action = False\n            in_args = False\n            in_string_arg = False\n            in_double_arg = False\n            in_type = False\n            c = int(indent * indent_size)\n            m = c\n            placeholder = ''\n            while m < len(line):\n                # print(m, line[m], 'place:', in_placeholder, 'act:', in_action, 'a:', in_args, 's:', in_string_arg, yaml.dump(parsed))\n                f = line[m]\n                next_f = line[m + 1] if m < len(line) - 1 else None\n                if f == '%' and not in_placeholder and next_f == '<':\n                    m += 2\n                    in_placeholder = True\n                    placeholder = ''\n                    continue\n                elif f == ':' and in_placeholder:\n                    m += 1\n                    in_placeholder = False\n                    in_action = True\n                    action = ''\n                    continue\n                elif f == ' ' and in_placeholder:\n                    m += 1\n                    continue\n                elif f == ' ' and in_action:\n                    m += 1\n                    in_action = False\n                    in_args = True\n                    args = ['']\n                    continue\n                elif f == ' ' and (in_string_arg or in_double_arg):\n                    args[-1] += f\n                    m += 1\n                    continue\n                elif f == ' ' and in_args:\n                    m += 1\n                    args.append('')\n                    continue\n                elif f == '\\'' and in_args:\n                    m += 1\n                    if in_string_arg:\n                        in_string_arg = False\n                        if args[-1] == '\\\\n':\n                            args[-1] = '\\n'\n                        args[-1] += f\n\n                    elif in_double_arg:\n                        args[-1] += f\n                    else:\n                        in_string_arg = True\n\n                    continue\n                elif f == '\"' and in_args:\n                    m += 1\n                    if in_double_arg:\n                        in_double_arg = False\n                        if args[-1] == '\\\\n':\n                            args[-1] = '\\n'\n                        args[-1] += f\n                    elif in_string_arg:\n                        args[-1] += f\n                    else:\n                        in_string_arg = True\n\n                    continue\n                elif f == '>' and in_args and not in_string_arg and not in_double_arg:\n                    m += 1\n                    if args[-1] == '':\n                        args = args[:-1]\n                    args = [arg[:-1] if arg[-1] == '\\'' else int(arg) for arg in args]\n                    in_args = False\n                    parsed.append(Action(placeholder, action, args))\n                    continue\n                elif f == '>' and in_action:\n                    m += 1\n                    in_action = False\n                    parsed.append(Action(placeholder, action, []))\n                elif f == '>' and in_placeholder:\n                    m += 1\n                    q = None\n                    # if '.' in placeholder[1:]:\n                    #     input(placeholder)\n                    if placeholder[0] == '#':\n                        q = Function(placeholder[1:])\n                    elif placeholder[0] == '@':\n                        q = PseudoType(placeholder[1:].split('.'))\n                    elif placeholder[0] == '.':\n                        q = SubTemplate(label, placeholder[1:])\n                    elif '.' in placeholder:\n                        q = SubElement(placeholder.split('.'))\n                    else:\n                        q = Placeholder(placeholder)\n                    in_placeholder = False\n                    parsed.append(q)\n                elif f == ' ':\n                    m += 1\n                    parsed.append(INTERNAL_WHITESPACE)\n                elif in_placeholder:\n                    m += 1\n                    placeholder += f\n                elif in_action:\n                    m += 1\n                    action += f\n                elif in_args:\n                    m += 1\n                    args[-1] += f\n                else:\n                    m += 1\n                    if parsed and isinstance(parsed[-1], str):\n                        parsed[-1] += f\n                    else:\n                        parsed.append(f)\n            if len(actual) > 1:\n                parsed.append(NEWLINE)\n        return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_node(value):\n    '''Expand to a literal node if a basic type otherwise just returns the node'''\n\n    if isinstance(value, Node):\n        return value\n    elif isinstance(value, str):\n        return Node('string', value=value, pseudo_type='String')\n    elif isinstance(value, int):\n        return Node('int', value=value, pseudo_type='Int')\n    elif isinstance(value, bool):\n        return Node('boolean', value=str(value).lower(), pseudo_type='Boolean')\n    elif isinstance(value, float):\n        return Node('float', value=value, pseudo_type='Float')\n    elif value is None:\n        return Node('null', pseudo_type='Void')\n    else:\n        1/0", "response": "Expand to a literal node if a basic type otherwise just returns the node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_op(op, reversed=False):\n    '''\n    create a function that transforms a method to a binary op\n\n    often we need to convert a pseudo method\n    <receiver>.<message>(<z>) to a binary op\n    <receiver> <op> <message>\n    that's a decorator that helps for that\n    '''\n    def transformer(receiver, param, pseudo_type):\n        if not reversed:\n            return Node('binary_op', op=op, left=receiver, right=param, pseudo_type=pseudo_type)\n        return Node('binary_op', op=op, left=param, right=receiver, pseudo_type=pseudo_type)\n    return transformer", "response": "create a function that transforms a method to a binary op\n    often we need to convert a pseudo method\n    <receiver > <op > <message >"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nleaks method for the given node", "response": "def leaking(self, z, module, name, node, context, *data):\n        '''\n        an expression leaking ...\n\n        assignment nodes into the nearest block list of nodes\n        c++ guys, stay calm\n        '''\n\n        # input(node.y)\n        args = [node.receiver] + node.args if node.type == 'standard_method_call' else node.args\n        z = z(module, name, args)\n        if context == 'expression':\n            if isinstance(z, NormalLeakingNode):\n                leaked_nodes, exp = z.as_expression()\n            else:\n                leaked_nodes, exp = z.as_expression()\n                zz = local(z.temp_name(getattr(z, 'default', '')), node.pseudo_type)\n                leaked_nodes = z.as_assignment(zz)\n                exp = local(zz, node.pseudo_type)\n            if exp is None or exp.pseudo_type == 'Void':\n                raise PseudoTypeError(\"pseudo can't handle values with void type in expression: %s?%s\" % (module, name))\n            self.leaked_nodes += leaked_nodes\n            return exp\n        elif context == 'assignment':\n            if isinstance(z, NormalLeakingNode):\n                leaked_nodes, exp = z.as_expression()\n                if exp is None or exp.pseudo_type == 'Void':\n                    raise PseudoTypeError(\"pseudo can't handle values with void type in expression: %s?%s\" % (module, name))\n                self.leaked_nodes += leaked_nodes\n                return assignment(data[0], exp)\n            else:\n                self.leaked_nodes += z.as_assignment(data[0])\n                return None\n        elif context == 'block':\n            leaked_nodes, exp = z.as_expression()\n            self.leaked_nodes += leaked_nodes\n            return exp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexpands the given api and return the result as a Node object.", "response": "def _expand_api(self, api, receiver, args, pseudo_type, equivalent):\n        '''\n        the heart of api translation dsl\n\n        function or <z>(<arg>, ..) can be expanded, <z> can be just a name for a global function, or #name for method, <arg> can be %{self} for self or %{n} for nth arg\n        '''\n\n        if callable(api):\n            if receiver:\n                return api(receiver, *(args + [pseudo_type]))\n            else:\n                return api(*(args + [pseudo_type]))\n        elif isinstance(api, str):\n            if '(' in api:\n                call_api, arg_code = api[:-1].split('(')\n                new_args = [self._parse_part(\n                    a.strip(), receiver, args, equivalent) for a in arg_code.split(',')]\n            else:\n                call_api, arg_code = api, ''\n                new_args = args\n            if '#' in call_api:\n                a, b = call_api.split('#')\n                method_receiver = self._parse_part(\n                    a, receiver, args, equivalent) if a else receiver\n                return method_call(method_receiver, b, new_args, pseudo_type=pseudo_type)\n            elif '.' in call_api:\n                a, b = call_api.split('.')\n                static_receiver = self._parse_part(\n                    a, receiver, args, equivalent) if a else receiver\n                if b[-1] != '!':\n                    return Node('static_call', receiver=static_receiver, message=b, args=new_args, pseudo_type=pseudo_type)\n                else:\n                    return Node('attr', object=static_receiver, attr=b[:-1], pseudo_type=pseudo_type)\n            else:\n                if receiver:\n                    return call(call_api, [receiver] + new_args, pseudo_type=pseudo_type)\n                else:\n                    return call(call_api, new_args, pseudo_type=pseudo_type)\n        else:\n            raise PseudoDSLError('%s not supported by api dsl' % str(api))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate output code for main in language", "response": "def generate_main(main, language):\n    '''\n    generate output code for main in `language`\n\n    `main` is a dict/Node or a list of dicts/Nodes with pseudo ast\n\n    e.g.\n    > print(generate_main({'type': 'int', 'value': 0, 'pseudo_type': 'Int'}, 'rb'))\n    2\n    > print(generate_main([pseudo.pseudo_tree.to_node('a'), pseudo.pseudo_tree.to_node(0)], 'js'))\n    'a';\n    0;\n    '''\n    base = {'type': 'module', 'custom_exceptions': [], 'definitions': [], 'constants': [], 'main': [], 'pseudo_type': 'Void'}\n    base_node = pseudo.loader.convert_to_syntax_tree(base)\n    if isinstance(main, dict):\n        base['main'] = [main]\n    elif isinstance(main, list):\n        if main and isinstance(main[0], dict):\n            base['main'] = main\n        else:\n            base_node.main = main\n    elif isinstance(main, pseudo.pseudo_tree.Node):\n        base_node.main = [main]\n    if base['main']:\n        q = pseudo.loader.convert_to_syntax_tree(base)\n    else:\n        q = base_node\n    return generate(q, language)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a node - based pseudo internal tree from a YAML input.", "response": "def generate_from_yaml(pseudo_ast, language):\n    '''\n    generate output code in `language`\n\n    converts yaml input to a Node-based pseudo internal tree and\n    passes it to `generate\n\n    '''\n    return pseudo.generate(pseudo.loader.as_tree(pseudo_ast), language)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate(pseudo_ast, language):\n    '''\n    generate output code in `language`\n\n    `pseudo_ast` can be a plain `dict` with ast data or\n    it can use the internal `pseudo` `Node(type, **fields)` format\n\n    if you want to play with it, you can use `generate_main` which \n    expects just a dict node / a list of dict nodes and a language\n\n    `language` can be 'py', 'python', 'rb', 'ruby',\n      'javascript', 'js', 'cs', 'csharp', 'go' or 'cpp'\n    '''\n\n    if isinstance(pseudo_ast, dict):\n        pseudo_ast = pseudo.loader.convert_to_syntax_tree(pseudo_ast)\n    translated_ast = API_TRANSLATORS[language](pseudo_ast).api_translate()\n    return GENERATORS[language]().generate(translated_ast)", "response": "generate output code in language"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sanitize(func):\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        return normalize('NFC', func(*args, **kwargs))\n    return wrapper", "response": "A decorator that returns a function that can be used to normalize the input arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts raw data into a str in Python 3 or unicode in Python 2 and returns a str in Python 3 or unicode in Python 2", "response": "def ported_string(raw_data, encoding='utf-8', errors='ignore'):\n    \"\"\"\n    Give as input raw data and output a str in Python 3\n    and unicode in Python 2.\n\n    Args:\n        raw_data: Python 2 str, Python 3 bytes or str to porting\n        encoding: string giving the name of an encoding\n        errors: his specifies the treatment of characters\n            which are invalid in the input encoding\n\n    Returns:\n        str (Python 3) or unicode (Python 2)\n    \"\"\"\n\n    if not raw_data:\n        return six.text_type()\n\n    if isinstance(raw_data, six.text_type):\n        return raw_data.strip()\n\n    if six.PY2:\n        try:\n            return six.text_type(raw_data, encoding, errors).strip()\n        except LookupError:\n            return six.text_type(raw_data, \"utf-8\", errors).strip()\n\n    if six.PY3:\n        try:\n            return six.text_type(raw_data, encoding).strip()\n        except (LookupError, UnicodeDecodeError):\n            return six.text_type(raw_data, \"utf-8\", errors).strip()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode a raw header part into a string", "response": "def decode_header_part(header):\n    \"\"\"\n    Given an raw header returns an decoded header\n\n    Args:\n        header (string): header to decode\n\n    Returns:\n        str (Python 3) or unicode (Python 2)\n    \"\"\"\n    if not header:\n        return six.text_type()\n\n    output = six.text_type()\n\n    try:\n        for d, c in decode_header(header):\n            c = c if c else 'utf-8'\n            output += ported_string(d, c, 'ignore')\n\n    # Header parsing failed, when header has charset Shift_JIS\n    except (HeaderParseError, UnicodeError):\n        log.error(\"Failed decoding header part: {}\".format(header))\n        output += header\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute msgconvert tool to convert msg Outlook message to eml mail format", "response": "def msgconvert(email):\n    \"\"\"\n    Exec msgconvert tool, to convert msg Outlook\n    mail in eml mail format\n\n    Args:\n        email (string): file path of Outlook msg mail\n\n    Returns:\n        tuple with file path of mail converted and\n        standard output data (unicode Python 2, str Python 3)\n    \"\"\"\n    log.debug(\"Started converting Outlook email\")\n    temph, temp = tempfile.mkstemp(prefix=\"outlook_\")\n    command = [\"msgconvert\", \"--outfile\", temp, email]\n\n    try:\n        if six.PY2:\n            with open(os.devnull, \"w\") as devnull:\n                out = subprocess.Popen(\n                    command, stdin=subprocess.PIPE,\n                    stdout=subprocess.PIPE, stderr=devnull)\n        elif six.PY3:\n            out = subprocess.Popen(\n                command, stdin=subprocess.PIPE,\n                stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n\n    except OSError:\n        message = \"To use this function you must install 'msgconvert' tool\"\n        log.exception(message)\n        raise MailParserOSError(message)\n\n    else:\n        stdoutdata, _ = out.communicate()\n        return temp, stdoutdata.decode(\"utf-8\").strip()\n\n    finally:\n        os.close(temph)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_received(received):\n\n    values_by_clause = {}\n    for pattern in RECEIVED_COMPILED_LIST:\n        matches = [match for match in pattern.finditer(received)]\n\n        if len(matches) == 0:\n            # no matches for this clause, but it's ok! keep going!\n            log.debug(\"No matches found for %s in %s\" % (\n                pattern.pattern, received))\n            continue\n        elif len(matches) > 1:\n            # uh, can't have more than one of each clause in a received.\n            # so either there's more than one or the current regex is wrong\n            msg = \"More than one match found for %s in %s\" % (\n                pattern.pattern, received)\n            log.error(msg)\n            raise MailParserReceivedParsingError(msg)\n        else:\n            # otherwise we have one matching clause!\n            log.debug(\"Found one match for %s in %s\" % (\n                pattern.pattern, received))\n            match = matches[0].groupdict()\n            if six.PY2:\n                values_by_clause[match.keys()[0]] = match.values()[0]\n            elif six.PY3:\n                key = list(match.keys())[0]\n                value = list(match.values())[0]\n                values_by_clause[key] = value\n\n    if len(values_by_clause) == 0:\n        # we weren't able to match anything...\n        msg = \"Unable to match any clauses in %s\" % (received)\n        log.error(msg)\n        raise MailParserReceivedParsingError(msg)\n    return values_by_clause", "response": "Parse a single received header and return a dictionary of values by clause."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef receiveds_parsing(receiveds):\n\n    parsed = []\n    receiveds = [re.sub(JUNK_PATTERN, \" \", i).strip() for i in receiveds]\n    n = len(receiveds)\n    log.debug(\"Nr. of receiveds. {}\".format(n))\n\n    for idx, received in enumerate(receiveds):\n        log.debug(\"Parsing received {}/{}\".format(idx + 1, n))\n        log.debug(\"Try to parse {!r}\".format(received))\n        try:\n            # try to parse the current received header...\n            values_by_clause = parse_received(received)\n        except MailParserReceivedParsingError:\n            # if we can't, let's append the raw\n            parsed.append({'raw': received})\n        else:\n            # otherwise append the full values_by_clause dict\n            parsed.append(values_by_clause)\n\n    log.debug(\"len(receiveds) %s, len(parsed) %s\" % (\n        len(receiveds), len(parsed)))\n\n    if len(receiveds) != len(parsed):\n        # something really bad happened,\n        # so just return raw receiveds with hop indices\n        log.error(\"len(receiveds): %s, len(parsed): %s, receiveds: %s, \\\n            parsed: %s\" % (len(receiveds), len(parsed), receiveds, parsed))\n        return receiveds_not_parsed(receiveds)\n\n    else:\n        # all's good! we have parsed or raw receiveds for each received header\n        return receiveds_format(parsed)", "response": "This function parses the receiveds headers and returns a list of parsed headers with first hop in first position"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a list of receiveds and returns a new list of dicts with raw field as first hop in first position.", "response": "def receiveds_not_parsed(receiveds):\n    \"\"\"\n    If receiveds are not parsed, makes a new structure with raw\n    field. It's useful to have the same structure of receiveds\n    parsed.\n\n    Args:\n        receiveds (list): list of raw receiveds headers\n\n    Returns:\n        a list of not parsed receiveds headers with first hop in first position\n    \"\"\"\n    log.debug(\"Receiveds for this email are not parsed\")\n\n    output = []\n    counter = Counter()\n\n    for i in receiveds[::-1]:\n        j = {\"raw\": i.strip()}\n        j[\"hop\"] = counter[\"hop\"] + 1\n        counter[\"hop\"] += 1\n        output.append(j)\n    else:\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a list of receiveds hops add metadata and reformat the new fields", "response": "def receiveds_format(receiveds):\n    \"\"\"\n    Given a list of receiveds hop, adds metadata and reformat\n    field values\n\n    Args:\n        receiveds (list): list of receiveds hops already formatted\n\n    Returns:\n        list of receiveds reformated and with new fields\n    \"\"\"\n    log.debug(\"Receiveds for this email are parsed\")\n\n    output = []\n    counter = Counter()\n\n    for i in receiveds[::-1]:\n        # Clean strings\n        j = {k: v.strip() for k, v in i.items() if v}\n\n        # Add hop\n        j[\"hop\"] = counter[\"hop\"] + 1\n\n        # Add UTC date\n        if i.get(\"date\"):\n            # Modify date to manage strange header like:\n            # \"for <eboktor@romolo.com>; Tue, 7 Mar 2017 14:29:24 -0800\",\n            i[\"date\"] = i[\"date\"].split(\";\")[-1]\n            try:\n                j[\"date_utc\"], _ = convert_mail_date(i[\"date\"])\n            except TypeError:\n                j[\"date_utc\"] = None\n\n        # Add delay\n        size = len(output)\n        now = j.get(\"date_utc\")\n\n        if size and now:\n            before = output[counter[\"hop\"] - 1].get(\"date_utc\")\n            if before:\n                j[\"delay\"] = (now - before).total_seconds()\n            else:\n                j[\"delay\"] = 0\n        else:\n            j[\"delay\"] = 0\n\n        # append result\n        output.append(j)\n\n        # new hop\n        counter[\"hop\"] += 1\n    else:\n        for i in output:\n            if i.get(\"date_utc\"):\n                i[\"date_utc\"] = i[\"date_utc\"].isoformat()\n        else:\n            return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_header(message, name):\n    header = message.get(name)\n    log.debug(\"Getting header {!r}: {!r}\".format(name, header))\n    if header:\n        return decode_header_part(header)\n    return six.text_type()", "response": "Gets an email. message. Message and a header name and returns\n    the mail header decoded with the correct charset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive an email. message. Message return a set with all email parts", "response": "def get_mail_keys(message, complete=True):\n    \"\"\"\n    Given an email.message.Message, return a set with all email parts to get\n\n    Args:\n        message (email.message.Message): email message object\n        complete (bool): if True returns all email headers\n\n    Returns:\n        set with all email parts\n    \"\"\"\n\n    if complete:\n        log.debug(\"Get all headers\")\n        all_headers_keys = {i.lower() for i in message.keys()}\n        all_parts = ADDRESSES_HEADERS | OTHERS_PARTS | all_headers_keys\n    else:\n        log.debug(\"Get only mains headers\")\n        all_parts = ADDRESSES_HEADERS | OTHERS_PARTS\n\n    log.debug(\"All parts to get: {}\".format(\", \".join(all_parts)))\n    return all_parts"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_file(cls, fp, is_outlook=False):\n        log.debug(\"Parsing email from file {!r}\".format(fp))\n\n        with ported_open(fp) as f:\n            message = email.message_from_file(f)\n\n        if is_outlook:\n            log.debug(\"Removing temp converted Outlook email {!r}\".format(fp))\n            os.remove(fp)\n\n        return cls(message)", "response": "Init a new object from a file path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _reset(self):\n        log.debug(\"Reset all variables\")\n\n        self._attachments = []\n        self._text_plain = []\n        self._text_html = []\n        self._defects = []\n        self._defects_categories = set()\n        self._has_defects = False", "response": "Reset all the internal state of the mail object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds new defects and defects categories to object attributes.", "response": "def _append_defects(self, part, part_content_type):\n        \"\"\"\n        Add new defects and defects categories to object attributes.\n\n        The defects are a list of all the problems found\n        when parsing this message.\n\n        Args:\n            part (string): mail part\n            part_content_type (string): content type of part\n        \"\"\"\n\n        part_defects = {}\n\n        for e in part.defects:\n            defects = \"{}: {}\".format(e.__class__.__name__, e.__doc__)\n            self._defects_categories.add(e.__class__.__name__)\n            part_defects.setdefault(part_content_type, []).append(defects)\n            log.debug(\"Added defect {!r}\".format(defects))\n\n        # Tag mail with defect\n        if part_defects:\n            self._has_defects = True\n\n            # Save all defects\n            self._defects.append(part_defects)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_server_ipaddress(self, trust):\n        log.debug(\"Trust string is {!r}\".format(trust))\n\n        if not trust.strip():\n            return\n\n        received = self.message.get_all(\"received\", [])\n\n        for i in received:\n            i = ported_string(i)\n            if trust in i:\n                log.debug(\"Trust string {!r} is in {!r}\".format(trust, i))\n                check = REGXIP.findall(i[0:i.find(\"by\")])\n\n                if check:\n                    try:\n                        ip_str = six.text_type(check[-1])\n                        log.debug(\"Found sender IP {!r} in {!r}\".format(\n                            ip_str, i))\n                        ip = ipaddress.ip_address(ip_str)\n                    except ValueError:\n                        return\n                    else:\n                        if not ip.is_private:\n                            log.debug(\"IP {!r} not private\".format(ip_str))\n                            return ip_str", "response": "This method extracts a reliable sender IP address from the message and returns the ip address of that sender."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef received_raw(self):\n        output = []\n        for i in self.message.get_all(\"received\", []):\n            output.append(decode_header_part(i))\n        return output", "response": "Return a list of all received headers in raw format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn only the headers as Python object", "response": "def headers(self):\n        \"\"\"\n        Return only the headers as Python object\n        \"\"\"\n        d = {}\n        for k, v in self.message.items():\n            d[k] = decode_header_part(v)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef date(self):\n        date = self.message.get('date')\n        conv = None\n\n        try:\n            conv, _ = convert_mail_date(date)\n        finally:\n            return conv", "response": "Return the mail date in datetime. datetime format and UTC."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning timezone offset from UTC.", "response": "def timezone(self):\n        \"\"\"\n        Return timezone. Offset from UTC.\n        \"\"\"\n        date = self.message.get('date')\n        timezone = 0\n\n        try:\n            _, timezone = convert_mail_date(date)\n        finally:\n            return timezone"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date_json(self):\n        if self.date:\n            return json.dumps(self.date.isoformat(), ensure_ascii=False)", "response": "Return the JSON of date"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mail_json(self):\n        if self.mail.get(\"date\"):\n            self._mail[\"date\"] = self.date.isoformat()\n        return json.dumps(self.mail, ensure_ascii=False, indent=2)", "response": "Return the JSON of the mail"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the JSON of the mail parsed partial", "response": "def mail_partial_json(self):\n        \"\"\"\n        Return the JSON of mail parsed partial\n        \"\"\"\n        if self.mail_partial.get(\"date\"):\n            self._mail_partial[\"date\"] = self.date.isoformat()\n        return json.dumps(self.mail_partial, ensure_ascii=False, indent=2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_worker_fn(scraper, img_url, pbar, status_flags, status_lock):\n    failed = False\n    size_failed = False\n    try:\n        scraper.download_image(img_url)\n    except ImageDownloadError:\n        failed = True\n    except ImageSizeError:\n        size_failed = True\n    status_lock.acquire(True)\n    if failed:\n        status_flags['failed'] += 1\n    elif size_failed:\n        status_flags['under_min_or_over_max_filesize'] += 1\n    status_flags['percent'] = status_flags[\n        'percent'] + old_div(100.0, scraper.no_to_download)\n    pbar.update(status_flags['percent'] % 100)\n    status_lock.release()\n    return True", "response": "Worker function that downloads images."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the command line arguments for the command line.", "response": "def get_arguments(self):\n        \"\"\" Gets the arguments from the command line. \"\"\"\n\n        parser = argparse.ArgumentParser(\n            description='Downloads images from given URL')\n        parser.add_argument('url2scrape', nargs=1, help=\"URL to scrape\")\n        parser.add_argument('-m', '--max-images', type=int, default=None,\n                            help=\"Limit on number of images\\n\")\n        parser.add_argument('-s', '--save-dir', type=str, default=\"images\",\n                            help=\"Directory in which images should be saved\")\n        parser.add_argument('-g', '--injected', help=\"Scrape injected images\",\n                            action=\"store_true\")\n        parser.add_argument('--proxy-server', type=str, default=None,\n                            help=\"Proxy server to use\")\n        parser.add_argument('--min-filesize', type=int, default=0,\n                            help=\"Limit on size of image in bytes\")\n        parser.add_argument('--max-filesize', type=int, default=100000000,\n                            help=\"Limit on size of image in bytes\")\n        parser.add_argument('--dump-urls', default=False,\n                            help=\"Print the URLs of the images\",\n                            action=\"store_true\")\n        parser.add_argument('--formats', nargs=\"*\", default=None,\n                            help=\"Specify formats in a list without any separator.\\\n                                  This argument must be after the URL.\")\n        parser.add_argument('--scrape-reverse', default=False,\n                            help=\"Scrape the images in reverse order\",\n                            action=\"store_true\")\n        parser.add_argument('--filename-pattern', type=str, default=None,\n                            help=\"Only scrape images with filenames that\\\n                                  match the given regex pattern\")\n        parser.add_argument('--nthreads', type=int, default=10,\n                            help=\"The number of threads to use when downloading images.\")\n        args = parser.parse_args()\n        self.url = args.url2scrape[0]\n        if not re.match(r'^[a-zA-Z]+://', self.url):\n            self.url = 'http://' + self.url\n        self.no_to_download = args.max_images\n        save_dir = args.save_dir + '_{uri.netloc}'.format(\n            uri=urlparse(self.url))\n        if args.save_dir != \"images\":\n            save_dir = args.save_dir\n        self.download_path = os.path.join(os.getcwd(), save_dir)\n        self.use_ghost = args.injected\n        self.format_list = args.formats if args.formats else [\n            \"jpg\", \"png\", \"gif\", \"svg\", \"jpeg\"]\n        self.min_filesize = args.min_filesize\n        self.max_filesize = args.max_filesize\n        self.dump_urls = args.dump_urls\n        self.proxy_url = args.proxy_server\n        self.proxies = {}\n        if self.proxy_url:\n            if not re.match(r'^[a-zA-Z]+://', self.proxy_url):\n                self.proxy_url = 'http://' + self.proxy_url\n            proxy_start_length = self.proxy_url.find(\"://\") + 3\n            self.proxies = {\n                self.proxy_url[:(proxy_start_length - 3)]: self.proxy_url\n            }\n\n        self.scrape_reverse = args.scrape_reverse\n        self.filename_pattern = args.filename_pattern\n        self.nthreads = args.nthreads\n        return (self.url, self.no_to_download, self.format_list,\n                self.download_path, self.min_filesize, self.max_filesize,\n                self.dump_urls, self.scrape_reverse, self.use_ghost, self.filename_pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_html(self):\n\n        if self.use_ghost:\n            self.url = urljoin(\"http://\", self.url)\n            import selenium\n            import selenium.webdriver\n            driver = selenium.webdriver.PhantomJS(\n                service_log_path=os.path.devnull)\n            driver.get(self.url)\n            page_html = driver.page_source\n            page_url = driver.current_url\n            driver.quit()\n        else:\n            if self.proxy_url:\n                print(\"Using proxy: \" + self.proxy_url + \"\\n\")\n            try:\n                page = requests.get(self.url, proxies=self.proxies)\n                if page.status_code != 200:\n                    raise PageLoadError(page.status_code)\n            except requests.exceptions.MissingSchema:\n                self.url = \"http://\" + self.url\n                page = requests.get(self.url, proxies=self.proxies)\n                if page.status_code != 200:\n                    raise PageLoadError(page.status_code)\n            except requests.exceptions.ConnectionError:\n                raise PageLoadError(None)\n            try:\n                page_html = page.text\n                page_url = page.url\n            except UnboundLocalError:\n                raise PageLoadError(None)\n\n        self.page_html = page_html\n        self.page_url = page_url\n        return (self.page_html, self.page_url)", "response": "Downloads the HTML content of the page given the page_url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget list of images from the page_html.", "response": "def get_img_list(self):\n        \"\"\" Gets list of images from the page_html. \"\"\"\n        tree = html.fromstring(self.page_html)\n        img = tree.xpath('//img/@src')\n        links = tree.xpath('//a/@href')\n        img_list = self.process_links(img)\n        img_links = self.process_links(links)\n        img_list.extend(img_links)\n\n        if self.filename_pattern:\n            # Compile pattern for efficiency\n            pattern = re.compile(self.filename_pattern)\n\n            # Verifies filename in the image URL matches pattern\n            def matches_pattern(img_url):\n                \"\"\" Function to check if pattern is matched. \"\"\"\n\n                img_filename = urlparse(img_url).path.split('/')[-1]\n                return pattern.search(img_filename)\n\n            images = [urljoin(self.url, img_url) for img_url in img_list\n                      if matches_pattern(img_url)]\n        else:\n            images = [urljoin(self.url, img_url) for img_url in img_list]\n\n        images = list(set(images))\n        self.images = images\n        if self.scrape_reverse:\n            self.images.reverse()\n        return self.images"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_download_path(self):\n        if os.path.exists(self.download_path):\n            if not os.access(self.download_path, os.W_OK):\n                raise DirectoryAccessError\n        elif os.access(os.path.dirname(self.download_path), os.W_OK):\n            os.makedirs(self.download_path)\n        else:\n            raise DirectoryCreateError\n        return True", "response": "Checks if the path exists and if it is a directory and if it is create it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload a single image.", "response": "def download_image(self, img_url):\n        \"\"\" Downloads a single image.\n\n            Downloads img_url using self.page_url as base.\n            Also, raises the appropriate exception if required.\n        \"\"\"\n        img_request = None\n        try:\n            img_request = requests.request(\n                'get', img_url, stream=True, proxies=self.proxies)\n            if img_request.status_code != 200:\n                raise ImageDownloadError(img_request.status_code)\n        except:\n            raise ImageDownloadError()\n\n        if img_url[-3:] == \"svg\" or (int(img_request.headers['content-length']) > self.min_filesize and\\\n                                     int(img_request.headers['content-length']) < self.max_filesize):\n            img_content = img_request.content\n            with open(os.path.join(self.download_path, img_url.split('/')[-1]), 'wb') as f:\n                byte_image = bytes(img_content)\n                f.write(byte_image)\n        else:\n            raise ImageSizeError(img_request.headers['content-length'])\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions to process the list of links and filter required links.", "response": "def process_links(self, links):\n        \"\"\" Function to process the list of links and filter required links.\"\"\"\n        links_list = []\n        for link in links:\n            if os.path.splitext(link)[1][1:].strip().lower() in self.format_list:\n                links_list.append(link)\n        return links_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, value):\n        \"Updates the progress bar to a new value.\"\n        if value <= 0.1:\n            value = 0\n        assert 0 <= value <= self.maxval\n        self.currval = value\n        if not self._need_update() or self.finished:\n            return\n        if not self.start_time:\n            self.start_time = time.time()\n        self.seconds_elapsed = time.time() - self.start_time\n        self.prev_percentage = self.percentage()\n        if value != self.maxval:\n            self.fd.write(self._format_line() + '\\r')\n        else:\n            self.finished = True\n            self.fd.write(self._format_line() + '\\n')", "response": "Updates the progress bar to a new value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef finish(self):\n        self.update(self.maxval)\n        if self.signal_set:\n            signal.signal(signal.SIGWINCH, signal.SIG_DFL)", "response": "Used to tell the progress is finished."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef console_main():\n    setproctitle('image-scraper')\n    scraper = ImageScraper()\n    scraper.get_arguments()\n    print(\"\\nImageScraper\\n============\\nRequesting page....\\n\")\n    try:\n        scraper.get_html()\n    except PageLoadError as err:\n        if err.status_code is None:\n            print(\"ImageScraper is unable to acces the internet.\")\n        else:\n            print(\"Page failed to load. Status code: {0}\".format(err.status_code))\n        sys.exit()\n\n    scraper.get_img_list()\n\n    if len(scraper.images) == 0:\n        sys.exit(\"Sorry, no images found.\")\n    if scraper.no_to_download is None:\n        scraper.no_to_download = len(scraper.images)\n\n    print(\"Found {0} images: \".format(len(scraper.images)))\n\n    try:\n        scraper.process_download_path()\n    except DirectoryAccessError:\n        print(\"Sorry, the directory can't be accessed.\")\n        sys.exit()\n    except DirectoryCreateError:\n        print(\"Sorry, the directory can't be created.\")\n        sys.exit()\n\n    if scraper.dump_urls:\n        for img_url in scraper.images:\n            print(img_url)\n\n    status_flags = {'count': 0, 'percent': 0.0, 'failed': 0, 'under_min_or_over_max_filesize': 0}\n    widgets = ['Progress: ', Percentage(), ' ', Bar(marker=RotatingMarker()),\n               ' ', ETA(), ' ', FileTransferSpeed()]\n    pbar = ProgressBar(widgets=widgets, maxval=100).start()\n    pool = ThreadPoolExecutor(max_workers=scraper.nthreads)\n    status_lock = threading.Lock()\n    for img_url in scraper.images:\n        if status_flags['count'] == scraper.no_to_download:\n            break\n        pool.submit(download_worker_fn, scraper, img_url, pbar, status_flags, status_lock)\n        status_flags['count'] += 1\n    pool.shutdown(wait=True)\n    pbar.finish()\n    print(\"\\nDone!\\nDownloaded {0} images\\nFailed: {1}\\n\".format(\n        status_flags['count']-status_flags['failed']-status_flags['under_min_or_over_max_filesize'],\n        status_flags['failed']))\n    return", "response": "This function handles all the console action."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(cls, raw):\n        msg = cls()\n        for line in raw.splitlines():\n            m = cls.sse_line_pattern.match(line)\n            if m is None:\n                # Malformed line.  Discard but warn.\n                warnings.warn('Invalid SSE line: \"%s\"' % line, SyntaxWarning)\n                continue\n\n            name = m.group('name')\n            if name == '':\n                # line began with a \":\", so is a comment.  Ignore\n                continue\n            value = m.group('value')\n\n            if name == 'data':\n                # If we already have some data, then join to it with a newline.\n                # Else this is it.\n                if msg.data:\n                    msg.data = '%s\\n%s' % (msg.data, value)\n                else:\n                    msg.data = value\n            elif name == 'event':\n                msg.event = value\n            elif name == 'id':\n                msg.id = value\n            elif name == 'retry':\n                msg.retry = int(value)\n\n        return msg", "response": "Given a possibly - multiline string representing an SSE message parse it\n            and return a Event object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a fresh branch from upstream master", "response": "def create_branch(version):\n    \"\"\"Create a fresh branch from upstream/master\"\"\"\n    repo = Repo.init(\".\")\n    if repo.is_dirty(untracked_files=True):\n        raise RuntimeError(f\"Repository is dirty, please commit/stash your changes.\")\n\n    branch_name = f\"release-{version}\"\n    print(f\"{Fore.CYAN}Create {branch_name} branch from upstream master\")\n    upstream = get_upstream(repo)\n    upstream.fetch()\n    release_branch = repo.create_head(branch_name, upstream.refs.master, force=True)\n    release_branch.checkout()\n    return repo"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_upstream(repo: Repo) -> Remote:\n    for remote in repo.remotes:\n        for url in remote.urls:\n            if url.endswith(\"pytest-dev/pluggy.git\"):\n                return remote\n    raise RuntimeError(\"could not find tox-dev/tox.git remote\")", "response": "Find upstream repository for pluggy on the remotes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pre_release(version):\n    create_branch(version)\n    changelog(version, write_out=True)\n\n    check_call([\"git\", \"commit\", \"-a\", \"-m\", f\"Preparing release {version}\"])\n\n    print()\n    print(f\"{Fore.GREEN}Please push your branch to your fork and open a PR.\")", "response": "Generates new docs release announcements and creates a local tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _wrapped_call(wrap_controller, func):\n    try:\n        next(wrap_controller)  # first yield\n    except StopIteration:\n        _raise_wrapfail(wrap_controller, \"did not yield\")\n    call_outcome = _Result.from_call(func)\n    try:\n        wrap_controller.send(call_outcome)\n        _raise_wrapfail(wrap_controller, \"has second yield\")\n    except StopIteration:\n        pass\n    return call_outcome.get_result()", "response": "Wrap calling to a function with a generator which needs to yield exactly once."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _multicall(hook_impls, caller_kwargs, firstresult=False):\n    __tracebackhide__ = True\n    results = []\n    excinfo = None\n    try:  # run impl and wrapper setup functions in a loop\n        teardowns = []\n        try:\n            for hook_impl in reversed(hook_impls):\n                try:\n                    args = [caller_kwargs[argname] for argname in hook_impl.argnames]\n                except KeyError:\n                    for argname in hook_impl.argnames:\n                        if argname not in caller_kwargs:\n                            raise HookCallError(\n                                \"hook call must provide argument %r\" % (argname,)\n                            )\n\n                if hook_impl.hookwrapper:\n                    try:\n                        gen = hook_impl.function(*args)\n                        next(gen)  # first yield\n                        teardowns.append(gen)\n                    except StopIteration:\n                        _raise_wrapfail(gen, \"did not yield\")\n                else:\n                    res = hook_impl.function(*args)\n                    if res is not None:\n                        results.append(res)\n                        if firstresult:  # halt further impl calls\n                            break\n        except BaseException:\n            excinfo = sys.exc_info()\n    finally:\n        if firstresult:  # first result hooks return a single value\n            outcome = _Result(results[0] if results else None, excinfo)\n        else:\n            outcome = _Result(results, excinfo)\n\n        # run all wrapper post-yield blocks\n        for gen in reversed(teardowns):\n            try:\n                gen.send(outcome)\n                _raise_wrapfail(gen, \"has second yield\")\n            except StopIteration:\n                pass\n\n        return outcome.get_result()", "response": "Execute a call into multiple python functions and return the resulting list of _Result objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef result(self):\n        msg = \"Use get_result() which forces correct exception handling\"\n        warnings.warn(DeprecationWarning(msg), stacklevel=2)\n        return self._result", "response": "Get the result for this hook call."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_result(self):\n        __tracebackhide__ = True\n        if self._excinfo is None:\n            return self._result\n        else:\n            ex = self._excinfo\n            if _py3:\n                raise ex[1].with_traceback(ex[2])\n            _reraise(*ex)", "response": "Get the result for this hook call."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(self, plugin, name=None):\n        plugin_name = name or self.get_canonical_name(plugin)\n\n        if plugin_name in self._name2plugin or plugin in self._plugin2hookcallers:\n            if self._name2plugin.get(plugin_name, -1) is None:\n                return  # blocked plugin, return None to indicate no registration\n            raise ValueError(\n                \"Plugin already registered: %s=%s\\n%s\"\n                % (plugin_name, plugin, self._name2plugin)\n            )\n\n        # XXX if an error happens we should make sure no state has been\n        # changed at point of return\n        self._name2plugin[plugin_name] = plugin\n\n        # register matching hook implementations of the plugin\n        self._plugin2hookcallers[plugin] = hookcallers = []\n        for name in dir(plugin):\n            hookimpl_opts = self.parse_hookimpl_opts(plugin, name)\n            if hookimpl_opts is not None:\n                normalize_hookimpl_opts(hookimpl_opts)\n                method = getattr(plugin, name)\n                hookimpl = HookImpl(plugin, plugin_name, method, hookimpl_opts)\n                hook = getattr(self.hook, name, None)\n                if hook is None:\n                    hook = _HookCaller(name, self._hookexec)\n                    setattr(self.hook, name, hook)\n                elif hook.has_spec():\n                    self._verify_hook(hook, hookimpl)\n                    hook._maybe_apply_history(hookimpl)\n                hook._add_hookimpl(hookimpl)\n                hookcallers.append(hook)\n        return plugin_name", "response": "Register a plugin and return its canonical name or None if the plugin is already registered."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unregister(self, plugin=None, name=None):\n        if name is None:\n            assert plugin is not None, \"one of name or plugin needs to be specified\"\n            name = self.get_name(plugin)\n\n        if plugin is None:\n            plugin = self.get_plugin(name)\n\n        # if self._name2plugin[name] == None registration was blocked: ignore\n        if self._name2plugin.get(name):\n            del self._name2plugin[name]\n\n        for hookcaller in self._plugin2hookcallers.pop(plugin, []):\n            hookcaller._remove_plugin(plugin)\n\n        return plugin", "response": "unregister a plugin object and all its contained hook implementations\n        from internal data structures."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nblock registrations of the given name unregister if already registered.", "response": "def set_blocked(self, name):\n        \"\"\" block registrations of the given name, unregister if already registered. \"\"\"\n        self.unregister(name=name)\n        self._name2plugin[name] = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds new hook specifications defined in the given module_or_class.", "response": "def add_hookspecs(self, module_or_class):\n        \"\"\" add new hook specifications defined in the given module_or_class.\n        Functions are recognized if they have been decorated accordingly. \"\"\"\n        names = []\n        for name in dir(module_or_class):\n            spec_opts = self.parse_hookspec_opts(module_or_class, name)\n            if spec_opts is not None:\n                hc = getattr(self.hook, name, None)\n                if hc is None:\n                    hc = _HookCaller(name, self._hookexec, module_or_class, spec_opts)\n                    setattr(self.hook, name, hc)\n                else:\n                    # plugins registered this hook without knowing the spec\n                    hc.set_specification(module_or_class, spec_opts)\n                    for hookfunction in hc.get_hookimpls():\n                        self._verify_hook(hc, hookfunction)\n                names.append(name)\n\n        if not names:\n            raise ValueError(\n                \"did not find any %r hooks in %r\" % (self.project_name, module_or_class)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the name of the given plugin or None if not registered.", "response": "def get_name(self, plugin):\n        \"\"\" Return name for registered plugin or None if not registered. \"\"\"\n        for name, val in self._name2plugin.items():\n            if plugin == val:\n                return name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify that all hooks which have not been verified against a hook specification are optional.", "response": "def check_pending(self):\n        \"\"\" Verify that all hooks which have not been verified against\n        a hook specification are optional, otherwise raise PluginValidationError\"\"\"\n        for name in self.hook.__dict__:\n            if name[0] != \"_\":\n                hook = getattr(self.hook, name)\n                if not hook.has_spec():\n                    for hookimpl in hook.get_hookimpls():\n                        if not hookimpl.optionalhook:\n                            raise PluginValidationError(\n                                hookimpl.plugin,\n                                \"unknown hook %r in plugin %r\"\n                                % (name, hookimpl.plugin),\n                            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads modules from querying the specified setuptools group.", "response": "def load_setuptools_entrypoints(self, group, name=None):\n        \"\"\" Load modules from querying the specified setuptools ``group``.\n\n        :param str group: entry point group to load plugins\n        :param str name: if given, loads only plugins with the given ``name``.\n        :rtype: int\n        :return: return the number of loaded plugins by this call.\n        \"\"\"\n        from pkg_resources import (\n            iter_entry_points,\n            DistributionNotFound,\n            VersionConflict,\n        )\n\n        count = 0\n        for ep in iter_entry_points(group, name=name):\n            # is the plugin registered or blocked?\n            if self.get_plugin(ep.name) or self.is_blocked(ep.name):\n                continue\n            try:\n                plugin = ep.load()\n            except DistributionNotFound:\n                continue\n            except VersionConflict as e:\n                raise PluginValidationError(\n                    plugin=None,\n                    message=\"Plugin %r could not be loaded: %s!\" % (ep.name, e),\n                )\n            self.register(plugin, name=ep.name)\n            self._plugin_distinfo.append((plugin, ep.dist))\n            count += 1\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_hookcall_monitoring(self, before, after):\n        return _tracing._TracedHookExecution(self, before, after).undo", "response": "add before and after functions for all hooks\n        and return an undo function which when called will remove the added tracers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nenabling tracing of hook calls and return an undo function.", "response": "def enable_tracing(self):\n        \"\"\" enable tracing of hook calls and return an undo function. \"\"\"\n        hooktrace = self.hook._trace\n\n        def before(hook_name, methods, kwargs):\n            hooktrace.root.indent += 1\n            hooktrace(hook_name, kwargs)\n\n        def after(outcome, hook_name, methods, kwargs):\n            if outcome.excinfo is None:\n                hooktrace(\"finish\", hook_name, \"-->\", outcome.get_result())\n            hooktrace.root.indent -= 1\n\n        return self.add_hookcall_monitoring(before, after)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new _HookCaller instance for the named method which manages calls to all registered plugins except the ones from remove_plugins.", "response": "def subset_hook_caller(self, name, remove_plugins):\n        \"\"\" Return a new _HookCaller instance for the named method\n        which manages calls to all registered plugins except the\n        ones from remove_plugins. \"\"\"\n        orig = getattr(self.hook, name)\n        plugins_to_remove = [plug for plug in remove_plugins if hasattr(plug, name)]\n        if plugins_to_remove:\n            hc = _HookCaller(\n                orig.name, orig._hookexec, orig.spec.namespace, orig.spec.opts\n            )\n            for hookimpl in orig.get_hookimpls():\n                plugin = hookimpl.plugin\n                if plugin not in plugins_to_remove:\n                    hc._add_hookimpl(hookimpl)\n                    # we also keep track of this hook caller so it\n                    # gets properly removed on plugin unregistration\n                    self._plugin2hookcallers.setdefault(plugin, []).append(hc)\n            return hc\n        return orig"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns tuple of positional and keywrord argument names for a function method class or callable object.", "response": "def varnames(func):\n    \"\"\"Return tuple of positional and keywrord argument names for a function,\n    method, class or callable.\n\n    In case of a class, its ``__init__`` method is considered.\n    For methods the ``self`` parameter is not included.\n    \"\"\"\n    cache = getattr(func, \"__dict__\", {})\n    try:\n        return cache[\"_varnames\"]\n    except KeyError:\n        pass\n\n    if inspect.isclass(func):\n        try:\n            func = func.__init__\n        except AttributeError:\n            return (), ()\n    elif not inspect.isroutine(func):  # callable object?\n        try:\n            func = getattr(func, \"__call__\", func)\n        except Exception:\n            return ()\n\n    try:  # func MUST be a function or method here or we won't parse any args\n        spec = _getargspec(func)\n    except TypeError:\n        return (), ()\n\n    args, defaults = tuple(spec.args), spec.defaults\n    if defaults:\n        index = -len(defaults)\n        args, defaults = args[:index], tuple(args[index:])\n    else:\n        defaults = ()\n\n    # strip any implicit instance arg\n    # pypy3 uses \"obj\" instead of \"self\" for default dunder methods\n    implicit_names = (\"self\",) if not _PYPY3 else (\"self\", \"obj\")\n    if args:\n        if inspect.ismethod(func) or (\n            \".\" in getattr(func, \"__qualname__\", ()) and args[0] in implicit_names\n        ):\n            args = args[1:]\n\n    try:\n        cache[\"_varnames\"] = args, defaults\n    except TypeError:\n        pass\n    return args, defaults"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_hookimpl(self, hookimpl):\n        if hookimpl.hookwrapper:\n            methods = self._wrappers\n        else:\n            methods = self._nonwrappers\n\n        if hookimpl.trylast:\n            methods.insert(0, hookimpl)\n        elif hookimpl.tryfirst:\n            methods.append(hookimpl)\n        else:\n            # find last non-tryfirst method\n            i = len(methods) - 1\n            while i >= 0 and methods[i].tryfirst:\n                i -= 1\n            methods.insert(i + 1, hookimpl)\n\n        if \"__multicall__\" in hookimpl.argnames:\n            warnings.warn(\n                \"Support for __multicall__ is now deprecated and will be\"\n                \"removed in an upcoming release.\",\n                DeprecationWarning,\n            )\n            self.multicall = _legacymulticall", "response": "Add an implementation to the callback chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall the hook with given kwargs and return the result of the hook.", "response": "def call_historic(self, result_callback=None, kwargs=None, proc=None):\n        \"\"\"Call the hook with given ``kwargs`` for all registered plugins and\n        for all plugins which will be registered afterwards.\n\n        If ``result_callback`` is not ``None`` it will be called for for each\n        non-None result obtained from a hook implementation.\n\n        .. note::\n            The ``proc`` argument is now deprecated.\n        \"\"\"\n        if proc is not None:\n            warnings.warn(\n                \"Support for `proc` argument is now deprecated and will be\"\n                \"removed in an upcoming release.\",\n                DeprecationWarning,\n            )\n            result_callback = proc\n\n        self._call_history.append((kwargs or {}, result_callback))\n        # historizing hooks don't return results\n        res = self._hookexec(self, self.get_hookimpls(), kwargs)\n        if result_callback is None:\n            return\n        # XXX: remember firstresult isn't compat with historic\n        for x in res or []:\n            result_callback(x)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef call_extra(self, methods, kwargs):\n        old = list(self._nonwrappers), list(self._wrappers)\n        for method in methods:\n            opts = dict(hookwrapper=False, trylast=False, tryfirst=False)\n            hookimpl = HookImpl(None, \"<temp>\", method, opts)\n            self._add_hookimpl(hookimpl)\n        try:\n            return self(**kwargs)\n        finally:\n            self._nonwrappers, self._wrappers = old", "response": "Call the hook with some additional temporarily participating\n        methods using the specified kwargs as call parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _maybe_apply_history(self, method):\n        if self.is_historic():\n            for kwargs, result_callback in self._call_history:\n                res = self._hookexec(self, [method], kwargs)\n                if res and result_callback is not None:\n                    result_callback(res[0])", "response": "Apply call history to a new hookimpl if it is marked as historic."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps the handlers in the given Logger with a MultiProcessingHandler.", "response": "def install_mp_handler(logger=None):\n    \"\"\"Wraps the handlers in the given Logger with an MultiProcessingHandler.\n\n    :param logger: whose handlers to wrap. By default, the root logger.\n    \"\"\"\n    if logger is None:\n        logger = logging.getLogger()\n\n    for i, orig_handler in enumerate(list(logger.handlers)):\n        handler = MultiProcessingHandler(\n            'mp-handler-{0}'.format(i), sub_handler=orig_handler)\n\n        logger.removeHandler(orig_handler)\n        logger.addHandler(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_version(new_version_number=None, old_version_number=''):\n    if new_version_number is None:\n        return ValueError\n\n    import fileinput\n    import sys\n\n    file = join('timezonefinder', '__init__.py')\n\n    for line in fileinput.input(file, inplace=1):\n        if old_version_number in line:\n            line = line.replace(old_version_number, new_version_number)\n        sys.stdout.write(line)", "response": "Set package version as listed in __version__ in __init__. py."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of polygon representation of the current timezone.", "response": "def get_geometry(self, tz_name='', tz_id=0, use_id=False, coords_as_pairs=False):\n        '''\n        :param tz_name: one of the names in timezone_names\n        :param tz_id: the id of the timezone (=index in timezone_names)\n        :param use_id: determines whether id or name should be used\n        :param coords_as_pairs: determines the structure of the polygon representation\n        :return: a data structure representing the multipolygon of this timezone\n        output format: [ [polygon1, hole1, hole2...], [polygon2, ...], ...]\n         and each polygon and hole is itself formated like: ([longitudes], [latitudes])\n         or [(lng1,lat1), (lng2,lat2),...] if ``coords_as_pairs=True``.\n        '''\n\n        if use_id:\n            zone_id = tz_id\n        else:\n            try:\n                zone_id = timezone_names.index(tz_name)\n            except ValueError:\n                raise ValueError(\"The timezone '\", tz_name, \"' does not exist.\")\n\n        self.poly_nr2zone_id.seek(NR_BYTES_H * zone_id)\n        # read poly_nr of the first polygon of that zone\n        first_polygon_nr = unpack(DTYPE_FORMAT_H, self.poly_nr2zone_id.read(NR_BYTES_H))[0]\n        # read poly_nr of the first polygon of the next zone\n        last_polygon_nr = unpack(DTYPE_FORMAT_H, self.poly_nr2zone_id.read(NR_BYTES_H))[0]\n        poly_nrs = list(range(first_polygon_nr, last_polygon_nr))\n        return [self.get_polygon(poly_nr, coords_as_pairs) for poly_nr in poly_nrs]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of zone_ids for all entries in the list", "response": "def id_list(self, polygon_id_list, nr_of_polygons):\n        \"\"\"\n        :param polygon_id_list:\n        :param nr_of_polygons: length of polygon_id_list\n        :return: (list of zone_ids, boolean: do all entries belong to the same zone)\n        \"\"\"\n        zone_id_list = empty([nr_of_polygons], dtype=DTYPE_FORMAT_H_NUMPY)\n        for pointer_local, polygon_id in enumerate(polygon_id_list):\n            zone_id = self.id_of(polygon_id)\n            zone_id_list[pointer_local] = zone_id\n\n        return zone_id_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile_id_list(self, polygon_id_list, nr_of_polygons):\n\n        # TODO functional\n        def all_equal(iterable):\n            x = None\n            for x in iterable:\n                # first_val = x\n                break\n            for y in iterable:\n                if x != y:\n                    return False\n            return True\n\n        zone_id_list = empty([nr_of_polygons], dtype=DTYPE_FORMAT_H_NUMPY)\n        counted_zones = {}\n        for pointer_local, polygon_id in enumerate(polygon_id_list):\n            zone_id = self.id_of(polygon_id)\n            zone_id_list[pointer_local] = zone_id\n            try:\n                counted_zones[zone_id] += 1\n            except KeyError:\n                counted_zones[zone_id] = 1\n\n        if len(counted_zones) == 1:\n            # there is only one zone. no sorting needed.\n            return polygon_id_list, zone_id_list, True\n\n        if all_equal(list(counted_zones.values())):\n            # all the zones have the same amount of polygons. no sorting needed.\n            return polygon_id_list, zone_id_list, False\n\n        counted_zones_sorted = sorted(list(counted_zones.items()), key=lambda zone: zone[1])\n        sorted_polygon_id_list = empty([nr_of_polygons], dtype=DTYPE_FORMAT_H_NUMPY)\n        sorted_zone_id_list = empty([nr_of_polygons], dtype=DTYPE_FORMAT_H_NUMPY)\n\n        pointer_output = 0\n        for zone_id, amount in counted_zones_sorted:\n            # write all polygons from this zone in the new list\n            pointer_local = 0\n            detected_polygons = 0\n            while detected_polygons < amount:\n                if zone_id_list[pointer_local] == zone_id:\n                    # the polygon at the pointer has the wanted zone_id\n                    detected_polygons += 1\n                    sorted_polygon_id_list[pointer_output] = polygon_id_list[pointer_local]\n                    sorted_zone_id_list[pointer_output] = zone_id\n                    pointer_output += 1\n\n                pointer_local += 1\n\n        return sorted_polygon_id_list, sorted_zone_id_list, False", "response": "compiles the list of polygon ids into a list of zone ids."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef certain_timezone_at(self, *, lng, lat):\n\n        lng, lat = rectify_coordinates(lng, lat)\n        shortcut_id_x, shortcut_id_y = coord2shortcut(lng, lat)\n        possible_polygons = self.polygon_ids_of_shortcut(shortcut_id_x, shortcut_id_y)\n\n        # x = longitude  y = latitude  both converted to 8byte int\n        x = coord2int(lng)\n        y = coord2int(lat)\n\n        # check if the point is actually included in one of the polygons\n        for polygon_nr in possible_polygons:\n\n            # get boundaries\n            self.poly_max_values.seek(4 * NR_BYTES_I * polygon_nr)\n            boundaries = self.fromfile(self.poly_max_values, dtype=DTYPE_FORMAT_SIGNED_I_NUMPY, count=4)\n            if not (x > boundaries[0] or x < boundaries[1] or y > boundaries[2] or y < boundaries[3]):\n\n                outside_all_holes = True\n                # when the point is within a hole of the polygon this timezone doesn't need to be checked\n                for hole_coordinates in self._holes_of_line(polygon_nr):\n                    if inside_polygon(x, y, hole_coordinates):\n                        outside_all_holes = False\n                        break\n\n                if outside_all_holes:\n                    if inside_polygon(x, y, self.coords_of(line=polygon_nr)):\n                        return timezone_names[self.id_of(polygon_nr)]\n\n        # no polygon has been matched\n        return None", "response": "This function looks up in which polygon the point certainly is included in the system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_offset(target):\n    from pytz import timezone\n    import pytz\n    from datetime import datetime\n\n    utc = pytz.utc\n\n    today = datetime.now()\n    tz_target = timezone(tf.certain_timezone_at(lat=target['lat'], lng=target['lng']))\n    # ATTENTION: tz_target could be None! handle error case\n    today_target = tz_target.localize(today)\n    today_utc = utc.localize(today)\n    return (today_utc - today_target).total_seconds() / 60", "response": "Returns a location s time zone offset from UTC in minutes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inside_polygon(x, y, coordinates):\n    contained = False\n    # the edge from the last to the first point is checked first\n    i = -1\n    y1 = coordinates[1][-1]\n    y_gt_y1 = y > y1\n    for y2 in coordinates[1]:\n        y_gt_y2 = y > y2\n        if y_gt_y1:\n            if not y_gt_y2:\n                x1 = coordinates[0][i]\n                x2 = coordinates[0][i + 1]\n                # only crossings \"right\" of the point should be counted\n                x1GEx = x <= x1\n                x2GEx = x <= x2\n                # compare the slope of the line [p1-p2] and [p-p2]\n                # depending on the position of p2 this determines whether the polygon edge is right or left of the point\n                # to avoid expensive division the divisors (of the slope dy/dx) are brought to the other side\n                # ( dy/dx > a  ==  dy > a * dx )\n                # int64 accuracy needed here!\n                if (x1GEx and x2GEx) or ((x1GEx or x2GEx)\n                                         and (int64(y2) - int64(y)) * (int64(x2) - int64(x1)) <= (\n                                             int64(y2) - int64(y1)) * (int64(x2) - int64(x))):\n                    contained = not contained\n\n        else:\n            if y_gt_y2:\n                x1 = coordinates[0][i]\n                x2 = coordinates[0][i + 1]\n                # only crossings \"right\" of the point should be counted\n                x1GEx = x <= x1\n                x2GEx = x <= x2\n                if (x1GEx and x2GEx) or ((x1GEx or x2GEx)\n                                         and (int64(y2) - int64(y)) * (int64(x2) - int64(x1)) >= (\n                                             int64(y2) - int64(y1)) * (int64(x2) - int64(x))):\n                    contained = not contained\n\n        y1 = y2\n        y_gt_y1 = y_gt_y2\n        i += 1\n\n    return contained", "response": "Returns True if the point x y lies within the polygon."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the first element in the list that is the same as the passed in element.", "response": "def all_the_same(pointer, length, id_list):\n    \"\"\"\n    :param pointer: starting from that element the list is being checked for equality of its elements\n    :param length:\n    :param id_list: List mustn't be empty or Null. There has to be at least one element\n    :return: returns the first encountered element if starting from the pointer all elements are the same,\n     otherwise it returns -1\n    \"\"\"\n    element = id_list[pointer]\n    pointer += 1\n    while pointer < length:\n        if element != id_list[pointer]:\n            return -1\n        pointer += 1\n    return element"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef distance_to_point_on_equator(lng_rad, lat_rad, lng_rad_p1):\n    # 2* for the distance in rad and * 12742 (mean diameter of earth) for the distance in km\n    return 12742 * asin(sqrt(((sin(lat_rad / 2)) ** 2 + cos(lat_rad) * (sin((lng_rad - lng_rad_p1) / 2)) ** 2)))", "response": "Calculates the distance between the point and p1 on the Kalman filter"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the Haversine distance between two points in the Knockout system.", "response": "def haversine(lng_p1, lat_p1, lng_p2, lat_p2):\n    \"\"\"\n    :param lng_p1: the longitude of point 1 in radians\n    :param lat_p1: the latitude of point 1 in radians\n    :param lng_p2: the longitude of point 1 in radians\n    :param lat_p2: the latitude of point 1 in radians\n    :return: distance between p1 and p2 in km\n    this is only an approximation since the earth is not a real sphere\n    \"\"\"\n    # 2* for the distance in rad and * 12742(mean diameter of earth) for the distance in km\n    return 12742 * asin(\n        sqrt(((sin((lat_p1 - lat_p2) / 2)) ** 2 + cos(lat_p2) * cos(lat_p1) * (sin((lng_p1 - lng_p2) / 2)) ** 2)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the minimum distance between two points in a polygon section.", "response": "def compute_min_distance(lng_rad, lat_rad, p0_lng, p0_lat, pm1_lng, pm1_lat, p1_lng, p1_lat):\n    \"\"\"\n    :param lng_rad: lng of px in radians\n    :param lat_rad: lat of px in radians\n    :param p0_lng: lng of p0 in radians\n    :param p0_lat: lat of p0 in radians\n    :param pm1_lng: lng of pm1 in radians\n    :param pm1_lat: lat of pm1 in radians\n    :param p1_lng: lng of p1 in radians\n    :param p1_lat: lat of p1 in radians\n    :return: shortest distance between pX and the polygon section (pm1---p0---p1) in radians\n    \"\"\"\n\n    # rotate coordinate system (= all the points) so that p0 would have lat_rad=lng_rad=0 (=origin)\n    # z rotation is simply subtracting the lng_rad\n    # convert the points to the cartesian coordinate system\n    px_cartesian = coords2cartesian(lng_rad - p0_lng, lat_rad)\n    p1_cartesian = coords2cartesian(p1_lng - p0_lng, p1_lat)\n    pm1_cartesian = coords2cartesian(pm1_lng - p0_lng, pm1_lat)\n\n    px_cartesian = y_rotate(p0_lat, px_cartesian)\n    p1_cartesian = y_rotate(p0_lat, p1_cartesian)\n    pm1_cartesian = y_rotate(p0_lat, pm1_cartesian)\n\n    # for both p1 and pm1 separately do:\n\n    # rotate coordinate system so that this point also has lat_p1_rad=0 and lng_p1_rad>0 (p0 does not change!)\n    rotation_rad = atan2(p1_cartesian[2], p1_cartesian[1])\n    p1_cartesian = x_rotate(rotation_rad, p1_cartesian)\n    lng_p1_rad = atan2(p1_cartesian[1], p1_cartesian[0])\n    px_retrans_rad = cartesian2rad(*x_rotate(rotation_rad, px_cartesian))\n\n    # if lng_rad of px is between 0 (<-point1) and lng_rad of point 2:\n    # the distance between point x and the 'equator' is the shortest\n    # if the point is not between p0 and p1 the distance to the closest of the two points should be used\n    # so clamp/clip the lng_rad of px to the interval of [0; lng_rad p1] and compute the distance with it\n    temp_distance = distance_to_point_on_equator(px_retrans_rad[0], px_retrans_rad[1],\n                                                 max(min(px_retrans_rad[0], lng_p1_rad), 0))\n\n    # ATTENTION: vars are being reused. p1 is actually pm1 here!\n    rotation_rad = atan2(pm1_cartesian[2], pm1_cartesian[1])\n    p1_cartesian = x_rotate(rotation_rad, pm1_cartesian)\n    lng_p1_rad = atan2(p1_cartesian[1], p1_cartesian[0])\n    px_retrans_rad = cartesian2rad(*x_rotate(rotation_rad, px_cartesian))\n\n    return min(temp_distance, distance_to_point_on_equator(px_retrans_rad[0], px_retrans_rad[1],\n                                                           max(min(px_retrans_rad[0], lng_p1_rad), 0)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget result for specified stream_id", "response": "def get_notification_result(self, stream_id):\n        \"\"\"\n        Get result for specified stream\n        The function returns: 'Success' or 'failure reason' or ('Unregistered', timestamp)\n        \"\"\"\n        with self._connection.get_response(stream_id) as response:\n            if response.status == 200:\n                return 'Success'\n            else:\n                raw_data = response.read().decode('utf-8')\n                data = json.loads(raw_data)\n                if response.status == 410:\n                    return data['reason'], data['timestamp']\n                else:\n                    return data['reason']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a notification to a list of tokens in batch.", "response": "def send_notification_batch(self, notifications, topic=None, priority=NotificationPriority.Immediate,\n                                expiration=None, collapse_id=None):\n        \"\"\"\n        Send a notification to a list of tokens in batch. Instead of sending a synchronous request\n        for each token, send multiple requests concurrently. This is done on the same connection,\n        using HTTP/2 streams (one request per stream).\n\n        APNs allows many streams simultaneously, but the number of streams can vary depending on\n        server load. This method reads the SETTINGS frame sent by the server to figure out the\n        maximum number of concurrent streams. Typically, APNs reports a maximum of 500.\n\n        The function returns a dictionary mapping each token to its result. The result is \"Success\"\n        if the token was sent successfully, or the string returned by APNs in the 'reason' field of\n        the response, if the token generated an error.\n        \"\"\"\n        notification_iterator = iter(notifications)\n        next_notification = next(notification_iterator, None)\n        # Make sure we're connected to APNs, so that we receive and process the server's SETTINGS\n        # frame before starting to send notifications.\n        self.connect()\n\n        results = {}\n        open_streams = collections.deque()\n        # Loop on the tokens, sending as many requests as possible concurrently to APNs.\n        # When reaching the maximum concurrent streams limit, wait for a response before sending\n        # another request.\n        while len(open_streams) > 0 or next_notification is not None:\n            # Update the max_concurrent_streams on every iteration since a SETTINGS frame can be\n            # sent by the server at any time.\n            self.update_max_concurrent_streams()\n            if self.should_send_notification(next_notification, open_streams):\n                logger.info('Sending to token %s', next_notification.token)\n                stream_id = self.send_notification_async(next_notification.token, next_notification.payload, topic,\n                                                         priority, expiration, collapse_id)\n                open_streams.append(RequestStream(stream_id, next_notification.token))\n\n                next_notification = next(notification_iterator, None)\n                if next_notification is None:\n                    # No tokens remaining. Proceed to get results for pending requests.\n                    logger.info('Finished sending all tokens, waiting for pending requests.')\n            else:\n                # We have at least one request waiting for response (otherwise we would have either\n                # sent new requests or exited the while loop.) Wait for the first outstanding stream\n                # to return a response.\n                pending_stream = open_streams.popleft()\n                result = self.get_notification_result(pending_stream.stream_id)\n                logger.info('Got response for %s: %s', pending_stream.token, result)\n                results[pending_stream.token] = result\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(self):\n        retries = 0\n        while retries < MAX_CONNECTION_RETRIES:\n            try:\n                self._connection.connect()\n                logger.info('Connected to APNs')\n                return\n            except Exception:  # pylint: disable=broad-except\n                # close the connnection, otherwise next connect() call would do nothing\n                self._connection.close()\n                retries += 1\n                logger.exception('Failed connecting to APNs (attempt %s of %s)', retries, MAX_CONNECTION_RETRIES)\n\n        raise ConnectionFailed()", "response": "Establish a connection to APNs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_raw(source, bitarray):\n        ''' Get raw data as integer, based on offset and size '''\n        offset = int(source['offset'])\n        size = int(source['size'])\n        return int(''.join(['1' if digit else '0' for digit in bitarray[offset:offset + size]]), 2)", "response": "Get raw data as integer based on offset and size"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_raw(target, raw_value, bitarray):\n        ''' put value into bit array '''\n        offset = int(target['offset'])\n        size = int(target['size'])\n        for digit in range(size):\n            bitarray[offset+digit] = (raw_value >> (size-digit-1)) & 0x01 != 0\n        return bitarray", "response": "put value into bitarray"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the value of the key from the XML data in the source XML element", "response": "def _get_value(self, source, bitarray):\n        ''' Get value, based on the data in XML '''\n        raw_value = self._get_raw(source, bitarray)\n\n        rng = source.find('range')\n        rng_min = float(rng.find('min').text)\n        rng_max = float(rng.find('max').text)\n\n        scl = source.find('scale')\n        scl_min = float(scl.find('min').text)\n        scl_max = float(scl.find('max').text)\n\n        return {\n            source['shortcut']: {\n                'description': source.get('description'),\n                'unit': source['unit'],\n                'value': (scl_max - scl_min) / (rng_max - rng_min) * (raw_value - rng_min) + scl_min,\n                'raw_value': raw_value,\n            }\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_enum(self, source, bitarray):\n        ''' Get enum value, based on the data in XML '''\n        raw_value = self._get_raw(source, bitarray)\n\n        # Find value description.\n        value_desc = source.find('item', {'value': str(raw_value)}) or self._get_rangeitem(source, raw_value)\n\n        return {\n            source['shortcut']: {\n                'description': source.get('description'),\n                'unit': source.get('unit', ''),\n                'value': value_desc['description'].format(value=raw_value),\n                'raw_value': raw_value,\n            }\n        }", "response": "Get the enum value based on the data in XML"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget boolean value based on the data in XML", "response": "def _get_boolean(self, source, bitarray):\n        ''' Get boolean value, based on the data in XML '''\n        raw_value = self._get_raw(source, bitarray)\n        return {\n            source['shortcut']: {\n                'description': source.get('description'),\n                'unit': source.get('unit', ''),\n                'value': True if raw_value else False,\n                'raw_value': raw_value,\n            }\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset given numeric value to target field in bitarray", "response": "def _set_value(self, target, value, bitarray):\n        ''' set given numeric value to target field in bitarray '''\n        # derive raw value\n        rng = target.find('range')\n        rng_min = float(rng.find('min').text)\n        rng_max = float(rng.find('max').text)\n        scl = target.find('scale')\n        scl_min = float(scl.find('min').text)\n        scl_max = float(scl.find('max').text)\n        raw_value = (value - scl_min) * (rng_max - rng_min) / (scl_max - scl_min) + rng_min\n        # store value in bitfield\n        return self._set_raw(target, int(raw_value), bitarray)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset given enum value to target field in bitarray", "response": "def _set_enum(self, target, value, bitarray):\n        ''' set given enum value (by string or integer value) to target field in bitarray '''\n        # derive raw value\n        if isinstance(value, int):\n            # check whether this value exists\n            if target.find('item', {'value': value}) or self._get_rangeitem(target, value):\n                # set integer values directly\n                raw_value = value\n            else:\n                raise ValueError('Enum value \"%s\" not found in EEP.' % (value))\n        else:\n            value_item = target.find('item', {'description': value})\n            if value_item is None:\n                raise ValueError('Enum description for value \"%s\" not found in EEP.' % (value))\n            raw_value = int(value_item['value'])\n        return self._set_raw(target, raw_value, bitarray)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the profile and data description matching RORG FUNC and TYPE.", "response": "def find_profile(self, bitarray, eep_rorg, rorg_func, rorg_type, direction=None, command=None):\n        ''' Find profile and data description, matching RORG, FUNC and TYPE '''\n        if not self.init_ok:\n            self.logger.warn('EEP.xml not loaded!')\n            return None\n\n        if eep_rorg not in self.telegrams.keys():\n            self.logger.warn('Cannot find rorg in EEP!')\n            return None\n\n        if rorg_func not in self.telegrams[eep_rorg].keys():\n            self.logger.warn('Cannot find func in EEP!')\n            return None\n\n        if rorg_type not in self.telegrams[eep_rorg][rorg_func].keys():\n            self.logger.warn('Cannot find type in EEP!')\n            return None\n\n        profile = self.telegrams[eep_rorg][rorg_func][rorg_type]\n\n        if command:\n            # multiple commands can be defined, with the command id always in same location (per RORG-FUNC-TYPE).\n            eep_command = profile.find('command', recursive=False)\n            # If commands are not set in EEP, or command is None,\n            # get the first data as a \"best guess\".\n            if not eep_command:\n                return profile.find('data', recursive=False)\n\n            # If eep_command is defined, so should be data.command\n            return profile.find('data', {'command': str(command)}, recursive=False)\n\n        # extract data description\n        # the direction tag is optional\n        if direction is None:\n            return profile.find('data', recursive=False)\n        return profile.find('data', {'direction': direction}, recursive=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_values(self, profile, bitarray, status):\n        ''' Get keys and values from bitarray '''\n        if not self.init_ok or profile is None:\n            return [], {}\n\n        output = OrderedDict({})\n        for source in profile.contents:\n            if not source.name:\n                continue\n            if source.name == 'value':\n                output.update(self._get_value(source, bitarray))\n            if source.name == 'enum':\n                output.update(self._get_enum(source, bitarray))\n            if source.name == 'status':\n                output.update(self._get_boolean(source, status))\n        return output.keys(), output", "response": "Get keys and values from bitarray"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_values(self, profile, data, status, properties):\n        ''' Update data based on data contained in properties '''\n        if not self.init_ok or profile is None:\n            return data, status\n\n        for shortcut, value in properties.items():\n            # find the given property from EEP\n            target = profile.find(shortcut=shortcut)\n            if not target:\n                # TODO: Should we raise an error?\n                self.logger.warning('Cannot find data description for shortcut %s', shortcut)\n                continue\n\n            # update bit_data\n            if target.name == 'value':\n                data = self._set_value(target, value, data)\n            if target.name == 'enum':\n                data = self._set_enum(target, value, data)\n            if target.name == 'status':\n                status = self._set_boolean(target, value, status)\n        return data, status", "response": "Update data based on data contained in properties"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef combine_hex(data):\n    ''' Combine list of integer values to one big integer '''\n    output = 0x00\n    for i, value in enumerate(reversed(data)):\n        output |= (value << i * 8)\n    return output", "response": "Combine list of integer values to one big integer"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts data to bitarray", "response": "def to_bitarray(data, width=8):\n    ''' Convert data (list of integers, bytearray or integer) to bitarray '''\n    if isinstance(data, list) or isinstance(data, bytearray):\n        data = combine_hex(data)\n    return [True if digit == '1' else False for digit in bin(data)[2:].zfill(width)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_hex_string(data):\n    ''' Convert list of integers to a hex string, separated by \":\" '''\n    if isinstance(data, int):\n        return '%02X' % data\n    return ':'.join([('%02X' % o) for o in data])", "response": "Convert a list of integers to a hex string separated by \":\""}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a message from buffer and returns a tuple of the message and packet.", "response": "def parse_msg(buf):\n        '''\n        Parses message from buffer.\n        returns:\n            - PARSE_RESULT\n            - remaining buffer\n            - Packet -object (if message was valid, else None)\n        '''\n        # If the buffer doesn't contain 0x55 (start char)\n        # the message isn't needed -> ignore\n        if 0x55 not in buf:\n            return PARSE_RESULT.INCOMPLETE, [], None\n\n        # Valid buffer starts from 0x55\n        # Convert to list, as index -method isn't defined for bytearray\n        buf = [ord(x) if not isinstance(x, int) else x for x in buf[list(buf).index(0x55):]]\n        try:\n            data_len = (buf[1] << 8) | buf[2]\n            opt_len = buf[3]\n        except IndexError:\n            # If the fields don't exist, message is incomplete\n            return PARSE_RESULT.INCOMPLETE, buf, None\n\n        # Header: 6 bytes, data, optional data and data checksum\n        msg_len = 6 + data_len + opt_len + 1\n        if len(buf) < msg_len:\n            # If buffer isn't long enough, the message is incomplete\n            return PARSE_RESULT.INCOMPLETE, buf, None\n\n        msg = buf[0:msg_len]\n        buf = buf[msg_len:]\n\n        packet_type = msg[4]\n        data = msg[6:6 + data_len]\n        opt_data = msg[6 + data_len:6 + data_len + opt_len]\n\n        # Check CRCs for header and data\n        if msg[5] != crc8.calc(msg[1:5]):\n            # Fail if doesn't match message\n            Packet.logger.error('Header CRC error!')\n            # Return CRC_MISMATCH\n            return PARSE_RESULT.CRC_MISMATCH, buf, None\n        if msg[6 + data_len + opt_len] != crc8.calc(msg[6:6 + data_len + opt_len]):\n            # Fail if doesn't match message\n            Packet.logger.error('Data CRC error!')\n            # Return CRC_MISMATCH\n            return PARSE_RESULT.CRC_MISMATCH, buf, None\n\n        # If we got this far, everything went ok (?)\n        if packet_type == PACKET.RADIO_ERP1:\n            # Need to handle UTE Teach-in here, as it's a separate packet type...\n            if data[0] == RORG.UTE:\n                packet = UTETeachInPacket(packet_type, data, opt_data)\n            else:\n                packet = RadioPacket(packet_type, data, opt_data)\n        elif packet_type == PACKET.RESPONSE:\n            packet = ResponsePacket(packet_type, data, opt_data)\n        elif packet_type == PACKET.EVENT:\n            packet = EventPacket(packet_type, data, opt_data)\n        else:\n            packet = Packet(packet_type, data, opt_data)\n\n        return PARSE_RESULT.OK, buf, packet"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(packet_type, rorg, rorg_func, rorg_type, direction=None, command=None,\n               destination=None,\n               sender=None,\n               learn=False, **kwargs):\n        '''\n        Creates an packet ready for sending.\n        Uses rorg, rorg_func and rorg_type to determine the values set based on EEP.\n        Additional arguments (**kwargs) are used for setting the values.\n\n        Currently only supports:\n            - PACKET.RADIO_ERP1\n            - RORGs RPS, BS1, BS4, VLD.\n\n        TODO:\n            - Require sender to be set? Would force the \"correct\" sender to be set.\n            - Do we need to set telegram control bits?\n              Might be useful for acting as a repeater?\n        '''\n\n        if packet_type != PACKET.RADIO_ERP1:\n            # At least for now, only support PACKET.RADIO_ERP1.\n            raise ValueError('Packet type not supported by this function.')\n\n        if rorg not in [RORG.RPS, RORG.BS1, RORG.BS4, RORG.VLD]:\n            # At least for now, only support these RORGS.\n            raise ValueError('RORG not supported by this function.')\n\n        if destination is None:\n            Packet.logger.warning('Replacing destination with broadcast address.')\n            destination = [0xFF, 0xFF, 0xFF, 0xFF]\n\n        # TODO: Should use the correct Base ID as default.\n        #       Might want to change the sender to be an offset from the actual address?\n        if sender is None:\n            Packet.logger.warning('Replacing sender with default address.')\n            sender = [0xDE, 0xAD, 0xBE, 0xEF]\n\n        if not isinstance(destination, list) or len(destination) != 4:\n            raise ValueError('Destination must a list containing 4 (numeric) values.')\n\n        if not isinstance(sender, list) or len(sender) != 4:\n            raise ValueError('Sender must a list containing 4 (numeric) values.')\n\n        packet = Packet(packet_type, data=[], optional=[])\n        packet.rorg = rorg\n        packet.data = [packet.rorg]\n        # Select EEP at this point, so we know how many bits we're dealing with (for VLD).\n        packet.select_eep(rorg_func, rorg_type, direction, command)\n\n        # Initialize data depending on the profile.\n        if rorg in [RORG.RPS, RORG.BS1]:\n            packet.data.extend([0])\n        elif rorg == RORG.BS4:\n            packet.data.extend([0, 0, 0, 0])\n        else:\n            packet.data.extend([0] * int(packet._profile.get('bits', '1')))\n        packet.data.extend(sender)\n        packet.data.extend([0])\n        # Always use sub-telegram 3, maximum dbm (as per spec, when sending),\n        # and no security (security not supported as per EnOcean Serial Protocol).\n        packet.optional = [3] + destination + [0xFF] + [0]\n\n        if command:\n            # Set CMD to command, if applicable.. Helps with VLD.\n            kwargs['CMD'] = command\n\n        packet.set_eep(kwargs)\n        if rorg in [RORG.BS1, RORG.BS4] and not learn:\n            if rorg == RORG.BS1:\n                packet.data[1] |= (1 << 3)\n            if rorg == RORG.BS4:\n                packet.data[4] |= (1 << 3)\n        packet.data[-1] = packet.status\n\n        # Parse the built packet, so it corresponds to the received packages\n        # For example, stuff like RadioPacket.learn should be set.\n        packet = Packet.parse_msg(packet.build())[2]\n        packet.rorg = rorg\n        packet.parse_eep(rorg_func, rorg_type, direction, command)\n        return packet", "response": "Create a new instance of a new Telegram message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self):\n        ''' Parse data from Packet '''\n        # Parse status from messages\n        if self.rorg in [RORG.RPS, RORG.BS1, RORG.BS4]:\n            self.status = self.data[-1]\n        if self.rorg == RORG.VLD:\n            self.status = self.optional[-1]\n\n        if self.rorg in [RORG.RPS, RORG.BS1, RORG.BS4]:\n            # These message types should have repeater count in the last for bits of status.\n            self.repeater_count = enocean.utils.from_bitarray(self._bit_status[4:])\n        return self.parsed", "response": "Parse data from Packet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef select_eep(self, rorg_func, rorg_type, direction=None, command=None):\n        ''' Set EEP based on FUNC and TYPE '''\n        # set EEP profile\n        self.rorg_func = rorg_func\n        self.rorg_type = rorg_type\n        self._profile = self.eep.find_profile(self._bit_data, self.rorg, rorg_func, rorg_type, direction, command)\n        return self._profile is not None", "response": "Select the EEP based on FUNC and TYPE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing EEP based on FUNC and TYPE", "response": "def parse_eep(self, rorg_func=None, rorg_type=None, direction=None, command=None):\n        ''' Parse EEP based on FUNC and TYPE '''\n        # set EEP profile, if demanded\n        if rorg_func is not None and rorg_type is not None:\n            self.select_eep(rorg_func, rorg_type, direction, command)\n        # parse data\n        provides, values = self.eep.get_values(self._profile, self._bit_data, self._bit_status)\n        self.parsed.update(values)\n        return list(provides)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_eep(self, data):\n        ''' Update packet data based on EEP. Input data is a dictionary with keys corresponding to the EEP. '''\n        self._bit_data, self._bit_status = self.eep.set_values(self._profile, self._bit_data, self._bit_status, data)", "response": "Update packet data based on EEP. Input data is a dictionary with keys corresponding to the EEP."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild Packet for sending to EnOcean controller", "response": "def build(self):\n        ''' Build Packet for sending to EnOcean controller '''\n        data_length = len(self.data)\n        ords = [0x55, (data_length >> 8) & 0xFF, data_length & 0xFF, len(self.optional), int(self.packet_type)]\n        ords.append(crc8.calc(ords[1:5]))\n        ords.extend(self.data)\n        ords.extend(self.optional)\n        ords.append(crc8.calc(ords[6:]))\n        return ords"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a message from the send queue if one exists return it.", "response": "def _get_from_send_queue(self):\n        ''' Get message from send queue, if one exists '''\n        try:\n            packet = self.transmit.get(block=False)\n            self.logger.info('Sending packet')\n            self.logger.debug(packet)\n            return packet\n        except queue.Empty:\n            pass\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the buffer and puts them to receive queue.", "response": "def parse(self):\n        ''' Parses messages and puts them to receive queue '''\n        # Loop while we get new messages\n        while True:\n            status, self._buffer, packet = Packet.parse_msg(self._buffer)\n            # If message is incomplete -> break the loop\n            if status == PARSE_RESULT.INCOMPLETE:\n                return status\n\n            # If message is OK, add it to receive queue or send to the callback method\n            if status == PARSE_RESULT.OK and packet:\n                packet.received = datetime.datetime.now()\n\n                if isinstance(packet, UTETeachInPacket) and self.teach_in:\n                    response_packet = packet.create_response_packet(self.base_id)\n                    self.logger.info('Sending response to UTE teach-in.')\n                    self.send(response_packet)\n\n                if self.__callback is None:\n                    self.receive.put(packet)\n                else:\n                    self.__callback(packet)\n                self.logger.debug(packet)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef base_id(self):\n        ''' Fetches Base ID from the transmitter, if required. Otherwise returns the currently set Base ID. '''\n        # If base id is already set, return it.\n        if self._base_id is not None:\n            return self._base_id\n\n        # Send COMMON_COMMAND 0x08, CO_RD_IDBASE request to the module\n        self.send(Packet(PACKET.COMMON_COMMAND, data=[0x08]))\n        # Loop over 10 times, to make sure we catch the response.\n        # Thanks to timeout, shouldn't take more than a second.\n        # Unfortunately, all other messages received during this time are ignored.\n        for i in range(0, 10):\n            try:\n                packet = self.receive.get(block=True, timeout=0.1)\n                # We're only interested in responses to the request in question.\n                if packet.packet_type == PACKET.RESPONSE and packet.response == RETURN_CODE.OK and len(packet.response_data) == 4:\n                    # Base ID is set in the response data.\n                    self._base_id = packet.response_data\n                    # Put packet back to the Queue, so the user can also react to it if required...\n                    self.receive.put(packet)\n                    break\n                # Put other packets back to the Queue.\n                self.receive.put(packet)\n            except queue.Empty:\n                continue\n        # Return the current Base ID (might be None).\n        return self._base_id", "response": "Fetches the Base ID from the transmitter if required. Otherwise returns the currently set Base ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap to implement simple timing of tests. Allows running multiple rounds to calculate average time. Limit (in milliseconds) can be set to assert, if (average) duration is too high.", "response": "def timing(rounds=1, limit=None):\n    '''\n    Wrapper to implement simple timing of tests.\n    Allows running multiple rounds to calculate average time.\n    Limit (in milliseconds) can be set to assert, if (average) duration is too high.\n    '''\n    def decorator(method):\n        @functools.wraps(method)\n        def f():\n            if rounds == 1:\n                start = time.time()\n                method()\n                duration = time.time() - start\n            else:\n                start = time.time()\n                for i in range(rounds):\n                    method()\n                duration = (time.time() - start) / rounds\n            # Use milliseconds for duration counter\n            duration = duration * 1e3\n\n            print('Test \"%s.%s\" took %.06f ms.' % (method.__module__, method.__name__, duration))\n            if limit is not None:\n                assert limit > duration, 'Timing failure: %.06f > %.06f' % (duration, limit)\n\n        # Run tests with timings, only if WITH_TIMINGS environment variable is set.\n        # This is because tests with multiple rounds can take long to process.\n        if environ.get('WITH_TIMINGS', None) == '1':\n            return f\n        return method\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(*, worker_settings, burst, check, watch, verbose):\n    sys.path.append(os.getcwd())\n    worker_settings = import_string(worker_settings)\n    logging.config.dictConfig(default_log_config(verbose))\n\n    if check:\n        exit(check_health(worker_settings))\n    else:\n        kwargs = {} if burst is None else {'burst': burst}\n        if watch:\n            loop = asyncio.get_event_loop()\n            loop.run_until_complete(watch_reload(watch, worker_settings, loop))\n        else:\n            run_worker(worker_settings, **kwargs)", "response": "A worker in python with asyncio and redis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the next datetime matching the given parameters.", "response": "def next_cron(\n    previous_dt: datetime,\n    *,\n    month: Union[None, set, int] = None,\n    day: Union[None, set, int] = None,\n    weekday: Union[None, set, int, str] = None,\n    hour: Union[None, set, int] = None,\n    minute: Union[None, set, int] = None,\n    second: Union[None, set, int] = 0,\n    microsecond: int = 123_456,\n):\n    \"\"\"\n    Find the next datetime matching the given parameters.\n    \"\"\"\n    dt = previous_dt + timedelta(seconds=1)\n    if isinstance(weekday, str):\n        weekday = weekdays.index(weekday.lower())\n    options = dict(\n        month=month, day=day, weekday=weekday, hour=hour, minute=minute, second=second, microsecond=microsecond\n    )\n\n    while True:\n        next_dt = _get_next_dt(dt, options)\n        # print(dt, next_dt)\n        if next_dt is None:\n            return dt\n        dt = next_dt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a cron job for the given .", "response": "def cron(\n    coroutine: Union[str, Callable],\n    *,\n    name: Optional[str] = None,\n    month: Union[None, set, int] = None,\n    day: Union[None, set, int] = None,\n    weekday: Union[None, set, int, str] = None,\n    hour: Union[None, set, int] = None,\n    minute: Union[None, set, int] = None,\n    second: Union[None, set, int] = 0,\n    microsecond: int = 123_456,\n    run_at_startup: bool = False,\n    unique: bool = True,\n    timeout: Optional[SecondsTimedelta] = None,\n    keep_result: Optional[float] = 0,\n    max_tries: Optional[int] = 1,\n) -> CronJob:\n    \"\"\"\n    Create a cron job, eg. it should be executed at specific times.\n\n    Workers will enqueue this job at or just after the set times. If ``unique`` is true (the default) the\n    job will only be run once even if multiple workers are running.\n\n    :param coroutine: coroutine function to run\n    :param name: name of the job, if None, the name of the coroutine is used\n    :param month: month(s) to run the job on, 1 - 12\n    :param day: day(s) to run the job on, 1 - 31\n    :param weekday: week day(s) to run the job on, 0 - 6 or mon - sun\n    :param hour: hour(s) to run the job on, 0 - 23\n    :param minute: minute(s) to run the job on, 0 - 59\n    :param second: second(s) to run the job on, 0 - 59\n    :param microsecond: microsecond(s) to run the job on,\n        defaults to 123456 as the world is busier at the top of a second, 0 - 1e6\n    :param run_at_startup: whether to run as worker starts\n    :param unique: whether the job should be only be executed once at each time\n    :param timeout: job timeout\n    :param keep_result: how long to keep the result for\n    :param max_tries: maximum number of tries for the job\n    \"\"\"\n\n    if isinstance(coroutine, str):\n        name = name or 'cron:' + coroutine\n        coroutine = import_string(coroutine)\n\n    assert asyncio.iscoroutinefunction(coroutine), f'{coroutine} is not a coroutine function'\n    timeout = to_seconds(timeout)\n    keep_result = to_seconds(keep_result)\n\n    return CronJob(\n        name or 'cron:' + coroutine.__qualname__,\n        coroutine,\n        month,\n        day,\n        weekday,\n        hour,\n        minute,\n        second,\n        microsecond,\n        run_at_startup,\n        unique,\n        timeout,\n        keep_result,\n        max_tries,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a datetime to number of milliseconds since 1970 and calculate timezone offset", "response": "def to_unix_ms(dt: datetime) -> int:\n    \"\"\"\n    convert a datetime to number of milliseconds since 1970 and calculate timezone offset\n    \"\"\"\n    utcoffset = dt.utcoffset()\n    ep = epoch if utcoffset is None else epoch_tz\n    return as_int((dt - ep).total_seconds() * 1000)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef truncate(s: str, length: int = DEFAULT_CURTAIL) -> str:\n    if len(s) > length:\n        s = s[: length - 1] + '\u2026'\n    return s", "response": "Truncates a string and adds an ellipsis to the end if it was too long"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def create_pool(settings: RedisSettings = None, *, _retry: int = 0) -> ArqRedis:\n    settings = settings or RedisSettings()\n    addr = settings.host, settings.port\n    try:\n        pool = await aioredis.create_redis_pool(\n            addr,\n            db=settings.database,\n            password=settings.password,\n            timeout=settings.conn_timeout,\n            encoding='utf8',\n            commands_factory=ArqRedis,\n        )\n    except (ConnectionError, OSError, aioredis.RedisError, asyncio.TimeoutError) as e:\n        if _retry < settings.conn_retries:\n            logger.warning(\n                'redis connection error %s:%s %s %s, %d retries remaining...',\n                settings.host,\n                settings.port,\n                e.__class__.__name__,\n                e,\n                settings.conn_retries - _retry,\n            )\n            await asyncio.sleep(settings.conn_retry_delay)\n        else:\n            raise\n    else:\n        if _retry > 0:\n            logger.info('redis connection successful')\n        return pool\n\n    # recursively attempt to create the pool outside the except block to avoid\n    # \"During handling of the above exception...\" madness\n    return await create_pool(settings, _retry=_retry + 1)", "response": "Create a new redis pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def enqueue_job(\n        self,\n        function: str,\n        *args: Any,\n        _job_id: Optional[str] = None,\n        _defer_until: Optional[datetime] = None,\n        _defer_by: Union[None, int, float, timedelta] = None,\n        _expires: Union[None, int, float, timedelta] = None,\n        _job_try: Optional[int] = None,\n        **kwargs: Any,\n    ) -> Optional[Job]:\n        \"\"\"\n        Enqueue a job.\n\n        :param function: Name of the function to call\n        :param args: args to pass to the function\n        :param _job_id: ID of the job, can be used to enforce job uniqueness\n        :param _defer_until: datetime at which to run the job\n        :param _defer_by: duration to wait before running the job\n        :param _expires: if the job still hasn't started after this duration, do not run it\n        :param _job_try: useful when re-enqueueing jobs within a job\n        :param kwargs: any keyword arguments to pass to the function\n        :return: :class:`arq.jobs.Job` instance or ``None`` if a job with this ID already exists\n        \"\"\"\n        job_id = _job_id or uuid4().hex\n        job_key = job_key_prefix + job_id\n        assert not (_defer_until and _defer_by), \"use either 'defer_until' or 'defer_by' or neither, not both\"\n\n        defer_by_ms = to_ms(_defer_by)\n        expires_ms = to_ms(_expires)\n\n        with await self as conn:\n            pipe = conn.pipeline()\n            pipe.unwatch()\n            pipe.watch(job_key)\n            job_exists = pipe.exists(job_key)\n            await pipe.execute()\n            if await job_exists:\n                return\n\n            enqueue_time_ms = timestamp_ms()\n            if _defer_until is not None:\n                score = to_unix_ms(_defer_until)\n            elif defer_by_ms:\n                score = enqueue_time_ms + defer_by_ms\n            else:\n                score = enqueue_time_ms\n\n            expires_ms = expires_ms or score - enqueue_time_ms + expires_extra_ms\n\n            job = pickle_job(function, args, kwargs, _job_try, enqueue_time_ms)\n            tr = conn.multi_exec()\n            tr.psetex(job_key, expires_ms, job)\n            tr.zadd(queue_name, score, job_id)\n            try:\n                await tr.execute()\n            except MultiExecError:\n                # job got enqueued since we checked 'job_exists'\n                return\n        return Job(job_id, self)", "response": "Enqueue a job in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def all_job_results(self) -> List[JobResult]:\n        keys = await self.keys(result_key_prefix + '*')\n        results = await asyncio.gather(*[self._get_job_result(k) for k in keys])\n        return sorted(results, key=attrgetter('enqueue_time'))", "response": "Get all job results for all jobs in redis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def main():\n    redis = await create_pool(RedisSettings())\n\n    # no id, random id will be generated\n    job1 = await redis.enqueue_job('the_task')\n    print(job1)\n    \"\"\"\n    >  <arq job 99edfef86ccf4145b2f64ee160fa3297>\n    \"\"\"\n\n    # random id again, again the job will be enqueued and a job will be returned\n    job2 = await redis.enqueue_job('the_task')\n    print(job2)\n    \"\"\"\n    >  <arq job 7d2163c056e54b62a4d8404921094f05>\n    \"\"\"\n\n    # custom job id, job will be enqueued\n    job3 = await redis.enqueue_job('the_task', _job_id='foobar')\n    print(job3)\n    \"\"\"\n    >  <arq job foobar>\n    \"\"\"\n\n    # same custom job id, job will not be enqueued and enqueue_job will return None\n    job4 = await redis.enqueue_job('the_task', _job_id='foobar')\n    print(job4)\n    \"\"\"\n    >  None\n    \"\"\"", "response": "This is the main function for the task. It will create a new job and enqueue it to get it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap for a function that can be used to configure more settings.", "response": "def func(\n    coroutine: Union[str, Function, Callable],\n    *,\n    name: Optional[str] = None,\n    keep_result: Optional[SecondsTimedelta] = None,\n    timeout: Optional[SecondsTimedelta] = None,\n    max_tries: Optional[int] = None,\n) -> Function:\n    \"\"\"\n    Wrapper for a job function which lets you configure more settings.\n\n    :param coroutine: coroutine function to call, can be a string to import\n    :param name: name for function, if None, ``coroutine.__qualname__`` is used\n    :param keep_result: duration to keep the result for, if 0 the result is not kept\n    :param timeout: maximum time the job should take\n    :param max_tries: maximum number of tries allowed for the function, use 1 to prevent retrying\n    \"\"\"\n    if isinstance(coroutine, Function):\n        return coroutine\n\n    if isinstance(coroutine, str):\n        name = name or coroutine\n        coroutine = import_string(coroutine)\n\n    assert asyncio.iscoroutinefunction(coroutine), f'{coroutine} is not a coroutine function'\n    timeout = to_seconds(timeout)\n    keep_result = to_seconds(keep_result)\n\n    return Function(name or coroutine.__qualname__, coroutine, timeout, keep_result, max_tries)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_health(settings_cls) -> int:\n    cls_kwargs = get_kwargs(settings_cls)\n    loop = asyncio.get_event_loop()\n    return loop.run_until_complete(async_check_health(cls_kwargs.get('redis_settings')))", "response": "Run a health check on the worker and return the appropriate exit code."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self) -> None:\n        self.main_task = self.loop.create_task(self.main())\n        try:\n            self.loop.run_until_complete(self.main_task)\n        except asyncio.CancelledError:\n            # happens on shutdown, fine\n            pass\n        finally:\n            self.loop.run_until_complete(self.close())", "response": "Main function to run the worker."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns the asynchronous job check and raise a FailedJobs exception if any failed jobs have failed.", "response": "async def run_check(self) -> int:\n        \"\"\"\n        Run :func:`arq.worker.Worker.async_run`, check for failed jobs and raise :class:`arq.worker.FailedJobs`\n        if any jobs have failed.\n\n        :return: number of completed jobs\n        \"\"\"\n        await self.async_run()\n        if self.jobs_failed:\n            failed_job_results = [r for r in await self.pool.all_job_results() if not r.success]\n            raise FailedJobs(self.jobs_failed, failed_job_results)\n        else:\n            return self.jobs_complete"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def main():\n    redis = await create_pool(RedisSettings())\n\n    job = await redis.enqueue_job('the_task')\n\n    # get the job's id\n    print(job.job_id)\n    \"\"\"\n    >  68362958a244465b9be909db4b7b5ab4 (or whatever)\n    \"\"\"\n\n    # get information about the job, will include results if the job has finished, but\n    # doesn't await the job's result\n    debug(await job.info())\n    \"\"\"\n    >   docs/examples/job_results.py:23 main\n    JobDef(\n        function='the_task',\n        args=(),\n        kwargs={},\n        job_try=None,\n        enqueue_time=datetime.datetime(2019, 4, 23, 13, 58, 56, 781000),\n        score=1556027936781\n    ) (JobDef)\n    \"\"\"\n\n    # get the Job's status\n    print(await job.status())\n    \"\"\"\n    >  JobStatus.queued\n    \"\"\"\n\n    # poll redis for the job result, if the job raised an exception,\n    # it will be raised here\n    # (You'll need the worker running at the same time to get a result here)\n    print(await job.result(timeout=5))\n    \"\"\"\n    >  42\n    \"\"\"", "response": "This is the main function for the task. It will enqueue the job and get the result of the job."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the result of the job.", "response": "async def result(self, timeout: Optional[float] = None, *, pole_delay: float = 0.5) -> Any:\n        \"\"\"\n        Get the result of the job, including waiting if it's not yet available. If the job raised an exception,\n        it will be raised here.\n\n        :param timeout: maximum time to wait for the job result before raising ``TimeoutError``, will wait forever\n        :param pole_delay: how often to poll redis for the job result\n        \"\"\"\n        async for delay in poll(pole_delay):\n            info = await self.result_info()\n            if info:\n                result = info.result\n                if info.success:\n                    return result\n                else:\n                    raise result\n            if timeout is not None and delay > timeout:\n                raise asyncio.TimeoutError()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn information about the job including its result if it s available.", "response": "async def info(self) -> Optional[JobDef]:\n        \"\"\"\n        All information on a job, including its result if it's available, does not wait for the result.\n        \"\"\"\n        info = await self.result_info()\n        if not info:\n            v = await self._redis.get(job_key_prefix + self.job_id, encoding=None)\n            if v:\n                info = unpickle_job(v)\n        if info:\n            info.score = await self._redis.zscore(queue_name, self.job_id)\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the job result if available.", "response": "async def result_info(self) -> Optional[JobResult]:\n        \"\"\"\n        Information about the job result if available, does not wait for the result. Does not raise an exception\n        even if the job raised one.\n        \"\"\"\n        v = await self._redis.get(result_key_prefix + self.job_id, encoding=None)\n        if v:\n            return unpickle_result(v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the status of the job.", "response": "async def status(self) -> JobStatus:\n        \"\"\"\n        Status of the job.\n        \"\"\"\n        if await self._redis.exists(result_key_prefix + self.job_id):\n            return JobStatus.complete\n        elif await self._redis.exists(in_progress_key_prefix + self.job_id):\n            return JobStatus.in_progress\n        else:\n            score = await self._redis.zscore(queue_name, self.job_id)\n            if not score:\n                return JobStatus.not_found\n            return JobStatus.deferred if score > timestamp_ms() else JobStatus.queued"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display_name(self):\n        for k in self._NAME_KEYS:\n            if self._raw.get(k):\n                return self._raw[k]\n            if \"profile\" in self._raw and self._raw[\"profile\"].get(k):\n                return self._raw[\"profile\"][k]\n        return self._raw[\"name\"]", "response": "Find the most appropriate display name for a user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef email(self):\n        if \"profile\" in self._raw:\n            email = self._raw[\"profile\"].get(\"email\")\n        elif \"bot_url\" in self._raw:\n            email = self._raw[\"bot_url\"]\n        else:\n            email = None\n        if not email:\n            logging.debug(\"No email found for %s\", self._raw.get(\"name\"))\n        return email", "response": "Return the e - mail address or bot URL for this user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the URL for the user icon in the desired pixel size.", "response": "def image_url(self, pixel_size=None):\n        \"\"\"\n        Get the URL for the user icon in the desired pixel size, if it exists. If no\n        size is supplied, give the URL for the full-size image.\n        \"\"\"\n        if \"profile\" not in self._raw:\n            return\n        profile = self._raw[\"profile\"]\n        if (pixel_size):\n            img_key = \"image_%s\" % pixel_size\n            if img_key in profile:\n                return profile[img_key]\n        return profile[self._DEFAULT_IMAGE_KEY]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches the fields list and process the text within each field.", "response": "def fields(self):\n        \"\"\"\n        Fetch the \"fields\" list, and process the text within each field, including markdown\n        processing if the message indicates that the fields contain markdown.\n\n        Only present on attachments, not files--this abstraction isn't 100% awesome.'\n        \"\"\"\n        process_markdown = (\"fields\" in self._raw.get(\"mrkdwn_in\", []))\n        fields = self._raw.get(\"fields\", [])\n        if fields:\n            logging.debug(\"Rendering with markdown markdown %s for %s\", process_markdown, fields)\n        return [\n            {\"title\": e[\"title\"], \"short\": e[\"short\"], \"value\": self._formatter.render_text(e[\"value\"], process_markdown)}\n            for e in fields\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of all dms with the members that have ever existed in the current workspace", "response": "def compile_dm_users(self):\n        \"\"\"\n        Gets the info for the members within the dm\n\n        Returns a list of all dms with the members that have ever existed\n\n        :rtype: [object]\n        {\n            id: <id>\n            users: [<user_id>]\n        }\n\n        \"\"\"\n\n        dm_data = self._read_from_json(\"dms.json\")\n        dms = dm_data.values()\n        all_dms_users = []\n\n        for dm in dms:\n            # checks if messages actually exsist\n            if dm[\"id\"] not in self._EMPTY_DMS:\n                # added try catch for users from shared workspaces not in current workspace\n                try:\n                    dm_members = {\"id\": dm[\"id\"], \"users\": [self.__USER_DATA[m] for m in dm[\"members\"]]}\n                    all_dms_users.append(dm_members)\n                except KeyError:\n                    dm_members = None   \n\n        return all_dms_users"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the info for the members within the multiple person instant message", "response": "def compile_mpim_users(self):\n        \"\"\"\n        Gets the info for the members within the multiple person instant message\n\n        Returns a list of all dms with the members that have ever existed\n\n        :rtype: [object]\n        {\n            name: <name>\n            users: [<user_id>]\n        }\n\n        \"\"\"\n\n        mpim_data = self._read_from_json(\"mpims.json\")\n        mpims = [c for c in mpim_data.values()]\n        all_mpim_users = []\n\n        for mpim in mpims:\n            mpim_members = {\"name\": mpim[\"name\"], \"users\": [self.__USER_DATA[m] for m in mpim[\"members\"]]}\n            all_mpim_users.append(mpim_members)\n\n        return all_mpim_users"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a list of messages from each json file in the directory structure that contains the data.", "response": "def _create_messages(self, names, data, isDms=False):\n        \"\"\"\n        Creates object of arrays of messages from each json file specified by the names or ids\n\n        :param [str] names: names of each group of messages\n\n        :param [object] data: array of objects detailing where to get the messages from in\n        the directory structure\n\n        :param bool isDms: boolean value used to tell if the data is dm data so the function can\n        collect the empty dm directories and store them in memory only\n\n        :return: object of arrays of messages\n\n        :rtype: object\n        \"\"\"\n\n        chats = {}\n        empty_dms = []\n        formatter = SlackFormatter(self.__USER_DATA, data)\n\n        for name in names:\n\n            # gets path to dm directory that holds the json archive\n            dir_path = os.path.join(self._PATH, name)\n            messages = []\n            # array of all days archived\n            day_files = glob.glob(os.path.join(dir_path, \"*.json\"))\n\n            # this is where it's skipping the empty directories\n            if not day_files:\n                if isDms:\n                    empty_dms.append(name)\n                continue\n\n            for day in sorted(day_files):\n                with io.open(os.path.join(self._PATH, day), encoding=\"utf8\") as f:\n                    # loads all messages\n                    day_messages = json.load(f)\n                    messages.extend([Message(formatter, d) for d in day_messages])\n\n            chats[name] = messages\n\n        if isDms:\n            self._EMPTY_DMS = empty_dms\n\n        return chats"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the file specified from json and creates an object based on the id of each element", "response": "def _read_from_json(self, file):\n        \"\"\"\n        Reads the file specified from json and creates an object based on the id of each element\n\n        :param str file: Path to file of json to read\n\n        :return: object of data read from json file\n\n        :rtype: object\n        \"\"\"\n\n        try:\n            with io.open(os.path.join(self._PATH, file), encoding=\"utf8\") as f:\n                return {u[\"id\"]: u for u in json.load(f)}\n        except IOError:\n            return {}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert str s to bytes", "response": "def to_bytes(s, encoding=\"utf8\"):\n    \"\"\"Converts str s to bytes\"\"\"\n    if PY_VERSION == 2:\n        b = bytes(s)\n    elif PY_VERSION == 3:\n        b = bytes(s, encoding)\n    else:\n        raise ValueError(\"Is Python 4 out already?\")\n\n    return b"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef SHA1_file(filepath, extra=b''):\n    h = hashlib.sha1()\n    with io.open(filepath, 'rb') as f:\n        for chunk in iter(lambda: f.read(h.block_size), b''):\n            h.update(chunk)\n    h.update(extra)\n    return h.hexdigest()", "response": "Returns the SHA1 hash of the file at filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_archive(filepath):\n\n    # Checks if file path is a directory\n    if os.path.isdir(filepath):\n        path = os.path.abspath(filepath)\n        print(\"Archive already extracted. Viewing from {}...\".format(path))\n        return path\n\n    # Checks if the filepath is a zipfile and continues to extract if it is\n    # if not it raises an error\n    elif not zipfile.is_zipfile(filepath):\n        # Misuse of TypeError? :P\n        raise TypeError(\"{} is not a zipfile\".format(filepath))\n\n    archive_sha = SHA1_file(\n        filepath=filepath,\n        # Add version of slackviewer to hash as well so we can invalidate the cached copy\n        #  if there are new features added\n        extra=to_bytes(slackviewer.__version__)\n    )\n\n    extracted_path = os.path.join(SLACKVIEWER_TEMP_PATH, archive_sha)\n\n    if os.path.exists(extracted_path):\n        print(\"{} already exists\".format(extracted_path))\n    else:\n        # Extract zip\n        with zipfile.ZipFile(filepath) as zip:\n            print(\"{} extracting to {}...\".format(filepath, extracted_path))\n            zip.extractall(path=extracted_path)\n\n        print(\"{} extracted to {}\".format(filepath, extracted_path))\n\n        # Add additional file with archive info\n        create_archive_info(filepath, extracted_path, archive_sha)\n\n    return extracted_path", "response": "Extracts the archive and returns the path of the extracted file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_archive_info(filepath, extracted_path, archive_sha=None):\n\n    archive_info = {\n        \"sha1\": archive_sha,\n        \"filename\": os.path.split(filepath)[1],\n    }\n\n    with io.open(\n        os.path.join(\n            extracted_path,\n            \".slackviewer_archive_info.json\",\n        ), 'w+', encoding=\"utf-8\"\n    ) as f:\n        s = json.dumps(archive_info, ensure_ascii=False)\n        s = to_unicode(s)\n        f.write(s)", "response": "Creates a json file containing the archive info for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a file or directory extract it and return information that will be used in", "response": "def get_export_info(archive_name):\n    \"\"\"\n    Given a file or directory, extract it and return information that will be used in\n    an export printout: the basename of the file, the name stripped of its extension, and\n    our best guess (based on Slack's current naming convention) of the name of the\n    workspace that this is an export of.\n    \"\"\"\n    extracted_path = extract_archive(archive_name)\n    base_filename = basename(archive_name)\n    (noext_filename, _) = splitext(base_filename)\n    # Typical extract name: \"My Friends and Family Slack export Jul 21 2018 - Sep 06 2018\"\n    # If that's not the format, we will just fall back to the extension-free filename.\n    (workspace_name, _) = noext_filename.split(\" Slack export \", 1)\n    return {\n        \"readable_path\": extracted_path,\n        \"basename\": base_filename,\n        \"stripped_name\": noext_filename,\n        \"workspace_name\": workspace_name,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving an email object and an action to determine the sender of the message.", "response": "def determine_sender(mail, action='reply'):\n    \"\"\"\n    Inspect a given mail to reply/forward/bounce and find the most appropriate\n    account to act from and construct a suitable From-Header to use.\n\n    :param mail: the email to inspect\n    :type mail: `email.message.Message`\n    :param action: intended use case: one of \"reply\", \"forward\" or \"bounce\"\n    :type action: str\n    \"\"\"\n    assert action in ['reply', 'forward', 'bounce']\n\n    # get accounts\n    my_accounts = settings.get_accounts()\n    assert my_accounts, 'no accounts set!'\n\n    # extract list of addresses to check for my address\n    # X-Envelope-To and Envelope-To are used to store the recipient address\n    # if not included in other fields\n    # Process the headers in order of importance: if a mail was sent with\n    # account X, with account Y in e.g. CC or delivered-to, make sure that\n    # account X is the one selected and not account Y.\n    candidate_headers = settings.get(\"reply_account_header_priority\")\n    for candidate_header in candidate_headers:\n        candidate_addresses = getaddresses(mail.get_all(candidate_header, []))\n\n        logging.debug('candidate addresses: %s', candidate_addresses)\n        # pick the most important account that has an address in candidates\n        # and use that account's realname and the address found here\n        for account in my_accounts:\n            for seen_name, seen_address in candidate_addresses:\n                if account.matches_address(seen_address):\n                    if settings.get(action + '_force_realname'):\n                        realname = account.realname\n                    else:\n                        realname = seen_name\n                    if settings.get(action + '_force_address'):\n                        address = str(account.address)\n                    else:\n                        address = seen_address\n\n                    logging.debug('using realname: \"%s\"', realname)\n                    logging.debug('using address: %s', address)\n\n                    from_value = formataddr((realname, address))\n                    return from_value, account\n\n    # revert to default account if nothing found\n    account = my_accounts[0]\n    realname = account.realname\n    address = account.address\n    logging.debug('using realname: \"%s\"', realname)\n    logging.debug('using address: %s', address)\n\n    from_value = formataddr((realname, str(address)))\n    return from_value, account"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsecures getter for header values that allows specifying a fallback value return string", "response": "def get(self, key, fallback=None):\n        \"\"\"secure getter for header values that allows specifying a `fallback`\n        return string (defaults to None). This returns the first matching value\n        and doesn't raise KeyErrors\"\"\"\n        if key in self.headers:\n            value = self.headers[key][0]\n        else:\n            value = fallback\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all(self, key, fallback=None):\n        if key in self.headers:\n            value = self.headers[key]\n        else:\n            value = fallback or []\n        return value", "response": "returns all header values for given key"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattaches a file to the internal list of attachments.", "response": "def attach(self, attachment, filename=None, ctype=None):\n        \"\"\"\n        attach a file\n\n        :param attachment: File to attach, given as\n            :class:`~alot.db.attachment.Attachment` object or path to a file.\n        :type attachment: :class:`~alot.db.attachment.Attachment` or str\n        :param filename: filename to use in content-disposition.\n            Will be ignored if `path` matches multiple files\n        :param ctype: force content-type to be used for this attachment\n        :type ctype: str\n        \"\"\"\n\n        if isinstance(attachment, Attachment):\n            self.attachments.append(attachment)\n        elif isinstance(attachment, str):\n            path = os.path.expanduser(attachment)\n            part = helper.mimewrap(path, filename, ctype)\n            self.attachments.append(Attachment(part))\n        else:\n            raise TypeError('attach accepts an Attachment or str')\n\n        if self.sent_time:\n            self.modified_since_sent = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds the message for the current object.", "response": "def construct_mail(self):\n        \"\"\"\n        compiles the information contained in this envelope into a\n        :class:`email.Message`.\n        \"\"\"\n        # Build body text part. To properly sign/encrypt messages later on, we\n        # convert the text to its canonical format (as per RFC 2015).\n        canonical_format = self.body.encode('utf-8')\n        textpart = MIMEText(canonical_format, 'plain', 'utf-8')\n\n        # wrap it in a multipart container if necessary\n        if self.attachments:\n            inner_msg = MIMEMultipart()\n            inner_msg.attach(textpart)\n            # add attachments\n            for a in self.attachments:\n                inner_msg.attach(a.get_mime_representation())\n        else:\n            inner_msg = textpart\n\n        if self.sign:\n            plaintext = inner_msg.as_bytes(policy=email.policy.SMTP)\n            logging.debug('signing plaintext: %s', plaintext)\n\n            try:\n                signatures, signature_str = crypto.detached_signature_for(\n                    plaintext, [self.sign_key])\n                if len(signatures) != 1:\n                    raise GPGProblem(\"Could not sign message (GPGME \"\n                                     \"did not return a signature)\",\n                                     code=GPGCode.KEY_CANNOT_SIGN)\n            except gpg.errors.GPGMEError as e:\n                if e.getcode() == gpg.errors.BAD_PASSPHRASE:\n                    # If GPG_AGENT_INFO is unset or empty, the user just does\n                    # not have gpg-agent running (properly).\n                    if os.environ.get('GPG_AGENT_INFO', '').strip() == '':\n                        msg = \"Got invalid passphrase and GPG_AGENT_INFO\\\n                                not set. Please set up gpg-agent.\"\n                        raise GPGProblem(msg, code=GPGCode.BAD_PASSPHRASE)\n                    else:\n                        raise GPGProblem(\"Bad passphrase. Is gpg-agent \"\n                                         \"running?\",\n                                         code=GPGCode.BAD_PASSPHRASE)\n                raise GPGProblem(str(e), code=GPGCode.KEY_CANNOT_SIGN)\n\n            micalg = crypto.RFC3156_micalg_from_algo(signatures[0].hash_algo)\n            unencrypted_msg = MIMEMultipart(\n                'signed', micalg=micalg, protocol='application/pgp-signature')\n\n            # wrap signature in MIMEcontainter\n            stype = 'pgp-signature; name=\"signature.asc\"'\n            signature_mime = MIMEApplication(\n                _data=signature_str.decode('ascii'),\n                _subtype=stype,\n                _encoder=encode_7or8bit)\n            signature_mime['Content-Description'] = 'signature'\n            signature_mime.set_charset('us-ascii')\n\n            # add signed message and signature to outer message\n            unencrypted_msg.attach(inner_msg)\n            unencrypted_msg.attach(signature_mime)\n            unencrypted_msg['Content-Disposition'] = 'inline'\n        else:\n            unencrypted_msg = inner_msg\n\n        if self.encrypt:\n            plaintext = unencrypted_msg.as_bytes(policy=email.policy.SMTP)\n            logging.debug('encrypting plaintext: %s', plaintext)\n\n            try:\n                encrypted_str = crypto.encrypt(\n                    plaintext, list(self.encrypt_keys.values()))\n            except gpg.errors.GPGMEError as e:\n                raise GPGProblem(str(e), code=GPGCode.KEY_CANNOT_ENCRYPT)\n\n            outer_msg = MIMEMultipart('encrypted',\n                                      protocol='application/pgp-encrypted')\n\n            version_str = 'Version: 1'\n            encryption_mime = MIMEApplication(_data=version_str,\n                                              _subtype='pgp-encrypted',\n                                              _encoder=encode_7or8bit)\n            encryption_mime.set_charset('us-ascii')\n\n            encrypted_mime = MIMEApplication(\n                _data=encrypted_str.decode('ascii'),\n                _subtype='octet-stream',\n                _encoder=encode_7or8bit)\n            encrypted_mime.set_charset('us-ascii')\n            outer_msg.attach(encryption_mime)\n            outer_msg.attach(encrypted_mime)\n\n        else:\n            outer_msg = unencrypted_msg\n\n        headers = self.headers.copy()\n        # add Message-ID\n        if 'Message-ID' not in headers:\n            headers['Message-ID'] = [email.utils.make_msgid()]\n\n        if 'User-Agent' in headers:\n            uastring_format = headers['User-Agent'][0]\n        else:\n            uastring_format = settings.get('user_agent').strip()\n        uastring = uastring_format.format(version=__version__)\n        if uastring:\n            headers['User-Agent'] = [uastring]\n\n        # copy headers from envelope to mail\n        for k, vlist in headers.items():\n            for v in vlist:\n                outer_msg.add_header(k, v)\n\n        return outer_msg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_template(self, tmp, reset=False, only_body=False):\n        logging.debug('GoT: \"\"\"\\n%s\\n\"\"\"', tmp)\n\n        if self.sent_time:\n            self.modified_since_sent = True\n\n        if only_body:\n            self.body = tmp\n        else:\n            m = re.match(r'(?P<h>([a-zA-Z0-9_-]+:.+\\n)*)\\n?(?P<b>(\\s*.*)*)',\n                         tmp)\n            assert m\n\n            d = m.groupdict()\n            headertext = d['h']\n            self.body = d['b']\n\n            # remove existing content\n            if reset:\n                self.headers = {}\n\n            # go through multiline, utf-8 encoded headers\n            # we decode the edited text ourselves here as\n            # email.message_from_file can't deal with raw utf8 header values\n            key = value = None\n            for line in headertext.splitlines():\n                if re.match('[a-zA-Z0-9_-]+:', line):  # new k/v pair\n                    if key and value:  # save old one from stack\n                        self.add(key, value)  # save\n                    key, value = line.strip().split(':', 1)  # parse new pair\n                    # strip spaces, otherwise we end up having \" foo\" as value\n                    # of \"Subject: foo\"\n                    value = value.strip()\n                elif key and value:  # append new line without key prefix\n                    value += line\n            if key and value:  # save last one if present\n                self.add(key, value)\n\n            # interpret 'Attach' pseudo header\n            if 'Attach' in self:\n                to_attach = []\n                for line in self.get_all('Attach'):\n                    gpath = os.path.expanduser(line.strip())\n                    to_attach += [g for g in glob.glob(gpath)\n                                  if os.path.isfile(g)]\n                logging.debug('Attaching: %s', to_attach)\n                for path in to_attach:\n                    self.attach(path)\n                del self['Attach']", "response": "parses a template or user edited string to fills this envelope."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit a commandline into a list of tokens.", "response": "def split_commandline(s, comments=False, posix=True):\n    \"\"\"\n    splits semi-colon separated commandlines\n    \"\"\"\n    # shlex seems to remove unescaped quotes and backslashes\n    s = s.replace('\\\\', '\\\\\\\\')\n    s = s.replace('\\'', '\\\\\\'')\n    s = s.replace('\\\"', '\\\\\\\"')\n    lex = shlex.shlex(s, posix=posix)\n    lex.whitespace_split = True\n    lex.whitespace = ';'\n    if not comments:\n        lex.commenters = ''\n    return list(lex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes a string to unicode bytestring.", "response": "def string_decode(string, enc='ascii'):\n    \"\"\"\n    safely decodes string to unicode bytestring, respecting `enc` as a hint.\n\n    :param string: the string to decode\n    :type string: str or unicode\n    :param enc: a hint what encoding is used in string ('ascii', 'utf-8', ...)\n    :type enc: str\n    :returns: the unicode decoded input string\n    :rtype: unicode\n\n    \"\"\"\n\n    if enc is None:\n        enc = 'ascii'\n    try:\n        string = str(string, enc, errors='replace')\n    except LookupError:  # malformed enc string\n        string = string.decode('ascii', errors='replace')\n    except TypeError:  # already str\n        pass\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshorten string if longer than maxlen appending ellipsis", "response": "def shorten(string, maxlen):\n    \"\"\"shortens string if longer than maxlen, appending ellipsis\"\"\"\n    if 1 < maxlen < len(string):\n        string = string[:maxlen - 1] + u'\u2026'\n    return string[:maxlen]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shorten_author_string(authors_string, maxlength):\n\n    # I will create a list of authors by parsing author_string. I use\n    # deque to do popleft without performance penalties\n    authors = deque()\n\n    # If author list is too long, it uses only the first part of each\n    # name (gmail style)\n    short_names = len(authors_string) > maxlength\n    for au in authors_string.split(\", \"):\n        if short_names:\n            author_as_list = au.split()\n            if len(author_as_list) > 0:\n                authors.append(author_as_list[0])\n        else:\n            authors.append(au)\n\n    # Author chain will contain the list of author strings to be\n    # concatenated using commas for the final formatted author_string.\n    authors_chain = deque()\n\n    if len(authors) == 0:\n        return u''\n\n    # reserve space for first author\n    first_au = shorten(authors.popleft(), maxlength)\n    remaining_length = maxlength - len(first_au)\n\n    # Tries to add an ellipsis if no space to show more than 1 author\n    if authors and maxlength > 3 and remaining_length < 3:\n        first_au = shorten(first_au, maxlength - 3)\n        remaining_length += 3\n\n    # Tries to add as more authors as possible. It takes into account\n    # that if any author will be hidden, and ellipsis should be added\n    while authors and remaining_length >= 3:\n        au = authors.pop()\n        if len(au) > 1 and (remaining_length == 3 or (authors and\n                                                      remaining_length < 7)):\n            authors_chain.appendleft(u'\\u2026')\n            break\n        else:\n            if authors:\n                # 5= ellipsis + 2 x comma and space used as separators\n                au_string = shorten(au, remaining_length - 5)\n            else:\n                # 2 = comma and space used as separator\n                au_string = shorten(au, remaining_length - 2)\n            remaining_length -= len(au_string) + 2\n            authors_chain.appendleft(au_string)\n\n    # Add the first author to the list and concatenate list\n    authors_chain.appendleft(first_au)\n    authorsstring = ', '.join(authors_chain)\n    return authorsstring", "response": "Shorten a list of authors to a maximum length."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pretty_datetime(d):\n    ampm = d.strftime('%p').lower()\n    if len(ampm):\n        hourfmt = '%I' + ampm\n        hourminfmt = '%I:%M' + ampm\n    else:\n        hourfmt = '%Hh'\n        hourminfmt = '%H:%M'\n\n    now = datetime.now()\n    today = now.date()\n    if d.date() == today or d > now - timedelta(hours=6):\n        delta = datetime.now() - d\n        if delta.seconds < 60:\n            string = 'just now'\n        elif delta.seconds < 3600:\n            string = '%dmin ago' % (delta.seconds // 60)\n        elif delta.seconds < 6 * 3600:\n            string = '%dh ago' % (delta.seconds // 3600)\n        else:\n            string = d.strftime(hourminfmt)\n    elif d.date() == today - timedelta(1):\n        string = d.strftime('yest ' + hourfmt)\n    elif d.date() > today - timedelta(7):\n        string = d.strftime('%a ' + hourfmt)\n    elif d.year != today.year:\n        string = d.strftime('%b %Y')\n    else:\n        string = d.strftime('%b %d')\n    return string_decode(string, 'UTF-8')", "response": "Pretty print a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall a shell command and returns the output of the shell command and immediately return.", "response": "def call_cmd(cmdlist, stdin=None):\n    \"\"\"\n    get a shell commands output, error message and return value and immediately\n    return.\n\n    .. warning::\n\n        This returns with the first screen content for interactive commands.\n\n    :param cmdlist: shellcommand to call, already splitted into a list accepted\n                    by :meth:`subprocess.Popen`\n    :type cmdlist: list of str\n    :param stdin: string to pipe to the process\n    :type stdin: str, bytes, or None\n    :return: triple of stdout, stderr, return value of the shell command\n    :rtype: str, str, int\n    \"\"\"\n    termenc = urwid.util.detected_encoding\n    if isinstance(stdin, str):\n        stdin = stdin.encode(termenc)\n    try:\n\n        logging.debug(\"Calling %s\" % cmdlist)\n        proc = subprocess.Popen(\n            cmdlist,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=subprocess.PIPE if stdin is not None else None)\n    except OSError as e:\n        out = b''\n        err = e.strerror\n        ret = e.errno\n    else:\n        out, err = proc.communicate(stdin)\n        ret = proc.returncode\n\n    out = string_decode(out, termenc)\n    err = string_decode(err, termenc)\n    return out, err, ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def call_cmd_async(cmdlist, stdin=None, env=None):\n    termenc = urwid.util.detected_encoding\n    cmdlist = [s.encode(termenc) for s in cmdlist]\n\n    environment = os.environ.copy()\n    if env is not None:\n        environment.update(env)\n    logging.debug('ENV = %s', environment)\n    logging.debug('CMD = %s', cmdlist)\n    try:\n        proc = await asyncio.create_subprocess_exec(\n            *cmdlist,\n            env=environment,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE,\n            stdin=asyncio.subprocess.PIPE if stdin else None)\n    except OSError as e:\n        return ('', str(e), 1)\n    out, err = await proc.communicate(stdin.encode(termenc) if stdin else None)\n    return (out.decode(termenc), err.decode(termenc), proc.returncode)", "response": "Given a command list return the output of that command asynchronously and return the return code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef guess_mimetype(blob):\n    mimetype = 'application/octet-stream'\n    # this is a bit of a hack to support different versions of python magic.\n    # Hopefully at some point this will no longer be necessary\n    #\n    # the version with open() is the bindings shipped with the file source from\n    # http://darwinsys.com/file/ - this is what is used by the python-magic\n    # package on Debian/Ubuntu. However, it is not available on pypi/via pip.\n    #\n    # the version with from_buffer() is available at\n    # https://github.com/ahupp/python-magic and directly installable via pip.\n    #\n    # for more detail see https://github.com/pazz/alot/pull/588\n    if hasattr(magic, 'open'):\n        m = magic.open(magic.MAGIC_MIME_TYPE)\n        m.load()\n        magictype = m.buffer(blob)\n    elif hasattr(magic, 'from_buffer'):\n        # cf. issue #841\n        magictype = magic.from_buffer(blob, mime=True) or magictype\n    else:\n        raise Exception('Unknown magic API')\n\n    # libmagic does not always return proper mimetype strings, cf. issue #459\n    if re.match(r'\\w+\\/\\w+', magictype):\n        mimetype = magictype\n    return mimetype", "response": "Guesses the mime - type of the given data blob."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef guess_encoding(blob):\n    # this is a bit of a hack to support different versions of python magic.\n    # Hopefully at some point this will no longer be necessary\n    #\n    # the version with open() is the bindings shipped with the file source from\n    # http://darwinsys.com/file/ - this is what is used by the python-magic\n    # package on Debian/Ubuntu.  However it is not available on pypi/via pip.\n    #\n    # the version with from_buffer() is available at\n    # https://github.com/ahupp/python-magic and directly installable via pip.\n    #\n    # for more detail see https://github.com/pazz/alot/pull/588\n    if hasattr(magic, 'open'):\n        m = magic.open(magic.MAGIC_MIME_ENCODING)\n        m.load()\n        return m.buffer(blob)\n    elif hasattr(magic, 'from_buffer'):\n        m = magic.Magic(mime_encoding=True)\n        return m.from_buffer(blob)\n    else:\n        raise Exception('Unknown magic API')", "response": "Try to guess the encoding of the given data blob."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef libmagic_version_at_least(version):\n    if hasattr(magic, 'open'):\n        magic_wrapper = magic._libraries['magic']\n    elif hasattr(magic, 'from_buffer'):\n        magic_wrapper = magic.libmagic\n    else:\n        raise Exception('Unknown magic API')\n\n    if not hasattr(magic_wrapper, 'magic_version'):\n        # The magic_version function has been introduced in libmagic 5.13,\n        # if it's not present, we can't guess right, so let's assume False\n        return False\n\n    return magic_wrapper.magic_version >= version", "response": "checks if the libmagic library installed is more recent than a given version"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking the contents of the given path and wraps them into an email. mime. base. MIMEBase object.", "response": "def mimewrap(path, filename=None, ctype=None):\n    \"\"\"Take the contents of the given path and wrap them into an email MIME\n    part according to the content type.  The content type is auto detected from\n    the actual file contents and the file name if it is not given.\n\n    :param path: the path to the file contents\n    :type path: str\n    :param filename: the file name to use in the generated MIME part\n    :type filename: str or None\n    :param ctype: the content type of the file contents in path\n    :type ctype: str or None\n    :returns: the message MIME part storing the data from path\n    :rtype: subclasses of email.mime.base.MIMEBase\n    \"\"\"\n\n    with open(path, 'rb') as f:\n        content = f.read()\n    if not ctype:\n        ctype = guess_mimetype(content)\n        # libmagic < 5.12 incorrectly detects excel/powerpoint files as\n        # 'application/msword' (see #179 and #186 in libmagic bugtracker)\n        # This is a workaround, based on file extension, useful as long\n        # as distributions still ship libmagic 5.11.\n        if (ctype == 'application/msword' and\n                not libmagic_version_at_least(513)):\n            mimetype, _ = mimetypes.guess_type(path)\n            if mimetype:\n                ctype = mimetype\n\n    maintype, subtype = ctype.split('/', 1)\n    if maintype == 'text':\n        part = MIMEText(content.decode(guess_encoding(content), 'replace'),\n                        _subtype=subtype,\n                        _charset='utf-8')\n    elif maintype == 'image':\n        part = MIMEImage(content, _subtype=subtype)\n    elif maintype == 'audio':\n        part = MIMEAudio(content, _subtype=subtype)\n    else:\n        part = MIMEBase(maintype, subtype)\n        part.set_payload(content)\n        # Encode the payload using Base64\n        email.encoders.encode_base64(part)\n    # Set the filename parameter\n    if not filename:\n        filename = os.path.basename(path)\n    part.add_header('Content-Disposition', 'attachment',\n                    filename=filename)\n    return part"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef humanize_size(size):\n    for factor, format_string in ((1, '%i'),\n                                  (1024, '%iKiB'),\n                                  (1024 * 1024, '%.1fMiB')):\n        if size / factor < 1024:\n            return format_string % (size / factor)\n    return format_string % (size / factor)", "response": "Create a nice human readable representation of the given size."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_mailto(mailto_str):\n    if mailto_str.startswith('mailto:'):\n        import urllib.parse\n        to_str, parms_str = mailto_str[7:].partition('?')[::2]\n        headers = {}\n        body = u''\n\n        to = urllib.parse.unquote(to_str)\n        if to:\n            headers['To'] = [to]\n\n        for s in parms_str.split('&'):\n            key, value = s.partition('=')[::2]\n            key = key.capitalize()\n            if key == 'Body':\n                body = urllib.parse.unquote(value)\n            elif value:\n                headers[key] = [urllib.parse.unquote(value)]\n        return (headers, body)\n    else:\n        return (None, None)", "response": "Interprets a mailto - string and returns a tuple of header fields and body"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mailto_to_envelope(mailto_str):\n    from alot.db.envelope import Envelope\n    headers, body = parse_mailto(mailto_str)\n    return Envelope(bodytext=body, headers=headers)", "response": "Interpret a mailto - string into an Envelope object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef RFC3156_canonicalize(text):\n    text = re.sub(\"\\r?\\n\", \"\\r\\n\", text)\n    text = re.sub(\"^From \", \"From=20\", text, flags=re.MULTILINE)\n    return text", "response": "Canonicalizes plain text according to RFC 3156."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nuse for XDG_ * env variables to return fallback if unset or empty", "response": "def get_xdg_env(env_name, fallback):\n    \"\"\" Used for XDG_* env variables to return fallback if unset *or* empty \"\"\"\n    env = os.environ.get(env_name)\n    return env if env else fallback"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lookup(self, query=''):\n        res = []\n        query = re.compile('.*%s.*' % re.escape(query), self.reflags)\n        for name, email in self.get_contacts():\n            if query.match(name) or query.match(email):\n                res.append((name, email))\n        return res", "response": "looks up all contacts where name or address match query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_focus(self, pos):\n        \"Set the focus in the underlying body widget.\"\n        logging.debug('setting focus to %s ', pos)\n        self.body.set_focus(pos)", "response": "Set the focus in the underlying body widget."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef focus_parent(self):\n        mid = self.get_selected_mid()\n        newpos = self._tree.parent_position(mid)\n        if newpos is not None:\n            newpos = self._sanitize_position((newpos,))\n            self.body.set_focus(newpos)", "response": "move focus to parent of currently focussed message"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef focus_first_reply(self):\n        mid = self.get_selected_mid()\n        newpos = self._tree.first_child_position(mid)\n        if newpos is not None:\n            newpos = self._sanitize_position((newpos,))\n            self.body.set_focus(newpos)", "response": "move focus to first reply to currently focussed message"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef focus_last_reply(self):\n        mid = self.get_selected_mid()\n        newpos = self._tree.last_child_position(mid)\n        if newpos is not None:\n            newpos = self._sanitize_position((newpos,))\n            self.body.set_focus(newpos)", "response": "move focus to last reply to currently focussed message"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfocus next sibling of currently focussed message in thread tree", "response": "def focus_next_sibling(self):\n        \"\"\"focus next sibling of currently focussed message in thread tree\"\"\"\n        mid = self.get_selected_mid()\n        newpos = self._tree.next_sibling_position(mid)\n        if newpos is not None:\n            newpos = self._sanitize_position((newpos,))\n            self.body.set_focus(newpos)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfocus previous sibling of currently focussed message in thread tree", "response": "def focus_prev_sibling(self):\n        \"\"\"\n        focus previous sibling of currently focussed message in thread tree\n        \"\"\"\n        mid = self.get_selected_mid()\n        localroot = self._sanitize_position((mid,))\n        if localroot == self.get_focus()[1]:\n            newpos = self._tree.prev_sibling_position(mid)\n            if newpos is not None:\n                newpos = self._sanitize_position((newpos,))\n        else:\n            newpos = localroot\n        if newpos is not None:\n            self.body.set_focus(newpos)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfocus next message in depth first order", "response": "def focus_next(self):\n        \"\"\"focus next message in depth first order\"\"\"\n        mid = self.get_selected_mid()\n        newpos = self._tree.next_position(mid)\n        if newpos is not None:\n            newpos = self._sanitize_position((newpos,))\n            self.body.set_focus(newpos)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfocusing previous message in depth first order", "response": "def focus_prev(self):\n        \"\"\"focus previous message in depth first order\"\"\"\n        mid = self.get_selected_mid()\n        localroot = self._sanitize_position((mid,))\n        if localroot == self.get_focus()[1]:\n            newpos = self._tree.prev_position(mid)\n            if newpos is not None:\n                newpos = self._sanitize_position((newpos,))\n        else:\n            newpos = localroot\n        if newpos is not None:\n            self.body.set_focus(newpos)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef focus_property(self, prop, direction):\n        newpos = self.get_selected_mid()\n        newpos = direction(newpos)\n        while newpos is not None:\n            MT = self._tree[newpos]\n            if prop(MT):\n                newpos = self._sanitize_position((newpos,))\n                self.body.set_focus(newpos)\n                break\n            newpos = direction(newpos)", "response": "does a walk in the given direction and focuses the first message tree that matches the given property"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfocus next matching message in depth first order", "response": "def focus_next_matching(self, querystring):\n        \"\"\"focus next matching message in depth first order\"\"\"\n        self.focus_property(lambda x: x._message.matches(querystring),\n                            self._tree.next_position)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef focus_prev_matching(self, querystring):\n        self.focus_property(lambda x: x._message.matches(querystring),\n                            self._tree.prev_position)", "response": "focus previous matching message in depth first order"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef focus_next_unfolded(self):\n        self.focus_property(lambda x: not x.is_collapsed(x.root),\n                            self._tree.next_position)", "response": "focus next unfolded message in depth first order"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef focus_prev_unfolded(self):\n        self.focus_property(lambda x: not x.is_collapsed(x.root),\n                            self._tree.prev_position)", "response": "focus previous unfolded message in depth first order"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexpand the tree at the given position", "response": "def expand(self, msgpos):\n        \"\"\"expand message at given position\"\"\"\n        MT = self._tree[msgpos]\n        MT.expand(MT.root)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncollapses the message at given position", "response": "def collapse(self, msgpos):\n        \"\"\"collapse message at given position\"\"\"\n        MT = self._tree[msgpos]\n        MT.collapse(MT.root)\n        self.focus_selected_message()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef collapse_all(self):\n        for MT in self.messagetrees():\n            MT.collapse(MT.root)\n        self.focus_selected_message()", "response": "collapse all messages in thread"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unfold_matching(self, querystring, focus_first=True):\n        first = None\n        for MT in self.messagetrees():\n            msg = MT._message\n            if msg.matches(querystring):\n                MT.expand(MT.root)\n                if first is None:\n                    first = (self._tree.position_of_messagetree(MT), MT.root)\n                    self.body.set_focus(first)\n            else:\n                MT.collapse(MT.root)\n        self.body.refresh()", "response": "expand all messages that match a given querystring."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_signature_headers(mail, sigs, error_msg):\n    '''Add pseudo headers to the mail indicating whether the signature\n    verification was successful.\n\n    :param mail: :class:`email.message.Message` the message to entitle\n    :param sigs: list of :class:`gpg.results.Signature`\n    :param error_msg: An error message if there is one, or None\n    :type error_msg: :class:`str` or `None`\n    '''\n    sig_from = ''\n    sig_known = True\n    uid_trusted = False\n\n    assert error_msg is None or isinstance(error_msg, str)\n\n    if not sigs:\n        error_msg = error_msg or u'no signature found'\n    elif not error_msg:\n        try:\n            key = crypto.get_key(sigs[0].fpr)\n            for uid in key.uids:\n                if crypto.check_uid_validity(key, uid.email):\n                    sig_from = uid.uid\n                    uid_trusted = True\n                    break\n            else:\n                # No trusted uid found, since we did not break from the loop.\n                sig_from = key.uids[0].uid\n        except GPGProblem:\n            sig_from = sigs[0].fpr\n            sig_known = False\n\n    if error_msg:\n        msg = 'Invalid: {}'.format(error_msg)\n    elif uid_trusted:\n        msg = 'Valid: {}'.format(sig_from)\n    else:\n        msg = 'Untrusted: {}'.format(sig_from)\n\n    mail.add_header(X_SIGNATURE_VALID_HEADER,\n                    'False' if (error_msg or not sig_known) else 'True')\n    mail.add_header(X_SIGNATURE_MESSAGE_HEADER, msg)", "response": "Add pseudo headers to the mail indicating whether the signature verification was successful."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting Content - Type parameters as dict.", "response": "def get_params(mail, failobj=None, header='content-type', unquote=True):\n    '''Get Content-Type parameters as dict.\n\n    RFC 2045 specifies that parameter names are case-insensitive, so\n    we normalize them here.\n\n    :param mail: :class:`email.message.Message`\n    :param failobj: object to return if no such header is found\n    :param header: the header to search for parameters, default\n    :param unquote: unquote the values\n    :returns: a `dict` containing the parameters\n    '''\n    failobj = failobj or []\n    return {k.lower(): v for k, v in mail.get_params(failobj, header, unquote)}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_signatures(original, message, params):\n    malformed = None\n    if len(message.get_payload()) != 2:\n        malformed = u'expected exactly two messages, got {0}'.format(\n            len(message.get_payload()))\n    else:\n        ct = message.get_payload(1).get_content_type()\n        if ct != _APP_PGP_SIG:\n            malformed = u'expected Content-Type: {0}, got: {1}'.format(\n                _APP_PGP_SIG, ct)\n\n    # TODO: RFC 3156 says the alg has to be lower case, but I've seen a message\n    # with 'PGP-'. maybe we should be more permissive here, or maybe not, this\n    # is crypto stuff...\n    if not params.get('micalg', 'nothing').startswith('pgp-'):\n        malformed = u'expected micalg=pgp-..., got: {0}'.format(\n            params.get('micalg', 'nothing'))\n\n    sigs = []\n    if not malformed:\n        try:\n            sigs = crypto.verify_detached(\n                message.get_payload(0).as_bytes(policy=email.policy.SMTP),\n                message.get_payload(1).get_payload(decode=True))\n        except GPGProblem as e:\n            malformed = str(e)\n\n    add_signature_headers(original, sigs, malformed)", "response": "This function handles the message signatures."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_encrypted(original, message, session_keys=None):\n    malformed = False\n\n    ct = message.get_payload(0).get_content_type()\n    if ct != _APP_PGP_ENC:\n        malformed = u'expected Content-Type: {0}, got: {1}'.format(\n            _APP_PGP_ENC, ct)\n\n    want = 'application/octet-stream'\n    ct = message.get_payload(1).get_content_type()\n    if ct != want:\n        malformed = u'expected Content-Type: {0}, got: {1}'.format(want, ct)\n\n    if not malformed:\n        # This should be safe because PGP uses US-ASCII characters only\n        payload = message.get_payload(1).get_payload().encode('ascii')\n        try:\n            sigs, d = crypto.decrypt_verify(payload, session_keys)\n        except GPGProblem as e:\n            # signature verification failures end up here too if the combined\n            # method is used, currently this prevents the interpretation of the\n            # recovered plain text mail. maybe that's a feature.\n            malformed = str(e)\n        else:\n            n = decrypted_message_from_bytes(d, session_keys)\n\n            # add the decrypted message to message. note that n contains all\n            # the attachments, no need to walk over n here.\n            original.attach(n)\n\n            original.defects.extend(n.defects)\n\n            # there are two methods for both signed and encrypted data, one is\n            # called 'RFC 1847 Encapsulation' by RFC 3156, and one is the\n            # 'Combined method'.\n            if not sigs:\n                # 'RFC 1847 Encapsulation', the signature is a detached\n                # signature found in the recovered mime message of type\n                # multipart/signed.\n                if X_SIGNATURE_VALID_HEADER in n:\n                    for k in (X_SIGNATURE_VALID_HEADER,\n                              X_SIGNATURE_MESSAGE_HEADER):\n                        original[k] = n[k]\n            else:\n                # 'Combined method', the signatures are returned by the\n                # decrypt_verify function.\n\n                # note that if we reached this point, we know the signatures\n                # are valid. if they were not valid, the else block of the\n                # current try would not have been executed\n                add_signature_headers(original, sigs, '')\n\n    if malformed:\n        msg = u'Malformed OpenPGP message: {0}'.format(malformed)\n        content = email.message_from_string(msg, policy=email.policy.SMTP)\n        content.set_charset('utf-8')\n        original.attach(content)", "response": "Handle encrypted messages helper."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decrypted_message_from_message(m, session_keys=None):\n    '''Detect and decrypt OpenPGP encrypted data in an email object. If this\n    succeeds, any mime messages found in the recovered plaintext\n    message are added to the returned message object.\n\n    :param m: an email object\n    :param session_keys: a list OpenPGP session keys\n    :returns: :class:`email.message.Message` possibly augmented with\n              decrypted data\n    '''\n    # make sure no one smuggles a token in (data from m is untrusted)\n    del m[X_SIGNATURE_VALID_HEADER]\n    del m[X_SIGNATURE_MESSAGE_HEADER]\n\n    if m.is_multipart():\n        p = get_params(m)\n\n        # handle OpenPGP signed data\n        if (m.get_content_subtype() == 'signed' and\n                p.get('protocol') == _APP_PGP_SIG):\n            _handle_signatures(m, m, p)\n\n        # handle OpenPGP encrypted data\n        elif (m.get_content_subtype() == 'encrypted' and\n              p.get('protocol') == _APP_PGP_ENC and\n              'Version: 1' in m.get_payload(0).get_payload()):\n            _handle_encrypted(m, m, session_keys)\n\n        # It is also possible to put either of the abov into a multipart/mixed\n        # segment\n        elif m.get_content_subtype() == 'mixed':\n            sub = m.get_payload(0)\n\n            if sub.is_multipart():\n                p = get_params(sub)\n\n                if (sub.get_content_subtype() == 'signed' and\n                        p.get('protocol') == _APP_PGP_SIG):\n                    _handle_signatures(m, sub, p)\n                elif (sub.get_content_subtype() == 'encrypted' and\n                      p.get('protocol') == _APP_PGP_ENC):\n                    _handle_encrypted(m, sub, session_keys)\n\n    return m", "response": "Detect and decrypt OpenPGP encrypted data in an email object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decrypted_message_from_bytes(bytestring, session_keys=None):\n    return decrypted_message_from_message(\n        email.message_from_bytes(bytestring, policy=email.policy.SMTP),\n        session_keys)", "response": "Create a Message from a bytestring."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts the headers from the mail", "response": "def extract_headers(mail, headers=None):\n    \"\"\"\n    returns subset of this messages headers as human-readable format:\n    all header values are decoded, the resulting string has\n    one line \"KEY: VALUE\" for each requested header present in the mail.\n\n    :param mail: the mail to use\n    :type mail: :class:`email.Message`\n    :param headers: headers to extract\n    :type headers: list of str\n    \"\"\"\n    headertext = u''\n    if headers is None:\n        headers = mail.keys()\n    for key in headers:\n        value = u''\n        if key in mail:\n            value = decode_header(mail.get(key, ''))\n        headertext += '%s: %s\\n' % (key, value)\n    return headertext"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_part(part, field_key='copiousoutput'):\n    ctype = part.get_content_type()\n    raw_payload = remove_cte(part)\n    rendered_payload = None\n    # get mime handler\n    _, entry = settings.mailcap_find_match(ctype, key=field_key)\n    if entry is not None:\n        tempfile_name = None\n        stdin = None\n        handler_raw_commandstring = entry['view']\n        # in case the mailcap defined command contains no '%s',\n        # we pipe the files content to the handling command via stdin\n        if '%s' in handler_raw_commandstring:\n            # open tempfile, respect mailcaps nametemplate\n            nametemplate = entry.get('nametemplate', '%s')\n            prefix, suffix = parse_mailcap_nametemplate(nametemplate)\n            with tempfile.NamedTemporaryFile(\n                    delete=False, prefix=prefix, suffix=suffix) \\\n                    as tmpfile:\n                tmpfile.write(raw_payload)\n                tempfile_name = tmpfile.name\n        else:\n            stdin = raw_payload\n\n        # read parameter, create handler command\n        parms = tuple('='.join(p) for p in part.get_params())\n\n        # create and call external command\n        cmd = mailcap.subst(entry['view'], ctype,\n                            filename=tempfile_name, plist=parms)\n        logging.debug('command: %s', cmd)\n        logging.debug('parms: %s', str(parms))\n        cmdlist = split_commandstring(cmd)\n        # call handler\n        stdout, _, _ = helper.call_cmd(cmdlist, stdin=stdin)\n        if stdout:\n            rendered_payload = stdout\n\n        # remove tempfile\n        if tempfile_name:\n            os.unlink(tempfile_name)\n\n    return rendered_payload", "response": "Renders a non - multipart email part into displayable plaintext by piping it through an external script."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_cte(part, as_string=False):\n    enc = part.get_content_charset() or 'ascii'\n    cte = str(part.get('content-transfer-encoding', '7bit')).lower().strip()\n    payload = part.get_payload()\n    sp = ''  # string variant of return value\n    bp = b''  # bytestring variant\n\n    logging.debug('Content-Transfer-Encoding: \"{}\"'.format(cte))\n    if cte not in ['quoted-printable', 'base64', '7bit', '8bit', 'binary']:\n        logging.info('Unknown Content-Transfer-Encoding: \"{}\"'.format(cte))\n\n    # switch through all sensible cases\n    # starting with those where payload is already a str\n    if '7bit' in cte or 'binary' in cte:\n        logging.debug('assuming Content-Transfer-Encoding: 7bit')\n        sp = payload\n        if as_string:\n            return sp\n        bp = payload.encode('utf-8')\n        return bp\n\n    # the remaining cases need decoding and define only bt;\n    # decoding into a str is done at the end if requested\n    elif '8bit' in cte:\n        logging.debug('assuming Content-Transfer-Encoding: 8bit')\n        # Python's mail library may decode 8bit as raw-unicode-escape, so\n        # we need to encode that back to bytes so we can decode it using\n        # the correct encoding, or it might not, in which case assume that\n        # the str representation we got is correct.\n        bp = payload.encode('raw-unicode-escape')\n\n    elif 'quoted-printable' in cte:\n        logging.debug('assuming Content-Transfer-Encoding: quoted-printable')\n        bp = quopri.decodestring(payload.encode('ascii'))\n\n    elif 'base64' in cte:\n        logging.debug('assuming Content-Transfer-Encoding: base64')\n        bp = base64.b64decode(payload)\n\n    else:\n        logging.debug('failed to interpret Content-Transfer-Encoding: '\n                      '\"{}\"'.format(cte))\n\n    # by now, bp is defined, sp is not.\n    if as_string:\n        try:\n            sp = bp.decode(enc)\n        except LookupError:\n            # enc is unknown;\n            # fall back to guessing the correct encoding using libmagic\n            sp = helper.try_decode(bp)\n        except UnicodeDecodeError as emsg:\n            # the mail contains chars that are not enc-encoded.\n            # libmagic works better than just ignoring those\n            logging.debug('Decoding failure: {}'.format(emsg))\n            sp = helper.try_decode(bp)\n        return sp\n    return bp", "response": "Interpret MIME - part according to it s Content - Transfer - Encodings and return the payload as a str or bytestring."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_body(mail, types=None, field_key='copiousoutput'):\n\n    preferred = 'text/plain' if settings.get(\n        'prefer_plaintext') else 'text/html'\n    has_preferred = False\n\n    # see if the mail has our preferred type\n    if types is None:\n        has_preferred = list(typed_subpart_iterator(\n            mail, *preferred.split('/')))\n\n    body_parts = []\n    for part in mail.walk():\n        # skip non-leaf nodes in the mail tree\n        if part.is_multipart():\n            continue\n\n        ctype = part.get_content_type()\n\n        if types is not None:\n            if ctype not in types:\n                continue\n        cd = part.get('Content-Disposition', '')\n        if cd.startswith('attachment'):\n            continue\n        # if the mail has our preferred type, we only keep this type\n        # note that if types != None, has_preferred always stays False\n        if has_preferred and ctype != preferred:\n            continue\n\n        if ctype == 'text/plain':\n            body_parts.append(string_sanitize(remove_cte(part, as_string=True)))\n        else:\n            rendered_payload = render_part(part)\n            if rendered_payload:  # handler had output\n                body_parts.append(string_sanitize(rendered_payload))\n            # mark as attachment\n            elif cd:\n                part.replace_header('Content-Disposition', 'attachment; ' + cd)\n            else:\n                part.add_header('Content-Disposition', 'attachment;')\n    return u'\\n\\n'.join(body_parts)", "response": "Extracts the body of a Message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding a header value to a unicode string", "response": "def decode_header(header, normalize=False):\n    \"\"\"\n    decode a header value to a unicode string\n\n    values are usually a mixture of different substrings\n    encoded in quoted printable using different encodings.\n    This turns it into a single unicode string\n\n    :param header: the header value\n    :type header: str\n    :param normalize: replace trailing spaces after newlines\n    :type normalize: bool\n    :rtype: str\n    \"\"\"\n    # some mailers send out incorrectly escaped headers\n    # and double quote the escaped realname part again. remove those\n    # RFC: 2047\n    regex = r'\"(=\\?.+?\\?.+?\\?[^ ?]+\\?=)\"'\n    value = re.sub(regex, r'\\1', header)\n    logging.debug(\"unquoted header: |%s|\", value)\n\n    # otherwise we interpret RFC2822 encoding escape sequences\n    valuelist = email.header.decode_header(value)\n    decoded_list = []\n    for v, enc in valuelist:\n        v = string_decode(v, enc)\n        decoded_list.append(string_sanitize(v))\n    value = ''.join(decoded_list)\n    if normalize:\n        value = re.sub(r'\\n\\s+', r' ', value)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncollapse if the message matches given querystring", "response": "def collapse_if_matches(self, querystring):\n        \"\"\"\n        collapse (and show summary only) if the :class:`alot.db.Message`\n        matches given `querystring`\n        \"\"\"\n        self.set_position_collapsed(\n            self.root, self._message.matches(querystring))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flush(self):\n        if self.ro:\n            raise DatabaseROError()\n        if self.writequeue:\n            # read notmuch's config regarding imap flag synchronization\n            sync = settings.get_notmuch_setting('maildir', 'synchronize_flags')\n\n            # go through writequeue entries\n            while self.writequeue:\n                current_item = self.writequeue.popleft()\n                logging.debug('write-out item: %s', str(current_item))\n\n                # watch out for notmuch errors to re-insert current_item\n                # to the queue on errors\n                try:\n                    # the first two coordinants are cnmdname and post-callback\n                    cmd, afterwards = current_item[:2]\n                    logging.debug('cmd created')\n\n                    # acquire a writeable db handler\n                    try:\n                        mode = Database.MODE.READ_WRITE\n                        db = Database(path=self.path, mode=mode)\n                    except NotmuchError:\n                        raise DatabaseLockedError()\n                    logging.debug('got write lock')\n\n                    # make this a transaction\n                    db.begin_atomic()\n                    logging.debug('got atomic')\n\n                    if cmd == 'add':\n                        logging.debug('add')\n                        path, tags = current_item[2:]\n                        msg, _ = db.add_message(path, sync_maildir_flags=sync)\n                        logging.debug('added msg')\n                        msg.freeze()\n                        logging.debug('freeze')\n                        for tag in tags:\n                            msg.add_tag(tag, sync_maildir_flags=sync)\n                        logging.debug('added tags ')\n                        msg.thaw()\n                        logging.debug('thaw')\n\n                    elif cmd == 'remove':\n                        path = current_item[2]\n                        db.remove_message(path)\n\n                    elif cmd == 'setconfig':\n                        key = current_item[2]\n                        value = current_item[3]\n                        db.set_config(key, value)\n\n                    else:  # tag/set/untag\n                        querystring, tags = current_item[2:]\n                        query = db.create_query(querystring)\n                        for msg in query.search_messages():\n                            msg.freeze()\n                            if cmd == 'tag':\n                                strategy = msg.add_tag\n                            if cmd == 'set':\n                                msg.remove_all_tags()\n                                strategy = msg.add_tag\n                            elif cmd == 'untag':\n                                strategy = msg.remove_tag\n                            for tag in tags:\n                                strategy(tag, sync_maildir_flags=sync)\n                            msg.thaw()\n\n                    logging.debug('ended atomic')\n                    # end transaction and reinsert queue item on error\n                    if db.end_atomic() != notmuch.STATUS.SUCCESS:\n                        raise DatabaseError('end_atomic failed')\n                    logging.debug('ended atomic')\n\n                    # close db\n                    db.close()\n                    logging.debug('closed db')\n\n                    # call post-callback\n                    if callable(afterwards):\n                        logging.debug(str(afterwards))\n                        afterwards()\n                        logging.debug('called callback')\n\n                # re-insert item to the queue upon Xapian/NotmuchErrors\n                except (XapianError, NotmuchError) as e:\n                    logging.exception(e)\n                    self.writequeue.appendleft(current_item)\n                    raise DatabaseError(str(e))\n                except DatabaseLockedError as e:\n                    logging.debug('index temporarily locked')\n                    self.writequeue.appendleft(current_item)\n                    raise e\n                logging.debug('flush finished')", "response": "Flush all queued write - commands in order."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding tags to messages matching querystring", "response": "def tag(self, querystring, tags, afterwards=None, remove_rest=False):\n        \"\"\"\n        add tags to messages matching `querystring`.\n        This appends a tag operation to the write queue and raises\n        :exc:`~errors.DatabaseROError` if in read only mode.\n\n        :param querystring: notmuch search string\n        :type querystring: str\n        :param tags: a list of tags to be added\n        :type tags: list of str\n        :param afterwards: callback that gets called after successful\n                           application of this tagging operation\n        :type afterwards: callable\n        :param remove_rest: remove tags from matching messages before tagging\n        :type remove_rest: bool\n        :exception: :exc:`~errors.DatabaseROError`\n\n        .. note::\n            This only adds the requested operation to the write queue.\n            You need to call :meth:`DBManager.flush` to actually write out.\n        \"\"\"\n        if self.ro:\n            raise DatabaseROError()\n        if remove_rest:\n            self.writequeue.append(('set', afterwards, querystring, tags))\n        else:\n            self.writequeue.append(('tag', afterwards, querystring, tags))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves tags from messages that match querystring.", "response": "def untag(self, querystring, tags, afterwards=None):\n        \"\"\"\n        removes tags from messages that match `querystring`.\n        This appends an untag operation to the write queue and raises\n        :exc:`~errors.DatabaseROError` if in read only mode.\n\n        :param querystring: notmuch search string\n        :type querystring: str\n        :param tags: a list of tags to be added\n        :type tags: list of str\n        :param afterwards: callback that gets called after successful\n                           application of this tagging operation\n        :type afterwards: callable\n        :exception: :exc:`~errors.DatabaseROError`\n\n        .. note::\n            This only adds the requested operation to the write queue.\n            You need to call :meth:`DBManager.flush` to actually write out.\n        \"\"\"\n        if self.ro:\n            raise DatabaseROError()\n        self.writequeue.append(('untag', afterwards, querystring, tags))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_notmuch_thread(self, tid):\n        query = self.query('thread:' + tid)\n        try:\n            return next(query.search_threads())\n        except StopIteration:\n            errmsg = 'no thread with id %s exists!' % tid\n            raise NonexistantObjectError(errmsg)", "response": "returns :class:`notmuch. database. Thread with given id"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a message with given id", "response": "def _get_notmuch_message(self, mid):\n        \"\"\"returns :class:`notmuch.database.Message` with given id\"\"\"\n        mode = Database.MODE.READ_ONLY\n        db = Database(path=self.path, mode=mode)\n        try:\n            return db.find_message(mid)\n        except:\n            errmsg = 'no message with id %s exists!' % mid\n            raise NonexistantObjectError(errmsg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all tagsstrings used in the database", "response": "def get_all_tags(self):\n        \"\"\"\n        returns all tagsstrings used in the database\n        :rtype: list of str\n        \"\"\"\n        db = Database(path=self.path)\n        return [t for t in db.get_all_tags()]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_named_queries(self):\n        db = Database(path=self.path)\n        return {k[6:]: v for k, v in db.get_configs('query.')}", "response": "Returns the named queries stored in the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef async_(self, cbl, fun):\n        # create two unix pipes to redirect the workers stdout and\n        # stderr\n        stdout = os.pipe()\n        stderr = os.pipe()\n\n        # create a multiprocessing pipe for the results\n        pipe = multiprocessing.Pipe(False)\n        receiver, sender = pipe\n\n        process = FillPipeProcess(cbl(), stdout[1], stderr[1], pipe, fun)\n        process.start()\n        self.processes.append(process)\n        logging.debug('Worker process %s spawned', process.pid)\n\n        def threaded_wait():\n            # wait(2) for the process to die\n            process.join()\n\n            if process.exitcode < 0:\n                msg = 'received signal {0}'.format(-process.exitcode)\n            elif process.exitcode > 0:\n                msg = 'returned error code {0}'.format(process.exitcode)\n            else:\n                msg = 'exited successfully'\n\n            logging.debug('Worker process %s %s', process.pid, msg)\n            self.processes.remove(process)\n\n        # XXX: it would be much nicer to run this as a coroutine than a thread,\n        # except that this code is executed before the eventloop is started.\n        #\n        # spawn a thread to collect the worker process once it dies\n        # preventing it from hanging around as zombie\n        threading.Thread(target=threaded_wait).start()\n\n        # TODO: avoid this if logging level > debug\n        def threaded_reader(prefix, fd):\n            with os.fdopen(fd) as handle:\n                for line in handle:\n                    logging.debug('Worker process %s said on %s: %s',\n                                  process.pid, prefix, line.rstrip())\n\n        # spawn two threads that read from the stdout and stderr pipes\n        # and write anything that appears there to the log\n        threading.Thread(target=threaded_reader,\n                         args=('stdout', stdout[0])).start()\n        os.close(stdout[1])\n        threading.Thread(target=threaded_reader,\n                         args=('stderr', stderr[0])).start()\n        os.close(stderr[1])\n\n        # closing the sending end in this (receiving) process guarantees\n        # that here the appropriate EOFError is raised upon .recv in the walker\n        sender.close()\n        return receiver, process", "response": "A function that returns a set of items from the iterable and writes them to the pipe and processes the process."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query(self, querystring):\n        mode = Database.MODE.READ_ONLY\n        db = Database(path=self.path, mode=mode)\n        q = db.create_query(querystring)\n        # add configured exclude tags\n        for tag in settings.get('exclude_tags'):\n            q.exclude_tag(tag)\n        return q", "response": "Creates a query object on demand with the given querystring"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a file to the notmuch index.", "response": "def add_message(self, path, tags=None, afterwards=None):\n        \"\"\"\n        Adds a file to the notmuch index.\n\n        :param path: path to the file\n        :type path: str\n        :param tags: tagstrings to add\n        :type tags: list of str\n        :param afterwards: callback to trigger after adding\n        :type afterwards: callable or None\n        \"\"\"\n        tags = tags or []\n\n        if self.ro:\n            raise DatabaseROError()\n        if not is_subdir_of(path, self.path):\n            msg = 'message path %s ' % path\n            msg += ' is not below notmuchs '\n            msg += 'root path (%s)' % self.path\n            raise DatabaseError(msg)\n        else:\n            self.writequeue.append(('add', afterwards, path, tags))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a message from the notmuch index.", "response": "def remove_message(self, message, afterwards=None):\n        \"\"\"\n        Remove a message from the notmuch index\n\n        :param message: message to remove\n        :type message: :class:`Message`\n        :param afterwards: callback to trigger after removing\n        :type afterwards: callable or None\n        \"\"\"\n        if self.ro:\n            raise DatabaseROError()\n        path = message.get_filename()\n        self.writequeue.append(('remove', afterwards, path))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves a named query string to the notmuch database.", "response": "def save_named_query(self, alias, querystring, afterwards=None):\n        \"\"\"\n        add an alias for a query string.\n\n        These are stored in the notmuch database and can be used as part of\n        more complex queries using the syntax \"query:alias\".\n        See :manpage:`notmuch-search-terms(7)` for more info.\n\n        :param alias: name of shortcut\n        :type alias: str\n        :param querystring: value, i.e., the full query string\n        :type querystring: str\n        :param afterwards: callback to trigger after adding the alias\n        :type afterwards: callable or None\n        \"\"\"\n        if self.ro:\n            raise DatabaseROError()\n        self.writequeue.append(('setconfig', afterwards, 'query.' + alias,\n                                querystring))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_named_query(self, alias, afterwards=None):\n        if self.ro:\n            raise DatabaseROError()\n        self.writequeue.append(('setconfig', afterwards, 'query.' + alias, ''))", "response": "remove a named query from the notmuch database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a GPGME hash algorithm name to one conforming to RFC3156.", "response": "def RFC3156_micalg_from_algo(hash_algo):\n    \"\"\"\n    Converts a GPGME hash algorithm name to one conforming to RFC3156.\n\n    GPGME returns hash algorithm names such as \"SHA256\", but RFC3156 says that\n    programs need to use names such as \"pgp-sha256\" instead.\n\n    :param str hash_algo: GPGME hash_algo\n    :returns: the lowercase name of of the algorithm with \"pgp-\" prepended\n    :rtype: str\n    \"\"\"\n    # hash_algo will be something like SHA256, but we need pgp-sha256.\n    algo = gpg.core.hash_algo_name(hash_algo)\n    if algo is None:\n        raise GPGProblem('Unknown hash algorithm {}'.format(algo),\n                         code=GPGCode.INVALID_HASH_ALGORITHM)\n    return 'pgp-' + algo.lower()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a key from the keyring by filtering for the keyid but only if the keyid is specific enough.", "response": "def get_key(keyid, validate=False, encrypt=False, sign=False,\n            signed_only=False):\n    \"\"\"\n    Gets a key from the keyring by filtering for the specified keyid, but\n    only if the given keyid is specific enough (if it matches multiple\n    keys, an exception will be thrown).\n\n    If validate is True also make sure that returned key is not invalid,\n    revoked or expired. In addition if encrypt or sign is True also validate\n    that key is valid for that action. For example only keys with private key\n    can sign. If signed_only is True make sure that the user id can be trusted\n    to belong to the key (is signed). This last check will only work if the\n    keyid is part of the user id associated with the key, not if it is part of\n    the key fingerprint.\n\n    :param keyid: filter term for the keyring (usually a key ID)\n    :type keyid: str\n    :param validate: validate that returned keyid is valid\n    :type validate: bool\n    :param encrypt: when validating confirm that returned key can encrypt\n    :type encrypt: bool\n    :param sign: when validating confirm that returned key can sign\n    :type sign: bool\n    :param signed_only: only return keys  whose uid is signed (trusted to\n        belong to the key)\n    :type signed_only: bool\n    :returns: A gpg key matching the given parameters\n    :rtype: gpg.gpgme._gpgme_key\n    :raises ~alot.errors.GPGProblem: if the keyid is ambiguous\n    :raises ~alot.errors.GPGProblem: if there is no key that matches the\n        parameters\n    :raises ~alot.errors.GPGProblem: if a key is found, but signed_only is true\n        and the key is unused\n    \"\"\"\n    ctx = gpg.core.Context()\n    try:\n        key = ctx.get_key(keyid)\n        if validate:\n            validate_key(key, encrypt=encrypt, sign=sign)\n    except gpg.errors.KeyNotFound:\n        raise GPGProblem('Cannot find key for \"{}\".'.format(keyid),\n                         code=GPGCode.NOT_FOUND)\n    except gpg.errors.GPGMEError as e:\n        if e.getcode() == gpg.errors.AMBIGUOUS_NAME:\n            # When we get here it means there were multiple keys returned by\n            # gpg for given keyid. Unfortunately gpgme returns invalid and\n            # expired keys together with valid keys. If only one key is valid\n            # for given operation maybe we can still return it instead of\n            # raising exception\n\n            valid_key = None\n\n            for k in list_keys(hint=keyid):\n                try:\n                    validate_key(k, encrypt=encrypt, sign=sign)\n                except GPGProblem:\n                    # if the key is invalid for given action skip it\n                    continue\n\n                if valid_key:\n                    # we have already found one valid key and now we find\n                    # another? We really received an ambiguous keyid\n                    raise GPGProblem(\n                        \"More than one key found matching this filter. \"\n                        \"Please be more specific \"\n                        \"(use a key ID like 4AC8EE1D).\",\n                        code=GPGCode.AMBIGUOUS_NAME)\n                valid_key = k\n\n            if not valid_key:\n                # there were multiple keys found but none of them are valid for\n                # given action (we don't have private key, they are expired\n                # etc), or there was no key at all\n                raise GPGProblem(\n                    'Can not find usable key for \"{}\".'.format(keyid),\n                    code=GPGCode.NOT_FOUND)\n            return valid_key\n        elif e.getcode() == gpg.errors.INV_VALUE:\n            raise GPGProblem(\n                'Can not find usable key for \"{}\".'.format(keyid),\n                code=GPGCode.NOT_FOUND)\n        else:\n            raise e  # pragma: nocover\n    if signed_only and not check_uid_validity(key, keyid):\n        raise GPGProblem(\n            'Cannot find a trusworthy key for \"{}\".'.format(keyid),\n            code=GPGCode.NOT_FOUND)\n    return key"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a generator that returns all keys containing the fingerprint or all keys containing the secret.", "response": "def list_keys(hint=None, private=False):\n    \"\"\"\n    Returns a generator of all keys containing the fingerprint, or all keys if\n    hint is None.\n\n    The generator may raise exceptions of :class:gpg.errors.GPGMEError, and it\n    is the caller's responsibility to handle them.\n\n    :param hint: Part of a fingerprint to usee to search\n    :type hint: str or None\n    :param private: Whether to return public keys or secret keys\n    :type private: bool\n    :returns: A generator that yields keys.\n    :rtype: Generator[gpg.gpgme.gpgme_key_t, None, None]\n    \"\"\"\n    ctx = gpg.core.Context()\n    return ctx.keylist(hint, private)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsigning the given plaintext string and returns the detached signature.", "response": "def detached_signature_for(plaintext_str, keys):\n    \"\"\"\n    Signs the given plaintext string and returns the detached signature.\n\n    A detached signature in GPG speak is a separate blob of data containing\n    a signature for the specified plaintext.\n\n    :param bytes plaintext_str: bytestring to sign\n    :param keys: list of one or more key to sign with.\n    :type keys: list[gpg.gpgme._gpgme_key]\n    :returns: A list of signature and the signed blob of data\n    :rtype: tuple[list[gpg.results.NewSignature], str]\n    \"\"\"\n    ctx = gpg.core.Context(armor=True)\n    ctx.signers = keys\n    (sigblob, sign_result) = ctx.sign(plaintext_str,\n                                      mode=gpg.constants.SIG_MODE_DETACH)\n    return sign_result.signatures, sigblob"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encrypt(plaintext_str, keys):\n    assert keys, 'Must provide at least one key to encrypt with'\n    ctx = gpg.core.Context(armor=True)\n    out = ctx.encrypt(plaintext_str, recipients=keys, sign=False,\n                      always_trust=True)[0]\n    return out", "response": "Encrypt data and return the encrypted form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bad_signatures_to_str(error):\n    return \", \".join(\"{}: {}\".format(s.fpr,\n                                     \"Bad signature for key(s)\")\n                     for s in error.result.signatures\n                     if s.status != NO_ERROR)", "response": "Convert a bad signature exception to a text message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify_detached(message, signature):\n    ctx = gpg.core.Context()\n    try:\n        verify_results = ctx.verify(message, signature)[1]\n        return verify_results.signatures\n    except gpg.errors.BadSignatures as e:\n        raise GPGProblem(bad_signatures_to_str(e), code=GPGCode.BAD_SIGNATURE)\n    except gpg.errors.GPGMEError as e:\n        raise GPGProblem(str(e), code=e.getcode())", "response": "Verifies whether the message is authentic by checking the signature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nasserting that a key is valide and optionally that it can be used for signing or encrypting. Raise GPGProblem otherwise.", "response": "def validate_key(key, sign=False, encrypt=False):\n    \"\"\"Assert that a key is valide and optionally that it can be used for\n    signing or encrypting.  Raise GPGProblem otherwise.\n\n    :param key: the GPG key to check\n    :type key: gpg.gpgme._gpgme_key\n    :param sign: whether the key should be able to sign\n    :type sign: bool\n    :param encrypt: whether the key should be able to encrypt\n    :type encrypt: bool\n    :raises ~alot.errors.GPGProblem: If the key is revoked, expired, or invalid\n    :raises ~alot.errors.GPGProblem: If encrypt is true and the key cannot be\n        used to encrypt\n    :raises ~alot.errors.GPGProblem: If sign is true and th key cannot be used\n        to encrypt\n    \"\"\"\n    if key.revoked:\n        raise GPGProblem('The key \"{}\" is revoked.'.format(key.uids[0].uid),\n                         code=GPGCode.KEY_REVOKED)\n    elif key.expired:\n        raise GPGProblem('The key \"{}\" is expired.'.format(key.uids[0].uid),\n                         code=GPGCode.KEY_EXPIRED)\n    elif key.invalid:\n        raise GPGProblem('The key \"{}\" is invalid.'.format(key.uids[0].uid),\n                         code=GPGCode.KEY_INVALID)\n    if encrypt and not key.can_encrypt:\n        raise GPGProblem(\n            'The key \"{}\" cannot be used to encrypt'.format(key.uids[0].uid),\n            code=GPGCode.KEY_CANNOT_ENCRYPT)\n    if sign and not key.can_sign:\n        raise GPGProblem(\n            'The key \"{}\" cannot be used to sign'.format(key.uids[0].uid),\n            code=GPGCode.KEY_CANNOT_SIGN)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_uid_validity(key, email):\n    def check(key_uid):\n        return (email == key_uid.email and\n                not key_uid.revoked and\n                not key_uid.invalid and\n                key_uid.validity >= gpg.constants.validity.FULL)\n\n    return any(check(u) for u in key.uids)", "response": "Check that a given email belongs to the given key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef kill_filler_process(self):\n        if self.proc:\n            if self.proc.is_alive():\n                self.proc.terminate()", "response": "Kills the processor that fills this buffers\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns currently selected thread", "response": "def get_selected_thread(self):\n        \"\"\"returns currently selected :class:`~alot.db.Thread`\"\"\"\n        threadlinewidget = self.get_selected_threadline()\n        thread = None\n        if threadlinewidget:\n            thread = threadlinewidget.get_thread()\n        return thread"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that interprets the value as urwid. AttrSpec triple for the colour modes 1 16 and 256.", "response": "def attr_triple(value):\n    \"\"\"\n    Check that interprets the value as `urwid.AttrSpec` triple for the colour\n    modes 1,16 and 256.  It assumes a <6 tuple of attribute strings for\n    mono foreground, mono background, 16c fg, 16c bg, 256 fg and 256 bg\n    respectively. If any of these are missing, we downgrade to the next\n    lower available pair, defaulting to 'default'.\n\n    :raises: VdtValueTooLongError, VdtTypeError\n    :rtype: triple of `urwid.AttrSpec`\n    \"\"\"\n    keys = ['dfg', 'dbg', '1fg', '1bg', '16fg', '16bg', '256fg', '256bg']\n    acc = {}\n    if not isinstance(value, (list, tuple)):\n        value = value,\n    if len(value) > 6:\n        raise VdtValueTooLongError(value)\n    # ensure we have exactly 6 attribute strings\n    attrstrings = (value + (6 - len(value)) * [None])[:6]\n    # add fallbacks for the empty list\n    attrstrings = (2 * ['default']) + attrstrings\n    for i, value in enumerate(attrstrings):\n        if value:\n            acc[keys[i]] = value\n        else:\n            acc[keys[i]] = acc[keys[i - 2]]\n    try:\n        mono = AttrSpec(acc['1fg'], acc['1bg'], 1)\n        normal = AttrSpec(acc['16fg'], acc['16bg'], 16)\n        high = AttrSpec(acc['256fg'], acc['256bg'], 256)\n    except AttrSpecError as e:\n        raise ValidateError(str(e))\n    return mono, normal, high"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating the width indicator of a sub - widget.", "response": "def width_tuple(value):\n    \"\"\"\n    test if value is a valid width indicator (for a sub-widget in a column).\n    This can either be\n    ('fit', min, max): use the length actually needed for the content, padded\n                       to use at least width min, and cut of at width max.\n                       Here, min and max are positive integers or 0 to disable\n                       the boundary.\n    ('weight',n): have it relative weight of n compared to other columns.\n                  Here, n is an int.\n    \"\"\"\n    if value is None:\n        res = 'fit', 0, 0\n    elif not isinstance(value, (list, tuple)):\n        raise VdtTypeError(value)\n    elif value[0] not in ['fit', 'weight']:\n        raise VdtTypeError(value)\n    if value[0] == 'fit':\n        if not isinstance(value[1], int) or not isinstance(value[2], int):\n            VdtTypeError(value)\n        res = 'fit', int(value[1]), int(value[2])\n    else:\n        if not isinstance(value[1], int):\n            VdtTypeError(value)\n        res = 'weight', int(value[1])\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the value points to a valid mail container in URI - style e. g. mbox://home username mail. box.", "response": "def mail_container(value):\n    \"\"\"\n    Check that the value points to a valid mail container,\n    in URI-style, e.g.: `mbox:///home/username/mail/mail.box`.\n    `~`-expansion will work, e.g.: `mbox://~/mail/mail.box`.\n    The value is cast to a :class:`mailbox.Mailbox` object.\n    \"\"\"\n    if not re.match(r'.*://.*', value):\n        raise VdtTypeError(value)\n    mburl = urlparse(value)\n    uri_scheme_to_mbclass = {\n            'mbox': mailbox.mbox,\n            'maildir': mailbox.Maildir,\n            'mh': mailbox.MH,\n            'babyl': mailbox.Babyl,\n            'mmdf': mailbox.MMDF,\n        }\n    klass = uri_scheme_to_mbclass.get(mburl.scheme)\n    if klass:\n        return klass(mburl.netloc + mburl.path)\n    raise VdtTypeError(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gpg_key(value):\n    try:\n        return crypto.get_key(value)\n    except GPGProblem as e:\n        raise ValidateError(str(e))", "response": "test if value points to a known gpg key and return that key as a gpg key object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_config(configpath=None, specpath=None, checks=None,\n                report_extra=False):\n    \"\"\"\n    get a (validated) config object for given config file path.\n\n    :param configpath: path to config-file or a list of lines as its content\n    :type configpath: str or list(str)\n    :param specpath: path to spec-file\n    :type specpath: str\n    :param checks: custom checks to use for validator.\n        see `validate docs <http://www.voidspace.org.uk/python/validate.html>`_\n    :type checks: dict str->callable,\n    :param report_extra: log if a setting is not present in the spec file\n    :type report_extra: boolean\n    :raises: :class:`~alot.settings.errors.ConfigError`\n    :rtype: `configobj.ConfigObj`\n    \"\"\"\n    checks = checks or {}\n\n    try:\n        config = ConfigObj(infile=configpath, configspec=specpath,\n                           file_error=True, encoding='UTF8')\n    except ConfigObjError as e:\n        msg = 'Error when parsing `%s`:\\n%s' % (configpath, e)\n        logging.error(msg)\n        raise ConfigError(msg)\n    except IOError:\n        raise ConfigError('Could not read %s and/or %s'\n                          % (configpath, specpath))\n    except UnboundLocalError:\n        # this works around a bug in configobj\n        msg = '%s is malformed. Check for sections without parents..'\n        raise ConfigError(msg % configpath)\n\n    if specpath:\n        validator = Validator()\n        validator.functions.update(checks)\n        try:\n            results = config.validate(validator, preserve_errors=True)\n        except ConfigObjError as e:\n            raise ConfigError(str(e))\n\n        if results is not True:\n            error_msg = ''\n            for (section_list, key, res) in flatten_errors(config, results):\n                if key is not None:\n                    if res is False:\n                        msg = 'key \"%s\" in section \"%s\" is missing.'\n                        msg = msg % (key, ', '.join(section_list))\n                    else:\n                        msg = 'key \"%s\" in section \"%s\" failed validation: %s'\n                        msg = msg % (key, ', '.join(section_list), res)\n                else:\n                    msg = 'section \"%s\" is missing' % '.'.join(section_list)\n                error_msg += msg + '\\n'\n            raise ConfigError(error_msg)\n\n        extra_values = get_extra_values(config) if report_extra else None\n        if extra_values:\n            msg = ['Unknown values were found in `%s`. Please check for '\n                   'typos if a specified setting does not seem to work:'\n                   % configpath]\n            for sections, val in extra_values:\n                if sections:\n                    msg.append('%s: %s' % ('->'.join(sections), val))\n                else:\n                    msg.append(str(val))\n            logging.info('\\n'.join(msg))\n    return config", "response": "Reads a config file and returns a new config object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving empty and default values by fallback values", "response": "def resolve_att(a, fallback):\n    \"\"\" replace '' and 'default' by fallback values \"\"\"\n    if a is None:\n        return fallback\n    if a.background in ['default', '']:\n        bg = fallback.background\n    else:\n        bg = a.background\n    if a.foreground in ['default', '']:\n        fg = fallback.foreground\n    else:\n        fg = a.foreground\n    return AttrSpec(fg, bg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the relevant part of a string in a sep - splitted list of substrings of original that pos is ia. n", "response": "def relevant_part(self, original, pos, sep=' '):\n        \"\"\"\n        calculates the subword in a `sep`-splitted list of substrings of\n        `original` that `pos` is ia.n\n        \"\"\"\n        start = original.rfind(sep, 0, pos) + 1\n        end = original.find(sep, pos - 1)\n        if end == -1:\n            end = len(original)\n        return original[start:end], start, end, pos - start"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the subword of original that pos is in", "response": "def relevant_part(self, original, pos):\n        \"\"\"\n        calculates the subword of `original` that `pos` is in\n        \"\"\"\n        start = original.rfind(self._separator, 0, pos)\n        if start == -1:\n            start = 0\n        else:\n            start = start + len(self._separator)\n        end = original.find(self._separator, pos - 1)\n        if end == -1:\n            end = len(original)\n        return original[start:end], start, end, pos - start"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_context(line, pos):\n        commands = split_commandline(line) + ['']\n        i = 0\n        start = 0\n        end = len(commands[i])\n        while pos > end:\n            i += 1\n            start = end + 1\n            end += 1 + len(commands[i])\n        return start, end", "response": "returns start and end position of substring of line that is the\n        command string under given position"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _path_factory(check):\n\n    @functools.wraps(check)\n    def validator(paths):\n        if isinstance(paths, str):\n            check(paths)\n        elif isinstance(paths, collections.Sequence):\n            for path in paths:\n                check(path)\n        else:\n            raise Exception('expected either basestr or sequenc of basstr')\n\n    return validator", "response": "Create a function that checks paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef optional_file_like(path):\n    if (os.path.exists(path) and not (os.path.isfile(path) or\n                                      stat.S_ISFIFO(os.stat(path).st_mode) or\n                                      stat.S_ISCHR(os.stat(path).st_mode))):\n        raise ValidationFailed(\n            '{} is not a valid file, character device, or fifo.'.format(path))", "response": "Validator that ensures that a file exists it regular a fifo or a character device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the name of the attached file.", "response": "def get_filename(self):\n        \"\"\"\n        return name of attached file.\n        If the content-disposition header contains no file name,\n        this returns `None`\n        \"\"\"\n        fname = self.part.get_filename()\n        if fname:\n            extracted_name = decode_header(fname)\n            if extracted_name:\n                return os.path.basename(extracted_name)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_content_type(self):\n        ctype = self.part.get_content_type()\n        # replace underspecified mime description by a better guess\n        if ctype in ['octet/stream', 'application/octet-stream',\n                     'application/octetstream']:\n            ctype = guess_mimetype(self.get_data())\n        return ctype", "response": "get the content type of the attachment part"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_mime_representation(self):\n        part = deepcopy(self.part)\n        part.set_param('maxlinelen', '78', header='Content-Disposition')\n        return part", "response": "returns mime part that constitutes this attachment"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_attribute(self, colourmode, mode, name, part=None):\n        thmble = self._config[mode][name]\n        if part is not None:\n            thmble = thmble[part]\n        thmble = thmble or DUMMYDEFAULT\n        return thmble[self._colours.index(colourmode)]", "response": "returns requested attribute in the specified mode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlook up how to display a Threadline wiidget in search mode for a given thread.", "response": "def get_threadline_theming(self, thread, colourmode):\n        \"\"\"\n        look up how to display a Threadline wiidget in search mode\n        for a given thread.\n\n        :param thread: Thread to theme Threadline for\n        :type thread: alot.db.thread.Thread\n        :param colourmode: colourmode to use, one of 1,16,256.\n        :type colourmode: int\n\n        This will return a dict mapping\n            :normal: to `urwid.AttrSpec`,\n            :focus: to `urwid.AttrSpec`,\n            :parts: to a list of strings indentifying subwidgets\n                    to be displayed in this order.\n\n        Moreover, for every part listed this will map 'part' to a dict mapping\n            :normal: to `urwid.AttrSpec`,\n            :focus: to `urwid.AttrSpec`,\n            :width: to a tuple indicating the width of the subpart.\n                    This is either `('fit', min, max)` to force the widget\n                    to be at least `min` and at most `max` characters wide,\n                    or `('weight', n)` which makes it share remaining space\n                    with other 'weight' parts.\n            :alignment: where to place the content if shorter than the widget.\n                        This is either 'right', 'left' or 'center'.\n        \"\"\"\n        def pickcolour(triple):\n            return triple[self._colours.index(colourmode)]\n\n        def matches(sec, thread):\n            if sec.get('tagged_with') is not None:\n                if not set(sec['tagged_with']).issubset(thread.get_tags()):\n                    return False\n            if sec.get('query') is not None:\n                if not thread.matches(sec['query']):\n                    return False\n            return True\n\n        default = self._config['search']['threadline']\n        match = default\n\n        candidates = self._config['search'].sections\n        for candidatename in candidates:\n            candidate = self._config['search'][candidatename]\n            if (candidatename.startswith('threadline') and\n                    (not candidatename == 'threadline') and\n                    matches(candidate, thread)):\n                match = candidate\n                break\n\n        # fill in values\n        res = {}\n        res['normal'] = pickcolour(match.get('normal') or default['normal'])\n        res['focus'] = pickcolour(match.get('focus') or default['focus'])\n        res['parts'] = match.get('parts') or default['parts']\n        for part in res['parts']:\n            defaultsec = default.get(part)\n            partsec = match.get(part) or {}\n\n            def fill(key, fallback=None):\n                pvalue = partsec.get(key) or defaultsec.get(key)\n                return pvalue or fallback\n\n            res[part] = {}\n            res[part]['width'] = fill('width', ('fit', 0, 0))\n            res[part]['alignment'] = fill('alignment', 'right')\n            res[part]['normal'] = pickcolour(fill('normal'))\n            res[part]['focus'] = pickcolour(fill('focus'))\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle keypresses. This function gets triggered directly by class:`urwid.MainLoop` upon user input and is supposed to pass on its `keys` parameter to let the root widget handle keys. We intercept the input here to trigger custom commands as defined in our keybindings.", "response": "def _input_filter(self, keys, raw):\n        \"\"\"\n        handles keypresses.\n        This function gets triggered directly by class:`urwid.MainLoop`\n        upon user input and is supposed to pass on its `keys` parameter\n        to let the root widget handle keys. We intercept the input here\n        to trigger custom commands as defined in our keybindings.\n        \"\"\"\n        logging.debug(\"Got key (%s, %s)\", keys, raw)\n        # work around: escape triggers this twice, with keys = raw = []\n        # the first time..\n        if not keys:\n            return\n        # let widgets handle input if key is virtual window resize keypress\n        # or we are in \"passall\" mode\n        elif 'window resize' in keys or self._passall:\n            return keys\n        # end \"lockdown\" mode if the right key was pressed\n        elif self._locked and keys[0] == self._unlock_key:\n            self._locked = False\n            self.mainloop.widget = self.root_widget\n            if callable(self._unlock_callback):\n                self._unlock_callback()\n        # otherwise interpret keybinding\n        else:\n            def clear(*_):\n                \"\"\"Callback that resets the input queue.\"\"\"\n                if self._alarm is not None:\n                    self.mainloop.remove_alarm(self._alarm)\n                self.input_queue = []\n\n            async def _apply_fire(cmdline):\n                try:\n                    await self.apply_commandline(cmdline)\n                except CommandParseError as e:\n                    self.notify(str(e), priority='error')\n\n            def fire(_, cmdline):\n                clear()\n                logging.debug(\"cmdline: '%s'\", cmdline)\n                if not self._locked:\n                    loop = asyncio.get_event_loop()\n                    loop.create_task(_apply_fire(cmdline))\n                # move keys are always passed\n                elif cmdline in ['move up', 'move down', 'move page up',\n                                 'move page down']:\n                    return [cmdline[5:]]\n\n            key = keys[0]\n            if key and 'mouse' in key[0]:\n                key = key[0] + ' %i' % key[1]\n            self.input_queue.append(key)\n            keyseq = ' '.join(self.input_queue)\n            candidates = settings.get_mapped_input_keysequences(self.mode,\n                                                                prefix=keyseq)\n            if keyseq in candidates:\n                # case: current input queue is a mapped keysequence\n                # get binding and interpret it if non-null\n                cmdline = settings.get_keybinding(self.mode, keyseq)\n                if cmdline:\n                    if len(candidates) > 1:\n                        timeout = float(settings.get('input_timeout'))\n                        if self._alarm is not None:\n                            self.mainloop.remove_alarm(self._alarm)\n                        self._alarm = self.mainloop.set_alarm_in(\n                            timeout, fire, cmdline)\n                    else:\n                        return fire(self.mainloop, cmdline)\n\n            elif not candidates:\n                # case: no sequence with prefix keyseq is mapped\n                # just clear the input queue\n                clear()\n            else:\n                # case: some sequences with proper prefix keyseq is mapped\n                timeout = float(settings.get('input_timeout'))\n                if self._alarm is not None:\n                    self.mainloop.remove_alarm(self._alarm)\n                self._alarm = self.mainloop.set_alarm_in(timeout, clear)\n            # update statusbar\n            self.update()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninterpret a command line and applies it to the internal state.", "response": "async def apply_commandline(self, cmdline):\n        \"\"\"\n        interprets a command line string\n\n        i.e., splits it into separate command strings,\n        instanciates :class:`Commands <alot.commands.Command>`\n        accordingly and applies then in sequence.\n\n        :param cmdline: command line to interpret\n        :type cmdline: str\n        \"\"\"\n        # remove initial spaces\n        cmdline = cmdline.lstrip()\n\n        # we pass Commands one by one to `self.apply_command`.\n        # To properly call them in sequence, even if they trigger asyncronous\n        # code (return Deferreds), these applications happen in individual\n        # callback functions which are then used as callback chain to some\n        # trivial Deferred that immediately calls its first callback. This way,\n        # one callback may return a Deferred and thus postpone the application\n        # of the next callback (and thus Command-application)\n\n        def apply_this_command(cmdstring):\n            logging.debug('%s command string: \"%s\"', self.mode, str(cmdstring))\n            # translate cmdstring into :class:`Command`\n            cmd = commandfactory(cmdstring, self.mode)\n            # store cmdline for use with 'repeat' command\n            if cmd.repeatable:\n                self.last_commandline = cmdline\n            return self.apply_command(cmd)\n\n        try:\n            for c in split_commandline(cmdline):\n                await apply_this_command(c)\n        except Exception as e:\n            self._error_handler(e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show_as_root_until_keypress(self, w, key, afterwards=None):\n        self.mainloop.widget = w\n        self._unlock_key = key\n        self._unlock_callback = afterwards\n        self._locked = True", "response": "Replaces the given widget with the UI\n        and sets the lock flag to True."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prompt(self, prefix, text=u'', completer=None, tab=0, history=None):\n        history = history or []\n\n        fut = asyncio.get_event_loop().create_future()\n        oldroot = self.mainloop.widget\n\n        def select_or_cancel(text):\n            \"\"\"Restore the main screen and invoce the callback (delayed return)\n            with the given text.\"\"\"\n            self.mainloop.widget = oldroot\n            self._passall = False\n            fut.set_result(text)\n\n        def cerror(e):\n            logging.error(e)\n            self.notify('completion error: %s' % str(e),\n                        priority='error')\n            self.update()\n\n        prefix = prefix + settings.get('prompt_suffix')\n\n        # set up widgets\n        leftpart = urwid.Text(prefix, align='left')\n        editpart = CompleteEdit(completer, on_exit=select_or_cancel,\n                                edit_text=text, history=history,\n                                on_error=cerror)\n\n        for _ in range(tab):  # hit some tabs\n            editpart.keypress((0,), 'tab')\n\n        # build promptwidget\n        both = urwid.Columns(\n            [\n                ('fixed', len(prefix), leftpart),\n                ('weight', 1, editpart),\n            ])\n        att = settings.get_theming_attribute('global', 'prompt')\n        both = urwid.AttrMap(both, att)\n\n        # put promptwidget as overlay on main widget\n        overlay = urwid.Overlay(both, oldroot,\n                                ('fixed left', 0),\n                                ('fixed right', 0),\n                                ('fixed bottom', 1),\n                                None)\n        self.mainloop.widget = overlay\n        self._passall = True\n        return fut", "response": "prompt for text input."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshutting down the user interface without cleaning up.", "response": "def exit():\n        \"\"\"\n        shuts down user interface without cleaning up.\n        Use a :class:`alot.commands.globals.ExitCommand` for a clean shutdown.\n        \"\"\"\n        exit_msg = None\n        try:\n            loop = asyncio.get_event_loop()\n            loop.stop()\n        except Exception as e:\n            logging.error('Could not stop loop: %s\\nShutting down anyway..',\n                          str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef paused(self):\n        self.mainloop.stop()\n        try:\n            yield\n        finally:\n            self.mainloop.start()\n\n            # make sure urwid renders its canvas at the correct size\n            self.mainloop.screen_size = None\n            self.mainloop.draw_screen()", "response": "Context manager that pauses the UI to allow running external commands."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef buffer_open(self, buf):\n\n        # call pre_buffer_open hook\n        prehook = settings.get_hook('pre_buffer_open')\n        if prehook is not None:\n            prehook(ui=self, dbm=self.dbman, buf=buf)\n\n        if self.current_buffer is not None:\n            offset = settings.get('bufferclose_focus_offset') * -1\n            currentindex = self.buffers.index(self.current_buffer)\n            self.buffers.insert(currentindex + offset, buf)\n        else:\n            self.buffers.append(buf)\n        self.buffer_focus(buf)\n\n        # call post_buffer_open hook\n        posthook = settings.get_hook('post_buffer_open')\n        if posthook is not None:\n            posthook(ui=self, dbm=self.dbman, buf=buf)", "response": "register and focus new :class ~alot. buffers. Buffer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef buffer_close(self, buf, redraw=True):\n\n        # call pre_buffer_close hook\n        prehook = settings.get_hook('pre_buffer_close')\n        if prehook is not None:\n            prehook(ui=self, dbm=self.dbman, buf=buf)\n\n        buffers = self.buffers\n        success = False\n        if buf not in buffers:\n            logging.error('tried to close unknown buffer: %s. \\n\\ni have:%s',\n                          buf, self.buffers)\n        elif self.current_buffer == buf:\n            logging.info('closing current buffer %s', buf)\n            index = buffers.index(buf)\n            buffers.remove(buf)\n            offset = settings.get('bufferclose_focus_offset')\n            nextbuffer = buffers[(index + offset) % len(buffers)]\n            self.buffer_focus(nextbuffer, redraw)\n            buf.cleanup()\n            success = True\n        else:\n            buffers.remove(buf)\n            buf.cleanup()\n            success = True\n\n        # call post_buffer_closed hook\n        posthook = settings.get_hook('post_buffer_closed')\n        if posthook is not None:\n            posthook(ui=self, dbm=self.dbman, buf=buf, success=success)", "response": "closes given :class:`~alot.buffers.Buffer`.\n\n        This it removes it from the bufferlist and calls its cleanup() method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfocusing given ~alot. buffers. Buffer object.", "response": "def buffer_focus(self, buf, redraw=True):\n        \"\"\"focus given :class:`~alot.buffers.Buffer`.\"\"\"\n\n        # call pre_buffer_focus hook\n        prehook = settings.get_hook('pre_buffer_focus')\n        if prehook is not None:\n            prehook(ui=self, dbm=self.dbman, buf=buf)\n\n        success = False\n        if buf not in self.buffers:\n            logging.error('tried to focus unknown buffer')\n        else:\n            if self.current_buffer != buf:\n                self.current_buffer = buf\n            self.mode = buf.modename\n            if isinstance(self.current_buffer, BufferlistBuffer):\n                self.current_buffer.rebuild()\n            self.update()\n            success = True\n\n        # call post_buffer_focus hook\n        posthook = settings.get_hook('post_buffer_focus')\n        if posthook is not None:\n            posthook(ui=self, dbm=self.dbman, buf=buf, success=success)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the bottom most focussed widget of the widget tree", "response": "def get_deep_focus(self, startfrom=None):\n        \"\"\"return the bottom most focussed widget of the widget tree\"\"\"\n        if not startfrom:\n            startfrom = self.current_buffer\n        if 'get_focus' in dir(startfrom):\n            focus = startfrom.get_focus()\n            if isinstance(focus, tuple):\n                focus = focus[0]\n            if isinstance(focus, urwid.Widget):\n                return self.get_deep_focus(startfrom=focus)\n        return startfrom"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning currently open buffers of a given type.", "response": "def get_buffers_of_type(self, t):\n        \"\"\"\n        returns currently open buffers for a given subclass of\n        :class:`~alot.buffers.Buffer`.\n\n        :param t: Buffer class\n        :type t: alot.buffers.Buffer\n        :rtype: list\n        \"\"\"\n        return [x for x in self.buffers if isinstance(x, t)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_notify(self, messages):\n        newpile = self._notificationbar.widget_list\n        for l in messages:\n            if l in newpile:\n                newpile.remove(l)\n        if newpile:\n            self._notificationbar = urwid.Pile(newpile)\n        else:\n            self._notificationbar = None\n        self.update()", "response": "Clears the popups that don t have a message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef choice(self, message, choices=None, select=None, cancel=None,\n               msg_position='above', choices_to_return=None):\n        \"\"\"\n        prompt user to make a choice.\n\n        :param message: string to display before list of choices\n        :type message: unicode\n        :param choices: dict of possible choices\n        :type choices: dict: keymap->choice (both str)\n        :param choices_to_return: dict of possible choices to return for the\n                                  choices of the choices of paramter\n        :type choices: dict: keymap->choice key is  str and value is any obj)\n        :param select: choice to return if enter/return is hit. Ignored if set\n                       to `None`.\n        :type select: str\n        :param cancel: choice to return if escape is hit. Ignored if set to\n                       `None`.\n        :type cancel: str\n        :param msg_position: determines if `message` is above or left of the\n                             prompt. Must be `above` or `left`.\n        :type msg_position: str\n        :rtype: asyncio.Future\n        \"\"\"\n        choices = choices or {'y': 'yes', 'n': 'no'}\n        assert select is None or select in choices.values()\n        assert cancel is None or cancel in choices.values()\n        assert msg_position in ['left', 'above']\n\n        fut = asyncio.get_event_loop().create_future()  # Create a returned future\n        oldroot = self.mainloop.widget\n\n        def select_or_cancel(text):\n            \"\"\"Restore the main screen and invoce the callback (delayed return)\n            with the given text.\"\"\"\n            self.mainloop.widget = oldroot\n            self._passall = False\n            fut.set_result(text)\n\n        # set up widgets\n        msgpart = urwid.Text(message)\n        choicespart = ChoiceWidget(choices,\n                                   choices_to_return=choices_to_return,\n                                   callback=select_or_cancel, select=select,\n                                   cancel=cancel)\n\n        # build widget\n        if msg_position == 'left':\n            both = urwid.Columns(\n                [\n                    ('fixed', len(message), msgpart),\n                    ('weight', 1, choicespart),\n                ], dividechars=1)\n        else:  # above\n            both = urwid.Pile([msgpart, choicespart])\n        att = settings.get_theming_attribute('global', 'prompt')\n        both = urwid.AttrMap(both, att, att)\n\n        # put promptwidget as overlay on main widget\n        overlay = urwid.Overlay(both, oldroot,\n                                ('fixed left', 0),\n                                ('fixed right', 0),\n                                ('fixed bottom', 1),\n                                None)\n        self.mainloop.widget = overlay\n        self._passall = True\n        return fut", "response": "Prompt user to make a choice."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef notify(self, message, priority='normal', timeout=0, block=False):\n        def build_line(msg, prio):\n            cols = urwid.Columns([urwid.Text(msg)])\n            att = settings.get_theming_attribute('global', 'notify_' + prio)\n            return urwid.AttrMap(cols, att)\n        msgs = [build_line(message, priority)]\n\n        if not self._notificationbar:\n            self._notificationbar = urwid.Pile(msgs)\n        else:\n            newpile = self._notificationbar.widget_list + msgs\n            self._notificationbar = urwid.Pile(newpile)\n        self.update()\n\n        def clear(*_):\n            self.clear_notify(msgs)\n\n        if block:\n            # put \"cancel to continue\" widget as overlay on main widget\n            txt = build_line('(escape continues)', priority)\n            overlay = urwid.Overlay(txt, self.root_widget,\n                                    ('fixed left', 0),\n                                    ('fixed right', 0),\n                                    ('fixed bottom', 0),\n                                    None)\n            self.show_as_root_until_keypress(overlay, 'esc',\n                                             afterwards=clear)\n        else:\n            if timeout >= 0:\n                if timeout == 0:\n                    timeout = settings.get('notify_timeout')\n                self.mainloop.set_alarm_in(timeout, clear)\n        return msgs[0]", "response": "opens a notification popup and returns the widget that can be used to display the message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the main frame with the current buffer and the mainloop", "response": "def update(self, redraw=True):\n        \"\"\"redraw interface\"\"\"\n        # get the main urwid.Frame widget\n        mainframe = self.root_widget.original_widget\n\n        # body\n        if self.current_buffer:\n            mainframe.set_body(self.current_buffer)\n\n        # footer\n        lines = []\n        if self._notificationbar:  # .get_text()[0] != ' ':\n            lines.append(self._notificationbar)\n        if self._show_statusbar:\n            lines.append(self.build_statusbar())\n\n        if lines:\n            mainframe.set_footer(urwid.Pile(lines))\n        else:\n            mainframe.set_footer(None)\n        # force a screen redraw\n        if self.mainloop.screen.started and redraw:\n            self.mainloop.draw_screen()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_statusbar(self):\n        info = {}\n        cb = self.current_buffer\n        btype = None\n\n        if cb is not None:\n            info = cb.get_info()\n            btype = cb.modename\n            info['buffer_no'] = self.buffers.index(cb)\n            info['buffer_type'] = btype\n        info['total_messages'] = self.dbman.count_messages('*')\n        info['pending_writes'] = len(self.dbman.writequeue)\n        info['input_queue'] = ' '.join(self.input_queue)\n\n        lefttxt = righttxt = u''\n        if cb is not None:\n            lefttxt, righttxt = settings.get(btype + '_statusbar', (u'', u''))\n            lefttxt = string_decode(lefttxt, 'UTF-8')\n            lefttxt = lefttxt.format(**info)\n            righttxt = string_decode(righttxt, 'UTF-8')\n            righttxt = righttxt.format(**info)\n\n        footerleft = urwid.Text(lefttxt, align='left')\n        pending_writes = len(self.dbman.writequeue)\n        if pending_writes > 0:\n            righttxt = ('|' * pending_writes) + ' ' + righttxt\n        footerright = urwid.Text(righttxt, align='right')\n        columns = urwid.Columns([\n            footerleft,\n            ('pack', footerright)])\n        footer_att = settings.get_theming_attribute('global', 'footer')\n        return urwid.AttrMap(columns, footer_att)", "response": "construct and return statusbar widget"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies a command to the current object.", "response": "async def apply_command(self, cmd):\n        \"\"\"\n        applies a command\n\n        This calls the pre and post hooks attached to the command,\n        as well as :meth:`cmd.apply`.\n\n        :param cmd: an applicable command\n        :type cmd: :class:`~alot.commands.Command`\n        \"\"\"\n        # FIXME: What are we guarding for here? We don't mention that None is\n        # allowed as a value fo cmd.\n        if cmd:\n            if cmd.prehook:\n                await cmd.prehook(ui=self, dbm=self.dbman, cmd=cmd)\n            try:\n                if asyncio.iscoroutinefunction(cmd.apply):\n                    await cmd.apply(self)\n                else:\n                    cmd.apply(self)\n            except Exception as e:\n                self._error_handler(e)\n            else:\n                if cmd.posthook:\n                    logging.info('calling post-hook')\n                    await cmd.posthook(ui=self, dbm=self.dbman, cmd=cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles UNIX signals This function currently just handles SIGUSR1. It could be extended to handle more :param signum: The signal number (see man 7 signal) :param frame: The execution frame (https://docs.python.org/2/reference/datamodel.html#frame-objects)", "response": "def handle_signal(self, signum, frame):\n        \"\"\"\n        handles UNIX signals\n\n        This function currently just handles SIGUSR1. It could be extended to\n        handle more\n\n        :param signum: The signal number (see man 7 signal)\n        :param frame: The execution frame\n            (https://docs.python.org/2/reference/datamodel.html#frame-objects)\n        \"\"\"\n        # it is a SIGINT ?\n        if signum == signal.SIGINT:\n            logging.info('shut down cleanly')\n            asyncio.ensure_future(self.apply_command(globals.ExitCommand()))\n        elif signum == signal.SIGUSR1:\n            if isinstance(self.current_buffer, SearchBuffer):\n                self.current_buffer.rebuild()\n                self.update()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndoing the final cleanup before shutting down.", "response": "def cleanup(self):\n        \"\"\"Do the final clean up before shutting down.\"\"\"\n        size = settings.get('history_size')\n        self._save_history_to_file(self.commandprompthistory,\n                                   self._cmd_hist_file, size=size)\n        self._save_history_to_file(self.senderhistory, self._sender_hist_file,\n                                   size=size)\n        self._save_history_to_file(self.recipienthistory,\n                                   self._recipients_hist_file, size=size)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a history list from a file and split it into lines.", "response": "def _load_history_from_file(path, size=-1):\n        \"\"\"Load a history list from a file and split it into lines.\n\n        :param path: the path to the file that should be loaded\n        :type path: str\n        :param size: the number of lines to load (0 means no lines, < 0 means\n            all lines)\n        :type size: int\n        :returns: a list of history items (the lines of the file)\n        :rtype: list(str)\n        \"\"\"\n        if size == 0:\n            return []\n        if os.path.exists(path):\n            with codecs.open(path, 'r', encoding='utf-8') as histfile:\n                lines = [line.rstrip('\\n') for line in histfile]\n            if size > 0:\n                lines = lines[-size:]\n            return lines\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving a history list to a file.", "response": "def _save_history_to_file(history, path, size=-1):\n        \"\"\"Save a history list to a file for later loading (possibly in another\n        session).\n\n        :param history: the history list to save\n        :type history: list(str)\n        :param path: the path to the file where to save the history\n        :param size: the number of lines to save (0 means no lines, < 0 means\n            all lines)\n        :type size: int\n        :type path: str\n        :returns: None\n        \"\"\"\n        if size == 0:\n            return\n        if size > 0:\n            history = history[-size:]\n        directory = os.path.dirname(path)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n        # Write linewise to avoid building a large string in menory.\n        with codecs.open(path, 'w', encoding='utf-8') as histfile:\n            for line in history:\n                histfile.write(line)\n                histfile.write('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parser():\n    parser = argparse.ArgumentParser(add_help=False)\n    parser.add_argument('-r', '--read-only', action='store_true',\n                        help='open notmuch database in read-only mode')\n    parser.add_argument('-c', '--config', metavar='FILENAME',\n                        action=cargparse.ValidatedStoreAction,\n                        validator=cargparse.require_file,\n                        help='configuration file')\n    parser.add_argument('-n', '--notmuch-config', metavar='FILENAME',\n                        default=os.environ.get(\n                            'NOTMUCH_CONFIG',\n                            os.path.expanduser('~/.notmuch-config')),\n                        action=cargparse.ValidatedStoreAction,\n                        validator=cargparse.require_file,\n                        help='notmuch configuration file')\n    parser.add_argument('-C', '--colour-mode', metavar='COLOURS',\n                        choices=(1, 16, 256), type=int,\n                        help='number of colours to use')\n    parser.add_argument('-p', '--mailindex-path', metavar='PATH',\n                        action=cargparse.ValidatedStoreAction,\n                        validator=cargparse.require_dir,\n                        help='path to notmuch index')\n    parser.add_argument('-d', '--debug-level', metavar='LEVEL', default='info',\n                        choices=('debug', 'info', 'warning', 'error'),\n                        help='debug level [default: %(default)s]')\n    parser.add_argument('-l', '--logfile', metavar='FILENAME',\n                        default='/dev/null',\n                        action=cargparse.ValidatedStoreAction,\n                        validator=cargparse.optional_file_like,\n                        help='log file [default: %(default)s]')\n    parser.add_argument('-h', '--help', action='help',\n                        help='display this help and exit')\n    parser.add_argument('-v', '--version', action='version',\n                        version=alot.__version__,\n                        help='output version information and exit')\n    # We will handle the subcommands in a separate run of argparse as argparse\n    # does not support optional subcommands until now.\n    parser.add_argument('command', nargs=argparse.REMAINDER,\n                        help='possible subcommands are {}'.format(\n                            ', '.join(_SUBCOMMANDS)))\n    options = parser.parse_args()\n\n    if options.command:\n        # We have a command after the initial options so we also parse that.\n        # But we just use the parser that is already defined for the internal\n        # command that will back this subcommand.\n        parser = argparse.ArgumentParser()\n        subparsers = parser.add_subparsers(dest='subcommand')\n        for subcommand in _SUBCOMMANDS:\n            subparsers.add_parser(subcommand,\n                                  parents=[COMMANDS['global'][subcommand][1]])\n        command = parser.parse_args(options.command)\n    else:\n        command = None\n\n    return options, command", "response": "Parse command line arguments validate them and return them."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    options, command = parser()\n\n    # logging\n    root_logger = logging.getLogger()\n    for log_handler in root_logger.handlers:\n        root_logger.removeHandler(log_handler)\n    root_logger = None\n    numeric_loglevel = getattr(logging, options.debug_level.upper(), None)\n    logformat = '%(levelname)s:%(module)s:%(message)s'\n    logging.basicConfig(level=numeric_loglevel, filename=options.logfile,\n                        filemode='w', format=logformat)\n\n    # locate alot config files\n    cpath = options.config\n    if options.config is None:\n        xdg_dir = get_xdg_env('XDG_CONFIG_HOME',\n                              os.path.expanduser('~/.config'))\n        alotconfig = os.path.join(xdg_dir, 'alot', 'config')\n        if os.path.exists(alotconfig):\n            cpath = alotconfig\n\n    try:\n        settings.read_config(cpath)\n        settings.read_notmuch_config(options.notmuch_config)\n    except (ConfigError, OSError, IOError) as e:\n        print('Error when parsing a config file. '\n              'See log for potential details.')\n        sys.exit(e)\n\n    # store options given by config swiches to the settingsManager:\n    if options.colour_mode:\n        settings.set('colourmode', options.colour_mode)\n\n    # get ourselves a database manager\n    indexpath = settings.get_notmuch_setting('database', 'path')\n    indexpath = options.mailindex_path or indexpath\n    dbman = DBManager(path=indexpath, ro=options.read_only)\n\n    # determine what to do\n    if command is None:\n        try:\n            cmdstring = settings.get('initial_command')\n        except CommandParseError as err:\n            sys.exit(err)\n    elif command.subcommand in _SUBCOMMANDS:\n        cmdstring = ' '.join(options.command)\n\n    # set up and start interface\n    UI(dbman, cmdstring)\n\n    # run the exit hook\n    exit_hook = settings.get_hook('exit')\n    if exit_hook is not None:\n        exit_hook()", "response": "This function is the main entry point of the alot main loop. It parses the command line and prepares\n    for the user interface main loop to run."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def update_keys(ui, envelope, block_error=False, signed_only=False):\n    encrypt_keys = []\n    for header in ('To', 'Cc'):\n        if header not in envelope.headers:\n            continue\n\n        for recipient in envelope.headers[header][0].split(','):\n            if not recipient:\n                continue\n            match = re.search(\"<(.*@.*)>\", recipient)\n            if match:\n                recipient = match.group(1)\n            encrypt_keys.append(recipient)\n\n    logging.debug(\"encryption keys: \" + str(encrypt_keys))\n    keys = await _get_keys(ui, encrypt_keys, block_error=block_error,\n                           signed_only=signed_only)\n    if keys:\n        envelope.encrypt_keys = keys\n        envelope.encrypt = True\n\n        if 'From' in envelope.headers:\n            try:\n                if envelope.account is None:\n                    envelope.account = settings.account_matching_address(\n                        envelope['From'])\n                acc = envelope.account\n                if acc.encrypt_to_self:\n                    if acc.gpg_key:\n                        logging.debug('encrypt to self: %s', acc.gpg_key.fpr)\n                        envelope.encrypt_keys[acc.gpg_key.fpr] = acc.gpg_key\n                    else:\n                        logging.debug('encrypt to self: no gpg_key in account')\n            except NoMatchingAccount:\n                logging.debug('encrypt to self: no account found')\n\n    else:\n        envelope.encrypt = False", "response": "Find and set the encryption keys in an envolope."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def _get_keys(ui, encrypt_keyids, block_error=False, signed_only=False):\n    keys = {}\n    for keyid in encrypt_keyids:\n        try:\n            key = crypto.get_key(keyid, validate=True, encrypt=True,\n                                 signed_only=signed_only)\n        except GPGProblem as e:\n            if e.code == GPGCode.AMBIGUOUS_NAME:\n                tmp_choices = ['{} ({})'.format(k.uids[0].uid, k.fpr) for k in\n                               crypto.list_keys(hint=keyid)]\n                choices = {str(i): t for i, t in enumerate(tmp_choices, 1)}\n                keys_to_return = {str(i): t for i, t in enumerate([k for k in\n                                  crypto.list_keys(hint=keyid)], 1)}\n                choosen_key = await ui.choice(\"ambiguous keyid! Which \" +\n                                              \"key do you want to use?\",\n                                              choices=choices,\n                                              choices_to_return=keys_to_return)\n                if choosen_key:\n                    keys[choosen_key.fpr] = choosen_key\n                continue\n            else:\n                ui.notify(str(e), priority='error', block=block_error)\n                continue\n        keys[key.fpr] = key\n    return keys", "response": "Get several keys from the GPG keyring."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_string(cls, address, case_sensitive=False):\n        assert isinstance(address, str), 'address must be str'\n        username, domainname = address.split('@')\n        return cls(username, domainname, case_sensitive=case_sensitive)", "response": "Alternate constructor for building from a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __cmp(self, other, comparitor):\n        if isinstance(other, str):\n            try:\n                ouser, odomain = other.split('@')\n            except ValueError:\n                ouser, odomain = '', ''\n        else:\n            ouser = other.username\n            odomain = other.domainname\n\n        if not self.case_sensitive:\n            ouser = ouser.lower()\n            username = self.username.lower()\n        else:\n            username = self.username\n\n        return (comparitor(username, ouser) and\n                comparitor(self.domainname.lower(), odomain.lower()))", "response": "Private helper for rich comparison operators."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef matches_address(self, address):\n        if self.address == address:\n            return True\n        for alias in self.aliases:\n            if alias == address:\n                return True\n        if self._alias_regexp and self._alias_regexp.match(address):\n            return True\n        return False", "response": "returns whether this account knows about an email address"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef store_mail(mbx, mail):\n        if not isinstance(mbx, mailbox.Mailbox):\n            logging.debug('Not a mailbox')\n            return False\n\n        mbx.lock()\n        if isinstance(mbx, mailbox.Maildir):\n            logging.debug('Maildir')\n            msg = mailbox.MaildirMessage(mail)\n            msg.set_flags('S')\n        else:\n            logging.debug('no Maildir')\n            msg = mailbox.Message(mail)\n\n        try:\n            message_id = mbx.add(msg)\n            mbx.flush()\n            mbx.unlock()\n            logging.debug('got mailbox msg id : %s', message_id)\n        except Exception as e:\n            raise StoreMailError(e)\n\n        path = None\n        # add new Maildir message to index and add tags\n        if isinstance(mbx, mailbox.Maildir):\n            # this is a dirty hack to get the path to the newly added file\n            # I wish the mailbox module were more helpful...\n            plist = glob.glob1(os.path.join(mbx._path, 'new'),\n                               message_id + '*')\n            if plist:\n                path = os.path.join(mbx._path, 'new', plist[0])\n                logging.debug('path of saved msg: %s', path)\n        return path", "response": "Stores given mail in mailbox."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores the given mail in the send - store.", "response": "def store_sent_mail(self, mail):\n        \"\"\"\n        stores mail (:class:`email.message.Message` or str) in send-store if\n        :attr:`sent_box` is set.\n        \"\"\"\n        if self.sent_box is not None:\n            return self.store_mail(self.sent_box, mail)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores the given mail as draft.", "response": "def store_draft_mail(self, mail):\n        \"\"\"\n        stores mail (:class:`email.message.Message` or str) as draft if\n        :attr:`draft_box` is set.\n        \"\"\"\n        if self.draft_box is not None:\n            return self.store_mail(self.draft_box, mail)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def send_mail(self, mail):\n        cmdlist = split_commandstring(self.cmd)\n\n        try:\n            # make sure self.mail is a string\n            out, err, code = await call_cmd_async(cmdlist, stdin=str(mail))\n            if code != 0:\n                msg = 'The sendmail command {} returned with code {}{}'.format(\n                    self.cmd, code, ':\\n' + err.strip() if err else '.')\n                raise Exception(msg)\n        except Exception as e:\n            logging.error(str(e))\n            raise SendingMailFailed(str(e))\n        logging.info('sent mail successfully')\n        logging.info(out)", "response": "Pipe the given mail to the configured sendmail command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refresh(self, thread=None):\n        if not thread:\n            thread = self._dbman._get_notmuch_thread(self._id)\n\n        self._total_messages = thread.get_total_messages()\n        self._notmuch_authors_string = thread.get_authors()\n\n        subject_type = settings.get('thread_subject')\n        if subject_type == 'notmuch':\n            subject = thread.get_subject()\n        elif subject_type == 'oldest':\n            try:\n                first_msg = list(thread.get_toplevel_messages())[0]\n                subject = first_msg.get_header('subject')\n            except IndexError:\n                subject = ''\n        self._subject = subject\n\n        self._authors = None\n        ts = thread.get_oldest_date()\n\n        try:\n            self._oldest_date = datetime.fromtimestamp(ts)\n        except ValueError:  # year is out of range\n            self._oldest_date = None\n        try:\n            timestamp = thread.get_newest_date()\n            self._newest_date = datetime.fromtimestamp(timestamp)\n        except ValueError:  # year is out of range\n            self._newest_date = None\n\n        self._tags = {t for t in thread.get_tags()}\n        self._messages = {}  # this maps messages to its children\n        self._toplevel_messages = []", "response": "refresh the metadata from the index"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn set of tagsstrings attached to this thread", "response": "def get_tags(self, intersection=False):\n        \"\"\"\n        returns tagsstrings attached to this thread\n\n        :param intersection: return tags present in all contained messages\n                             instead of in at least one (union)\n        :type intersection: bool\n        :rtype: set of str\n        \"\"\"\n        tags = set(list(self._tags))\n        if intersection:\n            for m in self.get_messages().keys():\n                tags = tags.intersection(set(m.get_tags()))\n        return tags"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_tags(self, tags, afterwards=None, remove_rest=False):\n        def myafterwards():\n            if remove_rest:\n                self._tags = set(tags)\n            else:\n                self._tags = self._tags.union(tags)\n            if callable(afterwards):\n                afterwards()\n\n        self._dbman.tag('thread:' + self._id, tags, afterwards=myafterwards,\n                        remove_rest=remove_rest)", "response": "add tags to all messages in this thread"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove tags from all messages in this thread", "response": "def remove_tags(self, tags, afterwards=None):\n        \"\"\"\n        remove `tags` (list of str) from all messages in this thread\n\n        .. note::\n\n            This only adds the requested operation to this objects\n            :class:`DBManager's <alot.db.DBManager>` write queue.\n            You need to call :meth:`DBManager.flush <alot.db.DBManager.flush>`\n            to actually write out.\n\n        :param tags: a list of tags to be added\n        :type tags: list of str\n        :param afterwards: callback that gets called after successful\n                           application of this tagging operation\n        :type afterwards: callable\n        \"\"\"\n        rmtags = set(tags).intersection(self._tags)\n        if rmtags:\n\n            def myafterwards():\n                self._tags = self._tags.difference(tags)\n                if callable(afterwards):\n                    afterwards()\n            self._dbman.untag('thread:' + self._id, tags, myafterwards)\n            self._tags = self._tags.difference(rmtags)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of authors name and addr of the messages", "response": "def get_authors(self):\n        \"\"\"\n        returns a list of authors (name, addr) of the messages.\n        The authors are ordered by msg date and unique (by name/addr).\n\n        :rtype: list of (str, str)\n        \"\"\"\n        if self._authors is None:\n            # Sort messages with date first (by date ascending), and those\n            # without a date last.\n            msgs = sorted(self.get_messages().keys(),\n                          key=lambda m: m.get_date() or datetime.max)\n\n            orderby = settings.get('thread_authors_order_by')\n            self._authors = []\n            if orderby == 'latest_message':\n                for m in msgs:\n                    pair = m.get_author()\n                    if pair in self._authors:\n                        self._authors.remove(pair)\n                    self._authors.append(pair)\n            else:  # i.e. first_message\n                for m in msgs:\n                    pair = m.get_author()\n                    if pair not in self._authors:\n                        self._authors.append(pair)\n\n        return self._authors"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_authors_string(self, own_accts=None, replace_own=None):\n        if replace_own is None:\n            replace_own = settings.get('thread_authors_replace_me')\n        if replace_own:\n            if own_accts is None:\n                own_accts = settings.get_accounts()\n            authorslist = []\n            for aname, aaddress in self.get_authors():\n                for account in own_accts:\n                    if account.matches_address(aaddress):\n                        aname = settings.get('thread_authors_me')\n                        break\n                if not aname:\n                    aname = aaddress\n                if aname not in authorslist:\n                    authorslist.append(aname)\n            return ', '.join(authorslist)\n        else:\n            return self._notmuch_authors_string", "response": "Returns a string of comma - separated authors that are associated with the current thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_messages(self):\n        if not self._messages:  # if not already cached\n            query = self._dbman.query('thread:' + self._id)\n            thread = next(query.search_threads())\n\n            def accumulate(acc, msg):\n                M = Message(self._dbman, msg, thread=self)\n                acc[M] = []\n                r = msg.get_replies()\n                if r is not None:\n                    for m in r:\n                        acc[M].append(accumulate(acc, m))\n                return M\n\n            self._messages = {}\n            for m in thread.get_toplevel_messages():\n                self._toplevel_messages.append(accumulate(self._messages, m))\n        return self._messages", "response": "Returns all messages in this thread as dict mapping all contained\n        messages to their direct responses."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all replies to the given message contained in this thread or None", "response": "def get_replies_to(self, msg):\n        \"\"\"\n        returns all replies to the given message contained in this thread.\n\n        :param msg: parent message to look up\n        :type msg: :class:`~alot.db.message.Message`\n        :returns: list of :class:`~alot.db.message.Message` or `None`\n        \"\"\"\n        mid = msg.get_message_id()\n        msg_hash = self.get_messages()\n        for m in msg_hash.keys():\n            if m.get_message_id() == mid:\n                return msg_hash[m]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef matches(self, query):\n        thread_query = 'thread:{tid} AND {subquery}'.format(tid=self._id,\n                                                            subquery=query)\n        num_matches = self._dbman.count_messages(thread_query)\n        return num_matches > 0", "response": "Check if this thread matches the given query."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn commandclass argparser and forced parameters used to construct a command for cmdname when called in mode", "response": "def lookup_command(cmdname, mode):\n    \"\"\"\n    returns commandclass, argparser and forced parameters used to construct\n    a command for `cmdname` when called in `mode`.\n\n    :param cmdname: name of the command to look up\n    :type cmdname: str\n    :param mode: mode identifier\n    :type mode: str\n    :rtype: (:class:`Command`, :class:`~argparse.ArgumentParser`,\n            dict(str->dict))\n    \"\"\"\n    if cmdname in COMMANDS[mode]:\n        return COMMANDS[mode][cmdname]\n    elif cmdname in COMMANDS['global']:\n        return COMMANDS['global'][cmdname]\n    else:\n        return None, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse and return a command object from a command line.", "response": "def commandfactory(cmdline, mode='global'):\n    \"\"\"\n    parses `cmdline` and constructs a :class:`Command`.\n\n    :param cmdline: command line to interpret\n    :type cmdline: str\n    :param mode: mode identifier\n    :type mode: str\n    \"\"\"\n    # split commandname and parameters\n    if not cmdline:\n        return None\n    logging.debug('mode:%s got commandline \"%s\"', mode, cmdline)\n    # allow to shellescape without a space after '!'\n    if cmdline.startswith('!'):\n        cmdline = 'shellescape \\'%s\\'' % cmdline[1:]\n    cmdline = re.sub(r'\"(.*)\"', r'\"\\\\\"\\1\\\\\"\"', cmdline)\n    try:\n        args = split_commandstring(cmdline)\n    except ValueError as e:\n        raise CommandParseError(str(e))\n    args = [string_decode(x, 'utf-8') for x in args]\n    logging.debug('ARGS: %s', args)\n    cmdname = args[0]\n    args = args[1:]\n\n    # unfold aliases\n    # TODO: read from settingsmanager\n\n    # get class, argparser and forced parameter\n    (cmdclass, parser, forcedparms) = lookup_command(cmdname, mode)\n    if cmdclass is None:\n        msg = 'unknown command: %s' % cmdname\n        logging.debug(msg)\n        raise CommandParseError(msg)\n\n    parms = vars(parser.parse_args(args))\n    parms.update(forcedparms)\n\n    logging.debug('cmd parms %s', parms)\n\n    # create Command\n    cmd = cmdclass(**parms)\n\n    # set pre and post command hooks\n    get_hook = settings.get_hook\n    cmd.prehook = get_hook('pre_%s_%s' % (mode, cmdname)) or \\\n        get_hook('pre_global_%s' % cmdname)\n    cmd.posthook = get_hook('post_%s_%s' % (mode, cmdname)) or \\\n        get_hook('post_global_%s' % cmdname)\n\n    return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert string chart into text markup with the correct attributes.", "response": "def parse_chart(chart, convert):\n    \"\"\"\n    Convert string chart into text markup with the correct attributes.\n\n    chart -- palette chart as a string\n    convert -- function that converts a single palette entry to an\n        (attr, text) tuple, or None if no match is found\n    \"\"\"\n    out = []\n    for match in re.finditer(ATTR_RE, chart):\n        if match.group('whitespace'):\n            out.append(match.group('whitespace'))\n        entry = match.group('entry')\n        entry = entry.replace(\"_\", \" \")\n        while entry:\n            # try the first four characters\n            attrtext = convert(entry[:SHORT_ATTR])\n            if attrtext:\n                elen = SHORT_ATTR\n                entry = entry[SHORT_ATTR:].strip()\n            else: # try the whole thing\n                attrtext = convert(entry.strip())\n                assert attrtext, \"Invalid palette entry: %r\" % entry\n                elen = len(entry)\n                entry = \"\"\n            attr, text = attrtext\n            out.append((attr, text.ljust(elen)))\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate text markup for a foreground colour chart", "response": "def foreground_chart(chart, background, colors):\n    \"\"\"\n    Create text markup for a foreground colour chart\n\n    chart -- palette chart as string\n    background -- colour to use for background of chart\n    colors -- number of colors (88 or 256)\n    \"\"\"\n    def convert_foreground(entry):\n        try:\n            attr = urwid.AttrSpec(entry, background, colors)\n        except urwid.AttrSpecError:\n            return None\n        return attr, entry\n    return parse_chart(chart, convert_foreground)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef background_chart(chart, foreground, colors):\n    def convert_background(entry):\n        try:\n            attr = urwid.AttrSpec(foreground, entry, colors)\n        except urwid.AttrSpecError:\n            return None\n        # fix 8 <= colour < 16\n        if colors > 16 and attr.background_basic and \\\n            attr.background_number >= 8:\n            # use high-colour with same number\n            entry = 'h%d'%attr.background_number\n            attr = urwid.AttrSpec(foreground, entry, colors)\n        return attr, entry\n    return parse_chart(chart, convert_background)", "response": "Create text markup for a background colour chart"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_tags_part(tags, attr_normal, attr_focus):\n    part_w = None\n    width = None\n    tag_widgets = []\n    cols = []\n    width = -1\n\n    # create individual TagWidgets and sort them\n    tag_widgets = [TagWidget(t, attr_normal, attr_focus) for t in tags]\n    tag_widgets = sorted(tag_widgets)\n\n    for tag_widget in tag_widgets:\n        if not tag_widget.hidden:\n            wrapped_tagwidget = tag_widget\n            tag_width = tag_widget.width()\n            cols.append(('fixed', tag_width, wrapped_tagwidget))\n            width += tag_width + 1\n    if cols:\n        part_w = urwid.Columns(cols, dividechars=1)\n    return width, part_w", "response": "build a list of tags as part of a threadline."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_text_part(name, thread, struct):\n\n    part_w = None\n    width = None\n\n    # extract min and max allowed width from theme\n    minw = 0\n    maxw = None\n    width_tuple = struct['width']\n    if width_tuple is not None:\n        if width_tuple[0] == 'fit':\n            minw, maxw = width_tuple[1:]\n\n    content = prepare_string(name, thread, maxw)\n\n    # pad content if not long enough\n    if minw:\n        alignment = struct['alignment']\n        if alignment == 'left':\n            content = content.ljust(minw)\n        elif alignment == 'center':\n            content = content.center(minw)\n        else:\n            content = content.rjust(minw)\n\n    # define width and part_w\n    text = urwid.Text(content, wrap='clip')\n    width = text.pack()[0]\n    part_w = AttrFlipWidget(text, struct)\n\n    return width, part_w", "response": "build a text part of a threadline"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract a content string for part partname from thread of maximal length maxw.", "response": "def prepare_string(partname, thread, maxw):\n    \"\"\"\n    extract a content string for part 'partname' from 'thread' of maximal\n    length 'maxw'.\n    \"\"\"\n    # map part names to function extracting content string and custom shortener\n    prep = {\n        'mailcount': (prepare_mailcount_string, None),\n        'date': (prepare_date_string, None),\n        'authors': (prepare_authors_string, shorten_author_string),\n        'subject': (prepare_subject_string, None),\n        'content': (prepare_content_string, None),\n    }\n\n    s = ' '  # fallback value\n    if thread:\n        # get extractor and shortener\n        content, shortener = prep[partname]\n\n        # get string\n        s = content(thread)\n\n    # sanitize\n    s = s.replace('\\n', ' ')\n    s = s.replace('\\r', '')\n\n    # shorten if max width is requested\n    if maxw:\n        if len(s) > maxw and shortener:\n            s = shortener(s, maxw)\n        else:\n            s = s[:maxw]\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reload(self):\n        self.read_notmuch_config(self._notmuchconfig.filename)\n        self.read_config(self._config.filename)", "response": "Reloads the notmuch and alot config files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_notmuch_config(self, path):\n        spec = os.path.join(DEFAULTSPATH, 'notmuch.rc.spec')\n        self._notmuchconfig = read_config(path, spec)", "response": "parse notmuch s config file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_config(self, path):\n        spec = os.path.join(DEFAULTSPATH, 'alot.rc.spec')\n        newconfig = read_config(path, spec, report_extra=True, checks={\n                'mail_container': checks.mail_container,\n                'force_list': checks.force_list,\n                'align': checks.align_mode,\n                'attrtriple': checks.attr_triple,\n                'gpg_key_hint': checks.gpg_key})\n        self._config.merge(newconfig)\n        self._config.walk(self._expand_config_values)\n\n        hooks_path = os.path.expanduser(self._config.get('hooksfile'))\n        try:\n            spec = importlib.util.spec_from_file_location('hooks', hooks_path)\n            self.hooks = importlib.util.module_from_spec(spec)\n            spec.loader.exec_module(self.hooks)\n        except:\n            logging.exception('unable to load hooks file:%s', hooks_path)\n        if 'bindings' in newconfig:\n            self._update_bindings(newconfig['bindings'])\n\n        tempdir = self._config.get('template_dir')\n        logging.debug('template directory: `%s`' % tempdir)\n\n        # themes\n        themestring = newconfig['theme']\n        themes_dir = self._config.get('themes_dir')\n        logging.debug('themes directory: `%s`' % themes_dir)\n\n        # if config contains theme string use that\n        data_dirs = [os.path.join(d, 'alot/themes') for d in DATA_DIRS]\n        if themestring:\n            # This is a python for/else loop\n            # https://docs.python.org/3/reference/compound_stmts.html#for\n            #\n            # tl/dr; If the loop loads a theme it breaks. If it doesn't break,\n            # then it raises a ConfigError.\n            for dir_ in itertools.chain([themes_dir], data_dirs):\n                theme_path = os.path.join(dir_, themestring)\n                if not os.path.exists(os.path.expanduser(theme_path)):\n                    logging.warning('Theme `%s` does not exist.', theme_path)\n                else:\n                    try:\n                        self._theme = Theme(theme_path)\n                    except ConfigError as e:\n                        raise ConfigError('Theme file `%s` failed '\n                                          'validation:\\n%s' % (theme_path, e))\n                    else:\n                        break\n            else:\n                raise ConfigError('Could not find theme {}, see log for more '\n                                  'information'.format(themestring))\n\n        # if still no theme is set, resort to default\n        if self._theme is None:\n            theme_path = os.path.join(DEFAULTSPATH, 'default.theme')\n            self._theme = Theme(theme_path)\n\n        self._accounts = self._parse_accounts(self._config)\n        self._accountmap = self._account_table(self._accounts)", "response": "Parse the alot s config file and parse it into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _expand_config_values(section, key):\n\n        def expand_environment_and_home(value):\n            \"\"\"\n            Expands environment variables and the home directory (~).\n\n            $FOO and ${FOO}-style environment variables are expanded, if they\n            exist. If they do not exist, they are left unchanged.\n            The exception are the following $XDG_* variables that are\n            expanded to fallback values, if they are empty or not set:\n            $XDG_CONFIG_HOME\n            $XDG_CACHE_HOME\n\n            :param value: configuration string\n            :type value: str\n            \"\"\"\n            xdg_vars = {'XDG_CONFIG_HOME': '~/.config',\n                        'XDG_CACHE_HOME': '~/.cache'}\n\n            for xdg_name, fallback in xdg_vars.items():\n                if xdg_name in value:\n                    xdg_value = get_xdg_env(xdg_name, fallback)\n                    value = value.replace('$%s' % xdg_name, xdg_value)\\\n                                 .replace('${%s}' % xdg_name, xdg_value)\n            return os.path.expanduser(os.path.expandvars(value))\n\n        value = section[key]\n\n        if isinstance(value, str):\n            section[key] = expand_environment_and_home(value)\n        elif isinstance(value, (list, tuple)):\n            new = list()\n            for item in value:\n                if isinstance(item, str):\n                    new.append(expand_environment_and_home(item))\n                else:\n                    new.append(item)\n            section[key] = new", "response": "Walks the config file and expands environment variables and home directories."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_accounts(config):\n        accounts = []\n        if 'accounts' in config:\n            for acc in config['accounts'].sections:\n                accsec = config['accounts'][acc]\n                args = dict(config['accounts'][acc].items())\n\n                # create abook for this account\n                abook = accsec['abook']\n                logging.debug('abook defined: %s', abook)\n                if abook['type'] == 'shellcommand':\n                    cmd = abook['command']\n                    regexp = abook['regexp']\n                    if cmd is not None and regexp is not None:\n                        ef = abook['shellcommand_external_filtering']\n                        args['abook'] = ExternalAddressbook(\n                            cmd, regexp, external_filtering=ef)\n                    else:\n                        msg = 'underspecified abook of type \\'shellcommand\\':'\n                        msg += '\\ncommand: %s\\nregexp:%s' % (cmd, regexp)\n                        raise ConfigError(msg)\n                elif abook['type'] == 'abook':\n                    contacts_path = abook['abook_contacts_file']\n                    args['abook'] = AbookAddressBook(\n                        contacts_path, ignorecase=abook['ignorecase'])\n                else:\n                    del args['abook']\n\n                cmd = args['sendmail_command']\n                del args['sendmail_command']\n                newacc = SendmailAccount(cmd, **args)\n                accounts.append(newacc)\n        return accounts", "response": "parse accounts information from configobj. ConfigObj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a lookup table for a given list of accounts", "response": "def _account_table(accounts):\n        \"\"\"\n        creates a lookup table (emailaddress -> account) for a given list of\n        accounts\n\n        :param accounts: list of accounts\n        :type accounts: list of `alot.account.Account`\n        :returns: hashtable\n        :rvalue: dict (str -> `alot.account.Account`)\n        \"\"\"\n        accountmap = {}\n        for acc in accounts:\n            accountmap[acc.address] = acc\n            for alias in acc.aliases:\n                accountmap[alias] = acc\n        return accountmap"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, key, fallback=None):\n        value = None\n        if key in self._config:\n            value = self._config[key]\n            if isinstance(value, Section):\n                value = None\n        if value is None:\n            value = fallback\n        return value", "response": "look up global config values from alot s config - file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlook up the value of a given key from the notmuch config file", "response": "def get_notmuch_setting(self, section, key, fallback=None):\n        \"\"\"\n        look up config values from notmuch's config\n\n        :param section: key is in\n        :type section: str\n        :param key: key to look up\n        :type key: str\n        :param fallback: fallback returned if key is not present\n        :type fallback: str\n        :returns: config value with type as specified in the spec-file\n        \"\"\"\n        value = None\n        if section in self._notmuchconfig:\n            if key in self._notmuchconfig[section]:\n                value = self._notmuchconfig[section][key]\n        if value is None:\n            value = fallback\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_theming_attribute(self, mode, name, part=None):\n        colours = int(self._config.get('colourmode'))\n        return self._theme.get_attribute(colours, mode, name, part)", "response": "look up theming attribute"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_threadline_theming(self, thread):\n        colours = int(self._config.get('colourmode'))\n        return self._theme.get_threadline_theming(thread, colours)", "response": "Returns a dict of theming info a threadline displaying a given thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary mapping from tagstring to alternative string representation", "response": "def get_tagstring_representation(self, tag, onebelow_normal=None,\n                                     onebelow_focus=None):\n        \"\"\"\n        looks up user's preferred way to represent a given tagstring.\n\n        :param tag: tagstring\n        :type tag: str\n        :param onebelow_normal: attribute that shines through if unfocussed\n        :type onebelow_normal: urwid.AttrSpec\n        :param onebelow_focus: attribute that shines through if focussed\n        :type onebelow_focus: urwid.AttrSpec\n\n        If `onebelow_normal` or `onebelow_focus` is given these attributes will\n        be used as fallbacks for fg/bg values '' and 'default'.\n\n        This returns a dictionary mapping\n            :normal: to :class:`urwid.AttrSpec` used if unfocussed\n            :focussed: to :class:`urwid.AttrSpec` used if focussed\n            :translated: to an alternative string representation\n        \"\"\"\n        colourmode = int(self._config.get('colourmode'))\n        theme = self._theme\n        cfg = self._config\n        colours = [1, 16, 256]\n\n        def colourpick(triple):\n            \"\"\" pick attribute from triple (mono,16c,256c) according to current\n            colourmode\"\"\"\n            if triple is None:\n                return None\n            return triple[colours.index(colourmode)]\n\n        # global default attributes for tagstrings.\n        # These could contain values '' and 'default' which we interpret as\n        # \"use the values from the widget below\"\n        default_normal = theme.get_attribute(colourmode, 'global', 'tag')\n        default_focus = theme.get_attribute(colourmode, 'global', 'tag_focus')\n\n        # local defaults for tagstring attributes. depend on next lower widget\n        fallback_normal = resolve_att(onebelow_normal, default_normal)\n        fallback_focus = resolve_att(onebelow_focus, default_focus)\n\n        for sec in cfg['tags'].sections:\n            if re.match('^{}$'.format(sec), tag):\n                normal = resolve_att(colourpick(cfg['tags'][sec]['normal']),\n                                     fallback_normal)\n                focus = resolve_att(colourpick(cfg['tags'][sec]['focus']),\n                                    fallback_focus)\n\n                translated = cfg['tags'][sec]['translated']\n                translated = string_decode(translated, 'UTF-8')\n                if translated is None:\n                    translated = tag\n                translation = cfg['tags'][sec]['translation']\n                if translation:\n                    translated = re.sub(translation[0], translation[1], tag)\n                break\n        else:\n            normal = fallback_normal\n            focus = fallback_focus\n            translated = tag\n\n        return {'normal': normal, 'focussed': focus, 'translated': translated}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget keybindings from MODE - maps sections", "response": "def get_keybindings(self, mode):\n        \"\"\"look up keybindings from `MODE-maps` sections\n\n        :param mode: mode identifier\n        :type mode: str\n        :returns: dictionaries of key-cmd for global and specific mode\n        :rtype: 2-tuple of dicts\n        \"\"\"\n        globalmaps, modemaps = {}, {}\n        bindings = self._bindings\n        # get bindings for mode `mode`\n        # retain empty assignations to silence corresponding global mappings\n        if mode in bindings.sections:\n            for key in bindings[mode].scalars:\n                value = bindings[mode][key]\n                if isinstance(value, list):\n                    value = ','.join(value)\n                modemaps[key] = value\n        # get global bindings\n        # ignore the ones already mapped in mode bindings\n        for key in bindings.scalars:\n            if key not in modemaps:\n                value = bindings[key]\n                if isinstance(value, list):\n                    value = ','.join(value)\n                if value and value != '':\n                    globalmaps[key] = value\n        # get rid of empty commands left in mode bindings\n        for k, v in list(modemaps.items()):\n            if not v:\n                del modemaps[k]\n\n        return globalmaps, modemaps"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlooks up keybinding from MODE - maps sections = > key", "response": "def get_keybinding(self, mode, key):\n        \"\"\"look up keybinding from `MODE-maps` sections\n\n        :param mode: mode identifier\n        :type mode: str\n        :param key: urwid-style key identifier\n        :type key: str\n        :returns: a command line to be applied upon keypress\n        :rtype: str\n        \"\"\"\n        cmdline = None\n        bindings = self._bindings\n        if key in bindings.scalars:\n            cmdline = bindings[key]\n        if mode in bindings.sections:\n            if key in bindings[mode].scalars:\n                value = bindings[mode][key]\n                if value:\n                    cmdline = value\n                else:\n                    # to be sure it isn't mapped globally\n                    cmdline = None\n        # Workaround for ConfigObj misbehaviour. cf issue #500\n        # this ensures that we get at least strings only as commandlines\n        if isinstance(cmdline, list):\n            cmdline = ','.join(cmdline)\n        return cmdline"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the first account that matches the given email address", "response": "def account_matching_address(self, address, return_default=False):\n        \"\"\"returns :class:`Account` for a given email address (str)\n\n        :param str address: address to look up. A realname part will be ignored.\n        :param bool return_default: If True and no address can be found, then\n            the default account wil be returned.\n        :rtype: :class:`Account`\n        :raises ~alot.settings.errors.NoMatchingAccount: If no account can be\n            found. This includes if return_default is True and there are no\n            accounts defined.\n        \"\"\"\n        _, address = email.utils.parseaddr(address)\n        for account in self.get_accounts():\n            if account.matches_address(address):\n                return account\n        if return_default:\n            try:\n                return self.get_accounts()[0]\n            except IndexError:\n                # Fall through\n                pass\n        raise NoMatchingAccount"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_addressbooks(self, order=None, append_remaining=True):\n        order = order or []\n        abooks = []\n        for a in order:\n            if a:\n                if a.abook:\n                    abooks.append(a.abook)\n        if append_remaining:\n            for a in self._accounts:\n                if a.abook and a.abook not in abooks:\n                    abooks.append(a.abook)\n        return abooks", "response": "returns list of all defined : class : AddressBooks objects"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mailcap_find_match(self, *args, **kwargs):\n        return mailcap.findmatch(self._mailcaps, *args, **kwargs)", "response": "Returns a list of matching mailcaps."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrepresent a given datetime obj into a string representation.", "response": "def represent_datetime(self, d):\n        \"\"\"\n        turns a given datetime obj into a string representation.\n        This will:\n\n        1) look if a fixed 'timestamp_format' is given in the config\n        2) check if a 'timestamp_format' hook is defined\n        3) use :func:`~alot.helper.pretty_datetime` as fallback\n        \"\"\"\n\n        fixed_format = self.get('timestamp_format')\n        if fixed_format:\n            rep = string_decode(d.strftime(fixed_format), 'UTF-8')\n        else:\n            format_hook = self.get_hook('timestamp_format')\n            if format_hook:\n                rep = string_decode(format_hook(d), 'UTF-8')\n            else:\n                rep = pretty_datetime(d)\n        return rep"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning currently selected : class:`Buffer` element from list", "response": "def get_selected_buffer(self):\n        \"\"\"returns currently selected :class:`Buffer` element from list\"\"\"\n        linewidget, _ = self.bufferlist.get_focus()\n        bufferlinewidget = linewidget.get_focus().original_widget\n        return bufferlinewidget.get_buffer()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef computed(self):\n        return (\n            self._computed and\n            self.solver.computed and\n            (self.kernel is None or not self.kernel.dirty)\n        )", "response": "Returns True if the process cache has been computed since the last update of the kernel?"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a list of samples to make sure that they have the correct dimensions.", "response": "def parse_samples(self, t):\n        \"\"\"\n        Parse a list of samples to make sure that it has the correct\n        dimensions.\n\n        :param t: ``(nsamples,)`` or ``(nsamples, ndim)``\n            The list of samples. If 1-D, this is assumed to be a list of\n            one-dimensional samples otherwise, the size of the second\n            dimension is assumed to be the dimension of the input space.\n\n        Raises:\n            ValueError: If the input dimension doesn't match the dimension of\n                the kernel.\n\n        \"\"\"\n        t = np.atleast_1d(t)\n        # Deal with one-dimensional data.\n        if len(t.shape) == 1:\n            t = np.atleast_2d(t).T\n\n        # Double check the dimensions against the kernel.\n        if len(t.shape) != 2 or (self.kernel is not None and\n                                 t.shape[1] != self.kernel.ndim):\n            raise ValueError(\"Dimension mismatch\")\n\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute(self, x, yerr=0.0, **kwargs):\n        # Parse the input coordinates and ensure the right memory layout.\n        self._x = self.parse_samples(x)\n        self._x = np.ascontiguousarray(self._x, dtype=np.float64)\n        try:\n            self._yerr2 = float(yerr)**2 * np.ones(len(x))\n        except TypeError:\n            self._yerr2 = self._check_dimensions(yerr) ** 2\n        self._yerr2 = np.ascontiguousarray(self._yerr2, dtype=np.float64)\n\n        # Set up and pre-compute the solver.\n        self.solver = self.solver_type(self.kernel, **(self.solver_kwargs))\n\n        # Include the white noise term.\n        yerr = np.sqrt(self._yerr2 + np.exp(self._call_white_noise(self._x)))\n        self.solver.compute(self._x, yerr, **kwargs)\n\n        self._const = -0.5 * (len(self._x) * np.log(2 * np.pi) +\n                              self.solver.log_determinant)\n        self.computed = True\n        self._alpha = None", "response": "Compute the covariance matrix and factorize it for a set of times\n            and uncertainties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recompute(self, quiet=False, **kwargs):\n        if not self.computed:\n            if not (hasattr(self, \"_x\") and hasattr(self, \"_yerr2\")):\n                raise RuntimeError(\"You need to compute the model first\")\n            try:\n                # Update the model making sure that we store the original\n                # ordering of the points.\n                self.compute(self._x, np.sqrt(self._yerr2), **kwargs)\n            except (ValueError, LinAlgError):\n                if quiet:\n                    return False\n                raise\n        return True", "response": "Recompute the model of a previously computed one."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the logarithm of the marginalized likelihood of a set of algebraic and a set of observations at the given coordinates.", "response": "def log_likelihood(self, y, quiet=False):\n        \"\"\"\n        Compute the logarithm of the marginalized likelihood of a set of\n        observations under the Gaussian process model. You must call\n        :func:`GP.compute` before this function.\n\n        :param y: ``(nsamples, )``\n            The observations at the coordinates provided in the ``compute``\n            step.\n\n        :param quiet:\n            If ``True`` return negative infinity instead of raising an\n            exception when there is an invalid kernel or linear algebra\n            failure. (default: ``False``)\n\n        \"\"\"\n        if not self.recompute(quiet=quiet):\n            return -np.inf\n        try:\n            mu = self._call_mean(self._x)\n        except ValueError:\n            if quiet:\n                return -np.inf\n            raise\n        r = np.ascontiguousarray(self._check_dimensions(y) - mu,\n                                 dtype=np.float64)\n        ll = self._const - 0.5 * self.solver.dot_solve(r)\n        return ll if np.isfinite(ll) else -np.inf"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the gradient of the log likelihood of the current state of the object.", "response": "def grad_log_likelihood(self, y, quiet=False):\n        \"\"\"\n        Compute the gradient of :func:`GP.log_likelihood` as a function of the\n        parameters returned by :func:`GP.get_parameter_vector`. You must call\n        :func:`GP.compute` before this function.\n\n        :param y: ``(nsamples,)``\n            The list of observations at coordinates ``x`` provided to the\n            :func:`compute` function.\n\n        :param quiet:\n            If ``True`` return a gradient of zero instead of raising an\n            exception when there is an invalid kernel or linear algebra\n            failure. (default: ``False``)\n\n        \"\"\"\n        # Make sure that the model is computed and try to recompute it if it's\n        # dirty.\n        if not self.recompute(quiet=quiet):\n            return np.zeros(len(self), dtype=np.float64)\n\n        # Pre-compute some factors.\n        try:\n            alpha = self._compute_alpha(y, False)\n        except ValueError:\n            if quiet:\n                return np.zeros(len(self), dtype=np.float64)\n            raise\n\n        if len(self.white_noise) or len(self.kernel):\n            K_inv = self.solver.get_inverse()\n            A = np.einsum(\"i,j\", alpha, alpha) - K_inv\n\n        # Compute each component of the gradient.\n        grad = np.empty(len(self))\n        n = 0\n\n        l = len(self.mean)\n        if l:\n            try:\n                mu = self._call_mean_gradient(self._x)\n            except ValueError:\n                if quiet:\n                    return np.zeros(len(self), dtype=np.float64)\n                raise\n            grad[n:n+l] = np.dot(mu, alpha)\n            n += l\n\n        l = len(self.white_noise)\n        if l:\n            wn = self._call_white_noise(self._x)\n            wng = self._call_white_noise_gradient(self._x)\n            grad[n:n+l] = 0.5 * np.sum((np.exp(wn)*np.diag(A))[None, :]*wng,\n                                       axis=1)\n            n += l\n\n        l = len(self.kernel)\n        if l:\n            Kg = self.kernel.get_gradient(self._x)\n            grad[n:n+l] = 0.5 * np.einsum(\"ijk,ij\", Kg, A)\n\n        return grad"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the conditional predictive distribution of the model on the observations y and t.", "response": "def predict(self, y, t,\n                return_cov=True,\n                return_var=False,\n                cache=True,\n                kernel=None):\n        \"\"\"\n        Compute the conditional predictive distribution of the model. You must\n        call :func:`GP.compute` before this function.\n\n        :param y: ``(nsamples,)``\n            The observations to condition the model on.\n\n        :param t: ``(ntest,)`` or ``(ntest, ndim)``\n            The coordinates where the predictive distribution should be\n            computed.\n\n        :param return_cov: (optional)\n            If ``True``, the full covariance matrix is computed and returned.\n            Otherwise, only the mean prediction is computed. (default:\n            ``True``)\n\n        :param return_var: (optional)\n            If ``True``, only return the diagonal of the predictive covariance;\n            this will be faster to compute than the full covariance matrix.\n            This overrides ``return_cov`` so, if both are set to ``True``,\n            only the diagonal is computed. (default: ``False``)\n\n        :param cache: (optional)\n            If ``True`` the value of alpha will be cached to speed up repeated\n            predictions.\n\n        :param kernel: (optional)\n            If provided, this kernel will be used to calculate the cross terms.\n            This can be used to separate the predictions from different\n            kernels.\n\n        Returns ``mu``, ``(mu, cov)``, or ``(mu, var)`` depending on the values\n        of ``return_cov`` and ``return_var``. These output values are:\n\n        * **mu** ``(ntest,)``: mean of the predictive distribution,\n        * **cov** ``(ntest, ntest)``: the predictive covariance matrix, and\n        * **var** ``(ntest,)``: the diagonal elements of ``cov``.\n\n        \"\"\"\n        self.recompute()\n        alpha = self._compute_alpha(y, cache)\n        xs = self.parse_samples(t)\n\n        if kernel is None:\n            kernel = self.kernel\n\n        # Compute the predictive mean.\n        Kxs = kernel.get_value(xs, self._x)\n        mu = np.dot(Kxs, alpha) + self._call_mean(xs)\n        if not (return_var or return_cov):\n            return mu\n\n        KinvKxs = self.solver.apply_inverse(Kxs.T)\n        if return_var:\n            var = kernel.get_value(xs, diag=True)\n            var -= np.sum(Kxs.T*KinvKxs, axis=0)\n            return mu, var\n\n        cov = kernel.get_value(xs)\n        cov -= np.dot(Kxs, KinvKxs)\n        return mu, cov"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sample_conditional(self, y, t, size=1):\n        mu, cov = self.predict(y, t)\n        return multivariate_gaussian_samples(cov, size, mean=mu)", "response": "Draw samples from the predictive conditional distribution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw samples from the prior distribution.", "response": "def sample(self, t=None, size=1):\n        \"\"\"\n        Draw samples from the prior distribution.\n\n        :param t: ``(ntest, )`` or ``(ntest, ndim)`` (optional)\n            The coordinates where the model should be sampled. If no\n            coordinates are given, the precomputed coordinates and\n            factorization are used.\n\n        :param size: (optional)\n            The number of samples to draw. (default: ``1``)\n\n        Returns **samples** ``(size, ntest)``, a list of predictions at\n        coordinates given by ``t``. If ``size == 1``, the result is a single\n        sample with shape ``(ntest,)``.\n\n        \"\"\"\n        if t is None:\n            self.recompute()\n            n, _ = self._x.shape\n\n            # Generate samples using the precomputed factorization.\n            results = self.solver.apply_sqrt(np.random.randn(size, n))\n            results += self._call_mean(self._x)\n            return results[0] if size == 1 else results\n\n        x = self.parse_samples(t)\n        cov = self.get_matrix(x)\n        cov[np.diag_indices_from(cov)] += TINY\n        return multivariate_gaussian_samples(cov, size,\n                                             mean=self._call_mean(x))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_matrix(self, x1, x2=None):\n        x1 = self.parse_samples(x1)\n        if x2 is None:\n            return self.kernel.get_value(x1)\n        x2 = self.parse_samples(x2)\n        return self.kernel.get_value(x1, x2)", "response": "Get the covariance matrix at a given set or two of independent\n            coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a boolean indicating whether a flag name is supported on the specified compiler.", "response": "def has_flag(compiler, flagname):\n    \"\"\"Return a boolean indicating whether a flag name is supported on\n    the specified compiler.\n    \"\"\"\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".cpp\") as f:\n        f.write(\"int main (int argc, char **argv) { return 0; }\")\n        try:\n            compiler.compile([f.name], extra_postargs=[flagname])\n        except setuptools.distutils.errors.CompileError:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_library(compiler, libname):\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".cpp\") as srcfile:\n        srcfile.write(\"int main (int argc, char **argv) { return 0; }\")\n        srcfile.flush()\n        outfn = srcfile.name + \".so\"\n        try:\n            compiler.link_executable(\n                [srcfile.name],\n                outfn,\n                libraries=[libname],\n            )\n        except setuptools.distutils.errors.LinkError:\n            return False\n        if not os.path.exists(outfn):\n            return False\n        os.remove(outfn)\n    return True", "response": "Return a boolean indicating whether a library is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes and factorize the covariance matrix.", "response": "def compute(self, x, yerr):\n        \"\"\"\n        Compute and factorize the covariance matrix.\n\n        Args:\n            x (ndarray[nsamples, ndim]): The independent coordinates of the\n                data points.\n            yerr (ndarray[nsamples] or float): The Gaussian uncertainties on\n                the data points at coordinates ``x``. These values will be\n                added in quadrature to the diagonal of the covariance matrix.\n\n        \"\"\"\n        # Compute the kernel matrix.\n        K = self.kernel.get_value(x)\n        K[np.diag_indices_from(K)] += yerr ** 2\n\n        # Factor the matrix and compute the log-determinant.\n        self._factor = (cholesky(K, overwrite_a=True, lower=False), False)\n        self.log_determinant = 2 * np.sum(np.log(np.diag(self._factor[0])))\n        self.computed = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_inverse(self, y, in_place=False):\n        return cho_solve(self._factor, y, overwrite_b=in_place)", "response": "r Apply the inverse of the covariance matrix to the input by solving the K matrix."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dot_solve(self, y):\n        return np.dot(y.T, cho_solve(self._factor, y))", "response": "r Compute the inner product of a vector with the inverse of the covariance matrix applied to itself."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the dense inverse covariance matrix.", "response": "def get_inverse(self):\n        \"\"\"\n        Get the dense inverse covariance matrix. This is used for computing\n        gradients, but it is not recommended in general.\n        \"\"\"\n        return self.apply_inverse(np.eye(len(self._factor[0])), in_place=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an ordered dictionary of the parameters", "response": "def get_parameter_dict(self, include_frozen=False):\n        \"\"\"\n        Get an ordered dictionary of the parameters\n\n        Args:\n            include_frozen (Optional[bool]): Should the frozen parameters be\n                included in the returned value? (default: ``False``)\n\n        \"\"\"\n        return OrderedDict(zip(\n            self.get_parameter_names(include_frozen=include_frozen),\n            self.get_parameter_vector(include_frozen=include_frozen),\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of the parameter names that are available in the current instance.", "response": "def get_parameter_names(self, include_frozen=False):\n        \"\"\"\n        Get a list of the parameter names\n\n        Args:\n            include_frozen (Optional[bool]): Should the frozen parameters be\n                included in the returned value? (default: ``False``)\n\n        \"\"\"\n        if include_frozen:\n            return self.parameter_names\n        return tuple(p\n                     for p, f in zip(self.parameter_names, self.unfrozen_mask)\n                     if f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of the parameter bounds that are in the order they were set.", "response": "def get_parameter_bounds(self, include_frozen=False):\n        \"\"\"\n        Get a list of the parameter bounds\n\n        Args:\n            include_frozen (Optional[bool]): Should the frozen parameters be\n                included in the returned value? (default: ``False``)\n\n        \"\"\"\n        if include_frozen:\n            return self.parameter_bounds\n        return list(p\n                    for p, f in zip(self.parameter_bounds, self.unfrozen_mask)\n                    if f)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an array of the parameter values in the correct order.", "response": "def get_parameter_vector(self, include_frozen=False):\n        \"\"\"\n        Get an array of the parameter values in the correct order\n\n        Args:\n            include_frozen (Optional[bool]): Should the frozen parameters be\n                included in the returned value? (default: ``False``)\n\n        \"\"\"\n        if include_frozen:\n            return self.parameter_vector\n        return self.parameter_vector[self.unfrozen_mask]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_parameter_vector(self, vector, include_frozen=False):\n        v = self.parameter_vector\n        if include_frozen:\n            v[:] = vector\n        else:\n            v[self.unfrozen_mask] = vector\n        self.parameter_vector = v\n        self.dirty = True", "response": "Sets the parameter vector to the given vector."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfreeze a parameter by name.", "response": "def freeze_parameter(self, name):\n        \"\"\"\n        Freeze a parameter by name\n\n        Args:\n            name: The name of the parameter\n\n        \"\"\"\n        i = self.get_parameter_names(include_frozen=True).index(name)\n        self.unfrozen_mask[i] = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef thaw_parameter(self, name):\n        i = self.get_parameter_names(include_frozen=True).index(name)\n        self.unfrozen_mask[i] = True", "response": "Thaw a parameter by name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_parameter(self, name):\n        i = self.get_parameter_names(include_frozen=True).index(name)\n        return self.get_parameter_vector(include_frozen=True)[i]", "response": "Get a parameter value by name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_parameter(self, name, value):\n        i = self.get_parameter_names(include_frozen=True).index(name)\n        v = self.get_parameter_vector(include_frozen=True)\n        v[i] = value\n        self.set_parameter_vector(v, include_frozen=True)", "response": "Set a parameter value by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log_prior(self):\n        for p, b in zip(self.parameter_vector, self.parameter_bounds):\n            if b[0] is not None and p < b[0]:\n                return -np.inf\n            if b[1] is not None and p > b[1]:\n                return -np.inf\n        return 0.0", "response": "Compute the log prior probability of the current parameters"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef multivariate_gaussian_samples(matrix, N, mean=None):\n    if mean is None:\n        mean = np.zeros(len(matrix))\n    samples = np.random.multivariate_normal(mean, matrix, N)\n    if N == 1:\n        return samples[0]\n    return samples", "response": "Generates samples from a multidimensional Gaussian with a given covariance matrix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsort an N - dimensional list of samples using a KDTree.", "response": "def nd_sort_samples(samples):\n    \"\"\"\n    Sort an N-dimensional list of samples using a KDTree.\n\n    :param samples: ``(nsamples, ndim)``\n        The list of samples. This must be a two-dimensional array.\n\n    :returns i: ``(nsamples,)``\n        The list of indices into the original array that return the correctly\n        sorted version.\n\n    \"\"\"\n    # Check the shape of the sample list.\n    assert len(samples.shape) == 2\n\n    # Build a KD-tree on the samples.\n    tree = cKDTree(samples)\n\n    # Compute the distances.\n    d, i = tree.query(samples[0], k=len(samples))\n    return i"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlook - up and return a pretty - printer that can print va.", "response": "def lookup_function(val):\n\t\"Look-up and return a pretty-printer that can print va.\"\n\t\n\ttype = val.type\n\t\n\tif type.code == gdb.TYPE_CODE_REF:\n\t\ttype = type.target()\n\t\n\ttype = type.unqualified().strip_typedefs()\n\t\n\ttypename = type.tag\n\tif typename == None:\n\t\treturn None\n\t\n\tfor function in pretty_printers_dict:\n\t\tif function.search(typename):\n\t\t\treturn pretty_printers_dict[function](val)\n\t\n\treturn None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serve_static(request, path, insecure=False, **kwargs):\n    # Follow the same logic Django uses for determining access to the\n    # static-serving view.\n    if not django_settings.DEBUG and not insecure:\n        raise ImproperlyConfigured(\"The staticfiles view can only be used in \"\n                                   \"debug mode or if the --insecure \"\n                                   \"option of 'runserver' is used\")\n\n    if not settings.PIPELINE_ENABLED and settings.PIPELINE_COLLECTOR_ENABLED:\n        # Collect only the requested file, in order to serve the result as\n        # fast as possible. This won't interfere with the template tags in any\n        # way, as those will still cause Django to collect all media.\n        default_collector.collect(request, files=[path])\n\n    return serve(request, path, document_root=django_settings.STATIC_ROOT,\n                 **kwargs)", "response": "Collect and serve static files.\n\n    This view serves up static files, much like Django's\n    :py:func:`~django.views.static.serve` view, with the addition that it\n    collects static files first (if enabled). This allows images, fonts, and\n    other assets to be served up without first loading a page using the\n    ``{% javascript %}`` or ``{% stylesheet %}`` template tags.\n\n    You can use this view by adding the following to any :file:`urls.py`::\n\n        urlpatterns += static('static/', view='pipeline.views.serve_static')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconcatenating and compress JS files", "response": "def compress_js(self, paths, templates=None, **kwargs):\n        \"\"\"Concatenate and compress JS files\"\"\"\n        js = self.concatenate(paths)\n        if templates:\n            js = js + self.compile_templates(templates)\n\n        if not settings.DISABLE_WRAPPER:\n            js = settings.JS_WRAPPER % js\n\n        compressor = self.js_compressor\n        if compressor:\n            js = getattr(compressor(verbose=self.verbose), 'compress_js')(js)\n\n        return js"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconcatenates and compress CSS files and rewrite them to output_filename.", "response": "def compress_css(self, paths, output_filename, variant=None, **kwargs):\n        \"\"\"Concatenate and compress CSS files\"\"\"\n        css = self.concatenate_and_rewrite(paths, output_filename, variant)\n        compressor = self.css_compressor\n        if compressor:\n            css = getattr(compressor(verbose=self.verbose), 'compress_css')(css)\n        if not variant:\n            return css\n        elif variant == \"datauri\":\n            return self.with_data_uri(css)\n        else:\n            raise CompressorError(\"\\\"%s\\\" is not a valid variant\" % variant)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef template_name(self, path, base):\n        if not base:\n            path = os.path.basename(path)\n        if path == base:\n            base = os.path.dirname(path)\n        name = re.sub(r\"^%s[\\/\\\\]?(.*)%s$\" % (\n            re.escape(base), re.escape(settings.TEMPLATE_EXT)\n        ), r\"\\1\", path)\n        return re.sub(r\"[\\/\\\\]\", settings.TEMPLATE_SEPARATOR, name)", "response": "Find out the name of a JS template"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconcatenate together files and rewrite urls", "response": "def concatenate_and_rewrite(self, paths, output_filename, variant=None):\n        \"\"\"Concatenate together files and rewrite urls\"\"\"\n        stylesheets = []\n        for path in paths:\n            def reconstruct(match):\n                quote = match.group(1) or ''\n                asset_path = match.group(2)\n                if NON_REWRITABLE_URL.match(asset_path):\n                    return \"url(%s%s%s)\" % (quote, asset_path, quote)\n                asset_url = self.construct_asset_path(asset_path, path,\n                                                      output_filename, variant)\n                return \"url(%s)\" % asset_url\n            content = self.read_text(path)\n            # content needs to be unicode to avoid explosions with non-ascii chars\n            content = re.sub(URL_DETECTOR, reconstruct, content)\n            stylesheets.append(content)\n        return '\\n'.join(stylesheets)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef construct_asset_path(self, asset_path, css_path, output_filename, variant=None):\n        public_path = self.absolute_path(asset_path, os.path.dirname(css_path).replace('\\\\', '/'))\n        if self.embeddable(public_path, variant):\n            return \"__EMBED__%s\" % public_path\n        if not posixpath.isabs(asset_path):\n            asset_path = self.relative_path(public_path, output_filename)\n        return asset_path", "response": "Construct the asset path for a stylesheet"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nam the asset embeddable?", "response": "def embeddable(self, path, variant):\n        \"\"\"Is the asset embeddable ?\"\"\"\n        name, ext = os.path.splitext(path)\n        font = ext in FONT_EXTS\n        if not variant:\n            return False\n        if not (re.search(settings.EMBED_PATH, path.replace('\\\\', '/')) and self.storage.exists(path)):\n            return False\n        if ext not in EMBED_EXTS:\n            return False\n        if not (font or len(self.encoded_content(path)) < settings.EMBED_MAX_IMAGE_SIZE):\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encoded_content(self, path):\n        if path in self.__class__.asset_contents:\n            return self.__class__.asset_contents[path]\n        data = self.read_bytes(path)\n        self.__class__.asset_contents[path] = force_text(base64.b64encode(data))\n        return self.__class__.asset_contents[path]", "response": "Return the base64 encoded contents of the file at the given path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mime_type(self, path):\n        name, ext = os.path.splitext(path)\n        return MIME_TYPES[ext]", "response": "Get mime - type from filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef absolute_path(self, path, start):\n        if posixpath.isabs(path):\n            path = posixpath.join(staticfiles_storage.location, path)\n        else:\n            path = posixpath.join(start, path)\n        return posixpath.normpath(path)", "response": "Return the absolute public path for an asset given the path of the stylesheet that contains it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrewrite paths relative to the output stylesheet path", "response": "def relative_path(self, absolute_path, output_filename):\n        \"\"\"Rewrite paths relative to the output stylesheet path\"\"\"\n        absolute_path = posixpath.join(settings.PIPELINE_ROOT, absolute_path)\n        output_path = posixpath.join(settings.PIPELINE_ROOT, posixpath.dirname(output_filename))\n        return relpath(absolute_path, output_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_bytes(self, path):\n        file = staticfiles_storage.open(path)\n        content = file.read()\n        file.close()\n        return content", "response": "Read file content in binary mode"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an iterator which yields the paths matching a pathname pattern.", "response": "def iglob(pathname):\n    \"\"\"Return an iterator which yields the paths matching a pathname pattern.\n\n    The pattern may contain simple shell-style wildcards a la fnmatch.\n\n    \"\"\"\n    if not has_magic(pathname):\n        yield pathname\n        return\n    dirname, basename = os.path.split(pathname)\n    if not dirname:\n        for name in glob1(dirname, basename):\n            yield name\n        return\n    if has_magic(dirname):\n        dirs = iglob(dirname)\n    else:\n        dirs = [dirname]\n    if has_magic(basename):\n        glob_in_dir = glob1\n    else:\n        glob_in_dir = glob0\n    for dirname in dirs:\n        for name in glob_in_dir(dirname, basename):\n            yield os.path.join(dirname, name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relpath(path, start=posixpath.curdir):\n    if not path:\n        raise ValueError(\"no path specified\")\n\n    start_list = posixpath.abspath(start).split(posixpath.sep)\n    path_list = posixpath.abspath(path).split(posixpath.sep)\n\n    # Work out how much of the filepath is shared by start and path.\n    i = len(posixpath.commonprefix([start_list, path_list]))\n\n    rel_list = [posixpath.pardir] * (len(start_list) - i) + path_list[i:]\n    if not rel_list:\n        return posixpath.curdir\n    return posixpath.join(*rel_list)", "response": "Return a relative version of a path"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the standard streams to non - blocking.", "response": "def set_std_streams_blocking():\n    \"\"\"\n    Set stdout and stderr to be blocking.\n\n    This is called after Popen.communicate() to revert stdout and stderr back\n    to be blocking (the default) in the event that the process to which they\n    were passed manipulated one or both file descriptors to be non-blocking.\n    \"\"\"\n    if not fcntl:\n        return\n    for f in (sys.__stdout__, sys.__stderr__):\n        fileno = f.fileno()\n        flags = fcntl.fcntl(fileno, fcntl.F_GETFL)\n        fcntl.fcntl(fileno, fcntl.F_SETFL, flags & ~os.O_NONBLOCK)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute_command(self, command, cwd=None, stdout_captured=None):\n        argument_list = []\n        for flattening_arg in command:\n            if isinstance(flattening_arg, string_types):\n                argument_list.append(flattening_arg)\n            else:\n                argument_list.extend(flattening_arg)\n\n        # The first element in argument_list is the program that will be executed; if it is '', then\n        # a PermissionError will be raised. Thus empty arguments are filtered out from argument_list\n        argument_list = list(filter(None, argument_list))\n        stdout = None\n        try:\n            # We always catch stdout in a file, but we may not have a use for it.\n            temp_file_container = cwd or os.path.dirname(stdout_captured or \"\") or os.getcwd()\n            with NamedTemporaryFile(delete=False, dir=temp_file_container) as stdout:\n                compiling = subprocess.Popen(argument_list, cwd=cwd,\n                                             stdout=stdout,\n                                             stderr=subprocess.PIPE)\n                _, stderr = compiling.communicate()\n                set_std_streams_blocking()\n\n            if compiling.returncode != 0:\n                stdout_captured = None  # Don't save erroneous result.\n                raise CompilerError(\n                    \"{0!r} exit code {1}\\n{2}\".format(argument_list, compiling.returncode, stderr),\n                    command=argument_list,\n                    error_output=stderr)\n\n            # User wants to see everything that happened.\n            if self.verbose:\n                with open(stdout.name) as out:\n                    print(out.read())\n                print(stderr)\n        except OSError as e:\n            stdout_captured = None  # Don't save erroneous result.\n            raise CompilerError(e, command=argument_list,\n                                error_output=text_type(e))\n        finally:\n            # Decide what to do with captured stdout.\n            if stdout:\n                if stdout_captured:\n                    shutil.move(stdout.name, os.path.join(cwd or os.curdir, stdout_captured))\n                else:\n                    os.remove(stdout.name)", "response": "Execute a command at cwd saving its normal output at stdout_captured."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all CSS files from the Media class.", "response": "def _get_css_files(cls, extra_files):\n        \"\"\"Return all CSS files from the Media class.\n\n        Args:\n            extra_files (dict):\n                The contents of the Media class's original :py:attr:`css`\n                attribute, if one was provided.\n\n        Returns:\n            dict:\n            The CSS media types and files to return for the :py:attr:`css`\n            attribute.\n        \"\"\"\n        packager = Packager()\n        css_packages = getattr(cls, 'css_packages', {})\n\n        return dict(\n            (media_target,\n             cls._get_media_files(packager=packager,\n                                  media_packages=media_packages,\n                                  media_type='css',\n                                  extra_files=extra_files.get(media_target,\n                                                              [])))\n            for media_target, media_packages in six.iteritems(css_packages)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_js_files(cls, extra_files):\n        return cls._get_media_files(\n            packager=Packager(),\n            media_packages=getattr(cls, 'js_packages', {}),\n            media_type='js',\n            extra_files=extra_files)", "response": "Returns all JavaScript files from the Media class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_media_files(cls, packager, media_packages, media_type,\n                         extra_files):\n        \"\"\"Return source or output media files for a list of packages.\n\n        This will go through the media files belonging to the provided list\n        of packages referenced in a Media class and return the output files\n        (if Pipeline is enabled) or the source files (if not enabled).\n\n        Args:\n            packager (pipeline.packager.Packager):\n                The packager responsible for media compilation for this type\n                of package.\n\n            media_packages (list of unicode):\n                The list of media packages referenced in Media to compile or\n                return.\n\n            extra_files (list of unicode):\n                The list of extra files to include in the result. This would\n                be the list stored in the Media class's original :py:attr:`css`\n                or :py:attr:`js` attributes.\n\n        Returns:\n            list:\n            The list of media files for the given packages.\n        \"\"\"\n        source_files = list(extra_files)\n\n        if (not settings.PIPELINE_ENABLED and\n            settings.PIPELINE_COLLECTOR_ENABLED):\n            default_collector.collect()\n\n        for media_package in media_packages:\n            package = packager.package_for(media_type, media_package)\n\n            if settings.PIPELINE_ENABLED:\n                source_files.append(\n                    staticfiles_storage.url(package.output_filename))\n            else:\n                source_files += packager.compile(package.paths)\n\n        return source_files", "response": "This function will go through the list of media files belonging to the given list of packages and return the source files or output files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender HTML for the package.", "response": "def render_compressed(self, package, package_name, package_type):\n        \"\"\"Render HTML for the package.\n\n        If ``PIPELINE_ENABLED`` is ``True``, this will render the package's\n        output file (using :py:meth:`render_compressed_output`). Otherwise,\n        this will render the package's source files (using\n        :py:meth:`render_compressed_sources`).\n\n        Subclasses can override this method to provide custom behavior for\n        determining what to render.\n        \"\"\"\n        if settings.PIPELINE_ENABLED:\n            return self.render_compressed_output(package, package_name,\n                                                 package_type)\n        else:\n            return self.render_compressed_sources(package, package_name,\n                                                  package_type)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_compressed_output(self, package, package_name, package_type):\n        method = getattr(self, 'render_{0}'.format(package_type))\n\n        return method(package, package.output_filename)", "response": "Render HTML for using the package s output file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_compressed_sources(self, package, package_name, package_type):\n        if settings.PIPELINE_COLLECTOR_ENABLED:\n            default_collector.collect(self.request)\n\n        packager = Packager()\n        method = getattr(self, 'render_individual_{0}'.format(package_type))\n\n        try:\n            paths = packager.compile(package.paths)\n        except CompilerError as e:\n            if settings.SHOW_ERRORS_INLINE:\n                method = getattr(self, 'render_error_{0}'.format(\n                    package_type))\n\n                return method(package_name, e)\n            else:\n                raise\n\n        templates = packager.pack_templates(package)\n\n        return method(package, paths, templates=templates)", "response": "Render HTML for using the package s list of source files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find(self, path, all=False):\n        matches = []\n        for elem in chain(settings.STYLESHEETS.values(), settings.JAVASCRIPT.values()):\n            if normpath(elem['output_filename']) == normpath(path):\n                match = safe_join(settings.PIPELINE_ROOT, path)\n                if not all:\n                    return match\n                matches.append(match)\n        return matches", "response": "Find all files in PIPELINE. STYLESHEETS and PIPELINE. JAVASCRIPT."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the uncached name of the file and look that up instead.", "response": "def find(self, path, all=False):\n        \"\"\"\n        Work out the uncached name of the file and look that up instead\n        \"\"\"\n        try:\n            start, _, extn = path.rsplit('.', 2)\n        except ValueError:\n            return []\n        path = '.'.join((start, extn))\n        return find(path, all=all) or []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post(self, uri_relative, request_bytes, custom_headers):\n\n        return self._request(\n            self._METHOD_POST,\n            uri_relative,\n            request_bytes,\n            {},\n            custom_headers\n        )", "response": "This method is used to make a POST request to the resource identified by uri_relative."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _request(self, method, uri_relative, request_bytes, params,\n                 custom_headers):\n        \"\"\"\n        :type method: str\n        :type uri_relative: str\n        :type request_bytes: bytes\n        :type params: dict[str, str]\n        :type custom_headers: dict[str, str]\n\n        :return: BunqResponseRaw\n        \"\"\"\n\n        uri_relative_with_params = self._append_params_to_uri(uri_relative,\n                                                              params)\n        if uri_relative not in self._URIS_NOT_REQUIRING_ACTIVE_SESSION:\n            if self._api_context.ensure_session_active():\n                from bunq.sdk.context import BunqContext\n\n                BunqContext.update_api_context(self._api_context)\n\n        all_headers = self._get_all_headers(\n            method,\n            uri_relative_with_params,\n            request_bytes,\n            custom_headers\n        )\n\n        response = requests.request(\n            method,\n            self._get_uri_full(uri_relative_with_params),\n            data=request_bytes,\n            headers=all_headers,\n            proxies={self._FIELD_PROXY_HTTPS: self._api_context.proxy_url},\n        )\n\n        self._assert_response_success(response)\n\n        if self._api_context.installation_context is not None:\n            security.validate_response(\n                self._api_context.installation_context.public_key_server,\n                response.status_code,\n                response.content,\n                response.headers\n            )\n\n        return self._create_bunq_response_raw(response)", "response": "Internal method to send a request to the Bunq API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _append_params_to_uri(cls, uri, params):\n\n        if params:\n            return uri + cls._DELIMITER_URL_QUERY + urlencode(params)\n\n        return uri", "response": "Appends the params to the uri"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict of all headers that can be sent to the server.", "response": "def _get_all_headers(self, method, endpoint, request_bytes, custom_headers):\n        \"\"\"\n        :type method: str\n        :type endpoint: str\n        :type request_bytes: bytes\n        :type custom_headers: dict[str, str]\n\n        :rtype: dict[str, str]\n        \"\"\"\n\n        headers = self._get_default_headers()\n        headers.update(custom_headers)\n\n        if self._api_context.token is not None:\n            headers[self.HEADER_AUTHENTICATION] = self._api_context.token\n            headers[self.HEADER_SIGNATURE] = security.sign_request(\n                self._api_context.installation_context.private_key_client,\n                method,\n                endpoint,\n                request_bytes,\n                headers\n            )\n\n        return headers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_default_headers(cls):\n\n        return {\n            cls.HEADER_USER_AGENT: cls._USER_AGENT_BUNQ,\n            cls.HEADER_REQUEST_ID: cls._generate_random_request_id(),\n            cls.HEADER_GEOLOCATION: cls._GEOLOCATION_ZERO,\n            cls.HEADER_LANGUAGE: cls._LANGUAGE_EN_US,\n            cls.HEADER_REGION: cls._REGION_NL_NL,\n            cls.HEADER_CACHE_CONTROL: cls._CACHE_CONTROL_NONE,\n        }", "response": "Returns a dictionary of default headers for the given class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise ApiException when the response is not successful.", "response": "def _assert_response_success(self, response):\n        \"\"\"\n        :type response: requests.Response\n\n        :rtype: None\n        :raise ApiException: When the response is not successful.\n        \"\"\"\n\n        if response.status_code != self._STATUS_CODE_OK:\n            raise ExceptionFactory.create_exception_for_response(\n                response.status_code,\n                self._fetch_all_error_message(response),\n                self._fetch_response_id(response)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _fetch_all_error_message(self, response):\n\n        response_content_string = response.content.decode()\n\n        try:\n            error_dict = converter.json_to_class(dict, response_content_string)\n\n            return self._fetch_error_descriptions(error_dict)\n        except ValueError:\n            return [response_content_string]", "response": "Returns a list of all error messages from the response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of error descriptions from a dictionary.", "response": "def _fetch_error_descriptions(self, error_dict):\n        \"\"\"\n        :type error_dict: dict[str, list[dict[str, str]]\n\n        :rtype: list[str]\n        \"\"\"\n\n        error_descriptions = []\n\n        for error in error_dict[self._FIELD_ERROR]:\n            description = error[self._FIELD_ERROR_DESCRIPTION]\n            error_descriptions.append(description)\n\n        return error_descriptions"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the response ID from the response header if it exists otherwise returns self. _ERROR_COULD_NOT_DETERMINE_RESPONSE_ID_HEADER.", "response": "def _fetch_response_id(self, response):\n        \"\"\"\n        :type response: requests.Response\n\n        :rtype: str\n        \"\"\"\n\n        headers = response.headers\n\n        if self.HEADER_RESPONSE_ID_UPPER_CASED in headers:\n            return headers[self.HEADER_RESPONSE_ID_UPPER_CASED]\n\n        if self.HEADER_RESPONSE_ID_LOWER_CASED in headers:\n            return headers[self.HEADER_RESPONSE_ID_LOWER_CASED]\n\n        return self._ERROR_COULD_NOT_DETERMINE_RESPONSE_ID_HEADER;"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef put(self, uri_relative, request_bytes, custom_headers):\n\n        return self._request(\n            self._METHOD_PUT,\n            uri_relative,\n            request_bytes,\n            {},\n            custom_headers\n        )", "response": "This method is used to send a PUT request to the resource identified by the uri_relative."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, uri_relative, params, custom_headers):\n\n        return self._request(\n            self._METHOD_GET,\n            uri_relative,\n            self._BYTES_EMPTY,\n            params,\n            custom_headers\n        )", "response": "This method returns a BunqResponseRaw\n            object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, uri_relative, custom_headers):\n\n        return self._request(\n            self._METHOD_DELETE,\n            uri_relative,\n            self._BYTES_EMPTY,\n            {},\n            custom_headers\n        )", "response": "This method is used to delete a resource from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncast a BunqResponse object to a BunqResource object.", "response": "def cast_from_bunq_response(cls, bunq_response):\n        \"\"\"\n        :type bunq_response: BunqResponse\n        \"\"\"\n\n        return cls(\n            bunq_response.value,\n            bunq_response.headers,\n            bunq_response.pagination\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dict of parameters to be passed to the previous page of the url.", "response": "def url_params_previous_page(self):\n        \"\"\"\n        :rtype: dict[str, str]\n        \"\"\"\n\n        self.assert_has_previous_page()\n\n        params = {self.PARAM_OLDER_ID: str(self.older_id)}\n        self._add_count_to_params_if_needed(params)\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_count_to_params_if_needed(self, params):\n\n        if self.count is not None:\n            params[self.PARAM_COUNT] = str(self.count)", "response": "Adds count to the params dict if needed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dict of parameters to be passed to the next page of the URL.", "response": "def url_params_next_page(self):\n        \"\"\"\n        :rtype: dict[str, str]\n        \"\"\"\n\n        self.assert_has_next_page()\n\n        params = {self.PARAM_NEWER_ID: str(self._next_id)}\n        self._add_count_to_params_if_needed(params)\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._contract_date_start is not None:\n            return False\n\n        if self._contract_date_end is not None:\n            return False\n\n        if self._contract_version is not None:\n            return False\n\n        if self._subscription_type is not None:\n            return False\n\n        if self._subscription_type_downgrade is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._sub_status is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_all_field_none(self):\n\n        if self._limit_monetary_account is not None:\n            return False\n\n        if self._limit_monetary_account_remaining is not None:\n            return False\n\n        if self._limit_card_debit_maestro is not None:\n            return False\n\n        if self._limit_card_debit_mastercard is not None:\n            return False\n\n        if self._limit_card_debit_wildcard is not None:\n            return False\n\n        if self._limit_card_debit_replacement is not None:\n            return False\n\n        if self._limit_invite_user_premium_limited is not None:\n            return False\n\n        if self._limit_amount_monthly is not None:\n            return False\n\n        if self._spent_amount_monthly is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(cls, invoice_id, custom_headers=None):\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_LISTING.format(\n            cls._determine_user_id(), invoice_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseBytes.cast_from_bunq_response(\n            client.BunqResponse(response_raw.body_bytes, response_raw.headers)\n        )", "response": "This method returns a list of all the related attributes of an invoice."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._invoice_date is not None:\n            return False\n\n        if self._invoice_number is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._group is not None:\n            return False\n\n        if self._total_vat_inclusive is not None:\n            return False\n\n        if self._total_vat_exclusive is not None:\n            return False\n\n        if self._total_vat is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._address is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._counterparty_address is not None:\n            return False\n\n        if self._chamber_of_commerce_number is not None:\n            return False\n\n        if self._vat_number is not None:\n            return False\n\n        if self._request_reference_split_the_bill is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(cls, request_bytes, monetary_account_id=None,\n               custom_headers=None):\n        \"\"\"\n        Create a new monetary account attachment. Create a POST request with a\n        payload that contains the binary representation of the file, without any\n        JSON wrapping. Make sure you define the MIME type (i.e. image/jpeg) in\n        the Content-Type header. You are required to provide a description of\n        the attachment using the X-Bunq-Attachment-Description header.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id))\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "This method creates a new monetary account attachment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(cls, request_bytes, custom_headers=None):\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_CREATE\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseStr.cast_from_bunq_response(\n            cls._process_for_uuid(response_raw)\n        )", "response": "Create a new public attachment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a specific attachment s metadata through its UUID.", "response": "def get(cls, attachment_public_uuid, custom_headers=None):\n        \"\"\"\n        Get a specific attachment's metadata through its UUID. The Content-Type\n        header of the response will describe the MIME type of the attachment\n        file.\n\n        :type api_context: context.ApiContext\n        :type attachment_public_uuid: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseAttachmentPublic\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(attachment_public_uuid)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseAttachmentPublic.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._uuid is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._attachment is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._attachment is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(cls, tab_uuid, tab_attachment_tab_id, custom_headers=None):\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(tab_uuid,\n                                                     tab_attachment_tab_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseTabAttachmentTab.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "Get a specific attachment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(cls, attachment_public_uuid, custom_headers=None):\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_ATTACHMENT_PUBLIC_UUID: attachment_public_uuid\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseStr.cast_from_bunq_response(\n            cls._process_for_uuid(response_raw)\n        )", "response": "This method creates a new public avatar image from which an avatar image must be created."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._user_alias is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._sub_status is not None:\n            return False\n\n        if self._time_start_desired is not None:\n            return False\n\n        if self._time_start_actual is not None:\n            return False\n\n        if self._time_end is not None:\n            return False\n\n        if self._attachment is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new Payment.", "response": "def create(cls, amount, counterparty_alias, description,\n               monetary_account_id=None, attachment=None,\n               merchant_reference=None, allow_bunqto=None, custom_headers=None):\n        \"\"\"\n        Create a new Payment.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :param amount: The Amount to transfer with the Payment. Must be bigger\n        than 0 and smaller than the MonetaryAccount's balance.\n        :type amount: object_.Amount\n        :param counterparty_alias: The Alias of the party we are transferring\n        the money to. Can be an Alias of type EMAIL or PHONE_NUMBER (for bunq\n        MonetaryAccounts or bunq.to payments) or IBAN (for external bank\n        account).\n        :type counterparty_alias: object_.Pointer\n        :param description: The description for the Payment. Maximum 140\n        characters for Payments to external IBANs, 9000 characters for Payments\n        to only other bunq MonetaryAccounts. Field is required but can be an\n        empty string.\n        :type description: str\n        :param attachment: The Attachments to attach to the Payment.\n        :type attachment: list[object_.AttachmentMonetaryAccountPayment]\n        :param merchant_reference: Optional data to be included with the Payment\n        specific to the merchant.\n        :type merchant_reference: str\n        :param allow_bunqto: Whether or not sending a bunq.to payment is\n        allowed.\n        :type allow_bunqto: bool\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_AMOUNT: amount,\n            cls.FIELD_COUNTERPARTY_ALIAS: counterparty_alias,\n            cls.FIELD_DESCRIPTION: description,\n            cls.FIELD_ATTACHMENT: attachment,\n            cls.FIELD_MERCHANT_REFERENCE: merchant_reference,\n            cls.FIELD_ALLOW_BUNQTO: allow_bunqto\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id))\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._amount is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._sub_type is not None:\n            return False\n\n        if self._bunqto_status is not None:\n            return False\n\n        if self._bunqto_sub_status is not None:\n            return False\n\n        if self._bunqto_share_url is not None:\n            return False\n\n        if self._bunqto_expiry is not None:\n            return False\n\n        if self._bunqto_time_responded is not None:\n            return False\n\n        if self._attachment is not None:\n            return False\n\n        if self._merchant_reference is not None:\n            return False\n\n        if self._batch_id is not None:\n            return False\n\n        if self._scheduled_id is not None:\n            return False\n\n        if self._address_shipping is not None:\n            return False\n\n        if self._address_billing is not None:\n            return False\n\n        if self._geolocation is not None:\n            return False\n\n        if self._allow_chat is not None:\n            return False\n\n        if self._request_reference_split_the_bill is not None:\n            return False\n\n        if self._balance_after_mutation is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._bunqme_fundraiser_profile is not None:\n            return False\n\n        if self._payments is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._color is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._attachment is not None:\n            return False\n\n        if self._pointer is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._redirect_url is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._time_expiry is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._bunqme_tab_share_url is not None:\n            return False\n\n        if self._bunqme_tab_entry is not None:\n            return False\n\n        if self._result_inquiries is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._uuid is not None:\n            return False\n\n        if self._amount_inquired is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._redirect_url is not None:\n            return False\n\n        if self._merchant_available is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, cards, custom_headers=None):\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_CARDS: cards\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id())\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseCardBatch.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_POST)\n        )", "response": "This method creates a new set of cards for a user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new debit card request.", "response": "def create(cls, second_line, name_on_card, alias=None, type_=None,\n               pin_code_assignment=None, monetary_account_id_fallback=None,\n               custom_headers=None):\n        \"\"\"\n        Create a new debit card request.\n\n        :type user_id: int\n        :param second_line: The second line of text on the card, used as\n        name/description for it. It can contain at most 17 characters and it can\n        be empty.\n        :type second_line: str\n        :param name_on_card: The user's name as it will be on the card. Check\n        'card-name' for the available card names for a user.\n        :type name_on_card: str\n        :param alias: The pointer to the monetary account that will be connected\n        at first with the card. Its IBAN code is also the one that will be\n        printed on the card itself. The pointer must be of type IBAN.\n        :type alias: object_.Pointer\n        :param type_: The type of card to order. Can be MAESTRO or MASTERCARD.\n        :type type_: str\n        :param pin_code_assignment: Array of Types, PINs, account IDs assigned\n        to the card.\n        :type pin_code_assignment: list[object_.CardPinAssignment]\n        :param monetary_account_id_fallback: ID of the MA to be used as fallback\n        for this card if insufficient balance. Fallback account is removed if\n        not supplied.\n        :type monetary_account_id_fallback: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseCardDebit\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_SECOND_LINE: second_line,\n            cls.FIELD_NAME_ON_CARD: name_on_card,\n            cls.FIELD_ALIAS: alias,\n            cls.FIELD_TYPE: type_,\n            cls.FIELD_PIN_CODE_ASSIGNMENT: pin_code_assignment,\n            cls.FIELD_MONETARY_ACCOUNT_ID_FALLBACK: monetary_account_id_fallback\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        request_bytes = security.encrypt(cls._get_api_context(), request_bytes,\n                                         custom_headers)\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id())\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseCardDebit.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_POST)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._public_uuid is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._sub_type is not None:\n            return False\n\n        if self._second_line is not None:\n            return False\n\n        if self._name_on_card is not None:\n            return False\n\n        if self._primary_account_number_four_digit is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._order_status is not None:\n            return False\n\n        if self._expiry_date is not None:\n            return False\n\n        if self._limit is not None:\n            return False\n\n        if self._country_permission is not None:\n            return False\n\n        if self._label_monetary_account_ordered is not None:\n            return False\n\n        if self._label_monetary_account_current is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._pin_code_assignment is not None:\n            return False\n\n        if self._monetary_account_id_fallback is not None:\n            return False\n\n        if self._country is not None:\n            return False\n\n        return True", "response": "returns True if all fields are None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(cls, card_id, type_=None, custom_headers=None):\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_TYPE: type_\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        request_bytes = security.encrypt(cls._get_api_context(), request_bytes,\n                                         custom_headers)\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       card_id)\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "This method generates a new CVC2 code for a card."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(cls, card_id, card_generated_cvc2_id, type_=None,\n               custom_headers=None):\n        \"\"\"\n        :type user_id: int\n        :type card_id: int\n        :type card_generated_cvc2_id: int\n        :param type_: The type of generated cvc2. Can be STATIC or GENERATED.\n        :type type_: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_TYPE: type_\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        request_bytes = security.encrypt(cls._get_api_context(), request_bytes,\n                                         custom_headers)\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id(),\n                                                       card_id,\n                                                       card_generated_cvc2_id)\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "This method updates the details of a specific cvc2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._cvc2 is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._expiry_time is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(cls, card_id, name_on_card=None, pin_code=None, second_line=None,\n               custom_headers=None):\n        \"\"\"\n        Request a card replacement.\n\n        :type user_id: int\n        :type card_id: int\n        :param name_on_card: The user's name as it will be on the card. Check\n        'card-name' for the available card names for a user.\n        :type name_on_card: str\n        :param pin_code: The plaintext pin code. Requests require encryption to\n        be enabled.\n        :type pin_code: str\n        :param second_line: The second line on the card.\n        :type second_line: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_NAME_ON_CARD: name_on_card,\n            cls.FIELD_PIN_CODE: pin_code,\n            cls.FIELD_SECOND_LINE: second_line\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        request_bytes = security.encrypt(cls._get_api_context(), request_bytes,\n                                         custom_headers)\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       card_id)\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "Request a new card replacement."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the card details.", "response": "def update(cls, card_id, pin_code=None, activation_code=None, status=None,\n               card_limit=None, card_limit_atm=None, limit=None,\n               mag_stripe_permission=None, country_permission=None,\n               pin_code_assignment=None, primary_account_numbers_virtual=None,\n               monetary_account_id_fallback=None, custom_headers=None):\n        \"\"\"\n        Update the card details. Allow to change pin code, status, limits,\n        country permissions and the monetary account connected to the card. When\n        the card has been received, it can be also activated through this\n        endpoint.\n\n        :type user_id: int\n        :type card_id: int\n        :param pin_code: The plaintext pin code. Requests require encryption to\n        be enabled.\n        :type pin_code: str\n        :param activation_code: DEPRECATED: Activate a card by setting status to\n        ACTIVE when the order_status is ACCEPTED_FOR_PRODUCTION.\n        :type activation_code: str\n        :param status: The status to set for the card. Can be ACTIVE,\n        DEACTIVATED, LOST, STOLEN or CANCELLED, and can only be set to\n        LOST/STOLEN/CANCELLED when order status is\n        ACCEPTED_FOR_PRODUCTION/DELIVERED_TO_CUSTOMER/CARD_UPDATE_REQUESTED/CARD_UPDATE_SENT/CARD_UPDATE_ACCEPTED.\n        Can only be set to DEACTIVATED after initial activation, i.e.\n        order_status is\n        DELIVERED_TO_CUSTOMER/CARD_UPDATE_REQUESTED/CARD_UPDATE_SENT/CARD_UPDATE_ACCEPTED.\n        Mind that all the possible choices (apart from ACTIVE and DEACTIVATED)\n        are permanent and cannot be changed after.\n        :type status: str\n        :param card_limit: The spending limit for the card.\n        :type card_limit: object_.Amount\n        :param card_limit_atm: The ATM spending limit for the card.\n        :type card_limit_atm: object_.Amount\n        :param limit: DEPRECATED: The limits to define for the card, among\n        CARD_LIMIT_CONTACTLESS, CARD_LIMIT_ATM, CARD_LIMIT_DIPPING and\n        CARD_LIMIT_POS_ICC (e.g. 25 EUR for CARD_LIMIT_CONTACTLESS). All the\n        limits must be provided on update.\n        :type limit: list[object_.CardLimit]\n        :param mag_stripe_permission: DEPRECATED: Whether or not it is allowed\n        to use the mag stripe for the card.\n        :type mag_stripe_permission: object_.CardMagStripePermission\n        :param country_permission: The countries for which to grant (temporary)\n        permissions to use the card.\n        :type country_permission: list[object_.CardCountryPermission]\n        :param pin_code_assignment: Array of Types, PINs, account IDs assigned\n        to the card.\n        :type pin_code_assignment: list[object_.CardPinAssignment]\n        :param primary_account_numbers_virtual: Array of PANs, status,\n        description and account id for online cards.\n        :type primary_account_numbers_virtual:\n        list[object_.CardVirtualPrimaryAccountNumber]\n        :param monetary_account_id_fallback: ID of the MA to be used as fallback\n        for this card if insufficient balance. Fallback account is removed if\n        not supplied.\n        :type monetary_account_id_fallback: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseCard\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_PIN_CODE: pin_code,\n            cls.FIELD_ACTIVATION_CODE: activation_code,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_CARD_LIMIT: card_limit,\n            cls.FIELD_CARD_LIMIT_ATM: card_limit_atm,\n            cls.FIELD_LIMIT: limit,\n            cls.FIELD_MAG_STRIPE_PERMISSION: mag_stripe_permission,\n            cls.FIELD_COUNTRY_PERMISSION: country_permission,\n            cls.FIELD_PIN_CODE_ASSIGNMENT: pin_code_assignment,\n            cls.FIELD_PRIMARY_ACCOUNT_NUMBERS_VIRTUAL: primary_account_numbers_virtual,\n            cls.FIELD_MONETARY_ACCOUNT_ID_FALLBACK: monetary_account_id_fallback\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        request_bytes = security.encrypt(cls._get_api_context(), request_bytes,\n                                         custom_headers)\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id(),\n                                                       card_id)\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseCard.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_PUT)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(cls, card_id, custom_headers=None):\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(cls._determine_user_id(),\n                                                     card_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseCard.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "Get a specific card."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._cash_register is not None:\n            return False\n\n        if self._tab_object is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(cls, name, status, avatar_uuid, monetary_account_id=None,\n               location=None, notification_filters=None,\n               tab_text_waiting_screen=None, custom_headers=None):\n        \"\"\"\n        Create a new CashRegister. Only an UserCompany can create a\n        CashRegisters. They need to be created with status PENDING_APPROVAL, an\n        bunq admin has to approve your CashRegister before you can use it. In\n        the sandbox testing environment an CashRegister will be automatically\n        approved immediately after creation.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :param name: The name of the CashRegister. Must be unique for this\n        MonetaryAccount.\n        :type name: str\n        :param status: The status of the CashRegister. Can only be created or\n        updated with PENDING_APPROVAL or CLOSED.\n        :type status: str\n        :param avatar_uuid: The UUID of the avatar of the CashRegister. Use the\n        calls /attachment-public and /avatar to create a new Avatar and get its\n        UUID.\n        :type avatar_uuid: str\n        :param location: The geolocation of the CashRegister.\n        :type location: object_.Geolocation\n        :param notification_filters: The types of notifications that will result\n        in a push notification or URL callback for this CashRegister.\n        :type notification_filters: list[object_.NotificationFilter]\n        :param tab_text_waiting_screen: The tab text for waiting screen of\n        CashRegister.\n        :type tab_text_waiting_screen: list[object_.TabTextWaitingScreen]\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_NAME: name,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_AVATAR_UUID: avatar_uuid,\n            cls.FIELD_LOCATION: location,\n            cls.FIELD_NOTIFICATION_FILTERS: notification_filters,\n            cls.FIELD_TAB_TEXT_WAITING_SCREEN: tab_text_waiting_screen\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id))\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "Create a new CashRegister."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._name is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._avatar is not None:\n            return False\n\n        if self._location is not None:\n            return False\n\n        if self._notification_filters is not None:\n            return False\n\n        if self._tab_text_waiting_screen is not None:\n            return False\n\n        return True", "response": "returns True if all fields are None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the object that is referenced by this object.", "response": "def get_referenced_object(self):\n        \"\"\"\n        :rtype: core.BunqModel\n        :raise: BunqException\n        \"\"\"\n\n        if self._TabUsageSingle is not None:\n            return self._TabUsageSingle\n\n        if self._TabUsageMultiple is not None:\n            return self._TabUsageMultiple\n\n        raise exception.BunqException(self._ERROR_NULL_FIELDS)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._uuid is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._merchant_reference is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._amount_total is not None:\n            return False\n\n        if self._amount_paid is not None:\n            return False\n\n        if self._qr_code_token is not None:\n            return False\n\n        if self._tab_url is not None:\n            return False\n\n        if self._visibility is not None:\n            return False\n\n        if self._minimum_age is not None:\n            return False\n\n        if self._require_address is not None:\n            return False\n\n        if self._redirect_url is not None:\n            return False\n\n        if self._expiration is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._cash_register_location is not None:\n            return False\n\n        if self._tab_item is not None:\n            return False\n\n        if self._tab_attachment is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._ean_code is not None:\n            return False\n\n        if self._avatar_attachment is not None:\n            return False\n\n        if self._tab_attachment is not None:\n            return False\n\n        if self._quantity is not None:\n            return False\n\n        if self._amount is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(cls, cash_register_id, description, status, amount_total,\n               monetary_account_id=None, allow_amount_higher=None,\n               allow_amount_lower=None, want_tip=None, minimum_age=None,\n               require_address=None, redirect_url=None, visibility=None,\n               expiration=None, tab_attachment=None, custom_headers=None):\n        \"\"\"\n        Create a TabUsageMultiple. On creation the status must be set to OPEN\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :type cash_register_id: int\n        :param description: The description of the TabUsageMultiple. Maximum\n        9000 characters. Field is required but can be an empty string.\n        :type description: str\n        :param status: The status of the TabUsageMultiple. On creation the\n        status must be set to OPEN. You can change the status from OPEN to\n        PAYABLE. If the TabUsageMultiple gets paid the status will remain\n        PAYABLE.\n        :type status: str\n        :param amount_total: The total amount of the Tab. Must be a positive\n        amount. As long as the tab has the status OPEN you can change the total\n        amount. This amount is not affected by the amounts of the TabItems.\n        However, if you've created any TabItems for a Tab the sum of the amounts\n        of these items must be equal to the total_amount of the Tab when you\n        change its status to PAYABLE\n        :type amount_total: object_.Amount\n        :param allow_amount_higher: [DEPRECATED] Whether or not a higher amount\n        can be paid.\n        :type allow_amount_higher: bool\n        :param allow_amount_lower: [DEPRECATED] Whether or not a lower amount\n        can be paid.\n        :type allow_amount_lower: bool\n        :param want_tip: [DEPRECATED] Whether or not the user paying the Tab\n        should be asked if he wants to give a tip. When want_tip is set to true,\n        allow_amount_higher must also be set to true and allow_amount_lower must\n        be false.\n        :type want_tip: bool\n        :param minimum_age: The minimum age of the user paying the Tab.\n        :type minimum_age: int\n        :param require_address: Whether a billing and shipping address must be\n        provided when paying the Tab. Possible values are: BILLING, SHIPPING,\n        BILLING_SHIPPING, NONE, OPTIONAL. Default is NONE.\n        :type require_address: str\n        :param redirect_url: The URL which the user is sent to after paying the\n        Tab.\n        :type redirect_url: str\n        :param visibility: The visibility of a Tab. A Tab can be visible trough\n        NearPay, the QR code of the CashRegister and its own QR code.\n        :type visibility: object_.TabVisibility\n        :param expiration: The moment when this Tab expires. Can be at most 365\n        days into the future.\n        :type expiration: str\n        :param tab_attachment: An array of attachments that describe the tab.\n        Uploaded through the POST /user/{userid}/attachment-tab endpoint.\n        :type tab_attachment: list[object_.BunqId]\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseStr\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_DESCRIPTION: description,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_AMOUNT_TOTAL: amount_total,\n            cls.FIELD_ALLOW_AMOUNT_HIGHER: allow_amount_higher,\n            cls.FIELD_ALLOW_AMOUNT_LOWER: allow_amount_lower,\n            cls.FIELD_WANT_TIP: want_tip,\n            cls.FIELD_MINIMUM_AGE: minimum_age,\n            cls.FIELD_REQUIRE_ADDRESS: require_address,\n            cls.FIELD_REDIRECT_URL: redirect_url,\n            cls.FIELD_VISIBILITY: visibility,\n            cls.FIELD_EXPIRATION: expiration,\n            cls.FIELD_TAB_ATTACHMENT: tab_attachment\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id),\n                                                       cash_register_id)\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseStr.cast_from_bunq_response(\n            cls._process_for_uuid(response_raw)\n        )", "response": "Create a TabUsageMultiple. On creation the status must be set to OPEN\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :type cash_register_id: int\n        :param description: The description of the TabUsageMultiple. Maximum\n        9000 characters. Field is required but can be an empty string.\n        :type description: str\n        :param status: The status of the TabUsageMultiple. On creation the\n        status must be set to OPEN. You can change the status from OPEN to\n        PAYABLE. If the TabUsageMultiple gets paid the status will remain\n        PAYABLE.\n        :type status: str\n        :param amount_total: The total amount of the Tab. Must be a positive\n        amount. As long as the tab has the status OPEN you can change the total\n        amount. This amount is not affected by the amounts of the TabItems.\n        However, if you've created any TabItems for a Tab the sum of the amounts\n        of these items must be equal to the total_amount of the Tab when you\n        change its status to PAYABLE\n        :type amount_total: object_.Amount\n        :param allow_amount_higher: [DEPRECATED] Whether or not a higher amount\n        can be paid.\n        :type allow_amount_higher: bool\n        :param allow_amount_lower: [DEPRECATED] Whether or not a lower amount\n        can be paid.\n        :type allow_amount_lower: bool\n        :param want_tip: [DEPRECATED] Whether or not the user paying the Tab\n        should be asked if he wants to give a tip. When want_tip is set to true,\n        allow_amount_higher must also be set to true and allow_amount_lower must\n        be false.\n        :type want_tip: bool\n        :param minimum_age: The minimum age of the user paying the Tab.\n        :type minimum_age: int\n        :param require_address: Whether a billing and shipping address must be\n        provided when paying the Tab. Possible values are: BILLING, SHIPPING,\n        BILLING_SHIPPING, NONE, OPTIONAL. Default is NONE.\n        :type require_address: str\n        :param redirect_url: The URL which the user is sent to after paying the\n        Tab.\n        :type redirect_url: str\n        :param visibility: The visibility of a Tab. A Tab can be visible trough\n        NearPay, the QR code of the CashRegister and its own QR code.\n        :type visibility: object_.TabVisibility\n        :param expiration: The moment when this Tab expires. Can be at most 365\n        days into the future.\n        :type expiration: str\n        :param tab_attachment: An array of attachments that describe the tab.\n        Uploaded through the POST /user/{userid}/attachment-tab endpoint.\n        :type tab_attachment: list[object_.BunqId]\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseStr"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(cls, cash_register_id, tab_usage_multiple_uuid,\n               monetary_account_id=None, status=None, amount_total=None,\n               visibility=None, expiration=None, tab_attachment=None,\n               custom_headers=None):\n        \"\"\"\n        Modify a specific TabUsageMultiple. You can change the amount_total,\n        status and visibility. Once you change the status to PAYABLE the\n        TabUsageMultiple will expire after a year (default). If you've created\n        any TabItems for a Tab the sum of the amounts of these items must be\n        equal to the total_amount of the Tab when you change its status to\n        PAYABLE.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :type cash_register_id: int\n        :type tab_usage_multiple_uuid: str\n        :param status: The status of the TabUsageMultiple. On creation the\n        status must be set to OPEN. You can change the status from OPEN to\n        PAYABLE. If the TabUsageMultiple gets paid the status will remain\n        PAYABLE.\n        :type status: str\n        :param amount_total: The total amount of the Tab. Must be a positive\n        amount. As long as the tab has the status OPEN you can change the total\n        amount. This amount is not affected by the amounts of the TabItems.\n        However, if you've created any TabItems for a Tab the sum of the amounts\n        of these items must be equal to the total_amount of the Tab when you\n        change its status to PAYABLE\n        :type amount_total: object_.Amount\n        :param visibility: The visibility of a Tab. A Tab can be visible trough\n        NearPay, the QR code of the CashRegister and its own QR code.\n        :type visibility: object_.TabVisibility\n        :param expiration: The moment when this Tab expires. Can be at most 365\n        days into the future.\n        :type expiration: str\n        :param tab_attachment: An array of attachments that describe the tab.\n        Uploaded through the POST /user/{userid}/attachment-tab endpoint.\n        :type tab_attachment: list[object_.BunqId]\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseStr\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_STATUS: status,\n            cls.FIELD_AMOUNT_TOTAL: amount_total,\n            cls.FIELD_VISIBILITY: visibility,\n            cls.FIELD_EXPIRATION: expiration,\n            cls.FIELD_TAB_ATTACHMENT: tab_attachment\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id),\n                                                       cash_register_id,\n                                                       tab_usage_multiple_uuid)\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseStr.cast_from_bunq_response(\n            cls._process_for_uuid(response_raw)\n        )", "response": "Update a specific TabUsageMultiple."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new DeviceServer providing the installation token in the header and signing the request with the private part of the key you used to create the installation. The API Key that you are using will be bound to the IP address of the DeviceServer which you have created.<br/><br/>Using a Wildcard API Key gives you the freedom to make API calls even if the IP address has changed after the POST device-server.<br/><br/>Find out more at this link <a href=\"https://bunq.com/en/apikey-dynamic-ip\" target=\"_blank\">https://bunq.com/en/apikey-dynamic-ip</a>. :param description: The description of the DeviceServer. This is only for your own reference when reading the DeviceServer again. :type description: str :param secret: The API key. You can request an API key in the bunq app. :type secret: str :param permitted_ips: An array of IPs (v4 or v6) this DeviceServer will be able to do calls from. These will be linked to the API key. :type permitted_ips: list[str] :type custom_headers: dict[str, str]|None :rtype: BunqResponseInt", "response": "def create(cls, description, secret, permitted_ips=None,\n               custom_headers=None):\n        \"\"\"\n        Create a new DeviceServer providing the installation token in the header\n        and signing the request with the private part of the key you used to\n        create the installation. The API Key that you are using will be bound to\n        the IP address of the DeviceServer which you have\n        created.<br/><br/>Using a Wildcard API Key gives you the freedom to make\n        API calls even if the IP address has changed after the POST\n        device-server.<br/><br/>Find out more at this link <a\n        href=\"https://bunq.com/en/apikey-dynamic-ip\"\n        target=\"_blank\">https://bunq.com/en/apikey-dynamic-ip</a>.\n\n        :param description: The description of the DeviceServer. This is only\n        for your own reference when reading the DeviceServer again.\n        :type description: str\n        :param secret: The API key. You can request an API key in the bunq app.\n        :type secret: str\n        :param permitted_ips: An array of IPs (v4 or v6) this DeviceServer will\n        be able to do calls from. These will be linked to the API key.\n        :type permitted_ips: list[str]\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_DESCRIPTION: description,\n            cls.FIELD_SECRET: secret,\n            cls.FIELD_PERMITTED_IPS: permitted_ips\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(cls, device_server_id, custom_headers=None):\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(device_server_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseDeviceServer.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "Get one of your Device Servers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._ip is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a single Device.", "response": "def get(cls, device_id, custom_headers=None):\n        \"\"\"\n        Get a single Device. A Device is either a DevicePhone or a DeviceServer.\n\n        :type api_context: context.ApiContext\n        :type device_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseDevice\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(device_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseDevice.cast_from_bunq_response(\n            cls._from_json(response_raw)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the referenced object.", "response": "def get_referenced_object(self):\n        \"\"\"\n        :rtype: core.BunqModel\n        :raise: BunqException\n        \"\"\"\n\n        if self._DeviceServer is not None:\n            return self._DeviceServer\n\n        raise exception.BunqException(self._ERROR_NULL_FIELDS)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(cls, entries, number_of_required_accepts,\n               monetary_account_id=None, status=None,\n               previous_updated_timestamp=None, custom_headers=None):\n        \"\"\"\n        Create a new DraftPayment.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :param entries: The list of entries in the DraftPayment. Each entry will\n        result in a payment when the DraftPayment is accepted.\n        :type entries: list[object_.DraftPaymentEntry]\n        :param number_of_required_accepts: The number of accepts that are\n        required for the draft payment to receive status ACCEPTED. Currently\n        only 1 is valid.\n        :type number_of_required_accepts: int\n        :param status: The status of the DraftPayment.\n        :type status: str\n        :param previous_updated_timestamp: The last updated_timestamp that you\n        received for this DraftPayment. This needs to be provided to prevent\n        race conditions.\n        :type previous_updated_timestamp: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_STATUS: status,\n            cls.FIELD_ENTRIES: entries,\n            cls.FIELD_PREVIOUS_UPDATED_TIMESTAMP: previous_updated_timestamp,\n            cls.FIELD_NUMBER_OF_REQUIRED_ACCEPTS: number_of_required_accepts\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id))\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "Create a new DraftPayment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._user_alias_created is not None:\n            return False\n\n        if self._responses is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._entries is not None:\n            return False\n\n        if self._object_ is not None:\n            return False\n\n        if self._request_reference_split_the_bill is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(cls, draft_share_invite_api_key_id, status=None, sub_status=None,\n               expiration=None, custom_headers=None):\n        \"\"\"\n        Update a draft share invite. When sending status CANCELLED it is\n        possible to cancel the draft share invite.\n\n        :type user_id: int\n        :type draft_share_invite_api_key_id: int\n        :param status: The status of the draft share invite. Can be CANCELLED\n        (the user cancels the draft share before it's used).\n        :type status: str\n        :param sub_status: The sub-status of the draft share invite. Can be\n        NONE, ACCEPTED or REJECTED.\n        :type sub_status: str\n        :param expiration: The moment when this draft share invite expires.\n        :type expiration: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseDraftShareInviteApiKey\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_STATUS: status,\n            cls.FIELD_SUB_STATUS: sub_status,\n            cls.FIELD_EXPIRATION: expiration\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id(),\n                                                       draft_share_invite_api_key_id)\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseDraftShareInviteApiKey.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_PUT)\n        )", "response": "This method is used to update a draft share invite."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_all_field_none(self):\n\n        if self._user_alias_created is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._sub_status is not None:\n            return False\n\n        if self._expiration is not None:\n            return False\n\n        if self._draft_share_url is not None:\n            return False\n\n        if self._api_key is not None:\n            return False\n\n        if self._id_ is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_all_field_none(self):\n\n        if self._user_alias_created is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._expiration is not None:\n            return False\n\n        if self._share_invite_bank_response_id is not None:\n            return False\n\n        if self._draft_share_url is not None:\n            return False\n\n        if self._draft_share_settings is not None:\n            return False\n\n        if self._id_ is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._action is not None:\n            return False\n\n        if self._user_id is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._object_ is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_all_field_none(self):\n\n        if self._avatar is not None:\n            return False\n\n        if self._title is not None:\n            return False\n\n        if self._sub_title is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._amount_guaranteed is not None:\n            return False\n\n        if self._amount_requested is not None:\n            return False\n\n        if self._expiration is not None:\n            return False\n\n        if self._issuer is not None:\n            return False\n\n        if self._issuer_name is not None:\n            return False\n\n        if self._issuer_authentication_url is not None:\n            return False\n\n        if self._purchase_identifier is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._status_timestamp is not None:\n            return False\n\n        if self._transaction_identifier is not None:\n            return False\n\n        if self._allow_chat is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_all_field_none(self):\n\n        if self._time_start is not None:\n            return False\n\n        if self._time_end is not None:\n            return False\n\n        if self._recurrence_unit is not None:\n            return False\n\n        if self._recurrence_size is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._object_ is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_all_field_none(self):\n\n        if self._state is not None:\n            return False\n\n        if self._time_start is not None:\n            return False\n\n        if self._time_end is not None:\n            return False\n\n        if self._error_message is not None:\n            return False\n\n        if self._scheduled_object is not None:\n            return False\n\n        if self._result_object is not None:\n            return False\n\n        if self._request_reference_split_the_bill is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._card_id is not None:\n            return False\n\n        if self._amount_local is not None:\n            return False\n\n        if self._amount_converted is not None:\n            return False\n\n        if self._amount_billing is not None:\n            return False\n\n        if self._amount_original_local is not None:\n            return False\n\n        if self._amount_original_billing is not None:\n            return False\n\n        if self._amount_fee is not None:\n            return False\n\n        if self._card_authorisation_id_response is not None:\n            return False\n\n        if self._decision is not None:\n            return False\n\n        if self._decision_description is not None:\n            return False\n\n        if self._decision_description_translated is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._authorisation_status is not None:\n            return False\n\n        if self._authorisation_type is not None:\n            return False\n\n        if self._pan_entry_mode_user is not None:\n            return False\n\n        if self._settlement_status is not None:\n            return False\n\n        if self._city is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._label_card is not None:\n            return False\n\n        if self._token_status is not None:\n            return False\n\n        if self._reservation_expiry_time is not None:\n            return False\n\n        if self._applied_limit is not None:\n            return False\n\n        if self._allow_chat is not None:\n            return False\n\n        if self._eligible_whitelist_id is not None:\n            return False\n\n        if self._secure_code_id is not None:\n            return False\n\n        if self._wallet_provider_id is not None:\n            return False\n\n        if self._request_reference_split_the_bill is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new batch of request inquiries.", "response": "def create(cls, request_inquiries, total_amount_inquired,\n               monetary_account_id=None, status=None, event_id=None,\n               custom_headers=None):\n        \"\"\"\n        Create a request batch by sending an array of single request objects,\n        that will become part of the batch.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :param request_inquiries: The list of request inquiries we want to send\n        in 1 batch.\n        :type request_inquiries: list[RequestInquiry]\n        :param total_amount_inquired: The total amount originally inquired for\n        this batch.\n        :type total_amount_inquired: object_.Amount\n        :param status: The status of the request.\n        :type status: str\n        :param event_id: The ID of the associated event if the request batch was\n        made using 'split the bill'.\n        :type event_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_REQUEST_INQUIRIES: request_inquiries,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_TOTAL_AMOUNT_INQUIRED: total_amount_inquired,\n            cls.FIELD_EVENT_ID: event_id\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id))\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._request_inquiries is not None:\n            return False\n\n        if self._total_amount_inquired is not None:\n            return False\n\n        if self._reference_split_the_bill is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(cls, amount_inquired, counterparty_alias, description,\n               allow_bunqme, monetary_account_id=None, attachment=None,\n               merchant_reference=None, status=None, minimum_age=None,\n               require_address=None, want_tip=None, allow_amount_lower=None,\n               allow_amount_higher=None, redirect_url=None, event_id=None,\n               custom_headers=None):\n        \"\"\"\n        Create a new payment request.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :param amount_inquired: The Amount requested to be paid by the person\n        the RequestInquiry is sent to. Must be bigger than 0.\n        :type amount_inquired: object_.Amount\n        :param counterparty_alias: The Alias of the party we are requesting the\n        money from. Can be an Alias of type EMAIL, PHONE_NUMBER or IBAN. In case\n        the EMAIL or PHONE_NUMBER Alias does not refer to a bunq monetary\n        account, 'allow_bunqme' needs to be 'true' in order to trigger the\n        creation of a bunq.me request. Otherwise no request inquiry will be\n        sent.\n        :type counterparty_alias: object_.Pointer\n        :param description: The description for the RequestInquiry. Maximum 9000\n        characters. Field is required but can be an empty string.\n        :type description: str\n        :param allow_bunqme: Whether or not sending a bunq.me request is\n        allowed.\n        :type allow_bunqme: bool\n        :param attachment: The Attachments to attach to the RequestInquiry.\n        :type attachment: list[object_.BunqId]\n        :param merchant_reference: Optional data to be included with the\n        RequestInquiry specific to the merchant. Has to be unique for the same\n        source MonetaryAccount.\n        :type merchant_reference: str\n        :param status: The status of the RequestInquiry. Ignored in POST\n        requests but can be used for revoking (cancelling) the RequestInquiry by\n        setting REVOKED with a PUT request.\n        :type status: str\n        :param minimum_age: The minimum age the user accepting the\n        RequestInquiry must have. Defaults to not checking. If set, must be\n        between 12 and 100 inclusive.\n        :type minimum_age: int\n        :param require_address: Whether a billing and shipping address must be\n        provided when paying the request. Possible values are: BILLING,\n        SHIPPING, BILLING_SHIPPING, NONE, OPTIONAL. Default is NONE.\n        :type require_address: str\n        :param want_tip: [DEPRECATED] Whether or not the accepting user can give\n        an extra tip on top of the requested Amount. Defaults to false.\n        :type want_tip: bool\n        :param allow_amount_lower: [DEPRECATED] Whether or not the accepting\n        user can choose to accept with a lower amount than requested. Defaults\n        to false.\n        :type allow_amount_lower: bool\n        :param allow_amount_higher: [DEPRECATED] Whether or not the accepting\n        user can choose to accept with a higher amount than requested. Defaults\n        to false.\n        :type allow_amount_higher: bool\n        :param redirect_url: The URL which the user is sent to after accepting\n        or rejecting the Request.\n        :type redirect_url: str\n        :param event_id: The ID of the associated event if the request was made\n        using 'split the bill'.\n        :type event_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_AMOUNT_INQUIRED: amount_inquired,\n            cls.FIELD_COUNTERPARTY_ALIAS: counterparty_alias,\n            cls.FIELD_DESCRIPTION: description,\n            cls.FIELD_ATTACHMENT: attachment,\n            cls.FIELD_MERCHANT_REFERENCE: merchant_reference,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_MINIMUM_AGE: minimum_age,\n            cls.FIELD_REQUIRE_ADDRESS: require_address,\n            cls.FIELD_WANT_TIP: want_tip,\n            cls.FIELD_ALLOW_AMOUNT_LOWER: allow_amount_lower,\n            cls.FIELD_ALLOW_AMOUNT_HIGHER: allow_amount_higher,\n            cls.FIELD_ALLOW_BUNQME: allow_bunqme,\n            cls.FIELD_REDIRECT_URL: redirect_url,\n            cls.FIELD_EVENT_ID: event_id\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id))\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "Create a new bunq. me payment request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(cls, request_inquiry_id, monetary_account_id=None, status=None,\n               custom_headers=None):\n        \"\"\"\n        Revoke a request for payment, by updating the status to REVOKED.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :type request_inquiry_id: int\n        :param status: The status of the RequestInquiry. Ignored in POST\n        requests but can be used for revoking (cancelling) the RequestInquiry by\n        setting REVOKED with a PUT request.\n        :type status: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseRequestInquiry\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_STATUS: status\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id),\n                                                       request_inquiry_id)\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseRequestInquiry.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_PUT)\n        )", "response": "This method allows you to update the status of a request inquiry."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._time_responded is not None:\n            return False\n\n        if self._time_expiry is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._amount_inquired is not None:\n            return False\n\n        if self._amount_responded is not None:\n            return False\n\n        if self._user_alias_created is not None:\n            return False\n\n        if self._user_alias_revoked is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._merchant_reference is not None:\n            return False\n\n        if self._attachment is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._batch_id is not None:\n            return False\n\n        if self._scheduled_id is not None:\n            return False\n\n        if self._minimum_age is not None:\n            return False\n\n        if self._require_address is not None:\n            return False\n\n        if self._bunqme_share_url is not None:\n            return False\n\n        if self._redirect_url is not None:\n            return False\n\n        if self._address_shipping is not None:\n            return False\n\n        if self._address_billing is not None:\n            return False\n\n        if self._geolocation is not None:\n            return False\n\n        if self._allow_chat is not None:\n            return False\n\n        if self._reference_split_the_bill is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(cls, request_response_id, monetary_account_id=None,\n               amount_responded=None, status=None, address_shipping=None,\n               address_billing=None, custom_headers=None):\n        \"\"\"\n        Update the status to accept or reject the RequestResponse.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :type request_response_id: int\n        :param amount_responded: The Amount the user decides to pay.\n        :type amount_responded: object_.Amount\n        :param status: The responding status of the RequestResponse. Can be\n        ACCEPTED or REJECTED.\n        :type status: str\n        :param address_shipping: The shipping Address to return to the user who\n        created the RequestInquiry. Should only be provided if 'require_address'\n        is set to SHIPPING, BILLING_SHIPPING or OPTIONAL.\n        :type address_shipping: object_.Address\n        :param address_billing: The billing Address to return to the user who\n        created the RequestInquiry. Should only be provided if 'require_address'\n        is set to BILLING, BILLING_SHIPPING or OPTIONAL.\n        :type address_billing: object_.Address\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseRequestResponse\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_AMOUNT_RESPONDED: amount_responded,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_ADDRESS_SHIPPING: address_shipping,\n            cls.FIELD_ADDRESS_BILLING: address_billing\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id),\n                                                       request_response_id)\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseRequestResponse.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_PUT)\n        )", "response": "Update the status of a specific RequestResponse."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._time_responded is not None:\n            return False\n\n        if self._time_expiry is not None:\n            return False\n\n        if self._time_refund_requested is not None:\n            return False\n\n        if self._time_refunded is not None:\n            return False\n\n        if self._user_refund_requested is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._amount_inquired is not None:\n            return False\n\n        if self._amount_responded is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._attachment is not None:\n            return False\n\n        if self._minimum_age is not None:\n            return False\n\n        if self._require_address is not None:\n            return False\n\n        if self._geolocation is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._sub_type is not None:\n            return False\n\n        if self._redirect_url is not None:\n            return False\n\n        if self._address_billing is not None:\n            return False\n\n        if self._address_shipping is not None:\n            return False\n\n        if self._allow_chat is not None:\n            return False\n\n        if self._credit_scheme_identifier is not None:\n            return False\n\n        if self._mandate_identifier is not None:\n            return False\n\n        if self._eligible_whitelist_id is not None:\n            return False\n\n        if self._request_reference_split_the_bill is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_all_field_none(self):\n\n        if self._tab is not None:\n            return False\n\n        if self._payment is not None:\n            return False\n\n        if self._request_reference_split_the_bill is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._monetary_account_paying_id is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._error_message is not None:\n            return False\n\n        if self._whitelist is not None:\n            return False\n\n        if self._object_ is not None:\n            return False\n\n        if self._request_reference_split_the_bill is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._sub_status is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._amount_reward is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, counter_user_alias, share_detail, status,\n               monetary_account_id=None, draft_share_invite_bank_id=None,\n               share_type=None, start_date=None, end_date=None,\n               custom_headers=None):\n        \"\"\"\n        Create a new share inquiry for a monetary account, specifying the\n        permission the other bunq user will have on it.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :param counter_user_alias: The pointer of the user to share with.\n        :type counter_user_alias: object_.Pointer\n        :param share_detail: The share details. Only one of these objects may be\n        passed.\n        :type share_detail: object_.ShareDetail\n        :param status: The status of the share. Can be PENDING, REVOKED (the\n        user deletes the share inquiry before it's accepted), ACCEPTED,\n        CANCELLED (the user deletes an active share) or CANCELLATION_PENDING,\n        CANCELLATION_ACCEPTED, CANCELLATION_REJECTED (for canceling mutual\n        connects).\n        :type status: str\n        :param draft_share_invite_bank_id: The id of the draft share invite\n        bank.\n        :type draft_share_invite_bank_id: int\n        :param share_type: The share type, either STANDARD or MUTUAL.\n        :type share_type: str\n        :param start_date: The start date of this share.\n        :type start_date: str\n        :param end_date: The expiration date of this share.\n        :type end_date: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_COUNTER_USER_ALIAS: counter_user_alias,\n            cls.FIELD_DRAFT_SHARE_INVITE_BANK_ID: draft_share_invite_bank_id,\n            cls.FIELD_SHARE_DETAIL: share_detail,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_SHARE_TYPE: share_type,\n            cls.FIELD_START_DATE: start_date,\n            cls.FIELD_END_DATE: end_date\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id))\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "Create a new BunqResponseInt containing a new counter user share inquiry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(cls, share_invite_bank_inquiry_id, monetary_account_id=None,\n               share_detail=None, status=None, start_date=None, end_date=None,\n               custom_headers=None):\n        \"\"\"\n        Update the details of a share. This includes updating status (revoking\n        or cancelling it), granted permission and validity period of this share.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :type share_invite_bank_inquiry_id: int\n        :param share_detail: The share details. Only one of these objects may be\n        passed.\n        :type share_detail: object_.ShareDetail\n        :param status: The status of the share. Can be PENDING, REVOKED (the\n        user deletes the share inquiry before it's accepted), ACCEPTED,\n        CANCELLED (the user deletes an active share) or CANCELLATION_PENDING,\n        CANCELLATION_ACCEPTED, CANCELLATION_REJECTED (for canceling mutual\n        connects).\n        :type status: str\n        :param start_date: The start date of this share.\n        :type start_date: str\n        :param end_date: The expiration date of this share.\n        :type end_date: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_SHARE_DETAIL: share_detail,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_START_DATE: start_date,\n            cls.FIELD_END_DATE: end_date\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id),\n                                                       share_invite_bank_inquiry_id)\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "This method updates the details of a share inquiry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_all_field_none(self):\n\n        if self._alias is not None:\n            return False\n\n        if self._user_alias_created is not None:\n            return False\n\n        if self._user_alias_revoked is not None:\n            return False\n\n        if self._counter_user_alias is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._draft_share_invite_bank_id is not None:\n            return False\n\n        if self._share_detail is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._share_type is not None:\n            return False\n\n        if self._start_date is not None:\n            return False\n\n        if self._end_date is not None:\n            return False\n\n        if self._id_ is not None:\n            return False\n\n        return True", "response": "returns True if all fields are None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._counter_alias is not None:\n            return False\n\n        if self._user_alias_cancelled is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._draft_share_invite_bank_id is not None:\n            return False\n\n        if self._share_detail is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._share_type is not None:\n            return False\n\n        if self._start_date is not None:\n            return False\n\n        if self._end_date is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        return True", "response": "returns True if all fields are None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._amount_guaranteed is not None:\n            return False\n\n        if self._amount_requested is not None:\n            return False\n\n        if self._issuer is not None:\n            return False\n\n        if self._issuer_authentication_url is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._error_message is not None:\n            return False\n\n        if self._transaction_identifier is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(cls, transferwise_quote_id, transferwise_transfer_id,\n            custom_headers=None):\n        \"\"\"\n        :type api_context: context.ApiContext\n        :type user_id: int\n        :type transferwise_quote_id: int\n        :type transferwise_transfer_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseTransferwiseTransfer\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(cls._determine_user_id(),\n                                                     transferwise_quote_id,\n                                                     transferwise_transfer_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseTransferwiseTransfer.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "This method returns a single entry in the list of available items for a given user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_all_field_none(self):\n\n        if self._alias is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._sub_status is not None:\n            return False\n\n        if self._status_transferwise is not None:\n            return False\n\n        if self._status_transferwise_issue is not None:\n            return False\n\n        if self._amount_source is not None:\n            return False\n\n        if self._amount_target is not None:\n            return False\n\n        if self._rate is not None:\n            return False\n\n        if self._reference is not None:\n            return False\n\n        if self._pay_in_reference is not None:\n            return False\n\n        if self._time_delivery_estimate is not None:\n            return False\n\n        if self._quote is not None:\n            return False\n\n        return True", "response": "returns True if all fields are None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._time_expiry is not None:\n            return False\n\n        if self._quote_id is not None:\n            return False\n\n        if self._amount_source is not None:\n            return False\n\n        if self._amount_target is not None:\n            return False\n\n        if self._amount_fee is not None:\n            return False\n\n        if self._rate is not None:\n            return False\n\n        if self._time_delivery_estimate is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._year is not None:\n            return False\n\n        if self._alias_user is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(cls, statement_format, date_start, date_end,\n               monetary_account_id=None, regional_format=None,\n               custom_headers=None):\n        \"\"\"\n        :type user_id: int\n        :type monetary_account_id: int\n        :param statement_format: The format type of statement. Allowed values:\n        MT940, CSV, PDF.\n        :type statement_format: str\n        :param date_start: The start date for making statements.\n        :type date_start: str\n        :param date_end: The end date for making statements.\n        :type date_end: str\n        :param regional_format: Required for CSV exports. The regional format of\n        the statement, can be UK_US (comma-separated) or EUROPEAN\n        (semicolon-separated).\n        :type regional_format: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_STATEMENT_FORMAT: statement_format,\n            cls.FIELD_DATE_START: date_start,\n            cls.FIELD_DATE_END: date_end,\n            cls.FIELD_REGIONAL_FORMAT: regional_format\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id))\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "This method creates a new entry for a specific date range."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._date_start is not None:\n            return False\n\n        if self._date_end is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._statement_number is not None:\n            return False\n\n        if self._statement_format is not None:\n            return False\n\n        if self._regional_format is not None:\n            return False\n\n        if self._alias_monetary_account is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new CurrencyUnit object for the user_id and currency.", "response": "def create(cls, currency, all_co_owner, description=None, daily_limit=None,\n               overdraft_limit=None, alias=None, avatar_uuid=None, status=None,\n               sub_status=None, reason=None, reason_description=None,\n               notification_filters=None, setting=None, custom_headers=None):\n        \"\"\"\n        :type user_id: int\n        :param currency: The currency of the MonetaryAccountJoint as an ISO 4217\n        formatted currency code.\n        :type currency: str\n        :param all_co_owner: The users the account will be joint with.\n        :type all_co_owner: list[object_.CoOwner]\n        :param description: The description of the MonetaryAccountJoint.\n        Defaults to 'bunq account'.\n        :type description: str\n        :param daily_limit: The daily spending limit Amount of the\n        MonetaryAccountJoint. Defaults to 1000 EUR. Currency must match the\n        MonetaryAccountJoint's currency. Limited to 10000 EUR.\n        :type daily_limit: object_.Amount\n        :param overdraft_limit: The maximum Amount the MonetaryAccountJoint can\n        be 'in the red'. Must be 0 EUR or omitted.\n        :type overdraft_limit: object_.Amount\n        :param alias: The Aliases to add to MonetaryAccountJoint. Must all be\n        confirmed first. Can mostly be ignored.\n        :type alias: list[object_.Pointer]\n        :param avatar_uuid: The UUID of the Avatar of the MonetaryAccountJoint.\n        :type avatar_uuid: str\n        :param status: The status of the MonetaryAccountJoint. Ignored in POST\n        requests (always set to ACTIVE) can be CANCELLED or PENDING_REOPEN in\n        PUT requests to cancel (close) or reopen the MonetaryAccountJoint. When\n        updating the status and/or sub_status no other fields can be updated in\n        the same request (and vice versa).\n        :type status: str\n        :param sub_status: The sub-status of the MonetaryAccountJoint providing\n        extra information regarding the status. Should be ignored for POST\n        requests. In case of PUT requests with status CANCELLED it can only be\n        REDEMPTION_VOLUNTARY, while with status PENDING_REOPEN it can only be\n        NONE. When updating the status and/or sub_status no other fields can be\n        updated in the same request (and vice versa).\n        :type sub_status: str\n        :param reason: The reason for voluntarily cancelling (closing) the\n        MonetaryAccountJoint, can only be OTHER. Should only be specified if\n        updating the status to CANCELLED.\n        :type reason: str\n        :param reason_description: The optional free-form reason for voluntarily\n        cancelling (closing) the MonetaryAccountJoint. Can be any user provided\n        message. Should only be specified if updating the status to CANCELLED.\n        :type reason_description: str\n        :param notification_filters: The types of notifications that will result\n        in a push notification or URL callback for this MonetaryAccountJoint.\n        :type notification_filters: list[object_.NotificationFilter]\n        :param setting: The settings of the MonetaryAccountJoint.\n        :type setting: object_.MonetaryAccountSetting\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_CURRENCY: currency,\n            cls.FIELD_DESCRIPTION: description,\n            cls.FIELD_DAILY_LIMIT: daily_limit,\n            cls.FIELD_OVERDRAFT_LIMIT: overdraft_limit,\n            cls.FIELD_ALIAS: alias,\n            cls.FIELD_AVATAR_UUID: avatar_uuid,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_SUB_STATUS: sub_status,\n            cls.FIELD_REASON: reason,\n            cls.FIELD_REASON_DESCRIPTION: reason_description,\n            cls.FIELD_ALL_CO_OWNER: all_co_owner,\n            cls.FIELD_NOTIFICATION_FILTERS: notification_filters,\n            cls.FIELD_SETTING: setting\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id())\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._avatar is not None:\n            return False\n\n        if self._currency is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._daily_limit is not None:\n            return False\n\n        if self._daily_spent is not None:\n            return False\n\n        if self._overdraft_limit is not None:\n            return False\n\n        if self._balance is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._public_uuid is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._sub_status is not None:\n            return False\n\n        if self._reason is not None:\n            return False\n\n        if self._reason_description is not None:\n            return False\n\n        if self._all_co_owner is not None:\n            return False\n\n        if self._user_id is not None:\n            return False\n\n        if self._monetary_account_profile is not None:\n            return False\n\n        if self._notification_filters is not None:\n            return False\n\n        if self._setting is not None:\n            return False\n\n        return True", "response": "returns True if all fields are None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the object that is referenced by this object.", "response": "def get_referenced_object(self):\n        \"\"\"\n        :rtype: core.BunqModel\n        :raise: BunqException\n        \"\"\"\n\n        if self._MonetaryAccountBank is not None:\n            return self._MonetaryAccountBank\n\n        if self._MonetaryAccountJoint is not None:\n            return self._MonetaryAccountJoint\n\n        if self._MonetaryAccountLight is not None:\n            return self._MonetaryAccountLight\n\n        if self._MonetaryAccountSavings is not None:\n            return self._MonetaryAccountSavings\n\n        raise exception.BunqException(self._ERROR_NULL_FIELDS)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_all_field_none(self):\n\n        if self._MonetaryAccountBank is not None:\n            return False\n\n        if self._MonetaryAccountJoint is not None:\n            return False\n\n        if self._MonetaryAccountLight is not None:\n            return False\n\n        if self._MonetaryAccountSavings is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._avatar is not None:\n            return False\n\n        if self._currency is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._daily_limit is not None:\n            return False\n\n        if self._daily_spent is not None:\n            return False\n\n        if self._balance is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._public_uuid is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._sub_status is not None:\n            return False\n\n        if self._reason is not None:\n            return False\n\n        if self._reason_description is not None:\n            return False\n\n        if self._user_id is not None:\n            return False\n\n        if self._balance_maximum is not None:\n            return False\n\n        if self._budget_month_used is not None:\n            return False\n\n        if self._budget_month_maximum is not None:\n            return False\n\n        if self._budget_year_used is not None:\n            return False\n\n        if self._budget_year_maximum is not None:\n            return False\n\n        if self._budget_withdrawal_year_used is not None:\n            return False\n\n        if self._budget_withdrawal_year_maximum is not None:\n            return False\n\n        if self._notification_filters is not None:\n            return False\n\n        if self._setting is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(cls, switch_service_payment_id,\n            note_attachment_bank_switch_service_netherlands_incoming_payment_id,\n            monetary_account_id=None, custom_headers=None):\n        \"\"\"\n        :type api_context: context.ApiContext\n        :type user_id: int\n        :type monetary_account_id: int\n        :type switch_service_payment_id: int\n        :type\n        note_attachment_bank_switch_service_netherlands_incoming_payment_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype:\n        BunqResponseNoteAttachmentBankSwitchServiceNetherlandsIncomingPayment\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(cls._determine_user_id(),\n                                                     cls._determine_monetary_account_id(\n                                                         monetary_account_id),\n                                                     switch_service_payment_id,\n                                                     note_attachment_bank_switch_service_netherlands_incoming_payment_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseNoteAttachmentBankSwitchServiceNetherlandsIncomingPayment.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "This method returns a specific note attachment bank switch service netherlands incoming payment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._label_user_creator is not None:\n            return False\n\n        if self._content is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(cls, bunqme_fundraiser_result_id,\n            note_text_bunq_me_fundraiser_result_id, monetary_account_id=None,\n            custom_headers=None):\n        \"\"\"\n        :type api_context: context.ApiContext\n        :type user_id: int\n        :type monetary_account_id: int\n        :type bunqme_fundraiser_result_id: int\n        :type note_text_bunq_me_fundraiser_result_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseNoteTextBunqMeFundraiserResult\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(cls._determine_user_id(),\n                                                     cls._determine_monetary_account_id(\n                                                         monetary_account_id),\n                                                     bunqme_fundraiser_result_id,\n                                                     note_text_bunq_me_fundraiser_result_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseNoteTextBunqMeFundraiserResult.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "This method returns a specific BunqResponseNoteTextBunqMeFundraiserResult object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(cls, request_response_id, note_text_request_response_id,\n            monetary_account_id=None, custom_headers=None):\n        \"\"\"\n        :type api_context: context.ApiContext\n        :type user_id: int\n        :type monetary_account_id: int\n        :type request_response_id: int\n        :type note_text_request_response_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseNoteTextRequestResponse\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(cls._determine_user_id(),\n                                                     cls._determine_monetary_account_id(\n                                                         monetary_account_id),\n                                                     request_response_id,\n                                                     note_text_request_response_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseNoteTextRequestResponse.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "This method returns a specific note text request response."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(cls, schedule_id, schedule_instance_id, attachment_id,\n               monetary_account_id=None, description=None, custom_headers=None):\n        \"\"\"\n        :type user_id: int\n        :type monetary_account_id: int\n        :type schedule_id: int\n        :type schedule_instance_id: int\n        :param attachment_id: The reference to the uploaded file to attach to\n        this note.\n        :type attachment_id: int\n        :param description: Optional description of the attachment.\n        :type description: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_DESCRIPTION: description,\n            cls.FIELD_ATTACHMENT_ID: attachment_id\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id),\n                                                       schedule_id,\n                                                       schedule_instance_id)\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "This method creates a new note."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(cls, whitelist_id, whitelist_result_id,\n            note_text_whitelist_result_id, monetary_account_id=None,\n            custom_headers=None):\n        \"\"\"\n        :type api_context: context.ApiContext\n        :type user_id: int\n        :type monetary_account_id: int\n        :type whitelist_id: int\n        :type whitelist_result_id: int\n        :type note_text_whitelist_result_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseNoteTextWhitelistResult\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(cls._determine_user_id(),\n                                                     cls._determine_monetary_account_id(\n                                                         monetary_account_id),\n                                                     whitelist_id,\n                                                     whitelist_result_id,\n                                                     note_text_whitelist_result_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponseNoteTextWhitelistResult.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "This method returns a specific note text whitelist entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a collection of all available users. :type params: dict[str, str]|None :type custom_headers: dict[str, str]|None :rtype: BunqResponseUserList", "response": "def list(cls, params=None, custom_headers=None):\n        \"\"\"\n        Get a collection of all available users.\n\n        :type params: dict[str, str]|None\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseUserList\n        \"\"\"\n\n        if params is None:\n            params = {}\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_LISTING\n        response_raw = api_client.get(endpoint_url, params, custom_headers)\n\n        return BunqResponseUserList.cast_from_bunq_response(\n            cls._from_json_list(response_raw)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the object that is referenced by this object.", "response": "def get_referenced_object(self):\n        \"\"\"\n        :rtype: core.BunqModel\n        :raise: BunqException\n        \"\"\"\n\n        if self._UserLight is not None:\n            return self._UserLight\n\n        if self._UserPerson is not None:\n            return self._UserPerson\n\n        if self._UserCompany is not None:\n            return self._UserCompany\n\n        if self._UserApiKey is not None:\n            return self._UserApiKey\n\n        raise exception.BunqException(self._ERROR_NULL_FIELDS)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_all_field_none(self):\n\n        if self._UserLight is not None:\n            return False\n\n        if self._UserPerson is not None:\n            return False\n\n        if self._UserCompany is not None:\n            return False\n\n        if self._UserApiKey is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(cls, first_name=None, middle_name=None, last_name=None,\n               public_nick_name=None, address_main=None, address_postal=None,\n               avatar_uuid=None, tax_resident=None, document_type=None,\n               document_number=None, document_country_of_issuance=None,\n               document_front_attachment_id=None,\n               document_back_attachment_id=None, date_of_birth=None,\n               place_of_birth=None, country_of_birth=None, nationality=None,\n               language=None, region=None, gender=None, status=None,\n               sub_status=None, legal_guardian_alias=None, session_timeout=None,\n               card_ids=None, card_limits=None,\n               daily_limit_without_confirmation_login=None,\n               notification_filters=None, display_name=None,\n               custom_headers=None):\n        \"\"\"\n        Modify a specific person object's data.\n\n        :type user_person_id: int\n        :param first_name: The person's first name.\n        :type first_name: str\n        :param middle_name: The person's middle name.\n        :type middle_name: str\n        :param last_name: The person's last name.\n        :type last_name: str\n        :param public_nick_name: The person's public nick name.\n        :type public_nick_name: str\n        :param address_main: The user's main address.\n        :type address_main: object_.Address\n        :param address_postal: The person's postal address.\n        :type address_postal: object_.Address\n        :param avatar_uuid: The public UUID of the user's avatar.\n        :type avatar_uuid: str\n        :param tax_resident: The user's tax residence numbers for different\n        countries.\n        :type tax_resident: list[object_.TaxResident]\n        :param document_type: The type of identification document the person\n        registered with.\n        :type document_type: str\n        :param document_number: The identification document number the person\n        registered with.\n        :type document_number: str\n        :param document_country_of_issuance: The country which issued the\n        identification document the person registered with.\n        :type document_country_of_issuance: str\n        :param document_front_attachment_id: The reference to the uploaded\n        picture/scan of the front side of the identification document.\n        :type document_front_attachment_id: int\n        :param document_back_attachment_id: The reference to the uploaded\n        picture/scan of the back side of the identification document.\n        :type document_back_attachment_id: int\n        :param date_of_birth: The person's date of birth. Accepts ISO8601 date\n        formats.\n        :type date_of_birth: str\n        :param place_of_birth: The person's place of birth.\n        :type place_of_birth: str\n        :param country_of_birth: The person's country of birth. Formatted as a\n        SO 3166-1 alpha-2 country code.\n        :type country_of_birth: str\n        :param nationality: The person's nationality. Formatted as a SO 3166-1\n        alpha-2 country code.\n        :type nationality: str\n        :param language: The person's preferred language. Formatted as a ISO\n        639-1 language code plus a ISO 3166-1 alpha-2 country code, seperated by\n        an underscore.\n        :type language: str\n        :param region: The person's preferred region. Formatted as a ISO 639-1\n        language code plus a ISO 3166-1 alpha-2 country code, seperated by an\n        underscore.\n        :type region: str\n        :param gender: The person's gender. Can be: MALE, FEMALE and UNKNOWN.\n        :type gender: str\n        :param status: The user status. You are not allowed to update the status\n        via PUT.\n        :type status: str\n        :param sub_status: The user sub-status. Can be updated to SUBMIT if\n        status is RECOVERY.\n        :type sub_status: str\n        :param legal_guardian_alias: The legal guardian of the user. Required\n        for minors.\n        :type legal_guardian_alias: object_.Pointer\n        :param session_timeout: The setting for the session timeout of the user\n        in seconds.\n        :type session_timeout: int\n        :param card_ids: Card ids used for centralized card limits.\n        :type card_ids: list[object_.BunqId]\n        :param card_limits: The centralized limits for user's cards.\n        :type card_limits: list[object_.CardLimit]\n        :param daily_limit_without_confirmation_login: The amount the user can\n        pay in the session without asking for credentials.\n        :type daily_limit_without_confirmation_login: object_.Amount\n        :param notification_filters: The types of notifications that will result\n        in a push notification or URL callback for this UserPerson.\n        :type notification_filters: list[object_.NotificationFilter]\n        :param display_name: The person's legal name. Available legal names can\n        be listed via the 'user/{user_id}/legal-name' endpoint.\n        :type display_name: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_FIRST_NAME: first_name,\n            cls.FIELD_MIDDLE_NAME: middle_name,\n            cls.FIELD_LAST_NAME: last_name,\n            cls.FIELD_PUBLIC_NICK_NAME: public_nick_name,\n            cls.FIELD_ADDRESS_MAIN: address_main,\n            cls.FIELD_ADDRESS_POSTAL: address_postal,\n            cls.FIELD_AVATAR_UUID: avatar_uuid,\n            cls.FIELD_TAX_RESIDENT: tax_resident,\n            cls.FIELD_DOCUMENT_TYPE: document_type,\n            cls.FIELD_DOCUMENT_NUMBER: document_number,\n            cls.FIELD_DOCUMENT_COUNTRY_OF_ISSUANCE: document_country_of_issuance,\n            cls.FIELD_DOCUMENT_FRONT_ATTACHMENT_ID: document_front_attachment_id,\n            cls.FIELD_DOCUMENT_BACK_ATTACHMENT_ID: document_back_attachment_id,\n            cls.FIELD_DATE_OF_BIRTH: date_of_birth,\n            cls.FIELD_PLACE_OF_BIRTH: place_of_birth,\n            cls.FIELD_COUNTRY_OF_BIRTH: country_of_birth,\n            cls.FIELD_NATIONALITY: nationality,\n            cls.FIELD_LANGUAGE: language,\n            cls.FIELD_REGION: region,\n            cls.FIELD_GENDER: gender,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_SUB_STATUS: sub_status,\n            cls.FIELD_LEGAL_GUARDIAN_ALIAS: legal_guardian_alias,\n            cls.FIELD_SESSION_TIMEOUT: session_timeout,\n            cls.FIELD_CARD_IDS: card_ids,\n            cls.FIELD_CARD_LIMITS: card_limits,\n            cls.FIELD_DAILY_LIMIT_WITHOUT_CONFIRMATION_LOGIN: daily_limit_without_confirmation_login,\n            cls.FIELD_NOTIFICATION_FILTERS: notification_filters,\n            cls.FIELD_DISPLAY_NAME: display_name\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id())\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "Update a specific person object s data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._public_uuid is not None:\n            return False\n\n        if self._first_name is not None:\n            return False\n\n        if self._middle_name is not None:\n            return False\n\n        if self._last_name is not None:\n            return False\n\n        if self._legal_name is not None:\n            return False\n\n        if self._display_name is not None:\n            return False\n\n        if self._public_nick_name is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._tax_resident is not None:\n            return False\n\n        if self._document_type is not None:\n            return False\n\n        if self._document_number is not None:\n            return False\n\n        if self._document_country_of_issuance is not None:\n            return False\n\n        if self._address_main is not None:\n            return False\n\n        if self._address_postal is not None:\n            return False\n\n        if self._date_of_birth is not None:\n            return False\n\n        if self._place_of_birth is not None:\n            return False\n\n        if self._country_of_birth is not None:\n            return False\n\n        if self._nationality is not None:\n            return False\n\n        if self._language is not None:\n            return False\n\n        if self._region is not None:\n            return False\n\n        if self._gender is not None:\n            return False\n\n        if self._avatar is not None:\n            return False\n\n        if self._version_terms_of_service is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._sub_status is not None:\n            return False\n\n        if self._session_timeout is not None:\n            return False\n\n        if self._daily_limit_without_confirmation_login is not None:\n            return False\n\n        if self._notification_filters is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a specific company s data.", "response": "def update(cls, name=None, public_nick_name=None, avatar_uuid=None,\n               address_main=None, address_postal=None, language=None,\n               region=None, country=None, ubo=None,\n               chamber_of_commerce_number=None, legal_form=None, status=None,\n               sub_status=None, session_timeout=None,\n               daily_limit_without_confirmation_login=None,\n               notification_filters=None, custom_headers=None):\n        \"\"\"\n        Modify a specific company's data.\n\n        :type user_company_id: int\n        :param name: The company name.\n        :type name: str\n        :param public_nick_name: The company's nick name.\n        :type public_nick_name: str\n        :param avatar_uuid: The public UUID of the company's avatar.\n        :type avatar_uuid: str\n        :param address_main: The user's main address.\n        :type address_main: object_.Address\n        :param address_postal: The company's postal address.\n        :type address_postal: object_.Address\n        :param language: The person's preferred language. Formatted as a ISO\n        639-1 language code plus a ISO 3166-1 alpha-2 country code, seperated by\n        an underscore.\n        :type language: str\n        :param region: The person's preferred region. Formatted as a ISO 639-1\n        language code plus a ISO 3166-1 alpha-2 country code, seperated by an\n        underscore.\n        :type region: str\n        :param country: The country where the company is registered.\n        :type country: str\n        :param ubo: The names and birth dates of the company's ultimate\n        beneficiary owners. Minimum zero, maximum four.\n        :type ubo: list[object_.Ubo]\n        :param chamber_of_commerce_number: The company's chamber of commerce\n        number.\n        :type chamber_of_commerce_number: str\n        :param legal_form: The company's legal form.\n        :type legal_form: str\n        :param status: The user status. Can be: ACTIVE, SIGNUP, RECOVERY.\n        :type status: str\n        :param sub_status: The user sub-status. Can be: NONE, FACE_RESET,\n        APPROVAL, APPROVAL_DIRECTOR, APPROVAL_PARENT, APPROVAL_SUPPORT,\n        COUNTER_IBAN, IDEAL or SUBMIT.\n        :type sub_status: str\n        :param session_timeout: The setting for the session timeout of the\n        company in seconds.\n        :type session_timeout: int\n        :param daily_limit_without_confirmation_login: The amount the company\n        can pay in the session without asking for credentials.\n        :type daily_limit_without_confirmation_login: object_.Amount\n        :param notification_filters: The types of notifications that will result\n        in a push notification or URL callback for this UserCompany.\n        :type notification_filters: list[object_.NotificationFilter]\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_NAME: name,\n            cls.FIELD_PUBLIC_NICK_NAME: public_nick_name,\n            cls.FIELD_AVATAR_UUID: avatar_uuid,\n            cls.FIELD_ADDRESS_MAIN: address_main,\n            cls.FIELD_ADDRESS_POSTAL: address_postal,\n            cls.FIELD_LANGUAGE: language,\n            cls.FIELD_REGION: region,\n            cls.FIELD_COUNTRY: country,\n            cls.FIELD_UBO: ubo,\n            cls.FIELD_CHAMBER_OF_COMMERCE_NUMBER: chamber_of_commerce_number,\n            cls.FIELD_LEGAL_FORM: legal_form,\n            cls.FIELD_STATUS: status,\n            cls.FIELD_SUB_STATUS: sub_status,\n            cls.FIELD_SESSION_TIMEOUT: session_timeout,\n            cls.FIELD_DAILY_LIMIT_WITHOUT_CONFIRMATION_LOGIN: daily_limit_without_confirmation_login,\n            cls.FIELD_NOTIFICATION_FILTERS: notification_filters\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id())\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._public_uuid is not None:\n            return False\n\n        if self._name is not None:\n            return False\n\n        if self._display_name is not None:\n            return False\n\n        if self._public_nick_name is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._chamber_of_commerce_number is not None:\n            return False\n\n        if self._legal_form is not None:\n            return False\n\n        if self._type_of_business_entity is not None:\n            return False\n\n        if self._sector_of_industry is not None:\n            return False\n\n        if self._counter_bank_iban is not None:\n            return False\n\n        if self._avatar is not None:\n            return False\n\n        if self._address_main is not None:\n            return False\n\n        if self._address_postal is not None:\n            return False\n\n        if self._version_terms_of_service is not None:\n            return False\n\n        if self._director_alias is not None:\n            return False\n\n        if self._language is not None:\n            return False\n\n        if self._country is not None:\n            return False\n\n        if self._region is not None:\n            return False\n\n        if self._ubo is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._sub_status is not None:\n            return False\n\n        if self._session_timeout is not None:\n            return False\n\n        if self._card_ids is not None:\n            return False\n\n        if self._card_limits is not None:\n            return False\n\n        if self._daily_limit_without_confirmation_login is not None:\n            return False\n\n        if self._notification_filters is not None:\n            return False\n\n        if self._customer is not None:\n            return False\n\n        if self._customer_limit is not None:\n            return False\n\n        if self._billing_contract is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._billing_account_id is not None:\n            return False\n\n        if self._invoice_notification_preference is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._requested_by_user is not None:\n            return False\n\n        if self._granted_by_user is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(cls, params=None, custom_headers=None):\n\n        if params is None:\n            params = {}\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_LISTING.format(\n            cls._determine_user_id())\n        response_raw = api_client.get(endpoint_url, params, custom_headers)\n\n        return BunqResponseOauthClientList.cast_from_bunq_response(\n            cls._from_json_list(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "This method returns a list of all the keys associated with the user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_all_field_none(self):\n\n        if self._status is not None:\n            return False\n\n        if self._client_id is not None:\n            return False\n\n        if self._secret is not None:\n            return False\n\n        if self._callback_url is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a specific entry in the payment service provider credential.", "response": "def get(cls, payment_service_provider_credential_id, custom_headers=None):\n        \"\"\"\n        :type api_context: context.ApiContext\n        :type payment_service_provider_credential_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponsePaymentServiceProviderCredential\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(\n            payment_service_provider_credential_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponsePaymentServiceProviderCredential.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(cls, client_payment_service_provider_certificate,\n               client_payment_service_provider_certificate_chain,\n               client_public_key_signature, custom_headers=None):\n        \"\"\"\n        :param client_payment_service_provider_certificate: Payment Services\n        Directive 2 compatible QSEAL certificate\n        :type client_payment_service_provider_certificate: str\n        :param client_payment_service_provider_certificate_chain: Intermediate\n        and root certificate belonging to the provided certificate.\n        :type client_payment_service_provider_certificate_chain: str\n        :param client_public_key_signature: The Base64 encoded signature of the\n        public key provided during installation and with the installation token\n        appended as a nonce. Signed with the private key belonging to the QSEAL\n        certificate.\n        :type client_public_key_signature: str\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_CLIENT_PAYMENT_SERVICE_PROVIDER_CERTIFICATE: client_payment_service_provider_certificate,\n            cls.FIELD_CLIENT_PAYMENT_SERVICE_PROVIDER_CERTIFICATE_CHAIN: client_payment_service_provider_certificate_chain,\n            cls.FIELD_CLIENT_PUBLIC_KEY_SIGNATURE: client_public_key_signature\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "This method creates a new token for the given client payment service provider certificate and root certificate."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._created is not None:\n            return False\n\n        if self._updated is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._expiry_time is not None:\n            return False\n\n        if self._token_value is not None:\n            return False\n\n        if self._permitted_device is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(cls, credential_password_ip_id, permitted_ip_id,\n            custom_headers=None):\n        \"\"\"\n        :type api_context: context.ApiContext\n        :type user_id: int\n        :type credential_password_ip_id: int\n        :type permitted_ip_id: int\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponsePermittedIp\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n        endpoint_url = cls._ENDPOINT_URL_READ.format(cls._determine_user_id(),\n                                                     credential_password_ip_id,\n                                                     permitted_ip_id)\n        response_raw = api_client.get(endpoint_url, {}, custom_headers)\n\n        return BunqResponsePermittedIp.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_GET)\n        )", "response": "This method returns a list of permissions for a user in the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new TabItem for a given Tab.", "response": "def create(cls, cash_register_id, tab_uuid, description,\n               monetary_account_id=None, ean_code=None,\n               avatar_attachment_uuid=None, tab_attachment=None, quantity=None,\n               amount=None, custom_headers=None):\n        \"\"\"\n        Create a new TabItem for a given Tab.\n\n        :type user_id: int\n        :type monetary_account_id: int\n        :type cash_register_id: int\n        :type tab_uuid: str\n        :param description: The TabItem's brief description. Can't be empty and\n        must be no longer than 100 characters\n        :type description: str\n        :param ean_code: The TabItem's EAN code.\n        :type ean_code: str\n        :param avatar_attachment_uuid: An AttachmentPublic UUID that used as an\n        avatar for the TabItem.\n        :type avatar_attachment_uuid: str\n        :param tab_attachment: A list of AttachmentTab attached to the TabItem.\n        :type tab_attachment: list[int]\n        :param quantity: The quantity of the TabItem. Formatted as a number\n        containing up to 15 digits, up to 15 decimals and using a dot.\n        :type quantity: str\n        :param amount: The money amount of the TabItem. Will not change the\n        value of the corresponding Tab.\n        :type amount: object_.Amount\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_DESCRIPTION: description,\n            cls.FIELD_EAN_CODE: ean_code,\n            cls.FIELD_AVATAR_ATTACHMENT_UUID: avatar_attachment_uuid,\n            cls.FIELD_TAB_ATTACHMENT: tab_attachment,\n            cls.FIELD_QUANTITY: quantity,\n            cls.FIELD_AMOUNT: amount\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id(),\n                                                       cls._determine_monetary_account_id(\n                                                           monetary_account_id),\n                                                       cash_register_id,\n                                                       tab_uuid)\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(cls, token, custom_headers=None):\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_TOKEN: token\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id())\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseTokenQrRequestIdeal.cast_from_bunq_response(\n            cls._from_json(response_raw, cls._OBJECT_TYPE_POST)\n        )", "response": "This method creates an ideal transaction from an ideal transaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._time_responded is not None:\n            return False\n\n        if self._time_expiry is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._amount_inquired is not None:\n            return False\n\n        if self._amount_responded is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._attachment is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._minimum_age is not None:\n            return False\n\n        if self._require_address is not None:\n            return False\n\n        if self._address_shipping is not None:\n            return False\n\n        if self._address_billing is not None:\n            return False\n\n        if self._geolocation is not None:\n            return False\n\n        if self._redirect_url is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._sub_type is not None:\n            return False\n\n        if self._allow_chat is not None:\n            return False\n\n        if self._eligible_whitelist_id is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, monetary_account_paying_id, request_id,\n               maximum_amount_per_month, custom_headers=None):\n        \"\"\"\n        Create a new SDD whitelist entry.\n\n        :type user_id: int\n        :param monetary_account_paying_id: ID of the monetary account of which\n        you want to pay from.\n        :type monetary_account_paying_id: int\n        :param request_id: ID of the request for which you want to whitelist the\n        originating SDD.\n        :type request_id: int\n        :param maximum_amount_per_month: The maximum amount of money that is\n        allowed to be deducted based on the whitelist.\n        :type maximum_amount_per_month: object_.Amount\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        request_map = {\n            cls.FIELD_MONETARY_ACCOUNT_PAYING_ID: monetary_account_paying_id,\n            cls.FIELD_REQUEST_ID: request_id,\n            cls.FIELD_MAXIMUM_AMOUNT_PER_MONTH: maximum_amount_per_month\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        api_client = client.ApiClient(cls._get_api_context())\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_CREATE.format(cls._determine_user_id())\n        response_raw = api_client.post(endpoint_url, request_bytes,\n                                       custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "This method creates a new SDD whitelist entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(cls, whitelist_sdd_id, monetary_account_paying_id=None,\n               maximum_amount_per_month=None, custom_headers=None):\n        \"\"\"\n        :type user_id: int\n        :type whitelist_sdd_id: int\n        :param monetary_account_paying_id: ID of the monetary account of which\n        you want to pay from.\n        :type monetary_account_paying_id: int\n        :param maximum_amount_per_month: The maximum amount of money that is\n        allowed to be deducted based on the whitelist.\n        :type maximum_amount_per_month: object_.Amount\n        :type custom_headers: dict[str, str]|None\n\n        :rtype: BunqResponseInt\n        \"\"\"\n\n        if custom_headers is None:\n            custom_headers = {}\n\n        api_client = client.ApiClient(cls._get_api_context())\n\n        request_map = {\n            cls.FIELD_MONETARY_ACCOUNT_PAYING_ID: monetary_account_paying_id,\n            cls.FIELD_MAXIMUM_AMOUNT_PER_MONTH: maximum_amount_per_month\n        }\n        request_map_string = converter.class_to_json(request_map)\n        request_map_string = cls._remove_field_for_request(request_map_string)\n\n        request_bytes = request_map_string.encode()\n        endpoint_url = cls._ENDPOINT_URL_UPDATE.format(cls._determine_user_id(),\n                                                       whitelist_sdd_id)\n        response_raw = api_client.put(endpoint_url, request_bytes,\n                                      custom_headers)\n\n        return BunqResponseInt.cast_from_bunq_response(\n            cls._process_for_id(response_raw)\n        )", "response": "This method allows you to update the user s account s attributes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._monetary_account_incoming_id is not None:\n            return False\n\n        if self._monetary_account_paying_id is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._credit_scheme_identifier is not None:\n            return False\n\n        if self._mandate_identifier is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._maximum_amount_per_month is not None:\n            return False\n\n        if self._user_alias_created is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing a object into a JSON string.", "response": "def class_to_json(obj):\n    \"\"\"\n    :type obj: int|str|bool|float|bytes|unicode|list|dict|object\n\n    :rtype: int|str|bool|list|dict\n    \"\"\"\n\n    obj_raw = serialize(obj)\n\n    return json.dumps(obj_raw, indent=_JSON_INDENT, sort_keys=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a custom JsonAdapter for a specific class.", "response": "def register_custom_adapter(cls, target_class, adapter):\n        \"\"\"\n        :type target_class: type\n        :type adapter: JsonAdapter|type\n\n        :rtype: None\n        \"\"\"\n\n        class_name = target_class.__name__\n\n        if adapter.can_serialize():\n            cls._custom_serializers[class_name] = adapter\n\n        if adapter.can_deserialize():\n            cls._custom_deserializers[class_name] = adapter"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_serializer(cls, cls_for):\n\n        if cls_for.__name__ in cls._custom_serializers:\n            return cls._custom_serializers[cls_for.__name__]\n\n        return JsonAdapter", "response": "Returns the serializer for the given class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_deserializer(cls, cls_for):\n\n        if cls_for.__name__ in cls._custom_deserializers:\n            return cls._custom_deserializers[cls_for.__name__]\n\n        return JsonAdapter", "response": "Returns the deserializer for the given class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the object is deserialized False otherwise.", "response": "def _is_deserialized(cls, cls_target, obj):\n        \"\"\"\n        :type cls_target: type\n        :type obj: int|str|bool|float|bytes|unicode|list|dict|object\n\n        :rtype: bool\n        \"\"\"\n\n        if cls_target is None:\n            return True\n\n        if cls_target in {list, dict}:\n            return True\n\n        if cls._is_bytes_type(cls_target):\n            return True\n\n        if obj is None:\n            return True\n\n        if type(obj) in {list, cls_target}:\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _deserialize_key(cls, key):\n\n        if key in cls._KEYS_OVERLAPPING:\n            return key + cls._SUFFIX_KEY_OVERLAPPING\n\n        return key", "response": "Deserializes a key into a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a ValueSpecs object for the given attribute name.", "response": "def _get_value_specs(cls, cls_in, attribute_name):\n        \"\"\"\n        :type cls_in: type\n        :type attribute_name: str\n\n        :rtype: ValueSpecs\n        \"\"\"\n\n        if cls_in in {dict, list}:\n            return ValueSpecs(None, ValueTypes(None, None))\n        else:\n            return cls._fetch_attribute_specs_from_doc(cls_in, attribute_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _fetch_attribute_specs_from_doc(cls, cls_in, attribute_name):\n\n        pattern = cls._TEMPLATE_PATTERN_PARAM_TYPES.format(attribute_name)\n        match = re.search(pattern, cls_in.__doc__)\n\n        if match is not None:\n            return ValueSpecs(\n                cls._fetch_name(match),\n                ValueTypes(\n                    cls._fetch_type_main(cls_in, match),\n                    cls._fetch_type_sub(cls_in, match)\n                )\n            )\n        else:\n            return None", "response": "Returns a ValueSpecs object for the given attribute name from the docstrings of the class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fetch_type_main(cls, cls_in, match):\n\n        return cls._str_to_type(\n            cls_in,\n            match.group(cls._SUBMATCH_INDEX_TYPE_MAIN)\n        )", "response": "Fetch the type of main from the match."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fetch_type_sub(cls, cls_in, match):\n\n        if match.group(cls._SUBMATCH_INDEX_TYPE_SUB):\n            return cls._str_to_type(\n                cls_in,\n                match.group(cls._SUBMATCH_INDEX_TYPE_SUB)\n            )\n        else:\n            return None", "response": "Fetch the type of the sub - tag from the match."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a string to a type in the specified context class.", "response": "def _str_to_type(cls, context_class, string):\n        \"\"\"\n        :type context_class: type\n        :type string: str\n\n        :rtype: type\n        \"\"\"\n\n        if string in cls._TYPE_NAMES_BUILTIN:\n            return eval(string)\n\n        module_ = sys.modules[context_class.__module__]\n\n        if hasattr(module_, string):\n            return getattr(module_, string)\n\n        return cls._str_to_type_from_member_module(module_, string)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a string to a class.", "response": "def _str_to_type_from_member_module(cls, module_, string):\n        \"\"\"\n        :type module_: module\n        :type string: str\n\n        :rtype: type\n        :raise: BunqException when could not find the class for the string.\n        \"\"\"\n\n        module_name_short, class_name = string.split(cls._DELIMITER_MODULE)\n        members = inspect.getmembers(module_, inspect.ismodule)\n\n        for name, module_member in members:\n            if module_name_short == name:\n                return getattr(module_member, class_name)\n\n        error_message = cls._ERROR_COULD_NOT_FIND_CLASS.format(string)\n\n        raise exception.BunqException(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfill in default values in dict_ with default values.", "response": "def _fill_default_values(cls, cls_context, dict_):\n        \"\"\"\n        :type cls_context: type\n        :type dict_: dict\n\n        :rtype: dict\n        \"\"\"\n\n        dict_with_default_values = dict(dict_)\n        params = re.findall(cls._PATTERN_PARAM_NAME_TYPED_ANY,\n                            cls_context.__doc__)\n\n        for param in params:\n            if param not in dict_with_default_values:\n                dict_with_default_values[param] = None\n\n        return dict_with_default_values"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serialize(cls, obj):\n\n        cls._initialize()\n        serializer = cls._get_serializer(type(obj))\n\n        if serializer == cls:\n            return cls._serialize_default(obj)\n        else:\n            return serializer.serialize(obj)", "response": "Serializes the object into a string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nserializing the object into a string.", "response": "def _serialize_default(cls, obj):\n        \"\"\"\n        :type obj: int|str|bool|float|bytes|unicode|list|dict|object\n\n        :rtype: int|str|bool|list|dict\n        \"\"\"\n\n        if obj is None or cls._is_primitive(obj):\n            return obj\n        elif cls._is_bytes(obj):\n            return obj.decode()\n        elif type(obj) == list:\n            return cls._serialize_list(obj)\n        else:\n            dict_ = cls._get_obj_raw(obj)\n\n            return cls._serialize_dict(dict_)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nserialize a list of items into a list of items.", "response": "def _serialize_list(cls, list_):\n        \"\"\"\n        :type list_: list\n\n        :rtype: list\n        \"\"\"\n\n        list_serialized = []\n\n        for item in list_:\n            item_serialized = cls.serialize(item)\n            list_serialized.append(item_serialized)\n\n        return list_serialized"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _serialize_dict(cls, dict_):\n\n        obj_serialized = {}\n\n        for key in dict_.keys():\n            item_serialized = cls.serialize(dict_[key])\n\n            if item_serialized is not None:\n                key = key.rstrip(cls._SUFFIX_KEY_OVERLAPPING)\n                key = key.lstrip(cls._PREFIX_KEY_PROTECTED)\n                obj_serialized[key] = item_serialized\n\n        return obj_serialized", "response": "Serializes a dictionary of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an exception based on the response code.", "response": "def create_exception_for_response(\n            cls,\n            response_code,\n            messages,\n            response_id\n    ):\n        \"\"\"\n        :type response_code: int\n        :type messages: list[str]\n        :type response_id: str\n\n        :return: The exception according to the status code.\n        :rtype:  ApiException\n        \"\"\"\n\n        error_message = cls._generate_message_error(\n            response_code,\n            messages,\n            response_id\n        )\n\n        if response_code == cls._HTTP_RESPONSE_CODE_BAD_REQUEST:\n            return BadRequestException(\n                error_message,\n                response_code,\n                response_id\n            )\n        if response_code == cls._HTTP_RESPONSE_CODE_UNAUTHORIZED:\n            return UnauthorizedException(\n                error_message,\n                response_code,\n                response_id\n            )\n        if response_code == cls._HTTP_RESPONSE_CODE_FORBIDDEN:\n            return ForbiddenException(\n                error_message,\n                response_code,\n                response_id\n            )\n        if response_code == cls._HTTP_RESPONSE_CODE_NOT_FOUND:\n            return NotFoundException(\n                error_message,\n                response_code,\n                response_id\n            )\n        if response_code == cls._HTTP_RESPONSE_CODE_METHOD_NOT_ALLOWED:\n            return MethodNotAllowedException(\n                error_message,\n                response_code,\n                response_id\n            )\n        if response_code == cls._HTTP_RESPONSE_CODE_TOO_MANY_REQUESTS:\n            return TooManyRequestsException(\n                error_message,\n                response_code,\n                response_id\n            )\n        if response_code == cls._HTTP_RESPONSE_CODE_INTERNAL_SERVER_ERROR:\n            return PleaseContactBunqException(\n                error_message,\n                response_code,\n                response_id\n            )\n\n        return UnknownApiErrorException(\n            error_message,\n            response_code,\n            response_id\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _generate_message_error(cls, response_code, messages, response_id):\n\n        line_response_code = cls._FORMAT_RESPONSE_CODE_LINE \\\n            .format(response_code)\n        line_response_id = cls._FORMAT_RESPONSE_ID_LINE.format(response_id)\n        line_error_message = cls._FORMAT_ERROR_MESSAGE_LINE.format(\n            cls._GLUE_ERROR_MESSAGE_STRING_EMPTY.join(messages)\n        )\n\n        return cls._glue_all_error_message(\n            [line_response_code, line_response_id, line_error_message]\n        )", "response": "Generate a message error from the response code and message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._type_ is not None:\n            return False\n\n        if self._type_description is not None:\n            return False\n\n        if self._type_description_translated is not None:\n            return False\n\n        if self._instance_description is not None:\n            return False\n\n        if self._product_vat_exclusive is not None:\n            return False\n\n        if self._product_vat_inclusive is not None:\n            return False\n\n        if self._item is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_all_field_none(self):\n\n        if self._billing_date is not None:\n            return False\n\n        if self._type_description is not None:\n            return False\n\n        if self._type_description_translated is not None:\n            return False\n\n        if self._unit_vat_exclusive is not None:\n            return False\n\n        if self._unit_vat_inclusive is not None:\n            return False\n\n        if self._vat is not None:\n            return False\n\n        if self._quantity is not None:\n            return False\n\n        if self._total_vat_exclusive is not None:\n            return False\n\n        if self._total_vat_inclusive is not None:\n            return False\n\n        return True", "response": "returns True if all fields are None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._iban is not None:\n            return False\n\n        if self._display_name is not None:\n            return False\n\n        if self._avatar is not None:\n            return False\n\n        if self._label_user is not None:\n            return False\n\n        if self._country is not None:\n            return False\n\n        if self._bunq_me is not None:\n            return False\n\n        if self._is_light is not None:\n            return False\n\n        if self._swift_bic is not None:\n            return False\n\n        if self._swift_account_number is not None:\n            return False\n\n        if self._transferwise_account_number is not None:\n            return False\n\n        if self._transferwise_bank_code is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._uuid is not None:\n            return False\n\n        if self._anchor_uuid is not None:\n            return False\n\n        if self._image is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._attachment_public_uuid is not None:\n            return False\n\n        if self._content_type is not None:\n            return False\n\n        if self._height is not None:\n            return False\n\n        if self._width is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._uuid is not None:\n            return False\n\n        if self._avatar is not None:\n            return False\n\n        if self._public_nick_name is not None:\n            return False\n\n        if self._display_name is not None:\n            return False\n\n        if self._country is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_all_field_none(self):\n\n        if self._type_ is not None:\n            return False\n\n        if self._value is not None:\n            return False\n\n        if self._name is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_all_field_none(self):\n\n        if self._street is not None:\n            return False\n\n        if self._house_number is not None:\n            return False\n\n        if self._po_box is not None:\n            return False\n\n        if self._postal_code is not None:\n            return False\n\n        if self._city is not None:\n            return False\n\n        if self._country is not None:\n            return False\n\n        if self._province is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._latitude is not None:\n            return False\n\n        if self._longitude is not None:\n            return False\n\n        if self._altitude is not None:\n            return False\n\n        if self._radius is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_all_field_none(self):\n\n        if self._uuid is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._content_type is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._daily_limit is not None:\n            return False\n\n        if self._currency is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._country is not None:\n            return False\n\n        if self._expiry_time is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._uuid is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._monetary_account_id is not None:\n            return False\n\n        if self._four_digit is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._notification_delivery_method is not None:\n            return False\n\n        if self._notification_target is not None:\n            return False\n\n        if self._category is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_all_field_none(self):\n\n        if self._cash_register_qr_code is not None:\n            return False\n\n        if self._tab_qr_code is not None:\n            return False\n\n        if self._location is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._content_type is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if all fields are None", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._id_ is not None:\n            return False\n\n        if self._amount is not None:\n            return False\n\n        if self._alias is not None:\n            return False\n\n        if self._counterparty_alias is not None:\n            return False\n\n        if self._description is not None:\n            return False\n\n        if self._merchant_reference is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._attachment is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_referenced_object(self):\n\n        if self._Payment is not None:\n            return self._Payment\n\n        if self._PaymentBatch is not None:\n            return self._PaymentBatch\n\n        raise exception.BunqException(self._ERROR_NULL_FIELDS)", "response": "Get the object that is referenced by this object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_all_field_none(self):\n\n        if self._share_detail is not None:\n            return False\n\n        if self._start_date is not None:\n            return False\n\n        if self._end_date is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._payment is not None:\n            return False\n\n        if self._read_only is not None:\n            return False\n\n        if self._draft_payment is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._view_balance is not None:\n            return False\n\n        if self._view_old_events is not None:\n            return False\n\n        if self._view_new_events is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a copy of the object with the same attributes as the original object.", "response": "def get_referenced_object(self):\n        \"\"\"\n        :rtype: core.BunqModel\n        :raise: BunqException\n        \"\"\"\n\n        if self._BunqMeTab is not None:\n            return self._BunqMeTab\n\n        if self._BunqMeTabResultResponse is not None:\n            return self._BunqMeTabResultResponse\n\n        if self._BunqMeFundraiserResult is not None:\n            return self._BunqMeFundraiserResult\n\n        if self._Card is not None:\n            return self._Card\n\n        if self._CardDebit is not None:\n            return self._CardDebit\n\n        if self._DraftPayment is not None:\n            return self._DraftPayment\n\n        if self._FeatureAnnouncement is not None:\n            return self._FeatureAnnouncement\n\n        if self._IdealMerchantTransaction is not None:\n            return self._IdealMerchantTransaction\n\n        if self._Invoice is not None:\n            return self._Invoice\n\n        if self._ScheduledPayment is not None:\n            return self._ScheduledPayment\n\n        if self._ScheduledPaymentBatch is not None:\n            return self._ScheduledPaymentBatch\n\n        if self._ScheduledInstance is not None:\n            return self._ScheduledInstance\n\n        if self._MasterCardAction is not None:\n            return self._MasterCardAction\n\n        if self._BankSwitchServiceNetherlandsIncomingPayment is not None:\n            return self._BankSwitchServiceNetherlandsIncomingPayment\n\n        if self._Payment is not None:\n            return self._Payment\n\n        if self._PaymentBatch is not None:\n            return self._PaymentBatch\n\n        if self._RequestInquiryBatch is not None:\n            return self._RequestInquiryBatch\n\n        if self._RequestInquiry is not None:\n            return self._RequestInquiry\n\n        if self._RequestResponse is not None:\n            return self._RequestResponse\n\n        if self._RewardRecipient is not None:\n            return self._RewardRecipient\n\n        if self._RewardSender is not None:\n            return self._RewardSender\n\n        if self._ShareInviteBankInquiryBatch is not None:\n            return self._ShareInviteBankInquiryBatch\n\n        if self._ShareInviteBankInquiry is not None:\n            return self._ShareInviteBankInquiry\n\n        if self._ShareInviteBankResponse is not None:\n            return self._ShareInviteBankResponse\n\n        if self._SofortMerchantTransaction is not None:\n            return self._SofortMerchantTransaction\n\n        if self._TabResultInquiry is not None:\n            return self._TabResultInquiry\n\n        if self._TabResultResponse is not None:\n            return self._TabResultResponse\n\n        if self._TransferwiseTransfer is not None:\n            return self._TransferwiseTransfer\n\n        raise exception.BunqException(self._ERROR_NULL_FIELDS)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_all_field_none(self):\n\n        if self._BunqMeTab is not None:\n            return False\n\n        if self._BunqMeTabResultResponse is not None:\n            return False\n\n        if self._BunqMeFundraiserResult is not None:\n            return False\n\n        if self._Card is not None:\n            return False\n\n        if self._CardDebit is not None:\n            return False\n\n        if self._DraftPayment is not None:\n            return False\n\n        if self._FeatureAnnouncement is not None:\n            return False\n\n        if self._IdealMerchantTransaction is not None:\n            return False\n\n        if self._Invoice is not None:\n            return False\n\n        if self._ScheduledPayment is not None:\n            return False\n\n        if self._ScheduledPaymentBatch is not None:\n            return False\n\n        if self._ScheduledInstance is not None:\n            return False\n\n        if self._MasterCardAction is not None:\n            return False\n\n        if self._BankSwitchServiceNetherlandsIncomingPayment is not None:\n            return False\n\n        if self._Payment is not None:\n            return False\n\n        if self._PaymentBatch is not None:\n            return False\n\n        if self._RequestInquiryBatch is not None:\n            return False\n\n        if self._RequestInquiry is not None:\n            return False\n\n        if self._RequestResponse is not None:\n            return False\n\n        if self._RewardRecipient is not None:\n            return False\n\n        if self._RewardSender is not None:\n            return False\n\n        if self._ShareInviteBankInquiryBatch is not None:\n            return False\n\n        if self._ShareInviteBankInquiry is not None:\n            return False\n\n        if self._ShareInviteBankResponse is not None:\n            return False\n\n        if self._SofortMerchantTransaction is not None:\n            return False\n\n        if self._TabResultInquiry is not None:\n            return False\n\n        if self._TabResultResponse is not None:\n            return False\n\n        if self._TransferwiseTransfer is not None:\n            return False\n\n        return True", "response": "returns True if all fields are None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._uuid is not None:\n            return False\n\n        if self._type_ is not None:\n            return False\n\n        if self._second_line is not None:\n            return False\n\n        if self._expiry_date is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        if self._label_user is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the object that is referenced by this object.", "response": "def get_referenced_object(self):\n        \"\"\"\n        :rtype: core.BunqModel\n        :raise: BunqException\n        \"\"\"\n\n        if self._BillingInvoice is not None:\n            return self._BillingInvoice\n\n        if self._DraftPayment is not None:\n            return self._DraftPayment\n\n        if self._MasterCardAction is not None:\n            return self._MasterCardAction\n\n        if self._Payment is not None:\n            return self._Payment\n\n        if self._PaymentBatch is not None:\n            return self._PaymentBatch\n\n        if self._RequestResponse is not None:\n            return self._RequestResponse\n\n        if self._ScheduleInstance is not None:\n            return self._ScheduleInstance\n\n        if self._TabResultResponse is not None:\n            return self._TabResultResponse\n\n        if self._WhitelistResult is not None:\n            return self._WhitelistResult\n\n        raise exception.BunqException(self._ERROR_NULL_FIELDS)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._BillingInvoice is not None:\n            return False\n\n        if self._DraftPayment is not None:\n            return False\n\n        if self._MasterCardAction is not None:\n            return False\n\n        if self._Payment is not None:\n            return False\n\n        if self._PaymentBatch is not None:\n            return False\n\n        if self._RequestResponse is not None:\n            return False\n\n        if self._ScheduleInstance is not None:\n            return False\n\n        if self._TabResultResponse is not None:\n            return False\n\n        if self._WhitelistResult is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_all_field_none(self):\n\n        if self._id_ is not None:\n            return False\n\n        if self._requestResponse is not None:\n            return False\n\n        if self._draftPayment is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_all_field_none(self):\n\n        if self._status is not None:\n            return False\n\n        if self._balance_preferred is not None:\n            return False\n\n        if self._balance_threshold_low is not None:\n            return False\n\n        if self._method_fill is not None:\n            return False\n\n        if self._issuer is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_all_field_none(self):\n\n        if self._status is not None:\n            return False\n\n        if self._balance_preferred is not None:\n            return False\n\n        if self._balance_threshold_high is not None:\n            return False\n\n        if self._savings_account_alias is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._color is not None:\n            return False\n\n        if self._default_avatar_status is not None:\n            return False\n\n        if self._restriction_chat is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if all fields are None.", "response": "def is_all_field_none(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self._target_url is not None:\n            return False\n\n        if self._category is not None:\n            return False\n\n        if self._event_type is not None:\n            return False\n\n        if self._object_ is not None:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_referenced_object(self):\n\n        if self._BunqMeFundraiserResult is not None:\n            return self._BunqMeFundraiserResult\n\n        if self._BunqMeTab is not None:\n            return self._BunqMeTab\n\n        if self._BunqMeTabResultInquiry is not None:\n            return self._BunqMeTabResultInquiry\n\n        if self._BunqMeTabResultResponse is not None:\n            return self._BunqMeTabResultResponse\n\n        if self._ChatMessage is not None:\n            return self._ChatMessage\n\n        if self._DraftPayment is not None:\n            return self._DraftPayment\n\n        if self._IdealMerchantTransaction is not None:\n            return self._IdealMerchantTransaction\n\n        if self._Invoice is not None:\n            return self._Invoice\n\n        if self._MasterCardAction is not None:\n            return self._MasterCardAction\n\n        if self._MonetaryAccount is not None:\n            return self._MonetaryAccount\n\n        if self._Payment is not None:\n            return self._Payment\n\n        if self._PaymentBatch is not None:\n            return self._PaymentBatch\n\n        if self._RequestInquiry is not None:\n            return self._RequestInquiry\n\n        if self._RequestInquiryBatch is not None:\n            return self._RequestInquiryBatch\n\n        if self._RequestResponse is not None:\n            return self._RequestResponse\n\n        if self._ShareInviteBankInquiry is not None:\n            return self._ShareInviteBankInquiry\n\n        if self._ShareInviteBankResponse is not None:\n            return self._ShareInviteBankResponse\n\n        if self._ScheduledPayment is not None:\n            return self._ScheduledPayment\n\n        if self._ScheduledInstance is not None:\n            return self._ScheduledInstance\n\n        if self._TabResultInquiry is not None:\n            return self._TabResultInquiry\n\n        if self._TabResultResponse is not None:\n            return self._TabResultResponse\n\n        if self._User is not None:\n            return self._User\n\n        raise exception.BunqException(self._ERROR_NULL_FIELDS)", "response": "returns a copy of the object with the same attributes as the original object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_all_field_none(self):\n\n        if self._BunqMeFundraiserResult is not None:\n            return False\n\n        if self._BunqMeTab is not None:\n            return False\n\n        if self._BunqMeTabResultInquiry is not None:\n            return False\n\n        if self._BunqMeTabResultResponse is not None:\n            return False\n\n        if self._ChatMessage is not None:\n            return False\n\n        if self._DraftPayment is not None:\n            return False\n\n        if self._IdealMerchantTransaction is not None:\n            return False\n\n        if self._Invoice is not None:\n            return False\n\n        if self._MasterCardAction is not None:\n            return False\n\n        if self._MonetaryAccount is not None:\n            return False\n\n        if self._Payment is not None:\n            return False\n\n        if self._PaymentBatch is not None:\n            return False\n\n        if self._RequestInquiry is not None:\n            return False\n\n        if self._RequestInquiryBatch is not None:\n            return False\n\n        if self._RequestResponse is not None:\n            return False\n\n        if self._ShareInviteBankInquiry is not None:\n            return False\n\n        if self._ShareInviteBankResponse is not None:\n            return False\n\n        if self._ScheduledPayment is not None:\n            return False\n\n        if self._ScheduledInstance is not None:\n            return False\n\n        if self._TabResultInquiry is not None:\n            return False\n\n        if self._TabResultResponse is not None:\n            return False\n\n        if self._User is not None:\n            return False\n\n        return True", "response": "returns True if all fields are None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_all_field_none(self):\n\n        if self._country is not None:\n            return False\n\n        if self._tax_number is not None:\n            return False\n\n        if self._status is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_all_field_none(self):\n\n        if self._name is not None:\n            return False\n\n        if self._date_of_birth is not None:\n            return False\n\n        if self._nationality is not None:\n            return False\n\n        return True", "response": "Returns True if all fields are None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_referenced_object(self):\n\n        if self._UserPerson is not None:\n            return self._UserPerson\n\n        if self._UserCompany is not None:\n            return self._UserCompany\n\n        raise exception.BunqException(self._ERROR_NULL_FIELDS)", "response": "Get the referenced object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new object from a pointer.", "response": "def create_from_pointer(cls, pointer):\n        \"\"\"\n        :type pointer: Pointer\n        \"\"\"\n\n        instance = cls.__new__(cls)\n        instance.pointer = pointer\n        instance.label_monetary_account = LabelMonetaryAccount()\n        instance.label_monetary_account._iban = pointer.value\n        instance.label_monetary_account._display_name = pointer.name\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_from_label_monetary_account(cls, label_monetary_account):\n\n        instance = cls.__new__(cls)\n        instance.label_monetary_account = label_monetary_account\n        instance.pointer = Pointer()\n        instance.pointer._name = label_monetary_account.display_name\n        instance.pointer._type_ = cls._POINTER_TYPE_IBAN\n        instance.pointer._value = label_monetary_account.iban\n\n        return instance", "response": "Create a new object from a label_monetary_account."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize(cls, installation):\n\n        return [\n            {cls._FIELD_ID: converter.serialize(installation.id_)},\n            {cls._FIELD_TOKEN: converter.serialize(installation.token)},\n            {\n                cls._FIELD_SERVER_PUBLIC_KEY: converter.serialize(\n                    installation.server_public_key\n                ),\n            },\n        ]", "response": "Returns a list of the object representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize(cls, session_server):\n\n        return [\n            {cls._FIELD_ID: converter.serialize(session_server.id_)},\n            {cls._FIELD_TOKEN: converter.serialize(session_server.token)},\n            {\n                cls._FIELD_USER_COMPANY:\n                    converter.serialize(session_server.user_company),\n            },\n            {\n                cls._FIELD_USER_PERSON:\n                    converter.serialize(session_server.user_person),\n            },\n            {\n                cls._FIELD_USER_API_KEY:\n                    converter.serialize(session_server.user_api_key),\n            },\n        ]", "response": "Returns a list of all the properties of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deserialize(cls, target_class, obj):\n\n        installation_context = target_class.__new__(target_class)\n        private_key_client = security.rsa_key_from_string(\n            obj[cls._FIELD_PRIVATE_KEY_CLIENT]\n        )\n        public_key_client = security.rsa_key_from_string(\n            obj[cls._FIELD_PUBLIC_KEY_CLIENT]\n        )\n        public_key_server = security.rsa_key_from_string(\n            obj[cls._FIELD_PUBLIC_KEY_SERVER]\n        )\n        installation_context.__dict__ = {\n            cls._ATTRIBUTE_TOKEN: obj[cls._FIELD_TOKEN],\n            cls._ATTRIBUTE_PRIVATE_KEY_CLIENT: private_key_client,\n            cls._ATTRIBUTE_PUBLIC_KEY_CLIENT: public_key_client,\n            cls._ATTRIBUTE_PUBLIC_KEY_SERVER: public_key_server,\n        }\n\n        return installation_context", "response": "Deserialize a dictionary into a new object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing the object to a dictionary.", "response": "def serialize(cls, installation_context):\n        \"\"\"\n        :type installation_context: context.InstallationContext\n\n        :rtype: dict\n        \"\"\"\n\n        return {\n            cls._FIELD_TOKEN: installation_context.token,\n            cls._FIELD_PUBLIC_KEY_CLIENT: security.public_key_to_string(\n                installation_context.private_key_client.publickey()\n            ),\n            cls._FIELD_PRIVATE_KEY_CLIENT: security.private_key_to_string(\n                installation_context.private_key_client\n            ),\n            cls._FIELD_PUBLIC_KEY_SERVER: security.public_key_to_string(\n                installation_context.public_key_server\n            ),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nserialize the given geolocation into a dictionary.", "response": "def serialize(cls, geolocation):\n        \"\"\"\n        :type geolocation: object_.Geolocation\n\n        :rtype: dict\n        \"\"\"\n\n        obj = {}\n\n        cls.add_if_not_none(obj, cls._FIELD_LATITUDE, geolocation.latitude)\n        cls.add_if_not_none(obj, cls._FIELD_LONGITUDE, geolocation.longitude)\n        cls.add_if_not_none(obj, cls._FIELD_ALTITUDE, geolocation.altitude)\n        cls.add_if_not_none(obj, cls._FIELD_RADIUS, geolocation.radius)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_if_not_none(cls, dict_, key, value):\n\n        if value is not None:\n            dict_[key] = str(value)", "response": "Adds a value to the dict_ if key is not None."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deserialize(cls, target_class, obj):\n\n        label_monetary_account = converter.deserialize(\n            object_.LabelMonetaryAccount,\n            obj\n        )\n\n        return target_class.create_from_label_monetary_account(\n            label_monetary_account\n        )", "response": "Deserialize a object into a target_class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize(cls, share_detail):\n\n        return {\n            cls._FIELD_PAYMENT: converter.serialize(\n                share_detail._payment_field_for_request),\n            cls._FIELD_READ_ONLY: converter.serialize(\n                share_detail._read_only_field_for_request),\n            cls._FIELD_DRAFT_PAYMENT: converter.serialize(\n                share_detail._draft_payment\n            ),\n        }", "response": "Serializes the object into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deserialize(cls, target_class, pagination_response):\n\n        pagination = client.Pagination()\n        pagination.__dict__.update(\n            cls.parse_pagination_dict(pagination_response)\n        )\n\n        return pagination", "response": "Deserialize a pagination response into a new object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_pagination_dict(cls, response_obj):\n\n        pagination_dict = {}\n\n        cls.update_dict_id_field_from_response_field(\n            pagination_dict,\n            cls._FIELD_OLDER_ID,\n            response_obj,\n            cls._FIELD_OLDER_URL,\n            client.Pagination.PARAM_OLDER_ID\n        )\n        cls.update_dict_id_field_from_response_field(\n            pagination_dict,\n            cls._FIELD_NEWER_ID,\n            response_obj,\n            cls._FIELD_NEWER_URL,\n            client.Pagination.PARAM_NEWER_ID\n        )\n        cls.update_dict_id_field_from_response_field(\n            pagination_dict,\n            cls._FIELD_FUTURE_ID,\n            response_obj,\n            cls._FIELD_FUTURE_URL,\n            client.Pagination.PARAM_NEWER_ID\n        )\n\n        return pagination_dict", "response": "Parses the response object to get the pagination dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the dict_id_field of the object with the value of the response_field.", "response": "def update_dict_id_field_from_response_field(cls, dict_, dict_id_field,\n                                                 response_obj, response_field,\n                                                 response_param):\n        \"\"\"\n        :type dict_: dict\n        :type dict_id_field: str\n        :type response_obj: dict\n        :type response_field: str\n        :type response_param: str\n        \"\"\"\n\n        url = response_obj[response_field]\n\n        if url is not None:\n            url_parsed = urlparse.urlparse(url)\n            parameters = urlparse.parse_qs(url_parsed.query)\n            dict_[dict_id_field] = int(\n                parameters[response_param][cls._INDEX_FIRST]\n            )\n\n            if cls._FIELD_COUNT in parameters and cls._FIELD_COUNT not in dict_:\n                dict_[cls._FIELD_COUNT] = int(\n                    parameters[client.Pagination.PARAM_COUNT][cls._INDEX_FIRST]\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _initialize(self, device_description, permitted_ips):\n\n        self._initialize_installation()\n        self._register_device(device_description, permitted_ips)\n        self._initialize_session()", "response": "Initialize the nac setuptools and session."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _initialize_installation(self):\n\n        private_key_client = security.generate_rsa_private_key()\n        installation = core.Installation.create(\n            self,\n            security.public_key_to_string(private_key_client.publickey())\n        ).value\n        token = installation.token.token\n        public_key_server_string = \\\n            installation.server_public_key.server_public_key\n        public_key_server = RSA.import_key(public_key_server_string)\n\n        self._installation_context = InstallationContext(\n            token,\n            private_key_client,\n            public_key_server\n        )", "response": "Initializes the _installation_context attribute."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a new device with the API key.", "response": "def _register_device(self, device_description,\n                         permitted_ips):\n        \"\"\"\n        :type device_description: str\n        :type permitted_ips: list[]\n\n        :rtype: None\n        \"\"\"\n\n        from bunq.sdk.model.device_server_internal import DeviceServerInternal\n\n        DeviceServerInternal.create(\n            device_description,\n            self.api_key,\n            permitted_ips,\n            api_context=self\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _initialize_session(self):\n\n        session_server = core.SessionServer.create(self).value\n        token = session_server.token.token\n        expiry_time = self._get_expiry_timestamp(session_server)\n        user_id = session_server.get_referenced_user().id_\n\n        self._session_context = SessionContext(token, expiry_time, user_id)", "response": "Initializes the session with the current token and expiry time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_expiry_timestamp(cls, session_server):\n\n        timeout_seconds = cls._get_session_timeout_seconds(session_server)\n        time_now = datetime.datetime.now()\n\n        return time_now + datetime.timedelta(seconds=timeout_seconds)", "response": "Returns the expiry timestamp of the session server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_session_timeout_seconds(cls, session_server):\n\n        if session_server.user_company is not None:\n            return session_server.user_company.session_timeout\n        elif session_server.user_person is not None:\n            return session_server.user_person.session_timeout\n        elif session_server.user_api_key is not None:\n            return session_server \\\n                .user_api_key \\\n                .requested_by_user \\\n                .get_referenced_object() \\\n                .session_timeout\n        else:\n            raise BunqException()", "response": "Returns the number of seconds that the user has requested the session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the session is active.", "response": "def is_session_active(self):\n        \"\"\"\n        :rtype: bool\n        \"\"\"\n\n        if self.session_context is None:\n            return False\n\n        time_now = datetime.datetime.now()\n        time_to_expiry = self.session_context.expiry_time - time_now\n        time_to_expiry_minimum = datetime.timedelta(\n            seconds=self._TIME_TO_SESSION_EXPIRY_MINIMUM_SECONDS\n        )\n\n        return time_to_expiry > time_to_expiry_minimum"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef token(self):\n\n        if self._session_context is not None:\n            return self.session_context.token\n        elif self._installation_context is not None:\n            return self.installation_context.token\n        else:\n            return None", "response": "Returns the token of the current session or installation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the current object to a file.", "response": "def save(self, path=None):\n        \"\"\"\n        :type path: str\n\n        :rtype: None\n        \"\"\"\n\n        if path is None:\n            path = self._PATH_API_CONTEXT_DEFAULT\n\n        with open(path, self._FILE_MODE_WRITE) as file_:\n            file_.write(self.to_json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrestores the current object from the given path.", "response": "def restore(cls, path=None):\n        \"\"\"\n        :type path: str\n\n        :rtype: ApiContext\n        \"\"\"\n\n        if path is None:\n            path = cls._PATH_API_CONTEXT_DEFAULT\n\n        with open(path, cls._FILE_MODE_READ) as file_:\n            return cls.from_json(file_.read())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the ApiContext and UserContext objects from the given ApiContext.", "response": "def load_api_context(cls, api_context):\n        \"\"\"\n        :type api_context: ApiContext\n        \"\"\"\n\n        cls._api_context = api_context\n        cls._user_context = UserContext(api_context.session_context.user_id)\n        cls._user_context.init_main_monetary_account()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initialize_converter():\n\n    import datetime\n    import inspect\n\n    from bunq.sdk import client\n    from bunq.sdk import context\n    from bunq.sdk.model import core\n    from bunq.sdk.json import adapters\n    from bunq.sdk.json import converter\n    from bunq.sdk.model.generated import object_\n    from bunq.sdk.model.generated import endpoint\n\n    converter.register_adapter(core.Installation, adapters.InstallationAdapter)\n    converter.register_adapter(\n        core.SessionServer,\n        adapters.SessionServerAdapter\n    )\n    converter.register_adapter(\n        context.InstallationContext,\n        adapters.InstallationContextAdapter\n    )\n    converter.register_adapter(\n        context.ApiEnvironmentType,\n        adapters.ApiEnvironmentTypeAdapter\n    )\n    converter.register_adapter(float, adapters.FloatAdapter)\n    converter.register_adapter(object_.Geolocation, adapters.GeolocationAdapter)\n    converter.register_adapter(\n        object_.MonetaryAccountReference,\n        adapters.MonetaryAccountReferenceAdapter\n    )\n    converter.register_adapter(object_.ShareDetail, adapters.ShareDetailAdapter)\n    converter.register_adapter(datetime.datetime, adapters.DateTimeAdapter)\n    converter.register_adapter(client.Pagination, adapters.PaginationAdapter)\n\n    def register_anchor_adapter(class_to_regsiter):\n        if issubclass(class_to_regsiter, core.AnchoredObjectInterface):\n            converter.register_adapter(\n                class_to_regsiter,\n                adapters.AnchoredObjectModelAdapter\n            )\n\n    def get_class(class_string_to_get):\n        if hasattr(object_, class_string_to_get):\n            return getattr(object_, class_string_to_get)\n\n        if hasattr(endpoint, class_string_to_get):\n            return getattr(endpoint, class_string_to_get)\n\n    for class_string in list(dir(object_) + dir(endpoint)):\n        class_ = get_class(class_string)\n\n        if not inspect.isclass(class_):\n            continue\n\n        register_anchor_adapter(class_)", "response": "Initialize the internal object converter."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a base64 - encoded signature for a request.", "response": "def sign_request(private_key, method, endpoint, body_bytes, headers):\n    \"\"\"\n    :type private_key: RSA.RsaKey\n    :type method: str\n    :type endpoint: str\n    :type body_bytes: bytes\n    :type headers: dict[str, str]\n\n    :rtype: str\n    \"\"\"\n\n    head_bytes = _generate_request_head_bytes(method, endpoint, headers)\n    bytes_to_sign = head_bytes + body_bytes\n    signer = PKCS1_v1_5.new(private_key)\n    digest = SHA256.new()\n    digest.update(bytes_to_sign)\n    sign = signer.sign(digest)\n\n    return b64encode(sign)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _generate_request_head_bytes(method, endpoint, headers):\n\n    head_string = _FORMAT_METHOD_AND_ENDPOINT.format(method, endpoint)\n    header_tuples = sorted((k, headers[k]) for k in headers)\n\n    for name, value in header_tuples:\n        if _should_sign_request_header(name):\n            head_string += _FORMAT_HEADER_STRING.format(name, value)\n\n    return (head_string + _DELIMITER_NEWLINE).encode()", "response": "Generate the request head bytes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _should_sign_request_header(header_name):\n\n    if header_name in {_HEADER_USER_AGENT, _HEADER_CACHE_CONTROL}:\n        return True\n\n    if re.match(_PATTERN_HEADER_PREFIX_BUNQ, header_name):\n        return True\n\n    return False", "response": "Returns True if the header should be signed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nencrypt a request with the given key and IV.", "response": "def encrypt(api_context, request_bytes, custom_headers):\n    \"\"\"\n    :type api_context: bunq.sdk.context.ApiContext\n    :type request_bytes: bytes\n    :type custom_headers: dict[str, str]\n\n    :rtype: bytes\n    \"\"\"\n\n    key = Random.get_random_bytes(_AES_KEY_SIZE)\n    iv = Random.get_random_bytes(_BLOCK_SIZE)\n    _add_header_client_encryption_key(api_context, key, custom_headers)\n    _add_header_client_encryption_iv(iv, custom_headers)\n    request_bytes = _encrypt_request_bytes(request_bytes, key, iv)\n    _add_header_client_encryption_hmac(request_bytes, key, iv, custom_headers)\n\n    return request_bytes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_header_client_encryption_key(api_context, key, custom_headers):\n\n    public_key_server = api_context.installation_context.public_key_server\n    key_cipher = PKCS1_v1_5_Cipher.new(public_key_server)\n    key_encrypted = key_cipher.encrypt(key)\n    key_encrypted_base64 = base64.b64encode(key_encrypted).decode()\n    custom_headers[_HEADER_CLIENT_ENCRYPTION_KEY] = key_encrypted_base64", "response": "Add the client encryption key to the custom headers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _encrypt_request_bytes(request_bytes, key, iv):\n\n    cipher = Cipher.AES.new(key, Cipher.AES.MODE_CBC, iv)\n    request_bytes_padded = _pad_bytes(request_bytes)\n\n    return cipher.encrypt(request_bytes_padded)", "response": "encrypt request_bytes with key and iv"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npads the given bytes into a block of _BLOCK_SIZE.", "response": "def _pad_bytes(request_bytes):\n    \"\"\"\n    :type request_bytes: bytes\n\n    :rtype: bytes\n    \"\"\"\n\n    padding_length = (_BLOCK_SIZE - len(request_bytes) % _BLOCK_SIZE)\n    padding_character = bytes(bytearray([padding_length]))\n\n    return request_bytes + padding_character * padding_length"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the HMAC - SHA1 header to the custom headers dict.", "response": "def _add_header_client_encryption_hmac(request_bytes, key, iv, custom_headers):\n    \"\"\"\n    :type request_bytes: bytes\n    :type key: bytes\n    :type iv: bytes\n    :type custom_headers: dict[str, str]\n\n    :rtype: None\n    \"\"\"\n\n    hashed = hmac.new(key, iv + request_bytes, sha1)\n    hashed_base64 = base64.b64encode(hashed.digest()).decode()\n    custom_headers[_HEADER_CLIENT_ENCRYPTION_HMAC] = hashed_base64"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generate_response_head_bytes(status_code, headers):\n\n    head_string = str(status_code) + _DELIMITER_NEWLINE\n    header_tuples = sorted((k, headers[k]) for k in headers)\n\n    for name, value in header_tuples:\n        name = _get_header_correctly_cased(name)\n\n        if _should_sign_response_header(name):\n            head_string += _FORMAT_HEADER_STRING.format(name, value)\n\n    return (head_string + _DELIMITER_NEWLINE).encode()", "response": "Generate the response head bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the header name in case it is correctly cased.", "response": "def _get_header_correctly_cased(header_name):\n    \"\"\"\n    :type header_name: str\n    :rtype:  str\n    \"\"\"\n\n    header_name = header_name.capitalize()\n\n    matches = re.findall(_REGEX_FOR_LOWERCASE_HEADERS, header_name)\n\n    for match in matches:\n        header_name = (re.sub(match, match.upper(), header_name))\n\n    return header_name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _should_sign_response_header(header_name):\n\n    if header_name == _HEADER_SERVER_SIGNATURE:\n        return False\n\n    if re.match(_PATTERN_HEADER_PREFIX_BUNQ, header_name):\n        return True\n\n    return False", "response": "Returns True if the header_name should be signed by the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __generate_new_sandbox_user():\n\n    url = ApiEnvironmentType.SANDBOX.uri_base + __ENDPOINT_SANDBOX_USER\n\n    headers = {\n        ApiClient.HEADER_REQUEST_ID: __UNIQUE_REQUEST_ID,\n        ApiClient.HEADER_CACHE_CONTROL: ApiClient._CACHE_CONTROL_NONE,\n        ApiClient.HEADER_GEOLOCATION: ApiClient._GEOLOCATION_ZERO,\n        ApiClient.HEADER_LANGUAGE: ApiClient._LANGUAGE_EN_US,\n        ApiClient.HEADER_REGION: ApiClient._REGION_NL_NL,\n    }\n\n    response = requests.request(ApiClient._METHOD_POST, url, headers=headers)\n\n    if response.status_code is ApiClient._STATUS_CODE_OK:\n        response_json = json.loads(response.text)\n        return endpoint.SandboxUser.from_json(\n            json.dumps(response_json[__FIELD_RESPONSE][__INDEX_FIRST][\n                           __FIELD_API_KEY]))\n\n    raise BunqException(_ERROR_COULD_NOT_CREATE_NEW_SANDBOX_USER)", "response": "Method to generate a new SANDBOX user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _from_json_array_nested(cls, response_raw):\n\n        json = response_raw.body_bytes.decode()\n        obj = converter.json_to_class(dict, json)\n        value = converter.deserialize(cls, obj[cls._FIELD_RESPONSE])\n\n        return client.BunqResponse(value, response_raw.headers)", "response": "Converts a JSON array to a BunqResponse object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _from_json(cls, response_raw, wrapper=None):\n\n        json = response_raw.body_bytes.decode()\n        obj = converter.json_to_class(dict, json)\n        value = converter.deserialize(\n            cls,\n            cls._unwrap_response_single(obj, wrapper)\n        )\n\n        return client.BunqResponse(value, response_raw.headers)", "response": "Convert the response from the JSON format to the appropriate class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nunwrap the response dict.", "response": "def _unwrap_response_single(cls, obj, wrapper=None):\n        \"\"\"\n        :type obj: dict\n        :type wrapper: str|None\n\n        :rtype: dict\n        \"\"\"\n\n        if wrapper is not None:\n            return obj[cls._FIELD_RESPONSE][cls._INDEX_FIRST][wrapper]\n\n        return obj[cls._FIELD_RESPONSE][cls._INDEX_FIRST]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_for_id(cls, response_raw):\n\n        json = response_raw.body_bytes.decode()\n        obj = converter.json_to_class(dict, json)\n        id_ = converter.deserialize(\n            Id,\n            cls._unwrap_response_single(obj, cls._FIELD_ID)\n        )\n\n        return client.BunqResponse(id_.id_, response_raw.headers)", "response": "Processes a response for a resource ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process_for_uuid(cls, response_raw):\n\n        json = response_raw.body_bytes.decode()\n        obj = converter.json_to_class(dict, json)\n        uuid = converter.deserialize(\n            Uuid,\n            cls._unwrap_response_single(obj, cls._FIELD_UUID)\n        )\n\n        return client.BunqResponse(uuid.uuid, response_raw.headers)", "response": "Processes a response for a UUID request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _determine_monetary_account_id(cls, monetary_account_id=None):\n\n        if monetary_account_id is None:\n            return context.BunqContext.user_context().primary_monetary_account.id_\n\n        return monetary_account_id", "response": "Helper method to determine the monetary account ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_referenced_user(self):\n\n        if self._user_person is not None:\n            return self._user_person\n\n        if self._user_company is not None:\n            return self._user_company\n\n        if self._user_api_key is not None:\n            return self._user_api_key\n\n        raise BunqException(self._ERROR_ALL_FIELD_IS_NULL)", "response": "Get the referenced user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef icon_resource(name, package=None):\n    if not package:\n        package = '%s.resources.images' % calling_package()\n    name = resource_filename(package, name)\n    if not name.startswith('/'):\n        return 'file://%s' % abspath(name)\n    return 'file://%s' % name", "response": "Returns the absolute URI path to an image resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef image_resources(package=None, directory='resources'):\n    if not package:\n        package = calling_package()\n    package_dir = '.'.join([package, directory])\n    images = []\n    for i in resource_listdir(package, directory):\n        if i.startswith('__') or i.endswith('.egg-info'):\n            continue\n        fname = resource_filename(package_dir, i)\n        if resource_isdir(package_dir, i):\n            images.extend(image_resources(package_dir, i))\n        elif what(fname):\n            images.append(fname)\n    return images", "response": "Returns all images under the specified directory relative to a package path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef console_writer(msg, tab=-1):\n    tab += 1\n\n    if isinstance(msg, Model):\n        msg = fromstring(msg.render(encoding='utf-8'))\n\n    print('%s`- %s: %s %s' % (\n        '  ' * tab,\n        click.style(msg.tag, bold=True),\n        click.style(msg.text, fg='red') if msg.text is not None else '',\n        click.style(repr(msg.attrib), fg='green', bold=True) if msg.attrib.keys() else ''\n    ))\n    for c in msg.getchildren():\n        print('  %s`- %s: %s %s' % (\n            '  ' * tab,\n            click.style(c.tag, bold=True),\n            click.style(c.text, fg='red') if c.text is not None else '',\n            click.style(repr(c.attrib), fg='green', bold=True) if c.attrib.keys() else ''\n        ))\n        for sc in c.getchildren():\n            tab += 1\n            console_writer(sc, tab)\n            tab -= 1", "response": "Internal API that returns a prettified tree - based output of an XML message for debugging purposes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays a msgbox with choices of Yes and No.", "response": "def ynbox(msg=\"Shall I continue?\"\n    , title=\" \"\n    , choices=(\"Yes\", \"No\")\n    , image=None\n    ):\n    \"\"\"\n    Display a msgbox with choices of Yes and No.\n\n    The default is \"Yes\".\n\n    The returned value is calculated this way::\n        if the first choice (\"Yes\") is chosen, or if the dialog is cancelled:\n            return 1\n        else:\n            return 0\n\n    If invoked without a msg argument, displays a generic request for a confirmation\n    that the user wishes to continue.  So it can be used this way::\n        if ynbox(): pass # continue\n        else: sys.exit(0)  # exit the program\n\n    @arg msg: the msg to be displayed.\n    @arg title: the window title\n    @arg choices: a list or tuple of the choices to be displayed\n    \"\"\"\n    return boolbox(msg, title, choices, image=image)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays a msgbox with choices of Continue and Cancel.", "response": "def ccbox(msg=\"Shall I continue?\"\n    , title=\" \"\n    , choices=(\"Continue\", \"Cancel\")\n    , image=None\n    ):\n    \"\"\"\n    Display a msgbox with choices of Continue and Cancel.\n\n    The default is \"Continue\".\n\n    The returned value is calculated this way::\n        if the first choice (\"Continue\") is chosen, or if the dialog is cancelled:\n            return 1\n        else:\n            return 0\n\n    If invoked without a msg argument, displays a generic request for a confirmation\n    that the user wishes to continue.  So it can be used this way::\n\n        if ccbox():\n            pass # continue\n        else:\n            sys.exit(0)  # exit the program\n\n    @arg msg: the msg to be displayed.\n    @arg title: the window title\n    @arg choices: a list or tuple of the choices to be displayed\n    \"\"\"\n    return boolbox(msg, title, choices, image=image)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef boolbox(msg=\"Shall I continue?\"\n    , title=\" \"\n    , choices=(\"Yes\",\"No\")\n    , image=None\n    ):\n    \"\"\"\n    Display a boolean msgbox.\n\n    The default is the first choice.\n\n    The returned value is calculated this way::\n        if the first choice is chosen, or if the dialog is cancelled:\n            returns 1\n        else:\n            returns 0\n    \"\"\"\n    reply = buttonbox(msg=msg, choices=choices, title=title, image=image)\n    if reply == choices[0]: return 1\n    else: return 0", "response": "Display a boolean msgbox."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying a buttonbox with the specified choices.", "response": "def indexbox(msg=\"Shall I continue?\"\n    , title=\" \"\n    , choices=(\"Yes\",\"No\")\n    , image=None\n    ):\n    \"\"\"\n    Display a buttonbox with the specified choices.\n    Return the index of the choice selected.\n    \"\"\"\n    reply = buttonbox(msg=msg, choices=choices, title=title, image=image)\n    index = -1\n    for choice in choices:\n        index = index + 1\n        if reply == choice: return index\n    raise AssertionError(\n        \"There is a program logic error in the EasyGui code for indexbox.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying a message a title and a set of buttons.", "response": "def buttonbox(msg=\"\",title=\" \"\n    ,choices=(\"Button1\", \"Button2\", \"Button3\")\n    , image=None\n    , root=None\n    ):\n    \"\"\"\n    Display a msg, a title, and a set of buttons.\n    The buttons are defined by the members of the choices list.\n    Return the text of the button that the user selected.\n\n    @arg msg: the msg to be displayed.\n    @arg title: the window title\n    @arg choices: a list or tuple of the choices to be displayed\n    \"\"\"\n    if sys.platform == 'darwin':\n        _bring_to_front()\n\n    global boxRoot, __replyButtonText, __widgetTexts, buttonsFrame\n\n\n    # Initialize __replyButtonText to the first choice.\n    # This is what will be used if the window is closed by the close button.\n    __replyButtonText = choices[0]\n\n    if root:\n        root.withdraw()\n        boxRoot = Toplevel(master=root)\n        boxRoot.withdraw()\n    else:\n        boxRoot = Tk()\n        boxRoot.withdraw()\n\n    boxRoot.protocol('WM_DELETE_WINDOW', denyWindowManagerClose )\n    boxRoot.title(title)\n    boxRoot.iconname('Dialog')\n    boxRoot.geometry(rootWindowPosition)\n    boxRoot.minsize(400, 100)\n\n    # ------------- define the messageFrame ---------------------------------\n    messageFrame = Frame(master=boxRoot)\n    messageFrame.pack(side=TOP, fill=BOTH)\n\n    # ------------- define the imageFrame ---------------------------------\n    tk_Image = None\n    if image:\n        imageFilename = os.path.normpath(image)\n        junk,ext = os.path.splitext(imageFilename)\n\n        if os.path.exists(imageFilename):\n            if ext.lower() in [\".gif\", \".pgm\", \".ppm\"]:\n                tk_Image = PhotoImage(master=boxRoot, file=imageFilename)\n            else:\n                if PILisLoaded:\n                    try:\n                        pil_Image = PILImage.open(imageFilename)\n                        tk_Image = PILImageTk.PhotoImage(pil_Image, master=boxRoot)\n                    except:\n                        msg += ImageErrorMsg % (imageFilename,\n                            \"\\nThe Python Imaging Library (PIL) could not convert this file to a displayable image.\"\n                            \"\\n\\nPIL reports:\\n\" + exception_format())\n\n                else:  # PIL is not loaded\n                    msg += ImageErrorMsg % (imageFilename,\n                    \"\\nI could not import the Python Imaging Library (PIL) to display the image.\\n\\n\"\n                    \"You may need to install PIL\\n\"\n                    \"(http://www.pythonware.com/products/pil/)\\n\"\n                    \"to display \" + ext + \" image files.\")\n\n        else:\n            msg += ImageErrorMsg % (imageFilename, \"\\nImage file not found.\")\n\n    if tk_Image:\n        imageFrame = Frame(master=boxRoot)\n        imageFrame.pack(side=TOP, fill=BOTH)\n        label = Label(imageFrame,image=tk_Image)\n        label.image = tk_Image # keep a reference!\n        label.pack(side=TOP, expand=YES, fill=X, padx='1m', pady='1m')\n\n    # ------------- define the buttonsFrame ---------------------------------\n    buttonsFrame = Frame(master=boxRoot)\n    buttonsFrame.pack(side=TOP, fill=BOTH)\n\n    # -------------------- place the widgets in the frames -----------------------\n    messageWidget = Message(messageFrame, text=msg, width=400)\n    messageWidget.configure(font=(PROPORTIONAL_FONT_FAMILY,PROPORTIONAL_FONT_SIZE))\n    messageWidget.pack(side=TOP, expand=YES, fill=X, padx='3m', pady='3m')\n\n    __put_buttons_in_buttonframe(choices)\n\n    # -------------- the action begins -----------\n    # put the focus on the first button\n    __firstWidget.focus_force()\n\n    boxRoot.deiconify()\n    boxRoot.mainloop()\n    boxRoot.destroy()\n    if root: root.deiconify()\n    return __replyButtonText"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef integerbox(msg=\"\"\n    , title=\" \"\n    , default=\"\"\n    , lowerbound=0\n    , upperbound=99\n    , image = None\n    , root  = None\n    , **invalidKeywordArguments\n    ):\n    \"\"\"\n    Show a box in which a user can enter an integer.\n\n    In addition to arguments for msg and title, this function accepts\n    integer arguments for \"default\", \"lowerbound\", and \"upperbound\".\n\n    The default argument may be None.\n\n    When the user enters some text, the text is checked to verify that it\n    can be converted to an integer between the lowerbound and upperbound.\n\n    If it can be, the integer (not the text) is returned.\n\n    If it cannot, then an error msg is displayed, and the integerbox is\n    redisplayed.\n\n    If the user cancels the operation, None is returned.\n\n    NOTE that the \"argLowerBound\" and \"argUpperBound\" arguments are no longer\n    supported.  They have been replaced by \"upperbound\" and \"lowerbound\".\n    \"\"\"\n    if sys.platform == 'darwin':\n        _bring_to_front()\n    if \"argLowerBound\" in invalidKeywordArguments:\n        raise AssertionError(\n            \"\\nintegerbox no longer supports the 'argLowerBound' argument.\\n\"\n            + \"Use 'lowerbound' instead.\\n\\n\")\n    if \"argUpperBound\" in invalidKeywordArguments:\n        raise AssertionError(\n            \"\\nintegerbox no longer supports the 'argUpperBound' argument.\\n\"\n            + \"Use 'upperbound' instead.\\n\\n\")\n\n    if default != \"\":\n        if type(default) != type(1):\n            raise AssertionError(\n                \"integerbox received a non-integer value for \"\n                + \"default of \" + dq(str(default)) , \"Error\")\n\n    if type(lowerbound) != type(1):\n        raise AssertionError(\n            \"integerbox received a non-integer value for \"\n            + \"lowerbound of \" + dq(str(lowerbound)) , \"Error\")\n\n    if type(upperbound) != type(1):\n        raise AssertionError(\n            \"integerbox received a non-integer value for \"\n            + \"upperbound of \" + dq(str(upperbound)) , \"Error\")\n\n    if msg == \"\":\n        msg = (\"Enter an integer between \" + str(lowerbound)\n            + \" and \"\n            + str(upperbound)\n            )\n\n    while 1:\n        reply = enterbox(msg, title, str(default), image=image, root=root)\n        if reply is None:\n            return None\n\n        try:\n            reply = int(reply)\n        except:\n            msgbox (\"The value that you entered:\\n\\t%s\\nis not an integer.\" % dq(str(reply))\n                    , \"Error\")\n            continue\n\n        if reply < lowerbound:\n            msgbox (\"The value that you entered is less than the lower bound of \"\n                + str(lowerbound) + \".\", \"Error\")\n            continue\n\n        if reply > upperbound:\n            msgbox (\"The value that you entered is greater than the upper bound of \"\n                + str(upperbound) + \".\", \"Error\")\n            continue\n\n        # reply has passed all validation checks.\n        # It is an integer between the specified bounds.\n        return reply", "response": "Return a new integerbox in the language of the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef multpasswordbox(msg=\"Fill in values for the fields.\"\n    , title=\" \"\n    , fields=tuple()\n    ,values=tuple()\n    ):\n    r\"\"\"\n    Same interface as multenterbox.  But in multpassword box,\n    the last of the fields is assumed to be a password, and\n    is masked with asterisks.\n\n    Example\n    =======\n\n    Here is some example code, that shows how values returned from\n    multpasswordbox can be checked for validity before they are accepted::\n        msg = \"Enter logon information\"\n        title = \"Demo of multpasswordbox\"\n        fieldNames = [\"Server ID\", \"User ID\", \"Password\"]\n        fieldValues = []  # we start with blanks for the values\n        fieldValues = multpasswordbox(msg,title, fieldNames)\n\n        # make sure that none of the fields was left blank\n        while 1:\n            if fieldValues == None: break\n            errmsg = \"\"\n            for i in range(len(fieldNames)):\n                if fieldValues[i].strip() == \"\":\n                    errmsg = errmsg + ('\"%s\" is a required field.\\n\\n' % fieldNames[i])\n                if errmsg == \"\": break # no problems found\n            fieldValues = multpasswordbox(errmsg, title, fieldNames, fieldValues)\n\n        writeln(\"Reply was: %s\" % str(fieldValues))\n    \"\"\"\n    return __multfillablebox(msg,title,fields,values,\"*\")", "response": "r Fill in values for the fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows a box in which a user can enter some text.", "response": "def enterbox(msg=\"Enter something.\"\n    , title=\" \"\n    , default=\"\"\n    , strip=True\n    , image=None\n    , root=None\n    ):\n    \"\"\"\n    Show a box in which a user can enter some text.\n\n    You may optionally specify some default text, which will appear in the\n    enterbox when it is displayed.\n\n    Returns the text that the user entered, or None if he cancels the operation.\n\n    By default, enterbox strips its result (i.e. removes leading and trailing\n    whitespace).  (If you want it not to strip, use keyword argument: strip=False.)\n    This makes it easier to test the results of the call::\n\n        reply = enterbox(....)\n        if reply:\n            ...\n        else:\n            ...\n    \"\"\"\n    result = __fillablebox(msg, title, default=default, mask=None,image=image,root=root)\n    if result and strip:\n        result = result.strip()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay a box in which a user can enter a password.", "response": "def passwordbox(msg=\"Enter your password.\"\n    , title=\" \"\n    , default=\"\"\n    , image=None\n    , root=None\n    ):\n    \"\"\"\n    Show a box in which a user can enter a password.\n    The text is masked with asterisks, so the password is not displayed.\n    Returns the text that the user entered, or None if he cancels the operation.\n    \"\"\"\n    return __fillablebox(msg, title, default, mask=\"*\",image=image,root=root)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __fillablebox(msg\n    , title=\"\"\n    , default=\"\"\n    , mask=None\n    , image=None\n    , root=None\n    ):\n    \"\"\"\n    Show a box in which a user can enter some text.\n    You may optionally specify some default text, which will appear in the\n    enterbox when it is displayed.\n    Returns the text that the user entered, or None if he cancels the operation.\n    \"\"\"\n    if sys.platform == 'darwin':\n        _bring_to_front()\n    global boxRoot, __enterboxText, __enterboxDefaultText\n    global cancelButton, entryWidget, okButton\n\n    if title is None:\n        title = \"\"\n    if default is None:\n        default = \"\"\n    __enterboxDefaultText = default\n    __enterboxText        = __enterboxDefaultText\n\n    if root:\n        root.withdraw()\n        boxRoot = Toplevel(master=root)\n        boxRoot.withdraw()\n    else:\n        boxRoot = Tk()\n        boxRoot.withdraw()\n\n    boxRoot.protocol('WM_DELETE_WINDOW', denyWindowManagerClose )\n    boxRoot.title(title)\n    boxRoot.iconname('Dialog')\n    boxRoot.geometry(rootWindowPosition)\n    boxRoot.bind(\"<Escape>\", __enterboxCancel)\n\n    # ------------- define the messageFrame ---------------------------------\n    messageFrame = Frame(master=boxRoot)\n    messageFrame.pack(side=TOP, fill=BOTH)\n\n    # ------------- define the imageFrame ---------------------------------\n    tk_Image = None\n    if image:\n        imageFilename = os.path.normpath(image)\n        junk,ext = os.path.splitext(imageFilename)\n\n        if os.path.exists(imageFilename):\n            if ext.lower() in [\".gif\", \".pgm\", \".ppm\"]:\n                tk_Image = PhotoImage(master=boxRoot, file=imageFilename)\n            else:\n                if PILisLoaded:\n                    try:\n                        pil_Image = PILImage.open(imageFilename)\n                        tk_Image = PILImageTk.PhotoImage(pil_Image, master=boxRoot)\n                    except:\n                        msg += ImageErrorMsg % (imageFilename,\n                            \"\\nThe Python Imaging Library (PIL) could not convert this file to a displayable image.\"\n                            \"\\n\\nPIL reports:\\n\" + exception_format())\n\n                else:  # PIL is not loaded\n                    msg += ImageErrorMsg % (imageFilename,\n                    \"\\nI could not import the Python Imaging Library (PIL) to display the image.\\n\\n\"\n                    \"You may need to install PIL\\n\"\n                    \"(http://www.pythonware.com/products/pil/)\\n\"\n                    \"to display \" + ext + \" image files.\")\n\n        else:\n            msg += ImageErrorMsg % (imageFilename, \"\\nImage file not found.\")\n\n    if tk_Image:\n        imageFrame = Frame(master=boxRoot)\n        imageFrame.pack(side=TOP, fill=BOTH)\n        label = Label(imageFrame,image=tk_Image)\n        label.image = tk_Image # keep a reference!\n        label.pack(side=TOP, expand=YES, fill=X, padx='1m', pady='1m')\n\n    # ------------- define the buttonsFrame ---------------------------------\n    buttonsFrame = Frame(master=boxRoot)\n    buttonsFrame.pack(side=TOP, fill=BOTH)\n\n\n    # ------------- define the entryFrame ---------------------------------\n    entryFrame = Frame(master=boxRoot)\n    entryFrame.pack(side=TOP, fill=BOTH)\n\n    # ------------- define the buttonsFrame ---------------------------------\n    buttonsFrame = Frame(master=boxRoot)\n    buttonsFrame.pack(side=TOP, fill=BOTH)\n\n    #-------------------- the msg widget ----------------------------\n    messageWidget = Message(messageFrame, width=\"4.5i\", text=msg)\n    messageWidget.configure(font=(PROPORTIONAL_FONT_FAMILY,PROPORTIONAL_FONT_SIZE))\n    messageWidget.pack(side=RIGHT, expand=1, fill=BOTH, padx='3m', pady='3m')\n\n    # --------- entryWidget ----------------------------------------------\n    entryWidget = Entry(entryFrame, width=40)\n    bindArrows(entryWidget)\n    entryWidget.configure(font=(PROPORTIONAL_FONT_FAMILY,TEXT_ENTRY_FONT_SIZE))\n    if mask:\n        entryWidget.configure(show=mask)\n    entryWidget.pack(side=LEFT, padx=\"3m\")\n    entryWidget.bind(\"<Return>\", __enterboxGetText)\n    entryWidget.bind(\"<Escape>\", __enterboxCancel)\n    # put text into the entryWidget\n    entryWidget.insert(0,__enterboxDefaultText)\n\n    # ------------------ ok button -------------------------------\n    okButton = Button(buttonsFrame, takefocus=1, text=\"OK\")\n    bindArrows(okButton)\n    okButton.pack(expand=1, side=LEFT, padx='3m', pady='3m', ipadx='2m', ipady='1m')\n\n    # for the commandButton, bind activation events to the activation event handler\n    commandButton  = okButton\n    handler = __enterboxGetText\n    for selectionEvent in STANDARD_SELECTION_EVENTS:\n        commandButton.bind(\"<%s>\" % selectionEvent, handler)\n\n\n    # ------------------ cancel button -------------------------------\n    cancelButton = Button(buttonsFrame, takefocus=1, text=\"Cancel\")\n    bindArrows(cancelButton)\n    cancelButton.pack(expand=1, side=RIGHT, padx='3m', pady='3m', ipadx='2m', ipady='1m')\n\n    # for the commandButton, bind activation events to the activation event handler\n    commandButton  = cancelButton\n    handler = __enterboxCancel\n    for selectionEvent in STANDARD_SELECTION_EVENTS:\n        commandButton.bind(\"<%s>\" % selectionEvent, handler)\n\n    # ------------------- time for action! -----------------\n    entryWidget.focus_force()    # put the focus on the entryWidget\n    boxRoot.deiconify()\n    boxRoot.mainloop()  # run it!\n\n    # -------- after the run has completed ----------------------------------\n    if root: root.deiconify()\n    boxRoot.destroy()  # button_click didn't destroy boxRoot, so we do it now\n    return __enterboxText", "response": "Fill a message with a specific message and image."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef multchoicebox(msg=\"Pick as many items as you like.\"\n    , title=\" \"\n    , choices=()\n    , **kwargs\n    ):\n    \"\"\"\n    Present the user with a list of choices.\n    allow him to select multiple items and return them in a list.\n    if the user doesn't choose anything from the list, return the empty list.\n    return None if he cancelled selection.\n\n    @arg msg: the msg to be displayed.\n    @arg title: the window title\n    @arg choices: a list or tuple of the choices to be displayed\n    \"\"\"\n    if len(choices) == 0: choices = [\"Program logic error - no choices were specified.\"]\n\n    global __choiceboxMultipleSelect\n    __choiceboxMultipleSelect = 1\n    return __choicebox(msg, title, choices)", "response": "Display a multchoicebox with a list of choices."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisplay a choicebox with a list of choices.", "response": "def choicebox(msg=\"Pick something.\"\n    , title=\" \"\n    , choices=()\n    ):\n    \"\"\"\n    Present the user with a list of choices.\n    return the choice that he selects.\n    return None if he cancels the selection selection.\n\n    @arg msg: the msg to be displayed.\n    @arg title: the window title\n    @arg choices: a list or tuple of the choices to be displayed\n    \"\"\"\n    if len(choices) == 0: choices = [\"Program logic error - no choices were specified.\"]\n\n    global __choiceboxMultipleSelect\n    __choiceboxMultipleSelect = 0\n    return __choicebox(msg,title,choices)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning that opens a dialog to get a file name.", "response": "def fileopenbox(msg=None\n    , title=None\n    , default=\"*\"\n    , filetypes=None\n    ):\n    \"\"\"\n    A dialog to get a file name.\n\n    About the \"default\" argument\n    ============================\n        The \"default\" argument specifies a filepath that (normally)\n        contains one or more wildcards.\n        fileopenbox will display only files that match the default filepath.\n        If omitted, defaults to \"*\" (all files in the current directory).\n\n        WINDOWS EXAMPLE::\n            ...default=\"c:/myjunk/*.py\"\n        will open in directory c:\\myjunk\\ and show all Python files.\n\n        WINDOWS EXAMPLE::\n            ...default=\"c:/myjunk/test*.py\"\n        will open in directory c:\\myjunk\\ and show all Python files\n        whose names begin with \"test\".\n\n\n        Note that on Windows, fileopenbox automatically changes the path\n        separator to the Windows path separator (backslash).\n\n    About the \"filetypes\" argument\n    ==============================\n        If specified, it should contain a list of items,\n        where each item is either::\n            - a string containing a filemask          # e.g. \"*.txt\"\n            - a list of strings, where all of the strings except the last one\n                are filemasks (each beginning with \"*.\",\n                such as \"*.txt\" for text files, \"*.py\" for Python files, etc.).\n                and the last string contains a filetype description\n\n        EXAMPLE::\n            filetypes = [\"*.css\", [\"*.htm\", \"*.html\", \"HTML files\"]  ]\n\n    NOTE THAT\n    =========\n\n        If the filetypes list does not contain (\"All files\",\"*\"),\n        it will be added.\n\n        If the filetypes list does not contain a filemask that includes\n        the extension of the \"default\" argument, it will be added.\n        For example, if     default=\"*abc.py\"\n        and no filetypes argument was specified, then\n        \"*.py\" will automatically be added to the filetypes argument.\n\n    @rtype: string or None\n    @return: the name of a file, or None if user chose to cancel\n\n    @arg msg: the msg to be displayed.\n    @arg title: the window title\n    @arg default: filepath with wildcards\n    @arg filetypes: filemasks that a user can choose, e.g. \"*.txt\"\n    \"\"\"\n    if sys.platform == 'darwin':\n        _bring_to_front()\n    localRoot = Tk()\n    localRoot.withdraw()\n\n    initialbase, initialfile, initialdir, filetypes = fileboxSetup(default,filetypes)\n\n    #------------------------------------------------------------\n    # if initialfile contains no wildcards; we don't want an\n    # initial file. It won't be used anyway.\n    # Also: if initialbase is simply \"*\", we don't want an\n    # initialfile; it is not doing any useful work.\n    #------------------------------------------------------------\n    if (initialfile.find(\"*\") < 0) and (initialfile.find(\"?\") < 0):\n        initialfile = None\n    elif initialbase == \"*\":\n        initialfile = None\n\n    f = tk_FileDialog.askopenfilename(parent=localRoot\n        , title=getFileDialogTitle(msg,title)\n        , initialdir=initialdir\n        , initialfile=initialfile\n        , filetypes=filetypes\n        )\n\n    localRoot.destroy()\n\n    if not f: return None\n    return os.path.normpath(f)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __buttonEvent(event):\n    global  boxRoot, __widgetTexts, __replyButtonText\n    __replyButtonText = __widgetTexts[event.widget]\n    boxRoot.quit()", "response": "Handle an event that is generated by a person clicking a button."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a MaltegoMessage to stdout and exit successfully", "response": "def message(msg):\n    \"\"\"Write a MaltegoMessage to stdout and exit successfully\"\"\"\n    v = MaltegoMessage(message=msg).render(encoding='utf-8')\n    return Response(v, status=200, mimetype='text/xml')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a signal handler to execute when Maltego forcibly terminates the transform.", "response": "def on_terminate(func):\n    \"\"\"Register a signal handler to execute when Maltego forcibly terminates the transform.\"\"\"\n    def exit_function(*args):\n        func()\n        exit(0)\n    signal.signal(signal.SIGTERM, exit_function)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef message(m, fd=sys.stdout):\n\n    if sys.platform == 'win32':\n        decoding = sys.stdout.encoding if sys.version_info[0] > 2 else 'cp1252'\n        click.echo(MaltegoMessage(message=m).render(fragment=True, encoding='utf-8').decode(decoding), file=fd)\n    else:\n        click.echo(MaltegoMessage(message=m).render(encoding='utf-8', fragment=True), file=fd)\n    exit(0)", "response": "Write a MaltegoMessage to stdout and exit successfully"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nthrow an exception in the Maltego GUI containing error_msg.", "response": "def croak(error, message_writer=message):\n    \"\"\"Throw an exception in the Maltego GUI containing error_msg.\"\"\"\n    if isinstance(error, MaltegoException):\n        message_writer(MaltegoTransformExceptionMessage(exceptions=[error]))\n    else:\n        message_writer(MaltegoTransformExceptionMessage(exceptions=[MaltegoException(error)]))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_entity(entity_type, value, fields):\n    e = entity_type(value)\n    for k, v in fields.items():\n        e.fields[k] = Field(k, v)\n    return e", "response": "Internal API to create an entity of type entity_type with the specified value and fields."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_transform_version(transform):\n\n    if sys.version_info[0] > 3:\n        spec = inspect.getfullargspec(transform)\n    else:\n        spec = inspect.getargspec(transform)\n\n    if spec.varargs:\n        return 3\n\n    n = len(spec.args)\n\n    if 2 <= n <= 3:\n        return n\n\n    raise Exception('Could not determine transform version.')", "response": "Internal API to determine the version of the transform function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend debug messages to the Maltego console.", "response": "def debug(*args):\n    \"\"\"Send debug messages to the Maltego console.\"\"\"\n    for i in args:\n        click.echo('D:%s' % str(i), err=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_aws_lambda(ctx, bucket, region_name, aws_access_key_id, aws_secret_access_key):\n    from canari.commands.create_aws_lambda import create_aws_lambda\n    create_aws_lambda(ctx.project, bucket, region_name, aws_access_key_id, aws_secret_access_key)", "response": "Creates an AWS Chalice project for deployment to AWS Lambda."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_package(package, author, email, description, create_example):\n    from canari.commands.create_package import create_package\n    create_package(package, author, email, description, create_example)", "response": "Creates a Canari transform package skeleton."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an importable Maltego profile file.", "response": "def create_profile(ctx, package):\n    \"\"\"Creates an importable Maltego profile (*.mtz) file.\"\"\"\n    from canari.commands.create_profile import create_profile\n    create_profile(ctx.config_dir, ctx.project, package)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_transform(ctx, transform):\n    from canari.commands.create_transform import create_transform\n    create_transform(ctx.project, transform)", "response": "Creates a new transform in the specified directory and auto - updates dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef debug_transform(ctx, transform, params, value, fields):\n    from canari.commands.debug_transform import debug_transform\n    debug_transform(transform, value, fields, params, ctx.project, ctx.config)", "response": "Runs Canari local transforms in a terminal - friendly fashion."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dockerize_package(ctx, os, host):\n    from canari.commands.dockerize_package import dockerize_package\n    dockerize_package(ctx.project, os, host)", "response": "Creates a Docker build file pre - configured with Plume."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert Maltego entity definition files to Canari python classes.", "response": "def generate_entities(ctx, output_path, mtz_file, exclude_namespace, namespace, maltego_entities, append, entity):\n    \"\"\"Converts Maltego entity definition files to Canari python classes.\n    Excludes Maltego built-in entities by default.\"\"\"\n    from canari.commands.generate_entities import generate_entities\n    generate_entities(\n        ctx.project, output_path, mtz_file, exclude_namespace, namespace, maltego_entities, append, entity)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating entities documentation from Canari python classes file.", "response": "def generate_entities_doc(ctx, out_path, package):\n    \"\"\"Create entities documentation from Canari python classes file.\"\"\"\n    from canari.commands.generate_entities_doc import generate_entities_doc\n    generate_entities_doc(ctx.project, out_path, package)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_plume_package(package, plume_dir, accept_defaults):\n    from canari.commands.load_plume_package import load_plume_package\n    load_plume_package(package, plume_dir, accept_defaults)", "response": "Loads a canari package into Plume."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remote_transform(host, transform, input, entity_field, transform_parameter, raw_output, ssl,\n                     base_path, soft_limit, hard_limit, verbose):\n    \"\"\"Runs Canari local transforms in a terminal-friendly fashion.\"\"\"\n    from canari.commands.remote_transform import remote_transform\n    remote_transform(host, transform, input, entity_field, transform_parameter, raw_output, ssl,\n                     base_path, soft_limit, hard_limit, verbose)", "response": "Runs Canari local transforms in a terminal - friendly fashion."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning a Canari interactive python shell", "response": "def shell(ctx, package, working_dir, sudo):\n    \"\"\"Runs a Canari interactive python shell\"\"\"\n    ctx.mode = CanariMode.LocalShellDebug\n    from canari.commands.shell import shell\n    shell(package, working_dir, sudo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unload_plume_package(package, plume_dir):\n    from canari.commands.unload_plume_package import unload_plume_package\n    unload_plume_package(package, plume_dir)", "response": "Unloads a canari package from Plume."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the global operating mode for Canari.", "response": "def set_canari_mode(mode=CanariMode.Unknown):\n    \"\"\"\n    Sets the global operating mode for Canari. This is used to alter the behaviour of dangerous classes like the\n    CanariConfigParser.\n\n    :param mode: the numeric Canari operating mode (CanariMode.Local, CanariMode.Remote, etc.).\n    :return: previous operating mode.\n    \"\"\"\n    global canari_mode\n    old_mode = canari_mode\n    canari_mode = mode\n    return old_mode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a 2d array that is a 2d array where the gradient of function fun is applied to the derivative of the function x.", "response": "def approx_fprime(x, f, epsilon=None, args=(), kwargs=None, centered=True):\n    \"\"\"\n    Gradient of function, or Jacobian if function fun returns 1d array\n\n    Parameters\n    ----------\n    x : array\n        parameters at which the derivative is evaluated\n    fun : function\n        `fun(*((x,)+args), **kwargs)` returning either one value or 1d array\n    epsilon : float, optional\n        Stepsize, if None, optimal stepsize is used. This is _EPS**(1/2)*x for\n        `centered` == False and _EPS**(1/3)*x for `centered` == True.\n    args : tuple\n        Tuple of additional arguments for function `fun`.\n    kwargs : dict\n        Dictionary of additional keyword arguments for function `fun`.\n    centered : bool\n        Whether central difference should be returned. If not, does forward\n        differencing.\n\n    Returns\n    -------\n    grad : array\n        gradient or Jacobian\n\n    Notes\n    -----\n    If fun returns a 1d array, it returns a Jacobian. If a 2d array is returned\n    by fun (e.g., with a value for each observation), it returns a 3d array\n    with the Jacobian of each observation with shape xk x nobs x xk. I.e.,\n    the Jacobian of the first observation would be [:, 0, :]\n\n    \"\"\"\n    kwargs = {} if kwargs is None else kwargs\n    n = len(x)\n    f0 = f(*(x,) + args, **kwargs)\n    dim = np.atleast_1d(f0).shape  # it could be a scalar\n    grad = np.zeros((n,) + dim, float)\n    ei = np.zeros(np.shape(x), float)\n    if not centered:\n        epsilon = _get_epsilon(x, 2, epsilon, n)\n        for k in range(n):\n            ei[k] = epsilon[k]\n            grad[k, :] = (f(*(x + ei,) + args, **kwargs) - f0) / epsilon[k]\n            ei[k] = 0.0\n    else:\n        epsilon = _get_epsilon(x, 3, epsilon, n) / 2.\n        for k in range(n):\n            ei[k] = epsilon[k]\n            grad[k, :] = (f(*(x + ei,) + args, **kwargs) -\n                          f(*(x - ei,) + args, **kwargs)) / (2 * epsilon[k])\n            ei[k] = 0.0\n    grad = grad.squeeze()\n    axes = [0, 1, 2][:grad.ndim]\n    axes[:2] = axes[1::-1]\n    return np.transpose(grad, axes=axes).squeeze()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef timefun(fun):\n    @wraps(fun)\n    def measure_time(*args, **kwargs):\n        t1 = timer()\n        result = fun(*args, **kwargs)\n        t2 = timer()\n        print(\"@timefun:\" + fun.__name__ + \" took \" + str(t2 - t1) + \" seconds\")\n        return result\n    return measure_time", "response": "Decorator to measure the execution time of a function in a timeit language."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_cprofile(func):\n    def profiled_func(*args, **kwargs):\n        profile = cProfile.Profile()\n        try:\n            profile.enable()\n            result = func(*args, **kwargs)\n            profile.disable()\n            return result\n        finally:\n            profile.print_stats()\n    return profiled_func", "response": "Decorator to profile a function on a sequence of functions."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap around scipy. ndimage. convolve1d that allows complex input.", "response": "def convolve(sequence, rule, **kwds):\n    \"\"\"Wrapper around scipy.ndimage.convolve1d that allows complex input.\"\"\"\n    dtype = np.result_type(float, np.ravel(sequence)[0])\n    seq = np.asarray(sequence, dtype=dtype)\n    if np.iscomplexobj(seq):\n        return (convolve1d(seq.real, rule, **kwds) + 1j * convolve1d(seq.imag, rule, **kwds))\n    return convolve1d(seq, rule, **kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextrapolates a slowly convergent sequence Parameters ---------- v0, v1, v2 : array-like 3 values of a convergent sequence to extrapolate Returns ------- result : array-like extrapolated value abserr : array-like absolute error estimate Notes ----- DEA3 attempts to extrapolate nonlinearly to a better estimate of the sequence's limiting value, thus improving the rate of convergence. The routine is based on the epsilon algorithm of P. Wynn, see [1]_. Examples -------- # integrate sin(x) from 0 to pi/2 >>> import numpy as np >>> import numdifftools as nd >>> Ei= np.zeros(3) >>> linfun = lambda i : np.linspace(0, np.pi/2., 2**(i+5)+1) >>> for k in np.arange(3): ... x = linfun(k) ... Ei[k] = np.trapz(np.sin(x),x) >>> [En, err] = nd.dea3(Ei[0], Ei[1], Ei[2]) >>> truErr = np.abs(En-1.) >>> np.all(truErr < err) True >>> np.allclose(En, 1) True >>> np.all(np.abs(Ei-1)<1e-3) True See also -------- dea References ---------- .. [1] C. Brezinski and M. Redivo Zaglia (1991) \"Extrapolation Methods. Theory and Practice\", North-Holland. .. [2] C. Brezinski (1977) \"Acceleration de la convergence en analyse numerique\", \"Lecture Notes in Math.\", vol. 584, Springer-Verlag, New York, 1977. .. [3] E. J. Weniger (1989) \"Nonlinear sequence transformations for the acceleration of convergence and the summation of divergent series\" Computer Physics Reports Vol. 10, 189 - 371 http://arxiv.org/abs/math/0306302v1", "response": "def dea3(v0, v1, v2, symmetric=False):\n    \"\"\"\n    Extrapolate a slowly convergent sequence\n\n    Parameters\n    ----------\n    v0, v1, v2 : array-like\n        3 values of a convergent sequence to extrapolate\n\n    Returns\n    -------\n    result : array-like\n        extrapolated value\n    abserr : array-like\n        absolute error estimate\n\n    Notes\n    -----\n    DEA3 attempts to extrapolate nonlinearly to a better estimate\n    of the sequence's limiting value, thus improving the rate of\n    convergence. The routine is based on the epsilon algorithm of\n    P. Wynn, see [1]_.\n\n     Examples\n     --------\n     # integrate sin(x) from 0 to pi/2\n\n     >>> import numpy as np\n     >>> import numdifftools as nd\n     >>> Ei= np.zeros(3)\n     >>> linfun = lambda i : np.linspace(0, np.pi/2., 2**(i+5)+1)\n     >>> for k in np.arange(3):\n     ...    x = linfun(k)\n     ...    Ei[k] = np.trapz(np.sin(x),x)\n     >>> [En, err] = nd.dea3(Ei[0], Ei[1], Ei[2])\n     >>> truErr = np.abs(En-1.)\n     >>> np.all(truErr < err)\n     True\n     >>> np.allclose(En, 1)\n     True\n     >>> np.all(np.abs(Ei-1)<1e-3)\n     True\n\n     See also\n     --------\n     dea\n\n     References\n     ----------\n     .. [1] C. Brezinski and M. Redivo Zaglia (1991)\n            \"Extrapolation Methods. Theory and Practice\", North-Holland.\n\n    ..  [2] C. Brezinski (1977)\n            \"Acceleration de la convergence en analyse numerique\",\n            \"Lecture Notes in Math.\", vol. 584,\n            Springer-Verlag, New York, 1977.\n\n    ..  [3] E. J. Weniger (1989)\n            \"Nonlinear sequence transformations for the acceleration of\n            convergence and the summation of divergent series\"\n            Computer Physics Reports Vol. 10, 189 - 371\n            http://arxiv.org/abs/math/0306302v1\n    \"\"\"\n    e0, e1, e2 = np.atleast_1d(v0, v1, v2)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")  # ignore division by zero and overflow\n        delta2, delta1 = e2 - e1, e1 - e0\n        err2, err1 = np.abs(delta2), np.abs(delta1)\n        tol2, tol1 = max_abs(e2, e1) * _EPS, max_abs(e1, e0) * _EPS\n        delta1[err1 < _TINY] = _TINY\n        delta2[err2 < _TINY] = _TINY  # avoid division by zero and overflow\n        ss = 1.0 / delta2 - 1.0 / delta1 + _TINY\n        smalle2 = abs(ss * e1) <= 1.0e-3\n        converged = (err1 <= tol1) & (err2 <= tol2) | smalle2\n        result = np.where(converged, e2 * 1.0, e1 + 1.0 / ss)\n    abserr = err1 + err2 + np.where(converged, tol2 * 10, np.abs(result - e2))\n    if symmetric and len(result) > 1:\n        return result[:-1], abserr[1:]\n    return result, abserr"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns matrix for finite difference and complex step derivation.", "response": "def _fd_matrix(step_ratio, parity, nterms):\n        \"\"\"\n        Return matrix for finite difference and complex step derivation.\n\n        Parameters\n        ----------\n        step_ratio : real scalar\n            ratio between steps in unequally spaced difference rule.\n        parity : scalar, integer\n            0 (one sided, all terms included but zeroth order)\n            1 (only odd terms included)\n            2 (only even terms included)\n            3 (only every 4'th order terms included starting from order 2)\n            4 (only every 4'th order terms included starting from order 4)\n            5 (only every 4'th order terms included starting from order 1)\n            6 (only every 4'th order terms included starting from order 3)\n        nterms : scalar, integer\n            number of terms\n        \"\"\"\n        _assert(0 <= parity <= 6,\n                'Parity must be 0, 1, 2, 3, 4, 5 or 6! ({0:d})'.format(parity))\n        step = [1, 2, 2, 4, 4, 4, 4][parity]\n        inv_sr = 1.0 / step_ratio\n        offset = [1, 1, 2, 2, 4, 1, 3][parity]\n        c0 = [1.0, 1.0, 1.0, 2.0, 24.0, 1.0, 6.0][parity]\n        c = c0 / \\\n            special.factorial(np.arange(offset, step * nterms + offset, step))\n        [i, j] = np.ogrid[0:nterms, 0:nterms]\n        return np.atleast_2d(c[j] * inv_sr ** (i * (step * j + offset)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _apply_fd_rule(self, step_ratio, sequence, steps):\n        f_del, h, original_shape = self._vstack(sequence, steps)\n        fd_rule = self._get_finite_difference_rule(step_ratio)\n        ne = h.shape[0]\n        nr = fd_rule.size - 1\n        _assert(nr < ne, 'num_steps ({0:d}) must  be larger than '\n                '({1:d}) n + order - 1 = {2:d} + {3:d} -1'\n                ' ({4:s})'.format(ne, nr+1, self.n, self.order, self.method))\n        f_diff = convolve(f_del, fd_rule[::-1], axis=0, origin=nr // 2)\n\n        der_init = f_diff / (h ** self.n)\n        ne = max(ne - nr, 1)\n        return der_init[:ne], h[:ne], original_shape", "response": "Return derivative estimates of fun at x0 for a sequence of stepsizes h\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating Hessian with complex - step derivative approximation", "response": "def _complex_even(f, fx, x, h):\n        \"\"\"\n        Calculate Hessian with complex-step derivative approximation\n\n        The stepsize is the same for the complex and the finite difference part\n        \"\"\"\n        n = len(x)\n        ee = np.diag(h)\n        hess = 2. * np.outer(h, h)\n        for i in range(n):\n            for j in range(i, n):\n                hess[i, j] = (f(x + 1j * ee[i] + ee[j])\n                              - f(x + 1j * ee[i] - ee[j])).imag / hess[j, i]\n                hess[j, i] = hess[i, j]\n        return hess"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate Hessian with Bicomplex - step derivative approximation", "response": "def _multicomplex2(f, fx, x, h):\n        \"\"\"Calculate Hessian with Bicomplex-step derivative approximation\"\"\"\n        n = len(x)\n        ee = np.diag(h)\n        hess = np.outer(h, h)\n        cmplx_wrap = Bicomplex.__array_wrap__\n        for i in range(n):\n            for j in range(i, n):\n                zph = Bicomplex(x + 1j * ee[i, :], ee[j, :])\n                hess[i, j] = cmplx_wrap(f(zph)).imag12 / hess[j, i]\n                hess[j, i] = hess[i, j]\n        return hess"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef directionaldiff(f, x0, vec, **options):\n    x0 = np.asarray(x0)\n    vec = np.asarray(vec)\n    if x0.size != vec.size:\n        raise ValueError('vec and x0 must be the same shapes')\n\n    vec = np.reshape(vec/np.linalg.norm(vec.ravel()), x0.shape)\n    return Derivative(lambda t: f(x0+t*vec), **options)(0)", "response": "Returns a Derivative of a function that computes the first derivative of a function in a specified direction."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef valarray(shape, value=np.NaN, typecode=None):\n    if typecode is None:\n        typecode = bool\n    out = np.ones(shape, dtype=typecode) * value\n\n    if not isinstance(out, np.ndarray):\n        out = np.asarray(out)\n    return out", "response": "Return an array of all value."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns finite differencing rule for a local step size.", "response": "def rule(self):\n        \"\"\"\n        Return finite differencing rule.\n\n        The rule is for a nominal unit step size, and must be scaled later\n        to reflect the local step size.\n\n        Member methods used\n        -------------------\n        _fd_matrix\n\n        Member variables used\n        ---------------------\n        n\n        order\n        method\n        \"\"\"\n        step_ratio = self.step_ratio\n        method = self.method\n        if method in ('multicomplex', ) or self.n == 0:\n            return np.ones((1,))\n\n        order, method_order = self.n - 1, self._method_order\n        parity = self._parity(method, order, method_order)\n        step = self._richardson_step()\n        num_terms, ix = (order + method_order) // step, order // step\n        fd_rules = FD_RULES.get((step_ratio, parity, num_terms))\n        if fd_rules is None:\n            fd_mat = self._fd_matrix(step_ratio, parity, num_terms)\n            fd_rules = linalg.pinv(fd_mat)\n            FD_RULES[(step_ratio, parity, num_terms)] = fd_rules\n\n        if self._flip_fd_rule:\n            return -fd_rules[ix]\n        return fd_rules[ix]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies finite difference rule along the first axis.", "response": "def apply(self, f_del, h):\n        \"\"\"\n        Apply finite difference rule along the first axis.\n        \"\"\"\n\n        fd_rule = self.rule\n\n        ne = h.shape[0]\n        nr = fd_rule.size - 1\n        _assert(nr < ne, 'num_steps ({0:d}) must  be larger than '\n                '({1:d}) n + order - 1 = {2:d} + {3:d} -1'\n                ' ({4:s})'.format(ne, nr+1, self.n, self.order, self.method))\n        f_diff = convolve(f_del, fd_rule[::-1], axis=0, origin=nr // 2)\n\n        der_init = f_diff / (h ** self.n)\n        ne = max(ne - nr, 1)\n        return der_init[:ne], h[:ne]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mod_c(self):\n        r12, r22 = self.z1*self.z1, self.z2*self.z2\n        r = np.sqrt(r12 + r22)\n        return r", "response": "Complex modulus of the current logarithm"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning finite difference weights for all orders up to n", "response": "def fd_weights_all(x, x0=0, n=1):\n    \"\"\"\n    Return finite difference weights for derivatives of all orders up to n.\n\n    Parameters\n    ----------\n    x : vector, length m\n        x-coordinates for grid points\n    x0 : scalar\n        location where approximations are to be accurate\n    n : scalar integer\n        highest derivative that we want to find weights for\n\n    Returns\n    -------\n    weights :  array, shape n+1 x m\n        contains coefficients for the j'th derivative in row j (0 <= j <= n)\n\n    Notes\n    -----\n    The x values can be arbitrarily spaced but must be distinct and len(x) > n.\n\n    The Fornberg algorithm is much more stable numerically than regular\n    vandermonde systems for large values of n.\n\n    See also\n    --------\n    fd_weights\n\n    References\n    ----------\n    B. Fornberg (1998)\n    \"Calculation of weights_and_points in finite difference formulas\",\n    SIAM Review 40, pp. 685-691.\n\n    http://www.scholarpedia.org/article/Finite_difference_method\n    \"\"\"\n    m = len(x)\n    _assert(n < m, 'len(x) must be larger than n')\n\n    weights = np.zeros((m, n + 1))\n    _fd_weights_all(weights, x, x0, n)\n    return weights.T"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fd_derivative(fx, x, n=1, m=2):\n    num_x = len(x)\n    _assert(n < num_x, 'len(x) must be larger than n')\n    _assert(num_x == len(fx), 'len(x) must be equal len(fx)')\n\n    du = np.zeros_like(fx)\n\n    mm = n // 2 + m\n    size = 2 * mm + 2  # stencil size at boundary\n    # 2 * mm boundary points\n    for i in range(mm):\n        du[i] = np.dot(fd_weights(x[:size], x0=x[i], n=n), fx[:size])\n        du[-i-1] = np.dot(fd_weights(x[-size:], x0=x[-i-1], n=n), fx[-size:])\n\n    # interior points\n    for i in range(mm, num_x-mm):\n        du[i] = np.dot(fd_weights(x[i-mm:i+mm+1], x0=x[i], n=n),\n                       fx[i-mm:i+mm+1])\n\n    return du", "response": "Returns then'th derivative of a vector function f."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _poor_convergence(z, r, f, bn, mvec):\n    check_points = (-0.4 + 0.3j, 0.7 + 0.2j, 0.02 - 0.06j)\n    diffs = []\n    ftests = []\n    for check_point in check_points:\n        rtest = r * check_point\n        ztest = z + rtest\n        ftest = f(ztest)\n        # Evaluate powerseries:\n        comp = np.sum(bn * np.power(check_point, mvec))\n        ftests.append(ftest)\n        diffs.append(comp - ftest)\n\n    max_abs_error = np.max(np.abs(diffs))\n    max_f_value = np.max(np.abs(ftests))\n    return max_abs_error > 1e-3 * max_f_value", "response": "Test for poor convergence based on three function evaluations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _num_taylor_coefficients(n):\n    _assert(n < 193, 'Number of derivatives too large.  Must be less than 193')\n    correction = np.array([0, 0, 1, 3, 4, 7])[_get_logn(n)]\n    log2n = _get_logn(n - correction)\n    m = 2 ** (log2n + 3)\n    return m", "response": "Returns the number of taylor coefficients for a given number of derivatives."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef richardson(vals, k, c=None):\n    if c is None:\n        c = richardson_parameter(vals, k)\n    return vals[k] - (vals[k] - vals[k - 1]) / c", "response": "Richardson extrapolation with parameter estimation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn Taylor coefficients of complex analytic function using FFT Parameters ---------- fun : callable function to differentiate z0 : real or complex scalar at which to evaluate the derivatives n : scalar integer, default 1 Number of taylor coefficents to compute. Maximum number is 100. r : real scalar, default 0.0061 Initial radius at which to evaluate. For well-behaved functions, the computation should be insensitive to the initial radius to within about four orders of magnitude. num_extrap : scalar integer, default 3 number of extrapolation steps used in the calculation step_ratio : real scalar, default 1.6 Initial grow/shrinking factor for finding the best radius. max_iter : scalar integer, default 30 Maximum number of iterations min_iter : scalar integer, default max_iter // 2 Minimum number of iterations before the solution may be deemed degenerate. A larger number allows the algorithm to correct a bad initial radius. full_output : bool, optional If `full_output` is False, only the coefficents is returned (default). If `full_output` is True, then (coefs, status) is returned Returns ------- coefs : ndarray array of taylor coefficents status: Optional object into which output information is written: degenerate: True if the algorithm was unable to bound the error iterations: Number of iterations executed function_count: Number of function calls final_radius: Ending radius of the algorithm failed: True if the maximum number of iterations was reached error_estimate: approximate bounds of the rounding error. Notes ----- This module uses the method of Fornberg to compute the Taylor series coefficents of a complex analytic function along with error bounds. The method uses a Fast Fourier Transform to invert function evaluations around a circle into Taylor series coefficients and uses Richardson Extrapolation to improve and bound the estimate. Unlike real-valued finite differences, the method searches for a desirable radius and so is reasonably insensitive to the initial radius-to within a number of orders of magnitude at least. For most cases, the default configuration is likely to succeed. Restrictions The method uses the coefficients themselves to control the truncation error, so the error will not be properly bounded for functions like low-order polynomials whose Taylor series coefficients are nearly zero. If the error cannot be bounded, degenerate flag will be set to true, and an answer will still be computed and returned but should be used with caution. Examples -------- Compute the first 6 taylor coefficients 1 / (1 - z) expanded round z0 = 0: >>> import numdifftools.fornberg as ndf >>> import numpy as np >>> c, info = ndf.taylor(lambda x: 1./(1-x), z0=0, n=6, full_output=True) >>> np.allclose(c, np.ones(8)) True >>> np.all(info.error_estimate < 1e-9) True >>> (info.function_count, info.iterations, info.failed) == (144, 18, False) True References ---------- [1] Fornberg, B. (1981). Numerical Differentiation of Analytic Functions. ACM Transactions on Mathematical Software (TOMS), 7(4), 512-526. http://doi.org/10.1145/355972.355979", "response": "def taylor(fun, z0=0, n=1, r=0.0061, num_extrap=3, step_ratio=1.6, **kwds):\n    \"\"\"\n    Return Taylor coefficients of complex analytic function using FFT\n\n    Parameters\n    ----------\n    fun : callable\n        function to differentiate\n    z0 : real or complex scalar at which to evaluate the derivatives\n    n : scalar integer, default 1\n        Number of taylor coefficents to compute. Maximum number is 100.\n    r : real scalar, default 0.0061\n        Initial radius at which to evaluate. For well-behaved functions,\n        the computation should be insensitive to the initial radius to within\n        about four orders of magnitude.\n    num_extrap : scalar integer, default 3\n        number of extrapolation steps used in the calculation\n    step_ratio : real scalar, default 1.6\n        Initial grow/shrinking factor for finding the best radius.\n    max_iter : scalar integer, default 30\n        Maximum number of iterations\n    min_iter : scalar integer, default max_iter // 2\n        Minimum number of iterations before the solution may be deemed\n        degenerate.  A larger number allows the algorithm to correct a bad\n        initial radius.\n    full_output : bool, optional\n        If `full_output` is False, only the coefficents is returned (default).\n        If `full_output` is True, then (coefs, status) is returned\n\n    Returns\n    -------\n    coefs : ndarray\n       array of taylor coefficents\n    status: Optional object into which output information is written:\n        degenerate: True if the algorithm was unable to bound the error\n        iterations: Number of iterations executed\n        function_count: Number of function calls\n        final_radius: Ending radius of the algorithm\n        failed: True if the maximum number of iterations was reached\n        error_estimate: approximate bounds of the rounding error.\n\n    Notes\n    -----\n    This module uses the method of Fornberg to compute the Taylor series\n    coefficents of a complex analytic function along with error bounds. The\n    method uses a Fast Fourier Transform to invert function evaluations around\n    a circle into Taylor series coefficients and uses Richardson Extrapolation\n    to improve and bound the estimate. Unlike real-valued finite differences,\n    the method searches for a desirable radius and so is reasonably\n    insensitive to the initial radius-to within a number of orders of\n    magnitude at least. For most cases, the default configuration is likely to\n    succeed.\n\n    Restrictions\n\n    The method uses the coefficients themselves to control the truncation\n    error, so the error will not be properly bounded for functions like\n    low-order polynomials whose Taylor series coefficients are nearly zero.\n    If the error cannot be bounded, degenerate flag will be set to true, and\n    an answer will still be computed and returned but should be used with\n    caution.\n\n    Examples\n    --------\n\n    Compute the first 6 taylor coefficients 1 / (1 - z) expanded round  z0 = 0:\n    >>> import numdifftools.fornberg as ndf\n    >>> import numpy as np\n    >>> c, info = ndf.taylor(lambda x: 1./(1-x), z0=0, n=6, full_output=True)\n    >>> np.allclose(c, np.ones(8))\n    True\n    >>> np.all(info.error_estimate < 1e-9)\n    True\n    >>> (info.function_count, info.iterations, info.failed) == (144, 18, False)\n    True\n\n\n    References\n    ----------\n    [1] Fornberg, B. (1981).\n        Numerical Differentiation of Analytic Functions.\n        ACM Transactions on Mathematical Software (TOMS),\n        7(4), 512-526. http://doi.org/10.1145/355972.355979\n    \"\"\"\n    return Taylor(fun, n=n, r=r, num_extrap=num_extrap, step_ratio=step_ratio, **kwds)(z0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef derivative(fun, z0, n=1, **kwds):\n    result = taylor(fun, z0, n=n, **kwds)\n    # convert taylor series --> actual derivatives.\n    m = _num_taylor_coefficients(n)\n    fact = factorial(np.arange(m))\n    if kwds.get('full_output'):\n        coefs, info_ = result\n        info = _INFO(info_.error_estimate * fact, *info_[1:])\n        return coefs * fact, info\n    return result * fact", "response": "This function calculates the n - th derivative of a complex analytic function at a given z0."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default_char(self):\n        reverse = mo.DECSCNM in self.mode\n        return Char(data=\" \", fg=\"default\", bg=\"default\", reverse=reverse)", "response": "An empty character with default foreground and background colors."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset(self):\n        self.dirty.update(range(self.lines))\n        self.buffer.clear()\n        self.margins = None\n\n        self.mode = set([mo.DECAWM, mo.DECTCEM])\n\n        self.title = \"\"\n        self.icon_name = \"\"\n\n        self.charset = 0\n        self.g0_charset = cs.LAT1_MAP\n        self.g1_charset = cs.VT100_MAP\n\n        # From ``man terminfo`` -- \"... hardware tabs are initially\n        # set every `n` spaces when the terminal is powered up. Since\n        # we aim to support VT102 / VT220 and linux -- we use n = 8.\n        self.tabstops = set(range(8, self.columns, 8))\n\n        self.cursor = Cursor(0, 0)\n        self.cursor_position()\n\n        self.saved_columns = None", "response": "Reset the terminal to its initial state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting top and bottom margins for the scrolling region.", "response": "def set_margins(self, top=None, bottom=None):\n        \"\"\"Select top and bottom margins for the scrolling region.\n\n        :param int top: the smallest line number that is scrolled.\n        :param int bottom: the biggest line number that is scrolled.\n        \"\"\"\n        # XXX 0 corresponds to the CSI with no parameters.\n        if (top is None or top == 0) and bottom is None:\n            self.margins = None\n            return\n\n        margins = self.margins or Margins(0, self.lines - 1)\n\n        # Arguments are 1-based, while :attr:`margins` are zero\n        # based -- so we have to decrement them by one. We also\n        # make sure that both of them is bounded by [0, lines - 1].\n        if top is None:\n            top = margins.top\n        else:\n            top = max(0, min(top - 1, self.lines - 1))\n        if bottom is None:\n            bottom = margins.bottom\n        else:\n            bottom = max(0, min(bottom - 1, self.lines - 1))\n\n        # Even though VT102 and VT220 require DECSTBM to ignore\n        # regions of width less than 2, some programs (like aptitude\n        # for example) rely on it. Practicality beats purity.\n        if bottom - top >= 1:\n            self.margins = Margins(top, bottom)\n\n            # The cursor moves to the home position when the top and\n            # bottom margins of the scrolling region (DECSTBM) changes.\n            self.cursor_position()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_mode(self, *modes, **kwargs):\n        # Private mode codes are shifted, to be distingiushed from non\n        # private ones.\n        if kwargs.get(\"private\"):\n            modes = [mode << 5 for mode in modes]\n            if mo.DECSCNM in modes:\n                self.dirty.update(range(self.lines))\n\n        self.mode.update(modes)\n\n        # When DECOLM mode is set, the screen is erased and the cursor\n        # moves to the home position.\n        if mo.DECCOLM in modes:\n            self.saved_columns = self.columns\n            self.resize(columns=132)\n            self.erase_in_display(2)\n            self.cursor_position()\n\n        # According to VT520 manual, DECOM should also home the cursor.\n        if mo.DECOM in modes:\n            self.cursor_position()\n\n        # Mark all displayed characters as reverse.\n        if mo.DECSCNM in modes:\n            for line in self.buffer.values():\n                line.default = self.default_char\n                for x in line:\n                    line[x] = line[x]._replace(reverse=True)\n\n            self.select_graphic_rendition(7)  # +reverse.\n\n        # Make the cursor visible.\n        if mo.DECTCEM in modes:\n            self.cursor.hidden = False", "response": "Set the mode codes for a given list of modes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndefine character set code in the system.", "response": "def define_charset(self, code, mode):\n        \"\"\"Define ``G0`` or ``G1`` charset.\n\n        :param str code: character set code, should be a character\n                         from ``\"B0UK\"``, otherwise ignored.\n        :param str mode: if ``\"(\"`` ``G0`` charset is defined, if\n                         ``\")\"`` -- we operate on ``G1``.\n\n        .. warning:: User-defined charsets are currently not supported.\n        \"\"\"\n        if code in cs.MAPS:\n            if mode == \"(\":\n                self.g0_charset = cs.MAPS[code]\n            elif mode == \")\":\n                self.g1_charset = cs.MAPS[code]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisplay decoded characters at the current cursor position and advances the cursor if mode is DECAWM is set.", "response": "def draw(self, data):\n        \"\"\"Display decoded characters at the current cursor position and\n        advances the cursor if :data:`~pyte.modes.DECAWM` is set.\n\n        :param str data: text to display.\n\n        .. versionchanged:: 0.5.0\n\n           Character width is taken into account. Specifically, zero-width\n           and unprintable characters do not affect screen state. Full-width\n           characters are rendered into two consecutive character containers.\n        \"\"\"\n        data = data.translate(\n            self.g1_charset if self.charset else self.g0_charset)\n\n        for char in data:\n            char_width = wcwidth(char)\n\n            # If this was the last column in a line and auto wrap mode is\n            # enabled, move the cursor to the beginning of the next line,\n            # otherwise replace characters already displayed with newly\n            # entered.\n            if self.cursor.x == self.columns:\n                if mo.DECAWM in self.mode:\n                    self.dirty.add(self.cursor.y)\n                    self.carriage_return()\n                    self.linefeed()\n                elif char_width > 0:\n                    self.cursor.x -= char_width\n\n            # If Insert mode is set, new characters move old characters to\n            # the right, otherwise terminal is in Replace mode and new\n            # characters replace old characters at cursor position.\n            if mo.IRM in self.mode and char_width > 0:\n                self.insert_characters(char_width)\n\n            line = self.buffer[self.cursor.y]\n            if char_width == 1:\n                line[self.cursor.x] = self.cursor.attrs._replace(data=char)\n            elif char_width == 2:\n                # A two-cell character has a stub slot after it.\n                line[self.cursor.x] = self.cursor.attrs._replace(data=char)\n                if self.cursor.x + 1 < self.columns:\n                    line[self.cursor.x + 1] = self.cursor.attrs \\\n                        ._replace(data=\"\")\n            elif char_width == 0 and unicodedata.combining(char):\n                # A zero-cell character is combined with the previous\n                # character either on this or preceeding line.\n                if self.cursor.x:\n                    last = line[self.cursor.x - 1]\n                    normalized = unicodedata.normalize(\"NFC\", last.data + char)\n                    line[self.cursor.x - 1] = last._replace(data=normalized)\n                elif self.cursor.y:\n                    last = self.buffer[self.cursor.y - 1][self.columns - 1]\n                    normalized = unicodedata.normalize(\"NFC\", last.data + char)\n                    self.buffer[self.cursor.y - 1][self.columns - 1] = \\\n                        last._replace(data=normalized)\n            else:\n                break  # Unprintable character or doesn't advance the cursor.\n\n            # .. note:: We can't use :meth:`cursor_forward()`, because that\n            #           way, we'll never know when to linefeed.\n            if char_width > 0:\n                self.cursor.x = min(self.cursor.x + char_width, self.columns)\n\n        self.dirty.add(self.cursor.y)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving the cursor down one line in the same column.", "response": "def index(self):\n        \"\"\"Move the cursor down one line in the same column. If the\n        cursor is at the last line, create a new line at the bottom.\n        \"\"\"\n        top, bottom = self.margins or Margins(0, self.lines - 1)\n        if self.cursor.y == bottom:\n            # TODO: mark only the lines within margins?\n            self.dirty.update(range(self.lines))\n            for y in range(top, bottom):\n                self.buffer[y] = self.buffer[y + 1]\n            self.buffer.pop(bottom, None)\n        else:\n            self.cursor_down()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmoves the cursor up one line in the same column.", "response": "def reverse_index(self):\n        \"\"\"Move the cursor up one line in the same column. If the cursor\n        is at the first line, create a new line at the top.\n        \"\"\"\n        top, bottom = self.margins or Margins(0, self.lines - 1)\n        if self.cursor.y == top:\n            # TODO: mark only the lines within margins?\n            self.dirty.update(range(self.lines))\n            for y in range(bottom, top, -1):\n                self.buffer[y] = self.buffer[y - 1]\n            self.buffer.pop(top, None)\n        else:\n            self.cursor_up()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef linefeed(self):\n        self.index()\n\n        if mo.LNM in self.mode:\n            self.carriage_return()", "response": "Perform an index and carriage return."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving to the next tab space.", "response": "def tab(self):\n        \"\"\"Move to the next tab space, or the end of the screen if there\n        aren't anymore left.\n        \"\"\"\n        for stop in sorted(self.tabstops):\n            if self.cursor.x < stop:\n                column = stop\n                break\n        else:\n            column = self.columns - 1\n\n        self.cursor.x = column"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npushing the current cursor position onto the stack.", "response": "def save_cursor(self):\n        \"\"\"Push the current cursor position onto the stack.\"\"\"\n        self.savepoints.append(Savepoint(copy.copy(self.cursor),\n                                         self.g0_charset,\n                                         self.g1_charset,\n                                         self.charset,\n                                         mo.DECOM in self.mode,\n                                         mo.DECAWM in self.mode))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrestore the current cursor position to whatever cursor is on top .", "response": "def restore_cursor(self):\n        \"\"\"Set the current cursor position to whatever cursor is on top\n        of the stack.\n        \"\"\"\n        if self.savepoints:\n            savepoint = self.savepoints.pop()\n\n            self.g0_charset = savepoint.g0_charset\n            self.g1_charset = savepoint.g1_charset\n            self.charset = savepoint.charset\n\n            if savepoint.origin:\n                self.set_mode(mo.DECOM)\n            if savepoint.wrap:\n                self.set_mode(mo.DECAWM)\n\n            self.cursor = savepoint.cursor\n            self.ensure_hbounds()\n            self.ensure_vbounds(use_margins=True)\n        else:\n            # If nothing was saved, the cursor moves to home position;\n            # origin mode is reset. :todo: DECAWM?\n            self.reset_mode(mo.DECOM)\n            self.cursor_position()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert_lines(self, count=None):\n        count = count or 1\n        top, bottom = self.margins or Margins(0, self.lines - 1)\n\n        # If cursor is outside scrolling margins it -- do nothin'.\n        if top <= self.cursor.y <= bottom:\n            self.dirty.update(range(self.cursor.y, self.lines))\n            for y in range(bottom, self.cursor.y - 1, -1):\n                if y + count <= bottom and y in self.buffer:\n                    self.buffer[y + count] = self.buffer[y]\n                self.buffer.pop(y, None)\n\n            self.carriage_return()", "response": "Insert the specified number of lines at the cursor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert_characters(self, count=None):\n        self.dirty.add(self.cursor.y)\n\n        count = count or 1\n        line = self.buffer[self.cursor.y]\n        for x in range(self.columns, self.cursor.x - 1, -1):\n            if x + count <= self.columns:\n                line[x + count] = line[x]\n            line.pop(x, None)", "response": "Insert the specified number of blank characters at the cursor."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nerasing the specified number of characters starting with the curser character at cursor position.", "response": "def erase_characters(self, count=None):\n        \"\"\"Erase the indicated # of characters, starting with the\n        character at cursor position. Character attributes are set\n        cursor attributes. The cursor remains in the same position.\n\n        :param int count: number of characters to erase.\n\n        .. note::\n\n           Using cursor attributes for character attributes may seem\n           illogical, but if recall that a terminal emulator emulates\n           a type writer, it starts to make sense. The only way a type\n           writer could erase a character is by typing over it.\n        \"\"\"\n        self.dirty.add(self.cursor.y)\n        count = count or 1\n\n        line = self.buffer[self.cursor.y]\n        for x in range(self.cursor.x,\n                       min(self.cursor.x + count, self.columns)):\n            line[x] = self.cursor.attrs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef erase_in_line(self, how=0, private=False):\n        self.dirty.add(self.cursor.y)\n        if how == 0:\n            interval = range(self.cursor.x, self.columns)\n        elif how == 1:\n            interval = range(self.cursor.x + 1)\n        elif how == 2:\n            interval = range(self.columns)\n\n        line = self.buffer[self.cursor.y]\n        for x in interval:\n            line[x] = self.cursor.attrs", "response": "Erases a line in a specific way."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nerasing the display in a specific way.", "response": "def erase_in_display(self, how=0, *args, **kwargs):\n        \"\"\"Erases display in a specific way.\n\n        Character attributes are set to cursor attributes.\n\n        :param int how: defines the way the line should be erased in:\n\n            * ``0`` -- Erases from cursor to end of screen, including\n              cursor position.\n            * ``1`` -- Erases from beginning of screen to cursor,\n              including cursor position.\n            * ``2`` and ``3`` -- Erases complete display. All lines\n              are erased and changed to single-width. Cursor does not\n              move.\n        :param bool private: when ``True`` only characters marked as\n                             eraseable are affected **not implemented**.\n\n        .. versionchanged:: 0.8.1\n\n           The method accepts any number of positional arguments as some\n           ``clear`` implementations include a ``;`` after the first\n           parameter causing the stream to assume a ``0`` second parameter.\n        \"\"\"\n        if how == 0:\n            interval = range(self.cursor.y + 1, self.lines)\n        elif how == 1:\n            interval = range(self.cursor.y)\n        elif how == 2 or how == 3:\n            interval = range(self.lines)\n\n        self.dirty.update(interval)\n        for y in interval:\n            line = self.buffer[y]\n            for x in line:\n                line[x] = self.cursor.attrs\n\n        if how == 0 or how == 1:\n            self.erase_in_line(how)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclears a horizontal tab stop at cursor position.", "response": "def clear_tab_stop(self, how=0):\n        \"\"\"Clear a horizontal tab stop.\n\n        :param int how: defines a way the tab stop should be cleared:\n\n            * ``0`` or nothing -- Clears a horizontal tab stop at cursor\n              position.\n            * ``3`` -- Clears all horizontal tab stops.\n        \"\"\"\n        if how == 0:\n            # Clears a horizontal tab stop at cursor position, if it's\n            # present, or silently fails if otherwise.\n            self.tabstops.discard(self.cursor.x)\n        elif how == 3:\n            self.tabstops = set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring the cursor is within horizontal screen bounds.", "response": "def ensure_hbounds(self):\n        \"\"\"Ensure the cursor is within horizontal screen bounds.\"\"\"\n        self.cursor.x = min(max(0, self.cursor.x), self.columns - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ensure_vbounds(self, use_margins=None):\n        if (use_margins or mo.DECOM in self.mode) and self.margins is not None:\n            top, bottom = self.margins\n        else:\n            top, bottom = 0, self.lines - 1\n\n        self.cursor.y = min(max(top, self.cursor.y), bottom)", "response": "Ensure the cursor is within vertical screen bounds."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cursor_up(self, count=None):\n        top, _bottom = self.margins or Margins(0, self.lines - 1)\n        self.cursor.y = max(self.cursor.y - (count or 1), top)", "response": "Move cursor up count lines."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cursor_down(self, count=None):\n        _top, bottom = self.margins or Margins(0, self.lines - 1)\n        self.cursor.y = min(self.cursor.y + (count or 1), bottom)", "response": "Move cursor down count lines in same column."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cursor_back(self, count=None):\n        # Handle the case when we've just drawn in the last column\n        # and would wrap the line on the next :meth:`draw()` call.\n        if self.cursor.x == self.columns:\n            self.cursor.x -= 1\n\n        self.cursor.x -= count or 1\n        self.ensure_hbounds()", "response": "Move cursor left the indicated number of columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cursor_position(self, line=None, column=None):\n        column = (column or 1) - 1\n        line = (line or 1) - 1\n\n        # If origin mode (DECOM) is set, line number are relative to\n        # the top scrolling margin.\n        if self.margins is not None and mo.DECOM in self.mode:\n            line += self.margins.top\n\n            # Cursor is not allowed to move out of the scrolling region.\n            if not self.margins.top <= line <= self.margins.bottom:\n                return\n\n        self.cursor.x = column\n        self.cursor.y = line\n        self.ensure_hbounds()\n        self.ensure_vbounds()", "response": "Set the cursor to a specific line and column."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving cursor to a specific line in the current column.", "response": "def cursor_to_line(self, line=None):\n        \"\"\"Move cursor to a specific line in the current column.\n\n        :param int line: line number to move the cursor to.\n        \"\"\"\n        self.cursor.y = (line or 1) - 1\n\n        # If origin mode (DECOM) is set, line number are relative to\n        # the top scrolling margin.\n        if mo.DECOM in self.mode:\n            self.cursor.y += self.margins.top\n\n            # FIXME: should we also restrict the cursor to the scrolling\n            # region?\n\n        self.ensure_vbounds()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef alignment_display(self):\n        self.dirty.update(range(self.lines))\n        for y in range(self.lines):\n            for x in range(self.columns):\n                self.buffer[y][x] = self.buffer[y][x]._replace(data=\"E\")", "response": "Fills screen with uppercase E s for screen focus and alignment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting the most recent useful color for a particular color.", "response": "def select_graphic_rendition(self, *attrs):\n        \"\"\"Set display attributes.\n\n        :param list attrs: a list of display attributes to set.\n        \"\"\"\n        replace = {}\n\n        # Fast path for resetting all attributes.\n        if not attrs or attrs == (0, ):\n            self.cursor.attrs = self.default_char\n            return\n        else:\n            attrs = list(reversed(attrs))\n\n        while attrs:\n            attr = attrs.pop()\n            if attr == 0:\n                # Reset all attributes.\n                replace.update(self.default_char._asdict())\n            elif attr in g.FG_ANSI:\n                replace[\"fg\"] = g.FG_ANSI[attr]\n            elif attr in g.BG:\n                replace[\"bg\"] = g.BG_ANSI[attr]\n            elif attr in g.TEXT:\n                attr = g.TEXT[attr]\n                replace[attr[1:]] = attr.startswith(\"+\")\n            elif attr in g.FG_AIXTERM:\n                replace.update(fg=g.FG_AIXTERM[attr], bold=True)\n            elif attr in g.BG_AIXTERM:\n                replace.update(bg=g.BG_AIXTERM[attr], bold=True)\n            elif attr in (g.FG_256, g.BG_256):\n                key = \"fg\" if attr == g.FG_256 else \"bg\"\n                try:\n                    n = attrs.pop()\n                    if n == 5:    # 256.\n                        m = attrs.pop()\n                        replace[key] = g.FG_BG_256[m]\n                    elif n == 2:  # 24bit.\n                        # This is somewhat non-standard but is nonetheless\n                        # supported in quite a few terminals. See discussion\n                        # here https://gist.github.com/XVilka/8346728.\n                        replace[key] = \"{0:02x}{1:02x}{2:02x}\".format(\n                            attrs.pop(), attrs.pop(), attrs.pop())\n                except IndexError:\n                    pass\n\n        self.cursor.attrs = self.cursor.attrs._replace(**replace)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreporting terminal identity attributes.", "response": "def report_device_attributes(self, mode=0, **kwargs):\n        \"\"\"Report terminal identity.\n\n        .. versionadded:: 0.5.0\n\n        .. versionchanged:: 0.7.0\n\n           If ``private`` keyword argument is set, the method does nothing.\n           This behaviour is consistent with VT220 manual.\n        \"\"\"\n        # We only implement \"primary\" DA which is the only DA request\n        # VT102 understood, see ``VT102ID`` in ``linux/drivers/tty/vt.c``.\n        if mode == 0 and not kwargs.get(\"private\"):\n            self.write_process_input(ctrl.CSI + \"?6c\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef report_device_status(self, mode):\n        if mode == 5:    # Request for terminal status.\n            self.write_process_input(ctrl.CSI + \"0n\")\n        elif mode == 6:  # Request for cursor position.\n            x = self.cursor.x + 1\n            y = self.cursor.y + 1\n\n            # \"Origin mode (DECOM) selects line numbering.\"\n            if mo.DECOM in self.mode:\n                y -= self.margins.top\n            self.write_process_input(ctrl.CSI + \"{0};{1}R\".format(y, x))", "response": "Report terminal status or cursor position."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures a screen is at the bottom of the history buffer.", "response": "def before_event(self, event):\n        \"\"\"Ensure a screen is at the bottom of the history buffer.\n\n        :param str event: event name, for example ``\"linefeed\"``.\n        \"\"\"\n        if event not in [\"prev_page\", \"next_page\"]:\n            while self.history.position < self.history.size:\n                self.next_page()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef after_event(self, event):\n        if event in [\"prev_page\", \"next_page\"]:\n            for line in self.buffer.values():\n                for x in line:\n                    if x > self.columns:\n                        line.pop(x)\n\n        # If we're at the bottom of the history buffer and `DECTCEM`\n        # mode is set -- show the cursor.\n        self.cursor.hidden = not (\n            self.history.position == self.history.size and\n            mo.DECTCEM in self.mode\n        )", "response": "Ensure all lines on a screen have proper width."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef erase_in_display(self, how=0, *args, **kwargs):\n        super(HistoryScreen, self).erase_in_display(how, *args, **kwargs)\n\n        if how == 3:\n            self._reset_history()", "response": "Overloaded to erase history state."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index(self):\n        top, bottom = self.margins or Margins(0, self.lines - 1)\n\n        if self.cursor.y == bottom:\n            self.history.top.append(self.buffer[top])\n\n        super(HistoryScreen, self).index()", "response": "Overloaded to update top history with the removed lines."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving the screen page up through the history buffer.", "response": "def prev_page(self):\n        \"\"\"Move the screen page up through the history buffer. Page\n        size is defined by ``history.ratio``, so for instance\n        ``ratio = .5`` means that half the screen is restored from\n        history on page switch.\n        \"\"\"\n        if self.history.position > self.lines and self.history.top:\n            mid = min(len(self.history.top),\n                      int(math.ceil(self.lines * self.history.ratio)))\n\n            self.history.bottom.extendleft(\n                self.buffer[y]\n                for y in range(self.lines - 1, self.lines - mid - 1, -1))\n            self.history = self.history \\\n                ._replace(position=self.history.position - mid)\n\n            for y in range(self.lines - 1, mid - 1, -1):\n                self.buffer[y] = self.buffer[y - mid]\n            for y in range(mid - 1, -1, -1):\n                self.buffer[y] = self.history.top.pop()\n\n            self.dirty = set(range(self.lines))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove the screen page down through the history buffer.", "response": "def next_page(self):\n        \"\"\"Move the screen page down through the history buffer.\"\"\"\n        if self.history.position < self.history.size and self.history.bottom:\n            mid = min(len(self.history.bottom),\n                      int(math.ceil(self.lines * self.history.ratio)))\n\n            self.history.top.extend(self.buffer[y] for y in range(mid))\n            self.history = self.history \\\n                ._replace(position=self.history.position + mid)\n\n            for y in range(self.lines - mid):\n                self.buffer[y] = self.buffer[y + mid]\n            for y in range(self.lines - mid, self.lines):\n                self.buffer[y] = self.history.bottom.popleft()\n\n            self.dirty = set(range(self.lines))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef attach(self, screen):\n        if self.listener is not None:\n            warnings.warn(\"As of version 0.6.0 the listener queue is \"\n                          \"restricted to a single element. Existing \"\n                          \"listener {0} will be replaced.\"\n                          .format(self.listener), DeprecationWarning)\n\n        if self.strict:\n            for event in self.events:\n                if not hasattr(screen, event):\n                    raise TypeError(\"{0} is missing {1}\".format(screen, event))\n\n        self.listener = screen\n        self._parser = None\n        self._initialize_parser()", "response": "Adds a given screen to the listener queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef feed(self, data):\n        send = self._send_to_parser\n        draw = self.listener.draw\n        match_text = self._text_pattern.match\n        taking_plain_text = self._taking_plain_text\n\n        length = len(data)\n        offset = 0\n        while offset < length:\n            if taking_plain_text:\n                match = match_text(data, offset)\n                if match:\n                    start, offset = match.span()\n                    draw(data[start:offset])\n                else:\n                    taking_plain_text = False\n            else:\n                taking_plain_text = send(data[offset:offset + 1])\n                offset += 1\n\n        self._taking_plain_text = taking_plain_text", "response": "Consume some data and advances the state as necessary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parser_fsm(self):\n        basic = self.basic\n        listener = self.listener\n        draw = listener.draw\n        debug = listener.debug\n\n        ESC, CSI_C1 = ctrl.ESC, ctrl.CSI_C1\n        OSC_C1 = ctrl.OSC_C1\n        SP_OR_GT = ctrl.SP + \">\"\n        NUL_OR_DEL = ctrl.NUL + ctrl.DEL\n        CAN_OR_SUB = ctrl.CAN + ctrl.SUB\n        ALLOWED_IN_CSI = \"\".join([ctrl.BEL, ctrl.BS, ctrl.HT, ctrl.LF,\n                                  ctrl.VT, ctrl.FF, ctrl.CR])\n        OSC_TERMINATORS = set([ctrl.ST_C0, ctrl.ST_C1, ctrl.BEL])\n\n        def create_dispatcher(mapping):\n            return defaultdict(lambda: debug, dict(\n                (event, getattr(listener, attr))\n                for event, attr in mapping.items()))\n\n        basic_dispatch = create_dispatcher(basic)\n        sharp_dispatch = create_dispatcher(self.sharp)\n        escape_dispatch = create_dispatcher(self.escape)\n        csi_dispatch = create_dispatcher(self.csi)\n\n        while True:\n            # ``True`` tells ``Screen.feed`` that it is allowed to send\n            # chunks of plain text directly to the listener, instead\n            # of this generator.\n            char = yield True\n\n            if char == ESC:\n                # Most non-VT52 commands start with a left-bracket after the\n                # escape and then a stream of parameters and a command; with\n                # a single notable exception -- :data:`escape.DECOM` sequence,\n                # which starts with a sharp.\n                #\n                # .. versionchanged:: 0.4.10\n                #\n                #    For compatibility with Linux terminal stream also\n                #    recognizes ``ESC % C`` sequences for selecting control\n                #    character set. However, in the current version these\n                #    are noop.\n                char = yield\n                if char == \"[\":\n                    char = CSI_C1  # Go to CSI.\n                elif char == \"]\":\n                    char = OSC_C1  # Go to OSC.\n                else:\n                    if char == \"#\":\n                        sharp_dispatch[(yield)]()\n                    elif char == \"%\":\n                        self.select_other_charset((yield))\n                    elif char in \"()\":\n                        code = yield\n                        if self.use_utf8:\n                            continue\n\n                        # See http://www.cl.cam.ac.uk/~mgk25/unicode.html#term\n                        # for the why on the UTF-8 restriction.\n                        listener.define_charset(code, mode=char)\n                    else:\n                        escape_dispatch[char]()\n                    continue    # Don't go to CSI.\n\n            if char in basic:\n                # Ignore shifts in UTF-8 mode. See\n                # http://www.cl.cam.ac.uk/~mgk25/unicode.html#term for\n                # the why on UTF-8 restriction.\n                if (char == ctrl.SI or char == ctrl.SO) and self.use_utf8:\n                    continue\n\n                basic_dispatch[char]()\n            elif char == CSI_C1:\n                # All parameters are unsigned, positive decimal integers, with\n                # the most significant digit sent first. Any parameter greater\n                # than 9999 is set to 9999. If you do not specify a value, a 0\n                # value is assumed.\n                #\n                # .. seealso::\n                #\n                #    `VT102 User Guide <http://vt100.net/docs/vt102-ug/>`_\n                #        For details on the formatting of escape arguments.\n                #\n                #    `VT220 Programmer Ref. <http://vt100.net/docs/vt220-rm/>`_\n                #        For details on the characters valid for use as\n                #        arguments.\n                params = []\n                current = \"\"\n                private = False\n                while True:\n                    char = yield\n                    if char == \"?\":\n                        private = True\n                    elif char in ALLOWED_IN_CSI:\n                        basic_dispatch[char]()\n                    elif char in SP_OR_GT:\n                        pass  # Secondary DA is not supported atm.\n                    elif char in CAN_OR_SUB:\n                        # If CAN or SUB is received during a sequence, the\n                        # current sequence is aborted; terminal displays\n                        # the substitute character, followed by characters\n                        # in the sequence received after CAN or SUB.\n                        draw(char)\n                        break\n                    elif char.isdigit():\n                        current += char\n                    elif char == \"$\":\n                        # XTerm-specific ESC]...$[a-z] sequences are not\n                        # currently supported.\n                        yield\n                        break\n                    else:\n                        params.append(min(int(current or 0), 9999))\n\n                        if char == \";\":\n                            current = \"\"\n                        else:\n                            if private:\n                                csi_dispatch[char](*params, private=True)\n                            else:\n                                csi_dispatch[char](*params)\n                            break  # CSI is finished.\n            elif char == OSC_C1:\n                code = yield\n                if code == \"R\":\n                    continue  # Reset palette. Not implemented.\n                elif code == \"P\":\n                    continue  # Set palette. Not implemented.\n\n                param = \"\"\n                while True:\n                    char = yield\n                    if char == ESC:\n                        char += yield\n                    if char in OSC_TERMINATORS:\n                        break\n                    else:\n                        param += char\n\n                param = param[1:]  # Drop the ;.\n                if code in \"01\":\n                    listener.set_icon_name(param)\n                if code in \"02\":\n                    listener.set_title(param)\n            elif char not in NUL_OR_DEL:\n                draw(char)", "response": "A generator that yields all of the FSM character sequences."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose all WS connections on shutdown.", "response": "async def on_shutdown(app):\n    \"\"\"Closes all WS connections on shutdown.\"\"\"\n    global is_shutting_down\n    is_shutting_down = True\n    for task in app[\"websockets\"]:\n        task.cancel()\n        try:\n            await task\n        except asyncio.CancelledError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates Root - mean - square deviation from two sets of vectors V and W.", "response": "def rmsd(V, W):\n    \"\"\"\n    Calculate Root-mean-square deviation from two sets of vectors V and W.\n\n    Parameters\n    ----------\n    V : array\n        (N,D) matrix, where N is points and D is dimension.\n    W : array\n        (N,D) matrix, where N is points and D is dimension.\n\n    Returns\n    -------\n    rmsd : float\n        Root-mean-square deviation between the two vectors\n    \"\"\"\n    D = len(V[0])\n    N = len(V)\n    result = 0.0\n    for v, w in zip(V, W):\n        result += sum([(v[i] - w[i])**2.0 for i in range(D)])\n    return np.sqrt(result/N)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrotates matrix P unto Q using Kabsch algorithm and calculate the RMSD.", "response": "def kabsch_rmsd(P, Q, translate=False):\n    \"\"\"\n    Rotate matrix P unto Q using Kabsch algorithm and calculate the RMSD.\n\n    Parameters\n    ----------\n    P : array\n        (N,D) matrix, where N is points and D is dimension.\n    Q : array\n        (N,D) matrix, where N is points and D is dimension.\n    translate : bool\n        Use centroids to translate vector P and Q unto each other.\n\n    Returns\n    -------\n    rmsd : float\n        root-mean squared deviation\n    \"\"\"\n    if translate:\n        Q = Q - centroid(Q)\n        P = P - centroid(P)\n\n    P = kabsch_rotate(P, Q)\n    return rmsd(P, Q)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrotate matrix P unto matrix Q using Kabsch algorithm.", "response": "def kabsch_rotate(P, Q):\n    \"\"\"\n    Rotate matrix P unto matrix Q using Kabsch algorithm.\n\n    Parameters\n    ----------\n    P : array\n        (N,D) matrix, where N is points and D is dimension.\n    Q : array\n        (N,D) matrix, where N is points and D is dimension.\n\n    Returns\n    -------\n    P : array\n        (N,D) matrix, where N is points and D is dimension,\n        rotated\n\n    \"\"\"\n    U = kabsch(P, Q)\n\n    # Rotate P\n    P = np.dot(P, U)\n    return P"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kabsch(P, Q):\n\n    # Computation of the covariance matrix\n    C = np.dot(np.transpose(P), Q)\n\n    # Computation of the optimal rotation matrix\n    # This can be done using singular value decomposition (SVD)\n    # Getting the sign of the det(V)*(W) to decide\n    # whether we need to correct our rotation matrix to ensure a\n    # right-handed coordinate system.\n    # And finally calculating the optimal rotation matrix U\n    # see http://en.wikipedia.org/wiki/Kabsch_algorithm\n    V, S, W = np.linalg.svd(C)\n    d = (np.linalg.det(V) * np.linalg.det(W)) < 0.0\n\n    if d:\n        S[-1] = -S[-1]\n        V[:, -1] = -V[:, -1]\n\n    # Create Rotation matrix U\n    U = np.dot(V, W)\n\n    return U", "response": "This function uses the Kabsch algorithm to compute the center of a set of paired points P and Q and the center of a set of paired points Q and centered around the centroid. The algorithm is used to compute the center of the set of paired points P and Q."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef quaternion_rmsd(P, Q):\n    rot = quaternion_rotate(P, Q)\n    P = np.dot(P, rot)\n    return rmsd(P, Q)", "response": "Calculates the RMSD of a single resource in a random system given a rotation matrix P unto Q and calculate the RMSD of a random resource in a random system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef quaternion_transform(r):\n    Wt_r = makeW(*r).T\n    Q_r = makeQ(*r)\n    rot = Wt_r.dot(Q_r)[:3, :3]\n    return rot", "response": "Get optimal rotation of a molecule"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef makeW(r1, r2, r3, r4=0):\n    W = np.asarray([\n        [r4, r3, -r2, r1],\n        [-r3, r4, r1, r2],\n        [r2, -r1, r4, r3],\n        [-r1, -r2, -r3, r4]])\n    return W", "response": "make a new hierarchy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef makeQ(r1, r2, r3, r4=0):\n    Q = np.asarray([\n        [r4, -r3, r2, r1],\n        [r3, r4, -r1, r2],\n        [-r2, r1, r4, r3],\n        [-r1, -r2, -r3, r4]])\n    return Q", "response": "make Q matrix involved in quaternion rotation"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the rotation matrix for a single resource in the cluster.", "response": "def quaternion_rotate(X, Y):\n    \"\"\"\n    Calculate the rotation\n\n    Parameters\n    ----------\n    X : array\n        (N,D) matrix, where N is points and D is dimension.\n    Y: array\n        (N,D) matrix, where N is points and D is dimension.\n\n    Returns\n    -------\n    rot : matrix\n        Rotation matrix (D,D)\n    \"\"\"\n    N = X.shape[0]\n    W = np.asarray([makeW(*Y[k]) for k in range(N)])\n    Q = np.asarray([makeQ(*X[k]) for k in range(N)])\n    Qt_dot_W = np.asarray([np.dot(Q[k].T, W[k]) for k in range(N)])\n    W_minus_Q = np.asarray([W[k] - Q[k] for k in range(N)])\n    A = np.sum(Qt_dot_W, axis=0)\n    eigen = np.linalg.eigh(A)\n    r = eigen[1][:, eigen[0].argmax()]\n    rot = quaternion_transform(r)\n    return rot"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reorder_distance(p_atoms, q_atoms, p_coord, q_coord):\n\n    # Find unique atoms\n    unique_atoms = np.unique(p_atoms)\n\n    # generate full view from q shape to fill in atom view on the fly\n    view_reorder = np.zeros(q_atoms.shape, dtype=int)\n\n    for atom in unique_atoms:\n\n        p_atom_idx, = np.where(p_atoms == atom)\n        q_atom_idx, = np.where(q_atoms == atom)\n\n        A_coord = p_coord[p_atom_idx]\n        B_coord = q_coord[q_atom_idx]\n\n        # Calculate distance from each atom to centroid\n        A_norms = np.linalg.norm(A_coord, axis=1)\n        B_norms = np.linalg.norm(B_coord, axis=1)\n\n        reorder_indices_A = np.argsort(A_norms)\n        reorder_indices_B = np.argsort(B_norms)\n\n        # Project the order of P onto Q\n        translator = np.argsort(reorder_indices_A)\n        view = reorder_indices_B[translator]\n        view_reorder[p_atom_idx] = q_atom_idx[view]\n\n    return view_reorder", "response": "Re - orders the input atom list and xyz coordinates by atom type and then by distance of each atom from the centroid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_permutations(elements, n):\n    c = [0] * n\n    yield elements\n    i = 0\n    while i < n:\n        if c[i] < i:\n            if i % 2 == 0:\n                elements[0], elements[i] = elements[i], elements[0]\n            else:\n                elements[c[i]], elements[i] = elements[i], elements[c[i]]\n            yield elements\n            c[i] += 1\n            i = 0\n        else:\n            c[i] = 0\n            i += 1", "response": "Generates all permutations of the n! elements in a list of n! elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nre-orders the input atom list and xyz coordinates using the brute force method of permuting all rows of the input coordinates Parameters ---------- A : array (N,D) matrix, where N is points and D is dimension B : array (N,D) matrix, where N is points and D is dimension Returns ------- view : array (N,1) matrix, reordered view of B projected to A", "response": "def brute_permutation(A, B):\n    \"\"\"\n    Re-orders the input atom list and xyz coordinates using the brute force\n    method of permuting all rows of the input coordinates\n\n    Parameters\n    ----------\n    A : array\n        (N,D) matrix, where N is points and D is dimension\n    B : array\n        (N,D) matrix, where N is points and D is dimension\n\n    Returns\n    -------\n    view : array\n        (N,1) matrix, reordered view of B projected to A\n    \"\"\"\n\n    rmsd_min = np.inf\n    view_min = None\n\n    # Sets initial ordering for row indices to [0, 1, 2, ..., len(A)], used in\n    # brute-force method\n\n    num_atoms = A.shape[0]\n    initial_order = list(range(num_atoms))\n\n    for reorder_indices in generate_permutations(initial_order, num_atoms):\n\n        # Re-order the atom array and coordinate matrix\n        coords_ordered = B[reorder_indices]\n\n        # Calculate the RMSD between structure 1 and the Hungarian re-ordered\n        # structure 2\n        rmsd_temp = kabsch_rmsd(A, coords_ordered)\n\n        # Replaces the atoms and coordinates with the current structure if the\n        # RMSD is lower\n        if rmsd_temp < rmsd_min:\n            rmsd_min = rmsd_temp\n            view_min = copy.deepcopy(reorder_indices)\n\n    return view_min"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reorder_brute(p_atoms, q_atoms, p_coord, q_coord):\n\n    # Find unique atoms\n    unique_atoms = np.unique(p_atoms)\n\n    # generate full view from q shape to fill in atom view on the fly\n    view_reorder = np.zeros(q_atoms.shape, dtype=int)\n    view_reorder -= 1\n\n    for atom in unique_atoms:\n        p_atom_idx, = np.where(p_atoms == atom)\n        q_atom_idx, = np.where(q_atoms == atom)\n\n        A_coord = p_coord[p_atom_idx]\n        B_coord = q_coord[q_atom_idx]\n\n        view = brute_permutation(A_coord, B_coord)\n        view_reorder[p_atom_idx] = q_atom_idx[view]\n\n    return view_reorder", "response": "Re - orders the input atom list and xyz coordinates using all permutation of the column results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_reflections(p_atoms, q_atoms, p_coord, q_coord,\n                      reorder_method=reorder_hungarian,\n                      rotation_method=kabsch_rmsd,\n                      keep_stereo=False):\n    \"\"\"\n    Minimize RMSD using reflection planes for molecule P and Q\n\n    Warning: This will affect stereo-chemistry\n\n    Parameters\n    ----------\n    p_atoms : array\n        (N,1) matrix, where N is points holding the atoms' names\n    q_atoms : array\n        (N,1) matrix, where N is points holding the atoms' names\n    p_coord : array\n        (N,D) matrix, where N is points and D is dimension\n    q_coord : array\n        (N,D) matrix, where N is points and D is dimension\n\n    Returns\n    -------\n    min_rmsd\n    min_swap\n    min_reflection\n    min_review\n\n    \"\"\"\n\n    min_rmsd = np.inf\n    min_swap = None\n    min_reflection = None\n    min_review = None\n    tmp_review = None\n    swap_mask = [1,-1,-1,1,-1,1]\n    reflection_mask = [1,-1,-1,-1,1,1,1,-1]\n\n    for swap, i in zip(AXIS_SWAPS, swap_mask):\n        for reflection, j in zip(AXIS_REFLECTIONS, reflection_mask):\n            if keep_stereo and  i * j == -1: continue # skip enantiomers\n\n            tmp_atoms = copy.copy(q_atoms)\n            tmp_coord = copy.deepcopy(q_coord)\n            tmp_coord = tmp_coord[:, swap]\n            tmp_coord = np.dot(tmp_coord, np.diag(reflection))\n            tmp_coord -= centroid(tmp_coord)\n\n            # Reorder\n            if reorder_method is not None:\n                tmp_review = reorder_method(p_atoms, tmp_atoms, p_coord, tmp_coord)\n                tmp_coord = tmp_coord[tmp_review]\n                tmp_atoms = tmp_atoms[tmp_review]\n\n            # Rotation\n            if rotation_method is None:\n                this_rmsd = rmsd(p_coord, tmp_coord)\n            else:\n                this_rmsd = rotation_method(p_coord, tmp_coord)\n\n            if this_rmsd < min_rmsd:\n                min_rmsd = this_rmsd\n                min_swap = swap\n                min_reflection = reflection\n                min_review = tmp_review\n\n    if not (p_atoms == q_atoms[min_review]).all():\n        print(\"error: Not aligned\")\n        quit()\n\n    return min_rmsd, min_swap, min_reflection, min_review", "response": "Minimize RMSD using reflection planes for molecule P and Q."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_coordinates(atoms, V, title=\"\", decimals=8):\n    N, D = V.shape\n\n    fmt = \"{:2s}\" + (\" {:15.\"+str(decimals)+\"f}\")*3\n\n    out = list()\n    out += [str(N)]\n    out += [title]\n\n    for i in range(N):\n        atom = atoms[i]\n        atom = atom[0].upper() + atom[1:]\n        out += [fmt.format(atom, V[i, 0], V[i, 1], V[i, 2])]\n\n    return \"\\n\".join(out)", "response": "Print coordinates V with corresponding atoms to stdout in XYZ format."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints coordinates V with corresponding atoms to stdout in XYZ format.", "response": "def print_coordinates(atoms, V, title=\"\"):\n    \"\"\"\n    Print coordinates V with corresponding atoms to stdout in XYZ format.\n\n    Parameters\n    ----------\n    atoms : list\n        List of element types\n    V : array\n        (N,3) matrix of atomic coordinates\n    title : string (optional)\n        Title of molecule\n\n    \"\"\"\n\n    print(set_coordinates(atoms, V, title=title))\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_coordinates(filename, fmt):\n    if fmt == \"xyz\":\n        get_func = get_coordinates_xyz\n    elif fmt == \"pdb\":\n        get_func = get_coordinates_pdb\n    else:\n        exit(\"Could not recognize file format: {:s}\".format(fmt))\n\n    return get_func(filename)", "response": "Get coordinates from filename in format fmt. Supports XYZ and PDB."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_coordinates_pdb(filename):\n\n    # PDB files tend to be a bit of a mess. The x, y and z coordinates\n    # are supposed to be in column 31-38, 39-46 and 47-54, but this is\n    # not always the case.\n    # Because of this the three first columns containing a decimal is used.\n    # Since the format doesn't require a space between columns, we use the\n    # above column indices as a fallback.\n\n    x_column = None\n    V = list()\n\n    # Same with atoms and atom naming.\n    # The most robust way to do this is probably\n    # to assume that the atomtype is given in column 3.\n\n    atoms = list()\n\n    with open(filename, 'r') as f:\n        lines = f.readlines()\n        for line in lines:\n            if line.startswith(\"TER\") or line.startswith(\"END\"):\n                break\n            if line.startswith(\"ATOM\"):\n                tokens = line.split()\n                # Try to get the atomtype\n                try:\n                    atom = tokens[2][0]\n                    if atom in (\"H\", \"C\", \"N\", \"O\", \"S\", \"P\"):\n                        atoms.append(atom)\n                    else:\n                        # e.g. 1HD1\n                        atom = tokens[2][1]\n                        if atom == \"H\":\n                            atoms.append(atom)\n                        else:\n                            raise Exception\n                except:\n                    exit(\"error: Parsing atomtype for the following line: \\n{0:s}\".format(line))\n\n                if x_column == None:\n                    try:\n                        # look for x column\n                        for i, x in enumerate(tokens):\n                            if \".\" in x and \".\" in tokens[i + 1] and \".\" in tokens[i + 2]:\n                                x_column = i\n                                break\n                    except IndexError:\n                        exit(\"error: Parsing coordinates for the following line: \\n{0:s}\".format(line))\n                # Try to read the coordinates\n                try:\n                    V.append(np.asarray(tokens[x_column:x_column + 3], dtype=float))\n                except:\n                    # If that doesn't work, use hardcoded indices\n                    try:\n                        x = line[30:38]\n                        y = line[38:46]\n                        z = line[46:54]\n                        V.append(np.asarray([x, y ,z], dtype=float))\n                    except:\n                        exit(\"error: Parsing input for the following line: \\n{0:s}\".format(line))\n\n\n    V = np.asarray(V)\n    atoms = np.asarray(atoms)\n\n    assert V.shape[0] == atoms.size\n\n    return atoms, V", "response": "Get coordinates from the first chain in a pdb file and return a vectorset with all the coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_coordinates_xyz(filename):\n\n    f = open(filename, 'r')\n    V = list()\n    atoms = list()\n    n_atoms = 0\n\n    # Read the first line to obtain the number of atoms to read\n    try:\n        n_atoms = int(f.readline())\n    except ValueError:\n        exit(\"error: Could not obtain the number of atoms in the .xyz file.\")\n\n    # Skip the title line\n    f.readline()\n\n    # Use the number of atoms to not read beyond the end of a file\n    for lines_read, line in enumerate(f):\n\n        if lines_read == n_atoms:\n            break\n\n        atom = re.findall(r'[a-zA-Z]+', line)[0]\n        atom = atom.upper()\n\n        numbers = re.findall(r'[-]?\\d+\\.\\d*(?:[Ee][-\\+]\\d+)?', line)\n        numbers = [float(number) for number in numbers]\n\n        # The numbers are not valid unless we obtain exacly three\n        if len(numbers) >= 3:\n            V.append(np.array(numbers)[:3])\n            atoms.append(atom)\n        else:\n            exit(\"Reading the .xyz file failed in line {0}. Please check the format.\".format(lines_read + 2))\n\n    f.close()\n    atoms = np.array(atoms)\n    V = np.array(V)\n    return atoms, V", "response": "Get coordinates from filename and return a vectorset with all the the\n    coordinates in XYZ format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef comparable(self):\n    string_parts = []\n\n    if self.data_stream:\n      string_parts.append('data stream: {0:s}'.format(self.data_stream))\n    if self.inode is not None:\n      string_parts.append('inode: {0:d}'.format(self.inode))\n    if self.location is not None:\n      string_parts.append('location: {0:s}'.format(self.location))\n\n    return self._GetComparable(sub_comparable_string=', '.join(string_parts))", "response": "str - comparable representation of the path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetFormatSpecification(self):\n    format_specification = specification.FormatSpecification(\n        self.type_indicator)\n\n    # TODO: add support for signature chains so that we add the 'BZ' at\n    # offset 0.\n\n    # BZIP2 compressed steam signature.\n    format_specification.AddNewSignature(b'\\x31\\x41\\x59\\x26\\x53\\x59', offset=4)\n\n    return format_specification", "response": "Retrieves the format specification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the directory entries.", "response": "def _EntriesGenerator(self):\n    \"\"\"Retrieves directory entries.\n\n    Since a directory can contain a vast number of entries using\n    a generator is more memory efficient.\n\n    Yields:\n      ZipPathSpec: a path specification.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n\n    if location and location.startswith(self._file_system.PATH_SEPARATOR):\n      # The zip_info filename does not have the leading path separator\n      # as the location string does.\n      zip_path = location[1:]\n\n      # Set of top level sub directories that have been yielded.\n      processed_directories = set()\n\n      zip_file = self._file_system.GetZipFile()\n      for zip_info in zip_file.infolist():\n        path = getattr(zip_info, 'filename', None)\n        if path is not None and not isinstance(path, py2to3.UNICODE_TYPE):\n          try:\n            path = path.decode(self._file_system.encoding)\n          except UnicodeDecodeError:\n            path = None\n\n        if not path or not path.startswith(zip_path):\n          continue\n\n        # Ignore the directory itself.\n        if path == zip_path:\n          continue\n\n        path_segment, suffix = self._file_system.GetPathSegmentAndSuffix(\n            zip_path, path)\n        if not path_segment:\n          continue\n\n        # Some times the ZIP file lacks directories, therefore we will\n        # provide virtual ones.\n        if suffix:\n          path_spec_location = self._file_system.JoinPath([\n              location, path_segment])\n          is_directory = True\n        else:\n          path_spec_location = self._file_system.JoinPath([path])\n          is_directory = path.endswith('/')\n\n        if is_directory:\n          if path_spec_location in processed_directories:\n            continue\n          processed_directories.add(path_spec_location)\n          # Restore / at end path to indicate a directory.\n          path_spec_location += self._file_system.PATH_SEPARATOR\n\n        yield zip_path_spec.ZipPathSpec(\n            location=path_spec_location, parent=self.path_spec.parent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _GetDirectory(self):\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return ZipDirectory(self._file_system, self.path_spec)", "response": "Retrieves a directory from the file system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the VFSStat object for the file entry.", "response": "def _GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object.\n    \"\"\"\n    stat_object = super(ZipFileEntry, self)._GetStat()\n\n    if self._zip_info is not None:\n      # File data stat information.\n      stat_object.size = getattr(self._zip_info, 'file_size', None)\n\n      # Ownership and permissions stat information.\n      if self._external_attributes != 0:\n        if self._creator_system == self._CREATOR_SYSTEM_UNIX:\n          st_mode = self._external_attributes >> 16\n          stat_object.mode = st_mode & 0x0fff\n\n    # Other stat information.\n    # zip_info.compress_type\n    # zip_info.comment\n    # zip_info.extra\n    # zip_info.create_version\n    # zip_info.extract_version\n    # zip_info.flag_bits\n    # zip_info.volume\n    # zip_info.internal_attr\n    # zip_info.compress_size\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _GetSubFileEntries(self):\n    if self._directory is None:\n      self._directory = self._GetDirectory()\n\n    zip_file = self._file_system.GetZipFile()\n    if self._directory and zip_file:\n      for path_spec in self._directory.entries:\n        location = getattr(path_spec, 'location', None)\n        if location is None:\n          continue\n\n        kwargs = {}\n        try:\n          kwargs['zip_info'] = zip_file.getinfo(location[1:])\n        except KeyError:\n          kwargs['is_virtual'] = True\n\n        yield ZipFileEntry(\n            self._resolver_context, self._file_system, path_spec, **kwargs)", "response": "Retrieves the sub file entries."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef name(self):\n    path = getattr(self.path_spec, 'location', None)\n    if path is not None and not isinstance(path, py2to3.UNICODE_TYPE):\n      try:\n        path = path.decode(self._file_system.encoding)\n      except UnicodeDecodeError:\n        path = None\n    return self._file_system.BasenamePath(path)", "response": "str name of the file entry without the full path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef modification_time(self):\n    if self._zip_info is None:\n      return None\n\n    time_elements = getattr(self._zip_info, 'date_time', None)\n    return dfdatetime_time_elements.TimeElements(time_elements)", "response": "Returns the modification time of the archive."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetParentFileEntry(self):\n    location = getattr(self.path_spec, 'location', None)\n    if location is None:\n      return None\n\n    parent_location = self._file_system.DirnamePath(location)\n    if parent_location is None:\n      return None\n\n    parent_path_spec = getattr(self.path_spec, 'parent', None)\n\n    if parent_location == '':\n      parent_location = self._file_system.PATH_SEPARATOR\n      is_root = True\n      is_virtual = True\n    else:\n      is_root = False\n      is_virtual = False\n\n    path_spec = zip_path_spec.ZipPathSpec(\n        location=parent_location, parent=parent_path_spec)\n    return ZipFileEntry(\n        self._resolver_context, self._file_system, path_spec, is_root=is_root,\n        is_virtual=is_virtual)", "response": "Retrieves the parent file entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the ZIP info object.", "response": "def GetZipInfo(self):\n    \"\"\"Retrieves the ZIP info object.\n\n    Returns:\n      zipfile.ZipInfo: a ZIP info object or None if not available.\n\n    Raises:\n      PathSpecError: if the path specification is incorrect.\n    \"\"\"\n    if not self._zip_info:\n      location = getattr(self.path_spec, 'location', None)\n      if location is None:\n        raise errors.PathSpecError('Path specification missing location.')\n\n      if not location.startswith(self._file_system.LOCATION_ROOT):\n        raise errors.PathSpecError('Invalid location in path specification.')\n\n      if len(location) == 1:\n        return None\n\n      zip_file = self._file_system.GetZipFile()\n      try:\n        self._zip_info = zip_file.getinfo(location[1:])\n      except KeyError:\n        pass\n\n    return self._zip_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the stat object for the current file entry.", "response": "def _GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object.\n    \"\"\"\n    stat_object = super(FVDEFileEntry, self)._GetStat()\n\n    stat_object.size = self._fvde_volume.get_size()\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the APFS volume identifiers.", "response": "def _GetAPFSVolumeIdentifiers(self, scan_node):\n    \"\"\"Determines the APFS volume identifiers.\n\n    Args:\n      scan_node (SourceScanNode): scan node.\n\n    Returns:\n      list[str]: APFS volume identifiers.\n\n    Raises:\n      ScannerError: if the format of or within the source is not supported\n          or the the scan node is invalid.\n      UserAbort: if the user requested to abort.\n    \"\"\"\n    if not scan_node or not scan_node.path_spec:\n      raise errors.ScannerError('Invalid scan node.')\n\n    volume_system = apfs_volume_system.APFSVolumeSystem()\n    volume_system.Open(scan_node.path_spec)\n\n    volume_identifiers = self._source_scanner.GetVolumeIdentifiers(\n        volume_system)\n    if not volume_identifiers:\n      return []\n\n    if len(volume_identifiers) > 1:\n      if not self._mediator:\n        raise errors.ScannerError(\n            'Unable to proceed. APFS volumes found but no mediator to '\n            'determine how they should be used.')\n\n      try:\n        volume_identifiers = self._mediator.GetAPFSVolumeIdentifiers(\n            volume_system, volume_identifiers)\n      except KeyboardInterrupt:\n        raise errors.UserAbort('File system scan aborted.')\n\n    return self._NormalizedVolumeIdentifiers(\n        volume_system, volume_identifiers, prefix='apfs')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the TSK partition identifiers for a given scan node.", "response": "def _GetTSKPartitionIdentifiers(self, scan_node):\n    \"\"\"Determines the TSK partition identifiers.\n\n    Args:\n      scan_node (SourceScanNode): scan node.\n\n    Returns:\n      list[str]: TSK partition identifiers.\n\n    Raises:\n      ScannerError: if the format of or within the source is not supported or\n          the scan node is invalid or if the volume for a specific identifier\n          cannot be retrieved.\n      UserAbort: if the user requested to abort.\n    \"\"\"\n    if not scan_node or not scan_node.path_spec:\n      raise errors.ScannerError('Invalid scan node.')\n\n    volume_system = tsk_volume_system.TSKVolumeSystem()\n    volume_system.Open(scan_node.path_spec)\n\n    volume_identifiers = self._source_scanner.GetVolumeIdentifiers(\n        volume_system)\n    if not volume_identifiers:\n      return []\n\n    if len(volume_identifiers) == 1:\n      return volume_identifiers\n\n    if not self._mediator:\n      raise errors.ScannerError(\n          'Unable to proceed. Partitions found but no mediator to determine '\n          'how they should be used.')\n\n    try:\n      volume_identifiers = self._mediator.GetPartitionIdentifiers(\n          volume_system, volume_identifiers)\n\n    except KeyboardInterrupt:\n      raise errors.UserAbort('File system scan aborted.')\n\n    return self._NormalizedVolumeIdentifiers(\n        volume_system, volume_identifiers, prefix='p')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine the VSS store identifiers.", "response": "def _GetVSSStoreIdentifiers(self, scan_node):\n    \"\"\"Determines the VSS store identifiers.\n\n    Args:\n      scan_node (SourceScanNode): scan node.\n\n    Returns:\n      list[str]: VSS store identifiers.\n\n    Raises:\n      ScannerError: if the format the scan node is invalid or no mediator\n          is provided and VSS store identifiers are found.\n      UserAbort: if the user requested to abort.\n    \"\"\"\n    if not scan_node or not scan_node.path_spec:\n      raise errors.ScannerError('Invalid scan node.')\n\n    volume_system = vshadow_volume_system.VShadowVolumeSystem()\n    volume_system.Open(scan_node.path_spec)\n\n    volume_identifiers = self._source_scanner.GetVolumeIdentifiers(\n        volume_system)\n    if not volume_identifiers:\n      return []\n\n    if not self._mediator:\n      raise errors.ScannerError(\n          'Unable to proceed. VSS stores found but no mediator to determine '\n          'how they should be used.')\n\n    try:\n      volume_identifiers = self._mediator.GetVSSStoreIdentifiers(\n          volume_system, volume_identifiers)\n\n    except KeyboardInterrupt:\n      raise errors.UserAbort('File system scan aborted.')\n\n    return self._NormalizedVolumeIdentifiers(\n        volume_system, volume_identifiers, prefix='vss')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _NormalizedVolumeIdentifiers(\n      self, volume_system, volume_identifiers, prefix='v'):\n    \"\"\"Normalizes volume identifiers.\n\n    Args:\n      volume_system (VolumeSystem): volume system.\n      volume_identifiers (list[int|str]): allowed volume identifiers, formatted\n          as an integer or string with prefix.\n      prefix (Optional[str]): volume identifier prefix.\n\n    Returns:\n      list[str]: volume identifiers with prefix.\n\n    Raises:\n      ScannerError: if the volume identifier is not supported or no volume\n          could be found that corresponds with the identifier.\n    \"\"\"\n    normalized_volume_identifiers = []\n    for volume_identifier in volume_identifiers:\n      if isinstance(volume_identifier, int):\n        volume_identifier = '{0:s}{1:d}'.format(prefix, volume_identifier)\n\n      elif not volume_identifier.startswith(prefix):\n        try:\n          volume_identifier = int(volume_identifier, 10)\n          volume_identifier = '{0:s}{1:d}'.format(prefix, volume_identifier)\n        except (TypeError, ValueError):\n          pass\n\n      try:\n        volume = volume_system.GetVolumeByIdentifier(volume_identifier)\n      except KeyError:\n        volume = None\n\n      if not volume:\n        raise errors.ScannerError(\n            'Volume missing for identifier: {0:s}.'.format(volume_identifier))\n\n      normalized_volume_identifiers.append(volume_identifier)\n\n    return normalized_volume_identifiers", "response": "Normalizes the list of volume identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ScanEncryptedVolume(self, scan_context, scan_node):\n    if not scan_node or not scan_node.path_spec:\n      raise errors.ScannerError('Invalid or missing scan node.')\n\n    credentials = credentials_manager.CredentialsManager.GetCredentials(\n        scan_node.path_spec)\n    if not credentials:\n      raise errors.ScannerError('Missing credentials for scan node.')\n\n    if not self._mediator:\n      raise errors.ScannerError(\n          'Unable to proceed. Encrypted volume found but no mediator to '\n          'determine how it should be unlocked.')\n\n    if self._mediator.UnlockEncryptedVolume(\n        self._source_scanner, scan_context, scan_node, credentials):\n      self._source_scanner.Scan(\n          scan_context, scan_path_spec=scan_node.path_spec)", "response": "Scans an encrypted volume scan node for volume and file systems."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nscanning a file system scan node for file systems.", "response": "def _ScanFileSystem(self, scan_node, base_path_specs):\n    \"\"\"Scans a file system scan node for file systems.\n\n    Args:\n      scan_node (SourceScanNode): file system scan node.\n      base_path_specs (list[PathSpec]): file system base path specifications.\n\n    Raises:\n      ScannerError: if the scan node is invalid.\n    \"\"\"\n    if not scan_node or not scan_node.path_spec:\n      raise errors.ScannerError('Invalid or missing file system scan node.')\n\n    base_path_specs.append(scan_node.path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscan a volume scan node for volume and file systems.", "response": "def _ScanVolume(self, scan_context, scan_node, base_path_specs):\n    \"\"\"Scans a volume scan node for volume and file systems.\n\n    Args:\n      scan_context (SourceScannerContext): source scanner context.\n      scan_node (SourceScanNode): volume scan node.\n      base_path_specs (list[PathSpec]): file system base path specifications.\n\n    Raises:\n      ScannerError: if the format of or within the source\n          is not supported or the scan node is invalid.\n    \"\"\"\n    if not scan_node or not scan_node.path_spec:\n      raise errors.ScannerError('Invalid or missing scan node.')\n\n    if scan_context.IsLockedScanNode(scan_node.path_spec):\n      # The source scanner found a locked volume and we need a credential to\n      # unlock it.\n      self._ScanEncryptedVolume(scan_context, scan_node)\n\n      if scan_context.IsLockedScanNode(scan_node.path_spec):\n        return\n\n    if scan_node.IsVolumeSystemRoot():\n      self._ScanVolumeSystemRoot(scan_context, scan_node, base_path_specs)\n\n    elif scan_node.IsFileSystem():\n      self._ScanFileSystem(scan_node, base_path_specs)\n\n    elif scan_node.type_indicator == definitions.TYPE_INDICATOR_VSHADOW:\n      # TODO: look into building VSS store on demand.\n\n      # We \"optimize\" here for user experience, alternatively we could scan for\n      # a file system instead of hard coding a TSK child path specification.\n      path_spec = path_spec_factory.Factory.NewPathSpec(\n          definitions.TYPE_INDICATOR_TSK, location='/',\n          parent=scan_node.path_spec)\n\n      base_path_specs.append(path_spec)\n\n    else:\n      for sub_scan_node in scan_node.sub_nodes:\n        self._ScanVolume(scan_context, sub_scan_node, base_path_specs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ScanVolumeSystemRoot(self, scan_context, scan_node, base_path_specs):\n    if not scan_node or not scan_node.path_spec:\n      raise errors.ScannerError('Invalid scan node.')\n\n    if scan_node.type_indicator == definitions.TYPE_INDICATOR_APFS_CONTAINER:\n      volume_identifiers = self._GetAPFSVolumeIdentifiers(scan_node)\n\n    elif scan_node.type_indicator == definitions.TYPE_INDICATOR_VSHADOW:\n      volume_identifiers = self._GetVSSStoreIdentifiers(scan_node)\n      # Process VSS stores (snapshots) starting with the most recent one.\n      volume_identifiers.reverse()\n\n    else:\n      raise errors.ScannerError(\n          'Unsupported volume system type: {0:s}.'.format(\n              scan_node.type_indicator))\n\n    for volume_identifier in volume_identifiers:\n      location = '/{0:s}'.format(volume_identifier)\n      sub_scan_node = scan_node.GetSubNodeByLocation(location)\n      if not sub_scan_node:\n        raise errors.ScannerError(\n            'Scan node missing for volume identifier: {0:s}.'.format(\n                volume_identifier))\n\n      self._ScanVolume(scan_context, sub_scan_node, base_path_specs)", "response": "Scans a volume system root scan node for volume and file systems."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetBasePathSpecs(self, source_path):\n    if not source_path:\n      raise errors.ScannerError('Invalid source path.')\n\n    # Note that os.path.exists() does not support Windows device paths.\n    if (not source_path.startswith('\\\\\\\\.\\\\') and\n        not os.path.exists(source_path)):\n      raise errors.ScannerError(\n          'No such device, file or directory: {0:s}.'.format(source_path))\n\n    scan_context = source_scanner.SourceScannerContext()\n    scan_context.OpenSourcePath(source_path)\n\n    try:\n      self._source_scanner.Scan(scan_context)\n    except (ValueError, errors.BackEndError) as exception:\n      raise errors.ScannerError(\n          'Unable to scan source with error: {0!s}'.format(exception))\n\n    self._source_path = source_path\n    self._source_type = scan_context.source_type\n\n    if self._source_type not in [\n        definitions.SOURCE_TYPE_STORAGE_MEDIA_DEVICE,\n        definitions.SOURCE_TYPE_STORAGE_MEDIA_IMAGE]:\n      scan_node = scan_context.GetRootScanNode()\n      return [scan_node.path_spec]\n\n    # Get the first node where where we need to decide what to process.\n    scan_node = scan_context.GetRootScanNode()\n    while len(scan_node.sub_nodes) == 1:\n      scan_node = scan_node.sub_nodes[0]\n\n    base_path_specs = []\n    if scan_node.type_indicator != definitions.TYPE_INDICATOR_TSK_PARTITION:\n      self._ScanVolume(scan_context, scan_node, base_path_specs)\n\n    else:\n      # Determine which partition needs to be processed.\n      partition_identifiers = self._GetTSKPartitionIdentifiers(scan_node)\n      for partition_identifier in partition_identifiers:\n        location = '/{0:s}'.format(partition_identifier)\n        sub_scan_node = scan_node.GetSubNodeByLocation(location)\n        self._ScanVolume(scan_context, sub_scan_node, base_path_specs)\n\n    return base_path_specs", "response": "Determines the base path specifications for a given source path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nscan a file system scan node for file systems.", "response": "def _ScanFileSystem(self, scan_node, base_path_specs):\n    \"\"\"Scans a file system scan node for file systems.\n\n    This method checks if the file system contains a known Windows directory.\n\n    Args:\n      scan_node (SourceScanNode): file system scan node.\n      base_path_specs (list[PathSpec]): file system base path specifications.\n\n    Raises:\n      ScannerError: if the scan node is invalid.\n    \"\"\"\n    if not scan_node or not scan_node.path_spec:\n      raise errors.ScannerError('Invalid or missing file system scan node.')\n\n    file_system = resolver.Resolver.OpenFileSystem(scan_node.path_spec)\n    if not file_system:\n      return\n\n    try:\n      path_resolver = windows_path_resolver.WindowsPathResolver(\n          file_system, scan_node.path_spec.parent)\n\n      if self._ScanFileSystemForWindowsDirectory(path_resolver):\n        base_path_specs.append(scan_node.path_spec)\n\n    finally:\n      file_system.Close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscan a file system for a known Windows directory.", "response": "def _ScanFileSystemForWindowsDirectory(self, path_resolver):\n    \"\"\"Scans a file system for a known Windows directory.\n\n    Args:\n      path_resolver (WindowsPathResolver): Windows path resolver.\n\n    Returns:\n      bool: True if a known Windows directory was found.\n    \"\"\"\n    result = False\n    for windows_path in self._WINDOWS_DIRECTORIES:\n      windows_path_spec = path_resolver.ResolvePath(windows_path)\n\n      result = windows_path_spec is not None\n      if result:\n        self._windows_directory = windows_path\n        break\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OpenFile(self, windows_path):\n    path_spec = self._path_resolver.ResolvePath(windows_path)\n    if path_spec is None:\n      return None\n\n    return self._file_system.GetFileObjectByPathSpec(path_spec)", "response": "Opens the file specified by the Windows path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscan for a Windows volume.", "response": "def ScanForWindowsVolume(self, source_path):\n    \"\"\"Scans for a Windows volume.\n\n    Args:\n      source_path (str): source path.\n\n    Returns:\n      bool: True if a Windows volume was found.\n\n    Raises:\n      ScannerError: if the source path does not exists, or if the source path\n          is not a file or directory, or if the format of or within the source\n          file is not supported.\n    \"\"\"\n    windows_path_specs = self.GetBasePathSpecs(source_path)\n    if (not windows_path_specs or\n        self._source_type == definitions.SOURCE_TYPE_FILE):\n      return False\n\n    file_system_path_spec = windows_path_specs[0]\n    self._file_system = resolver.Resolver.OpenFileSystem(file_system_path_spec)\n\n    if file_system_path_spec.type_indicator == definitions.TYPE_INDICATOR_OS:\n      mount_point = file_system_path_spec\n    else:\n      mount_point = file_system_path_spec.parent\n\n    self._path_resolver = windows_path_resolver.WindowsPathResolver(\n        self._file_system, mount_point)\n\n    # The source is a directory or single volume storage media image.\n    if not self._windows_directory:\n      self._ScanFileSystemForWindowsDirectory(self._path_resolver)\n\n    if not self._windows_directory:\n      return False\n\n    self._path_resolver.SetEnvironmentVariable(\n        'SystemRoot', self._windows_directory)\n    self._path_resolver.SetEnvironmentVariable(\n        'WinDir', self._windows_directory)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nflushing the cached objects for the specified format categories.", "response": "def _FlushCache(cls, format_categories):\n    \"\"\"Flushes the cached objects for the specified format categories.\n\n    Args:\n      format_categories (set[str]): format categories.\n    \"\"\"\n    if definitions.FORMAT_CATEGORY_ARCHIVE in format_categories:\n      cls._archive_remainder_list = None\n      cls._archive_scanner = None\n      cls._archive_store = None\n\n    if definitions.FORMAT_CATEGORY_COMPRESSED_STREAM in format_categories:\n      cls._compressed_stream_remainder_list = None\n      cls._compressed_stream_scanner = None\n      cls._compressed_stream_store = None\n\n    if definitions.FORMAT_CATEGORY_FILE_SYSTEM in format_categories:\n      cls._file_system_remainder_list = None\n      cls._file_system_scanner = None\n      cls._file_system_store = None\n\n    if definitions.FORMAT_CATEGORY_STORAGE_MEDIA_IMAGE in format_categories:\n      cls._storage_media_image_remainder_list = None\n      cls._storage_media_image_scanner = None\n      cls._storage_media_image_store = None\n\n    if definitions.FORMAT_CATEGORY_VOLUME_SYSTEM in format_categories:\n      cls._volume_system_remainder_list = None\n      cls._volume_system_scanner = None\n      cls._volume_system_store = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _GetSignatureScanner(cls, specification_store):\n    signature_scanner = pysigscan.scanner()\n    signature_scanner.set_scan_buffer_size(cls._SCAN_BUFFER_SIZE)\n\n    for format_specification in specification_store.specifications:\n      for signature in format_specification.signatures:\n        pattern_offset = signature.offset\n\n        if pattern_offset is None:\n          signature_flags = pysigscan.signature_flags.NO_OFFSET\n        elif pattern_offset < 0:\n          pattern_offset *= -1\n          signature_flags = pysigscan.signature_flags.RELATIVE_FROM_END\n        else:\n          signature_flags = pysigscan.signature_flags.RELATIVE_FROM_START\n\n        signature_scanner.add_signature(\n            signature.identifier, pattern_offset, signature.pattern,\n            signature_flags)\n\n    return signature_scanner", "response": "Initializes a signature scanner based on a specification store."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the format specification store for the specified format category.", "response": "def _GetSpecificationStore(cls, format_category):\n    \"\"\"Retrieves the specification store for specified format category.\n\n    Args:\n      format_category (str): format category.\n\n    Returns:\n      tuple[FormatSpecificationStore, list[AnalyzerHelper]]: a format\n          specification store and remaining analyzer helpers that do not have\n          a format specification.\n    \"\"\"\n    specification_store = specification.FormatSpecificationStore()\n    remainder_list = []\n\n    for analyzer_helper in iter(cls._analyzer_helpers.values()):\n      if not analyzer_helper.IsEnabled():\n        continue\n\n      if format_category in analyzer_helper.format_categories:\n        format_specification = analyzer_helper.GetFormatSpecification()\n\n        if format_specification is not None:\n          specification_store.AddSpecification(format_specification)\n        else:\n          remainder_list.append(analyzer_helper)\n\n    return specification_store, remainder_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines if a file contains a supported format types.", "response": "def _GetTypeIndicators(\n      cls, signature_scanner, specification_store, remainder_list, path_spec,\n      resolver_context=None):\n    \"\"\"Determines if a file contains a supported format types.\n\n    Args:\n      signature_scanner (pysigscan.scanner): signature scanner.\n      specification_store (FormatSpecificationStore): specification store.\n      remainder_list (list[AnalyzerHelper]): remaining analyzer helpers that\n          do not have a format specification.\n      path_spec (PathSpec): path specification.\n      resolver_context (Optional[Context]): resolver context, where None\n          represents the built-in context which is not multi process safe.\n\n    Returns:\n      list[str]: supported format type indicators.\n    \"\"\"\n    type_indicator_list = []\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec, resolver_context=resolver_context)\n    scan_state = pysigscan.scan_state()\n\n    try:\n      signature_scanner.scan_file_object(scan_state, file_object)\n\n      for scan_result in iter(scan_state.scan_results):\n        format_specification = specification_store.GetSpecificationBySignature(\n            scan_result.identifier)\n\n        if format_specification.identifier not in type_indicator_list:\n          type_indicator_list.append(format_specification.identifier)\n\n      for analyzer_helper in remainder_list:\n        result = analyzer_helper.AnalyzeFileObject(file_object)\n\n        if result is not None:\n          type_indicator_list.append(result)\n\n    finally:\n      file_object.close()\n\n    return type_indicator_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef DeregisterHelper(cls, analyzer_helper):\n    if analyzer_helper.type_indicator not in cls._analyzer_helpers:\n      raise KeyError(\n          'Analyzer helper object not set for type indicator: {0:s}.'.format(\n              analyzer_helper.type_indicator))\n\n    analyzer_helper = cls._analyzer_helpers[analyzer_helper.type_indicator]\n\n    cls._FlushCache(analyzer_helper.format_categories)\n\n    del cls._analyzer_helpers[analyzer_helper.type_indicator]", "response": "Deregisters a format analyzer helper."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetArchiveTypeIndicators(cls, path_spec, resolver_context=None):\n    if (cls._archive_remainder_list is None or\n        cls._archive_store is None):\n      specification_store, remainder_list = cls._GetSpecificationStore(\n          definitions.FORMAT_CATEGORY_ARCHIVE)\n      cls._archive_remainder_list = remainder_list\n      cls._archive_store = specification_store\n\n    if cls._archive_scanner is None:\n      cls._archive_scanner = cls._GetSignatureScanner(cls._archive_store)\n\n    return cls._GetTypeIndicators(\n        cls._archive_scanner, cls._archive_store,\n        cls._archive_remainder_list, path_spec,\n        resolver_context=resolver_context)", "response": "Determines if a file contains a supported archive types."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetCompressedStreamTypeIndicators(cls, path_spec, resolver_context=None):\n    if (cls._compressed_stream_remainder_list is None or\n        cls._compressed_stream_store is None):\n      specification_store, remainder_list = cls._GetSpecificationStore(\n          definitions.FORMAT_CATEGORY_COMPRESSED_STREAM)\n      cls._compressed_stream_remainder_list = remainder_list\n      cls._compressed_stream_store = specification_store\n\n    if cls._compressed_stream_scanner is None:\n      cls._compressed_stream_scanner = cls._GetSignatureScanner(\n          cls._compressed_stream_store)\n\n    return cls._GetTypeIndicators(\n        cls._compressed_stream_scanner, cls._compressed_stream_store,\n        cls._compressed_stream_remainder_list, path_spec,\n        resolver_context=resolver_context)", "response": "Determines if a file contains a supported compressed stream types."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetFileSystemTypeIndicators(cls, path_spec, resolver_context=None):\n    if (cls._file_system_remainder_list is None or\n        cls._file_system_store is None):\n      specification_store, remainder_list = cls._GetSpecificationStore(\n          definitions.FORMAT_CATEGORY_FILE_SYSTEM)\n      cls._file_system_remainder_list = remainder_list\n      cls._file_system_store = specification_store\n\n    if cls._file_system_scanner is None:\n      cls._file_system_scanner = cls._GetSignatureScanner(\n          cls._file_system_store)\n\n    return cls._GetTypeIndicators(\n        cls._file_system_scanner, cls._file_system_store,\n        cls._file_system_remainder_list, path_spec,\n        resolver_context=resolver_context)", "response": "Determines if a file contains a supported file system types."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine if a file contains a supported storage media image types.", "response": "def GetStorageMediaImageTypeIndicators(cls, path_spec, resolver_context=None):\n    \"\"\"Determines if a file contains a supported storage media image types.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      resolver_context (Optional[Context]): resolver context, where None\n          represents the built-in context which is not multi process safe.\n\n    Returns:\n      list[str]: supported format type indicators.\n    \"\"\"\n    if (cls._storage_media_image_remainder_list is None or\n        cls._storage_media_image_store is None):\n      specification_store, remainder_list = cls._GetSpecificationStore(\n          definitions.FORMAT_CATEGORY_STORAGE_MEDIA_IMAGE)\n      cls._storage_media_image_remainder_list = remainder_list\n      cls._storage_media_image_store = specification_store\n\n    if cls._storage_media_image_scanner is None:\n      cls._storage_media_image_scanner = cls._GetSignatureScanner(\n          cls._storage_media_image_store)\n\n    return cls._GetTypeIndicators(\n        cls._storage_media_image_scanner, cls._storage_media_image_store,\n        cls._storage_media_image_remainder_list, path_spec,\n        resolver_context=resolver_context)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetVolumeSystemTypeIndicators(cls, path_spec, resolver_context=None):\n    if (cls._volume_system_remainder_list is None or\n        cls._volume_system_store is None):\n      specification_store, remainder_list = cls._GetSpecificationStore(\n          definitions.FORMAT_CATEGORY_VOLUME_SYSTEM)\n      cls._volume_system_remainder_list = remainder_list\n      cls._volume_system_store = specification_store\n\n    if cls._volume_system_scanner is None:\n      cls._volume_system_scanner = cls._GetSignatureScanner(\n          cls._volume_system_store)\n\n    return cls._GetTypeIndicators(\n        cls._volume_system_scanner, cls._volume_system_store,\n        cls._volume_system_remainder_list, path_spec,\n        resolver_context=resolver_context)", "response": "Determines if a file contains a supported format type indicators."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecompresses the compressed data.", "response": "def Decompress(self, compressed_data):\n    \"\"\"Decompresses the compressed data.\n\n    Args:\n      compressed_data (bytes): compressed data.\n\n    Returns:\n      tuple(bytes, bytes): uncompressed data and remaining compressed data.\n\n    Raises:\n      BackEndError: if the zlib compressed stream cannot be decompressed.\n    \"\"\"\n    try:\n      uncompressed_data = self._zlib_decompressor.decompress(compressed_data)\n      remaining_compressed_data = getattr(\n          self._zlib_decompressor, 'unused_data', b'')\n\n    except zlib.error as exception:\n      raise errors.BackEndError((\n          'Unable to decompress zlib compressed stream with error: '\n          '{0!s}.').format(exception))\n\n    return uncompressed_data, remaining_compressed_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens the file system object defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      tsk_image_object = tsk_image.TSKFileSystemImage(file_object)\n      tsk_file_system = pytsk3.FS_Info(tsk_image_object)\n    except:\n      file_object.close()\n      raise\n\n    self._file_object = file_object\n    self._tsk_file_system = tsk_file_system"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef FileEntryExistsByPathSpec(self, path_spec):\n    # Opening a file by inode number is faster than opening a file by location.\n    tsk_file = None\n    inode = getattr(path_spec, 'inode', None)\n    location = getattr(path_spec, 'location', None)\n\n    try:\n      if inode is not None:\n        tsk_file = self._tsk_file_system.open_meta(inode=inode)\n      elif location is not None:\n        tsk_file = self._tsk_file_system.open(location)\n\n    except IOError:\n      pass\n\n    return tsk_file is not None", "response": "Determines if a file entry for a path specification exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a TSKFileEntry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      TSKFileEntry: a file entry or None if not available.\n    \"\"\"\n    # Opening a file by inode number is faster than opening a file by location.\n    tsk_file = None\n    inode = getattr(path_spec, 'inode', None)\n    location = getattr(path_spec, 'location', None)\n\n    root_inode = self.GetRootInode()\n    if (location == self.LOCATION_ROOT or\n        (inode is not None and root_inode is not None and inode == root_inode)):\n      tsk_file = self._tsk_file_system.open(self.LOCATION_ROOT)\n      return tsk_file_entry.TSKFileEntry(\n          self._resolver_context, self, path_spec, tsk_file=tsk_file,\n          is_root=True)\n\n    try:\n      if inode is not None:\n        tsk_file = self._tsk_file_system.open_meta(inode=inode)\n      elif location is not None:\n        tsk_file = self._tsk_file_system.open(location)\n\n    except IOError:\n      pass\n\n    if tsk_file is None:\n      return None\n\n    # TODO: is there a way to determine the parent inode number here?\n    return tsk_file_entry.TSKFileEntry(\n        self._resolver_context, self, path_spec, tsk_file=tsk_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the file system type.", "response": "def GetFsType(self):\n    \"\"\"Retrieves the file system type.\n\n    Returns:\n      pytsk3.TSK_FS_TYPE_ENUM: file system type.\n    \"\"\"\n    if self._tsk_fs_type is None:\n      self._tsk_fs_type = pytsk3.TSK_FS_TYPE_UNSUPP\n      if (not self._tsk_file_system or\n          not hasattr(self._tsk_file_system, 'info')):\n        return self._tsk_fs_type\n\n      self._tsk_fs_type = getattr(\n          self._tsk_file_system.info, 'ftype', pytsk3.TSK_FS_TYPE_UNSUPP)\n\n    return self._tsk_fs_type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      TSKFileEntry: a file entry.\n    \"\"\"\n    kwargs = {}\n\n    root_inode = self.GetRootInode()\n    if root_inode is not None:\n      kwargs['inode'] = root_inode\n\n    kwargs['location'] = self.LOCATION_ROOT\n    kwargs['parent'] = self._path_spec.parent\n\n    path_spec = tsk_path_spec.TSKPathSpec(**kwargs)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetTSKFileByPathSpec(self, path_spec):\n    # Opening a file by inode number is faster than opening a file\n    # by location.\n    inode = getattr(path_spec, 'inode', None)\n    location = getattr(path_spec, 'location', None)\n\n    if inode is not None:\n      tsk_file = self._tsk_file_system.open_meta(inode=inode)\n    elif location is not None:\n      tsk_file = self._tsk_file_system.open(location)\n    else:\n      raise errors.PathSpecError(\n          'Path specification missing inode and location.')\n\n    return tsk_file", "response": "Retrieves the SleuthKit file object for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef IsHFS(self):\n    tsk_fs_type = self.GetFsType()\n    return tsk_fs_type in [\n        pytsk3.TSK_FS_TYPE_HFS, pytsk3.TSK_FS_TYPE_HFS_DETECT]", "response": "Determines if the file system is HFS"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef IsNTFS(self):\n    tsk_fs_type = self.GetFsType()\n    return tsk_fs_type in [\n        pytsk3.TSK_FS_TYPE_NTFS, pytsk3.TSK_FS_TYPE_NTFS_DETECT]", "response": "Determines if the file system is NTFS."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclose the file - like object.", "response": "def _Close(self):\n    \"\"\"Closes the file-like object.\"\"\"\n    # pylint: disable=protected-access\n    super(EWFFile, self)._Close()\n\n    for file_object in self._file_objects:\n      file_object.close()\n\n    self._file_objects = []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen the file - like object defined by path specification.", "response": "def _OpenFileObject(self, path_spec):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      pyewf.handle: a file-like object or None.\n\n    Raises:\n      PathSpecError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    parent_path_spec = path_spec.parent\n\n    file_system = resolver.Resolver.OpenFileSystem(\n        parent_path_spec, resolver_context=self._resolver_context)\n\n    # Note that we cannot use pyewf's glob function since it does not\n    # handle the file system abstraction dfvfs provides.\n    segment_file_path_specs = ewf.EWFGlobPathSpec(file_system, path_spec)\n    if not segment_file_path_specs:\n      return None\n\n    if parent_path_spec.IsSystemLevel():\n      # Typically the file-like object cache should have room for 127 items.\n      self._resolver_context.SetMaximumNumberOfFileObjects(\n          len(segment_file_path_specs) + 127)\n\n    for segment_file_path_spec in segment_file_path_specs:\n      file_object = resolver.Resolver.OpenFileObject(\n          segment_file_path_spec, resolver_context=self._resolver_context)\n      self._file_objects.append(file_object)\n\n    ewf_handle = pyewf.handle()\n    ewf_handle.open_file_objects(self._file_objects)\n    return ewf_handle"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Open(self, path_spec=None, mode='rb'):\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    if path_spec.HasParent():\n      raise errors.PathSpecError('Unsupported path specification with parent.')\n\n    location = getattr(path_spec, 'location', None)\n\n    if location is None:\n      raise errors.PathSpecError('Path specification missing location.')\n\n    # Windows does not support running os.stat on device files so we use\n    # libsmdev to do an initial check.\n    try:\n      is_device = pysmdev.check_device(location)\n    except IOError as exception:\n      # Since os.stat() will not recognize Windows device file names and\n      # will return '[Error 87] The parameter is incorrect' we check here\n      # if pysmdev exception message contains ' access denied ' and raise\n      # AccessError instead.\n\n      # Note that exception.message no longer works in Python 3.\n      exception_string = str(exception)\n      if not isinstance(exception_string, py2to3.UNICODE_TYPE):\n        exception_string = py2to3.UNICODE_TYPE(\n            exception_string, errors='replace')\n\n      if ' access denied ' in exception_string:\n        raise errors.AccessError(\n            'Access denied to file: {0:s} with error: {1!s}'.format(\n                location, exception_string))\n      is_device = False\n\n    if not is_device:\n      try:\n        stat_info = os.stat(location)\n      except OSError as exception:\n        raise IOError('Unable to open file with error: {0!s}.'.format(\n            exception))\n\n      # In case the libsmdev check is not able to detect the device also use\n      # the stat information.\n      if stat.S_ISCHR(stat_info.st_mode) or stat.S_ISBLK(stat_info.st_mode):\n        is_device = True\n\n    if is_device:\n      self._file_object = pysmdev.handle()\n      self._file_object.open(location, mode=mode)\n      self._size = self._file_object.media_size\n\n    else:\n      self._file_object = open(location, mode=mode)\n      self._size = stat_info.st_size", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a byte string from the file - like object at the current offset.", "response": "def read(self, size=None):\n    \"\"\"Reads a byte string from the file-like object at the current offset.\n\n    The function will read a byte string of the specified size or\n    all of the remaining data if no size was specified.\n\n    Args:\n      size (Optional[int]): number of bytes to read, where None is all\n          remaining data.\n\n    Returns:\n      bytes: data read.\n\n    Raises:\n      IOError: if the read failed.\n      OSError: if the read failed.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if size is None:\n      size = self._size - self._file_object.tell()\n\n    return self._file_object.read(size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef seek(self, offset, whence=os.SEEK_SET):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    # For a yet unknown reason a Python file-like object on Windows allows for\n    # invalid whence values to be passed to the seek function. This check\n    # makes sure the behavior of the function is the same on all platforms.\n    if whence not in [os.SEEK_SET, os.SEEK_CUR, os.SEEK_END]:\n      raise IOError('Unsupported whence.')\n\n    self._file_object.seek(offset, whence)", "response": "Seeks to an offset within the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecompress the compressed data.", "response": "def Decompress(self, compressed_data):\n    \"\"\"Decompresses the compressed data.\n\n    Args:\n      compressed_data (bytes): compressed data.\n\n    Returns:\n      tuple(bytes, bytes): uncompressed data and remaining compressed data.\n\n    Raises:\n      BackEndError: if the BZIP2 compressed stream cannot be decompressed.\n    \"\"\"\n    try:\n      uncompressed_data = self._bz2_decompressor.decompress(compressed_data)\n      remaining_compressed_data = getattr(\n          self._bz2_decompressor, 'unused_data', b'')\n\n    except (EOFError, IOError) as exception:\n      raise errors.BackEndError((\n          'Unable to decompress BZIP2 compressed stream with error: '\n          '{0!s}.').format(exception))\n\n    return uncompressed_data, remaining_compressed_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Decrypt(self, encrypted_data):\n    decrypted_data = self._rc4_cipher.decrypt(encrypted_data)\n    return decrypted_data, b''", "response": "Decrypts the encrypted data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the database file object.", "response": "def Close(self):\n    \"\"\"Closes the database file object.\n\n    Raises:\n      IOError: if the close failed.\n      OSError: if the close failed.\n    \"\"\"\n    if self._connection:\n      self._cursor = None\n      self._connection.close()\n      self._connection = None\n\n    # TODO: move this to a central temp file manager and have it track errors.\n    # https://github.com/log2timeline/dfvfs/issues/92\n    try:\n      os.remove(self._temp_file_path)\n    except (IOError, OSError):\n      pass\n\n    self._temp_file_path = ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the number of rows in the table.", "response": "def GetNumberOfRows(self, table_name):\n    \"\"\"Retrieves the number of rows in the table.\n\n    Args:\n      table_name (str): name of the table.\n\n    Returns:\n      int: number of rows.\n\n    Raises:\n      IOError: if the file-like object has not been opened.\n      OSError: if the file-like object has not been opened.\n    \"\"\"\n    if not self._connection:\n      raise IOError('Not opened.')\n\n    self._cursor.execute(self._NUMBER_OF_ROWS_QUERY.format(table_name))\n    row = self._cursor.fetchone()\n    if not row:\n      raise IOError(\n          'Unable to retrieve number of rows of table: {0:s}'.format(\n              table_name))\n\n    number_of_rows = row[0]\n    if isinstance(number_of_rows, py2to3.STRING_TYPES):\n      try:\n        number_of_rows = int(number_of_rows, 10)\n      except ValueError as exception:\n        raise IOError((\n            'Unable to determine number of rows of table: {0:s} '\n            'with error: {1!s}').format(table_name, exception))\n\n    return number_of_rows"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if a specific column exists in the database.", "response": "def HasColumn(self, table_name, column_name):\n    \"\"\"Determines if a specific column exists.\n\n    Args:\n      table_name (str): name of the table.\n      column_name (str): name of the column.\n\n    Returns:\n      bool: True if the column exists.\n\n    Raises:\n      IOError: if the database file is not opened.\n      OSError: if the database file is not opened.\n    \"\"\"\n    if not self._connection:\n      raise IOError('Not opened.')\n\n    if not column_name:\n      return False\n\n    table_name = table_name.lower()\n    column_names = self._column_names_per_table.get(table_name, None)\n    if column_names is None:\n      column_names = []\n\n      self._cursor.execute(self._HAS_COLUMN_QUERY.format(table_name))\n      for row in self._cursor.fetchall():\n        if not row[1]:\n          continue\n\n        row_column_name = row[1]\n        if isinstance(row_column_name, bytes):\n          row_column_name = row_column_name.decode('utf-8')\n\n        column_names.append(row_column_name.lower())\n\n      self._column_names_per_table[table_name] = column_names\n\n    column_name = column_name.lower()\n    return column_name in column_names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining if a specific table exists.", "response": "def HasTable(self, table_name):\n    \"\"\"Determines if a specific table exists.\n\n    Args:\n      table_name (str): name of the table.\n\n    Returns:\n      bool: True if the column exists.\n\n    Raises:\n      IOError: if the database file is not opened.\n      OSError: if the database file is not opened.\n    \"\"\"\n    if not self._connection:\n      raise IOError('Not opened.')\n\n    if not table_name:\n      return False\n\n    if self._table_names is None:\n      self._table_names = []\n\n      self._cursor.execute(self._HAS_TABLE_QUERY)\n      for row in self._cursor.fetchall():\n        if not row[0]:\n          continue\n\n        row_table_name = row[0]\n        if isinstance(row_table_name, bytes):\n          row_table_name = row_table_name.decode('utf-8')\n\n        self._table_names.append(row_table_name.lower())\n\n    table_name = table_name.lower()\n    return table_name in self._table_names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen the database file object.", "response": "def Open(self, file_object):\n    \"\"\"Opens the database file object.\n\n    Args:\n      file_object (FileIO): file-like object.\n\n    Raises:\n      IOError: if the SQLite database signature does not match.\n      OSError: if the SQLite database signature does not match.\n      ValueError: if the file-like object is invalid.\n    \"\"\"\n    if not file_object:\n      raise ValueError('Missing file-like object.')\n\n    # Since pysqlite3 does not provide an exclusive read-only mode and\n    # cannot interact with a file-like object directly we make a temporary\n    # copy. Before making a copy we check the header signature.\n\n    file_object.seek(0, os.SEEK_SET)\n    data = file_object.read(len(self._HEADER_SIGNATURE))\n\n    if data != self._HEADER_SIGNATURE:\n      file_object.close()\n      raise IOError('Unsupported SQLite database signature.')\n\n    with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n      self._temp_file_path = temp_file.name\n      while data:\n        temp_file.write(data)\n        data = file_object.read(self._COPY_BUFFER_SIZE)\n\n    self._connection = sqlite3.connect(self._temp_file_path)\n    self._connection.text_factory = bytes\n    self._cursor = self._connection.cursor()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Query(self, query, parameters=None):\n    # TODO: catch Warning and return None.\n    # Note that we cannot pass parameters as a keyword argument here.\n    # A parameters value of None is not supported.\n    if parameters:\n      self._cursor.execute(query, parameters)\n    else:\n      self._cursor.execute(query)\n\n    return self._cursor.fetchall()", "response": "Queries the database file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining the file system cache identifier for the path specification.", "response": "def _GetFileSystemCacheIdentifier(self, path_spec):\n    \"\"\"Determines the file system cache identifier for the path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      str: identifier of the VFS object.\n    \"\"\"\n    string_parts = []\n\n    string_parts.append(getattr(path_spec.parent, 'comparable', ''))\n    string_parts.append('type: {0:s}'.format(path_spec.type_indicator))\n\n    return ''.join(string_parts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CacheFileObject(self, path_spec, file_object):\n    self._file_object_cache.CacheObject(path_spec.comparable, file_object)", "response": "Caches a file - like object based on a path specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef CacheFileSystem(self, path_spec, file_system):\n    identifier = self._GetFileSystemCacheIdentifier(path_spec)\n    self._file_system_cache.CacheObject(identifier, file_system)", "response": "Caches a file system object based on a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ForceRemoveFileObject(self, path_spec):\n    cache_value = self._file_object_cache.GetCacheValue(path_spec.comparable)\n    if not cache_value:\n      return False\n\n    while not cache_value.IsDereferenced():\n      cache_value.vfs_object.close()\n\n    return True", "response": "Forces the removal of a file - like object based on a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the reference count of a cached file - like object.", "response": "def GetFileObjectReferenceCount(self, path_spec):\n    \"\"\"Retrieves the reference count of a cached file-like object.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      int: reference count or None if there is no file-like object for\n          the corresponding path specification cached.\n    \"\"\"\n    cache_value = self._file_object_cache.GetCacheValue(path_spec.comparable)\n    if not cache_value:\n      return None\n\n    return cache_value.reference_count"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving a file system object defined by path specification.", "response": "def GetFileSystem(self, path_spec):\n    \"\"\"Retrieves a file system object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      FileSystem: a file system object or None if not cached.\n    \"\"\"\n    identifier = self._GetFileSystemCacheIdentifier(path_spec)\n    return self._file_system_cache.GetObject(identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetFileSystemReferenceCount(self, path_spec):\n    identifier = self._GetFileSystemCacheIdentifier(path_spec)\n    cache_value = self._file_system_cache.GetCacheValue(identifier)\n    if not cache_value:\n      return None\n\n    return cache_value.reference_count", "response": "Retrieves the reference count of a cached file system object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngrabs a cached file system object defined by path specification.", "response": "def GrabFileSystem(self, path_spec):\n    \"\"\"Grabs a cached file system object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n    \"\"\"\n    identifier = self._GetFileSystemCacheIdentifier(path_spec)\n    self._file_system_cache.GrabObject(identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ReleaseFileObject(self, file_object):\n    identifier, cache_value = self._file_object_cache.GetCacheValueByObject(\n        file_object)\n\n    if not identifier:\n      raise RuntimeError('Object not cached.')\n\n    if not cache_value:\n      raise RuntimeError('Invalid cache value.')\n\n    self._file_object_cache.ReleaseObject(identifier)\n\n    result = cache_value.IsDereferenced()\n    if result:\n      self._file_object_cache.RemoveObject(identifier)\n\n    return result", "response": "Releases a cached file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreleasing a cached file system object.", "response": "def ReleaseFileSystem(self, file_system):\n    \"\"\"Releases a cached file system object.\n\n    Args:\n      file_system (FileSystem): file system object.\n\n    Returns:\n      bool: True if the file system object can be closed.\n\n    Raises:\n      PathSpecError: if the path specification is incorrect.\n      RuntimeError: if the file system object is not cached or an inconsistency\n          is detected in the cache.\n    \"\"\"\n    identifier, cache_value = self._file_system_cache.GetCacheValueByObject(\n        file_system)\n\n    if not identifier:\n      raise RuntimeError('Object not cached.')\n\n    if not cache_value:\n      raise RuntimeError('Invalid cache value.')\n\n    self._file_system_cache.ReleaseObject(identifier)\n\n    result = cache_value.IsDereferenced()\n    if result:\n      self._file_system_cache.RemoveObject(identifier)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the file - like object.", "response": "def _Close(self):\n    \"\"\"Closes the file-like object.\"\"\"\n    # pylint: disable=protected-access\n    super(RawFile, self)._Close()\n\n    for file_object in self._file_objects:\n      file_object.close()\n\n    self._file_objects = []"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens the file - like object defined by path specification.", "response": "def _OpenFileObject(self, path_spec):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      pysmraw.handle: a file-like object or None.\n\n    Raises:\n      PathSpecError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    parent_path_spec = path_spec.parent\n\n    file_system = resolver.Resolver.OpenFileSystem(\n        parent_path_spec, resolver_context=self._resolver_context)\n\n    # Note that we cannot use pysmraw's glob function since it does not\n    # handle the file system abstraction dfvfs provides.\n    segment_file_path_specs = raw.RawGlobPathSpec(file_system, path_spec)\n    if not segment_file_path_specs:\n      return None\n\n    if parent_path_spec.IsSystemLevel():\n      # Typically the file-like object cache should have room for 127 items.\n      self._resolver_context.SetMaximumNumberOfFileObjects(\n          len(segment_file_path_specs) + 127)\n\n    file_objects = []\n    for segment_file_path_spec in segment_file_path_specs:\n      file_object = resolver.Resolver.OpenFileObject(\n          segment_file_path_spec, resolver_context=self._resolver_context)\n      file_objects.append(file_object)\n\n    raw_handle = pysmraw.handle()\n    raw_handle.open_file_objects(file_objects)\n    return raw_handle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Close(self):\n    if not self._file_object_set_in_init:\n      self._file_object.close()\n      self._file_object = None\n\n    self._decoder = None\n    self._decoded_data = b''\n    self._encoded_data = b''", "response": "Closes the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _GetDecodedStreamSize(self):\n    self._file_object.seek(0, os.SEEK_SET)\n\n    self._decoder = self._GetDecoder()\n    self._decoded_data = b''\n\n    encoded_data_offset = 0\n    encoded_data_size = self._file_object.get_size()\n    decoded_stream_size = 0\n\n    while encoded_data_offset < encoded_data_size:\n      read_count = self._ReadEncodedData(self._ENCODED_DATA_BUFFER_SIZE)\n      if read_count == 0:\n        break\n\n      encoded_data_offset += read_count\n      decoded_stream_size += self._decoded_data_size\n\n    return decoded_stream_size", "response": "Retrieves the decoded stream size."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _AlignDecodedDataOffset(self, decoded_data_offset):\n    self._file_object.seek(0, os.SEEK_SET)\n\n    self._decoder = self._GetDecoder()\n    self._decoded_data = b''\n\n    encoded_data_offset = 0\n    encoded_data_size = self._file_object.get_size()\n\n    while encoded_data_offset < encoded_data_size:\n      read_count = self._ReadEncodedData(self._ENCODED_DATA_BUFFER_SIZE)\n      if read_count == 0:\n        break\n\n      encoded_data_offset += read_count\n\n      if decoded_data_offset < self._decoded_data_size:\n        self._decoded_data_offset = decoded_data_offset\n        break\n\n      decoded_data_offset -= self._decoded_data_size", "response": "Aligns the encoded file with the decoded data offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ReadEncodedData(self, read_size):\n    encoded_data = self._file_object.read(read_size)\n\n    read_count = len(encoded_data)\n\n    self._encoded_data = b''.join([self._encoded_data, encoded_data])\n\n    self._decoded_data, self._encoded_data = (\n        self._decoder.Decode(self._encoded_data))\n\n    self._decoded_data_size = len(self._decoded_data)\n\n    return read_count", "response": "Reads the encoded data from the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SetDecodedStreamSize(self, decoded_stream_size):\n    if self._is_open:\n      raise IOError('Already open.')\n\n    if decoded_stream_size < 0:\n      raise ValueError((\n          'Invalid decoded stream size: {0:d} value out of '\n          'bounds.').format(decoded_stream_size))\n\n    self._decoded_stream_size = decoded_stream_size", "response": "Sets the decoded stream size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, size=None):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError(\n          'Invalid current offset: {0:d} value less than zero.'.format(\n              self._current_offset))\n\n    if self._decoded_stream_size is None:\n      self._decoded_stream_size = self._GetDecodedStreamSize()\n\n    if self._decoded_stream_size < 0:\n      raise IOError('Invalid decoded stream size.')\n\n    if self._current_offset >= self._decoded_stream_size:\n      return b''\n\n    if self._realign_offset:\n      self._AlignDecodedDataOffset(self._current_offset)\n      self._realign_offset = False\n\n    if size is None:\n      size = self._decoded_stream_size\n    if self._current_offset + size > self._decoded_stream_size:\n      size = self._decoded_stream_size - self._current_offset\n\n    decoded_data = b''\n\n    if size == 0:\n      return decoded_data\n\n    while size > self._decoded_data_size:\n      decoded_data = b''.join([\n          decoded_data,\n          self._decoded_data[self._decoded_data_offset:]])\n\n      remaining_decoded_data_size = (\n          self._decoded_data_size - self._decoded_data_offset)\n\n      self._current_offset += remaining_decoded_data_size\n      size -= remaining_decoded_data_size\n\n      if self._current_offset >= self._decoded_stream_size:\n        break\n\n      read_count = self._ReadEncodedData(self._ENCODED_DATA_BUFFER_SIZE)\n      self._decoded_data_offset = 0\n      if read_count == 0:\n        break\n\n    if size > 0:\n      slice_start_offset = self._decoded_data_offset\n      slice_end_offset = slice_start_offset + size\n\n      decoded_data = b''.join([\n          decoded_data,\n          self._decoded_data[slice_start_offset:slice_end_offset]])\n\n      self._decoded_data_offset += size\n      self._current_offset += size\n\n    return decoded_data", "response": "Reads a byte string from the file - like object at the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef seek(self, offset, whence=os.SEEK_SET):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError(\n          'Invalid current offset: {0:d} value less than zero.'.format(\n              self._current_offset))\n\n    if whence == os.SEEK_CUR:\n      offset += self._current_offset\n\n    elif whence == os.SEEK_END:\n      if self._decoded_stream_size is None:\n        self._decoded_stream_size = self._GetDecodedStreamSize()\n        if self._decoded_stream_size is None:\n          raise IOError('Invalid decoded stream size.')\n\n      offset += self._decoded_stream_size\n\n    elif whence != os.SEEK_SET:\n      raise IOError('Unsupported whence.')\n\n    if offset < 0:\n      raise IOError('Invalid offset value less than zero.')\n\n    if offset != self._current_offset:\n      self._current_offset = offset\n      self._realign_offset = True", "response": "Seeks to an offset within the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the size of the file - like object.", "response": "def get_size(self):\n    \"\"\"Retrieves the size of the file-like object.\n\n    Returns:\n      int: size of the decoded stream.\n\n    Raises:\n      IOError: if the file-like object has not been opened.\n      OSError: if the file-like object has not been opened.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._decoded_stream_size is None:\n      self._decoded_stream_size = self._GetDecodedStreamSize()\n\n    return self._decoded_stream_size"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _AddAttribute(self, attribute):\n    if attribute.identifier in self._attributes:\n      raise KeyError((\n          'Volume attribute object already set for volume attribute '\n          'identifier: {0:s}.').format(attribute.identifier))\n\n    self._attributes[attribute.identifier] = attribute", "response": "Adds an attribute to the internal list of available attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extents(self):\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    return self._extents", "response": "list of VolumeExtent objects representing volume extents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef number_of_attributes(self):\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    return len(self._attributes)", "response": "int number of attributes in the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef number_of_extents(self):\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    return len(self._extents)", "response": "int number of extents in the current node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a specific attribute within the volume.", "response": "def GetAttribute(self, identifier):\n    \"\"\"Retrieves a specific attribute.\n\n    Args:\n      identifier (str): identifier of the attribute within the volume.\n\n    Returns:\n      VolumeAttribute: volume attribute or None if not available.\n    \"\"\"\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    if identifier not in self._attributes:\n      return None\n\n    return self._attributes[identifier]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a volume to the internal list of available volumes.", "response": "def _AddVolume(self, volume):\n    \"\"\"Adds a volume.\n\n    Args:\n      volume (Volume): a volume.\n\n    Raises:\n      KeyError: if volume is already set for the corresponding volume\n          identifier.\n    \"\"\"\n    if volume.identifier in self._volumes:\n      raise KeyError(\n          'Volume object already set for volume identifier: {0:s}'.format(\n              volume.identifier))\n\n    self._volumes[volume.identifier] = volume\n    self._volume_identifiers.append(volume.identifier)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef number_of_sections(self):\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    return len(self._sections)", "response": "int number of sections in the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef number_of_volumes(self):\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    return len(self._volumes)", "response": "int number of volumes in the container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist [ VolumeExtent ] sections.", "response": "def sections(self):\n    \"\"\"list[VolumeExtent]: sections.\"\"\"\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    return self._sections"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef volumes(self):\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    return iter(self._volumes.values())", "response": "generator that returns all volumes in the volume tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetSectionByIndex(self, section_index):\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    if section_index < 0 or section_index >= len(self._sections):\n      return None\n\n    return self._sections[section_index]", "response": "Retrieves a specific section based on the index."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves a specific volume based on the identifier.", "response": "def GetVolumeByIdentifier(self, volume_identifier):\n    \"\"\"Retrieves a specific volume based on the identifier.\n\n    Args:\n      volume_identifier (str): identifier of the volume within\n          the volume system.\n\n    Returns:\n      Volume: a volume.\n    \"\"\"\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    return self._volumes[volume_identifier]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetVolumeByIndex(self, volume_index):\n    if not self._is_parsed:\n      self._Parse()\n      self._is_parsed = True\n\n    if volume_index < 0 or volume_index >= len(self._volume_identifiers):\n      return None\n\n    volume_identifier = self._volume_identifiers[volume_index]\n    return self._volumes[volume_identifier]", "response": "Retrieves a specific volume based on the index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Close(self):\n    if not self._file_object_set_in_init:\n      self._file_object.close()\n      self._file_object = None\n\n    self._compressed_data = b''\n    self._uncompressed_data = b''\n    self._decompressor = None", "response": "Closes the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the uncompressed stream size.", "response": "def _GetUncompressedStreamSize(self):\n    \"\"\"Retrieves the uncompressed stream size.\n\n    Returns:\n      int: uncompressed stream size.\n    \"\"\"\n    self._file_object.seek(0, os.SEEK_SET)\n\n    self._decompressor = self._GetDecompressor()\n    self._uncompressed_data = b''\n\n    compressed_data_offset = 0\n    compressed_data_size = self._file_object.get_size()\n    uncompressed_stream_size = 0\n\n    while compressed_data_offset < compressed_data_size:\n      read_count = self._ReadCompressedData(self._COMPRESSED_DATA_BUFFER_SIZE)\n      if read_count == 0:\n        break\n\n      compressed_data_offset += read_count\n      uncompressed_stream_size += self._uncompressed_data_size\n\n    return uncompressed_stream_size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\naligning the compressed file with the uncompressed data offset.", "response": "def _AlignUncompressedDataOffset(self, uncompressed_data_offset):\n    \"\"\"Aligns the compressed file with the uncompressed data offset.\n\n    Args:\n      uncompressed_data_offset (int): uncompressed data offset.\n    \"\"\"\n    self._file_object.seek(0, os.SEEK_SET)\n\n    self._decompressor = self._GetDecompressor()\n    self._uncompressed_data = b''\n\n    compressed_data_offset = 0\n    compressed_data_size = self._file_object.get_size()\n\n    while compressed_data_offset < compressed_data_size:\n      read_count = self._ReadCompressedData(self._COMPRESSED_DATA_BUFFER_SIZE)\n      if read_count == 0:\n        break\n\n      compressed_data_offset += read_count\n\n      if uncompressed_data_offset < self._uncompressed_data_size:\n        self._uncompressed_data_offset = uncompressed_data_offset\n        break\n\n      uncompressed_data_offset -= self._uncompressed_data_size"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ReadCompressedData(self, read_size):\n    compressed_data = self._file_object.read(read_size)\n\n    read_count = len(compressed_data)\n\n    self._compressed_data = b''.join([self._compressed_data, compressed_data])\n\n    self._uncompressed_data, self._compressed_data = (\n        self._decompressor.Decompress(self._compressed_data))\n\n    self._uncompressed_data_size = len(self._uncompressed_data)\n\n    return read_count", "response": "Reads compressed data from the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, size=None):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError(\n          'Invalid current offset: {0:d} value less than zero.'.format(\n              self._current_offset))\n\n    if self._uncompressed_stream_size is None:\n      self._uncompressed_stream_size = self._GetUncompressedStreamSize()\n\n    if self._uncompressed_stream_size < 0:\n      raise IOError('Invalid uncompressed stream size.')\n\n    if self._current_offset >= self._uncompressed_stream_size:\n      return b''\n\n    if self._realign_offset:\n      self._AlignUncompressedDataOffset(self._current_offset)\n      self._realign_offset = False\n\n    if size is None:\n      size = self._uncompressed_stream_size\n    if self._current_offset + size > self._uncompressed_stream_size:\n      size = self._uncompressed_stream_size - self._current_offset\n\n    uncompressed_data = b''\n\n    if size == 0:\n      return uncompressed_data\n\n    while size > self._uncompressed_data_size:\n      uncompressed_data = b''.join([\n          uncompressed_data,\n          self._uncompressed_data[self._uncompressed_data_offset:]])\n\n      remaining_uncompressed_data_size = (\n          self._uncompressed_data_size - self._uncompressed_data_offset)\n\n      self._current_offset += remaining_uncompressed_data_size\n      size -= remaining_uncompressed_data_size\n\n      if self._current_offset >= self._uncompressed_stream_size:\n        break\n\n      read_count = self._ReadCompressedData(self._COMPRESSED_DATA_BUFFER_SIZE)\n      self._uncompressed_data_offset = 0\n      if read_count == 0:\n        break\n\n    if size > 0:\n      slice_start_offset = self._uncompressed_data_offset\n      slice_end_offset = slice_start_offset + size\n\n      uncompressed_data = b''.join([\n          uncompressed_data,\n          self._uncompressed_data[slice_start_offset:slice_end_offset]])\n\n      self._uncompressed_data_offset += size\n      self._current_offset += size\n\n    return uncompressed_data", "response": "Reads a byte string from the file - like object at the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef seek(self, offset, whence=os.SEEK_SET):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError(\n          'Invalid current offset: {0:d} value less than zero.'.format(\n              self._current_offset))\n\n    if whence == os.SEEK_CUR:\n      offset += self._current_offset\n\n    elif whence == os.SEEK_END:\n      if self._uncompressed_stream_size is None:\n        self._uncompressed_stream_size = self._GetUncompressedStreamSize()\n        if self._uncompressed_stream_size is None:\n          raise IOError('Invalid uncompressed stream size.')\n\n      offset += self._uncompressed_stream_size\n\n    elif whence != os.SEEK_SET:\n      raise IOError('Unsupported whence.')\n\n    if offset < 0:\n      raise IOError('Invalid offset value less than zero.')\n\n    if offset != self._current_offset:\n      self._current_offset = offset\n      self._realign_offset = True", "response": "Seeks to an offset within the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_size(self):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._uncompressed_stream_size is None:\n      self._uncompressed_stream_size = self._GetUncompressedStreamSize()\n\n    return self._uncompressed_stream_size", "response": "Retrieves the size of the uncompressed stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening the file - like object defined by path specification.", "response": "def _Open(self, path_spec=None, mode='rb'):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file-like object could not be opened.\n      OSError: if the file-like object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    self._file_system = resolver.Resolver.OpenFileSystem(\n        path_spec, resolver_context=self._resolver_context)\n    tsk_volume = self._file_system.GetTSKVolume()\n    tsk_vs, _ = tsk_partition.GetTSKVsPartByPathSpec(tsk_volume, path_spec)\n\n    if tsk_vs is None:\n      raise errors.PathSpecError(\n          'Unable to retrieve TSK volume system part from path '\n          'specification.')\n\n    range_offset = tsk_partition.TSKVsPartGetStartSector(tsk_vs)\n    range_size = tsk_partition.TSKVsPartGetNumberOfSectors(tsk_vs)\n\n    if range_offset is None or range_size is None:\n      raise errors.PathSpecError(\n          'Unable to retrieve TSK volume system part data range from path '\n          'specification.')\n\n    bytes_per_sector = tsk_partition.TSKVolumeGetBytesPerSector(tsk_volume)\n    range_offset *= bytes_per_sector\n    range_size *= bytes_per_sector\n\n    self.SetRange(range_offset, range_size)\n    self._file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n    self._file_object_set_in_init = True\n\n    # pylint: disable=protected-access\n    super(TSKPartitionFile, self)._Open(path_spec=path_spec, mode=mode)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the VFSStat object for the current file entry.", "response": "def _GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object.\n    \"\"\"\n    stat_object = vfs_stat.VFSStat()\n\n    if self._compressed_stream:\n      stat_object.size = self._compressed_stream.get_size()\n\n    stat_object.type = self.entry_type\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _Close(self):\n    self._vshadow_volume.close()\n    self._vshadow_volume = None\n\n    self._file_object.close()\n    self._file_object = None", "response": "Closes the file system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _Open(self, path_spec, mode='rb'):\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      vshadow_volume = pyvshadow.volume()\n      vshadow_volume.open_file_object(file_object)\n    except:\n      file_object.close()\n      raise\n\n    self._file_object = file_object\n    self._vshadow_volume = vshadow_volume", "response": "Opens the file system object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef FileEntryExistsByPathSpec(self, path_spec):\n    store_index = vshadow.VShadowPathSpecGetStoreIndex(path_spec)\n\n    # The virtual root file has not corresponding store index but\n    # should have a location.\n    if store_index is None:\n      location = getattr(path_spec, 'location', None)\n      return location is not None and location == self.LOCATION_ROOT\n\n    return 0 <= store_index < self._vshadow_volume.number_of_stores", "response": "Determines if a file entry for a path specification exists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      VShadowFileEntry: file entry or None if not available.\n    \"\"\"\n    store_index = vshadow.VShadowPathSpecGetStoreIndex(path_spec)\n\n    # The virtual root file has not corresponding store index but\n    # should have a location.\n    if store_index is None:\n      location = getattr(path_spec, 'location', None)\n      if location is None or location != self.LOCATION_ROOT:\n        return None\n\n      return vshadow_file_entry.VShadowFileEntry(\n          self._resolver_context, self, path_spec, is_root=True,\n          is_virtual=True)\n\n    if store_index < 0 or store_index >= self._vshadow_volume.number_of_stores:\n      return None\n\n    return vshadow_file_entry.VShadowFileEntry(\n        self._resolver_context, self, path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      VShadowFileEntry: file entry or None if not available.\n    \"\"\"\n    path_spec = vshadow_path_spec.VShadowPathSpec(\n        location=self.LOCATION_ROOT, parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetVShadowStoreByPathSpec(self, path_spec):\n    store_index = vshadow.VShadowPathSpecGetStoreIndex(path_spec)\n    if store_index is None:\n      return None\n\n    return self._vshadow_volume.get_store(store_index)", "response": "Retrieves a VSS store for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _Close(self):\n    self._tsk_attribute = None\n    self._tsk_file = None\n\n    self._file_system.Close()\n    self._file_system = None", "response": "Closes the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening the file - like object defined by path specification.", "response": "def _Open(self, path_spec=None, mode='rb'):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file-like object could not be opened.\n      OSError: if the file-like object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    data_stream = getattr(path_spec, 'data_stream', None)\n\n    file_system = resolver.Resolver.OpenFileSystem(\n        path_spec, resolver_context=self._resolver_context)\n\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n    if not file_entry:\n      file_system.Close()\n      raise IOError('Unable to retrieve file entry.')\n\n    tsk_file = file_entry.GetTSKFile()\n    tsk_attribute = None\n\n    # Note that because pytsk3.File does not explicitly defines info\n    # we need to check if the attribute exists and has a value other\n    # than None.\n    if getattr(tsk_file, 'info', None) is None:\n      file_system.Close()\n      raise IOError('Missing attribute info in file (pytsk3.File).')\n\n    # Note that because pytsk3.TSK_FS_FILE does not explicitly defines meta\n    # we need to check if the attribute exists and has a value other\n    # than None.\n    if getattr(tsk_file.info, 'meta', None) is None:\n      file_system.Close()\n      raise IOError(\n          'Missing attribute meta in file.info pytsk3.TSK_FS_FILE).')\n\n    # Note that because pytsk3.TSK_FS_META does not explicitly defines size\n    # we need to check if the attribute exists.\n    if not hasattr(tsk_file.info.meta, 'size'):\n      file_system.Close()\n      raise IOError(\n          'Missing attribute size in file.info.meta (pytsk3.TSK_FS_META).')\n\n    # Note that because pytsk3.TSK_FS_META does not explicitly defines type\n    # we need to check if the attribute exists.\n    if not hasattr(tsk_file.info.meta, 'type'):\n      file_system.Close()\n      raise IOError(\n          'Missing attribute type in file.info.meta (pytsk3.TSK_FS_META).')\n\n    if data_stream:\n      for attribute in tsk_file:\n        if getattr(attribute, 'info', None) is None:\n          continue\n\n        # The value of the attribute name will be None for the default\n        # data stream.\n        attribute_name = getattr(attribute.info, 'name', None)\n        if attribute_name is None:\n          attribute_name = ''\n\n        else:\n          try:\n            # pytsk3 returns an UTF-8 encoded byte string.\n            attribute_name = attribute_name.decode('utf8')\n          except UnicodeError:\n            # Continue here since we cannot represent the attribute name.\n            continue\n\n        attribute_type = getattr(attribute.info, 'type', None)\n        if attribute_name == data_stream and attribute_type in (\n            pytsk3.TSK_FS_ATTR_TYPE_HFS_DEFAULT,\n            pytsk3.TSK_FS_ATTR_TYPE_HFS_DATA,\n            pytsk3.TSK_FS_ATTR_TYPE_NTFS_DATA):\n          tsk_attribute = attribute\n          break\n\n      if tsk_attribute is None:\n        file_system.Close()\n        raise IOError('Unable to open data stream: {0:s}.'.format(data_stream))\n\n    if (not tsk_attribute and\n        tsk_file.info.meta.type != pytsk3.TSK_FS_META_TYPE_REG):\n      file_system.Close()\n      raise IOError('Not a regular file.')\n\n    self._current_offset = 0\n    self._file_system = file_system\n    self._tsk_attribute = tsk_attribute\n    self._tsk_file = tsk_file\n\n    if self._tsk_attribute:\n      self._size = self._tsk_attribute.info.size\n    else:\n      self._size = self._tsk_file.info.meta.size"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, size=None):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError('Invalid current offset value less than zero.')\n\n    # The SleuthKit is not POSIX compliant in its read behavior. Therefore\n    # pytsk3 will raise an IOError if the read offset is beyond the data size.\n    if self._current_offset >= self._size:\n      return b''\n\n    if size is None or self._current_offset + size > self._size:\n      size = self._size - self._current_offset\n\n    if self._tsk_attribute:\n      data = self._tsk_file.read_random(\n          self._current_offset, size, self._tsk_attribute.info.type,\n          self._tsk_attribute.info.id)\n    else:\n      data = self._tsk_file.read_random(self._current_offset, size)\n\n    # It is possible the that returned data size is not the same as the\n    # requested data size. At this layer we don't care and this discrepancy\n    # should be dealt with on a higher layer if necessary.\n    self._current_offset += len(data)\n\n    return data", "response": "Reads a byte string from the file - like object at the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Parse(self):\n    vslvm_logical_volume = self._file_entry.GetLVMLogicalVolume()\n\n    volume_attribute = volume_system.VolumeAttribute(\n        'identifier', vslvm_logical_volume.identifier)\n    self._AddAttribute(volume_attribute)\n\n    # TODO: implement in pyvslvm\n    # TODO: add support for creation time\n    # TODO: add support for logical volume extents\n    volume_extent = volume_system.VolumeExtent(0, vslvm_logical_volume.size)\n    self._extents.append(volume_extent)", "response": "Extracts attributes and extents from the volume."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deprecated(function):  # pylint: disable=invalid-name\n\n  def IssueDeprecationWarning(*args, **kwargs):\n    \"\"\"Issue a deprecation warning.\"\"\"\n    warnings.simplefilter('default', DeprecationWarning)\n    warnings.warn('Call to deprecated function: {0:s}.'.format(\n        function.__name__), category=DeprecationWarning, stacklevel=2)\n\n    return function(*args, **kwargs)\n\n  IssueDeprecationWarning.__name__ = function.__name__\n  IssueDeprecationWarning.__doc__ = function.__doc__\n  IssueDeprecationWarning.__dict__.update(function.__dict__)\n  return IssueDeprecationWarning", "response": "Decorator to mark functions or methods as deprecated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _Close(self):\n    if self._zip_ext_file:\n      self._zip_ext_file.close()\n      self._zip_ext_file = None\n\n    self._zip_file = None\n    self._zip_info = None\n\n    self._file_system.Close()\n    self._file_system = None", "response": "Closes the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen the file - like object defined by path specification.", "response": "def _Open(self, path_spec=None, mode='rb'):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (Optional[PathSpec]): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file-like object could not be opened.\n      OSError: if the file-like object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    file_system = resolver.Resolver.OpenFileSystem(\n        path_spec, resolver_context=self._resolver_context)\n\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n    if not file_entry:\n      file_system.Close()\n      raise IOError('Unable to retrieve file entry.')\n\n    if not file_entry.IsFile():\n      file_system.Close()\n      raise IOError('Not a regular file.')\n\n    self._file_system = file_system\n    self._zip_file = self._file_system.GetZipFile()\n    self._zip_info = file_entry.GetZipInfo()\n\n    self._current_offset = 0\n    self._uncompressed_stream_size = self._zip_info.file_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _AlignUncompressedDataOffset(self, uncompressed_data_offset):\n    if self._zip_ext_file:\n      self._zip_ext_file.close()\n      self._zip_ext_file = None\n\n    try:\n      # The open can fail if the file path in the local file header\n      # does not use the same path segment separator as the corresponding\n      # entry in the central directory.\n      self._zip_ext_file = self._zip_file.open(self._zip_info, 'r')\n    except zipfile.BadZipfile as exception:\n      raise IOError(\n          'Unable to open ZIP file with error: {0!s}'.format(exception))\n\n    self._uncompressed_data = b''\n    self._uncompressed_data_size = 0\n    self._uncompressed_data_offset = 0\n\n    while uncompressed_data_offset > 0:\n      self._ReadCompressedData(self._UNCOMPRESSED_DATA_BUFFER_SIZE)\n\n      if uncompressed_data_offset < self._uncompressed_data_size:\n        self._uncompressed_data_offset = uncompressed_data_offset\n        break\n\n      uncompressed_data_offset -= self._uncompressed_data_size", "response": "Aligns the compressed file with the uncompressed data offset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ReadCompressedData(self, read_size):\n    self._uncompressed_data = self._zip_ext_file.read(read_size)\n    self._uncompressed_data_size = len(self._uncompressed_data)", "response": "Reads compressed data from the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nanalyzes the format specification of a file - like object.", "response": "def AnalyzeFileObject(self, file_object):\n    \"\"\"Retrieves the format specification.\n\n    Args:\n      file_object (FileIO): file-like object.\n\n    Returns:\n      str: type indicator if the file-like object contains a supported format\n          or None otherwise.\n    \"\"\"\n    tsk_image_object = tsk_image.TSKFileSystemImage(file_object)\n\n    try:\n      pytsk3.Volume_Info(tsk_image_object)\n    except IOError:\n      return None\n\n    return self.type_indicator"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the file entry type find specifications.", "response": "def _CheckFileEntryType(self, file_entry):\n    \"\"\"Checks the file entry type find specifications.\n\n    Args:\n      file_entry (FileEntry): file entry.\n\n    Returns:\n      bool: True if the file entry matches the find specification, False if\n          not or None if no file entry type specification is defined.\n    \"\"\"\n    if not self._file_entry_types:\n      return None\n\n    return (\n        self._CheckIsDevice(file_entry) or self._CheckIsDirectory(file_entry) or\n        self._CheckIsFile(file_entry) or self._CheckIsLink(file_entry) or\n        self._CheckIsPipe(file_entry) or self._CheckIsSocket(file_entry))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the is_device find specification.", "response": "def _CheckIsDevice(self, file_entry):\n    \"\"\"Checks the is_device find specification.\n\n    Args:\n      file_entry (FileEntry): file entry.\n\n    Returns:\n      bool: True if the file entry matches the find specification, False if not.\n    \"\"\"\n    if definitions.FILE_ENTRY_TYPE_DEVICE not in self._file_entry_types:\n      return False\n    return file_entry.IsDevice()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _CheckIsDirectory(self, file_entry):\n    if definitions.FILE_ENTRY_TYPE_DIRECTORY not in self._file_entry_types:\n      return False\n    return file_entry.IsDirectory()", "response": "Checks the is_directory find specification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _CheckIsFile(self, file_entry):\n    if definitions.FILE_ENTRY_TYPE_FILE not in self._file_entry_types:\n      return False\n    return file_entry.IsFile()", "response": "Checks the is_file find specification."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _CheckIsLink(self, file_entry):\n    if definitions.FILE_ENTRY_TYPE_LINK not in self._file_entry_types:\n      return False\n    return file_entry.IsLink()", "response": "Checks the is_link find specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the is_pipe find specification.", "response": "def _CheckIsPipe(self, file_entry):\n    \"\"\"Checks the is_pipe find specification.\n\n    Args:\n      file_entry (FileEntry): file entry.\n\n    Returns:\n      bool: True if the file entry matches the find specification, False if not.\n    \"\"\"\n    if definitions.FILE_ENTRY_TYPE_PIPE not in self._file_entry_types:\n      return False\n    return file_entry.IsPipe()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _CheckIsSocket(self, file_entry):\n    if definitions.FILE_ENTRY_TYPE_SOCKET not in self._file_entry_types:\n      return False\n    return file_entry.IsSocket()", "response": "Checks the is_socket find specification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking the location find specification.", "response": "def _CheckLocation(self, file_entry, search_depth):\n    \"\"\"Checks the location find specification.\n\n    Args:\n      file_entry (FileEntry): file entry.\n      search_depth (int): number of location path segments to compare.\n\n    Returns:\n      bool: True if the file entry matches the find specification, False if not.\n    \"\"\"\n    if self._location_segments is None:\n      return False\n\n    if search_depth < 0 or search_depth > self._number_of_location_segments:\n      return False\n\n    # Note that the root has no entry in the location segments and\n    # no name to match.\n    if search_depth == 0:\n      segment_name = ''\n    else:\n      segment_name = self._location_segments[search_depth - 1]\n\n      if self._is_regex:\n        if isinstance(segment_name, py2to3.STRING_TYPES):\n          # Allow '\\n' to be matched by '.' and make '\\w', '\\W', '\\b', '\\B',\n          # '\\d', '\\D', '\\s' and '\\S' Unicode safe.\n          flags = re.DOTALL | re.UNICODE\n          if not self._is_case_sensitive:\n            flags |= re.IGNORECASE\n\n          try:\n            segment_name = r'^{0:s}$'.format(segment_name)\n            segment_name = re.compile(segment_name, flags=flags)\n          except sre_constants.error:\n            # TODO: set self._location_segments[search_depth - 1] to None ?\n            return False\n\n          self._location_segments[search_depth - 1] = segment_name\n\n      elif not self._is_case_sensitive:\n        segment_name = segment_name.lower()\n        self._location_segments[search_depth - 1] = segment_name\n\n    if search_depth > 0:\n      if self._is_regex:\n        if not segment_name.match(file_entry.name):  # pylint: disable=no-member\n          return False\n\n      elif self._is_case_sensitive:\n        if segment_name != file_entry.name:\n          return False\n\n      elif segment_name != file_entry.name.lower():\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if the find specification is at maximum depth.", "response": "def AtMaximumDepth(self, search_depth):\n    \"\"\"Determines if the find specification is at maximum depth.\n\n    Args:\n      search_depth (int): number of location path segments to compare.\n\n    Returns:\n      bool: True if at maximum depth, False if not.\n    \"\"\"\n    if self._location_segments is not None:\n      if search_depth >= self._number_of_location_segments:\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Matches(self, file_entry, search_depth):\n    if self._location_segments is None:\n      location_match = None\n    else:\n      location_match = self._CheckLocation(file_entry, search_depth)\n      if not location_match:\n        return False, location_match\n\n      if search_depth != self._number_of_location_segments:\n        return False, location_match\n\n    match = self._CheckFileEntryType(file_entry)\n    if match is not None and not match:\n      return False, location_match\n\n    match = self._CheckIsAllocated(file_entry)\n    if match is not None and not match:\n      return False, location_match\n\n    return True, location_match", "response": "Determines if the file entry matches the find specification."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef PrepareMatches(self, file_system):\n    if self._location is not None:\n      self._location_segments = self._SplitPath(\n          self._location, file_system.PATH_SEPARATOR)\n\n    elif self._location_regex is not None:\n      path_separator = file_system.PATH_SEPARATOR\n      if path_separator == '\\\\':\n        # The backslash '\\' is escaped within a regular expression.\n        path_separator = '\\\\\\\\'\n\n      self._location_segments = self._SplitPath(\n          self._location_regex, path_separator)\n\n    if self._location_segments is not None:\n      self._number_of_location_segments = len(self._location_segments)", "response": "Prepares the find specification for matching."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _FindInFileEntry(self, file_entry, find_specs, search_depth):\n    sub_find_specs = []\n    for find_spec in find_specs:\n      match, location_match = find_spec.Matches(file_entry, search_depth)\n      if match:\n        yield file_entry.path_spec\n\n      # pylint: disable=singleton-comparison\n      if location_match != False and not find_spec.AtMaximumDepth(search_depth):\n        sub_find_specs.append(find_spec)\n\n    if not sub_find_specs:\n      return\n\n    search_depth += 1\n    try:\n      for sub_file_entry in file_entry.sub_file_entries:\n        for matching_path_spec in self._FindInFileEntry(\n            sub_file_entry, sub_find_specs, search_depth):\n          yield matching_path_spec\n    except errors.AccessError:\n      pass", "response": "Searches for matching file entries within a file entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for matching file entries within the file system.", "response": "def Find(self, find_specs=None):\n    \"\"\"Searches for matching file entries within the file system.\n\n    Args:\n      find_specs (list[FindSpec]): find specifications. where None\n          will return all allocated file entries.\n\n    Yields:\n      PathSpec: path specification of a matching file entry.\n    \"\"\"\n    if not find_specs:\n      find_specs.append(FindSpec())\n\n    for find_spec in find_specs:\n      find_spec.PrepareMatches(self._file_system)\n\n    if path_spec_factory.Factory.IsSystemLevelTypeIndicator(\n        self._file_system.type_indicator):\n      file_entry = self._file_system.GetFileEntryByPathSpec(self._mount_point)\n    else:\n      file_entry = self._file_system.GetRootFileEntry()\n\n    for matching_path_spec in self._FindInFileEntry(file_entry, find_specs, 0):\n      yield matching_path_spec"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetRelativePath(self, path_spec):\n    location = getattr(path_spec, 'location', None)\n    if location is None:\n      raise errors.PathSpecError('Path specification missing location.')\n\n    if path_spec_factory.Factory.IsSystemLevelTypeIndicator(\n        self._file_system.type_indicator):\n      if not location.startswith(self._mount_point.location):\n        raise errors.PathSpecError(\n            'Path specification does not contain mount point.')\n    else:\n      if not hasattr(path_spec, 'parent'):\n        raise errors.PathSpecError('Path specification missing parent.')\n\n      if path_spec.parent != self._mount_point:\n        raise errors.PathSpecError(\n            'Path specification does not contain mount point.')\n\n    path_segments = self._file_system.SplitPath(location)\n\n    if path_spec_factory.Factory.IsSystemLevelTypeIndicator(\n        self._file_system.type_indicator):\n      mount_point_path_segments = self._file_system.SplitPath(\n          self._mount_point.location)\n      path_segments = path_segments[len(mount_point_path_segments):]\n\n    return '{0:s}{1:s}'.format(\n        self._file_system.PATH_SEPARATOR,\n        self._file_system.PATH_SEPARATOR.join(path_segments))", "response": "Retrieves the relative path based on a resolved path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens the file system object defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n      mode (Optional[str]): file access mode. The default is 'rb' which\n          represents read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      tsk_image_object = tsk_image.TSKFileSystemImage(file_object)\n      tsk_volume = pytsk3.Volume_Info(tsk_image_object)\n    except:\n      file_object.close()\n      raise\n\n    self._file_object = file_object\n    self._tsk_volume = tsk_volume"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if a file entry for a path specification exists.", "response": "def FileEntryExistsByPathSpec(self, path_spec):\n    \"\"\"Determines if a file entry for a path specification exists.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n\n    Returns:\n      bool: True if the file entry exists or false otherwise.\n    \"\"\"\n    tsk_vs_part, _ = tsk_partition.GetTSKVsPartByPathSpec(\n        self._tsk_volume, path_spec)\n\n    # The virtual root file has not corresponding TSK volume system part object\n    # but should have a location.\n    if tsk_vs_part is None:\n      location = getattr(path_spec, 'location', None)\n      return location is not None and location == self.LOCATION_ROOT\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a TSKPartitionFileEntry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n\n    Returns:\n      TSKPartitionFileEntry: a file entry or None of not available.\n    \"\"\"\n    tsk_vs_part, partition_index = tsk_partition.GetTSKVsPartByPathSpec(\n        self._tsk_volume, path_spec)\n\n    location = getattr(path_spec, 'location', None)\n\n    # The virtual root file has not corresponding TSK volume system part object\n    # but should have a location.\n    if tsk_vs_part is None:\n      if location is None or location != self.LOCATION_ROOT:\n        return None\n\n      return tsk_partition_file_entry.TSKPartitionFileEntry(\n          self._resolver_context, self, path_spec, is_root=True,\n          is_virtual=True)\n\n    if location is None and partition_index is not None:\n      path_spec.location = '/p{0:d}'.format(partition_index)\n\n    return tsk_partition_file_entry.TSKPartitionFileEntry(\n        self._resolver_context, self, path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      TSKPartitionFileEntry: a file entry or None of not available.\n    \"\"\"\n    path_spec = tsk_partition_path_spec.TSKPartitionPathSpec(\n        location=self.LOCATION_ROOT, parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve directory entries. Since a directory can contain a vast number of entries using a generator is more memory efficient. Yields: APFSPathSpec: APFS path specification.", "response": "def _EntriesGenerator(self):\n    \"\"\"Retrieves directory entries.\n\n    Since a directory can contain a vast number of entries using\n    a generator is more memory efficient.\n\n    Yields:\n      APFSPathSpec: APFS path specification.\n    \"\"\"\n    try:\n      fsapfs_file_entry = self._file_system.GetAPFSFileEntryByPathSpec(\n          self.path_spec)\n    except errors.PathSpecError:\n      return\n\n    location = getattr(self.path_spec, 'location', None)\n\n    for fsapfs_sub_file_entry in fsapfs_file_entry.sub_file_entries:\n      directory_entry = fsapfs_sub_file_entry.name\n\n      if location == self._file_system.PATH_SEPARATOR:\n        directory_entry = self._file_system.JoinPath([directory_entry])\n      else:\n        directory_entry = self._file_system.JoinPath([\n            location, directory_entry])\n\n      yield apfs_path_spec.APFSPathSpec(\n          identifier=fsapfs_sub_file_entry.identifier, location=directory_entry,\n          parent=self.path_spec.parent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _GetDirectory(self):\n    if self._fsapfs_file_entry.number_of_sub_file_entries <= 0:\n      return None\n\n    return APFSDirectory(self._file_system, self.path_spec)", "response": "Retrieves a directory.\n\n    Returns:\n      APFSDirectory: directory or None if not available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the link. Returns: str: path of the linked file.", "response": "def _GetLink(self):\n    \"\"\"Retrieves the link.\n\n    Returns:\n      str: path of the linked file.\n    \"\"\"\n    if self._link is None:\n      self._link = ''\n      if self.entry_type != definitions.FILE_ENTRY_TYPE_LINK:\n        return self._link\n\n      link = self._fsapfs_file_entry.symbolic_link_target\n      if link and link[0] != self._file_system.PATH_SEPARATOR:\n        # TODO: make link absolute.\n        self._link = '/{0:s}'.format(link)\n\n    return self._link"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve information about the file entry.", "response": "def _GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object.\n    \"\"\"\n    stat_object = super(APFSFileEntry, self)._GetStat()\n\n    # File data stat information.\n    stat_object.size = self._fsapfs_file_entry.size\n\n    # Ownership and permissions stat information.\n    stat_object.mode = self._fsapfs_file_entry.file_mode & 0x0fff\n    stat_object.uid = self._fsapfs_file_entry.owner_identifier\n    stat_object.gid = self._fsapfs_file_entry.group_identifier\n\n    # File entry type stat information.\n    stat_object.type = self.entry_type\n\n    # Other stat information.\n    stat_object.ino = self._fsapfs_file_entry.identifier\n    stat_object.fs_type = 'APFS'\n\n    stat_object.is_allocated = True\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the current access time of the APK.", "response": "def access_time(self):\n    \"\"\"dfdatetime.DateTimeValues: access time or None if not available.\"\"\"\n    timestamp = self._fsapfs_file_entry.get_access_time_as_integer()\n    return dfdatetime_apfs_time.APFSTime(timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef change_time(self):\n    timestamp = self._fsapfs_file_entry.get_inode_change_time_as_integer()\n    return dfdatetime_apfs_time.APFSTime(timestamp=timestamp)", "response": "Returns the current change time of the APK."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef creation_time(self):\n    timestamp = self._fsapfs_file_entry.get_creation_time_as_integer()\n    return dfdatetime_apfs_time.APFSTime(timestamp=timestamp)", "response": "Return the creation time of the APK."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the modification time of the APK.", "response": "def modification_time(self):\n    \"\"\"dfdatetime.DateTimeValues: modification time or None if not available.\"\"\"\n    timestamp = self._fsapfs_file_entry.get_modification_time_as_integer()\n    return dfdatetime_apfs_time.APFSTime(timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetLinkedFileEntry(self):\n    link = self._GetLink()\n    if not link:\n      return None\n\n    # TODO: is there a way to determine the identifier here?\n    link_identifier = None\n\n    parent_path_spec = getattr(self.path_spec, 'parent', None)\n    path_spec = apfs_path_spec.APFSPathSpec(\n        location=link, parent=parent_path_spec)\n\n    is_root = bool(\n        link == self._file_system.LOCATION_ROOT or\n        link_identifier == self._file_system.ROOT_DIRECTORY_IDENTIFIER)\n\n    return APFSFileEntry(\n        self._resolver_context, self._file_system, path_spec, is_root=is_root)", "response": "Retrieves the linked file entry e. g. for a symbolic link."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the parent file entry.", "response": "def GetParentFileEntry(self):\n    \"\"\"Retrieves the parent file entry.\n\n    Returns:\n      APFSFileEntry: parent file entry or None if not available.\n    \"\"\"\n    parent_location = None\n\n    location = getattr(self.path_spec, 'location', None)\n    if location is not None:\n      parent_location = self._file_system.DirnamePath(location)\n      if parent_location == '':\n        parent_location = self._file_system.PATH_SEPARATOR\n\n    parent_identifier = self._fsapfs_file_entry.parent_identifier\n    if parent_identifier is None:\n      return None\n\n    parent_path_spec = getattr(self.path_spec, 'parent', None)\n    path_spec = apfs_path_spec.APFSPathSpec(\n        location=parent_location, identifier=parent_identifier,\n        parent=parent_path_spec)\n\n    is_root = bool(\n        parent_location == self._file_system.LOCATION_ROOT or\n        parent_identifier == self._file_system.ROOT_DIRECTORY_IDENTIFIER)\n\n    return APFSFileEntry(\n        self._resolver_context, self._file_system, path_spec, is_root=is_root)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen the file - like object defined by path specification.", "response": "def _Open(self, path_spec=None, mode='rb'):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file-like object could not be opened.\n      OSError: if the file-like object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec:\n      raise ValueError('Missing path specfication.')\n\n    volume_index = lvm.LVMPathSpecGetVolumeIndex(path_spec)\n    if volume_index is None:\n      raise errors.PathSpecError(\n          'Unable to retrieve volume index from path specification.')\n\n    self._file_system = resolver.Resolver.OpenFileSystem(\n        path_spec, resolver_context=self._resolver_context)\n    vslvm_volume_group = self._file_system.GetLVMVolumeGroup()\n\n    if (volume_index < 0 or\n        volume_index >= vslvm_volume_group.number_of_logical_volumes):\n      raise errors.PathSpecError((\n          'Unable to retrieve LVM logical volume index: {0:d} from path '\n          'specification.').format(volume_index))\n\n    self._vslvm_logical_volume = vslvm_volume_group.get_logical_volume(\n        volume_index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a byte string from the file - like object at the current offset.", "response": "def read(self, size=None):\n    \"\"\"Reads a byte string from the file-like object at the current offset.\n\n    The function will read a byte string of the specified size or\n    all of the remaining data if no size was specified.\n\n    Args:\n      size (Optional[int]): number of bytes to read, where None is all\n          remaining data.\n\n    Returns:\n      bytes: data read.\n\n    Raises:\n      IOError: if the read failed.\n      OSError: if the read failed.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    return self._vslvm_logical_volume.read(size)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef seek(self, offset, whence=os.SEEK_SET):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    self._vslvm_logical_volume.seek(offset, whence)", "response": "Seeks to an offset within the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _OpenFileObject(self, path_spec):\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n    qcow_file = pyqcow.file()\n    qcow_file.open_file_object(file_object)\n    return qcow_file", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Main():\n  argument_parser = argparse.ArgumentParser(description=(\n      'Calculates a message digest hash for every file in a directory or '\n      'storage media image.'))\n\n  argument_parser.add_argument(\n      'source', nargs='?', action='store', metavar='image.raw', default=None,\n      help=('path of the directory or filename of a storage media image '\n            'containing the file.'))\n\n  argument_parser.add_argument(\n      '--no-auto-recurse', '--no_auto_recurse', dest='no_auto_recurse',\n      action='store_true', default=False, help=(\n          'Indicate that the source scanner should not auto-recurse.'))\n\n  options = argument_parser.parse_args()\n\n  if not options.source:\n    print('Source value is missing.')\n    print('')\n    argument_parser.print_help()\n    print('')\n    return False\n\n  logging.basicConfig(\n      level=logging.INFO, format='[%(levelname)s] %(message)s')\n\n  output_writer = StdoutWriter()\n\n  if not output_writer.Open():\n    print('Unable to open output writer.')\n    print('')\n    return False\n\n  return_value = True\n  source_analyzer = SourceAnalyzer(auto_recurse=not options.no_auto_recurse)\n\n  try:\n    source_analyzer.Analyze(options.source, output_writer)\n\n    print('Completed.')\n\n  except KeyboardInterrupt:\n    return_value = False\n\n    print('Aborted by user.')\n\n  output_writer.Close()\n\n  return return_value", "response": "The main function of the main program."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _EncodeString(self, string):\n    try:\n      # Note that encode() will first convert string into a Unicode string\n      # if necessary.\n      encoded_string = string.encode(\n          self._preferred_encoding, errors=self._encode_errors)\n    except UnicodeEncodeError:\n      if self._encode_errors == 'strict':\n        logging.error(\n            'Unable to properly write output due to encoding error. '\n            'Switching to error tolerant encoding which can result in '\n            'non Basic Latin (C0) characters to be replaced with \"?\" or '\n            '\"\\\\ufffd\".')\n        self._encode_errors = 'replace'\n\n      encoded_string = string.encode(\n          self._preferred_encoding, errors=self._encode_errors)\n\n    return encoded_string", "response": "Encodes a string in the preferred encoding."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _PromptUserForEncryptedVolumeCredential(\n      self, scan_context, locked_scan_node, output_writer):\n    \"\"\"Prompts the user to provide a credential for an encrypted volume.\n\n    Args:\n      scan_context (SourceScannerContext): the source scanner context.\n      locked_scan_node (SourceScanNode): the locked scan node.\n      output_writer (StdoutWriter): the output writer.\n    \"\"\"\n    credentials = credentials_manager.CredentialsManager.GetCredentials(\n        locked_scan_node.path_spec)\n\n    # TODO: print volume description.\n    if locked_scan_node.type_indicator == (\n        definitions.TYPE_INDICATOR_APFS_CONTAINER):\n      line = 'Found an APFS encrypted volume.'\n    elif locked_scan_node.type_indicator == definitions.TYPE_INDICATOR_BDE:\n      line = 'Found a BitLocker encrypted volume.'\n    elif locked_scan_node.type_indicator == definitions.TYPE_INDICATOR_FVDE:\n      line = 'Found a CoreStorage (FVDE) encrypted volume.'\n    else:\n      line = 'Found an encrypted volume.'\n\n    output_writer.WriteLine(line)\n\n    credentials_list = list(credentials.CREDENTIALS)\n    credentials_list.append('skip')\n\n    # TODO: check which credentials are available.\n    output_writer.WriteLine('Supported credentials:')\n    output_writer.WriteLine('')\n    for index, name in enumerate(credentials_list):\n      output_writer.WriteLine('  {0:d}. {1:s}'.format(index + 1, name))\n    output_writer.WriteLine('')\n\n    result = False\n    while not result:\n      output_writer.WriteString(\n          'Select a credential to unlock the volume: ')\n      # TODO: add an input reader.\n      input_line = sys.stdin.readline()\n      input_line = input_line.strip()\n\n      if input_line in credentials_list:\n        credential_identifier = input_line\n      else:\n        try:\n          credential_identifier = int(input_line, 10)\n          credential_identifier = credentials_list[credential_identifier - 1]\n        except (IndexError, ValueError):\n          output_writer.WriteLine(\n              'Unsupported credential: {0:s}'.format(input_line))\n          continue\n\n      if credential_identifier == 'skip':\n        break\n\n      getpass_string = 'Enter credential data: '\n      if sys.platform.startswith('win') and sys.version_info[0] < 3:\n        # For Python 2 on Windows getpass (win_getpass) requires an encoded\n        # byte string. For Python 3 we need it to be a Unicode string.\n        getpass_string = self._EncodeString(getpass_string)\n\n      credential_data = getpass.getpass(getpass_string)\n      output_writer.WriteLine('')\n\n      result = self._source_scanner.Unlock(\n          scan_context, locked_scan_node.path_spec, credential_identifier,\n          credential_data)\n\n      if not result:\n        output_writer.WriteLine('Unable to unlock volume.')\n        output_writer.WriteLine('')", "response": "Prompts the user to provide a credential for an encrypted volume."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Analyze(self, source_path, output_writer):\n    if not os.path.exists(source_path):\n      raise RuntimeError('No such source: {0:s}.'.format(source_path))\n\n    scan_context = source_scanner.SourceScannerContext()\n    scan_path_spec = None\n    scan_step = 0\n\n    scan_context.OpenSourcePath(source_path)\n\n    while True:\n      self._source_scanner.Scan(\n          scan_context, auto_recurse=self._auto_recurse,\n          scan_path_spec=scan_path_spec)\n\n      if not scan_context.updated:\n        break\n\n      if not self._auto_recurse:\n        output_writer.WriteScanContext(scan_context, scan_step=scan_step)\n      scan_step += 1\n\n      # The source is a directory or file.\n      if scan_context.source_type in [\n          definitions.SOURCE_TYPE_DIRECTORY, definitions.SOURCE_TYPE_FILE]:\n        break\n\n      # The source scanner found a locked volume, e.g. an encrypted volume,\n      # and we need a credential to unlock the volume.\n      for locked_scan_node in scan_context.locked_scan_nodes:\n        self._PromptUserForEncryptedVolumeCredential(\n            scan_context, locked_scan_node, output_writer)\n\n      if not self._auto_recurse:\n        scan_node = scan_context.GetUnscannedScanNode()\n        if not scan_node:\n          return\n        scan_path_spec = scan_node.path_spec\n\n    if self._auto_recurse:\n      output_writer.WriteScanContext(scan_context)", "response": "Analyzes the source path and writes the result to the output writer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef WriteScanContext(self, scan_context, scan_step=None):\n    if scan_step is not None:\n      print('Scan step: {0:d}'.format(scan_step))\n\n    print('Source type\\t\\t: {0:s}'.format(scan_context.source_type))\n    print('')\n\n    scan_node = scan_context.GetRootScanNode()\n    self.WriteScanNode(scan_context, scan_node)\n    print('')", "response": "Writes the source scanner context to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the source scanner node to stdout.", "response": "def WriteScanNode(self, scan_context, scan_node, indentation=''):\n    \"\"\"Writes the source scanner node to stdout.\n\n    Args:\n      scan_context (SourceScannerContext): the source scanner context.\n      scan_node (SourceScanNode): the scan node.\n      indentation (Optional[str]): indentation.\n    \"\"\"\n    if not scan_node:\n      return\n\n    values = []\n\n    part_index = getattr(scan_node.path_spec, 'part_index', None)\n    if part_index is not None:\n      values.append('{0:d}'.format(part_index))\n\n    store_index = getattr(scan_node.path_spec, 'store_index', None)\n    if store_index is not None:\n      values.append('{0:d}'.format(store_index))\n\n    start_offset = getattr(scan_node.path_spec, 'start_offset', None)\n    if start_offset is not None:\n      values.append('start offset: {0:d} (0x{0:08x})'.format(start_offset))\n\n    location = getattr(scan_node.path_spec, 'location', None)\n    if location is not None:\n      values.append('location: {0:s}'.format(location))\n\n    values = ', '.join(values)\n\n    flags = ''\n    if scan_node in scan_context.locked_scan_nodes:\n      flags = ' [LOCKED]'\n\n    print('{0:s}{1:s}: {2:s}{3:s}'.format(\n        indentation, scan_node.path_spec.type_indicator, values, flags))\n\n    indentation = '  {0:s}'.format(indentation)\n    for sub_scan_node in scan_node.sub_nodes:\n      self.WriteScanNode(scan_context, sub_scan_node, indentation=indentation)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _CalculateHashDataStream(self, file_entry, data_stream_name):\n    hash_context = hashlib.sha256()\n\n    try:\n      file_object = file_entry.GetFileObject(data_stream_name=data_stream_name)\n    except IOError as exception:\n      logging.warning((\n          'Unable to open path specification:\\n{0:s}'\n          'with error: {1!s}').format(\n              file_entry.path_spec.comparable, exception))\n      return None\n\n    if not file_object:\n      return None\n\n    try:\n      data = file_object.read(self._READ_BUFFER_SIZE)\n      while data:\n        hash_context.update(data)\n        data = file_object.read(self._READ_BUFFER_SIZE)\n    except IOError as exception:\n      logging.warning((\n          'Unable to read from path specification:\\n{0:s}'\n          'with error: {1!s}').format(\n              file_entry.path_spec.comparable, exception))\n      return None\n\n    finally:\n      file_object.close()\n\n    return hash_context.hexdigest()", "response": "Calculates a message digest hash of the data of a file entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _CalculateHashesFileEntry(\n      self, file_system, file_entry, parent_full_path, output_writer):\n    \"\"\"Recursive calculates hashes starting with the file entry.\n\n    Args:\n      file_system (dfvfs.FileSystem): file system.\n      file_entry (dfvfs.FileEntry): file entry.\n      parent_full_path (str): full path of the parent file entry.\n      output_writer (StdoutWriter): output writer.\n    \"\"\"\n    # Since every file system implementation can have their own path\n    # segment separator we are using JoinPath to be platform and file system\n    # type independent.\n    full_path = file_system.JoinPath([parent_full_path, file_entry.name])\n    for data_stream in file_entry.data_streams:\n      hash_value = self._CalculateHashDataStream(file_entry, data_stream.name)\n      display_path = self._GetDisplayPath(\n          file_entry.path_spec, full_path, data_stream.name)\n      output_writer.WriteFileHash(display_path, hash_value or 'N/A')\n\n    for sub_file_entry in file_entry.sub_file_entries:\n      self._CalculateHashesFileEntry(\n          file_system, sub_file_entry, full_path, output_writer)", "response": "Recursive calculates hashes starting with the file entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves a path to display.", "response": "def _GetDisplayPath(self, path_spec, full_path, data_stream_name):\n    \"\"\"Retrieves a path to display.\n\n    Args:\n      path_spec (dfvfs.PathSpec): path specification of the file entry.\n      full_path (str): full path of the file entry.\n      data_stream_name (str): name of the data stream.\n\n    Returns:\n      str: path to display.\n    \"\"\"\n    display_path = ''\n\n    if path_spec.HasParent():\n      parent_path_spec = path_spec.parent\n      if parent_path_spec and parent_path_spec.type_indicator == (\n          dfvfs_definitions.TYPE_INDICATOR_TSK_PARTITION):\n        display_path = ''.join([display_path, parent_path_spec.location])\n\n    display_path = ''.join([display_path, full_path])\n    if data_stream_name:\n      display_path = ':'.join([display_path, data_stream_name])\n\n    return display_path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencoding the string. Args: string (str): string to encode. Returns: bytes: encoded string.", "response": "def _EncodeString(self, string):\n    \"\"\"Encodes the string.\n\n    Args:\n      string (str): string to encode.\n\n    Returns:\n      bytes: encoded string.\n    \"\"\"\n    try:\n      # Note that encode() will first convert string into a Unicode string\n      # if necessary.\n      encoded_string = string.encode(self._encoding, errors=self._errors)\n    except UnicodeEncodeError:\n      if self._errors == 'strict':\n        logging.error(\n            'Unable to properly write output due to encoding error. '\n            'Switching to error tolerant encoding which can result in '\n            'non Basic Latin (C0) characters to be replaced with \"?\" or '\n            '\"\\\\ufffd\".')\n        self._errors = 'replace'\n\n      encoded_string = string.encode(self._encoding, errors=self._errors)\n\n    return encoded_string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the file path and hash to the file.", "response": "def WriteFileHash(self, path, hash_value):\n    \"\"\"Writes the file path and hash to file.\n\n    Args:\n      path (str): path of the file.\n      hash_value (str): message digest hash calculated over the file data.\n    \"\"\"\n    string = '{0:s}\\t{1:s}\\n'.format(hash_value, path)\n\n    encoded_string = self._EncodeString(string)\n    self._file_object.write(encoded_string)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef WriteFileHash(self, path, hash_value):\n    string = '{0:s}\\t{1:s}'.format(hash_value, path)\n\n    encoded_string = self._EncodeString(string)\n    print(encoded_string)", "response": "Writes the file path and hash to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator that yields the directory entries.", "response": "def _EntriesGenerator(self):\n    \"\"\"Retrieves directory entries.\n\n    Since a directory can contain a vast number of entries using\n    a generator is more memory efficient.\n\n    Yields:\n      OSPathSpec: a path specification.\n\n    Raises:\n      AccessError: if the access to list the directory was denied.\n      BackEndError: if the directory could not be listed.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n    if location is not None:\n      # Windows will raise WindowsError, which can be caught by OSError,\n      # if the process has not access to list the directory. The os.access()\n      # function cannot be used since it will return true even when os.listdir()\n      # fails.\n      try:\n        for directory_entry in os.listdir(location):\n          directory_entry_location = self._file_system.JoinPath([\n              location, directory_entry])\n          yield os_path_spec.OSPathSpec(location=directory_entry_location)\n\n      except OSError as exception:\n        if exception.errno == errno.EACCES:\n          exception_string = str(exception)\n          if not isinstance(exception_string, py2to3.UNICODE_TYPE):\n            exception_string = py2to3.UNICODE_TYPE(\n                exception_string, errors='replace')\n\n          raise errors.AccessError(\n              'Access to directory denied with error: {0!s}'.format(\n                  exception_string))\n        else:\n          raise errors.BackEndError(\n              'Unable to list directory: {0:s} with error: {1!s}'.format(\n                  location, exception))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a directory object.", "response": "def _GetDirectory(self):\n    \"\"\"Retrieves a directory.\n\n    Returns:\n      OSDirectory: a directory object or None if not available.\n    \"\"\"\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return OSDirectory(self._file_system, self.path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetStat(self):\n    stat_object = super(OSFileEntry, self)._GetStat()\n\n    if not self._is_windows_device:\n      # File data stat information.\n      stat_object.size = self._stat_info.st_size\n\n      # Ownership and permissions stat information.\n      stat_object.mode = stat.S_IMODE(self._stat_info.st_mode)\n      stat_object.uid = self._stat_info.st_uid\n      stat_object.gid = self._stat_info.st_gid\n\n      # Other stat information.\n      stat_object.ino = self._stat_info.st_ino\n      # stat_info.st_dev\n      # stat_info.st_nlink\n\n    return stat_object", "response": "Retrieves the stat information about the file entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef access_time(self):\n    if self._stat_info is None:\n      return None\n\n    timestamp = int(self._stat_info.st_atime)\n    return dfdatetime_posix_time.PosixTime(timestamp=timestamp)", "response": "Return the access time of the stat file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef change_time(self):\n    if self._stat_info is None:\n      return None\n\n    timestamp = int(self._stat_info.st_ctime)\n    return dfdatetime_posix_time.PosixTime(timestamp=timestamp)", "response": "Returns the change time of the stat file or None if not available."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef modification_time(self):\n    if self._stat_info is None:\n      return None\n\n    timestamp = int(self._stat_info.st_mtime)\n    return dfdatetime_posix_time.PosixTime(timestamp=timestamp)", "response": "Returns the modification time of the file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetLinkedFileEntry(self):\n    link = self._GetLink()\n    if not link:\n      return None\n\n    path_spec = os_path_spec.OSPathSpec(location=link)\n    return OSFileEntry(self._resolver_context, self._file_system, path_spec)", "response": "Retrieves the linked file entry for example for a symbolic link."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the parent file entry.", "response": "def GetParentFileEntry(self):\n    \"\"\"Retrieves the parent file entry.\n\n    Returns:\n      OSFileEntry: parent file entry or None if not available.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n    if location is None:\n      return None\n\n    parent_location = self._file_system.DirnamePath(location)\n    if parent_location is None:\n      return None\n\n    if parent_location == '':\n      parent_location = self._file_system.PATH_SEPARATOR\n\n    path_spec = os_path_spec.OSPathSpec(location=parent_location)\n    return OSFileEntry(self._resolver_context, self._file_system, path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclosing the file - like object.", "response": "def _Close(self):\n    \"\"\"Closes the file-like object.\n\n    If the file-like object was passed in the init function the file\n    object-based file-like object does not control the file-like object\n    and should not actually close it.\n    \"\"\"\n    if not self._file_object_set_in_init:\n      try:\n        # TODO: fix close being called for the same object multiple times.\n        self._file_object.close()\n      except IOError:\n        pass\n      self._file_object = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens the file - like object defined by path specification.", "response": "def _Open(self, path_spec=None, mode='rb'):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (Optional[PathSpec]): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file-like object could not be opened.\n      OSError: if the file-like object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not self._file_object_set_in_init and not path_spec:\n      raise ValueError('Missing path specification.')\n\n    if self._file_object_set_in_init:\n      return\n\n    self._file_object = self._OpenFileObject(path_spec)\n    if not self._file_object:\n      raise IOError('Unable to open missing file-like object.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, size=None):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    # Do not pass the size argument as a keyword argument since it breaks\n    # some file-like object implementations.\n    return self._file_object.read(size)", "response": "Reads a byte string from the file - like object at the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_offset(self):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if not hasattr(self._file_object, 'get_offset'):\n      return self._file_object.tell()\n    return self._file_object.get_offset()", "response": "Retrieves the current offset into the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the size of the file - like object.", "response": "def get_size(self):\n    \"\"\"Retrieves the size of the file-like object.\n\n    Returns:\n      int: size of the file-like object data.\n\n    Raises:\n      IOError: if the file-like object has not been opened.\n      OSError: if the file-like object has not been opened.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if not hasattr(self._file_object, 'get_size'):\n      if not self._size:\n        current_offset = self.get_offset()\n        self.seek(0, os.SEEK_END)\n        self._size = self.get_offset()\n        self.seek(current_offset, os.SEEK_SET)\n      return self._size\n\n    return self._file_object.get_size()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens the file system defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system defined by path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n      mode (Optional[str]): file access mode. The default is 'rb' which\n          represents read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    range_offset = getattr(path_spec, 'range_offset', None)\n    if range_offset is None:\n      raise errors.PathSpecError(\n          'Unsupported path specification without encoding method.')\n\n    range_size = getattr(path_spec, 'range_size', None)\n    if range_size is None:\n      raise errors.PathSpecError(\n          'Unsupported path specification without encoding method.')\n\n    self._range_offset = range_offset\n    self._range_size = range_size"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n\n    Returns:\n      DataRangeFileEntry: a file entry or None if not available.\n    \"\"\"\n    return data_range_file_entry.DataRangeFileEntry(\n        self._resolver_context, self, path_spec, is_root=True, is_virtual=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetRootFileEntry(self):\n    path_spec = data_range_path_spec.DataRangePathSpec(\n        range_offset=self._range_offset,\n        range_size=self._range_size,\n        parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)", "response": "Retrieves the root file entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens the file system defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system defined by path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n      mode (Optional[str])): file access mode. The default is 'rb' read-only\n          binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      fsapfs_container = pyfsapfs.container()\n      fsapfs_container.open_file_object(file_object)\n    except:\n      file_object.close()\n      raise\n\n    self._file_object = file_object\n    self._fsapfs_container = fsapfs_container"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine if a file entry for a path specification exists.", "response": "def FileEntryExistsByPathSpec(self, path_spec):\n    \"\"\"Determines if a file entry for a path specification exists.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n\n    Returns:\n      bool: True if the file entry exists.\n    \"\"\"\n    volume_index = apfs_helper.APFSContainerPathSpecGetVolumeIndex(path_spec)\n\n    # The virtual root file has not corresponding volume index but\n    # should have a location.\n    if volume_index is None:\n      location = getattr(path_spec, 'location', None)\n      return location is not None and location == self.LOCATION_ROOT\n\n    return 0 <= volume_index < self._fsapfs_container.number_of_volumes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetAPFSVolumeByPathSpec(self, path_spec):\n    volume_index = apfs_helper.APFSContainerPathSpecGetVolumeIndex(path_spec)\n    if volume_index is None:\n      return None\n\n    return self._fsapfs_container.get_volume(volume_index)", "response": "Retrieves an APFS volume for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetFileEntryByPathSpec(self, path_spec):\n    volume_index = apfs_helper.APFSContainerPathSpecGetVolumeIndex(path_spec)\n\n    # The virtual root file has not corresponding volume index but\n    # should have a location.\n    if volume_index is None:\n      location = getattr(path_spec, 'location', None)\n      if location is None or location != self.LOCATION_ROOT:\n        return None\n\n      return apfs_container_file_entry.APFSContainerFileEntry(\n          self._resolver_context, self, path_spec, is_root=True,\n          is_virtual=True)\n\n    if (volume_index < 0 or\n        volume_index >= self._fsapfs_container.number_of_volumes):\n      return None\n\n    return apfs_container_file_entry.APFSContainerFileEntry(\n        self._resolver_context, self, path_spec)", "response": "Retrieves a file entry for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetRootFileEntry(self):\n    path_spec = apfs_container_path_spec.APFSContainerPathSpec(\n        location=self.LOCATION_ROOT, parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)", "response": "Retrieves the root file entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a glob pattern to a regular expression pattern.", "response": "def Glob2Regex(glob_pattern):\n  \"\"\"Converts a glob pattern to a regular expression.\n\n  This function supports basic glob patterns that consist of:\n  *       matches everything\n  ?       matches any single character\n  [seq]   matches any character in sequence\n  [!seq]  matches any character not in sequence\n\n  Args:\n    glob_pattern (str): glob pattern.\n\n  Returns:\n    str: regular expression pattern.\n\n  Raises:\n    ValueError: if the glob pattern cannot be converted.\n  \"\"\"\n  if not glob_pattern:\n    raise ValueError('Missing glob pattern.')\n\n  regex_pattern = []\n\n  glob_pattern_index = 0\n  glob_pattern_length = len(glob_pattern)\n  while glob_pattern_index < glob_pattern_length:\n    character = glob_pattern[glob_pattern_index]\n    glob_pattern_index += 1\n\n    if character == '*':\n      regex_pattern.append('.*')\n\n    elif character == '?':\n      regex_pattern.append('.')\n\n    elif character != '[':\n      regex_character = re.escape(character)\n      regex_pattern.append(regex_character)\n\n    else:\n      glob_group_index = glob_pattern_index\n\n      if (glob_group_index < glob_pattern_length and\n          glob_pattern[glob_group_index] == '!'):\n        glob_group_index += 1\n\n      if (glob_group_index < glob_pattern_length and\n          glob_pattern[glob_group_index] == ']'):\n        glob_group_index += 1\n\n      while (glob_group_index < glob_pattern_length and\n             glob_pattern[glob_group_index] != ']'):\n        glob_group_index += 1\n\n      if glob_group_index >= glob_pattern_length:\n        regex_pattern.append('\\\\[')\n        continue\n\n      glob_group = glob_pattern[glob_pattern_index:glob_group_index]\n      glob_pattern_index = glob_group_index + 1\n\n      glob_group = glob_group.replace('\\\\', '\\\\\\\\')\n      if py2to3.PY_3_7_AND_LATER:\n        glob_group = glob_group.replace('|', '\\\\|')\n\n      regex_pattern.append('[')\n\n      if glob_group[0] == '!':\n        regex_pattern.append('^')\n        glob_group = glob_group[1:]\n\n      elif glob_group[0] == '^':\n        regex_pattern.append('\\\\')\n\n      regex_pattern.append(glob_group)\n      regex_pattern.append(']')\n\n  return ''.join(regex_pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef comparable(self):\n    string_parts = []\n\n    if self.location is not None:\n      string_parts.append('location: {0:s}'.format(self.location))\n    if self.part_index is not None:\n      string_parts.append('part index: {0:d}'.format(self.part_index))\n    if self.start_offset is not None:\n      string_parts.append('start offset: 0x{0:08x}'.format(self.start_offset))\n\n    return self._GetComparable(sub_comparable_string=', '.join(string_parts))", "response": "str - comparable representation of the path specification."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen the file system defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system defined by path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n      mode (Optional[str]): file access mode. The default is 'rb' which\n          represents read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    resolver.Resolver.key_chain.ExtractCredentialsFromPathSpec(path_spec)\n\n    encryption_method = getattr(path_spec, 'encryption_method', None)\n    if not encryption_method:\n      raise errors.PathSpecError(\n          'Unsupported path specification without encryption method.')\n\n    self._encryption_method = encryption_method"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetFileEntryByPathSpec(self, path_spec):\n    return encrypted_stream_file_entry.EncryptedStreamFileEntry(\n        self._resolver_context, self, path_spec, is_root=True, is_virtual=True)", "response": "Retrieves a file entry for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      EncryptedStreamFileEntry: a file entry or None if not available.\n    \"\"\"\n    path_spec = encrypted_stream_path_spec.EncryptedStreamPathSpec(\n        encryption_method=self._encryption_method,\n        parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a JSON dict into a path specification object.", "response": "def _ConvertDictToObject(self, json_dict):\n    \"\"\"Converts a JSON dict into a path specification object.\n\n    The dictionary of the JSON serialized objects consists of:\n    {\n        '__type__': 'PathSpec'\n        'type_indicator': 'OS'\n        'parent': { ... }\n        ...\n    }\n\n    Here '__type__' indicates the object base type in this case this should\n    be 'PathSpec'. The rest of the elements of the dictionary make up the\n    path specification object properties. Note that json_dict is a dict of\n    dicts and the _ConvertDictToObject method will be called for every dict.\n    That is how the path specification parent objects are created.\n\n    Args:\n      json_dict (dict[str, object]): JSON serialized objects.\n\n    Returns:\n      PathSpec: a path specification.\n\n    Raises:\n      TypeError: if the JSON serialized object does not contain a '__type__'\n          attribute that contains 'PathSpec'.\n    \"\"\"\n    # Use __type__ to indicate the object class type.\n    class_type = json_dict.get('__type__', None)\n\n    if class_type not in self._CLASS_TYPES:\n      raise TypeError('Missing path specification object type.')\n\n    # Remove the class type from the JSON dict since we cannot pass it.\n    del json_dict['__type__']\n\n    type_indicator = json_dict.get('type_indicator', None)\n    if type_indicator:\n      del json_dict['type_indicator']\n\n    # Convert row_condition back to a tuple.\n    if 'row_condition' in json_dict:\n      json_dict['row_condition'] = tuple(json_dict['row_condition'])\n\n    return path_spec_factory.Factory.NewPathSpec(type_indicator, **json_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a path specification object into a JSON dictionary.", "response": "def default(self, path_spec_object):\n    \"\"\"Converts a path specification object into a JSON dictionary.\n\n    The resulting dictionary of the JSON serialized objects consists of:\n    {\n        '__type__': 'PathSpec'\n        'type_indicator': 'OS'\n        'parent': { ... }\n        ...\n    }\n\n    Here '__type__' indicates the object base type in this case this should\n    be 'PathSpec'. The rest of the elements of the dictionary make up the\n    path specification object properties. The supported property names are\n    defined in path_spec_factory.Factory.PROPERTY_NAMES. Note that this method\n    is called recursively for every path specification object and creates\n    a dict of dicts in the process that is transformed into a JSON string\n    by the JSON encoder.\n\n    Args:\n      path_spec_object (PathSpec): a path specification.\n\n    Returns:\n      dict[str, object]: JSON serialized objects.\n\n    Raises:\n      TypeError: if not an instance of PathSpec.\n    \"\"\"\n    if not isinstance(path_spec_object, path_spec.PathSpec):\n      raise TypeError\n\n    json_dict = {'__type__': 'PathSpec'}\n    for property_name in path_spec_factory.Factory.PROPERTY_NAMES:\n      property_value = getattr(path_spec_object, property_name, None)\n      if property_value is not None:\n        # Convert row_condition tuple to a list\n        if property_name == 'row_condition':\n          json_dict[property_name] = list(property_value)\n        else:\n          json_dict[property_name] = property_value\n\n    if path_spec_object.HasParent():\n      json_dict['parent'] = self.default(path_spec_object.parent)\n\n    json_dict['type_indicator'] = path_spec_object.type_indicator\n    location = getattr(path_spec_object, 'location', None)\n    if location:\n      json_dict['location'] = location\n\n    return json_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef CacheObject(self, identifier, vfs_object):\n    if identifier in self._values:\n      raise KeyError('Object already cached for identifier: {0:s}'.format(\n          identifier))\n\n    if len(self._values) == self._maximum_number_of_cached_values:\n      raise errors.CacheFullError('Maximum number of cached values reached.')\n\n    self._values[identifier] = ObjectsCacheValue(vfs_object)", "response": "Caches a VFS object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetCacheValueByObject(self, vfs_object):\n    for identifier, cache_value in iter(self._values.items()):\n      if not cache_value:\n        raise RuntimeError('Missing cache value.')\n\n      if cache_value.vfs_object == vfs_object:\n        return identifier, cache_value\n\n    return None, None", "response": "Retrieves the cache value for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve a cached object based on the identifier.", "response": "def GetObject(self, identifier):\n    \"\"\"Retrieves a cached object based on the identifier.\n\n    This method ignores the cache value reference count.\n\n    Args:\n      identifier (str): VFS object identifier.\n\n    Returns:\n      object: cached VFS object or None if not cached.\n    \"\"\"\n    cache_value = self._values.get(identifier, None)\n    if not cache_value:\n      return None\n\n    return cache_value.vfs_object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GrabObject(self, identifier):\n    if identifier not in self._values:\n      raise KeyError('Missing cached object for identifier: {0:s}'.format(\n          identifier))\n\n    cache_value = self._values[identifier]\n    if not cache_value:\n      raise RuntimeError('Missing cache value for identifier: {0:s}'.format(\n          identifier))\n\n    cache_value.IncrementReferenceCount()", "response": "Grabs a cached object based on the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ReleaseObject(self, identifier):\n    if identifier not in self._values:\n      raise KeyError('Missing cached object for identifier: {0:s}'.format(\n          identifier))\n\n    cache_value = self._values[identifier]\n    if not cache_value:\n      raise RuntimeError('Missing cache value for identifier: {0:s}'.format(\n          identifier))\n\n    cache_value.DecrementReferenceCount()", "response": "Releases a cached object based on the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RemoveObject(self, identifier):\n    if identifier not in self._values:\n      raise KeyError('Missing cached object for identifier: {0:s}'.format(\n          identifier))\n\n    del self._values[identifier]", "response": "Removes a cached object based on the identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Decode(self, encoded_data):\n    try:\n      # TODO: replace by libuna implementation or equivalent. The behavior of\n      # base64.b64decode() does not raise TypeError for certain invalid base64\n      # data e.g. b'\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08' these are silently\n      # ignored.\n      decoded_data = base64.b64decode(encoded_data)\n    except (TypeError, binascii.Error) as exception:\n      raise errors.BackEndError(\n          'Unable to decode base64 stream with error: {0!s}.'.format(\n              exception))\n\n    return decoded_data, b''", "response": "Decode the base64 stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef access_time(self):\n    timestamp = self._fsntfs_attribute.get_access_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)", "response": "Returns the current access time of the file system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef creation_time(self):\n    timestamp = self._fsntfs_attribute.get_creation_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)", "response": "Returns the creation time of the file system."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the modification time of the entry in the file system.", "response": "def entry_modification_time(self):\n    \"\"\"dfdatetime.Filetime: entry modification time or None if not set.\"\"\"\n    timestamp = self._fsntfs_attribute.get_entry_modification_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the modification time of the file.", "response": "def modification_time(self):\n    \"\"\"dfdatetime.Filetime: modification time.\"\"\"\n    timestamp = self._fsntfs_attribute.get_modification_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)"}
